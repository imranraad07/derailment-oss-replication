link,title,speaker,comments_count,issue_id,comment_sequence,comment_unique_id,toxic,reply_to,timestamp,text,is_first_comment,tbdf,author_association
https://api.github.com/repos/doctrine/mongodb-odm/issues/540,Throw exception for DateType conversion error and add tests,jmikola,3,12543441,1,12543441,0,0,2013-03-28T00:23:29Z,"@jwage: Please take a look at the first commit here, as it reverts behavior you originally added in b702787. I don't have a record of you following up on my comment there, but I think the behavior was incorrect.

I decided to follow up on this and add some unit tests while merging #533.
",True,0,MEMBER
https://api.github.com/repos/doctrine/mongodb-odm/issues/comments/15655171,Throw exception for DateType conversion error and add tests,tystr,3,12543441,2,15655171,0,12543441,2013-03-29T18:53:51Z,":thumbsup: Seems correct to throw an exception in this case
",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/mongodb-odm/issues/comments/15741721,Throw exception for DateType conversion error and add tests,jmikola,3,12543441,3,15741721,0,15655171,2013-04-01T22:38:19Z,"Note: this will need rebasing if #546 is merged first. Additionally, the test class will need to be fixed to respect the private `Type` constructor.
",False,0,MEMBER
https://api.github.com/repos/doctrine/mongodb-odm/issues/comments/17141038,Throw exception for DateType conversion error and add tests,jwage,3,12543441,4,17141038,0,15741721,2013-04-28T19:38:17Z,":+1:
",False,0,MEMBER
https://api.github.com/repos/doctrine/mongodb-odm/issues/542,Remove unused convert/closure methods in type classes,jmikola,3,12586758,1,12586758,0,0,2013-03-28T21:57:18Z,"- `closureToMongo()` is never used and should likely be removed across the board.
- `convertToPHPValue()` is only used for identifier fields (called by `ClassMetadataInfo::getPHPIdentifierValue()`).

Earlier discussion on this subject: #237
",True,0,MEMBER
https://api.github.com/repos/doctrine/mongodb-odm/issues/comments/111734754,Remove unused convert/closure methods in type classes,malarzm,3,12586758,2,111734754,0,12586758,2015-06-13T17:24:00Z,"@jmikola citing part of https://github.com/doctrine/mongodb-odm/issues/237#issuecomment-39916549

> I know he [@jwage] has plans to ultimately generate code for persister classes as well, so that explains why we have a pair of closure methods.

do we still want to remove `closureToMongo`? Personally I don't think we'll do generated persisters before 2.0.0 :)

/cc @jwage 
",False,0,MEMBER
https://api.github.com/repos/doctrine/mongodb-odm/issues/comments/111736263,Remove unused convert/closure methods in type classes,jmikola,3,12586758,3,111736263,0,111734754,2015-06-13T17:45:43Z,"I don't see the harm in leaving it in place for the existing types, especially since the base Type class includes it. Theoretically, generated Persister classes shouldn't require a major version bump since it'd just be a new feature; however, I think removing the method for 1.0.0 would require a bump to 2.0.0 if we need to introduce the method to the base Type class (which may as well be our interface).
",False,0,MEMBER
https://api.github.com/repos/doctrine/mongodb-odm/issues/comments/111737462,Remove unused convert/closure methods in type classes,malarzm,3,12586758,4,111737462,0,111736263,2015-06-13T18:11:46Z,"I think that we should leave them, maybe they'll come in handy one day :)
",False,0,MEMBER
https://api.github.com/repos/doctrine/mongodb-odm/issues/543,PersistentCollection::count() improvements,sergponomaryov,3,12604115,1,12604115,0,0,2013-03-29T13:18:25Z,"`PersistentCollection::count()` method consumes too much memory and time when there are many referenced documents. It queries and hydrates referenced documents and uses `ArrayCollection::count()` method to get quantity of result elements instead of executing `count` command into database.

This PR improves `PersistentCollection::count()` method. New behavior:
- it executes database `count` command when collection is `InverseSide` and not inititalized yet
- uses `ArrayCollection::count()` method in an opposite way
",True,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/mongodb-odm/issues/comments/17141720,PersistentCollection::count() improvements,jwage,3,12604115,2,17141720,0,12604115,2013-04-28T20:13:47Z,"Cool. Looks like a nice change! :+1:
",False,0,MEMBER
https://api.github.com/repos/doctrine/mongodb-odm/issues/comments/19063913,PersistentCollection::count() improvements,jmikola,3,12604115,3,19063913,0,17141720,2013-06-06T18:15:33Z,"Thanks for the PR. I'm going to hold off on including this in BETA9 because there will be some collection refactoring coming up and I'd like to integrate this with those changes.

In the meantime, there is a [gh543](https://github.com/doctrine/mongodb-odm/tree/gh543) branch with this PR rebased atop master (there were some small conflicts), if anyone would like to grab the change for personal use.
",False,0,MEMBER
https://api.github.com/repos/doctrine/mongodb-odm/issues/comments/21965520,PersistentCollection::count() improvements,jmikola,3,12604115,4,21965520,0,19063913,2013-08-01T20:02:31Z,"See: #649.
",False,0,MEMBER
https://api.github.com/repos/doctrine/mongodb-odm/issues/546,Refactor types to be consistent with other Doctrine adapters,jmikola,4,12680086,1,12680086,0,0,2013-04-01T22:36:16Z,"This includes commits from #203, rebased atop master.

Notable BC breaks:
- Namespace change for all Type classes (`Mapping/` is removed).
- `Type` class constructor is private, so types must be fetched via `Type::getType()` (as is done in 43432d06ca2d4f6a2b8b9eef46ade971958b3260).

/cc @l3pp4rd: Will this pose any problems for your [extensions](https://github.com/l3pp4rd/DoctrineExtensions)?
",True,0,MEMBER
https://api.github.com/repos/doctrine/mongodb-odm/issues/comments/15771827,Refactor types to be consistent with other Doctrine adapters,l3pp4rd,4,12680086,2,15771827,0,12680086,2013-04-02T12:22:26Z,"will check that, thanks for cc @jmikola 
",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/mongodb-odm/issues/comments/15794914,Refactor types to be consistent with other Doctrine adapters,l3pp4rd,4,12680086,3,15794914,0,15771827,2013-04-02T18:53:16Z,"there is a place at least with [translatable](https://github.com/l3pp4rd/DoctrineExtensions/blob/master/lib/Gedmo/Translatable/Mapping/Event/Adapter/ODM.php#L177) which checks the type. There are two ways, either check the odm version or use a new version in the master. When it is planed to be released?
",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/mongodb-odm/issues/comments/15814472,Refactor types to be consistent with other Doctrine adapters,jmikola,4,12680086,4,15814472,0,15794914,2013-04-03T02:32:59Z,"BETA8 is the most recent [tag](https://github.com/doctrine/mongodb-odm/tags), so I would tag BETA9 immediately after merging this. If you'd rather not depend on the versioning, you could add some code to prefer the Type class' new namespace or fall back to the original if that's not found.
",False,0,MEMBER
https://api.github.com/repos/doctrine/mongodb-odm/issues/comments/17140983,Refactor types to be consistent with other Doctrine adapters,jwage,4,12680086,5,17140983,0,15814472,2013-04-28T19:35:26Z,":+1:
",False,0,MEMBER
https://api.github.com/repos/capistrano/capistrano/issues/426,fixed deploy asset precompile recipe ,zxiest,7,12662380,1,12662380,0,0,2013-04-01T14:28:47Z,"bundle exec rake RAILS_ENV=production production assets:precompile was being executed, causing Capistrano to return: Don't know how to build task 'production'. Removing #{assets_env} from command fixes it on rake (10.0.4)
",True,0,CONTRIBUTOR
https://api.github.com/repos/capistrano/capistrano/issues/comments/15788323,fixed deploy asset precompile recipe ,leehambley,7,12662380,2,15788323,0,12662380,2013-04-02T17:00:42Z,"I have to say, I'm not sure how this ever worked, but I'll merge this pull request to a) get rid of it and b) to wake up anyone who's relying on the old behaviour which I believe is simply broken.
",False,0,MEMBER
https://api.github.com/repos/capistrano/capistrano/issues/comments/15803697,fixed deploy asset precompile recipe ,zxiest,7,12662380,3,15803697,0,15788323,2013-04-02T21:26:54Z,"Nice! :-)
",False,0,CONTRIBUTOR
https://api.github.com/repos/capistrano/capistrano/issues/comments/15824044,fixed deploy asset precompile recipe ,nlenepveu,7,12662380,4,15824044,0,15803697,2013-04-03T08:18:10Z,"The default value of `asset_env` should not be ""production"" but some env vars :

``` ruby
_cset :asset_env, ""RAILS_GROUPS=assets""
```

@zxiest I think that your issue is that you overwrite `asset_env`.

This PR has just removed a feature that works well :-) 
",False,0,CONTRIBUTOR
https://api.github.com/repos/capistrano/capistrano/issues/comments/15824430,fixed deploy asset precompile recipe ,leehambley,7,12662380,5,15824430,0,15824044,2013-04-03T08:27:44Z,"Does f975e75 need to be reverted? (I don't use the asset pipeline, so I can't really speak about what is, or isn't working about it)
",False,0,MEMBER
https://api.github.com/repos/capistrano/capistrano/issues/comments/15824585,fixed deploy asset precompile recipe ,nlenepveu,7,12662380,6,15824585,0,15824430,2013-04-03T08:31:46Z,"Yes, please revert it.
",False,0,CONTRIBUTOR
https://api.github.com/repos/capistrano/capistrano/issues/comments/15824686,fixed deploy asset precompile recipe ,leehambley,7,12662380,7,15824686,0,15824585,2013-04-03T08:34:09Z,"If I had known that `_cset :asset_env, ""RAILS_GROUPS=assets""` was committed as part of the asset pipeline I would never have allowed it, that's an absolutely horrible implementation.

``` ruby
_cset(:asset_env, {RAILS_GROUPS: 'assets' }) 
```

Might have been acceptable, but still horrible. I'll revert the change, and try and purge having seen this from my mind.
",False,0,MEMBER
https://api.github.com/repos/capistrano/capistrano/issues/comments/15824730,fixed deploy asset precompile recipe ,leehambley,7,12662380,8,15824730,0,15824686,2013-04-03T08:35:27Z,"Reverted in 082fcf4.
",False,0,MEMBER
https://api.github.com/repos/capistrano/capistrano/issues/427,"Fix ""undefined method shellescape for nil:NilClass (NoMethodError)""",nlenepveu,6,12760224,1,12760224,0,0,2013-04-03T16:19:41Z,"If `deploy:assets:precompile` is executed while no servers match and `current_release` is not yet evaluated, the task try to call `shellescape` on nil.

This prevents this case by just silent error during the build of the command line.
",True,0,CONTRIBUTOR
https://api.github.com/repos/capistrano/capistrano/issues/comments/16392803,"Fix ""undefined method shellescape for nil:NilClass (NoMethodError)""",jimryan,6,12760224,2,16392803,0,12760224,2013-04-15T15:41:34Z,"Can you go into more detail about the scenario that this occurs under?  If we fail to copy the manifest to the release path, that release's assets may be prematurely removed by the `clean_expired` task.  It would also break the `rollback` task.
",False,0,CONTRIBUTOR
https://api.github.com/repos/capistrano/capistrano/issues/comments/16429514,"Fix ""undefined method shellescape for nil:NilClass (NoMethodError)""",nlenepveu,6,12760224,3,16429514,0,16392803,2013-04-16T07:02:28Z,"This fix allows to evaluate the task even if no servers match the assets role. It is not about copy failure as the command won't be executed.
",False,0,CONTRIBUTOR
https://api.github.com/repos/capistrano/capistrano/issues/comments/16431354,"Fix ""undefined method shellescape for nil:NilClass (NoMethodError)""",nlenepveu,6,12760224,4,16431354,0,16429514,2013-04-16T08:00:29Z,"The issue happens if `current_release` is not yet evaluated. The task executes the command to retrieve the current path using its roles rather than the roles of the `current_release` request. As no servers match, `current_release` = nil. 
",False,0,CONTRIBUTOR
https://api.github.com/repos/capistrano/capistrano/issues/comments/16484844,"Fix ""undefined method shellescape for nil:NilClass (NoMethodError)""",jimryan,6,12760224,5,16484844,0,16431354,2013-04-17T03:21:10Z,"I'm sorry, I must still be missing something here.  How is the `precompile` task being run on a server that's not in the assets role?

I'd still like to understand the scenario that prompted this fix, but regardless, if the precompile task is being run and `current_release` is evaluating to `nil`, then the `precompile` task will try to copy the asset manifest file to the server's root directory, which is definitely unexpected, and would (hopefully) fail.  If we fail to back up the manifest to the release path, it breaks rollbacks and will cause any assets associated with only that release to be removed when the `clean_expired` task is invoked if they're older than `expire_assets_after` (default 1 week).
",False,0,CONTRIBUTOR
https://api.github.com/repos/capistrano/capistrano/issues/comments/16494963,"Fix ""undefined method shellescape for nil:NilClass (NoMethodError)""",nlenepveu,6,12760224,6,16494963,0,16484844,2013-04-17T09:09:58Z,"It's not about executing the commands of the `precompile` task, but just evaluating the tasks (to know which commands to execute).

When you run the `deploy` task with `deploy/assets` loaded but no servers have the assets role, the `precompile` task is still evaluated (even if the commands inside are not run), right ? For now, this is not possible when `current_release` is not evaluated yet.

I agree to say that the `current_release` path should not be `nil` at any time, but as it is evaluated inside a task with no servers match the roles, this could not be otherwise.
",False,0,CONTRIBUTOR
https://api.github.com/repos/capistrano/capistrano/issues/comments/16515552,"Fix ""undefined method shellescape for nil:NilClass (NoMethodError)""",jimryan,6,12760224,7,16515552,0,16494963,2013-04-17T16:11:29Z,"Ah, thank you very much for patiently explaining that to me.  I didn't realize that capistrano evaluated the tasks beforehand, even if they're not being invoked.  

Is there ever a situation where a user may invoke the `precompile` task and `current_release` evaluates to `nil`?  I'm concerned that this fix will gloss over that instead of blowing up, which is probably what should happen.  If the assets successfully compile and we don't back up the manifest, the user won't be able to rollback, which will bite them later and it'll be confusing for them to figure out what happened.
",False,0,CONTRIBUTOR
https://api.github.com/repos/capistrano/capistrano/issues/432,Sftp hangs if sftp server run on an another port,milesto,4,12874725,1,12874725,0,0,2013-04-06T10:25:36Z,"I have hosting with sftp server running on port 2222.
SSH on standart port.
When i was trying execute 'cap deploy', connection hanged.
I try to write 'set :ssh_options, :forward_agent => true, :port => 2222', and upload works, but ssh commands does not work.

How i can change default sftp port to 2222?
",True,0,NONE
https://api.github.com/repos/capistrano/capistrano/issues/comments/15995466,Sftp hangs if sftp server run on an another port,leehambley,4,12874725,2,15995466,0,12874725,2013-04-06T12:35:30Z,"Capistrano defers all SCP/SFTP to Net::SSH/SFTP respectively; you'll have to raise that with their maintainers. We use `ssh_options` to open an ssh connection in general, and then we call methods `ssh.{sftp,scp}` on that connection, therefore we don't have a lot of control over what ports/etc might need to be especially assigned.
",False,0,MEMBER
https://api.github.com/repos/capistrano/capistrano/issues/comments/16013414,Sftp hangs if sftp server run on an another port,milesto,4,12874725,3,16013414,0,15995466,2013-04-07T11:23:50Z,"it's a pity.
",False,0,NONE
https://api.github.com/repos/capistrano/capistrano/issues/comments/16013560,Sftp hangs if sftp server run on an another port,leehambley,4,12874725,4,16013560,0,16013414,2013-04-07T11:34:55Z,"@greybird did you open the issue with the netssh/net-scp and netssh/net-sftp repositories?
",False,0,MEMBER
https://api.github.com/repos/capistrano/capistrano/issues/comments/16018732,Sftp hangs if sftp server run on an another port,milesto,4,12874725,5,16018732,0,16013560,2013-04-07T17:02:05Z,"No, i did not.
",False,0,NONE
https://api.github.com/repos/capistrano/capistrano/issues/433,capture on multiple servers,ghost,6,13015301,1,13015301,0,0,2013-04-10T11:59:21Z,"Is there a reason, why once => true is forced on capture? 
Couldn't it be the default, but overwritten if needed?
Codewise, this would only be a small change to lib/capistrano/configuration/actions/inspect.rb, wouldn't it?

Then I e.g. could get the number of running unicorn workers on each server and process it further. 
",True,0,NONE
https://api.github.com/repos/capistrano/capistrano/issues/comments/21115814,capture on multiple servers,gtmtech,6,13015301,2,21115814,0,13015301,2013-07-17T14:18:07Z,"I agree it would be simpler. However you can do this

``` ruby
  desc ""capture output from multiple servers""
  task :capture_multiple_servers, :roles => [:some_servers] do
    results = {}
    run ""hostname --fqdn"" do |channel, stream, data|
      if stream == :out
        results[channel[:host]] = [] unless results.key?(channel[:host])
        results[channel[:host]] << data if stream == :out
      end
    end
    puts ""Your results were:""
    results.keys.sort.each do | host |
      puts ""#{host}:#{results[host].join}""
    end
  end
```
",False,0,NONE
https://api.github.com/repos/capistrano/capistrano/issues/comments/21117716,capture on multiple servers,leehambley,6,13015301,3,21117716,0,21115814,2013-07-17T14:45:01Z,"Relying on the hostname is a hack, infact that entire method is a hack, using all kinds of internal APIs that just can't (in theory) be relied upon. You should take a look at the cap3 `--pre` release, which captures individually on each server.
",False,0,MEMBER
https://api.github.com/repos/capistrano/capistrano/issues/comments/21118626,capture on multiple servers,gtmtech,6,13015301,4,21118626,0,21117716,2013-07-17T14:56:45Z,"I'd be interested to know where you don't envisage it working in case I come up against that situation... what cant be relied upon?
",False,0,NONE
https://api.github.com/repos/capistrano/capistrano/issues/comments/21118789,capture on multiple servers,leehambley,6,13015301,5,21118789,0,21118626,2013-07-17T14:58:41Z,"> `do |channel, stream, data|`

is an undocumented api, and works just as a coincidence related to the current v2 implementation.
",False,0,MEMBER
https://api.github.com/repos/capistrano/capistrano/issues/comments/21118977,capture on multiple servers,gtmtech,6,13015301,6,21118977,0,21118789,2013-07-17T15:01:10Z,"Ah, I took it straight from the bottom of this page : https://github.com/capistrano/capistrano/wiki/2.x-DSL-Action-Invocation-Run

But looking forward to cap3 
",False,0,NONE
https://api.github.com/repos/capistrano/capistrano/issues/comments/21119390,capture on multiple servers,leehambley,6,13015301,7,21119390,0,21118977,2013-07-17T15:06:35Z,"Yeah, some contributions to the wiki aren't exactly what you might call _official_.

You can already play with cap3, and the supporting ssh toolkit library [`sshkit`](https://github.com/leehambley/sshkit) for which there are extensive examples in the `EXAMPLES.md` file
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/717,Timeout on connection,crystalik,22,25881400,1,25881400,0,0,2014-01-19T14:43:37Z,"Added timeout on connection. It's very critical for me.
",True,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32712558,Timeout on connection,dougwilson,22,25881400,2,32712558,0,25881400,2014-01-19T16:42:54Z,"How does this affect the use of the pool? Will this suddenly cause the connections that are idling in the pool to get ejected after 3 seconds? What about performing a query that takes longer than 3 seconds?
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/32713178,Timeout on connection,dougwilson,22,25881400,3,32713178,0,32712558,2014-01-19T17:06:39Z,"Here are my findings:

Since this sets a default timeout of 3 seconds, it seems like this is backwards-incompatible. Performing a query that takes 5 seconds (over the timeout limit):

``` javascript
connection.query('SELECT SLEEP(5)', function(err) {
  if (error) console.error('got error: ' + err);
  console.log('no error');
});
```

results in:

```
got error: Error: timeout
```

when previously with the same connection it would have succeeded just fine. It also doesn't seem like a query taking longer than the timeout should be a protocol error as implemented in their PR, but idk.

This change will in fact cause connections to get ejected from the connection pool after idling for 3 seconds. This seems like it would make the pool less useful, but it would at least be a major change in behavior from before.

What part of the process is this intending to detect a timeout in, as it seems to be triggering all over the place when there isn't an error condition.
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/32724044,Timeout on connection,sidorares,22,25881400,4,32724044,0,32713178,2014-01-19T22:18:57Z,"It might be useful to have connect timeout, but query timeout probably should live in user's code. Another useful timeout - ""How much time command spend in the queue"", sometimes you want to discard query if it spent too much time before actually sent to server
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/32725410,Timeout on connection,dougwilson,22,25881400,5,32725410,0,32724044,2014-01-19T23:07:16Z,"This PR adds a timeout for no network activity on the socket, which seems wrong to me, as it'll timeout when a query takes longer than the timeout (since no data is being sent/received during that time) and it'll timeout when connections sit in the pool (which is valid, but since they don't send/receive data, this kills them).

@crystalik were you intending for this to just be a timeout on connection?
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/32731580,Timeout on connection,crystalik,22,25881400,6,32731580,0,32725410,2014-01-20T03:12:11Z,"Sorry for my English. Try to explain.
I'm building a cluster for sphinx search nodes with realtime (RT) indexes. When one of the search nodes is unavailable, it must be immediately removed from the pool and query should go to another available server. ""Long time"" is 3000 ms by default, and I'm overriding it in connection options and changing it to 500 ms.
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32731759,Timeout on connection,dougwilson,22,25881400,7,32731759,0,32731580,2014-01-20T03:19:33Z,"Ah. As implemented here, this timeout option does not tell you when a server becomes unavailable, rather it tells you when no data has been sent or received for 3000 ms, which kills any query that takes over 3000 ms by default. Also, since the timeout is passed to `setTimeout`, the way the configuration is implemented makes it impossible for people to opt out, as you need to call `setTimeout(0)` to disable the timeout, but the configuration will just override `0` to `3000`.
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/32731760,Timeout on connection,sidorares,22,25881400,8,32731760,0,32731759,2014-01-20T03:19:37Z,"It should work (in theory) with current pool design: if tcp connection is closed pool connection is destroyed.
Have you tried pool or poolCluster?
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/32732901,Timeout on connection,crystalik,22,25881400,9,32732901,0,32731760,2014-01-20T04:01:40Z,"@dougwilson, i set the connection for each request. If the server is unavailable, it will be removed from the cluster through the time that I have (setTimeout(500)). Because the timeout triggered before the connection is established.
""but the configuration will just override 0 to 3000"" - You're right, it is necessary to correct.

@sidorares, я использую poolCluster. Но в нём нет таймаутов на соединение. Если сервер недоступен, то getConnection пытается установить соединение в течение примерно 10 секунд (я не знаю откуда это время). Это слишком много для меня, так как соединение устанавливается при каждом запросе.
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32733693,Timeout on connection,sidorares,22,25881400,10,32733693,0,32732901,2014-01-20T04:33:15Z,"@crystalik - а у тебя есть контроль над shinx серверами? Отчего они бывают ""недоступны""? 10 секунд похоже на таймаут когда от сервера не приходит вообще ничего (т е закрыт файерволом). Eсли сервер не в сети или в сети но никто порт не слушает то обычно мгновенно приходит EHOSTUNREACH или ECONNRESET
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/32734026,Timeout on connection,crystalik,22,25881400,11,32734026,0,32733693,2014-01-20T04:46:50Z,"@sidorares, контроль есть, всё в нашей инфраструктуре. Они иногда падают, и надо мгновенно начать использовать другой сервер. Та реализация, которую я зареквестил, справляется. Если сервер падает и при запросе, коннект не установился в течение 500 мс, то срабатывает timeout, происходит reconnect и согласно Round Robin из пула берётся другой сервер. А этот через n попыток будет удалён из пула.

10 секунд - это когда сервера не в сети, я отключаю vpn, чтобы сымитировать падение.

Возможно, предложенная реализация далека от совершенства :-)
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32734171,Timeout on connection,sidorares,22,25881400,12,32734171,0,32734026,2014-01-20T04:53:34Z,"You can have your custom getConnectionWithTimeout like this:

```
function getConnectionWithTimeoutAndRetries(cb) {
   var connected = false;
   var numRetries = 0;
   var maxRetries = 8;
   var timeout;
   function doConnect() {
     if (numRetries == maxRetries)
       return cb(new Error('doh'));
     pool.getConnection(function(err, conn) {
       if(err) {
           numRetries++;
           return doConnection();
       }
       if (connected) {
           connection.release();
           return;
       } else {
           connected = true;
           clearTimeout(timeout);
           cb(null, connection)
     });
   }
   function checkConnected() {
     if (!connected) {
        cb(new Error('...'))
        connected = true; // prevent callbacks later
     }
   }
   setTimeout(checkConnected, 1000);
   doConnect();
}
```
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/32734265,Timeout on connection,sidorares,22,25881400,13,32734265,0,32734171,2014-01-20T04:57:33Z,"@crystalik можно попробовать пинговать (через connection.ping()) раз в секунду и если ответа нет то выкидывать соединение. setTimeout на сам коннекшн плох по уже указаным причинам - будет закрываться соединение при живом сервере и законных 'SELECT SLEEP(3.5)' ( или просто при падении нагрузки )
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/32734630,Timeout on connection,crystalik,22,25881400,14,32734630,0,32734265,2014-01-20T05:13:51Z,"@sidorares, да, такое решение пробовал. Может до ума не довёл, но получалось так, когда checkConnected() вызывал cb(new Error('...')), то pool.getConnection(...) в doConnect(), продолжало висеть и ждать те самые 10 секунд.
Ну и хотелось нормального решения на уровне драйвера mysql.
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32734704,Timeout on connection,sidorares,22,25881400,15,32734704,0,32734630,2014-01-20T05:16:29Z,"на уровне драйвера будет maxWait тут - #505
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/32734777,Timeout on connection,sidorares,22,25881400,16,32734777,0,32734704,2014-01-20T05:18:53Z,"ну и пускай висит - тебе же уже каллбэк сказал про ошибку?
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/32734926,Timeout on connection,crystalik,22,25881400,17,32734926,0,32734777,2014-01-20T05:24:47Z,"Да, сказал. Попробую давести до ума такое решение. Благодарю за дискуссию.
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32734950,Timeout on connection,sidorares,22,25881400,18,32734950,0,32734926,2014-01-20T05:25:33Z,"не за что :)
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/33877721,Timeout on connection,mikermcneil,22,25881400,19,33877721,0,32734950,2014-02-01T17:28:39Z,"[These guys](https://groups.google.com/forum/#!topic/nodejs/xsCBfrQEJhU) say the config should live in the db itself.  Of course, if you have multiple apps connecting to the same MySQL db, and you don't want to change the settings for your other apps, this doesn't help you.

@felixge Is this something you'd like to see added to node-mysql?  (happy to send a pull request for it, should be pretty trivial)  Otherwise I can just implement a wrapper on the [sails-mysql](https://github.com/balderdashy/sails-mysql/tree/v0.10) side. (and ps- great library, thanks!)

@sidorares @crystalik lost track of what was going on in the conversation there :)  Thanks for the help everyone!
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/33929551,Timeout on connection,felixge,22,25881400,20,33929551,0,33877721,2014-02-03T07:35:27Z,"@mikermcneil I've not fully followed this discussion, but I think you're asking about adding a method that returns a connection that has a server side query timeout configured? I'd be -1 on that as it seems very high level.
",False,0,COLLABORATOR
https://api.github.com/repos/mysqljs/mysql/issues/comments/33966965,Timeout on connection,mikermcneil,22,25881400,21,33966965,0,33929551,2014-02-03T15:46:39Z,"Almost- I mean a setting when connecting that sets a timer for a connection timeout, eg if it takes longer than 30 seconds, callback triggered with error. Very easy to implement, and I can put it in the Sails adapter, but I'm just checking to see if you think it belongs here first :)

## 

Mike's phone

> On Feb 3, 2014, at 1:35, Felix Geisendörfer notifications@github.com wrote:
> 
> @mikermcneil I've not fully followed this discussion, but I think you're asking about adding a method that returns a connection that has a server side query timeout configured? I'd be -1 on that as it seems very high level.
> 
> —
> Reply to this email directly or view it on GitHub.
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/33978143,Timeout on connection,dougwilson,22,25881400,22,33978143,0,33966965,2014-02-03T17:28:33Z,"@mikermcneil does PR #726 implement the timeout that you are looking for?
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/48535458,Timeout on connection,mikermcneil,22,25881400,23,48535458,0,33978143,2014-07-09T21:17:41Z,"@dougwilson I believe so sir, thank you!
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/718,Module does not work in Node.js 0.6 (was: ECONNREFUSED),EgidioCaprino,42,25905222,1,25905222,0,0,2014-01-20T08:46:23Z,"Hello.

I'm trying to connect to MySQL server in this way.

``` javascript
var config = require('./config.js'),
    mysql = require('./node_modules/mysql/index.js'),
    csv = require('./node_modules/csv/index.js'),
    fs = require('fs');

console.log(config.db);

var db = mysql.createConnection(config.db);
db.connect();
```

but I get this error:

```
{ [Error: connect ECONNREFUSED]
  code: 'ECONNREFUSED',
  errno: 'ECONNREFUSED',
  syscall: 'connect',
  fatal: true }
```

I tried all the solution on the web but nothing worked.
",True,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32745864,Module does not work in Node.js 0.6 (was: ECONNREFUSED),jdrydn,42,25905222,2,32745864,0,25905222,2014-01-20T09:48:01Z,"Interesting how you're loading the mysql module - why not:

```
var mysql = require(""mysql"");
```
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32746276,Module does not work in Node.js 0.6 (was: ECONNREFUSED),sidorares,42,25905222,3,32746276,0,32745864,2014-01-20T09:54:31Z,"1) Do you run mysql server locally? 2) can you connect to it with command line client (with ""-h 127.0.0.1"" switch)? 3) what is output of `ps ax |grep mysqld`?
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/32751269,Module does not work in Node.js 0.6 (was: ECONNREFUSED),EgidioCaprino,42,25905222,4,32751269,0,32746276,2014-01-20T11:14:43Z,"@jdrydn I load it in that way because npm install mysql put it in subdirectory of the project.

@sidorares The server is local and I can connect to it by CLI (`mysql -u user -p db -h 127.0.0.1`).  This is the output of `ps ax |grep mysqld`

```
root@host2:~# ps ax |grep mysqld
 7384 ?        Ssl    7:05 /usr/sbin/mysqld
30539 pts/0    S+     0:00 grep --color=auto mysqld
```

Thank you guys.
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32751486,Module does not work in Node.js 0.6 (was: ECONNREFUSED),jdrydn,42,25905222,5,32751486,0,32751269,2014-01-20T11:18:17Z,"Yeh, NPM installs modules to a `node_modules` folder - See http://nodejs.org/api/modules.html#modules_loading_from_node_modules_folders ;)

(Therefore, `require(""mysql"")` resolves to `/node_modules/mysql/index.js` ;) _technically_)
(Also, if you have multiple Node projects, all using the same module, you can put `node_modules` folders up the hierarchy so multiple projects share the same modules :+1: )
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32756054,Module does not work in Node.js 0.6 (was: ECONNREFUSED),EgidioCaprino,42,25905222,6,32756054,0,32751486,2014-01-20T12:38:27Z,"@jdrydn do you think this is the problem? What do you mean exactly with _up the hierarchy_?
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32756208,Module does not work in Node.js 0.6 (was: ECONNREFUSED),jdrydn,42,25905222,7,32756208,0,32756054,2014-01-20T12:41:07Z,"No, I think the problem lies in your database config, especially if you can connect over the CLI, could you comment with the object you have at `config.db` (obviously blanking out usernames and password `;)`). I'm just commenting on the way you seem to have pulled in the mysql module, which I've never seen used like that before!
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32756360,Module does not work in Node.js 0.6 (was: ECONNREFUSED),jdrydn,42,25905222,8,32756360,0,32756208,2014-01-20T12:43:31Z,"I.e. Mine often looks like:

``` javascript
    var config = {
        database: {
            host: ""localhost"",
            user: ""myawesomeuser"",
            password: ""mysecurepassword"",
            database: ""thedatabase""
        }
    };

    var mysql = require(""mysql"");

    var connection = mysql.createConnection(config.database);

```
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32756516,Module does not work in Node.js 0.6 (was: ECONNREFUSED),EgidioCaprino,42,25905222,9,32756516,0,32756360,2014-01-20T12:46:25Z,"Thank you. This is the definition of _config.db_.

``` javascript
exports.db = {
    host: '127.0.0.1',
    user: 'user',
    password: 'passwd',
    database: 'zadmin_shopriparando'
};
```
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32756567,Module does not work in Node.js 0.6 (was: ECONNREFUSED),EgidioCaprino,42,25905222,10,32756567,0,32756516,2014-01-20T12:47:10Z,"What settings do you think are wrong with my DB?
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32756850,Module does not work in Node.js 0.6 (was: ECONNREFUSED),jdrydn,42,25905222,11,32756850,0,32756567,2014-01-20T12:52:03Z,"What I would do, for debugging irritating connection issues like this, is put the contents of the example (https://github.com/felixge/node-mysql#introduction) into a file `testdatabase.js`, fill in your connection details, and try running that on it's own (`$ node testdatabase.js`).

Do you still get a connection issue?

---

**Edit:** If no, then perhaps it's a problem with your user not being able to access your database? Check the privileges of of your database, make sure the user can do stuff on the database.
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32757341,Module does not work in Node.js 0.6 (was: ECONNREFUSED),EgidioCaprino,42,25905222,12,32757341,0,32756850,2014-01-20T13:00:31Z,"The problem persists. I tried with

``` javascript
var mysql = require('mysql');
var connection = mysql.createConnection({
    host : 'testdb',
    user: 'me',
    password: 'beryqeqes',
    database: 'zadmin_testdb'
});

connection.connect();
```

but I get the same error. I do not know if it matters, but we use ZPanel to manage databases and users.
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32758001,Module does not work in Node.js 0.6 (was: ECONNREFUSED),jdrydn,42,25905222,13,32758001,0,32757341,2014-01-20T13:11:18Z,"Take off the database parameter, can you connect to the MySQL server?
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32758246,Module does not work in Node.js 0.6 (was: ECONNREFUSED),EgidioCaprino,42,25905222,14,32758246,0,32758001,2014-01-20T13:15:52Z,"No. Same error :(
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32758699,Module does not work in Node.js 0.6 (was: ECONNREFUSED),tgvashworth,42,25905222,15,32758699,0,32758246,2014-01-20T13:22:54Z,"Possibly stupid question but: you do actually have a mysql server running, right?

@jdrydn sup ;)
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32759014,Module does not work in Node.js 0.6 (was: ECONNREFUSED),EgidioCaprino,42,25905222,16,32759014,0,32758699,2014-01-20T13:28:14Z,"@phuu sure. I can also connect to the database through CLI, with the same credentials I use in the script.
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32761254,Module does not work in Node.js 0.6 (was: ECONNREFUSED),dougwilson,42,25905222,17,32761254,0,32759014,2014-01-20T14:01:23Z,"This simply means that you cannot connect to MySQL because it has networking disabled. You can connect to it using the UNIX socket. Get the path using `mysql_config --socket` and they set that as the `socketPath` option in the connection configuration.
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/32762784,Module does not work in Node.js 0.6 (was: ECONNREFUSED),jdrydn,42,25905222,18,32762784,0,32761254,2014-01-20T14:21:59Z,"@phuu Sup dawg ;)
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32784694,Module does not work in Node.js 0.6 (was: ECONNREFUSED),EgidioCaprino,42,25905222,19,32784694,0,32762784,2014-01-20T18:31:41Z,"@dougwilson thank you. I will try as soon as I can.
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/33213077,Module does not work in Node.js 0.6 (was: ECONNREFUSED),cazgp,42,25905222,20,33213077,0,32784694,2014-01-24T10:43:39Z,"`mysql_config --socket` + `socketPath` worked :)
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/33670150,Module does not work in Node.js 0.6 (was: ECONNREFUSED),s2zaman,42,25905222,21,33670150,0,33213077,2014-01-30T08:59:56Z,"I got the same error as below while running `compound server`

```
Compound server listening on 0.0.0.0:3000 within development environment
connection.connect err { [Error: connect ECONNREFUSED]
  code: 'ECONNREFUSED',
  errno: 'ECONNREFUSED',
  syscall: 'connect',
  fatal: true }
connection.connect err { [Error: connect ECONNREFUSED]
```

I guessed it as missing of MySQL.
So i used WAMP Server’s MySQL. (actually i stopped the APACHE and PHP services in it and used only the MySQL service). This was temporary solution.

What may be the possible good solution for this Error.
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/36625347,Module does not work in Node.js 0.6 (was: ECONNREFUSED),jacog,42,25905222,22,36625347,0,33670150,2014-03-04T13:53:17Z,"Can confirm same issue as OP. Have one lamp stack, php connects without problems. node with mysql (from same host as db and default port) gives:
<code>
{ [Error: connect ECONNREFUSED]
  code: 'ECONNREFUSED',
  errno: 'ECONNREFUSED',
  syscall: 'connect',
  fatal: true }
</code>

connecting via socketPath works.
User has access to applicable schemas. User can connect from localhost. User can connect from php.
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/36638658,Module does not work in Node.js 0.6 (was: ECONNREFUSED),dougwilson,42,25905222,23,36638658,0,36625347,2014-03-04T15:51:08Z,"@jacog this is not a bug. Your PHP is connecting over a UNIX socket, not over TCP. This module simply makes you explicitly chose instead of defaulting to a hard-coded UNIX socket path like PHP does. If you want to connect over TCP with this module, you'll need to enable networking in your MySQL server, otherwise continue to use the `socketPath` option.
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/36660906,Module does not work in Node.js 0.6 (was: ECONNREFUSED),jacog,42,25905222,24,36660906,0,36638658,2014-03-04T19:04:56Z,"@dougwilson thanx for the info, I didn't know php does that by itself. It is a bit weird that even though in php you specify hostname / port and not socket path. Perhaps it does it because it is on the same box. I looked over the mysql cnf, didnt see anything disabling networking. Will have another look. Thanks.
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/36661291,Module does not work in Node.js 0.6 (was: ECONNREFUSED),dougwilson,42,25905222,25,36661291,0,36660906,2014-03-04T19:08:14Z,"@jacog the setting is called `skip-networking`: http://dev.mysql.com/doc/refman/5.1/en/server-options.html#option_mysqld_skip-networking It is typically enabled (i.e. it disables TCP) out-of-the-box on things like Ubuntu.
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/36662129,Module does not work in Node.js 0.6 (was: ECONNREFUSED),dougwilson,42,25905222,26,36662129,0,36661291,2014-03-04T19:15:16Z,"@jacog The setting is probably in the `/etc/mysql/my.cnf` file. See if there is a `skip-networking` line in there, remove it, and restart MySQL. This will open your MySQL install up to the network, though, so be careful.
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/36715332,Module does not work in Node.js 0.6 (was: ECONNREFUSED),jacog,42,25905222,27,36715332,0,36662129,2014-03-05T06:58:19Z,"@dougwilson Interesting thing is, I can connect to my server from my workstation (which is a different machine altogether) with mysql workbench - using ip / port. Well connecting via socket is fine. For anyone strugling with this, you can find your socketPath in <code>/etc/mysql/my.cnf</code> on ubuntu it should be <code>/var/run/mysqld/mysqld.sock</code>
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/36751341,Module does not work in Node.js 0.6 (was: ECONNREFUSED),dougwilson,42,25905222,28,36751341,0,36715332,2014-03-05T15:09:53Z,"@jacog it's possible your MySQL is bound and listening only on your external IP and not on your localhost as well. Another possibility is that your localhost is resolving to something weird so changing it to 127.0.0.1 may work.
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/36752275,Module does not work in Node.js 0.6 (was: ECONNREFUSED),dougwilson,42,25905222,29,36752275,0,36751341,2014-03-05T15:17:44Z,"To everyone here, I'm going to close this issue since it has gotten very long as is not even a bug with this module unless there is a patch that fixes the issue. `ECONNREFUSED` comes with within node.js and is because there is either nothing listening on `127.0.0.1:3306`.

There are many ways you can check this. One way is to use `netstat` to verify there is a TCP listening socket at 127.0.0.1:3306:

```
sudo netstat -nalp | grep 3306
tcp        0      0 127.0.0.1:3306          0.0.0.0:*               LISTEN      18241/mysqld
```
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/40725181,Module does not work in Node.js 0.6 (was: ECONNREFUSED),LoicGombeaud,42,25905222,30,40725181,0,36752275,2014-04-17T15:13:49Z,"I am getting the same error; the MySQL server I am trying to connect to is on a different host, and I can connect to it via the CLI client as well as via PHP, by specifying its IP (it also works by specifying its DNS name). I can also telnet to it.
When trying the following code, I get the same error as mentioned above: ECONNREFUSED

``` javascript
var mysql = require('mysql');

var connection = mysql.createConnection({
       host: 'db.domain.tld',
       user: 'myuser',
       password: 'secret',
       database: 'something'
});
connection.connect(function(err) {
       console.log(err);
});
```

Can you please tell me how to test further, to find the exact cause of the issue?
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/40729326,Module does not work in Node.js 0.6 (was: ECONNREFUSED),dougwilson,42,25905222,31,40729326,0,40725181,2014-04-17T15:48:50Z,"@loicAG `ECONNREFUSED` means that something is actively rejecting your TCP connection to `db.domain.tld` on port 3306. You can always try running this command from the machine that would run your node.js mysql client: `nc -v -z db.domain.tld 3306`. If this fails, there is something wrong with how your MySQL server it setup, something wrong with the network between the machines, or a firewall blocking the connection somewhere.
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/721,Query result empty after first query,denyskoch,22,26044044,1,26044044,0,0,2014-01-21T20:55:32Z,"on the first execution the query result ist correct, but on the next execution of this block the result is empty, why?

```
var query = db.query(lastSessionQuery, [channel], function(err, result){
    if(err) {
        console.log('[error][mysql] query for last session failed!', query.sql, err);
        return;
    }
    publisher.raw(channel, result); 
});  
```
",True,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32962410,Query result empty after first query,sidorares,22,26044044,2,32962410,0,26044044,2014-01-21T20:57:08Z,"What's in the error? Could be dropped network connection or lots of different reasons
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/32962558,Query result empty after first query,denyskoch,22,26044044,3,32962558,0,32962410,2014-01-21T20:58:34Z,"there is no error ...
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32962807,Query result empty after first query,sidorares,22,26044044,4,32962807,0,32962558,2014-01-21T21:00:58Z,"so this line is not executed? `console.log('[error][mysql] query for last session failed!', query.sql, err);`
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/32963013,Query result empty after first query,denyskoch,22,26044044,5,32963013,0,32962807,2014-01-21T21:02:58Z,"no is it not, the line 
    publisher.raw(channel, result); 

is everytime executed :)
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32963167,Query result empty after first query,sidorares,22,26044044,6,32963167,0,32963013,2014-01-21T21:04:29Z,"can you show your `lastSessionQuery` and `result`?
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/32963410,Query result empty after first query,denyskoch,22,26044044,7,32963410,0,32963167,2014-01-21T21:06:55Z,"``` javascript
var lastSessionQuery = '\
SELECT \
    channel, \
    time, \
    latitude, \
    longitude \
FROM ( \
    SELECT \
        time, \
        (@prev_time - time) AS time_diff, \
        IF( (@prev_time - time) > 300, @prev_time := 9999999999,@prev_time := time) AS prev_time, \                                                                                                                                           
        latitude, \
        longitude, \
        channel \
    FROM \
        waypoints, (SELECT @prev_time := 0) AS diffs \
    WHERE waypoints.channel = ? \
    ORDER BY time DESC \
) AS tmp \
 \
WHERE tmp.time_diff < 300 \
ORDER BY time DESC \
';
```

result is []
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32963584,Query result empty after first query,sidorares,22,26044044,8,32963584,0,32963410,2014-01-21T21:08:36Z,"this is strange, result can't be empty array. One more try: could you show output when client is connected with `debug: true`?
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/32964017,Query result empty after first query,denyskoch,22,26044044,9,32964017,0,32963584,2014-01-21T21:12:47Z,"see first query with non-empty result and second with empty result(wrong): https://gist.github.com/denyskoch/8548467
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32964222,Query result empty after first query,dougwilson,22,26044044,10,32964222,0,32964017,2014-01-21T21:14:54Z,"I believe it is because you are trying to reset the `@prev_time` variable in `(SELECT @prev_time := 0) AS diffs`, but that runs too late, so `@prev_time` contains the value from your previous run, which is why the second run produces different results. Usually you can use a `CROSS JOIN` to reset your variable as part of the query.
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/32964251,Query result empty after first query,sidorares,22,26044044,11,32964251,0,32964222,2014-01-21T21:15:07Z,"oops, I'm wrong - result can be empty. You just have zero rows in response, this is ok
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/32965098,Query result empty after first query,dougwilson,22,26044044,12,32965098,0,32964251,2014-01-21T21:24:27Z,"@denyskoch try this query, where the variable reset is first:

``` sql
SELECT
    channel,
    time,
    latitude,
    longitude
FROM (
    SELECT
        time,
        (@prev_time - time) AS time_diff,
        IF( (@prev_time - time) > 300, @prev_time := 9999999999,@prev_time := time) AS prev_time,
        latitude,
        longitude,
        channel
    FROM
        (SELECT @prev_time := 0) AS vars
        JOIN waypoints
    WHERE waypoints.channel = ?
    ORDER BY time DESC
) AS tmp
WHERE tmp.time_diff < 300
ORDER BY time DESC
```
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/32965507,Query result empty after first query,denyskoch,22,26044044,13,32965507,0,32965098,2014-01-21T21:28:34Z,"@dougwilson still not work :(
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32966359,Query result empty after first query,dougwilson,22,26044044,14,32966359,0,32965507,2014-01-21T21:37:26Z,"OK. Can you run this and send the output?

``` javascript
function run(next) {
  db.query('SELECT @prev_time AS t', function (err, rows) {
    if (err) throw err;
    console.log('prev_time=' + rows[0].t);
    db.query(lastSessionQuery, [channel], function (err, result) {
      if (err) throw err;
      console.log(result.length + ' results');
      next && next();
    });
  });
}

run(run.bind(null,run));
```
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/32966669,Query result empty after first query,denyskoch,22,26044044,15,32966669,0,32966359,2014-01-21T21:40:55Z,"```
prev_time=null
6 results
prev_time=9999999999
0 results
prev_time=9999999999
0 results
´´´
```
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32966828,Query result empty after first query,dougwilson,22,26044044,16,32966828,0,32966669,2014-01-21T21:42:49Z,"OK. Now if you run this and it works, you need to fix your query to correctly reset the `@prev_time` variable, which is beyond me, and not an issue with this library:

``` javascript
function run(next) {
  db.query('SET @prev_time := NULL', function (err, rows) {
    if (err) throw err;
    db.query(lastSessionQuery, [channel], function (err, result) {
      if (err) throw err;
      console.log(result.length + ' results');
      next && next();
    });
  });
}

run(run.bind(null,run));
```
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/32966985,Query result empty after first query,denyskoch,22,26044044,17,32966985,0,32966828,2014-01-21T21:44:45Z,"6 results
0 results
0 results
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32967285,Query result empty after first query,dougwilson,22,26044044,18,32967285,0,32966985,2014-01-21T21:47:54Z,"Try this:

``` javascript
function run(next) {
  db.query(lastSessionQuery.replace(/SELECT/g, 'SELECT SQL_NO_CACHE'), [channel], function (err, result) {
    if (err) throw err;
    console.log(result.length + ' results');
    next && next();
  });
}

run(run.bind(null,run));
```
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/32967606,Query result empty after first query,denyskoch,22,26044044,19,32967606,0,32967285,2014-01-21T21:50:58Z,"still:

```
6 results
0 results
0 results
```
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32967679,Query result empty after first query,dougwilson,22,26044044,20,32967679,0,32967606,2014-01-21T21:51:43Z,"Can you open a MySQL shell and run the query three times in a row and see if you get 6 results each time, or the 6-0-0 pattern?
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/32968277,Query result empty after first query,denyskoch,22,26044044,21,32968277,0,32967679,2014-01-21T21:57:31Z,"on mysql console getting 6 - 0 - 0
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/32968402,Query result empty after first query,dougwilson,22,26044044,22,32968402,0,32968277,2014-01-21T21:58:48Z,"Ok, then that definitely means you have a problem with your query. If it doesn't work in the MySQL shell, it's not going to work in this library, as it's basically doing the same thing. Your query is beyond me, so I don't know what you need to change to fix it, but it is leaving some state behind from the first execution that is changing the subsequent executions.
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/32969529,Query result empty after first query,denyskoch,22,26044044,23,32969529,0,32968402,2014-01-21T22:09:37Z,"hmm looks like this ist not related to node-mysql. thanks :+1: 
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/724, Connection lost: The server closed the connection.,masterofdaemon,5,26702229,1,26702229,0,0,2014-01-31T17:40:28Z,"here is the code:
out = fs.createWriteStream ""input.txt.gz""
connection.query(""select id from user limit 1;"").stream({encoding:""binary""}).pipe(out)
it's waiting time:
real    1m5.522s
user    0m0.214s
sys 0m0.031s
until server drop my connetion
",True,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/33826737, Connection lost: The server closed the connection.,dougwilson,5,26702229,2,33826737,0,26702229,2014-01-31T18:07:01Z,"It looks like this is because the stream that is created is not emitting `end` when the stream ends, only `close`.
",False,0,MEMBER
https://api.github.com/repos/mysqljs/mysql/issues/comments/33827233, Connection lost: The server closed the connection.,masterofdaemon,5,26702229,3,33827233,0,33826737,2014-01-31T18:12:47Z,"this code work's fine: var gzip = zlib.createGzip();
var fs = require('fs');
var inp = fs.createReadStream('input.txt');
var out = fs.createWriteStream('input.txt.gz');

inp.pipe(gzip).pipe(out);

and i think it is the same streams 
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/33827524, Connection lost: The server closed the connection.,masterofdaemon,5,26702229,4,33827524,0,33827233,2014-01-31T18:16:12Z,"http://nodejs.org/api/stream.html#stream_event_close - ""not all streams will emit this"", but how can i handle this issue ?
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/33827869, Connection lost: The server closed the connection.,masterofdaemon,5,26702229,5,33827869,0,33827524,2014-01-31T18:20:42Z,"connection.end() its sync constructions
",False,0,NONE
https://api.github.com/repos/mysqljs/mysql/issues/comments/33828402, Connection lost: The server closed the connection.,dougwilson,5,26702229,6,33828402,0,33827869,2014-01-31T18:26:50Z,"Ah, yes, an open connection to MySQL will hold on your process.
",False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/6,Move (important) old issues to GitHub?,gigaherz,8,30125570,1,30125570,0,0,2014-03-25T14:04:06Z,"We need to decide what to do with the old issues.

Options:
- ~~Ignore old issues, make people open new issues here.~~
- **Do nothing, keep track of old issues in the old issue tracker, use new issues from here.**
- ~~Manually copy important issues to this issue tracker, abandon low-priority issues.~~

Gcode Issue Tracker: http://code.google.com/p/pcsx2/issues/list

Comments welcome.
",True,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/38567738,Move (important) old issues to GitHub?,gigaherz,8,30125570,2,38567738,0,30125570,2014-03-25T14:07:09Z,"CCing @PCSX2/owners 
",False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/38573752,Move (important) old issues to GitHub?,ramapcsx2,8,30125570,3,38573752,0,38567738,2014-03-25T14:54:36Z,"I vote on option 2, simply because we always lacked the manpower to keep track of all the issues anyway. The Google issue tracker will stay online for ages, simply check the one for PCSX2 Playground :)
",False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/38574952,Move (important) old issues to GitHub?,gregory38,8,30125570,4,38574952,0,38573752,2014-03-25T15:03:34Z,"Same for me. Option 2. Besides, people won't be registered anymore to the bug, and therefore less likely to reply if we need more info.
",False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/38659221,Move (important) old issues to GitHub?,gregory38,8,30125570,5,38659221,0,38574952,2014-03-26T08:23:06Z,"However I'm in favor to get back the wiki page ;)
",False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/38660035,Move (important) old issues to GitHub?,gigaherz,8,30125570,6,38660035,0,38659221,2014-03-26T08:35:49Z,"What Wiki page? If you mean this: http://code.google.com/p/pcsx2/wiki/IssuesNotice?tm=3
That page appears when you click on the Issues icon, from the gcode site, I direct-linked to the issues list from here.
",False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/38700669,Move (important) old issues to GitHub?,sudonim1,8,30125570,7,38700669,0,38660035,2014-03-26T15:49:51Z,"Well they can be moved any time if we change our mind, there's no need for an immediate clean break.
",False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/38700892,Move (important) old issues to GitHub?,sudonim1,8,30125570,8,38700892,0,38700669,2014-03-26T15:51:20Z,"Hmm actually there may even be a good reason to leave old issues on there: the svn revision autolinks.
",False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/38701226,Move (important) old issues to GitHub?,gigaherz,8,30125570,9,38701226,0,38700892,2014-03-26T15:53:55Z,"Okay let's call this an official consensus, then: Old issues stay where they are. Closing as resolved.
",False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/8,Feature Request: Framelimiter for GSDX for use in PSX emulators.,ghost,16,30325838,1,30325838,0,0,2014-03-27T17:56:42Z,"GSDX can be used in PSX emulators but without framelimiter it's way to fast in many cases. Could you please create some kind of framelimiting hack or option in GSDX for use in emulators like EPSXE and especially PCSX-Reloaded. Also dedicated hotkey to toggle this framelimiter would be helpful.
",True,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/38886986,Feature Request: Framelimiter for GSDX for use in PSX emulators.,ghost,16,30325838,2,38886986,0,30325838,2014-03-28T04:01:26Z,"Don't we already have a frame limiter built in?
",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/38930232,Feature Request: Framelimiter for GSDX for use in PSX emulators.,ghost,16,30325838,3,38930232,0,38886986,2014-03-28T15:16:17Z,"Oh okay I support your idea sounds great
",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39018389,Feature Request: Framelimiter for GSDX for use in PSX emulators.,Squall-Leonhart,16,30325838,4,39018389,0,38930232,2014-03-30T05:50:44Z,"Frame limiter should not be performed from the graphics plugin side, it should be always done from the SPU
",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39021398,Feature Request: Framelimiter for GSDX for use in PSX emulators.,gigaherz,16,30325838,5,39021398,0,39018389,2014-03-30T09:35:29Z,"@Squall-Leonhart Framelimiting from the audio side only works well if the buffer ""piece"" size is small. In Vista and up, the sound mixer works in something like 1024 or 2048 sample increments, which translates to 42.67ms intervals. At 60fps, the interval between frames should be of 16.67ms, but since the audio sync results in 42.67ms jumps, it sends an average of 2.56 frames (that means it sends 3 frames a bit more times than it sends 2) every time the audio writes a new buffer to the mixer queue. Essentially, it results in uneven framerate.

If you used exclusive hardware streaming, and a block size no larger than 800 samples, then sound-based limiting would be usable. Ideally, though, you'd want an even smaller size, so that the intervals have a higher chance of matching the required frame ""timings"". But for everyone else who's stuck on the software mixer, it's not doable.
",False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39336897,Feature Request: Framelimiter for GSDX for use in PSX emulators.,pal1000,16,30325838,6,39336897,0,39021398,2014-04-02T14:30:25Z,"Seeing this post made me give a try on using GSDX on ePSXe 1.9.0. After a couple of tests I managed to get it into an usable state. The big problem that was spotted is the emulator speed. For ePSXe I solved this by using the core SPU from ePSXe instead of any other SPU.
Other problems that probably weren't mentioned:
-ePSXe may crash when game boots while using GSDX;
-ePSXe crashes if you load state before anything gets drawn on screen (don't load state too soon, be patient or press F4 to fast forward);
-when pausing game an orange-like layout  may be drawn over all windows borders and taskbar (wears off when exit ePSXe);
-1 bad thing will happen when you resume emulation chosen randomly from this list:
1. ePSXe crashes;
2. graphics looks horribly messed up until the game does a full screen clearing. After this some elements will be missing until game is reset. Workaround: Save state before pausing emulation then load the state after you resume.

GSDX can be used experimentally on ePSXe if you watch out for these:
-don't load state until something gets drawn on screen;
-save state before pausing emulation.
As for settings I set the internal resolution to Hx2 - Vx2.(you can try Hx4 - Vx4 if you have a very powerful Nvidia GPU); the best filter is the Nearest filter, bilinear looks pretty bad; in terms of performance and even accuracy GDSX beats  Pete's OpenGL2 plugin, but all these problems I discovered while playing Final Fantasy IX makes it into an experiment for PSX emulation rather than a true solution. 
",False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39337607,Feature Request: Framelimiter for GSDX for use in PSX emulators.,ghost,16,30325838,7,39337607,0,39336897,2014-04-02T14:36:08Z,"But there is another feature to do with frames you don't have a increase frame rate button/key like most other emulator
",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39342873,Feature Request: Framelimiter for GSDX for use in PSX emulators.,Squall-Leonhart,16,30325838,8,39342873,0,39337607,2014-04-02T15:16:04Z,"opinions are not fact.

GSDX is not likely to get any improvement for PSX emulators until such time as pcsx2 implements PSX support (which is likely never to happen)

Its actually been discussed that the psx support be removed on a number of occasions.
",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39344224,Feature Request: Framelimiter for GSDX for use in PSX emulators.,Squall-Leonhart,16,30325838,9,39344224,0,39342873,2014-04-02T15:26:52Z,"No it didn't, there were no GSDX changes in that patch Refraction provided.
",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39345278,Feature Request: Framelimiter for GSDX for use in PSX emulators.,gigaherz,16,30325838,10,39345278,0,39344224,2014-04-02T15:35:03Z,"People, if you want to have a conversation, use the forums. This is meant to give feedback/details on the given issue.
",False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39345775,Feature Request: Framelimiter for GSDX for use in PSX emulators.,Squall-Leonhart,16,30325838,11,39345775,0,39345278,2014-04-02T15:38:48Z,"No changes to GSDX have been made in regards to the PSX support in 5927, it was specifically changes to build files.

5921 is the ""Initial Work"" patch and there was no changes to GSDX.

""How do you now GSDX wont be improved for PSX emulation? You are not PCSX2 developer Squall.""
https://code.google.com/p/pcsx2/issues/detail?id=1363#c3

Because I've spoken with Alex and Rama2 about gsdx's psx support on numerous occasions, and gsdx being the prized work of Gabest that it is....

@Gigaherz, 
This is feedback.
",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39348654,Feature Request: Framelimiter for GSDX for use in PSX emulators.,Squall-Leonhart,16,30325838,12,39348654,0,39345775,2014-04-02T16:01:59Z,"PSX games use variable framerates depending on what is being drawn on screen, and are restricted based on Core or SPU timing.
Games which use 3D objects are often 30fps and only 60fps when the menu's are visible as they are rendered every other frame.

Restricting the performance in the gpu plugin will see these games go fast forward in the cases where they should be operating at 30fps, but are now operating at a capped 60 because the graphics plugin doesn't actually have any notion of how fast the game timing should be running.
",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39349455,Feature Request: Framelimiter for GSDX for use in PSX emulators.,Squall-Leonhart,16,30325838,13,39349455,0,39348654,2014-04-02T16:08:57Z,""" and work fine.""
No they don't.
",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39380890,Feature Request: Framelimiter for GSDX for use in PSX emulators.,gregory38,16,30325838,14,39380890,0,39349455,2014-04-02T20:43:17Z,"Hum someone sent me some patches to make gsdx ogl run on linux 64 bits. He only got a black screen. I try the patch on my side but i only got a crash. Maybe when I have time I will try to look. Anyway end of trolling, we understand the issue and it is at lowest stage of priority.

Note for the crash. I think they change a bits the interface of the plugin. On linux, gcc detects a stack corruption.
",False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39444793,Feature Request: Framelimiter for GSDX for use in PSX emulators.,ramapcsx2,16,30325838,15,39444793,0,39380890,2014-04-03T12:28:29Z,"Since I like the PSX a lot I would spend time investigating this, but it really doesn't have much to do with PCSX2 or GSdx. Yes, GSdx supports a PSX mode but no one really knows why.
This entire feature should get requested in PSX emulator repositories!
",False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39449050,Feature Request: Framelimiter for GSDX for use in PSX emulators.,Squall-Leonhart,16,30325838,16,39449050,0,39444793,2014-04-03T13:15:27Z,"""Yes, GSdx supports a PSX mode but no one really knows why.""

Well... Gabest added it in 2009 for the lulz?
",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/99232871,Feature Request: Framelimiter for GSDX for use in PSX emulators.,Mohsen865,16,30325838,17,99232871,0,39449050,2015-05-05T21:45:39Z,"I have added frame limiter and some other feature to the GSdx for PSX mode!
But it doesn't detect the limiting mode correctly....
Check this: (Watch in full screen) http://i.imgur.com/2TsZHfz.png
<a href=""http://imgur.com/2TsZHfz""><img src=""http://i.imgur.com/2TsZHfz.png"" title=""source: imgur.com"" /></a>
",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/12,Build and segfault fix on gentoo,roelaaij,5,30465534,1,30465534,0,0,2014-03-30T13:45:23Z,"The gentoo ebuild which builds from the git sources performs an out of tree build. The common/include/svnrev.h file was generated in the build directory in that case.

A segfault on boot cd is fixed be adding an extra check for a 0 window ID.
",True,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39027234,Build and segfault fix on gentoo,roelaaij,5,30465534,2,39027234,0,30465534,2014-03-30T14:50:05Z,"I misunderstood, only the change to the git show command was necessary. I've reverted the binary to source dir change.

I've tried to squash commits to fix the history, but I've clearly made a mess of it. Apologies. Please feel free to ignore my pull request.
",False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39027294,Build and segfault fix on gentoo,gregory38,5,30465534,3,39027294,0,39027234,2014-03-30T14:53:24Z,"Ok, I'm good with the C change. I need to look git stuff, I'm still a gti beginner (in worst case I will do the rebase on my side)
",False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39027362,Build and segfault fix on gentoo,roelaaij,5,30465534,4,39027362,0,39027294,2014-03-30T14:55:45Z,"Thanks!

I've been using git for a while, but never these kind of operations. I'll try to find a way to fix things up without introducing extra mess.
",False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39027488,Build and segfault fix on gentoo,gregory38,5,30465534,5,39027488,0,39027362,2014-03-30T14:59:52Z,"That ok. I fixed it on my side :)
",False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39027567,Build and segfault fix on gentoo,gregory38,5,30465534,6,39027567,0,39027488,2014-03-30T15:02:42Z,"Done. Tell me if you still have issues. Thanks for your contribution.
",False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/16,Buildbots not updating after move to git,pal1000,29,30487651,1,30487651,0,0,2014-03-31T06:24:35Z,"Definitely needs update. Both Orphis and EmuCR buildbots are stuck at SVN r5932.
",True,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39059536,Buildbots not updating after move to git,pal1000,29,30487651,2,39059536,0,30487651,2014-03-31T07:17:05Z,"I informed EmuCR about this change. Orphis  would be the next but with that weird formed e-mail address I don't feel like giving a try. 
",False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39059709,Buildbots not updating after move to git,gregory38,29,30487651,3,39059709,0,39059536,2014-03-31T07:20:14Z,"Yes we know. We are working on it.
",False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39061428,Buildbots not updating after move to git,gigaherz,29,30487651,4,39061428,0,39059709,2014-03-31T07:49:16Z,"Orphis buildbot is up. The ""SVN"" page already shows Git hashes: http://pcsx2.net/download/development/svn.html

Closing.
",False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39061532,Buildbots not updating after move to git,gigaherz,29,30487651,5,39061532,0,39061428,2014-03-31T07:51:15Z,"Oh I just noticed, the links in the page are wrong...
",False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39063282,Buildbots not updating after move to git,gigaherz,29,30487651,6,39063282,0,39061532,2014-03-31T08:12:47Z,"From Orphis: ""The git log script I have seems to have some issue I'm investigating""
",False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39065769,Buildbots not updating after move to git,ghost,29,30487651,7,39065769,0,39063282,2014-03-31T08:46:09Z,"Well it wouldnt hurt if they keep compiling.
",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39071411,Buildbots not updating after move to git,Dokman,29,30487651,8,39071411,0,39065769,2014-03-31T09:55:11Z,"the best thing you could do is to build it you, it's really easy in windows you only have to install a VS2013 2012 or 2010 to compile it and compile with your processor specs and it's ready to use ^^
",False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39203809,Buildbots not updating after move to git,bositman,29,30487651,9,39203809,0,39071411,2014-04-01T13:19:53Z,"The links on the SVN page of pcsx2.net can't be proper since there are no links on the buildbot page for them :P When Orphis sets it up, I'll update it to point to the proper builds
",False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39343830,Buildbots not updating after move to git,Squall-Leonhart,29,30487651,10,39343830,0,39203809,2014-04-02T15:23:40Z,"who cares about EmuCR.

they put virus's in their builds.
",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39348057,Buildbots not updating after move to git,ghost,29,30487651,11,39348057,0,39343830,2014-04-02T15:57:14Z,"''they put virus's in their builds''
Its a lie I never had  any viruses from Emucr.
",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39436934,Buildbots not updating after move to git,pal1000,29,30487651,12,39436934,0,39348057,2014-04-03T10:40:46Z,"@Squall-Leonhart is right partially, unfortunately. If you don't uncheck ""use download manager"" you may get infected. It also matters which mirror you choose, some are safer while others are really a threat if you are not careful.
",False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39443788,Buildbots not updating after move to git,ghost,29,30487651,13,39443788,0,39436934,2014-04-03T12:15:45Z,"So its mirrors fault not Emucr. Well I used Sendspace and there was no viruses.
",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39641548,Buildbots not updating after move to git,ghost,29,30487651,14,39641548,0,39443788,2014-04-05T15:34:10Z,"I think you can close it now. Emucr is already compiling PCSX2 so Buildbot-Orphis is redundant.Still its strange why switching to Git is taking buildbot so long.
",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39642029,Buildbots not updating after move to git,gigaherz,29,30487651,15,39642029,0,39641548,2014-04-05T15:52:16Z,"Orphis buildbot is officially supported, EmuCR is not.
",False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39642779,Buildbots not updating after move to git,ghost,29,30487651,16,39642779,0,39642029,2014-04-05T16:18:17Z,"Than  you should support Emucr as well its more reliable as you can see.
",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39644192,Buildbots not updating after move to git,Squall-Leonhart,29,30487651,17,39644192,0,39642779,2014-04-05T17:03:19Z,"Reliable!
BWAHAHAHAHA

Enjoy your virus's.
",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39644451,Buildbots not updating after move to git,gigaherz,29,30487651,18,39644451,0,39644192,2014-04-05T17:10:19Z,"Orphis is a friend, though, while EmuCR do it on their own. So we'll continue supporting the builds we can trust not to include any modifications.
",False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39644530,Buildbots not updating after move to git,bositman,29,30487651,19,39644530,0,39644451,2014-04-05T17:13:08Z,"> I think you can close it now. Emucr is already compiling PCSX2 so Buildbot-Orphis is redundant.Still its strange why switching to Git is taking buildbot so long.

Bots, as the name suggests, don't start doing stuff on their own. Orphis will get around to modifying it when he gets time. It's that simple.
",False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39645627,Buildbots not updating after move to git,gigaherz,29,30487651,20,39645627,0,39644530,2014-04-05T17:53:29Z,"Took the liberty of fixing your quote. ;P
",False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39645714,Buildbots not updating after move to git,ghost,29,30487651,21,39645714,0,39645627,2014-04-05T17:56:17Z,"''Enjoy your virus's.'' Like I said before I never encountered any viruses on Emucr.
",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39645792,Buildbots not updating after move to git,gigaherz,29,30487651,22,39645792,0,39645714,2014-04-05T17:58:56Z,"Please disregard Squall. Let's keep the issue tracker professional. We may end up having to delete user comments if people keep being unable to keep their opinions separate from the issue tracker, but we'd rather prefer it doesn't come to that.
",False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39645822,Buildbots not updating after move to git,Squall-Leonhart,29,30487651,23,39645822,0,39645792,2014-04-05T18:00:03Z,"Disregard nothing

https://www.google.com.au/search?q=EmuCR+virus&ie=utf-8&oe=utf-8&aq=t&client=firefox-a&rlz=1R1GGGL_en-GB___AU349&gfe_rd=cr&ei=ikRAU4uUKMHC8geChoG4DQ

Also, EmuCR host 'warez' in the form of WinDS Pro.

You also cannot trust them to use the right build settings, compiler or include the correct files.
",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39646021,Buildbots not updating after move to git,gigaherz,29,30487651,24,39646021,0,39645822,2014-04-05T18:06:51Z,"EmuCR may or may not include viruses, but that's beside the point. The issue is about the buildbot(s) not including builds. If you want to convince people against using EmuCR's builds, please do so elsewhere. We already choose to support only 3rdparty builds coming from Orphis' buildbot (which, in a way, makes them first-party builds, or something like that).

Whenever Orphis fixes his buildbot, we'll close the issue. Unless @pal1000 decides to retract the issue himself. Meanwhile, it stays as-is.
",False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/39651614,Buildbots not updating after move to git,Doriphor,29,30487651,25,39651614,0,39646021,2014-04-05T21:38:40Z,"The only real problem with EmuCr is that builds are updated kind of erratically (there's only been one Git post for PCSX2 and that was last month)
",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/44852579,Buildbots not updating after move to git,akemin-dayo,29,30487651,26,44852579,0,39651614,2014-06-02T15:35:15Z,"I'll be adding PCSX2 builds for Windows (32-bit) to my buildbot that I use for other projects (PPSSPP, nds4ios, GBA4iOS, nds4droid, reicast, etc.)

Builds will be available at http://karenbuildbot.angelxwind.net/ and http://pcsx2.angelxwind.net/ (the latter does not exist yet)
",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/44876959,Buildbots not updating after move to git,uyjulian,29,30487651,27,44876959,0,44852579,2014-06-02T18:58:02Z,"I might make a buildbot once I can get PCSX2 to work on Macs.
",False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/48039650,Buildbots not updating after move to git,bositman,29,30487651,28,48039650,0,44876959,2014-07-04T12:42:43Z,"Orphis got around to it, back to working :)
",False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/51451459,Buildbots not updating after move to git,pal1000,29,30487651,29,51451459,0,48039650,2014-08-07T09:46:14Z,"Orphis Buildbot died again. Last build is v1.2.1-422-g 5d1f224 from Aug 05, 2014. For some reason I am not allowed to re-open although I was the one who created this issue report. I don't know what  @bositman did when he closed this.
",False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/51451794,Buildbots not updating after move to git,Doriphor,29,30487651,30,51451794,0,51451459,2014-08-07T09:49:43Z,"This issue seems different from the previous one seeing as it's not related to the move to git. Wouldn't it warrant opening a new issue anyway?
",False,0,NONE
https://api.github.com/repos/thoughtbot/factory_bot/issues/670,Problem while loading model class when there's a lib class with the same name,TiuTalk,5,36142032,1,36142032,0,0,2014-06-20T05:28:39Z,"Suppose I have the following files:
- **app/models/payment.rb** => With the class `Payment` (model)
- **libs/paypal/payment.rb** => With the class `Paypal::Payment`

And then I define a factory for the `Payment` model:

``` ruby
# spec/factories/payments.rb
FactoryGirl.define do
  factory :payment do
    # fields
  end
end
```

Now when I run `FactoryGirl.lint` to validate my factories, I get the following error:

> Unable to autoload constant Payment, expected /lib/pag_seguro/payment.rb to define it (LoadError)
### Dirty fix

I had to put require the model inside my factory to make it work:

``` ruby
# spec/factories/payments.rb
require ""#{Rails.root}/app/models/payment.rb""

FactoryGirl.define do
  factory :payment do
    # fields
  end
end
```

There's anything I can do/provide to help solving this issue?
## 

Here is the stack trace:

```
/Users/myuser/.rvm/gems/ruby-2.1.2@myapp/gems/activesupport-4.1.1/lib/active_support/dependencies.rb:481:in `load_missing_constant': Unable to autoload constant Payment, expected /Users/myuser/Projects/myapp/lib/pag_seguro/payment.rb to define it (LoadError)
  from /Users/myuser/.rvm/gems/ruby-2.1.2@myapp/gems/activesupport-4.1.1/lib/active_support/dependencies.rb:180:in `const_missing'
  from /Users/myuser/.rvm/gems/ruby-2.1.2@myapp/gems/activesupport-4.1.1/lib/active_support/inflector/methods.rb:238:in `const_get'
  from /Users/myuser/.rvm/gems/ruby-2.1.2@myapp/gems/activesupport-4.1.1/lib/active_support/inflector/methods.rb:238:in `block in constantize'
  from /Users/myuser/.rvm/gems/ruby-2.1.2@myapp/gems/activesupport-4.1.1/lib/active_support/inflector/methods.rb:236:in `each'
  from /Users/myuser/.rvm/gems/ruby-2.1.2@myapp/gems/activesupport-4.1.1/lib/active_support/inflector/methods.rb:236:in `inject'
  from /Users/myuser/.rvm/gems/ruby-2.1.2@myapp/gems/activesupport-4.1.1/lib/active_support/inflector/methods.rb:236:in `constantize'
  from /Users/myuser/.rvm/gems/ruby-2.1.2@myapp/gems/activesupport-4.1.1/lib/active_support/core_ext/string/inflections.rb:66:in `constantize'
  from /Users/myuser/.rvm/gems/ruby-2.1.2@myapp/gems/factory_girl-4.4.0/lib/factory_girl/factory.rb:26:in `build_class'
  from /Users/myuser/.rvm/gems/ruby-2.1.2@myapp/gems/factory_girl-4.4.0/lib/factory_girl/factory.rb:37:in `run'
  from /Users/myuser/.rvm/gems/ruby-2.1.2@myapp/gems/factory_girl-4.4.0/lib/factory_girl/factory_runner.rb:23:in `block in run'
  from /Users/myuser/.rvm/gems/ruby-2.1.2@myapp/gems/activesupport-4.1.1/lib/active_support/notifications.rb:161:in `instrument'
  from /Users/myuser/.rvm/gems/ruby-2.1.2@myapp/gems/factory_girl-4.4.0/lib/factory_girl/factory_runner.rb:22:in `run'
  from /Users/myuser/.rvm/gems/ruby-2.1.2@myapp/gems/factory_girl-4.4.0/lib/factory_girl/strategy_syntax_method_registrar.rb:20:in `block in define_singular_strategy_method'
  from /Users/myuser/.rvm/gems/ruby-2.1.2@myapp/gems/factory_girl-4.4.0/lib/factory_girl.rb:59:in `block in lint'
  from /Users/myuser/.rvm/gems/ruby-2.1.2@myapp/gems/factory_girl-4.4.0/lib/factory_girl/registry.rb:17:in `each'
  from /Users/myuser/.rvm/gems/ruby-2.1.2@myapp/gems/factory_girl-4.4.0/lib/factory_girl/registry.rb:17:in `each'
  from /Users/myuser/.rvm/gems/ruby-2.1.2@myapp/gems/factory_girl-4.4.0/lib/factory_girl/decorator.rb:10:in `select'
  from /Users/myuser/.rvm/gems/ruby-2.1.2@myapp/gems/factory_girl-4.4.0/lib/factory_girl/decorator.rb:10:in `method_missing'
  from /Users/myuser/.rvm/gems/ruby-2.1.2@myapp/gems/factory_girl-4.4.0/lib/factory_girl.rb:58:in `lint'
  from /Users/myuser/Projects/myapp/spec/support/factory_girl.rb:7:in `block (2 levels) in <top (required)>'
  ... REDACTED ...
```
",True,0,NONE
https://api.github.com/repos/thoughtbot/factory_bot/issues/comments/46689037,Problem while loading model class when there's a lib class with the same name,djcp,5,36142032,2,46689037,0,36142032,2014-06-20T15:09:36Z,"Can you give your :payment factory an explicit class name during definition?

``` ruby
FactoryGirl.define do
  factory :payment, class: Payment do
    # fields
  end
end
```

https://github.com/thoughtbot/factory_girl/blob/master/GETTING_STARTED.md#defining-factories
",False,0,NONE
https://api.github.com/repos/thoughtbot/factory_bot/issues/comments/46771344,Problem while loading model class when there's a lib class with the same name,TiuTalk,5,36142032,3,46771344,0,46689037,2014-06-22T03:20:56Z,"@djcp I tried that, the error persists.
",False,0,NONE
https://api.github.com/repos/thoughtbot/factory_bot/issues/comments/46772624,Problem while loading model class when there's a lib class with the same name,joshuaclayton,5,36142032,4,46772624,0,46771344,2014-06-22T05:01:46Z,"@TiuTalk what about being explicit about the namespace, e.g.

``` ruby
FactoryGirl.define do
  factory :payment, class: ::Payment do
    # fields
  end
end
```
",False,0,CONTRIBUTOR
https://api.github.com/repos/thoughtbot/factory_bot/issues/comments/46772804,Problem while loading model class when there's a lib class with the same name,joshuaclayton,5,36142032,5,46772804,0,46772624,2014-06-22T05:15:52Z,"@TiuTalk I put together a quick Rails repo demonstrating a `User` and `Paypal::User` and linting before the test suite - can you verify it works on your machine? I'm not able to reproduce this failure.

https://github.com/joshuaclayton/fg-namespace-demo
",False,0,CONTRIBUTOR
https://api.github.com/repos/thoughtbot/factory_bot/issues/comments/46774376,Problem while loading model class when there's a lib class with the same name,TiuTalk,5,36142032,6,46774376,0,46772804,2014-06-22T07:16:59Z,"Yep.. your project is OK here.

I think I've found the problem (it was related to the Rails `config.autoload_paths` config).

### Before

``` ruby
# config/application.rb
config.autoload_paths += Dir[""#{config.root}/lib/**/""]
```

### After

``` ruby
# config/application.rb
config.autoload_paths += Dir[""#{config.root}/app/models/""]
config.autoload_paths += Dir[""#{config.root}/lib/**/""]
```

And this made everything work! :cake: 

Somehow, this config put theses paths **before** the Rails paths on the autoloading order.

With this I can assume that this has nothing to do with FactoryGirl, but instead with Rails, or just a missconfiguration of my part.

Thanks for your help and your time! :+1: 
",False,0,NONE
https://api.github.com/repos/thoughtbot/factory_bot/issues/671,FactoryGirl::InvalidFactoryError When Linting Factory with Validation on has_many,Undistraction,3,36178123,1,36178123,0,0,2014-06-20T15:39:12Z,"Using the method outlined in the [GETTING_STARTED](http://rubydoc.info/gems/factory_girl/file/GETTING_STARTED.md) docs to populate a `has_many` association causes a `FactoryGirl::InvalidFactoryError` during linting if the association has a validation for `presence: true`.

```
#app/models/order.rb

class Order < ActiveRecord::Base
  has_many :items
  validates :items, presence: true
end
```

```
#spec/factories/orders.rb

FactoryGirl.define do
  factory :order do
    ignore do
      items_count 1
    end
    after(:build) do |order, evaluator|
      create_list(:item, evaluator.items_count, order: order)
    end
  end
end
```

```
#spec/models/order_spec.rb

require 'spec_helper'

describe Order do
  it { should have_many :items }
  it { should validate_presence_of :items}
end
```

Linting Error:

```
/Users/me/.gem/ruby/2.0.0/gems/factory_girl-4.4.0/lib/factory_girl.rb:73:in `lint': The following factories are invalid: (FactoryGirl::InvalidFactoryError)
```

I managed to work around it using:

```
 after(:build) do |order, evaluator|
    evaluator.items_count.times do
      order.items << build(:item)
    end
  end
```
",True,0,NONE
https://api.github.com/repos/thoughtbot/factory_bot/issues/comments/46832308,FactoryGirl::InvalidFactoryError When Linting Factory with Validation on has_many,joshuaclayton,3,36178123,2,46832308,0,36178123,2014-06-23T11:28:20Z,"@1ndivisible I tried to recreate this linting failure locally but didn't have any luck. Can you provide more context on the failure itself?
",False,0,CONTRIBUTOR
https://api.github.com/repos/thoughtbot/factory_bot/issues/comments/55496540,FactoryGirl::InvalidFactoryError When Linting Factory with Validation on has_many,nicohvi,3,36178123,3,55496540,0,46832308,2014-09-13T15:05:53Z,"I'm encountering the same error, the workaround worked for me as well.
",False,0,NONE
https://api.github.com/repos/thoughtbot/factory_bot/issues/comments/240108352,FactoryGirl::InvalidFactoryError When Linting Factory with Validation on has_many,joshuaclayton,3,36178123,4,240108352,0,55496540,2016-08-16T13:53:22Z,"Closing due to inactivity.
",False,0,CONTRIBUTOR
https://api.github.com/repos/thoughtbot/factory_bot/issues/672,"FactoryGirl seems to ignore sequences when a dash ""-"" is put directly before the #{n}",peterklijn,6,36915136,1,36915136,0,0,2014-07-01T17:37:47Z,"Hi,

I have the following factory:

``` ruby
FactoryGirl.define do
...
    factory :page, class: LeWeb::Page do
        sequence(:title) { |n| ""Page title #{n}"" }
        sequence(:url) { |n| ""page-url-#{n}"" }
        text ""<p>Lorum ipsum</p>""
    end
...
end
```

Which causes the following  error when I use it more then once in a test:

``` ruby
    let(:page) { FactoryGirl.create(:page) }
    let(:page2) { FactoryGirl.create(:page) }
```

```
     Failure/Error: let(:page) { FactoryGirl.create(:page) }
     ActiveRecord::RecordInvalid:
       Validation failed: Url has already been taken
```

However, when I change the url to `""page-url#{n}` (without the dash after url) my tests do succeed. Is this a bug or expected behavior?
",True,0,NONE
https://api.github.com/repos/thoughtbot/factory_bot/issues/comments/47687298,"FactoryGirl seems to ignore sequences when a dash ""-"" is put directly before the #{n}",joshuaclayton,6,36915136,2,47687298,0,36915136,2014-07-01T17:43:05Z,"@pklijn what are the values that you're expecting, and how does the data in your DB differ?
",False,0,CONTRIBUTOR
https://api.github.com/repos/thoughtbot/factory_bot/issues/comments/47690151,"FactoryGirl seems to ignore sequences when a dash ""-"" is put directly before the #{n}",peterklijn,6,36915136,3,47690151,0,47687298,2014-07-01T18:07:10Z,"I don't think I understand your question, i'm expecting the url values to be unique per page I create, hence the sequence code.
I'm assuming the urls will be `page-url-0`, `page-url-1`, or whatever value sequence starts with.

My LeWeb::Page model requires a unique url. I want to use multiple in my tests. For some reason this does not work when i use `sequence(:url) { |n| ""page-url-#{n}"" }` but does if I use `sequence(:url) { |n| ""page-url#{n}"" }`.
I use RSpec for testing and afaik the DB is empty on start (I'm kinda new to rails).

I just narrowed my tests down to the following:
spec/models/page_spec.rb

``` ruby
require 'rails_helper'

describe LeWeb::Page do
    let(:page) { FactoryGirl.create(:page) }
    subject { page }
    it { should be_valid }
end
```

spec/factories.rb

``` ruby
FactoryGirl.define do
    factory :page, class: LeWeb::Page do
        sequence(:title) { |n| ""Page title #{n}"" }
        sequence(:url) { |n| ""page-url-#{n}"" }
        text ""<p>Lorum ipsum</p>""
    end
end
```

```
F

Failures:

  1) LeWeb::Page
     Failure/Error: let(:page) { FactoryGirl.create(:page) }
     ActiveRecord::RecordInvalid:
       Validation failed: Url has already been taken
     # ./spec/models/page_spec.rb:5:in `block (2 levels) in <top (required)>'
     # ./spec/models/page_spec.rb:8:in `block (2 levels) in <top (required)>'
     # ./spec/models/page_spec.rb:15:in `block (2 levels) in <top (required)>'

Finished in 0.01767 seconds (files took 1.39 seconds to load)
1 example, 1 failure

Failed examples:

rspec ./spec/models/page_spec.rb:15 # LeWeb::Page
```

Don't mind the row numbers, I removed the commented tests in the post.
",False,0,NONE
https://api.github.com/repos/thoughtbot/factory_bot/issues/comments/47690534,"FactoryGirl seems to ignore sequences when a dash ""-"" is put directly before the #{n}",peterklijn,6,36915136,4,47690534,0,47690151,2014-07-01T18:10:22Z,"Ow, I forgot to add the versions I use:
rspec-support 3.0.2
rspec-core 3.0.2
rspec-expectations 3.0.2
rspec-mocks 3.0.2
rspec-rails 3.0.1
factory_girl 4.4.0
factory_girl_rails 4.4.1
",False,0,NONE
https://api.github.com/repos/thoughtbot/factory_bot/issues/comments/47690552,"FactoryGirl seems to ignore sequences when a dash ""-"" is put directly before the #{n}",joshuaclayton,6,36915136,5,47690552,0,47690534,2014-07-01T18:10:28Z,"@pklijn I'm just trying to identify what records already exist in the database for the uniqueness validation to be thrown - since I'm pretty certain this isn't actually an issue with factory_girl.

Do pages automatically generate URLs based on slugged titles or anything that could be contributing to uniqueness constraints? This is my current best guess as to why things are failing.

Can you use [pry](https://github.com/pry/pry) to look at the records in the database before creating the erroneous record to determine what data is present?
",False,0,CONTRIBUTOR
https://api.github.com/repos/thoughtbot/factory_bot/issues/comments/47691385,"FactoryGirl seems to ignore sequences when a dash ""-"" is put directly before the #{n}",peterklijn,6,36915136,6,47691385,0,47690552,2014-07-01T18:17:33Z,"My apologies, it appears that their was a page with ""page-url-1"" present in my test database, I was under the impression that rails/rspec would delete all changes running tests. 
",False,0,NONE
https://api.github.com/repos/thoughtbot/factory_bot/issues/comments/47691583,"FactoryGirl seems to ignore sequences when a dash ""-"" is put directly before the #{n}",joshuaclayton,6,36915136,7,47691583,0,47691385,2014-07-01T18:19:13Z,"@pklijn ah, makes sense - I'd look into [Database Cleaner](https://github.com/DatabaseCleaner/database_cleaner), along with [a wonderful post by Avdi Grimm](http://devblog.avdi.org/2012/08/31/configuring-database_cleaner-with-rails-rspec-capybara-and-selenium/) about how to configure it correctly.
",False,0,CONTRIBUTOR
https://api.github.com/repos/thoughtbot/factory_bot/issues/673,multiple factory directories,jcavalieri,5,37097356,1,37097356,0,0,2014-07-03T16:15:11Z,"Sorry if this documented somewhere, I couldn't find it if it is. I'm wondering if multiple directories can be passed into factory girl.

Instead of just one, e.g.
    g.fixture_replacement :factory_girl, :dir => 'test/factories'

Thanks,
John
",True,0,NONE
https://api.github.com/repos/thoughtbot/factory_bot/issues/comments/100331638,multiple factory directories,drapergeek,5,37097356,2,100331638,0,37097356,2015-05-08T19:15:56Z,"Yes they can! That is actually the default when using `factory_girl_rails`: https://github.com/thoughtbot/factory_girl_rails#configuration
",False,0,CONTRIBUTOR
https://api.github.com/repos/thoughtbot/factory_bot/issues/comments/100336774,multiple factory directories,jcavalieri,5,37097356,3,100336774,0,100331638,2015-05-08T19:40:13Z,"Hi @drapergeek ,

So if I want multiple do I pass in an array of factories?

```
config.generators do |g|
  g.factory_girl dir: ['custom/dir1/for/factories', 'custom/dir2/for/factories']
end
```
",False,0,NONE
https://api.github.com/repos/thoughtbot/factory_bot/issues/comments/100901281,multiple factory directories,drapergeek,5,37097356,4,100901281,0,100336774,2015-05-11T13:13:04Z,"@jcavalieri I don't think that would work. This is for the generators so it is asking where you want it to create those files. If you have two directories at the top, the application wouldn't have any way of knowing which directory to put things in given a specific scenario.
",False,0,CONTRIBUTOR
https://api.github.com/repos/thoughtbot/factory_bot/issues/comments/100929759,multiple factory directories,jcavalieri,5,37097356,5,100929759,0,100901281,2015-05-11T14:44:16Z,"Ahh that makes sense. Thanks.
",False,0,NONE
https://api.github.com/repos/thoughtbot/factory_bot/issues/comments/281690243,multiple factory directories,Nowaker,5,37097356,6,281690243,0,100929759,2017-02-22T14:50:05Z,For those who found this in Google. Here's how to get multiple directories: https://github.com/thoughtbot/factory_girl/wiki/Installation,False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/5307,local-exec push not working on Windows,tsauter,7,57004054,1,57004054,0,0,2015-02-09T09:00:48Z,"The local-exec push method is not working on Windows. 
The ruby fork statement isn't supported on this platform. It doesn't matter if an inline or external script is used.

Full error message is:

```
C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/util/safe_exec.rb:22:in `fork': fork() function is unimplemented on this machine (NotImplementedError)
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/util/safe_exec.rb:22:in `exec'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/pushes/local-exec/push.rb:41:in `execute!'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/pushes/local-exec/push.rb:36:in `execute_script!'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/pushes/local-exec/push.rb:14:in `push'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/environment.rb:567:in `push'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/push/command.rb:28:in `execute'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/cli.rb:42:in `execute'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/environment.rb:301:in `cli'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/bin/vagrant:174:in `<main>'
```
",True,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/78555803,local-exec push not working on Windows,molnara,7,57004054,2,78555803,0,57004054,2015-03-12T18:23:04Z,"I get the same error in Windows 7.
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/82400542,local-exec push not working on Windows,sethvargo,7,57004054,3,82400542,0,78555803,2015-03-17T15:13:02Z,"@mitchellh weird... how do the other shell things work?
",False,0,CONTRIBUTOR
https://api.github.com/repos/hashicorp/vagrant/issues/comments/87469191,local-exec push not working on Windows,neuron303,7,57004054,4,87469191,0,82400542,2015-03-29T20:23:19Z,"Actually it is working with script files. Use files that windows is able to start (i.e. use .bat, .exe, ... files)

Since the inline script is written to a .sh temporary file this feature is broken.

The error message is triggered by the fallback mechanism to fork when Kernel.exec does not work.
If the fallback is disabled Kernel.exec returns following:

```
C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/util/safe_exec.rb:23:in `exec': Exec format error - C:/Users/user/my-script.sh (Errno::ENOEXEC)
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/util/safe_exec.rb:23:in `exec'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/pushes/local-exec/push.rb:41:in `execute!'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/pushes/local-exec/push.rb:36:in `execute_script!'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/pushes/local-exec/push.rb:14:in `push'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/environment.rb:567:in `push'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/push/command.rb:28:in `execute'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/cli.rb:42:in `execute'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/environment.rb:301:in `cli'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/bin/vagrant:174:in `<main>'
```
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/150035779,local-exec push not working on Windows,robotnealan,7,57004054,5,150035779,0,87469191,2015-10-21T21:53:25Z,"Not sure as to the actual root cause of the issue (other than Windows not supporting fork() by default), but using git-bash from https://git-for-windows.github.io/ works as a workaround as it automatically includes Cygwin (which adds support for fork()).

Has an option to add everything to your default path (so it'd fix the issue in other terminals), but haven't tested it personally.
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/205844689,local-exec push not working on Windows,dpalomar,7,57004054,6,205844689,0,150035779,2016-04-05T14:56:13Z,"Same issue, tested on win10 with git bash and cygwin.
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/236545428,local-exec push not working on Windows,KptnKMan,7,57004054,7,236545428,0,205844689,2016-08-01T10:29:07Z,"Same issue, win10 using OpenSSH and vagrant 1.8.5
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/608198160,local-exec push not working on Windows,ghost,7,57004054,8,608198160,0,236545428,2020-04-03T02:40:29Z,"I'm going to lock this issue because it has been closed for _30 days_ ⏳. This helps our maintainers find and focus on the active issues.

If you have found a problem that seems similar to this, please open a new issue and complete the issue template so we can capture all the details necessary to investigate further.
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/5308,Missing interpolation argument when raising Vagrant::Errors::VirtualBoxVersionEmpty,call-a3,12,57027462,1,57027462,0,0,2015-02-09T13:00:32Z,"Two problems seem to be going on here. The one that this issue is about is the first one: the missing interpolation argument that is reported.

I'm using vagrant 1.7.2 on windows 8.1 (x64) and Virtualbox 4.3.20r96997.

```
c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/config.rb:83:in `block in missing_interpolation_argument_handler': missing interpolation argument :vboxmanage in ""Vagrant detected that VirtualBox appears installed on your system,\nbut calls to detect the version are returning empty. This is often\nindicative of installation issues with VirtualBox. Please verify\nthat VirtualBox is properly installed. As a final verification,\nplease run the following command manually and verify a version is\noutputted:\n\n%{vboxmanage} --version"" {:_key=>:virtualbox_version_empty, :_namespace=>""vagrant.errors""} given) (I18
n::MissingInterpolationArgument)
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/interpolate/ruby.rb:29:in `call'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/interpolate/ruby.rb:29:in `block in interpolate_hash'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/interpolate/ruby.rb:21:in `gsub'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/interpolate/ruby.rb:21:in `interpolate_hash'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/interpolate/ruby.rb:17:in `interpolate'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/backend/base.rb:153:in `interpolate'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/backend/base.rb:41:in `translate'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n.rb:157:in `block in translate'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n.rb:153:in `catch'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n.rb:153:in `translate'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/errors.rb:103:in `translate_error'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/errors.rb:72:in `initialize'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/virtualbox/driver/meta.rb:155:in `exception'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/virtualbox/driver/meta.rb:155:in `raise'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/virtualbox/driver/meta.rb:155:in `block in read_version'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/util/retryable.rb:17:in `retryable'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/virtualbox/driver/meta.rb:140:in `read_version'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/virtualbox/driver/meta.rb:38:in `initialize'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/virtualbox/provider.rb:11:in `new'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/virtualbox/provider.rb:11:in `usable?'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/environment.rb:378:in `block in default_provider'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/environment.rb:377:in `each'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/environment.rb:377:in `default_provider'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/plugin/v2/command.rb:165:in `block in with_target_vms'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/plugin/v2/command.rb:192:in `call'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/plugin/v2/command.rb:192:in `block in with_target_vms'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/plugin/v2/command.rb:174:in `each'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/plugin/v2/command.rb:174:in `with_target_vms'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/up/command.rb:74:in `block in execute'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/environment.rb:277:in `block (2 levels) in batch'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/environment.rb:275:in `tap'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/environment.rb:275:in `block in batch'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/environment.rb:274:in `synchronize'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/environment.rb:274:in `batch'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/up/command.rb:58:in `execute'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/cli.rb:42:in `execute'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/environment.rb:301:in `cli'
        from c:/Program_Files/HashiCorp/Vagrant/bin/../embedded/gems/gems/vagrant-1.7.2/bin/vagrant:174:in `<main>'
```
",True,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/74636766,Missing interpolation argument when raising Vagrant::Errors::VirtualBoxVersionEmpty,petardudas,12,57027462,2,74636766,0,57027462,2015-02-17T09:07:10Z,"I've had the same problem and I'm using : 
Windows 8.1 64bit, Virtualbox 4.3.20r96997, Vagrant 1.7.2
and I'm also have installed and use VMWare Player 7.0.0 build-2305329

If you suspend or halt your virtual machine sometimes vagrant doesn't kill the process. Look in your task manager and kill all Virtualbox instances and try again. That's how I solve most of the problems with Vagrant.

There is also an another issue, but I think it's from Windows updates. Sometimes I can't start the virtual machines with Virtualbox, with VMWare Player I can start them but can't access the machines  through ssh or ping to and from the machine and have no network connection. The solution was for me to uninstall Virtualbox and VMWare Player, which didn't worked, and install them again and everything worked just fine with both virtualisations.

Hope this helps.
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/74660462,Missing interpolation argument when raising Vagrant::Errors::VirtualBoxVersionEmpty,call-a3,12,57027462,3,74660462,0,74636766,2015-02-17T12:29:12Z,"Virtualbox is not running at the time of the error, so there are no instances to kill. (Yes, I just checked in task manager.)

I have tried reinstalling both virtualbox and/or vagrant multiple times by now, and nothing helps. I reboot between every uninstall/reinstall to avoid any weird quirks.
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/74709029,Missing interpolation argument when raising Vagrant::Errors::VirtualBoxVersionEmpty,petardudas,12,57027462,4,74709029,0,74660462,2015-02-17T17:20:46Z,"When did the VM with Vagrant stopped working? Can you start the VM with the Virtualbox GUI ?
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/75530300,Missing interpolation argument when raising Vagrant::Errors::VirtualBoxVersionEmpty,call-a3,12,57027462,5,75530300,0,74709029,2015-02-23T12:03:34Z,"@petardudas The VM never worked, or rather: Vagrant never succeeded in detecting it's version. As a consequence, there is no VM to start because it was never created... I can however confirm that Virtualbox works as it should, because it works fine for other tools I'm using. (SailfishOS SDK uses two virtualboxes, one for compiling and one as an emulator).
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/75531187,Missing interpolation argument when raising Vagrant::Errors::VirtualBoxVersionEmpty,call-a3,12,57027462,6,75531187,0,75530300,2015-02-23T12:11:44Z,"Actually, @petardudas, this issue was intended to be about the interpolation error in the i18n gem, not about the fact that vagrant can't detect virtualbox properly. That's what issue #5309 is about. Maybe we should continue this conversation there?
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/75819573,Missing interpolation argument when raising Vagrant::Errors::VirtualBoxVersionEmpty,mitchellh,12,57027462,7,75819573,0,75531187,2015-02-24T18:49:09Z,"Fixed. Thanks.
",False,0,CONTRIBUTOR
https://api.github.com/repos/hashicorp/vagrant/issues/comments/81252099,Missing interpolation argument when raising Vagrant::Errors::VirtualBoxVersionEmpty,mani0070,12,57027462,8,81252099,0,75819573,2015-03-15T21:35:33Z,"This same issue is happening on hyper-V as well. Any help is much appericated?
Below is the error message

``` text
==> default: Verifying Hyper-V is enabled...
C:/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/config.rb:83:in `block in missing_interpolation_argume
nt_handler': missing interpolation argument :name in ""The box you're using with the Hyper-V provider ('%{name}')\ni
s invalid. A Hyper-V box should contain both a\n\""Virtual Machines\"" and a \""Virtual Hard Disks\"" folder that are\n
created as part of exporting a Hyper-V machine.\n\nWithin these directories, Vagrant expects to find the\nvirtual m
achine configuration as well as the root hard disk.\n\nThe box you're attempting to use is missing one or both of\n
these directories or does not contain the files expected. Verify\nthat you added the correct box. If this problem p
ersists,\nplease contact the creator of the box for assistance."" ({:_key=>:box_invalid, :_namespace=>""vagrant_hyper
v.errors""} given) (I18n::MissingInterpolationArgument)
        from C:/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/interpolate/ruby.rb:29:in `call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/interpolate/ruby.rb:29:in `block in inter
polate_hash'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/interpolate/ruby.rb:21:in `gsub'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/interpolate/ruby.rb:21:in `interpolate_ha
sh'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/interpolate/ruby.rb:17:in `interpolate'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/backend/base.rb:153:in `interpolate'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/backend/base.rb:41:in `translate'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n.rb:157:in `block in translate'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n.rb:153:in `catch'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n.rb:153:in `translate'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/errors.rb:103:in `translate_error'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/errors.rb:72:in `initialize'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/hyperv/action/import.rb:41:in
`exception'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/hyperv/action/import.rb:41:in
`raise'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/hyperv/action/import.rb:41:in
`call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:95:in `block in fin
alize_action'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/builder.rb:116:in `call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/runner.rb:66:in `block in run
'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/util/busy.rb:19:in `busy'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/runner.rb:66:in `run'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/builtin/call.rb:53:in `call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/builtin/config_validate.rb:25
:in `call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/builtin/handle_box.rb:56:in `
call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/hyperv/action/check_enabled.rb
:18:in `call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/builder.rb:116:in `call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/runner.rb:66:in `block in run
'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/util/busy.rb:19:in `busy'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/runner.rb:66:in `run'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/machine.rb:214:in `action_raw'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/machine.rb:191:in `block in action'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/environment.rb:516:in `lock'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/machine.rb:178:in `call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/machine.rb:178:in `action'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/batch_action.rb:82:in `block (2 leve
ls) in run'
```
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/81507035,Missing interpolation argument when raising Vagrant::Errors::VirtualBoxVersionEmpty,call-a3,12,57027462,9,81507035,0,81252099,2015-03-16T08:43:47Z,"@mani0070 This was already fixed but hasn't made it into a published version. Have you tried running vagrant from the current master branch?
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/81508302,Missing interpolation argument when raising Vagrant::Errors::VirtualBoxVersionEmpty,mani0070,12,57027462,10,81508302,0,81507035,2015-03-16T08:46:18Z,"Not yet.. Any dates when its available for public?

--- Original Message ---

From: ""Adriaan Callaerts"" notifications@github.com
Sent: 16 March 2015 08:44
To: ""mitchellh/vagrant"" vagrant@noreply.github.com
Cc: ""Manimaran Chandrasekaran"" mani@dinventive.com
Subject: Re: [vagrant] Missing interpolation argument when raising Vagrant::Errors::VirtualBoxVersionEmpty (#5308)

@mani0070 This was already fixed but hasn't made it into a published version. Have you tried running vagrant from the current master branch?

---

Reply to this email directly or view it on GitHub:
https://github.com/mitchellh/vagrant/issues/5308#issuecomment-81507035
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/81518802,Missing interpolation argument when raising Vagrant::Errors::VirtualBoxVersionEmpty,call-a3,12,57027462,11,81518802,0,81508302,2015-03-16T09:09:19Z,"I have no idea... I'm not a maintainer of this project, so I don't really
have anything to say in the matter :p

We should ask @mitchellh 
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/140545864,Missing interpolation argument when raising Vagrant::Errors::VirtualBoxVersionEmpty,blindpet,12,57027462,12,140545864,0,81518802,2015-09-15T21:15:33Z,"Getting the same error as @mani0070 for Hyper-V on Windows 2012R2. I even went as far as installing from latest Vagrant master branch and same error (version 1.7.4).

The box i am trying is below but I have tried several and they yield the same error
vagrant init yjwong/vivid
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/161108525,Missing interpolation argument when raising Vagrant::Errors::VirtualBoxVersionEmpty,borrelan,12,57027462,13,161108525,0,140545864,2015-12-01T21:58:01Z,"Same issue here using Windows 10 (Version   10.0.10586 Build 10586) and the latest master branch (original version 1.7.2).  Generating my own box file with this version of windows produces this error, but a previously generated box file works fine.

```
 vagrant up --provider hyperv
You appear to be running Vagrant outside of the official installers.
Note that the installers are what ensure that Vagrant has all required
dependencies, and Vagrant assumes that these dependencies exist. By
running outside of the installer environment, Vagrant may not function
properly. To remove this warning, install Vagrant using one of the
official packages from vagrantup.com.

Bringing machine 'default' up with 'hyperv' provider...
==> default: Verifying Hyper-V is enabled...
==> default: Box 'blah' could not be found. Attempting to find and install...
    default: Box Provider: hyperv
    default: Box Version: >= 0
==> default: Adding box 'blah' (v0) for provider: hyperv
    default: Unpacking necessary files from: file:///D/hyperv/blah.box
    default:
==> default: Successfully added box 'blah' (v0) for 'hyperv'!
==> default: Configured Dynamical memory allocation, maxmemory is 4096
==> default: Configured startup memory is 512
==> default: Configured cpus number is 4
==> default: Configured vmname is blah
C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/i18n-0.7.0/lib/i18n/config.rb:92:in `block in missing_interpolation_argument_handler': missing interpolation argument :name in ""The box you're using with the Hyper-V provider ('%{name}')\nis invalid. A Hyper-V box should contain both a\n\""Virtual Machines\"" and a \""Virtual Hard Disks\"" folder that are\ncreated as part of exporting a Hyper-V machine.\n\nWithin these directories, Vagrant expects to find the\nvirtual machine configuration as well as the root hard disk.\n\nThe box you're attempting to use is missing one or both of\nthese directories or does not contain the files expected. Verify\nthat you added the correct box. If this problem persists,\nplease contact the creator of the box for assistance."" ({:_key=>:box_invalid, :_namespace=>""vagrant_hyperv.errors""} given) (I18n::MissingInterpolationArgument)
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/i18n-0.7.0/lib/i18n/interpolate/ruby.rb:29:in `call'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/i18n-0.7.0/lib/i18n/interpolate/ruby.rb:29:in `block in interpolate_hash'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/i18n-0.7.0/lib/i18n/interpolate/ruby.rb:21:in `gsub'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/i18n-0.7.0/lib/i18n/interpolate/ruby.rb:21:in `interpolate_hash'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/i18n-0.7.0/lib/i18n/interpolate/ruby.rb:17:in `interpolate'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/i18n-0.7.0/lib/i18n/backend/base.rb:152:in `interpolate'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/i18n-0.7.0/lib/i18n/backend/base.rb:41:in `translate'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/i18n-0.7.0/lib/i18n.rb:158:in `block in translate'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/i18n-0.7.0/lib/i18n.rb:154:in `catch'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/i18n-0.7.0/lib/i18n.rb:154:in `translate'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/lib/vagrant/errors.rb:103:in `translate_error'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/lib/vagrant/errors.rb:72:in `initialize'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/plugins/providers/hyperv/action/import.rb:50:in `exception'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/plugins/providers/hyperv/action/import.rb:50:in `raise'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/plugins/providers/hyperv/action/import.rb:50:in `call'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:95:in `block in finalize_action'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/lib/vagrant/action/builder.rb:116:in `call'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/lib/vagrant/action/runner.rb:66:in `block in run'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/lib/vagrant/util/busy.rb:19:in `busy'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/lib/vagrant/action/runner.rb:66:in `run'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/lib/vagrant/action/builtin/call.rb:53:in `call'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/lib/vagrant/action/builtin/config_validate.rb:25:in `call'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/lib/vagrant/action/builtin/handle_box.rb:56:in `call'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/plugins/providers/hyperv/action/check_enabled.rb:18:in `call'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/lib/vagrant/action/builder.rb:116:in `call'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/lib/vagrant/action/runner.rb:66:in `block in run'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/lib/vagrant/util/busy.rb:19:in `busy'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/lib/vagrant/action/runner.rb:66:in `run'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/lib/vagrant/machine.rb:214:in `action_raw'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/lib/vagrant/machine.rb:191:in `block in action'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/lib/vagrant/environment.rb:516:in `lock'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/lib/vagrant/machine.rb:178:in `call'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/lib/vagrant/machine.rb:178:in `action'
        from C:/Ruby22-x64/lib/ruby/gems/2.2.0/gems/vagrant-1.7.2/lib/vagrant/batch_action.rb:82:in `block (2 levels) in run'
```
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/5309,Vagrant cannot find version of Virtualbox on Windows 8.1,call-a3,22,57028956,1,57028956,0,0,2015-02-09T13:16:24Z,"I realize this is a recurring/known bug, but I have tried various approaches to fixing this and still no dice. So here goes (again):

I'm using 
- Vagrant 1.7.2
- Virtualbox 4.3.20r96997
- Windows 8.1 (x64)

As you will see, I can execute vboxmanage manually from the terminal (using Git bash here because I prefer it, but same is happening in cmd). I have tried changing the path to use short notation, tried reinstalling both vagrant and virtualbox, installing both in paths that don't contain spaces (notice the underscore in ""c:/Program_Files"" below) and I'm getting slightly annoyed at vagrant for not working properly.

The reported output is

```
Adriaan@A3-BTO-WIN81 /d/Users/Adriaan/Workspace/vm$ vboxmanage --version
4.3.20r96997

Adriaan@A3-BTO-WIN81 /d/Users/Adriaan/Workspace/vm$ vagrant up
 INFO global: Vagrant version: 1.7.2
 INFO global: Ruby version: 2.0.0
 INFO global: RubyGems version: 2.0.14
 INFO global: VAGRANT_DETECTED_OS=""MINGW32_NT-6.2""
 INFO global: VAGRANT_EXECUTABLE=""c:/Program_Files/HashiCorp/Vagrant/bin/../embedded/gems/gems/vagrant-1.7.2/bin/vagrant""
 INFO global: VAGRANT_INSTALLER_EMBEDDED_DIR=""c:/Program_Files/HashiCorp/Vagrant/bin/../embedded""
 INFO global: VAGRANT_INSTALLER_ENV=""1""
 INFO global: VAGRANT_INSTALLER_VERSION=""2""
 INFO global: VAGRANT_INTERNAL_BUNDLERIZED=""1""
 INFO global: VAGRANT_LOG=""debug""
 INFO global: Plugins:
 INFO global:   - bundler = 1.7.11
 INFO global:   - json = 1.8.2
 INFO global:   - mime-types = 1.25.1
 INFO global:   - rdoc = 4.2.0
 INFO global:   - rest-client = 1.6.8
 INFO global:   - vagrant-share = 1.1.3
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/box/plugin.rb
 INFO manager: Registered plugin: box command
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/destroy/plugin.rb
 INFO manager: Registered plugin: destroy command
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/global-status/plugin.rb
 INFO manager: Registered plugin: global-status command
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/halt/plugin.rb
 INFO manager: Registered plugin: halt command
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/help/plugin.rb
 INFO manager: Registered plugin: help command
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/init/plugin.rb
 INFO manager: Registered plugin: init command
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/list-commands/plugin.rb
 INFO manager: Registered plugin: list-commands command
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/login/plugin.rb
 INFO manager: Registered plugin: vagrant-login
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/package/plugin.rb
 INFO manager: Registered plugin: package command
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/plugin/plugin.rb
 INFO manager: Registered plugin: plugin command
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/provision/plugin.rb
 INFO manager: Registered plugin: provision command
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/push/plugin.rb
 INFO manager: Registered plugin: push command
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/rdp/plugin.rb
 INFO manager: Registered plugin: rdp command
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/reload/plugin.rb
 INFO manager: Registered plugin: reload command
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/resume/plugin.rb
 INFO manager: Registered plugin: resume command
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/ssh/plugin.rb
 INFO manager: Registered plugin: ssh command
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/ssh_config/plugin.rb
 INFO manager: Registered plugin: ssh-config command
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/status/plugin.rb
 INFO manager: Registered plugin: status command
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/suspend/plugin.rb
 INFO manager: Registered plugin: suspend command
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/up/plugin.rb
 INFO manager: Registered plugin: up command
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/version/plugin.rb
 INFO manager: Registered plugin: version command
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/communicators/ssh/plugin.rb
 INFO manager: Registered plugin: ssh communicator
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/communicators/winrm/plugin.rb
 INFO manager: Registered plugin: winrm communicator
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/guests/arch/plugin.rb
 INFO manager: Registered plugin: Arch guest
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/guests/coreos/plugin.rb
 INFO manager: Registered plugin: CoreOS guest
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/guests/darwin/plugin.rb
 INFO manager: Registered plugin: Darwin guest
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/guests/debian/plugin.rb
 INFO manager: Registered plugin: Debian guest
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/guests/esxi/plugin.rb
 INFO manager: Registered plugin: ESXi guest.
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/guests/fedora/plugin.rb
 INFO manager: Registered plugin: Fedora guest
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/guests/freebsd/plugin.rb
 INFO manager: Registered plugin: FreeBSD guest
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/guests/funtoo/plugin.rb
 INFO manager: Registered plugin: Funtoo guest
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/guests/gentoo/plugin.rb
 INFO manager: Registered plugin: Gentoo guest
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/guests/linux/plugin.rb
 INFO manager: Registered plugin: Linux guest.
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/guests/mint/plugin.rb
 INFO manager: Registered plugin: Mint guest
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/guests/netbsd/plugin.rb
 INFO manager: Registered plugin: NetBSD guest
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/guests/nixos/plugin.rb
 INFO manager: Registered plugin: NixOS guest
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/guests/omnios/plugin.rb
 INFO manager: Registered plugin: OmniOS guest.
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/guests/openbsd/plugin.rb
 INFO manager: Registered plugin: OpenBSD guest
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/guests/pld/plugin.rb
 INFO manager: Registered plugin: PLD Linux guest
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/guests/redhat/plugin.rb
 INFO manager: Registered plugin: RedHat guest
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/guests/smartos/plugin.rb
 INFO manager: Registered plugin: SmartOS guest.
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/guests/solaris/plugin.rb
 INFO manager: Registered plugin: Solaris guest.
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/guests/solaris11/plugin.rb
 INFO manager: Registered plugin: Solaris 11 guest.
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/guests/suse/plugin.rb
 INFO manager: Registered plugin: SUSE guest
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/guests/tinycore/plugin.rb
 INFO manager: Registered plugin: TinyCore Linux guest.
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/guests/ubuntu/plugin.rb
 INFO manager: Registered plugin: Ubuntu guest
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/guests/windows/plugin.rb
 INFO manager: Registered plugin: Windows guest.
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/hosts/arch/plugin.rb
 INFO manager: Registered plugin: Arch host
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/hosts/bsd/plugin.rb
 INFO manager: Registered plugin: BSD host
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/hosts/darwin/plugin.rb
 INFO manager: Registered plugin: Mac OS X host
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/hosts/freebsd/plugin.rb
 INFO manager: Registered plugin: FreeBSD host
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/hosts/gentoo/plugin.rb
 INFO manager: Registered plugin: Gentoo host
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/hosts/linux/plugin.rb
 INFO manager: Registered plugin: Linux host
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/hosts/null/plugin.rb
 INFO manager: Registered plugin: null host
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/hosts/redhat/plugin.rb
 INFO manager: Registered plugin: Red Hat host
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/hosts/slackware/plugin.rb
 INFO manager: Registered plugin: Slackware host
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/hosts/suse/plugin.rb
 INFO manager: Registered plugin: SUSE host
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/hosts/windows/plugin.rb
 INFO manager: Registered plugin: Windows host
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/kernel_v1/plugin.rb
 INFO manager: Registered plugin: kernel
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/kernel_v2/plugin.rb
 INFO manager: Registered plugin: kernel
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/docker/plugin.rb
 INFO manager: Registered plugin: docker-provider
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/hyperv/plugin.rb
 INFO manager: Registered plugin: Hyper-V provider
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/virtualbox/plugin.rb
 INFO manager: Registered plugin: VirtualBox provider
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/provisioners/ansible/plugin.rb
 INFO manager: Registered plugin: ansible
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/provisioners/cfengine/plugin.rb
 INFO manager: Registered plugin: CFEngine Provisioner
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/provisioners/chef/plugin.rb
 INFO manager: Registered plugin: chef
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/provisioners/docker/plugin.rb
 INFO manager: Registered plugin: docker
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/provisioners/file/plugin.rb
 INFO manager: Registered plugin: file
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/provisioners/puppet/plugin.rb
 INFO manager: Registered plugin: puppet
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/provisioners/salt/plugin.rb
 INFO manager: Registered plugin: salt
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/provisioners/shell/plugin.rb
 INFO manager: Registered plugin: shell
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/pushes/atlas/plugin.rb
 INFO manager: Registered plugin: atlas
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/pushes/ftp/plugin.rb
 INFO manager: Registered plugin: ftp
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/pushes/heroku/plugin.rb
 INFO manager: Registered plugin: heroku
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/pushes/local-exec/plugin.rb
 INFO manager: Registered plugin: local-exec
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/pushes/noop/plugin.rb
 INFO manager: Registered plugin: noop
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/synced_folders/nfs/plugin.rb
 INFO manager: Registered plugin: NFS synced folders
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/synced_folders/rsync/plugin.rb
 INFO manager: Registered plugin: RSync synced folders
DEBUG global: Loading core plugin: c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/synced_folders/smb/plugin.rb
 INFO manager: Registered plugin: SMB synced folders
 INFO global: Loading plugins!
 INFO manager: Registered plugin: vagrant-share
 INFO vagrant: `vagrant` invoked: [""up""]
DEBUG vagrant: Creating Vagrant environment
 INFO environment: Environment initialized (#<Vagrant::Environment:0x2af5940>)
 INFO environment:   - cwd: d:/Users/Adriaan/Workspace/Skedify/vm
 INFO environment: Home path: C:/Users/Adriaan/.vagrant.d
 INFO environment: Local data path: d:/Users/Adriaan/Workspace/Skedify/vm/.vagrant
DEBUG environment: Creating: d:/Users/Adriaan/Workspace/Skedify/vm/.vagrant
 INFO environment: Running hook: environment_plugins_loaded
 INFO runner: Preparing hooks for middleware sequence...
 INFO runner: 1 hooks defined.
 INFO runner: Running action: #<Vagrant::Action::Builder:0x2e7aab0>
 INFO environment: Running hook: environment_load
 INFO runner: Preparing hooks for middleware sequence...
 INFO runner: 1 hooks defined.
 INFO runner: Running action: #<Vagrant::Action::Builder:0x37060b0>
 INFO cli: CLI: [] ""up"" []
DEBUG cli: Invoking command class: VagrantPlugins::CommandUp::Command []
DEBUG command: 'Up' each target VM...
 INFO loader: Set :root = #<Pathname:d:/Users/Adriaan/Workspace/Skedify/vm/Vagrantfile>
DEBUG loader: Populating proc cache for #<Pathname:d:/Users/Adriaan/Workspace/Skedify/vm/Vagrantfile>
DEBUG loader: Load procs for pathname: d:/Users/Adriaan/Workspace/Skedify/vm/Vagrantfile
 INFO loader: Loading configuration in order: [:home, :root]
DEBUG loader: Loading from: root (evaluating)
DEBUG provisioner: Provisioner defined: ensure-puppet
DEBUG provisioner: Provisioner defined:
DEBUG loader: Configuration loaded successfully, finalizing and returning
DEBUG push: finalizing
DEBUG command: Getting target VMs for command. Arguments:
DEBUG command:  -- names: [""default""]
DEBUG command:  -- options: {:provider=>nil}
DEBUG command: Finding machine that match name: default
 INFO loader: Set ""30900480_machine_default"" = []
 INFO loader: Loading configuration in order: [:home, :root, ""30900480_machine_default""]
DEBUG loader: Loading from: root (cache)
DEBUG loader: Configuration loaded successfully, finalizing and returning
DEBUG push: finalizing
DEBUG base: Windows. Trying VBOX_INSTALL_PATH for VBoxManage
DEBUG base: VBOX_INSTALL_PATH value: C:\Program_Files\Oracle\VirtualBox\
 INFO base: VBoxManage path: C:\Program_Files\Oracle\VirtualBox\VBoxManage.exe
 INFO subprocess: Starting process: [""C:\\Program_Files\\Oracle\\VirtualBox\\VBoxManage.exe"", ""--version""]
DEBUG subprocess: Selecting on IO
DEBUG subprocess: Waiting for process to exit. Remaining to timeout: 32000
DEBUG subprocess: Exit status: 0
 INFO environment: Running hook: environment_unload
 INFO host: Autodetecting host type for [#<Vagrant::Environment: d:/Users/Adriaan/Workspace/Skedify/vm>]
DEBUG host: Trying: arch
DEBUG host: Trying: darwin
DEBUG host: Trying: freebsd
DEBUG host: Trying: gentoo
DEBUG host: Trying: redhat
DEBUG host: Trying: slackware
DEBUG host: Trying: suse
DEBUG host: Trying: bsd
DEBUG host: Trying: linux
DEBUG host: Trying: null
DEBUG host: Trying: windows
 INFO host: Detected: windows!
 INFO runner: Preparing hooks for middleware sequence...
 INFO runner: 1 hooks defined.
 INFO runner: Running action: #<Vagrant::Action::Builder:0x2de97d8>
c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/config.rb:83:in block in missing_interpolation_argument_handler': missing interpolation argument :vboxmanage in ""Vagrant detected that VirtualBox appears installed on your system,\nbut calls to detect the version are returning empty. This is often\nindicative of installation issues with VirtualBox. Please verify\nthat VirtualBox is properly installed. As a final verification,\nplease run the following command manually and verify a version is\noutputted:\n\n%{vboxmanage} --version"" {:_key=>:virtualbox_version_empty, :_namespace=>""vagrant.errors""} given) (I18n::MissingInterpolationArgument)
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/interpolate/ruby.rb:29:in `call'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/interpolate/ruby.rb:29:in `block in interpolate_hash'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/interpolate/ruby.rb:21:in `gsub'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/interpolate/ruby.rb:21:in `interpolate_hash'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/interpolate/ruby.rb:17:in `interpolate'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/backend/base.rb:153:in `interpolate'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/backend/base.rb:41:in `translate'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n.rb:157:in `block in translate'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n.rb:153:in `catch'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n.rb:153:in `translate'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/errors.rb:103:in `translate_error'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/errors.rb:72:in `initialize'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/virtualbox/driver/meta.rb:155:in `exception'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/virtualbox/driver/meta.rb:155:in `raise'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/virtualbox/driver/meta.rb:155:in `block in read_version'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/util/retryable.rb:17:in `retryable'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/virtualbox/driver/meta.rb:140:in `read_version'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/virtualbox/driver/meta.rb:38:in `initialize'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/virtualbox/provider.rb:11:in `new'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/virtualbox/provider.rb:11:in `usable?'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/environment.rb:378:in `block in default_provider'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/environment.rb:377:in `each'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/environment.rb:377:in `default_provider'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/plugin/v2/command.rb:165:in `block in with_target_vms'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/plugin/v2/command.rb:192:in `call'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/plugin/v2/command.rb:192:in `block in with_target_vms'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/plugin/v2/command.rb:174:in `each'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/plugin/v2/command.rb:174:in `with_target_vms'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/up/command.rb:74:in `block in execute'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/environment.rb:277:in `block (2 levels) in batch'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/environment.rb:275:in `tap'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/environment.rb:275:in `block in batch'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/environment.rb:274:in `synchronize'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/environment.rb:274:in `batch'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/up/command.rb:58:in `execute'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/cli.rb:42:in `execute'
        from c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/environment.rb:301:in `cli'
        from c:/Program_Files/HashiCorp/Vagrant/bin/../embedded/gems/gems/vagrant-1.7.2/bin/vagrant:174:in `<main>'
```

I tried manually 'hacking' `c:/Program_Files/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/virtualbox/driver/meta.rb` by just inserting `return ""4.3.20""` on line 414, but then vagrant up still fails at trying to determine the recommended name for my VirtualBox VM.

```
ERROR warden: Error occurred: Vagrant was unable to determine the recommended name for your
VirtualBox VM. This is usually an issue with VirtualBox. The output
from VirtualBox is shown below, which may contain an error to fix.
The best way to fix this issue is usually to uninstall VirtualBox,
restart your computer, then reinstall VirtualBox.
```

As stated I have uninstalled Virtualbox, restarted my computer and reinstalled VirtualBox. All to no avail.
",True,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/75550956,Vagrant cannot find version of Virtualbox on Windows 8.1,petardudas,22,57028956,2,75550956,0,57028956,2015-02-23T14:37:26Z,"@call-a3 I may assume that you have initialised a vagrant VM with something like ""vagrant init ubuntu/trusty64"" to create a ""Vagrantfile"". Try deactivate all other network adapters except the one you are connected to the internet and the ""Virtual Box Host-Only Network"" and try to start the VM with ""vagrant up"". 
That's how I solved my Vagrant and VMWare error.
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/75614293,Vagrant cannot find version of Virtualbox on Windows 8.1,call-a3,22,57028956,3,75614293,0,75550956,2015-02-23T19:32:52Z,"I'm trying to initialize a box from an existing Vagrantfile, so you are right to assume that ""vagrant init"" is not needed anymore.
I tried your suggestion of turning off all unnecessary network interfaces, but this didn't change anything. 

I might be mistaken since I'm not very familiar with vagrant internals, but I don't see why my network interfaces should even matter at this point.

After some investigation, I would think that the implementation of `Vagrant::Util::Subprocess.execute` in [C:\Program_Files\HashiCorp\Vagrant\embedded\gems\gems\vagrant-1.7.2\lib\vagrant\util\subprocess.rb](https://github.com/mitchellh/vagrant/blob/v1.7.2/lib/vagrant/util/subprocess.rb#L38) is somehow unable to read the output of a perfectly fine-working VBoxManage.
Alternatively, it is possible that [C:\Program_Files\HashiCorp\Vagrant\embedded\gems\gems\vagrant-1.7.2\plugins\providers\virtualbox\driver\base.rb:404](https://github.com/mitchellh/vagrant/blob/v1.7.2/plugins/providers/virtualbox/driver/base.rb#L404) is somehow wrongly set up so it does not handle the output it receives from the aforementioned method properly.
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/75819157,Vagrant cannot find version of Virtualbox on Windows 8.1,mitchellh,22,57028956,4,75819157,0,75614293,2015-02-24T18:46:54Z,"100% of the time we've seen this error it is indicative of a broken VirtualBox installation. VirtualBox on Windows sometimes appears to be installed but is simply broken. We've seen situations where executing VBoxManage directly in a shell gets output 50% of the time. 

@call-a3 may be correct and our subprocess implementation may be buggy, but until we can get a clean repro case I can't really fix it. I understand your expertise may be less but since you have a clear repro case you're in the best position to find a fix. I apologize, I want to help but I can't without a repro.

It is really annoying and we'd like this to be 100% solved, but so far we've seen it mostly as a VirtualBox issue, though this may be a different case.
",False,0,CONTRIBUTOR
https://api.github.com/repos/hashicorp/vagrant/issues/comments/75933349,Vagrant cannot find version of Virtualbox on Windows 8.1,call-a3,22,57028956,5,75933349,0,75819157,2015-02-25T09:53:59Z,"I can see I'll have to (try to) solve this one myself... Could you at least give me some pointers about how I should go about debugging this issue? I have never built anything in ruby myself, let alone debugged anything... I have enough coding skill in other languages and general reasoning power to more-or-less understand what's happening in the ruby code when I read through it though.

Could I somehow hook into vagrant while it's executing the ""vagrant up""-command with some debugger and from there do step-by-step execution? Or is there a way to start vagrant straight from a debugger so that it acts as if ""vagrant up"" was called from a terminal?
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/75960112,Vagrant cannot find version of Virtualbox on Windows 8.1,call-a3,22,57028956,6,75960112,0,75933349,2015-02-25T13:36:16Z,"Never mind my previous request. I followed the instructions on rubyinstaller.org for getting ruby ready for development/debugging and installed the trial version of RubyMine. So I'm up and running with a functional debugger/code editor for ruby on Windows :)

My first discoveries while stepping through the code is oddly, without making any further changes to my system, that vagrant now DOES manage to get the output from VBoxManage. However, it only does so when I have some breakpoints enabled around the pieces of code that read input from the process. 

[/lib/vagrant/util/subprocess.rb:144](/mitchellh/vagrant/blob/master/lib/vagrant/util/subprocess.rb#L144)
[/lib/vagrant/util/subprocess.rb:186](/mitchellh/vagrant/blob/master/lib/vagrant/util/subprocess.rb#L186)

Without the breakpoints, vagrant fails with a Vagrant::Errors::VirtualBoxVersionEmpty. With the breakpoints, vagrant continues as if everything is fine. This makes me suspect that some timing issue is at play here... 
Any feedback on this? Is there a way to make vagrant wait a little longer for output? Is it possible that this is a bug in the childprocess gem or should I continue to look into how/if vagrant waits for output?
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/75993594,Vagrant cannot find version of Virtualbox on Windows 8.1,mitchellh,22,57028956,7,75993594,0,75960112,2015-02-25T16:32:33Z,"Hey @call-a3 that is really helpful. I'm going to reopen this so I know to look at this. The fact that it works with ""breakpoints"" means it might be timing related.
",False,0,CONTRIBUTOR
https://api.github.com/repos/hashicorp/vagrant/issues/comments/78254463,Vagrant cannot find version of Virtualbox on Windows 8.1,jnehring,22,57028956,8,78254463,0,75993594,2015-03-11T12:35:24Z,"+1 to fix this. Im having the same problem on Windows 8.1 x64, Vagrant 1.7.2 and Virtual Box 4.3 and cannot use Vagrant.
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/78362067,Vagrant cannot find version of Virtualbox on Windows 8.1,call-a3,22,57028956,9,78362067,0,78254463,2015-03-11T20:18:53Z,"I've further narrowed it down. Since I put both breakpoints on the same function call (`read_until_block`), I decided to do some further digging into that function. I found that the problem is solved by either increasing the timeout on the select() function on [line 28 of the io utility file](https://github.com/mitchellh/vagrant/blob/master/lib/vagrant/util/io.rb#L28) from 0.1 to 1.0, OR replacing `break` with `next` on the next line.

I did run into some other bug (SSH exiting with non-0) while using the first approach. This might be completely unrelated though (external reason for failure rather than this patch), but either way I'm running vagrant without issue right now using the second alternative fix.
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/78449140,Vagrant cannot find version of Virtualbox on Windows 8.1,jnehring,22,57028956,10,78449140,0,78362067,2015-03-12T09:41:37Z,"I changed the timeout in the io utility file from 0.1 to 1.0 as you suggested and now vagrant works fine. Thank you, that's really good :)
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/81252833,Vagrant cannot find version of Virtualbox on Windows 8.1,mani0070,22,57028956,11,81252833,0,78449140,2015-03-15T21:37:26Z,"I'm having the same problem using hyperV any help ?

==> default: Verifying Hyper-V is enabled...
C:/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/config.rb:83:in `block in missing_interpolation_argume
nt_handler': missing interpolation argument :name in ""The box you're using with the Hyper-V provider ('%{name}')\ni
s invalid. A Hyper-V box should contain both a\n\""Virtual Machines\"" and a \""Virtual Hard Disks\"" folder that are\n
created as part of exporting a Hyper-V machine.\n\nWithin these directories, Vagrant expects to find the\nvirtual m
achine configuration as well as the root hard disk.\n\nThe box you're attempting to use is missing one or both of\n
these directories or does not contain the files expected. Verify\nthat you added the correct box. If this problem p
ersists,\nplease contact the creator of the box for assistance."" ({:_key=>:box_invalid, :_namespace=>""vagrant_hyper
v.errors""} given) (I18n::MissingInterpolationArgument)
        from C:/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/interpolate/ruby.rb:29:in`call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/interpolate/ruby.rb:29:in `block in inter
polate_hash'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/interpolate/ruby.rb:21:in`gsub'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/interpolate/ruby.rb:21:in `interpolate_ha
sh'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/interpolate/ruby.rb:17:in`interpolate'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/backend/base.rb:153:in `interpolate'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n/backend/base.rb:41:in`translate'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n.rb:157:in `block in translate'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n.rb:153:in`catch'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/i18n-0.6.11/lib/i18n.rb:153:in `translate'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/errors.rb:103:in`translate_error'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/errors.rb:72:in `initialize'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/hyperv/action/import.rb:41:in
`exception'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/hyperv/action/import.rb:41:in
`raise'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/hyperv/action/import.rb:41:in
`call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:95:in`block in fin
alize_action'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in`call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/builder.rb:116:in `call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/runner.rb:66:in`block in run
'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/util/busy.rb:19:in `busy'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/runner.rb:66:in`run'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/builtin/call.rb:53:in `call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in`call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/builtin/config_validate.rb:25
:in `call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in`call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/builtin/handle_box.rb:56:in `
call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in`call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/hyperv/action/check_enabled.rb
:18:in `call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in`call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/builder.rb:116:in `call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/runner.rb:66:in`block in run
'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/util/busy.rb:19:in `busy'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/runner.rb:66:in`run'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/machine.rb:214:in `action_raw'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/machine.rb:191:in`block in action'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/environment.rb:516:in `lock'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/machine.rb:178:in`call'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/machine.rb:178:in `action'
        from C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/batch_action.rb:82:in`block (2 leve
ls) in run'
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/81518523,Vagrant cannot find version of Virtualbox on Windows 8.1,call-a3,22,57028956,12,81518523,0,81252833,2015-03-16T09:08:04Z,"@mani0070 I don't immediately see how this is the same problem... Can you explain why you think your problem is caused by the same bug that this issue is about?
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/81748256,Vagrant cannot find version of Virtualbox on Windows 8.1,call-a3,22,57028956,13,81748256,0,81518523,2015-03-16T15:41:22Z,"@jnehring I found that adjusting the timeout to 1.0 is not a reliable fix. It does make this error less likely to occur, but doesn't completely avoid it. Changing `break` into `next` on line 29 is more reliable and fixes the root of the problem: only to stop listening for output until EOF is encountered.
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/104542695,Vagrant cannot find version of Virtualbox on Windows 8.1,call-a3,22,57028956,14,104542695,0,81748256,2015-05-22T07:07:08Z,"@mitchellh Could you apply this fix (change `break` to `next` on [lib/vagrant/util/io.rb:28](https://github.com/mitchellh/vagrant/blob/master/lib/vagrant/util/io.rb#L28)) or do you prefer me to create a fork and PR for this?
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/115221438,Vagrant cannot find version of Virtualbox on Windows 8.1,djkwagala,22,57028956,15,115221438,0,104542695,2015-06-25T11:56:15Z,"@mitchellh please  rectify this.
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/118978053,Vagrant cannot find version of Virtualbox on Windows 8.1,mitchellh,22,57028956,16,118978053,0,115221438,2015-07-06T19:54:22Z,"I've upped the timeout for this patch release, and we'll look at a better solution for 1.8.
",False,0,CONTRIBUTOR
https://api.github.com/repos/hashicorp/vagrant/issues/comments/119118264,Vagrant cannot find version of Virtualbox on Windows 8.1,call-a3,22,57028956,17,119118264,0,118978053,2015-07-07T08:28:01Z,"@mitchellh Actually, I found out that changing `break` to `next` inside the wait-loop is a better solution than increasing the timeout. Unless of course you have a reason for breaking before an EOF is encountered inside that loop...
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/119220291,Vagrant cannot find version of Virtualbox on Windows 8.1,sethvargo,22,57028956,18,119220291,0,119118264,2015-07-07T14:24:12Z,"@mitchellh reopened this - looks like we might have a simpler solution
",False,0,CONTRIBUTOR
https://api.github.com/repos/hashicorp/vagrant/issues/comments/119223227,Vagrant cannot find version of Virtualbox on Windows 8.1,mitchellh,22,57028956,19,119223227,0,119220291,2015-07-07T14:35:06Z,"No, I read that. I don't want to do that for 1.7.3 because it is more invasive and requires more thought before making that change. It can cause other issues. The reason we break is because if that read ever blocks, it is not good, and the select is telling us it _will_ block. 

I need to know why the select isn't working.
",False,0,CONTRIBUTOR
https://api.github.com/repos/hashicorp/vagrant/issues/comments/119236668,Vagrant cannot find version of Virtualbox on Windows 8.1,sethvargo,22,57028956,20,119236668,0,119223227,2015-07-07T15:18:25Z,":+1: 
",False,0,CONTRIBUTOR
https://api.github.com/repos/hashicorp/vagrant/issues/comments/140548962,Vagrant cannot find version of Virtualbox on Windows 8.1,blindpet,22,57028956,21,140548962,0,119236668,2015-09-15T21:21:22Z,"I am getting the same error as @mitchellh with Hyper-V (Windows 2012R2 Datacenter). Googling my error led me here so the issue must be similar enough if it throws the same error message. Will create a separate ticket.
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/247793620,Vagrant cannot find version of Virtualbox on Windows 8.1,friend0,22,57028956,22,247793620,0,140548962,2016-09-17T17:53:56Z,"Changing the timeout didn't address this issue for me. Neither did a Virtualbox re-install. Interestingly, the debug command the error prompts a user to try is not properly formatted with quotes as Windows requires.
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/608195891,Vagrant cannot find version of Virtualbox on Windows 8.1,ghost,22,57028956,23,608195891,0,247793620,2020-04-03T02:32:14Z,"I'm going to lock this issue because it has been closed for _30 days_ ⏳. This helps our maintainers find and focus on the active issues.

If you have found a problem that seems similar to this, please open a new issue and complete the issue template so we can capture all the details necessary to investigate further.
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/5310,Vagrant package --base fails,digitalronin,6,57052292,1,57052292,0,0,2015-02-09T16:20:06Z,"""vagrant package --base [server name]"" is generating the following errors;

```
my-trusty64: Inserting generated public key within guest...
/opt/vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/communicators/ssh/communicator.rb:171:in `ready?': undefined method `join' for nil:NilClass (NoMethodError)
from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/machine.rb:249:in `guest'
from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/builtin/graceful_halt.rb:50:in `call'
from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
```

AFAICT, Vagrant::Machine#data_dir is coming back as nil which, according to the comments in lib/vagrant/machine.rb shouldn't happen. 

It seems as though plugins/commands/package/command.rb might need a default value for data_dir to pass into Vagrant::Machine.new, but that's as far as I could get in figuring out how to fix this.

More details and full log & backtrace are below.

David

This is my Vagrantfile;

```
# -*- mode: ruby -*-
# vi: set ft=ruby :

Vagrant.configure('2') do |config|
  config.vm.box = 'ubuntu/trusty64'
  config.vm.provider ""virtualbox"" do |vb|
    vb.name = 'my-trusty64'
  end
end
```

Then;

```
$ vagrant up
$ vagrant package --base my-trusty64
```

...and boom.

This is using Vagrant 1.7.2 and Ruby 2.2.0 with VirtualBox 4.3.20r96996 on a Mac running OS X 10.9.5 (I got the same result using Ruby 1.8.7)

Log and backtrace;

```
Bringing machine 'default' up with 'virtualbox' provider...
==> default: Importing base box 'ubuntu/trusty64'...
...default: Matching MAC address for NAT networking...
==> default: Checking if box 'ubuntu/trusty64' is up to date...
==> default: Setting the name of the VM: my-trusty64
==> default: Clearing any previously set forwarded ports...
==> default: Clearing any previously set network interfaces...
==> default: Preparing network interfaces based on configuration...
    default: Adapter 1: nat
==> default: Forwarding ports...
    default: 22 => 2222 (adapter 1)
==> default: Booting VM...
==> default: Waiting for machine to boot. This may take a few minutes...
    default: SSH address: 127.0.0.1:2222
    default: SSH username: vagrant
    default: SSH auth method: private key
    default: Warning: Connection timeout. Retrying...
    default: Warning: Remote connection disconnect. Retrying...
    default: 
    default: Vagrant insecure key detected. Vagrant will automatically replace
    default: this with a newly generated keypair for better security.
    default: 
    default: Inserting generated public key within guest...
    default: Removing insecure key from the guest if its present...
    default: Key inserted! Disconnecting and reconnecting using new SSH key...
==> default: Machine booted and ready!
GuestAdditions versions on your host (4.3.20) and guest (4.3.10) do not match.
stdin: is not a tty
 * Stopping VirtualBox Additions
   ...done.
stdin: is not a tty
Reading package lists...
Building dependency tree...
Reading state information...
The following packages were automatically installed and are no longer required:
  dkms fakeroot gcc gcc-4.8 libasan0 libatomic1 libc-dev-bin libc6-dev
  libdrm-intel1 libdrm-nouveau2 libdrm-radeon1 libfakeroot libfontenc1
  libgcc-4.8-dev libgl1-mesa-dri libgl1-mesa-glx libglapi-mesa libgomp1
  libice6 libitm1 libllvm3.4 libpciaccess0 libpixman-1-0 libquadmath0 libsm6
  libtsan0 libtxc-dxtn-s2tc0 libx11-xcb1 libxaw7 libxcb-dri2-0 libxcb-dri3-0
  libxcb-glx0 libxcb-present0 libxcb-sync1 libxcomposite1 libxdamage1
  libxfixes3 libxfont1 libxkbfile1 libxmu6 libxpm4 libxrandr2 libxrender1
  libxshmfence1 libxt6 libxxf86vm1 linux-libc-dev manpages-dev x11-common
  x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils xserver-common
  xserver-xorg-core
Use 'apt-get autoremove' to remove them.
The following packages will be REMOVED:
  virtualbox-guest-dkms* virtualbox-guest-utils* virtualbox-guest-x11*
0 upgraded, 0 newly installed, 3 to remove and 0 not upgraded.
After this operation, 12.1 MB disk space will be freed.
(Reading database ... 60959 files and directories currently installed.)
Removing virtualbox-guest-dkms (4.3.10-dfsg-1) ...

-------- Uninstall Beginning --------
Module:  virtualbox-guest
Version: 4.3.10
Kernel:  3.13.0-39-generic (x86_64)
-------------------------------------

Status: Before uninstall, this module version was ACTIVE on this kernel.

vboxguest.ko:
 - Uninstallation
   - Deleting from: /lib/modules/3.13.0-39-generic/updates/dkms/
 - Original module
   - No original module was found for this module on this kernel.
   - Use the dkms install command to reinstall any previous module version.


vboxsf.ko:
 - Uninstallation
   - Deleting from: /lib/modules/3.13.0-39-generic/updates/dkms/
 - Original module
   - No original module was found for this module on this kernel.
   - Use the dkms install command to reinstall any previous module version.


vboxvideo.ko:
 - Uninstallation
   - Deleting from: /lib/modules/3.13.0-39-generic/updates/dkms/
 - Original module
   - No original module was found for this module on this kernel.
   - Use the dkms install command to reinstall any previous module version.

depmod....

DKMS: uninstall completed.

------------------------------
Deleting module version: 4.3.10
completely from the DKMS tree.
------------------------------
Done.
Removing virtualbox-guest-x11 (4.3.10-dfsg-1) ...
Purging configuration files for virtualbox-guest-x11 (4.3.10-dfsg-1) ...
Removing virtualbox-guest-utils (4.3.10-dfsg-1) ...
Purging configuration files for virtualbox-guest-utils (4.3.10-dfsg-1) ...
Processing triggers for man-db (2.6.7.1-1ubuntu1) ...
Processing triggers for libc-bin (2.19-0ubuntu6.3) ...
stdin: is not a tty
Reading package lists...
Building dependency tree...
Reading state information...
dkms is already the newest version.
dkms set to manually installed.
linux-headers-3.13.0-39-generic is already the newest version.
linux-headers-3.13.0-39-generic set to manually installed.
The following packages were automatically installed and are no longer required:
  libdrm-intel1 libdrm-nouveau2 libdrm-radeon1 libfontenc1 libgl1-mesa-dri
  libgl1-mesa-glx libglapi-mesa libice6 libllvm3.4 libpciaccess0 libpixman-1-0
  libsm6 libtxc-dxtn-s2tc0 libx11-xcb1 libxaw7 libxcb-dri2-0 libxcb-dri3-0
  libxcb-glx0 libxcb-present0 libxcb-sync1 libxcomposite1 libxdamage1
  libxfixes3 libxfont1 libxkbfile1 libxmu6 libxpm4 libxrandr2 libxrender1
  libxshmfence1 libxt6 libxxf86vm1 x11-common x11-xkb-utils xfonts-base
  xfonts-encodings xfonts-utils xserver-common xserver-xorg-core
Use 'apt-get autoremove' to remove them.
0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.
Copy iso file /Applications/VirtualBox.app/Contents/MacOS/VBoxGuestAdditions.iso into the box /tmp/VBoxGuestAdditions.iso
stdin: is not a tty
mount: block device /tmp/VBoxGuestAdditions.iso is write-protected, mounting read-only
Installing Virtualbox Guest Additions 4.3.20 - guest version is 4.3.10
stdin: is not a tty
Verifying archive integrity... All good.
Uncompressing VirtualBox 4.3.20 Guest Additions for Linux............
VirtualBox Guest Additions installer
Copying additional installer modules ...
Installing additional modules ...
Removing existing VirtualBox DKMS kernel modules ...done.
Removing existing VirtualBox non-DKMS kernel modules ...done.
Building the VirtualBox Guest Additions kernel modules ...done.
Doing non-kernel setup of the Guest Additions ...done.
Starting the VirtualBox Guest Additions ...done.
Installing the Window System drivers
Could not find the X.Org or XFree86 Window System, skipping.
An error occurred during installation of VirtualBox Guest Additions 4.3.20. Some functionality may not work as intended.
In most cases it is OK that the ""Window System drivers"" installation failed.
stdin: is not a tty
==> default: Checking for guest additions in VM...
==> default: Mounting shared folders...
    default: /vagrant => /Users/david/Projects/vagrant-basebox

$ vagrant package --base my-trusty64

==> my-trusty64: Attempting graceful shutdown of VM...
Text will be echoed in the clear. Please install the HighLine or Termios libraries to suppress echoed text.
vagrant@127.0.0.1's password:    my-trusty64: 
    my-trusty64: Vagrant insecure key detected. Vagrant will automatically replace
    my-trusty64: this with a newly generated keypair for better security.
    my-trusty64: 
    my-trusty64: Inserting generated public key within guest...
/opt/vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/communicators/ssh/communicator.rb:171:in `ready?': undefined method `join' for nil:NilClass (NoMethodError)
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/machine.rb:249:in `guest'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/builtin/graceful_halt.rb:50:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/builder.rb:116:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/runner.rb:66:in `block in run'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/util/busy.rb:19:in `busy'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/runner.rb:66:in `run'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/builtin/call.rb:43:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:95:in `block in finalize_action'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:95:in `block in finalize_action'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/builder.rb:116:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/runner.rb:66:in `block in run'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/util/busy.rb:19:in `busy'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/runner.rb:66:in `run'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/builtin/call.rb:53:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/virtualbox/action/discard_state.rb:15:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/virtualbox/action/check_accessible.rb:18:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:95:in `block in finalize_action'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/builder.rb:116:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/runner.rb:66:in `block in run'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/util/busy.rb:19:in `busy'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/runner.rb:66:in `run'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/builtin/call.rb:53:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/virtualbox/action/check_virtualbox.rb:17:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/virtualbox/action/check_accessible.rb:18:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/virtualbox/action/setup_package_files.rb:46:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:95:in `block in finalize_action'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/builder.rb:116:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/runner.rb:66:in `block in run'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/util/busy.rb:19:in `busy'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/runner.rb:66:in `run'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/builtin/call.rb:53:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/virtualbox/action/check_virtualbox.rb:17:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/builder.rb:116:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/runner.rb:66:in `block in run'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/util/busy.rb:19:in `busy'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/runner.rb:66:in `run'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/machine.rb:214:in `action_raw'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/machine.rb:191:in `block in action'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/environment.rb:516:in `lock'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/machine.rb:178:in `call'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/machine.rb:178:in `action'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/package/command.rb:83:in `package_vm'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/package/command.rb:66:in `package_base'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/commands/package/command.rb:42:in `execute'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/cli.rb:42:in `execute'
  from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/environment.rb:301:in `cli'
  from /opt/vagrant/bin/../embedded/gems/gems/vagrant-1.7.2/bin/vagrant:174:in `<main>'
```
",True,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/74487890,Vagrant package --base fails,dnataraj,6,57052292,2,74487890,0,57052292,2015-02-16T10:31:42Z,"I have the same error with vagrant 1.7.2, ruby 2.1.2p95, chefdk 0.3.6 while packagine a Centos 7 base box.

```
vagrant@127.0.0.1's password:vagrant
    f09c19ae-4ba4-4537-813d-c425de7dc32d: 
    f09c19ae-4ba4-4537-813d-c425de7dc32d: Vagrant insecure key detected. Vagrant will automatically replace
    f09c19ae-4ba4-4537-813d-c425de7dc32d: this with a newly generated keypair for better security.
    f09c19ae-4ba4-4537-813d-c425de7dc32d: 
    f09c19ae-4ba4-4537-813d-c425de7dc32d: Inserting generated public key within guest...
/opt/vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/communicators/ssh/communicator.rb:171:in `ready?': undefined method `join' for nil:NilClass (NoMethodError)
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/machine.rb:249:in `guest'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/builtin/graceful_halt.rb:50:in `call'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/builder.rb:116:in `call'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/runner.rb:66:in `block in run'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/util/busy.rb:19:in `busy'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/runner.rb:66:in `run'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/builtin/call.rb:43:in `call'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:95:in `block in finalize_action'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:95:in `block in finalize_action'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/builder.rb:116:in `call'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/runner.rb:66:in `block in run'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/util/busy.rb:19:in `busy'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/runner.rb:66:in `run'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/builtin/call.rb:53:in `call'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/virtualbox/action/discard_state.rb:15:in `call'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/providers/virtualbox/action/check_accessible.rb:18:in `call'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:95:in `block in finalize_action'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/warden.rb:34:in `call'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/builder.rb:116:in `call'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/action/runner.rb:66:in `block in run'
    from /opt/vagrant/embedded/gems/gems/vagrant-1.7.2/lib/vagrant/util/busy.rb:19:in `busy'

```
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/75737835,Vagrant package --base fails,cdelaitre,6,57052292,3,75737835,0,74487890,2015-02-24T11:08:20Z,"Workaround for vagrant 1.7.2 :
In file Vagrant/embedded/gems/gems/vagrant-1.7.2/plugins/communicators/ssh/communicator.rb
line 171 : add .env after @machine :
@machine.env.data_dir.join(""private_key"").open(""w+"") do |f|

Test OK :
$ vagrant package --output ac-centos66.box --base ac-centos66
==> ac-centos66: Attempting graceful shutdown of VM...
    ac-centos66:
    ac-centos66: Vagrant insecure key detected. Vagrant will automatically replace
    ac-centos66: this with a newly generated keypair for better security.
    ac-centos66:
    ac-centos66: Inserting generated public key within guest...
    ac-centos66: Removing insecure key from the guest if its present...
    ac-centos66: Key inserted! Disconnecting and reconnecting using new SSH key...
...
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/87606975,Vagrant package --base fails,kmark,6,57052292,4,87606975,0,75737835,2015-03-30T09:18:46Z,"@cdelaitre Thanks for the workaround.
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/99924732,Vagrant package --base fails,jgrossmanrtr,6,57052292,5,99924732,0,87606975,2015-05-07T16:11:19Z,"cdelaitre, thank you very much for sharing the workaround. 
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/141662015,Vagrant package --base fails,nmusatti,6,57052292,6,141662015,0,99924732,2015-09-19T12:58:30Z,"Same problem while packaging a CentOS 7 box with Vagrant 1.7.4 on a Windows 7 host. My current workaround is NOT to setup port forwarding for the VM's port 22.
",False,0,NONE
https://api.github.com/repos/hashicorp/vagrant/issues/comments/157907874,Vagrant package --base fails,mitchellh,6,57052292,7,157907874,0,141662015,2015-11-19T00:25:19Z,"Fixed! :) 
",False,0,CONTRIBUTOR
https://api.github.com/repos/gabordemooij/redbean/issues/438,"if table doesn't exist, redbean created an int(11) unsigned column for any string property ending in an numeric value like ""abc123""",r3wt,5,70735039,1,70735039,0,0,2015-04-24T16:36:20Z,"else i have no idea what happened. here's the code that resulted in this (seemingly) unexpected behavior.

``` php
//assume that $tx is an model of type ""transaction""

$db = \App\DB::getInstance(); //returns an instance of DB abstraction layer built on Redbean.
$prefix = 'abc';
$tx = $db->model('transaction');
$tx->tx_id = $db->getUnusedTxId($prefix);


//public function getUnusedTxId($prefix)
public function getUnusedTxId($prefix,$trys = 0)
{
    $prefix = str_replace(
        [' ','_','.','&',','],
        '',
        $prefix
    );
    if($trys > 100 && strpos($prefix,'-') === false){
        $prefix .= '-';
    }
    $word = '';
    for($i = 0; $i < 4; $i++){
        $word .= strval(rand(0,9));
    }
    $tx = $prefix.$word;
    if( !empty( \R::getRow('SELECT id FROM transaction WHERE tx_id=:tx AND active=""1""',[':tx'=>$tx]) ) ){
        $tx = $this->getUnusedTxId($prefix,++$trys); //recursion
    }
    return $tx; //so function would return $prefix + 4 charachter numeric string.
}
```

The first run of this code resulted in the following `tx_id`:

 `Morris0120`

redbean created and `INT(11)` column, which resulted in a stored value of `0`

going to the db and manually changing column to varchar solved the issue.
",True,0,CONTRIBUTOR
https://api.github.com/repos/gabordemooij/redbean/issues/comments/96132176,"if table doesn't exist, redbean created an int(11) unsigned column for any string property ending in an numeric value like ""abc123""",r3wt,5,70735039,2,96132176,0,70735039,2015-04-25T05:17:30Z,"was able to confirm the issue when creating a relation to another table based upon the `tx_id` column. i will prepare a test case if necessary.
",False,0,CONTRIBUTOR
https://api.github.com/repos/gabordemooij/redbean/issues/comments/96191117,"if table doesn't exist, redbean created an int(11) unsigned column for any string property ending in an numeric value like ""abc123""",gabordemooij,5,70735039,3,96191117,0,96132176,2015-04-25T12:25:14Z,"Thanks for reporting this. I just read the post, I will research this issue.
",False,0,OWNER
https://api.github.com/repos/gabordemooij/redbean/issues/comments/96195551,"if table doesn't exist, redbean created an int(11) unsigned column for any string property ending in an numeric value like ""abc123""",gabordemooij,5,70735039,4,96195551,0,96191117,2015-04-25T12:50:28Z,"Unfortunately I have been unable to confirm this issue.

Code:

```
 R::nuke();
 $test = R::dispense('test');
 $test->text = 'test123';
 R::store($test);
 print_r(R::inspect('test'));
```

Output:

```
 Array
 (
     [id] => int(11) unsigned
     [text] => varchar(191)
 )
```
",False,0,OWNER
https://api.github.com/repos/gabordemooij/redbean/issues/comments/96219763,"if table doesn't exist, redbean created an int(11) unsigned column for any string property ending in an numeric value like ""abc123""",r3wt,5,70735039,5,96219763,0,96195551,2015-04-25T15:00:30Z,"the name of your column needs to end in `_id`
",False,0,CONTRIBUTOR
https://api.github.com/repos/gabordemooij/redbean/issues/comments/96282463,"if table doesn't exist, redbean created an int(11) unsigned column for any string property ending in an numeric value like ""abc123""",gabordemooij,5,70735039,6,96282463,0,96219763,2015-04-25T21:35:54Z,"Ah, I see.

_id is a reserved prefix in RedBeanPHP, it denotes a reference to an database key.

This is part of the RedBeanPHP schema policy.
",False,0,OWNER
https://api.github.com/repos/gabordemooij/redbean/issues/441,Error: A database has already be specified for this key,sclearion,4,73423244,1,73423244,0,0,2015-05-05T20:30:51Z,"Is there a solvent workaround for ""A database has already be specified for this key"" when unit testing. If they key is already specified then why is it not invoked or used when called again? The Non-Static way is  verbose and is too coupled for our standards.
",True,0,NONE
https://api.github.com/repos/gabordemooij/redbean/issues/comments/99213539,Error: A database has already be specified for this key,sclearion,4,73423244,2,99213539,0,73423244,2015-05-05T20:38:07Z,"Nevermind, we found the src of the exception and will hack it accordingly.
",False,0,NONE
https://api.github.com/repos/gabordemooij/redbean/issues/comments/151784611,Error: A database has already be specified for this key,maheshkajale,4,73423244,3,151784611,0,99213539,2015-10-28T09:54:51Z,"I got the same error.

A database has already be specified for this key. in /var/www/html...

I have already setup one database and want to connect another database then I used R::addDatabase() function to add new databse and R::selectDatabase() function to select that database.

code is

define('dsn2', 'pgsql:host=localhost;dbname=mydb';
R::addDatabase('DB2', dsn2, 'dbusers', 'dbpasss');
R::selectDatabase('DB2');
",False,0,NONE
https://api.github.com/repos/gabordemooij/redbean/issues/comments/154186463,Error: A database has already be specified for this key,gabordemooij,4,73423244,4,154186463,0,151784611,2015-11-05T20:50:55Z,"Sorry, there is no way around this. Some people got burned by the database keys, so I implemented this protection mechanism.
",False,0,OWNER
https://api.github.com/repos/gabordemooij/redbean/issues/comments/320880646,Error: A database has already be specified for this key,paooolino,4,73423244,5,320880646,0,154186463,2017-08-08T07:56:10Z,"Sorry for reopening this. 

I'm facing the same problem and looked into the source code. 

Maybe I'm missing something, but sending R::close() I thought the current database ""key"" would have been removed. 

If it's not possible, we should have a method to clear the $toolboxes[$key] array, if not for production, just for tests. What do you think?",False,0,NONE
https://api.github.com/repos/gabordemooij/redbean/issues/443,Request For Feedback,r3wt,5,75947050,1,75947050,0,0,2015-05-13T11:08:43Z,"@gabordemooij 

As you probably know by now, i'm a religious zealot when it comes to redbean. I absolutely love the library. At work, i built a small library called ""Filter"" for processing huge medical forms and generating redbean models. We loved it so much it replaced all form processing and validation in our application.

 I have received permission to release an open source version of it, so i've begun doing so.

In a nutshell it just automates the entire process of filtering and validating input and building the redbean model. I've just pushed the first commit. Its basically just the library and a small example for now. Just to get the idea out there and see if people think its useful.

https://github.com/r3wt/RedBeanFVM

Feedback + Contribution welcomed (and appreciated). Cheers!
",True,0,CONTRIBUTOR
https://api.github.com/repos/gabordemooij/redbean/issues/comments/101776627,Request For Feedback,gabordemooij,5,75947050,2,101776627,0,75947050,2015-05-13T18:54:59Z,"Hi there,

Looks wonderful, I can imagine how such a tool boosts productivity.
Thanks for sharing this with us.
If you provide me with a nice description ala..

# RedBean FVM

Does this... etc does that etc...

I will put it on the RedBeanPHP website :)

cheers,
Gabor

On 2015-05-13 13:08, Garrett R. Morris wrote:

> @gabordemooij [1]
> 
> As you probably know by now, i'm a religious zealot when it comes to
> redbean. I absolutely love the library. At work, i built a small
> library called ""Filter"" for processing huge medical forms and
> generating redbean models. We loved it so much it replaced all form
> processing and validation in our application.
> 
> I have received permission to release an open source version of it, 
> so
> i've begun doing so.
> 
> In a nutshell it just automates the entire process of filtering and
> validating input and building the redbean model. I've just pushed the
> first commit. Its basically just the library and a small example for
> now. Just to get the idea out there and see if people think its
> useful.
> 
> https://github.com/r3wt/RedBean-FVM/blob/master/RedBeanFVM/examples/post.php
> [2]
> 
> Feedback + Contribution welcomed (and appreciated). Cheers!
> 
> ## 
> 
> Reply to this email directly or view it on GitHub [3].
> 
>   *
> 
> ## Links:
> 
> [1] https://github.com/gabordemooij
> [2]
> 
> https://github.com/r3wt/RedBean-FVM/blob/master/RedBeanFVM/examples/post.php
> [3] https://github.com/gabordemooij/redbean/issues/443
",False,0,OWNER
https://api.github.com/repos/gabordemooij/redbean/issues/comments/101802782,Request For Feedback,r3wt,5,75947050,3,101802782,0,101776627,2015-05-13T20:16:31Z,"Thanks for your reply Gabor. I will notify you once i have a stable release candidate ready. I actually just threw it all together this morning to get the idea out there. Thanks for your time!
",False,0,CONTRIBUTOR
https://api.github.com/repos/gabordemooij/redbean/issues/comments/102642698,Request For Feedback,r3wt,5,75947050,4,102642698,0,101802782,2015-05-16T15:55:10Z,"@gabordemooij Ok Gabor. I've finished up the library. Now i'm just doing some testing just to make sure i didn't miss any edge cases or make any mistakes. I attempted to write a succinct explanation of the plugin, but i'm not sure i did a good job of explaining it:

# RedBeanFVM

RedbeanFVM makes Filtering, Validating , and Generating RedBean Models easy, by taking your blank Model, some rules, and the data source and generating a fully constructed RedBean Model.

You can see a list of examples in the [README](https://github.com/r3wt/RedBeanFVM/blob/master/README.md)
",False,0,CONTRIBUTOR
https://api.github.com/repos/gabordemooij/redbean/issues/comments/102652476,Request For Feedback,gabordemooij,5,75947050,5,102652476,0,102642698,2015-05-16T16:55:59Z,"added http://www.redbeanphp.com/plugins
",False,0,OWNER
https://api.github.com/repos/gabordemooij/redbean/issues/comments/102655329,Request For Feedback,r3wt,5,75947050,6,102655329,0,102652476,2015-05-16T17:05:29Z,"Alright cool. i'm going to go ahead and close this now. Thanks! Long live RedBeanPHP!
",False,0,CONTRIBUTOR
https://api.github.com/repos/gabordemooij/redbean/issues/444,"Getting  'Base table or view not found' with simple R::findOne, R::find, R::count before table exists",robertleeplummerjr,8,76458248,1,76458248,0,0,2015-05-14T19:07:23Z,"Query

``` php
R::count( 'group', ' name = ? ', [ 'Anon' ] );
```

Redbean latest
On: Ubuntu 15.04 with php 5.6.4

Oddly this happened just after I installed xdebug.
",True,0,NONE
https://api.github.com/repos/gabordemooij/redbean/issues/comments/102140348,"Getting  'Base table or view not found' with simple R::findOne, R::find, R::count before table exists",robertleeplummerjr,8,76458248,2,102140348,0,76458248,2015-05-14T19:10:12Z,"Stack trace:

```
Fatal error: Uncaught [42] - SQLSTATE[42S02]:
  Base table or view not found: 1146 Table 'Enpowi.group' doesn't exist trace:
    #0 /home/robert/Projects/Enpowi/vendor/gabordemooij/redbean/RedBeanPHP/Driver/RPDO.php(312): RedBeanPHP\Driver\RPDO->runQuery('SELECT COUNT(*)...', Array)
    #1 /home/robert/Projects/Enpowi/vendor/gabordemooij/redbean/RedBeanPHP/Driver/RPDO.php(349): RedBeanPHP\Driver\RPDO->GetAll('SELECT COUNT(*)...', Array)
    #2 /home/robert/Projects/Enpowi/vendor/gabordemooij/redbean/RedBeanPHP/Adapter/DBAdapter.php(164): RedBeanPHP\Driver\RPDO->GetOne('SELECT COUNT(*)...', Array)
    #3 /home/robert/Projects/Enpowi/vendor/gabordemooij/redbean/RedBeanPHP/QueryWriter/AQueryWriter.php(988): RedBeanPHP\Adapter\DBAdapter->getCell('SELECT COUNT(*)...', Array)
    #4 /home/robert/Projects/Enpowi/vendor/gabordemooij/redbean/RedBeanPHP/Repository.php(526): RedBeanPHP\QueryWriter\AQueryWriter->queryRecordCount('group', Array, ' name = ? ', Array)
    #5 /home/robert/Projects/Enpowi/vendor/gabordemooij/redbean/RedBeanPHP/OODB.php(457): RedBe in /home/robert/Projects/Enpowi/vendor/gabordemooij/redbean/RedBeanPHP/Driver/RPDO.php on line 171
```
",False,0,NONE
https://api.github.com/repos/gabordemooij/redbean/issues/comments/102153006,"Getting  'Base table or view not found' with simple R::findOne, R::find, R::count before table exists",robertleeplummerjr,8,76458248,3,102153006,0,102140348,2015-05-14T20:09:11Z,"So after turning off xdebug, the issue ""went away"", but after putting an echo out on the line throwing it, it looks like the issue persists, xdebug was just not allowing it to continue when it happened.  It looks like there are quite a few errors when handling each use case.  Are there plans on handling these errors?
",False,0,NONE
https://api.github.com/repos/gabordemooij/redbean/issues/comments/102623626,"Getting  'Base table or view not found' with simple R::findOne, R::find, R::count before table exists",gabordemooij,8,76458248,4,102623626,0,102153006,2015-05-16T12:40:08Z,"I will have a look into this issue.
RedBeanPHP inspects the error from the database, if the database is capable of providing proper SQL ANSI error codes, it will only allow the error to bubble op if the database is frozen.
",False,0,OWNER
https://api.github.com/repos/gabordemooij/redbean/issues/comments/102650510,"Getting  'Base table or view not found' with simple R::findOne, R::find, R::count before table exists",gabordemooij,8,76458248,5,102650510,0,102623626,2015-05-16T16:49:29Z,"I read some test code and it turns out count() is an exception.
Count will just return 0 if you try to count something that does not exist.
",False,0,OWNER
https://api.github.com/repos/gabordemooij/redbean/issues/comments/102707888,"Getting  'Base table or view not found' with simple R::findOne, R::find, R::count before table exists",robertleeplummerjr,8,76458248,6,102707888,0,102650510,2015-05-16T22:44:04Z,"Shouldn't you have the situation rather than throw an exception?
",False,0,NONE
https://api.github.com/repos/gabordemooij/redbean/issues/comments/102766683,"Getting  'Base table or view not found' with simple R::findOne, R::find, R::count before table exists",gabordemooij,8,76458248,7,102766683,0,102707888,2015-05-17T08:08:53Z,"I dont understand what you mean.
You count something that does not exists, so it returns 0.
I don't know why xdebug throws an exception, I get no exceptions here. If I turn on R::debug() I see the error appear but the script continues as expected.
",False,0,OWNER
https://api.github.com/repos/gabordemooij/redbean/issues/comments/102766705,"Getting  'Base table or view not found' with simple R::findOne, R::find, R::count before table exists",gabordemooij,8,76458248,8,102766705,0,102766683,2015-05-17T08:09:45Z,"Might be an xdebug configuration issue?
http://stackoverflow.com/questions/2904105/disabling-xdebugs-dumping-of-caught-exceptions
",False,0,OWNER
https://api.github.com/repos/gabordemooij/redbean/issues/comments/102786636,"Getting  'Base table or view not found' with simple R::findOne, R::find, R::count before table exists",robertleeplummerjr,8,76458248,9,102786636,0,102766705,2015-05-17T11:39:54Z,"Xdebug is just more verbose.  The exception isn't being thrown there, it is
thrown in php.  It has been my experience that try and catch are not the
ideal way to handle these scenarios, especially if you know that in a
certain context a specific error would be thrown...  That being said,
redbean is not a normal project.  What it tries to accomplish is quite
amazing, and perhaps there is a specific reason why an exception it thrown
rather than handling the scenario.
On May 17, 2015 4:09 AM, ""Gabor de Mooij"" notifications@github.com wrote:

> Might be an xdebug configuration issue?
> 
> http://stackoverflow.com/questions/2904105/disabling-xdebugs-dumping-of-caught-exceptions
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/gabordemooij/redbean/issues/444#issuecomment-102766705
> .
",False,0,NONE
https://api.github.com/repos/qbittorrent/qBittorrent/issues/3356,labels bug,uazuaz,4,93109737,1,93109737,0,0,2015-07-05T12:59:45Z,"sorry my poor english.
i use an example to explain this bug:
i have the ""append the label of the torrent to the save path"" option active; i use a folder called ""temporary"" for unfinished files, a ""download"" folder and a ""movies"" subfolder.
if i download a file without choosing any label, the unfinished file will be placed inside the ""temporary"" folder of course, but if i add the ""movies"" label to this already started download, the unfinished file is moved inside the ""movies"" folder instantly.
(this happens only if the label is added on a file who is already downloading; if you add the label from the very start it doesn't happen)

even worse, if i close and restart qbittorrent, the client will check for files inside the ""temporary"" folder, but the unfinished file is inside ""movies"" now, so the file will be downloaded again from the start, and you will have 2 unfinished files; one inside ""movies"" and another inside ""temporary"".
(this can be avoided cut-pasting the unfinished file back to ""temporary"" before restarting the client)

---

qbittorrent latest version (3.2.0)
o.s. windows 7 home premium 64 bit
",True,0,NONE
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/118624203,labels bug,chrishirst,4,93109737,2,118624203,0,93109737,2015-07-05T14:17:45Z,"Version??

Operating System??
",False,0,CONTRIBUTOR
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/118638348,labels bug,uazuaz,4,93109737,3,118638348,0,118624203,2015-07-05T17:01:41Z,"qbittorrent latest version (3.2.0)
o.s. windows 7 home premium 64 bit

edited the op.
",False,0,NONE
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/242113677,labels bug,thalieht,4,93109737,4,242113677,0,118638348,2016-08-24T15:47:07Z,"@uazuaz this doesn't happen anymore can you close this?
",False,0,CONTRIBUTOR
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/242150871,labels bug,uazuaz,4,93109737,5,242150871,0,242113677,2016-08-24T17:47:01Z,"ok, closed.
",False,0,NONE
https://api.github.com/repos/qbittorrent/qBittorrent/issues/3357,'Last Seen Complete' frequently updates to the recent time when torrent is incomplete,yurivict,8,93144364,1,93144364,0,0,2015-07-05T20:24:33Z,"I am looking at one torrent that is stuck at particular percentage value < 100% for weeks, and many other peers also show that same percentage. So it appears that nobody has an availability beyond that number.

However, 'Last Seen Complete' regularly gets updated to the recent time. This seems to be wrong, because nobody has it complete, and percentage of other peers also doesn't grow.

So why does qBittorrent keep updating 'Last Seen Complete'?",True,0,CONTRIBUTOR
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/118756690,'Last Seen Complete' frequently updates to the recent time when torrent is incomplete,chrishirst,8,93144364,2,118756690,0,93144364,2015-07-06T07:33:19Z,"> So it appears that nobody has an availability beyond that number.

Check the availability value on the general tab.

> However, 'Last Seen Complete' regularly gets updated to the recent time.

When does it get updated and how recent does it update to?

**AND**

**WHAT version and OS** ????????????????????????????????????????????????
",False,0,CONTRIBUTOR
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/118764613,'Last Seen Complete' frequently updates to the recent time when torrent is incomplete,yurivict,8,93144364,3,118764613,0,118756690,2015-07-06T08:02:10Z,"Availability tab shows the same availability percentage for many weeks.
'Last Seen Complete' usually shows time within 2 hours from now.

version 3.2.0 from ports on FreeBSD 10.1
",False,0,CONTRIBUTOR
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/118787397,'Last Seen Complete' frequently updates to the recent time when torrent is incomplete,chrishirst,8,93144364,4,118787397,0,118764613,2015-07-06T09:39:02Z,"Well, quite possibly a seed or additional peer(s) come 'on-line' for a few moments but do not stick around long enough to complete the missing piece(s).
",False,0,CONTRIBUTOR
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/118800598,'Last Seen Complete' frequently updates to the recent time when torrent is incomplete,yurivict,8,93144364,5,118800598,0,118787397,2015-07-06T10:21:06Z,"Either this, or 'Last Seen Complete' is bogus.
",False,0,CONTRIBUTOR
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/119006272,'Last Seen Complete' frequently updates to the recent time when torrent is incomplete,yurivict,8,93144364,6,119006272,0,118800598,2015-07-06T21:46:07Z,"It _could_ happen that there is some very unstable torrent node that periodically advertises availability, but doesn't let anyone to actually download. But this explanation seems less likely compared to bogus value being displayed.
- Solution suggestion:

The way to solve this problem is to add the set of hosts that were seen to provide higher availability compared to the local availability. This should be added to the 'General' tab when the torrent is locally incomplete. This can also be very useful in evaluation if it makes sense to wait longer in case of an incomplete torrent.
",False,0,CONTRIBUTOR
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/167275166,'Last Seen Complete' frequently updates to the recent time when torrent is incomplete,maersi,8,93144364,7,167275166,0,119006272,2015-12-26T03:47:14Z,"There is definitely an issue with Last Seen Complete. 

I have 2 torrents stalled. One is obscure and stuck at 75.4%, and has been for almost 2 months, however, I live in hope. It shows last seen complete as 20 minutes ago, and is regularly updated.
The other is more popular, and is stuck at 90.6% for me and several other users all with different clients. Currently showing last seen complete 8 minutes ago, and has been stalled for more than 12 hours. The really weird thing about the second one is that at one point, last seen complete went backwards, from 11:05 to 11:00. 
I probably changed my IP address (VPN) between these 2 times, but fail to understand why or how that could affect last seen complete in this way.

Second file is now showing as just 4 minutes ago.
General tab availability 0.906

Windows 10, version 3.2.5 
",False,0,NONE
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/499672822,'Last Seen Complete' frequently updates to the recent time when torrent is incomplete,Plantfood,8,93144364,8,499672822,0,167275166,2019-06-06T21:23:08Z,"> I am looking at one torrent that is stuck at particular percentage value < 100% for weeks

Kinda old thread but leaving this for anyone that sees this in a search. When torrents in QBitTorrent show 100% but not complete, a ""force recheck"" usually fixes it and it will then show as complete. I think this might happen due to it getting confused when files have the same name (files being downloaded, not torrent names).",False,0,NONE
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/1209426008,'Last Seen Complete' frequently updates to the recent time when torrent is incomplete,ghost,8,93144364,9,1209426008,0,499672822,2022-08-09T14:03:44Z,Closing this as it was reported on a very old version and therefore most likely fixed in latest version. If you're still experiencing it then please open a new ticket with updated information.,False,0,NONE
https://api.github.com/repos/qbittorrent/qBittorrent/issues/3358,Add checkbox for disabling WebUI port forwarding in WebUI,FuturePilot,4,93180288,1,93180288,0,0,2015-07-06T03:41:16Z,"There is no checkbox to disable the WebUI port forwarding in the WebUI like there is in the GUI client

![qbittorrent-webui-settings2](https://cloud.githubusercontent.com/assets/4391536/8531620/c2ebf33e-23f6-11e5-9c7d-3149000ca759.png)
![qbittorrent-webui-webui-settings2](https://cloud.githubusercontent.com/assets/4391536/8531621/c2f5a492-23f6-11e5-8bc9-4c9296fa9170.png)

Version 3.2.0
",True,0,NONE
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/118957893,Add checkbox for disabling WebUI port forwarding in WebUI,FuturePilot,4,93180288,2,118957893,0,93180288,2015-07-06T18:55:17Z,"Ok so this should be renamed. There is an option to disable this however there's no checkbox in the webui like there is in the GUI client.

`WebUI\UseUPnP=false`
",False,0,NONE
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/119513072,Add checkbox for disabling WebUI port forwarding in WebUI,ngosang,4,93180288,3,119513072,0,118957893,2015-07-08T09:16:46Z,"I think there isn't that option for the same reason there isn't ""Enable Web User Interface"". The inexperienced user may not be able to access the Web UI again.
",False,0,MEMBER
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/119877956,Add checkbox for disabling WebUI port forwarding in WebUI,ngosang,4,93180288,4,119877956,0,119513072,2015-07-09T08:46:33Z,"Fixed in #3384.
",False,0,MEMBER
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/119984947,Add checkbox for disabling WebUI port forwarding in WebUI,FuturePilot,4,93180288,5,119984947,0,119877956,2015-07-09T13:58:17Z,"[**@ngosang**](https://github.com/ngosang) commented on [Jul 8, 2015, 5:16 AM EDT](https://github.com/qbittorrent/qBittorrent/issues/3358#issuecomment-119513072):

> I think there isn't that option for the same reason there isn't ""Enable Web User Interface"". The inexperienced user may not be able to access the Web UI again.

Yeah I did consider that but I didn't think it would be as detrimental as accidentally disabling the webui.
",False,0,NONE
https://api.github.com/repos/qbittorrent/qBittorrent/issues/3360,Cannot add very large torrent,AyrA,25,93293514,1,93293514,0,0,2015-07-06T14:30:25Z,"I have a torrent with over 400 GB of data which qBittorrent refuses to add.

I am using qBittorrent 3.2.0 on W7 x64

I do not want to publish the torrent or its magnet link online. If a dev is ready, feel free to ask me and I can message you the file and the magnet link.

The torrent won't add at all with the message: **Failed to load the torrent: invalid or missing 'piece length' entry in torrent file.**

Adding of the magnet link works, but it stays stuck at ""Downloading metadata"". There are over 1000 users in the swarm with over 30 seeders.
",True,0,NONE
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/118955055,Cannot add very large torrent,mak0t0san,25,93293514,2,118955055,0,93293514,2015-07-06T18:47:22Z,"I am also experiencing this same issue, with the same torrent file.  The torrent file is about 24MB in size, and has a SHA-256 hash value of 4d4205349780a127bfa4cc3f0b1ca1bce2dcaec7c36960f0d7cb8871340b7017
",False,0,NONE
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/119002737,Cannot add very large torrent,bozhodimitrov,25,93293514,3,119002737,0,118955055,2015-07-06T21:27:04Z,"Same here with latest Win7 SP1 x64 and qBt 3.2.0.
Torrent infoHash just for testing: 51603bff88e0a1b3bad3962614978929c9d26955
",False,0,NONE
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/119016657,Cannot add very large torrent,AyrA,25,93293514,4,119016657,0,119002737,2015-07-06T22:31:29Z,"I have converted the torrent file to json, so I can analyze it in my browser.

Some stats:

```
files: 166067
piece length: 2097152 (equals 1024*2048 bytes [2MiB])
pieces: 3965080 bytes array (198254 SHA-1 hashes)
sum of all file sizes: 415768052618 bytes (396508 MiB)
```
",False,0,NONE
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/119024146,Cannot add very large torrent,ngosang,25,93293514,5,119024146,0,119016657,2015-07-06T23:09:50Z,"I'm trying to download this magnet but I can't retrieve the metadata... 

> magnet:?xt=urn:btih:51603bff88e0a1b3bad3962614978929c9d26955&tr=http%3a%2f%2fbt.careland.com.cn%3a6969%2fannounce&tr=http%3a%2f%2fmgtracker.org%3a2710%2fannounce&tr=udp%3a%2f%2f9.rarbg.me%3a2710%2fannounc&tr=udp%3a%2f%2fopen.demonii.com%3a1337&tr=udp%3a%2f%2f9.rarbg.me%3a2710%2fannounce&tr=udp%3a%2f%2fcoppersurfer.tk%3a6969%2fannounce&tr=udp%3a%2f%2fopen.demonii.com%3a1337%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2710%2fannounce&tr=udp%3a%2f%2ftracker.coppersurfer.tk%3a6969&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce

Please upload the .torrent to some filestorage service.
",False,0,MEMBER
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/119029912,Cannot add very large torrent,AyrA,25,93293514,6,119029912,0,119024146,2015-07-06T23:51:18Z,"See here: http://s000.tinyupload.com/?file_id=39983808449563766849
",False,0,NONE
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/119342973,Cannot add very large torrent,Skoddd,25,93293514,7,119342973,0,119029912,2015-07-07T21:14:42Z,"same here
",False,0,NONE
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/120703259,Cannot add very large torrent,dartraiden,25,93293514,8,120703259,0,119342973,2015-07-12T09:25:45Z,"https://hecker.io/eyyxo.torrent
http://infotomb.com/eyyxo.torrent

Tixati (Windows) - ok
Transmission-Qt (Windows) - fail
qBittorrent (Windows) - fail
uTorrent (Windows) - fail
",False,0,CONTRIBUTOR
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/121048385,Cannot add very large torrent,ngosang,25,93293514,9,121048385,0,120703259,2015-07-13T20:35:47Z,"This is a limitation in libtorrent. You can open a new issue here https://github.com/arvidn/libtorrent/issues quoting this issue. Error messages is ""metadata too large"".
",False,0,MEMBER
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/121098618,Cannot add very large torrent,AyrA,25,93293514,10,121098618,0,121048385,2015-07-14T00:32:42Z,"This limitation has been fixed a while ago: https://github.com/arvidn/libtorrent/issues/33#issuecomment-121068366

Please include the latest libTorrent and configure the value mentioned in the comment.
",False,0,NONE
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/121156705,Cannot add very large torrent,ngosang,25,93293514,11,121156705,0,121098618,2015-07-14T07:55:02Z,"In libtorrent-1.0.5 stable
max_metadata_size = 3MiB
In current libtorrent master branch
**max_metadata_size = 30MiB**
I think this will be solved in the next libtorrent release.
",False,0,MEMBER
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/121201573,Cannot add very large torrent,AyrA,25,93293514,12,121201573,0,121156705,2015-07-14T11:00:50Z,"this should be a settings somebody can make in his qBittorrent client. I have 16GiB of RAM and really do not care how high that value is. After all, if we load a torrent file, we now how big it will be in memory and there is no need for an artificial limit.
",False,0,NONE
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/121718590,Cannot add very large torrent,pluser,25,93293514,13,121718590,0,121201573,2015-07-15T19:15:12Z,"Hi,
I patched to libbittorrent to change max_metadata_size.
But qBittorrent doesn't accept .torrent file from web ui.
qBittorrent reports: `Jul 16 04:07:57 qbittorrent qbittorrent-nox[12022]: Http::RequestParser::ErrorCode Http::RequestParser::parseHttpRequest(const QByteArray&, Http::Request&) bad request: message too long`
A dialog box appears in the browser(firefox) and it says: `Upload Failed!`
My .torrent size is about 14MB and smaller one is seemed to be acceptable.
",False,0,NONE
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/121740504,Cannot add very large torrent,ngosang,25,93293514,14,121740504,0,121718590,2015-07-15T20:39:59Z,"Patch this line in qBittorrent too: https://github.com/qbittorrent/qBittorrent/blob/master/src/core/http/requestparser.h#L51
I think we should change this limit to 30 MiB in the next release to have the same limit as libtorrent. @sledgehammer999 
",False,0,MEMBER
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/121741076,Cannot add very large torrent,pluser,25,93293514,15,121741076,0,121740504,2015-07-15T20:42:40Z,"Thanks for your reply, @ngosang .
~~I patched that line, but the problem is remaining.~~
Now that line is `static ErrorCode parse(const QByteArray &data, Request &request, uint maxContentLength = 60000000 /* ~60MB */);` in my side.
",False,0,NONE
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/121748257,Cannot add very large torrent,pluser,25,93293514,16,121748257,0,121741076,2015-07-15T21:09:00Z,"Oh very sorry. That is my mistake.
I was changing the code and I built another code!
Your advice make the qbittorrent work fine.
Thanks!
",False,0,NONE
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/121757102,Cannot add very large torrent,sledgehammer999,25,93293514,17,121757102,0,121748257,2015-07-15T21:34:17Z,"Loading a huge .torrent file is different than loading a huge magnet.
When loading the .torrent file we use the `torrent_info::torrent_info(std::string const& filename, error_code& ec, int flags = 0);` which has an internal limit(I think it is 10MB). If we read the file into a buffer and instead use the `torrent_info (char const* buffer, int size, error_code& ec, int flags = 0);` constructor this limit doesn't apply.

session_settings::max_metadata_size controls the size of the metadata libtorrent will download when we pass it a magnet link before aborting.

The webui stuff is another issue.
",False,0,MEMBER
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/121841975,Cannot add very large torrent,pluser,25,93293514,18,121841975,0,121757102,2015-07-16T05:55:41Z,"I see.
Ok I will create another issue ticket if needed.
",False,0,NONE
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/132030653,Cannot add very large torrent,sledgehammer999,25,93293514,19,132030653,0,121841975,2015-08-18T01:59:54Z,"So, what is the status of this? I am little bit lost in the comments. Should I close this? (@pluser if yes, you can close it too)
",False,0,MEMBER
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/133163708,Cannot add very large torrent,pluser,25,93293514,20,133163708,0,132030653,2015-08-20T20:38:31Z,"I don't mind that :-)
",False,0,NONE
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/133170450,Cannot add very large torrent,dartraiden,25,93293514,21,133170450,0,133163708,2015-08-20T21:02:10Z,"Problem fixed in libtorrent/master and configurable by max_metadata_size.
but that is an ABI breaking, so it is not included in minor releases
https://github.com/arvidn/libtorrent/issues/33#issuecomment-121066932
",False,0,CONTRIBUTOR
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/336049712,Cannot add very large torrent,AyrA,25,93293514,22,336049712,0,133170450,2017-10-12T07:51:53Z,I close this because it's now over 2 years and no issue with sizes has appeared again.,False,0,NONE
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/565810290,Cannot add very large torrent,sicode,25,93293514,23,565810290,0,336049712,2019-12-15T13:35:06Z,"still here
using  4.2.0 on docker
try to add 1469kb torrent file


error mseeage
bool Http::RequestParser::parseFormData(const QByteArray&) multipart/form-data format error


Http::RequestParser::ParseResult Http::RequestParser::doParse(const QByteArray&) message body parsing error
",False,0,NONE
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/565810655,Cannot add very large torrent,AyrA,25,93293514,24,565810655,0,565810290,2019-12-15T13:40:02Z,"This looks like a different issue. The size issue was caused by a limitation of the underlying library, your issue seems to be with the web interface.",False,0,NONE
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/565836781,Cannot add very large torrent,FranciscoPombal,25,93293514,25,565836781,0,565810655,2019-12-15T19:00:35Z,@sicode Please open another issue with more details.,False,0,MEMBER
https://api.github.com/repos/qbittorrent/qBittorrent/issues/comments/567272362,Cannot add very large torrent,sicode,25,93293514,26,567272362,0,565836781,2019-12-19T00:21:37Z,"> @sicode Please open another issue with more details.

OK",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/1319,Show long file names,f242,27,118300774,1,118300774,0,0,2015-11-23T00:22:44Z,"![screen](http://img-fotki.yandex.ru/get/15513/78276594.c/0_eef0b_3fc2d6dd_orig.png)

> If someone sends a file with a long filename, a mouseover with the full filename should appear .
",True,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/158916933,Show long file names,auchri,27,118300774,2,158916933,0,118300774,2015-11-23T12:13:12Z,"Amazing description :+1:
",False,0,CONTRIBUTOR
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/279469455,Show long file names,cristian64,27,118300774,3,279469455,0,158916933,2017-02-13T17:56:06Z,I'm currently being annoyed by this issue. No way you can read the full name unless the file is downloaded first.,False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/279479657,Show long file names,f242,27,118300774,4,279479657,0,279469455,2017-02-13T18:32:22Z,"@cristian64 you can go to profile -> shared media -> files
but i think tooltip will be more useful",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/279483522,Show long file names,cristian64,27,118300774,5,279483522,0,279479657,2017-02-13T18:46:03Z,"Actually, I hadn't thought of that list of files, thank you. However, the list you see there doesn't even have the original file names, but some kind of cooked name, to remove special characters apparently.",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/279484031,Show long file names,john-preston,27,118300774,6,279484031,0,279483522,2017-02-13T18:47:53Z,@cristian64 I'm afraid they're removed on the server-side.,False,0,MEMBER
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/279485139,Show long file names,cristian64,27,118300774,7,279485139,0,279484031,2017-02-13T18:51:42Z,I think you're right. Only the client that sent the files have some trace of the original name.,False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/390419465,Show long file names,Aokromes,27,118300774,8,390419465,0,279485139,2018-05-19T17:17:17Z,"Interesting point on this, on chat side the filename is cut, but on contacts part the full name is show.
https://i.imgur.com/stLButz.png ",False,0,COLLABORATOR
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/501798127,Show long file names,SmartManoj,27,118300774,9,501798127,0,390419465,2019-06-13T17:19:16Z,"@f242 even on  profile -> shared media -> files , it truncated with ...
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/585869224,Show long file names,ido1990,27,118300774,10,585869224,0,501798127,2020-02-13T17:16:32Z,5 yrs and still the same?,False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/585870136,Show long file names,Aokromes,27,118300774,11,585870136,0,585869224,2020-02-13T17:18:05Z,"> 5 yrs and still the same?

pull requests are welcomed, also. like i pointed, on contacts part the full name is show, so if we take that we can use it for tooltip.",False,0,COLLABORATOR
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/585871253,Show long file names,ido1990,27,118300774,12,585871253,0,585870136,2020-02-13T17:20:14Z,"> 
> 
> > 5 yrs and still the same?
> 
> pull requests are welcomed, also. like i pointed, on contacts part the full name is show, so if we take that we can use it for tooltip.

I wish I could contribute to Telegram Desktop.
Don't know C++ :(",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/715652700,Show long file names,stale[bot],27,118300774,13,715652700,0,585871253,2020-10-24T01:34:57Z,"Hey there!

This issue will be automatically closed in 7 days if there would be no activity. We therefore assume that the user has lost interest or resolved the problem on their own.

Don't worry though; if this is an error, let us know with a comment and we'll be happy to reopen the issue.

Thanks!
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/715850742,Show long file names,SmartManoj,27,118300774,14,715850742,0,715652700,2020-10-24T07:22:37Z,"@ilya-fedin, stale bot can know the No. of reactions on an issue?",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/715851603,Show long file names,SmartManoj,27,118300774,15,715851603,0,715850742,2020-10-24T07:23:20Z,"@Aokromes image
![](https://i.imgur.com/stLButz.png)",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/715852428,Show long file names,SmartManoj,27,118300774,16,715852428,0,715851603,2020-10-24T07:23:56Z,@Aokromes could you send the file to a test channel?,False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/715853188,Show long file names,ilya-fedin,27,118300774,17,715853188,0,715852428,2020-10-24T07:24:32Z,"> stale bot can know the No. of reactions on an issue?

it doesn't look at reactions AFAIK

Don't know if authors of the bot can add such a feature, though",False,0,CONTRIBUTOR
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/715862346,Show long file names,Aokromes,27,118300774,18,715862346,0,715853188,2020-10-24T07:32:04Z,https://t.me/TelegramDesktopTalk/49074,False,0,COLLABORATOR
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/824749843,Show long file names,stale[bot],27,118300774,19,824749843,0,715862346,2021-04-22T11:13:49Z,"Hey there!

This issue was inactive for a long time and will be automatically closed in 30 days if there isn't any further activity. We therefore assume that the user has lost interest or resolved the problem on their own.

Don't worry though; if this is an error, let us know with a comment and we'll be happy to reopen the issue.

Thanks!
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/824871978,Show long file names,Remu-rin,27,118300774,20,824871978,0,824749843,2021-04-22T14:05:19Z,Still relevant.,False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/824954262,Show long file names,AndydeCleyre,27,118300774,21,824954262,0,824871978,2021-04-22T15:42:58Z,Relevant: #5231,False,0,CONTRIBUTOR
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/854100270,Show long file names,AxE47,27,118300774,22,854100270,0,824954262,2021-06-03T18:53:15Z,Still Not Solved !!!!!,False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/968758349,Show long file names,voltrare,27,118300774,23,968758349,0,854100270,2021-11-15T10:39:42Z,"true
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/1153164930,Show long file names,pablogzlezmora,27,118300774,24,1153164930,0,968758349,2022-06-12T13:16:20Z,Relevant.,False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/1229446318,Show long file names,ShreyMarwaha,27,118300774,25,1229446318,0,1153164930,2022-08-28T12:24:36Z,Still relevant.,False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/1231065560,Show long file names,MinusAlternative,27,118300774,26,1231065560,0,1229446318,2022-08-30T02:22:39Z,Please fix this. I find it insane that an app with 1B+ downloads misses such a basic feature.,False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/1304609702,Show long file names,23rd,27,118300774,27,1304609702,0,1231065560,2022-11-05T18:47:09Z,Tooltips for long filenames should be added to the 4.3.0 version.,False,0,COLLABORATOR
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/1597508089,Show long file names,Aokromes,27,118300774,28,1597508089,0,1304609702,2023-06-19T17:10:53Z,"yes, tooltip is there, but if 2 files contains 99% of the start of file with same name the 2nd and following will have the end of filename (without extension) cut, but acording preston this is server side limitation.

File name length
up to 60 characters, others will be trimmed out",False,0,COLLABORATOR
https://api.github.com/repos/telegramdesktop/tdesktop/issues/1320,Cannot send Photos with Telegram 0.9.10 under Windows 10,GAlexMES,54,118461644,1,118461644,0,0,2015-11-23T20:07:01Z,"I can't send photos with the current Telegram version under Windows 10. Telegram tries to send the photo, but it still has the waiting circle after over 20 minutes of waiting.
",True,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/159060968,Cannot send Photos with Telegram 0.9.10 under Windows 10,twiforce,54,118461644,2,159060968,0,118461644,2015-11-23T20:53:01Z,"Can confirm this. Files are affected too. Bug has started to appear on Windows 10 version 1511 (build 10586).
Sometimes Telegram app sends file instantly though. Running in compatibility mode or with higher privileges did not helped in my case.
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/159950728,Cannot send Photos with Telegram 0.9.10 under Windows 10,tyga,54,118461644,3,159950728,0,159060968,2015-11-26T16:10:20Z,"I also can confirm this after the update to Windows 10 version 1511. Just tried a clean reinstall of the tdesktop app and it fixed the issue for me.
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/160058734,Cannot send Photos with Telegram 0.9.10 under Windows 10,GAlexMES,54,118461644,4,160058734,0,159950728,2015-11-27T07:29:54Z,"What exactly do you mean with clean install? I tried a ""normal"" reinstall, and it did not fix the issue for me.
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/160063415,Cannot send Photos with Telegram 0.9.10 under Windows 10,brawaru,54,118461644,5,160063415,0,160058734,2015-11-27T08:00:54Z,"@GAlexMES, I think, ""clean reinstall"" is FULLY deleting of app (files, cache, registry)
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/160072425,Cannot send Photos with Telegram 0.9.10 under Windows 10,auchri,54,118461644,6,160072425,0,160063415,2015-11-27T08:45:10Z,"And it doesn't work with 0.9.13 either?
",False,0,CONTRIBUTOR
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/160155199,Cannot send Photos with Telegram 0.9.10 under Windows 10,bereap,54,118461644,7,160155199,0,160072425,2015-11-27T14:59:13Z,"I tried to reinstall the app first and it doesn't work (version 0.9.13). But then I tried to send a compressed image with caption and oddly enough the image could be send. After that sending files worked, too.
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/160185481,Cannot send Photos with Telegram 0.9.10 under Windows 10,GAlexMES,54,118461644,8,160185481,0,160155199,2015-11-27T18:20:05Z,"Yes, maybe the 0.9.13 fixed the problem. I uninstalled it, deleted the cache and everything in %appdata% and reinstalled it. That worked for me.
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/160202372,Cannot send Photos with Telegram 0.9.10 under Windows 10,twiforce,54,118461644,9,160202372,0,160185481,2015-11-27T20:53:22Z,"File sharing was working for a whole day but right now it stuck again. Don't really know what is triggering this.
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/161767755,Cannot send Photos with Telegram 0.9.10 under Windows 10,GAlexMES,54,118461644,10,161767755,0,160202372,2015-12-03T20:05:27Z,"@twiforce yeah, same here. It was more then a day, but is failing now too.
I don't know, what is triggering this too.
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/164196784,Cannot send Photos with Telegram 0.9.10 under Windows 10,telegram-error,54,118461644,11,164196784,0,161767755,2015-12-12T22:00:54Z,"This needs to be fixed. It seems to work for like an hour a day and then just stop working at all. The images will not be sent immediatelly but instead hours afterwards.

Is there any other place where bugs can be reported for telegram? Their trello page says: https://core.telegram.org/tsi/trello.com
trello.com
The page has not been saved
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/167260546,Cannot send Photos with Telegram 0.9.10 under Windows 10,twiforce,54,118461644,12,167260546,0,164196784,2015-12-25T19:59:47Z,"Images are still stuck sometimes.
This might be irrelevant, but I've just sent some images from clipboard (PrtScr, Ctrl+V in Telegram) and after a while app alerted with this:
https://github.com/telegramdesktop/tdesktop/blob/50222ad87e7cb2deb78582985c54f3a70e96ab7e/Telegram/SourceFiles/localimageloader.cpp#L412 (""Could not send an empty file :("")
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/169459087,Cannot send Photos with Telegram 0.9.10 under Windows 10,GAlexMES,54,118461644,13,169459087,0,167260546,2016-01-06T20:59:20Z,"Same problem with version 0.9.18.
Not even images, the whole upload process is affected.I tried .pdf, .png, .jpg, .txt, .java.
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/175523793,Cannot send Photos with Telegram 0.9.10 under Windows 10,kuyantus,54,118461644,14,175523793,0,169459087,2016-01-27T10:04:01Z,"I can confirm this bug too. Telegram desktop 0.9.18 + windows 10 build 10586, images are not sending.
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/179084337,Cannot send Photos with Telegram 0.9.10 under Windows 10,eddiezato,54,118461644,15,179084337,0,175523793,2016-02-03T08:24:24Z,"I confirm this bug too. This is annoying. Telegram 0.9.19 dev, Windows 10586.71
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/186067851,Cannot send Photos with Telegram 0.9.10 under Windows 10,CansecoDev,54,118461644,16,186067851,0,179084337,2016-02-19T05:50:25Z,"Confirmed this, it is really annoying, even sending an 33 KB image, it freezes at [ 32 / 33KB ]
Telegram Desktop 0.9.24 - Windows 10 Version 1511 Build 10586.104

[Imgur](http://i.imgur.com/msQcIcZ.png)
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/189490847,Cannot send Photos with Telegram 0.9.10 under Windows 10,CansecoDev,54,118461644,17,189490847,0,186067851,2016-02-26T21:36:20Z,"Can reproduce in tdesktop 0.9.28
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/190635625,Cannot send Photos with Telegram 0.9.10 under Windows 10,eddiezato,54,118461644,18,190635625,0,189490847,2016-03-01T09:40:26Z,"Still bugged. Telegram 0.9.28 dev, Windows 10586.104
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/196279772,Cannot send Photos with Telegram 0.9.10 under Windows 10,SilentPrayeCG,54,118461644,19,196279772,0,190635625,2016-03-14T12:04:25Z,"My friend, have same problem. I tried figure out what's wrong, but can't. We both have win 10 x64, and for me telegram works fine, for him - is not. Also it start working, kinda, after titling one of sending photo, but bug is return after restarting telegram.
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/196287144,Cannot send Photos with Telegram 0.9.10 under Windows 10,twiforce,54,118461644,20,196287144,0,196279772,2016-03-14T12:19:00Z,"When sending large files, e.g. mp3, flac or zip, it stucks just like the images. Hovewer, I've noticed that app fails to send last 0.2 Mb of a file. Either this, or just 0 Mb sent. Circle indicator is becoming full after a while if sending has begun, but the file just stuck with this 8/8.2 Mb for an hour or two.
This works only in Windows 10, builds older than 1511.
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/196299869,Cannot send Photos with Telegram 0.9.10 under Windows 10,telegramdesktop,54,118461644,21,196299869,0,196287144,2016-03-14T12:59:54Z,"@twiforce Please try the latest 0.9.30 dev version with files upload. Still the same problem?
",False,0,COLLABORATOR
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/196335203,Cannot send Photos with Telegram 0.9.10 under Windows 10,twiforce,54,118461644,22,196335203,0,196299869,2016-03-14T14:32:42Z,"@telegramdesktop I couldn't find 0.9.30 so I've downloaded 0.9.31 from [here](https://updates.tdesktop.com/tsetup/tportable.0.9.31.zip) (bulit-in updater didn't saw update yet). Drag-and-dropped a large file, same problem:

![telegram](https://cloud.githubusercontent.com/assets/4412289/13747333/d097d20e-ea08-11e5-9e93-b754f385a6b7.gif)

I've tried sending image as a photo by clicking on the button in input, same. Tried to run with compatibility mode (Windows 8) or as administrator — no luck.
Same home network, on phone it works like a charm. Starting to appear on Windows 10 after update to 1511 version. I'll try this update on newer Windows builds, though.
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/196348821,Cannot send Photos with Telegram 0.9.10 under Windows 10,telegramdesktop,54,118461644,23,196348821,0,196335203,2016-03-14T14:52:47Z,"@twiforce so it didn't even start to upload?.. Would you please do the following:
1. go to Settings, type ""debugmode"" and enable debug logs
2. go to any chat and try to upload a photo
3. wait for a minute or two while it tries to upload, without doing anything else
4. quit Telegram and archive DebugLogs folder near Telegram.exe for me

(you can contact me directly at https://telegram.me/preston instead of here, I would suggest you not to upload it here because of the private data in logs, it contains full network activity)
",False,0,COLLABORATOR
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/196384490,Cannot send Photos with Telegram 0.9.10 under Windows 10,SilentPrayeCG,54,118461644,24,196384490,0,196348821,2016-03-14T16:01:35Z,"I also asked friend check 30dev, and then 31stable, and it still doesn't work for him. I mean sending, it didn't stuck, it doesn't start sending at all, except if image was titled, it start working (but sometimes).
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/196413188,Cannot send Photos with Telegram 0.9.10 under Windows 10,twiforce,54,118461644,25,196413188,0,196384490,2016-03-14T17:04:33Z,"Done with logs, just checked on Windows 1511, build 14279 (newest Insider build), same troubles.
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/202110711,Cannot send Photos with Telegram 0.9.10 under Windows 10,alexanderwiller,54,118461644,26,202110711,0,196413188,2016-03-27T17:34:44Z,"I just want to confirm this. I already uninstalled the desktop client, removed all temporary files and deleted every single Telegram registry key. After reinstalling the client, the behaviour has not changed.

On rare ocassions, the transfer works, but most of the time the progress indicator just shows a dot spinning around. Sometimes I experience another behaviour: The transfer seems to start, the progress indicator shows some progress, but when the indicator shows a complete circle, it just does not disappear and the image is still not transfered.
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/205255837,Cannot send Photos with Telegram 0.9.10 under Windows 10,andrew2511,54,118461644,27,205255837,0,202110711,2016-04-04T11:31:52Z,"I have the same problem. Can't find a solution, I've also formatted my pc.
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/205376714,Cannot send Photos with Telegram 0.9.10 under Windows 10,andrew2511,54,118461644,28,205376714,0,205255837,2016-04-04T16:26:39Z,"I solved it disabling the function **Large Send Offload** in my ethernet driver settings. Try it!
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/205835504,Cannot send Photos with Telegram 0.9.10 under Windows 10,puraminy,54,118461644,29,205835504,0,205376714,2016-04-05T14:34:15Z,"I have this problem in windows 8.1 and Telegram 0.9.32, I am located in Iran,

@andrew2511  where can I find such an option? please guide exactly where should I go.
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/205839763,Cannot send Photos with Telegram 0.9.10 under Windows 10,andrew2511,54,118461644,30,205839763,0,205835504,2016-04-05T14:46:16Z,"I've a Killer E2200 Ethernet Controller (atheros) on Windows 10, I solved in this way:
- Enter in **Device Manager**: (press Win+R, type _devmgmt.msc_ and hit Enter)
- Select your Network device and go to **Driver** tab then **Advanced**

Set:
- Large Send Offload (IPv4) = **Disabled**
- Large Send Offload v2 (IPv4) = **Disabled**

Then reboot. Good luck :)

![image](https://cloud.githubusercontent.com/assets/395639/14286036/f8cd38ee-fb4d-11e5-85fe-63407de83f71.png)
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/205869757,Cannot send Photos with Telegram 0.9.10 under Windows 10,puraminy,54,118461644,31,205869757,0,205839763,2016-04-05T15:59:28Z,"@andrew2511  thank you, however I use a wireless modem to connect to internet. Yet I can connect with cable. 
But before I try that I just Restart my computer and now can send pictures!

Then sometimes a restart may fix the problem!
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/1321,Larger emoji size in preview,diazbastian,7,118480369,1,118480369,0,0,2015-11-23T21:49:47Z,"Hello, I think the desktop would be nice to have a preview of the emoji in a slightly larger size/resolution.
There are other applications that show the apple emoji with higher resolution and increase in size, increasing the size of the font. Is it now possible in TDesktop?
http://emojipedia.org/apple/

On the other hand, the possibility of changing emoji pack is highly desirable. My favorites are used by Twitter ... maybe others like it used in Google, etc.
Cutegram possible change emoji pack, but is far behind Tdesktop.

http://emojipedia.org/twitter/
http://emojipedia.org/google/

Thanks
",True,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/159077864,Larger emoji size in preview,auchri,7,118480369,2,159077864,0,118480369,2015-11-23T21:55:16Z,"> On the other hand, the possibility of changing emoji pack is highly desirable

No, we want the same emojis at all official clients.
",False,0,CONTRIBUTOR
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/160303592,Larger emoji size in preview,flick1999,7,118480369,3,160303592,0,159077864,2015-11-28T14:24:16Z,"I came here to make this feature request as well. I'd like to be able to hover over a sticker and have a preview image pop up that's much larger. These eyes are getting old, I'm afraid....
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/160751356,Larger emoji size in preview,diazbastian,7,118480369,4,160751356,0,160303592,2015-11-30T20:25:12Z,"@auchri I realized that since the last update Telegram for Android and iOS, there are new emojis that are not supported by TDesktop. I need not create a new report to be closely related.

Thanks
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/160751643,Larger emoji size in preview,telegramdesktop,7,118480369,5,160751643,0,160751356,2015-11-30T20:25:56Z,"@diazbastian Those new emoji will be supported in the next version.
",False,0,COLLABORATOR
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/160751843,Larger emoji size in preview,auchri,7,118480369,6,160751843,0,160751643,2015-11-30T20:26:53Z,"@diazbastian #1196
",False,0,CONTRIBUTOR
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/291058876,Larger emoji size in preview,auchri,7,118480369,7,291058876,0,160751843,2017-04-03T06:29:42Z,See #2804 ,False,0,CONTRIBUTOR
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/793350589,Larger emoji size in preview,github-actions[bot],7,118480369,8,793350589,0,291058876,2021-03-09T04:01:59Z,This issue has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.,False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/1322,Confirmation to send stickers,diazbastian,3,118482104,1,118482104,0,0,2015-11-23T21:58:54Z,"Send wrong stickers is something that happens to me often. With the system of scroll with two fingers it is very easy to make mistakes.

In android, there is a way to see the sticker before sending it (holding down the sticker). In Tdesktop could add a confirmation button on the talk bubble (delete/send) to avoid making mistakes.
",True,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/162224300,Confirmation to send stickers,alirezanet,3,118482104,2,162224300,0,118482104,2015-12-05T17:13:55Z,"bump . i have same problem... :+1: 
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/225766980,Confirmation to send stickers,diazbastian,3,118482104,3,225766980,0,162224300,2016-06-14T02:56:42Z,"I think this issue is solved several versions behind. If you would like to close this report. Thank you.
",False,0,NONE
https://api.github.com/repos/telegramdesktop/tdesktop/issues/comments/794885015,Confirmation to send stickers,github-actions[bot],3,118482104,4,794885015,0,225766980,2021-03-10T05:02:10Z,This issue has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.,False,0,NONE
https://api.github.com/repos/rails/rails/issues/22410,ActiveJob is using the object's old `updated_at` value...,abitdodgy,3,118883615,1,118883615,0,0,2015-11-25T17:14:31Z,"I'm running a job that keeps a snapshot of an object after it has been updated. 

``` ruby
class UpdateDocumentJob < ActiveJob::Base
  def perform(document, changes)
   # Logging for debugging purposes. See screen shot
    puts ""CHANGES: === #{changes}""
    puts ""OBJECT:  === #{document.updated_at}""

    activity = document.activities.create!({
      diff: changes,
      snapshot: document.to_json,
    })

    puts ""SNAPSHOT: === #{activity.snapshot['updated_at']}""
  end
end
```

![active_job](https://cloud.githubusercontent.com/assets/545430/11404064/2a5e942c-9387-11e5-8e5c-0c2a0e5c1e68.jpg)

Here's how the job is being called

``` ruby
class Document < ActiveRecord::Base
  def save_with_activity!(attrs)
    assign_attributes(attrs)
    save!
    UpdateDocumentJob.perform_later(self, previous_changes.to_json)
  end
end
```

Whenever I look at the `snapshot` column, the `updated_at` value shows the old value, from before when the object was updated, and not the new value, from the current update.

I'm not sure what's going on. Perhaps this is something to do with the object becoming committed to the database? In which case how would I solve this? Delay the job sufficiently for the DB transaction to finish?
",True,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/159688861,ActiveJob is using the object's old `updated_at` value...,pixeltrix,3,118883615,2,159688861,0,118883615,2015-11-25T18:02:10Z,"@abitdodgy we keep the issue tracker for reporting bugs/adding code in Rails - for application development support please use one of the support channels like the mailing list, IRC, Stack Overflow, etc, thanks.
",False,0,CONTRIBUTOR
https://api.github.com/repos/rails/rails/issues/comments/159693405,ActiveJob is using the object's old `updated_at` value...,abitdodgy,3,118883615,3,159693405,0,159688861,2015-11-25T18:22:19Z,"@pixeltrix thanks. I'm not asking for support. I'm wondering if this is a bug, or normal behaviour. Can I assume that this is normal behaviour, and that my assumption (that this is to do with the database commit) is correct?
",False,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/159736784,ActiveJob is using the object's old `updated_at` value...,pixeltrix,3,118883615,4,159736784,0,159693405,2015-11-25T21:37:46Z,"@abitdodgy it depends on what the cause is - it maybe that the job is not seeing the updates outside of the transaction but that would only be the case if you're using Resque or Sidekiq. Try queueing the job in an `after_commit` callback to see if that fixes your problem.
",False,0,CONTRIBUTOR
https://api.github.com/repos/rails/rails/issues/22412,db:structure:dump with MySQL includes current timestamp,atsheehan,5,118919271,1,118919271,0,0,2015-11-25T20:33:57Z,"When running `rake db:structure:dump` in an application with MySQL configured, the generated `db/structure.sql` file contains the timestamp for when the dump was completed. Even if the underlying database does not change, running `rake db:structure:dump` will produce a different output each time. Because `db/structure.sql` is often version controlled, this timestamp will generate a lot of noise if each change is committed.

If the `config.active_record.schema_format = :sql` option is set, this command is also run after `rake db:migrate`, updating the `db/structure.sql` file even if no new migrations are run.

A test case has been included at [https://gist.github.com/atsheehan/3477a1659b97741de4ae](https://gist.github.com/atsheehan/3477a1659b97741de4ae). It creates a new MySQL database, performs two structure dumps within a few seconds of each other, and checks if they differ. This test requires MySQL to be installed and running locally.

This behavior of `mysqldump` is also described at [https://bugs.mysql.com/bug.php?id=31077](https://bugs.mysql.com/bug.php?id=31077). It appears that a `--skip-dump-date` flag has been added around 2007 that avoids this issue.

If this sounds like a valid issue, I believe the fix would be to include the `--skip-dump-date` option [here](https://github.com/rails/rails/blob/master/activerecord/lib/active_record/tasks/mysql_database_tasks.rb#L58-L61). Adding an extra flag when calling an external program might break old versions of `mysqldump`, but since the patch to include it was from 2007 I would assume most clients support it by now.
",True,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/159726053,db:structure:dump with MySQL includes current timestamp,atsheehan,5,118919271,2,159726053,0,118919271,2015-11-25T20:39:09Z,"Here's an example of a `git diff` after running `rake db:migrate` without any modifications to the database:

```
diff --git a/db/structure.sql b/db/structure.sql
index cc5f1a1..0e993be 100644
--- a/db/structure.sql
+++ b/db/structure.sql
@@ -1034,6 +1034,6 @@ CREATE TABLE `users` (
 /*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
 /*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;

--- Dump completed on 2015-11-25 13:42:22
+-- Dump completed on 2015-11-25 15:09:07
```
",False,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/164012900,db:structure:dump with MySQL includes current timestamp,rishav,5,118919271,3,164012900,0,159726053,2015-12-11T18:36:57Z,"Seems like a valid issue, can you create a Pull Request ? I can do it if you want me to
",False,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/232252011,db:structure:dump with MySQL includes current timestamp,rails-bot,5,118919271,4,232252011,0,164012900,2016-07-13T04:12:04Z,"This issue has been automatically marked as stale because it has not been commented on for at least
three months.

The resources of the Rails team are limited, and so we are asking for your help.

If you can still reproduce this error on the `5-0-stable` branch or on `master`,
please reply with all of the information you have about it in order to keep the issue open.

Thank you for all your contributions.
",False,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/283510830,db:structure:dump with MySQL includes current timestamp,rails-bot,5,118919271,5,283510830,0,232252011,2017-03-01T23:53:12Z,"This issue has been automatically closed because of inactivity.

If you can still reproduce this error on the `5-0-stable` branch or on `master`,
please reply with all of the information you have about it in order to keep the issue open.

Thank you for all your contributions.
",False,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/352967765,db:structure:dump with MySQL includes current timestamp,datashaman,5,118919271,6,352967765,0,283510830,2017-12-20T05:21:52Z,an observation from the sidelines: that dump date is very useful for resolving merge conflicts (and they happen often with this file during project creation). The schema method deliberately uses a timestamp in the output for the same reason.,False,0,NONE
https://api.github.com/repos/rails/rails/issues/22414,got rid of exsessive code,lakesare,5,118933882,1,118933882,0,0,2015-11-25T22:22:44Z,"unless endpoint or @endpoint are false, they will have the same value table.
",True,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/159744875,got rid of exsessive code,rails-bot,5,118933882,2,159744875,0,118933882,2015-11-25T22:22:46Z,"Thanks for the pull request, and welcome! The Rails team is excited to review your changes, and you should hear from @schneems (or someone else) soon.

If any changes to this PR are deemed necessary, please add them as extra commits. This ensures that the reviewer can see what has changed since they last reviewed the code. Due to the way GitHub handles out-of-date commits, this should also make it reasonably obvious what issues have or haven't been addressed. Large or tricky changes may require several passes of review and changes.

Please see [the contribution instructions](http://edgeguides.rubyonrails.org/contributing_to_ruby_on_rails.html) for more information.
",False,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/159747709,got rid of exsessive code,schneems,5,118933882,3,159747709,0,159744875,2015-11-25T22:41:44Z,"We don't take refactoring pull requests. It screws up git blame. Sorry.
",False,0,MEMBER
https://api.github.com/repos/rails/rails/issues/comments/159773022,got rid of exsessive code,tubbo,5,118933882,4,159773022,0,159747709,2015-11-26T01:19:31Z,"@schneems please update the guide on contributing to reflect this point, if it is indeed true: http://edgeguides.rubyonrails.org/contributing_to_ruby_on_rails.html

The following line reads as though you _can_ submit refactoring pull requests:

> Refactorings and documentation changes generally should not go to the CHANGELOG.
",False,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/159808741,got rid of exsessive code,rafaelfranca,5,118933882,5,159808741,0,159773022,2015-11-26T05:20:00Z,"@tubbo it is there:

> Changes that are cosmetic in nature and do not add anything substantial to the stability, functionality, or testability of Rails will generally not be accepted (read more about our rationales behind this decision).
",False,0,MEMBER
https://api.github.com/repos/rails/rails/issues/comments/159926412,got rid of exsessive code,schneems,5,118933882,6,159926412,0,159808741,2015-11-26T14:22:13Z,"Thanks for the PR even if we aren't merging, it will make another really easy. Check out http://www.docsdoctor.org or http://www.codetriage.com to help find other places to contribute. We want you as a contributor and thankful for your effort
",False,0,MEMBER
https://api.github.com/repos/rails/rails/issues/22415,Add prepared statements support for `Mysql2Adapter`,kamipo,3,118959544,1,118959544,0,0,2015-11-26T02:30:22Z,"Reopen #22352 because mysql2 0.4.2 is released.
",True,0,MEMBER
https://api.github.com/repos/rails/rails/issues/comments/159784931,Add prepared statements support for `Mysql2Adapter`,rails-bot,3,118959544,2,159784931,0,118959544,2015-11-26T02:30:29Z,"r? @matthewd

(@rails-bot has picked a reviewer for you, use r? to override)
",False,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/159976818,Add prepared statements support for `Mysql2Adapter`,sgrif,3,118959544,3,159976818,0,159784931,2015-11-26T18:53:09Z,"@kamipo Looks like this causes an intermittent test failure (possibly order dependent, unsure). I'm going to revert for now, can you look into it? It looks like it might even be a bug in the mysql2 gem. https://travis-ci.org/rails/rails/jobs/93407920
",False,0,CONTRIBUTOR
https://api.github.com/repos/rails/rails/issues/comments/160005823,Add prepared statements support for `Mysql2Adapter`,kamipo,3,118959544,4,160005823,0,159976818,2015-11-26T23:40:36Z,"It seems that this is caused by https://github.com/brianmario/mysql2/issues/694. I'll investigating the cause, thanks!
",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/3636,DDC-2879: Persisting collections with Composite Primary Keys composed of 2 Foreign Keys and one metadata field,doctrinebot,5,120669449,1,120669449,0,0,2013-12-31T17:23:44Z,"Jira issue originally created by user dylanlgs:
# SYNOPSIS

Bug prevents persisting a collection of entities in a join table with a Composite Primary 
Key made up of 2 Foreign Keys and one metadata field. From these mapping instructions:
http://docs.doctrine-project.org/en/latest/tutorials/composite-primary-keys.html#use-case-3-join-table-with-metadata
## ISSUE DETAILS

**SUCCESS:** When FOREIGN KEY 1 is the same across items in a collection to be persisted, and FOREIGN KEY 2 is greater than FOREIGN KEY 2 in any existing PRIMARY KEY, the entity and collection are persisted correctly
***\* Example: GPA ""add val below"" exists and has assessment value `{""grade*point_average_id"":1,""assessment_id"":1,""value"":4}` We will try to add a new assessment value where assessment_id > that of any existing assessment value for GPA ""add val below""
*_*\* Request Payload: `{""name"":""Add Val Below"",""courses"":[],""assessmentValues"":[{""assessment"":1,""value"":4},{""assessment"":3,""value"":2}]}`
***\* Debug Log: `
[2014-01-07 11:48:01] app.INFO: START GRADE*POINT_AVERAGE_REPOSITORY #SAVE [GPA #GET*NAME =ADD VAL BELOW] [] []
[2014-01-07 11:48:01] app.INFO:   BEGIN OUTPUT FOR GRADE POINT AVERAGE Add Val Below - ASSESSMENT VALUE 1 [] []
[2014-01-07 11:48:01] app.INFO:         ASSESSMENT*VALUE #GET_GRADE_POINT_AVERAGE #GET*ID: 1 [] []
[2014-01-07 11:48:01] app.INFO:         GRADE*POINT_AVERAGE #GET*ID: 1 [] []
[2014-01-07 11:48:01] app.INFO:         ASSESSMENT*VALUE #GET_ASSESSMENT #GET*ID: 1 [] []
[2014-01-07 11:48:01] app.INFO:         ASSESSMENT*VALUE #GET*VALUE: 4 [] []
[2014-01-07 11:48:01] app.INFO:         MANAGED? 1 [] []
[2014-01-07 11:48:01] app.INFO:   END OUTPUT FOR GRADE POINT AVERAGE Add Val Below - ASSESSMENT VALUE 2 [] []
[2014-01-07 11:48:01] app.INFO:   BEGIN OUTPUT FOR GRADE POINT AVERAGE Add Val Below - ASSESSMENT VALUE 2 [] []
[2014-01-07 11:48:01] app.INFO:         ASSESSMENT*VALUE #GET_GRADE_POINT_AVERAGE #GET*ID: 1 [] []
[2014-01-07 11:48:01] app.INFO:         GRADE*POINT_AVERAGE #GET*ID: 1 [] []
[2014-01-07 11:48:01] app.INFO:         ASSESSMENT*VALUE #GET_ASSESSMENT #GET*ID: 3 [] []
[2014-01-07 11:48:01] app.INFO:         ASSESSMENT*VALUE #GET*VALUE: 2 [] []
[2014-01-07 11:48:01] app.INFO:         MANAGED?  [] []
[2014-01-07 11:48:01] app.INFO:   END OUTPUT FOR GRADE POINT AVERAGE Add Val Below - ASSESSMENT VALUE 3 [] []
[2014-01-07 11:48:01] app.INFO: END GRADE*POINT_AVERAGE_REPOSITORY #SAVE [GPA #GET*NAME =ADD VAL BELOW] [] []
[2014-01-07 11:48:01] doctrine.DEBUG: ""START TRANSACTION"" [] []
[2014-01-07 11:48:01] doctrine.DEBUG: INSERT INTO gpa*assessment_value (point_value, grade_point_average_id, assessment*id) VALUES (?, ?, ?) {""1"":2,""2"":""1"",""3"":""3""} []
[2014-01-07 11:48:01] doctrine.DEBUG: UPDATE gpa*assessment_value SET point_value = ? WHERE grade_point_average_id = ? AND assessment*id = ? [4,1,1] []
[2014-01-07 11:48:01] doctrine.DEBUG: ""COMMIT"" [] []`

**FAILURE:\* When FOREIGN KEY 1 is the same across items in a collection, and FOREIGN KEY 2 is less than any existing FOREIGN KEY 2, the unit of work tries to INSERT existing entity and does not operate on new entity. *The EntityManager thinks it contains() the new entity, but not the old one** 

***\* Example: GPA ""add val above"" exists and has assessment value `{""assessment"":3,""value"":2}` We will try to add a new assessment value where assessment_id < that of any existing assessment value for GPA ""add val above""

***\* Request Payload: `{""name"":""Add Val Above"",""courses"":[],""assessmentValues"":[{""assessment"":1,""value"":4},{""assessment"":3,""value"":2}]}`

***\* Debug log:

```
[2014-01-07 11:47:09] app.INFO: START GRADE*POINT_AVERAGE_REPOSITORY #SAVE [GPA #GET*NAME =ADD VAL ABOVE] [] []
[2014-01-07 11:47:09] app.INFO:   BEGIN OUTPUT FOR GRADE POINT AVERAGE Add Val Above - ASSESSMENT VALUE 1 [] []
[2014-01-07 11:47:09] app.INFO:         ASSESSMENT*VALUE #GET_GRADE_POINT_AVERAGE #GET*ID: 2 [] []
[2014-01-07 11:47:09] app.INFO:         GRADE*POINT_AVERAGE #GET*ID: 2 [] []
[2014-01-07 11:47:09] app.INFO:         ASSESSMENT*VALUE #GET_ASSESSMENT #GET*ID: 1 [] []
[2014-01-07 11:47:09] app.INFO:         ASSESSMENT*VALUE #GET*VALUE: 4 [] []
[2014-01-07 11:47:09] app.INFO:         MANAGED? 1 [] []
[2014-01-07 11:47:09] app.INFO:   END OUTPUT FOR GRADE POINT AVERAGE Add Val Above - ASSESSMENT VALUE 2 [] []
[2014-01-07 11:47:09] app.INFO:   BEGIN OUTPUT FOR GRADE POINT AVERAGE Add Val Above - ASSESSMENT VALUE 2 [] []
[2014-01-07 11:47:09] app.INFO:         ASSESSMENT*VALUE #GET_GRADE_POINT_AVERAGE #GET*ID: 2 [] []
[2014-01-07 11:47:09] app.INFO:         GRADE*POINT_AVERAGE #GET*ID: 2 [] []
[2014-01-07 11:47:09] app.INFO:         ASSESSMENT*VALUE #GET_ASSESSMENT #GET*ID: 3 [] []
[2014-01-07 11:47:09] app.INFO:         ASSESSMENT*VALUE #GET*VALUE: 2 [] []
[2014-01-07 11:47:09] app.INFO:         MANAGED?  [] []
[2014-01-07 11:47:09] app.INFO:   END OUTPUT FOR GRADE POINT AVERAGE Add Val Above - ASSESSMENT VALUE 3 [] []
[2014-01-07 11:47:09] app.INFO: END GRADE*POINT_AVERAGE_REPOSITORY #SAVE [GPA #GET*NAME =ADD VAL ABOVE] [] []
[2014-01-07 11:47:09] doctrine.DEBUG: ""START TRANSACTION"" [] []
[2014-01-07 11:47:09] doctrine.DEBUG: INSERT INTO gpa*assessment_value (point_value, grade_point_average_id, assessment*id) VALUES (?, ?, ?) {""1"":2,""2"":""2"",""3"":""3""} []
[2014-01-07 11:47:09] doctrine.DEBUG: ""ROLLBACK"" [] []
[2014-01-07 11:47:09] event.DEBUG: Notified event ""kernel.exception"" to listener ""Symfony\Component\Security\Http\Firewall\ExceptionListener::onKernelException"". [] []
[2014-01-07 11:47:09] event.DEBUG: Notified event ""kernel.exception"" to listener ""Symfony\Component\HttpKernel\EventListener\ProfilerListener::onKernelException"". [] []
[2014-01-07 11:47:09] event.DEBUG: Notified event ""kernel.exception"" to listener ""Symfony\Component\HttpKernel\EventListener\ExceptionListener::onKernelException"". [] []
[2014-01-07 11:47:09] request.CRITICAL: Uncaught PHP Exception Doctrine\DBAL\DBALException: ""An exception occurred while executing 'INSERT INTO gpa*assessment_value (point_value, grade_point_average_id, assessment*id) VALUES (?, ?, ?)' with params [2, ""2"", ""3""]:

SQLSTATE[23505]: Unique violation: 7 ERROR:  duplicate key value violates unique constraint ""gpa*assessment_value*pkey""
DETAIL:  Key (grade*point_average_id, assessment_id)=(2, 3) already exists."" at /vagrant/vendor/doctrine/dbal/lib/Doctrine/DBAL/DBALException.php line 47 {""exception"":""[object] (Doctrine\\DBAL\\DBALException: An exception occurred while executing 'INSERT INTO gpa_assessment_value (point_value, grade_point_average_id, assessment_id) VALUES (?, ?, ?)' with params [2, \""2\"", \""3\""]:\n\nSQLSTATE[23505]: Unique violation: 7 ERROR:  duplicate key value violates unique constraint \""gpa_assessment_value_pkey\""\nDETAIL:  Key (grade_point_average_id, assessment_id)=(2, 3) already exists. at /vagrant/vendor/doctrine/dbal/lib/Doctrine/DBAL/DBALException.php:47, PDOException: SQLSTATE[23505]: Unique violation: 7 ERROR:  duplicate key value violates unique constraint \""gpa_assessment_value_pkey\""\nDETAIL:  Key (grade_point_average_id, assessment*id)=(2, 3) already exists. at /vagrant/vendor/doctrine/dbal/lib/Doctrine/DBAL/Statement.php:138)""} []
```

---
## CODE

```
CREATE TABLE assessment
(
    id       bigserial NOT NULL,
    scale_id bigint    NOT NULL,
    title    varchar   NOT NULL,
    passing  boolean   NOT NULL,
    rank     int,

    PRIMARY KEY (id)
);

CREATE TABLE assessment_scale
(
    id   bigserial NOT NULL,
    name varchar   NOT NULL,

    PRIMARY KEY (id)
);

-- ...

CREATE TABLE grade*point*average
(
    id                         bigserial       NOT NULL,
    name                       varchar         NOT NULL,
    additional*credit*allowance numeric(4, 2),

    PRIMARY KEY (id)
);

-- ...

CREATE TABLE gpa*assessment*value
(
    grade*point_average*id bigint        NOT NULL,
    assessment_id          bigint        NOT NULL,
    point_value            numeric(4, 2) NOT NULL,

    PRIMARY KEY (assessment*id, grade_point_average*id),
    FOREIGN KEY (assessment_id) REFERENCES assessment,
    FOREIGN KEY (grade*point_average_id) REFERENCES grade_point*average
);
```

```
<?php
namespace LGSConnect\Model;

use Doctrine\ORM\Mapping\Entity;
use Doctrine\ORM\Mapping\Id;
use Doctrine\ORM\Mapping\GeneratedValue;
use Doctrine\ORM\Mapping\Column;
//...
use Doctrine\Common\Collections\Collection;
use Doctrine\Common\Collections\ArrayCollection;
use LGSConnect\Util\ConstructorArgs;
use LGSConnect\Model\GradePointAverage\AssessmentValue;
// ...

/****
 * @Entity(""LGSConnect\Repository\GradePointAverageRepository"")
 */
class GradePointAverage
{
    // GradePointAverage Model (owning side): a tool for evaluating a student's performance 
    // by dividing the total points earned by total credits attempted.

    use ConstructorArgs;

    /****
     * @Id
     * @GeneratedValue
     * @Column(type=""bigint"")
     *
     * @var int
     */
    private $id;

    // ...

    /****
     * @OneToMany(targetEntity=""LGSConnect\Model\GradePointAverage\AssessmentValue"", mappedBy=""gradePointAverage"", cascade=""persist"")
     *
     * @var Collection
     */
    private $assessmentValues;

    // ...

    /****
     * @param array $args
     */
    public function **construct(array $args = [])
    {
        $this->assessmentValues = new ArrayCollection;
        // ...
        $this->handleArgs($args);
    }

    // ...

    /****
     * @return Collection
     */
    public function getAssessmentValues()
    {
        return $this->assessmentValues;
    }

    /****
     * @param ArrayCollection $assessmentValues
     */
    public function setAssessmentValues(ArrayCollection $assessmentValues)
    {
        $this->assessmentValues = $assessmentValues;
    }

    /****
     * @param AssessmentValue $assessmentValue
     */
    public function addAssessmentValue(AssessmentValue $assessmentValue)
    {
        $this->assessmentValues->add($assessmentValue);
    }

    /****
     * @param AssessmentValue $assessmentValue
     */
    public function removeAssessmentValue(AssessmentValue $assessmentValue)
    {
        $this->assessmentValues->removeElement($assessmentValue);
    }

    // ...
}
```

```
<?php
namespace LGSConnect\Model\GradePointAverage;

use Doctrine\ORM\Mapping\Entity;
use Doctrine\ORM\Mapping\Table;
use Doctrine\ORM\Mapping\Column;
use Doctrine\ORM\Mapping\Id;
use Doctrine\ORM\Mapping\GeneratedValue;
use Doctrine\ORM\Mapping\ManyToOne;
use Doctrine\ORM\Mapping\JoinColumn;
use LGSConnect\Model\GradePointAverage;
use LGSConnect\Model\Assessment;
use LGSConnect\Util\ConstructorArgs;

/****
 * @Entity(""LGSConnect\Repository\GradePointAverage\AssessmentValueRepository"")
 * @Table(""gpa*assessment*value"")
 */
class AssessmentValue
{
    // AssessmentValue Model (inverse side): a number of points assigned 
    // to an Assessment by a Grade Point Average

    use ConstructorArgs;

    /****
     * @Id
     * @ManyToOne(targetEntity=""LGSConnect\Model\GradePointAverage"")
     */
    private $gradePointAverage;

    /****
     * @Id
     * @ManyToOne(targetEntity=""LGSConnect\Model\Assessment"")
     */
    private $assessment;

    /****
     * @Column(""point_value"")
     *
     * @var float
     */
    private $value;

    /****
     * @param array $args
     */
    public function **construct(array $args = [])
    {
        $this->handleArgs($args);
    }

    /****
     * @return GradePointAverage
     */
    public function getGradePointAverage()
    {
        return $this->gradePointAverage;
    }

    /****
     * @param GradePointAverage $gradePointAverage
     */
    public function setGradePointAverage(GradePointAverage $gradePointAverage)
    {
        $this->gradePointAverage = $gradePointAverage;
    }

    /****
     * @return Assessment
     */
    public function getAssessment()
    {
        return $this->assessment;
    }

    /****
     * @param Assessment $assessment
     */
    public function setAssessment(Assessment $assessment)
    {
        $this->assessment = $assessment;
    }

    /****
     * @return float
     */
    public function getValue()
    {
        return $this->value;
    }

    /****
     * @param float $value
     */
    public function setValue($value)
    {
        $this->value = $value;
    }

    /****
     * @return AssessmentScale
     */
    public function getAssessmentScale()
    {
        return $this->assessment->getScale();
    }
}
```

```
<?php
namespace LGSConnect\Model;

use Doctrine\ORM\Mapping\Entity;
use Doctrine\ORM\Mapping\Id;
use Doctrine\ORM\Mapping\GeneratedValue;
use Doctrine\ORM\Mapping\Column;
use Doctrine\ORM\Mapping\ManyToOne;
use LGSConnect\Model\Assessment\Scale;
use LGSConnect\Util\ConstructorArgs;

/****
 * @Entity(""LGSConnect\Repository\AssessmentRepository"")
 */
class Assessment
{
    // Assessment (related, but unmapped): A ""grade"" assigned to a student 
    // for attending a course section

    use ConstructorArgs;

    /****
     * @Id
     * @GeneratedValue
     * @Column(type=""bigint"")
     *
     * @var int
     */
    private $id;

    // ...

    /****
     * @param array $args
     */
    public function **construct(array $args = [])
    {
        $this->handleArgs($args);
    }

    /****
     * @return int
     */
    public function getId()
    {
        return $this->id;
    }

    // ...
}
```

```
<?php
namespace LGSConnect\Repository;

use Doctrine\ORM\EntityRepository;
// ...
use LGSConnect\Model\GradePointAverage;

class GradePointAverageRepository extends BaseRepository implements GradePointAverageRepositoryInterface
{
    // ...

    /****
     * @param GradePointAverage $gradePointAverage
     */
    public function save(GradePointAverage $gradePointAverage)
    {
        $this->getEntityManager()->persist($gradePointAverage);
        $this->getEntityManager()->flush();
    }
}
```

```
<?php
namespace LGSConnect\Repository\GradePointAverage;

use Doctrine\ORM\EntityRepository;
use LGSConnect\Model\GradePointAverage\AssessmentValue;

class AssessmentValueRepository extends EntityRepository
{
    /****
     * @param AssessmentValue $assessmentValue
     */
    public function save(AssessmentValue $assessmentValue)
    {
        $this->getEntityManager()->persist($assessmentValue);
        $this->getEntityManager()->flush();
    }
}
```

```
<?php
namespace LGSConnect\Manager;

use InvalidArgumentException;
use Symfony\Component\Validator\ValidatorInterface;
use JMS\DiExtraBundle\Annotation\Service;
use JMS\DiExtraBundle\Annotation\InjectParams;
use JMS\SecurityExtraBundle\Annotation\PreAuthorize;
use Knp\Component\Pager\Pagination\PaginationInterface;
use LGSConnect\Repository\GradePointAverageRepository;
use LGSConnect\PaginationFactory\GradePointAveragePaginationFactoryInterface;
use LGSConnect\Model\GradePointAverage;

/****
 * @Service(""grade*point_average*manager"")
 */
class GradePointAverageManager
{
    /****
     * @var GradePointAverageRepository
     */
    private $gradePointAverageRepository;

    /****
     * @var GradePointAveragePaginationFactoryInterface
     */
    private $gradePointAveragePaginationFactory;

    /****
     * @var ValidatorInterface
     */
    private $validator;

    /****
     * @InjectParams
     *
     * @param GradePointAverageRepository $gradePointAverageRepository
     * @param GradePointAveragePaginationFactoryInterface $gradePointAveragePaginationFactory
     * @param ValidatorInterface $validator
     */
    public function **construct(
        GradePointAverageRepository $gradePointAverageRepository,
        GradePointAveragePaginationFactoryInterface $gradePointAveragePaginationFactory,
        ValidatorInterface $validator
    )
    {
        $this->gradePointAverageRepository = $gradePointAverageRepository;
        $this->gradePointAveragePaginationFactory = $gradePointAveragePaginationFactory;
        $this->validator = $validator;
    }

    /****
     * @PreAuthorize(""isAllowedToManageTheGradePointAverage(#gradePointAverage)"")
     * @param GradePointAverage $gradePointAverage
     * @throws InvalidArgumentException
     */
    public function save(GradePointAverage $gradePointAverage)
    {
        $violationList = $this->validator->validate($gradePointAverage);
        if ($violationList->count()) {
            throw new InvalidArgumentException;
        }

        $this->gradePointAverageRepository->save($gradePointAverage);
    }
}
```

```
<?php
namespace LGSConnect\Controller;

use Symfony\Component\HttpFoundation\Request;
use Symfony\Component\HttpFoundation\Response;
use Symfony\Component\HttpKernel\Log\LoggerInterface;
use Sensio\Bundle\FrameworkExtraBundle\Configuration\Route;
use Sensio\Bundle\FrameworkExtraBundle\Configuration\Method;
use Doctrine\Common\Collections\ArrayCollection;
use FOS\RestBundle\View\View;
use JMS\DiExtraBundle\Annotation\Service;
use JMS\DiExtraBundle\Annotation\InjectParams;
use JMS\SecurityExtraBundle\Annotation\PreAuthorize;
use Knp\Component\Pager\Pagination\PaginationInterface;
use LGSConnect\Manager\GradePointAverageManager;
use LGSConnect\Model\GradePointAverage;
use LGSConnect\Model\GradePointAverage\AssessmentValue;

/****
 * @Service(""grade*point_average*controller"", parent=""lgs.controller.abstract"")
 * @Route(""/gpa"", service=""grade*point_average*controller"")
 */
class GradePointAverageController extends BaseController
{
    /****
     * @var GradePointAverageManager
     */
    private $gradePointAverageManager;

    private $logger;

    /****
     * @InjectParams
     *
     * @param GradePointAverageManager $gradePointAverageManager
     * @param LoggerInterface $logger
     */
    public function **construct(GradePointAverageManager $gradePointAverageManager, LoggerInterface $logger)
    {
        $this->gradePointAverageManager = $gradePointAverageManager;
        $this->logger = $logger;
    }

    // ...

    /****
     * @Route(""/{id}"", name=""gpa.edit"", requirements={""id"" = ""\d+""})
     * @Method(""PUT"")
     *
     * @param Request $request
     * @param GradePointAverage $gpa
     * @return View
     */
    public function editAction(Request $request, GradePointAverage $gpa)
    {
        $form = $this->formFactory->createNamed(null, 'gpa', $gpa, [
            'method' => 'PUT',
        ]);
        $form->handleRequest($request);

        foreach ($gpa->getAssessmentValues() as $av) {
            $this->logger->info('GPA ID PREVALIDATE IN CONTROLLER:'.$gpa->getId());
            $this->logger->info('PREVALIDATE IN CONTROLLER ASSESSMENT VAL ASSESSMENT ID:'.$av->getAssessment()->getId());
            $this->logger->info('PREVALIDATE IN CONTROLLER ASSESSMENT VAL POINTS:'.$av->getValue());
        }

        /*
        // try reversing the order of the collection to see if that helps
        $assessmentVals = $gpa->getAssessmentValues()->toArray();
        $reversed = array_reverse($assessmentVals);
        $reversedColl = new ArrayCollection($reversed);
        $gpa->setAssessmentValues($reversedColl);
        */

        if ($form->isValid()) {
            foreach ($gpa->getAssessmentValues() as $av) {
                $this->logger->info('GPA ID PRESAVE IN CONTROLLER:'.$gpa->getId());
                $this->logger->info('PRESAVE IN CONTROLLER ASSESSMENT VAL ASSESSMENT ID:'.$av->getAssessment()->getId());
                $this->logger->info('PRESAVE IN CONTROLLER ASSESSMENT VAL POINTS:'.$av->getValue());
            }
            $this->gradePointAverageManager->save($gpa);

            return new View($gpa, 204);
        }

        return new View($form);
    }

    // ...
}
```

```
<?php
namespace LGSConnect\Form\Type;

use Symfony\Component\Form\AbstractType;
use Symfony\Component\Form\FormBuilderInterface;
use JMS\DiExtraBundle\Annotation\FormType;

/****
 * @FormType
 */
class GradePointAverageType extends AbstractType
{
    /****
     * @param FormBuilderInterface $builder
     * @param array $options
     */
    public function buildForm(FormBuilderInterface $builder, array $options)
    {
        $builder
            ->add('name')
            ->add('courses', 'entity', [
                'class' => 'Model:Course',
                'multiple' => true
            ])
            ->add('assessmentValues', 'collection', [
                'type' => 'gpa*assessment*value',
                'allow_add' => true,
                'by_reference' => false,
            ])
        ;
    }

    /****
     * @return string
     */
    public function getName()
    {
        return 'gpa';
    }
}
```

```
<?php
namespace LGSConnect\Form\Type\GradePointAverage;

use Symfony\Component\Form\AbstractType;
use Symfony\Component\Form\FormBuilderInterface;
use JMS\DiExtraBundle\Annotation\FormType;
use Symfony\Component\OptionsResolver\OptionsResolverInterface;

/****
 * @FormType(""gpa*assessment*value"")
 */
class AssessmentValueType extends AbstractType
{
    /****
     * @param FormBuilderInterface $builder
     * @param array $options
     */
    public function buildForm(FormBuilderInterface $builder, array $options)
    {
        $builder
            ->add('assessment', 'entity', [
                'class' => 'Model:Assessment',
            ])
            ->add('value', 'number', [
                'precision' => 2,
            ])
        ;
    }

    /****
     * @param OptionsResolverInterface $resolver
     */
    public function setDefaultOptions(OptionsResolverInterface $resolver)
    {
        $resolver->setDefaults([
            'data_class' => 'LGSConnect\Model\GradePointAverage\AssessmentValue',
        ]);
    }

    /****
     * @return string
     */
    public function getName()
    {
        return 'gpa*assessment*value';
    }
}
```
",True,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/162364570,DDC-2879: Persisting collections with Composite Primary Keys composed of 2 Foreign Keys and one metadata field,doctrinebot,5,120669449,2,162364570,0,120669449,2015-01-23T18:20:28Z,"Comment created by kozlice:

Any update on this issue? We've got same problem in our project (PostgreSQL 9.4, Doctrine 2.4.7)
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/162364571,DDC-2879: Persisting collections with Composite Primary Keys composed of 2 Foreign Keys and one metadata field,doctrinebot,5,120669449,3,162364571,0,162364570,2015-01-24T07:05:25Z,"Comment created by @ocramius:

Removed the ""feedback required"" flag.

[~kozlice] if there is no ticket update, well... then there is no actual update.

Somewhat related to https://github.com/doctrine/doctrine2/pull/1113

I suggest getting your hands dirty and fixing it yourself if it affects you.
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/162364572,DDC-2879: Persisting collections with Composite Primary Keys composed of 2 Foreign Keys and one metadata field,doctrinebot,5,120669449,4,162364572,0,162364571,2015-01-24T08:50:20Z,"Comment created by @doctrinebot:

A related Github Pull-Request [GH-1113] was labeled:
https://github.com/doctrine/doctrine2/pull/1113
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/162364574,DDC-2879: Persisting collections with Composite Primary Keys composed of 2 Foreign Keys and one metadata field,doctrinebot,5,120669449,5,162364574,0,162364572,2015-01-24T08:50:21Z,"Comment created by @doctrinebot:

A related Github Pull-Request [GH-1113] was labeled:
https://github.com/doctrine/doctrine2/pull/1113
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/162364575,DDC-2879: Persisting collections with Composite Primary Keys composed of 2 Foreign Keys and one metadata field,doctrinebot,5,120669449,6,162364575,0,162364574,2015-02-16T01:18:10Z,"Comment created by @doctrinebot:

A related Github Pull-Request [GH-1113] was closed:
https://github.com/doctrine/doctrine2/pull/1113
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/3638,DDC-2880: [GH-894] Fix typos - QueryBuilder,doctrinebot,3,120669453,1,120669453,0,0,2014-01-03T16:29:11Z,"Jira issue originally created by user @doctrinebot:

This issue is created automatically through a Github pull request on behalf of piotrantosik:

Url: https://github.com/doctrine/doctrine2/pull/894

Message:
",True,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/162364577,DDC-2880: [GH-894] Fix typos - QueryBuilder,doctrinebot,3,120669453,2,162364577,0,120669453,2014-01-03T17:23:56Z,"Comment created by @doctrinebot:

A related Github Pull-Request [GH-894] was closed:
https://github.com/doctrine/doctrine2/pull/894
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/162364578,DDC-2880: [GH-894] Fix typos - QueryBuilder,doctrinebot,3,120669453,3,162364578,0,162364577,2014-01-03T17:24:12Z,"Comment created by @deeky666:

Fixed in commit: https://github.com/doctrine/doctrine2/commit/5828e4c67c08f564dccc4dcdd6277080a164212f
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/162364579,DDC-2880: [GH-894] Fix typos - QueryBuilder,doctrinebot,3,120669453,4,162364579,0,162364578,2014-01-03T17:24:12Z,"Issue was closed with resolution ""Fixed""
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/3639,DDC-2881: [GH-895] Fix for no dot on Class Names,doctrinebot,3,120669455,1,120669455,0,0,2014-01-04T15:09:59Z,"Jira issue originally created by user @doctrinebot:

This issue is created automatically through a Github pull request on behalf of sinner:

Url: https://github.com/doctrine/doctrine2/pull/895

Message:

If you work with PostgreSQL Schemas, You should filter the names of table to generate Correct name for PHP Classes. This way allow not write dots (.) as part of the Class Name.

Additionally, there is a variable ($schema) that must be contained in the class ""Doctrine\DBAL\Schema\Table"" on an $schema possible property but this is not available. (recomended)
",True,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/162364580,DDC-2881: [GH-895] Fix for no dot on Class Names,doctrinebot,3,120669455,2,162364580,0,120669455,2014-01-04T15:09:59Z,"- is duplicated by [DDC-3384: [GH-1180] Fix for no dot on Class Names](http://www.doctrine-project.org/jira/browse/DDC-3384)
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/162364581,DDC-2881: [GH-895] Fix for no dot on Class Names,doctrinebot,3,120669455,3,162364581,0,162364580,2015-01-14T20:07:22Z,"Comment created by @doctrinebot:

A related Github Pull-Request [GH-895] was closed:
https://github.com/doctrine/doctrine2/pull/895
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/162364582,DDC-2881: [GH-895] Fix for no dot on Class Names,doctrinebot,3,120669455,4,162364582,0,162364581,2015-01-14T20:09:19Z,"Issue was closed with resolution ""Incomplete""
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/3640,DDC-2882: Second Level Cache and DELETE/UPDATE DQL queries,doctrinebot,3,120669456,1,120669456,0,0,2014-01-04T17:26:32Z,"Jira issue originally created by user @beberlei:

How do they interact?
",True,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/162364583,DDC-2882: Second Level Cache and DELETE/UPDATE DQL queries,doctrinebot,3,120669456,2,162364583,0,120669456,2014-01-04T18:08:28Z,"Comment created by @FabioBatSilva:

Have you seem the docs for [delete/update queries](http://docs.doctrine-project.org/projects/doctrine-orm/en/latest/reference/second-level-cache.html#delete-update-queries) ?

Please let me know if you want me to document something else...
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/162364584,DDC-2882: Second Level Cache and DELETE/UPDATE DQL queries,doctrinebot,3,120669456,3,162364584,0,162364583,2014-01-04T18:51:06Z,"Comment created by @beberlei:

You have thought of everything :-) Super
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/162364585,DDC-2882: Second Level Cache and DELETE/UPDATE DQL queries,doctrinebot,3,120669456,4,162364585,0,162364584,2014-01-04T18:51:06Z,"Issue was closed with resolution ""Invalid""
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/4555,DDC-3719: Criteria won't work on non-owning side of many to many collection,doctrinebot,3,120671143,1,120671143,0,0,2015-04-29T18:43:29Z,"Jira issue originally created by user baileylo:

I received the following error when trying to call _matching_ on a ManyToMany relationship from the non-owning side.

{quote}
ErrorException in ManyToManyPersister.php line 234: Undefined index: relationToSourceKeyColumns
{quote}

_ManyToManyPersister::loadCriteria_ relies on the _relationToSourceKeyColumns_ data from the mapping data. This value is set in ClassMetadataInfo::_validateAndCompleteManyToManyMapping, but it's only set on the owning side of the relationship.
",True,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/162368491,DDC-3719: Criteria won't work on non-owning side of many to many collection,doctrinebot,3,120671143,2,162368491,0,120671143,2015-04-29T18:43:29Z,"- is referenced by [DDC-3723: [GH-1399] Fix for DDC-3719.](http://www.doctrine-project.org/jira/browse/DDC-3723)
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/270645586,DDC-3719: Criteria won't work on non-owning side of many to many collection,boesing,3,120671143,3,270645586,0,162368491,2017-01-05T13:37:32Z,"Since PR #5638 was merged, when will this fix merged into 2.5 branch or will this be part of 2.6?
I am expiriencing this aswell and would love to use this fix.

Never mind, got the milestone 2.6, even if I am wondering why bugfixes are not merged into current branches.",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/270768980,DDC-3719: Criteria won't work on non-owning side of many to many collection,Ocramius,3,120671143,4,270768980,0,270645586,2017-01-05T21:55:51Z,@boesing it's up to the merger to decide whether a fix is worth backporting or not.,False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/4556,DDC-372: Improve documentation of doctrine command line tasks,doctrinebot,5,120671144,1,120671144,0,0,2010-02-25T05:16:30Z,"Jira issue originally created by user giorgiosironi:

It was somewhat difficult to get the doctrine.php orm:schema-tool to run because it was not clear where and how to define configuration. So I am going to expand a bit the manual in this chapter.
",True,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/162368492,DDC-372: Improve documentation of doctrine command line tasks,doctrinebot,5,120671144,2,162368492,0,120671144,2010-02-25T05:17:56Z,"Comment created by giorgiosironi:

Expansion of the manual chapter on tools.
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/162368493,DDC-372: Improve documentation of doctrine command line tasks,doctrinebot,5,120671144,3,162368493,0,162368492,2010-02-27T13:45:27Z,"Comment created by romanb:

Patch looks good to me.
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/162368494,DDC-372: Improve documentation of doctrine command line tasks,doctrinebot,5,120671144,4,162368494,0,162368493,2010-03-02T21:03:00Z,"Comment created by @guilhermeblanco:

In r7302 this issue was fixed. Thanks for the patch!
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/162368495,DDC-372: Improve documentation of doctrine command line tasks,doctrinebot,5,120671144,5,162368495,0,162368494,2010-03-02T21:03:00Z,"Issue was closed with resolution ""Fixed""
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/164286949,DDC-372: Improve documentation of doctrine command line tasks,doctrinebot,5,120671144,6,164286949,0,162368495,2015-12-13T18:44:09Z,"Imported 1 attachments from Jira into https://gist.github.com/6994899ecf18cf5f368f
- [10391_ddc-372.patch](https://gist.github.com/6994899ecf18cf5f368f#file-10391_ddc-372-patch)
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/4560,DDC-3723: [GH-1399] Fix for DDC-3719.,doctrinebot,4,120671151,1,120671151,0,0,2015-05-03T17:43:22Z,"Jira issue originally created by user @doctrinebot:

This issue is created automatically through a Github pull request on behalf of boskee:

Url: https://github.com/doctrine/doctrine2/pull/1399

Message:

Switch to relationToTargetKeyColumns when matching non-owning side with Criteria. Fixes [DDC-3719](http://www.doctrine-project.org/jira/browse/DDC-3719).
",True,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/162368504,DDC-3723: [GH-1399] Fix for DDC-3719.,doctrinebot,4,120671151,2,162368504,0,120671151,2015-05-03T17:43:22Z,"- relates to [DDC-3719: Criteria won't work on non-owning side of many to many collection](http://www.doctrine-project.org/jira/browse/DDC-3719)
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/162368505,DDC-3723: [GH-1399] Fix for DDC-3719.,doctrinebot,4,120671151,3,162368505,0,162368504,2015-07-16T20:07:20Z,"Comment created by @doctrinebot:

A related Github Pull-Request [GH-1399] was labeled:
https://github.com/doctrine/doctrine2/pull/1399
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/162368506,DDC-3723: [GH-1399] Fix for DDC-3719.,doctrinebot,4,120671151,4,162368506,0,162368505,2015-08-25T16:32:29Z,"Comment created by davidkmenta:

Hi!

Can anybody please resolve this issue? I am experiencing same problem :-(
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/203328225,DDC-3723: [GH-1399] Fix for DDC-3719.,wwsh,4,120671151,5,203328225,0,162368506,2016-03-30T08:51:28Z,"Hello. Any changes on that? It looks like it's crashing the latest Doctrine...
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/4562,DDC-3725: [GH-1400] pgsql and mysqli are supported by HHVM,doctrinebot,4,120671153,1,120671153,0,0,2015-05-04T23:25:29Z,"Jira issue originally created by user @doctrinebot:

This issue is created automatically through a Github pull request on behalf of photodude:

Url: https://github.com/doctrine/doctrine2/pull/1400

Message:
- reference to [Known compatible extensions for HHVM](http://docs.hhvm.com/manual/en/extensions.alphabetical.php)
",True,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/162368508,DDC-3725: [GH-1400] pgsql and mysqli are supported by HHVM,doctrinebot,4,120671153,2,162368508,0,120671153,2015-07-16T20:08:05Z,"Comment created by @doctrinebot:

A related Github Pull-Request [GH-1400] was assigned:
https://github.com/doctrine/doctrine2/pull/1400
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/162368509,DDC-3725: [GH-1400] pgsql and mysqli are supported by HHVM,doctrinebot,4,120671153,3,162368509,0,162368508,2015-07-16T20:08:10Z,"Comment created by @doctrinebot:

A related Github Pull-Request [GH-1400] was labeled:
https://github.com/doctrine/doctrine2/pull/1400
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/162368510,DDC-3725: [GH-1400] pgsql and mysqli are supported by HHVM,doctrinebot,4,120671153,4,162368510,0,162368509,2015-07-16T20:08:41Z,"Comment created by @doctrinebot:

A related Github Pull-Request [GH-1400] was merged:
https://github.com/doctrine/doctrine2/pull/1400
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/162368511,DDC-3725: [GH-1400] pgsql and mysqli are supported by HHVM,doctrinebot,4,120671153,5,162368511,0,162368510,2015-07-16T20:09:35Z,"Issue was closed with resolution ""Fixed""
",False,0,NONE
https://api.github.com/repos/composer/composer/issues/4732,Add explicit possibility to selectively replace vendor classes,malkusch,8,123798414,1,123798414,0,0,2015-12-24T12:21:22Z,"Sometimes an upstream class in vendor is not extensible enough with conventional language constructs (e.g. it's `final`, has no suitable extension point or simply an existing bug won't be fixed in that version stream anymore). In such case only replacing that offending class with an own implementation is viable.

Currently this is possible because composer's class loader prefers `PSR-4` over `PSR-0`. So if the vendor package uses `PSR-0` you could simply provide a replacement by adding a `PSR-4` path to the new class. However this is an implicit implementation detail of composer which is only available by reading the code of the private method in [`ClassLoader::findFileWithExtension()`](https://github.com/composer/composer/blob/1.0.0-alpha11/src/Composer/Autoload/ClassLoader.php#L344) and could change with any release.

Composer as the central authority for loading classes brings the great opportunity to replace selectively vendor classes completely. Let's specify an explicit mechanism to define a sequence of class paths.

The detailed specification should come with this discussion. For a starter we could discuss a simple `overwrite` field to the composer.json schema which would accept the same fields as `autoload` but has a higher priority in the autoloading process. Or we can target an extensible and well defined class loader hierarchy as we have in Java.
",True,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/167323017,Add explicit possibility to selectively replace vendor classes,alcohol,8,123798414,2,167323017,0,123798414,2015-12-26T13:04:11Z,"You've never heard of interfaces? Wrappers? Adapters?

There is zero need to selectively replace an existing class.
",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/167436417,Add explicit possibility to selectively replace vendor classes,malkusch,8,123798414,3,167436417,0,167323017,2015-12-27T19:08:13Z,"> There is zero need to selectively replace an existing class.

I can understand your reluctance and I would also not promote that feature highly. However I disagree with zero need. Imagine you would depend on a third party library which you want to behave slightly differently (e.g. you want to log a message). Sometimes the author didn't provide extension points which would enable this. All your friendly questions will not help in this case, as the offending class might be final or is instantiated as an implementation detail.

Forking and patching the class in the fork is a viable option, but then again why do I need to fork in the first place, if technically replacing the offending class is possible?
",False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/167437595,Add explicit possibility to selectively replace vendor classes,staabm,8,123798414,4,167437595,0,167436417,2015-12-27T19:38:16Z,"@malkusch https://github.com/krakjoe/uopz is what you are after.

Allow this kind of monkey patching at composer level sounds like a can of worms to me, which should better stay closed. 
",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/167516609,Add explicit possibility to selectively replace vendor classes,alcohol,8,123798414,5,167516609,0,167437595,2015-12-28T08:52:05Z,"@malkusch 

> Sometimes the author didn't provide extension points which would enable this.

There is **always** a way to do this.
",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/167642790,Add explicit possibility to selectively replace vendor classes,malkusch,8,123798414,6,167642790,0,167516609,2015-12-28T19:59:15Z,"> uopz is what you are after.

Thank you for that suggestion. I'm aware of PHP extensions which would do the job (e.g. runkit to name a further one). This proposal is specifically targeted to use plain PHP's autoload mechanism for most portability.

Well, I can see that until now there's no support for this idea. I'm really Sorry for not coming up with any new use cases, but elaborating on the existing ones:

## Mocks for final classes

Surprisingly I see `final` very rarely in PHP land. So it might happen that it never occurred to you. But it is a very valid decision to design classes explicitly without inheritance in mind.  Now consider the case that you write a class which depends on such a third party final class. You could now simply instantiate that class and wire up all it's dependencies. But depending on the complexity of the object graph, the intention of your test might get easily lost in a jungle of instantiation code.

## No suitable extension point

This is actually more a generalization of the `final` argument. Final is not the only way to prevent extension. Consider a class which creates some helper classes with `new`. This is absolutely valid as clients shouldn't care about such implementation details. Eventually in reality it turns out that we specifically need logging somewhere in such an instantiated class. As we don't control instantiation we cannot inject a modified derivation.

## Won't be fixed

Let me present my current use case: I'm the author of [php-mock](https://github.com/php-mock/php-mock) which is a mocking tool targeted at PHP's built-in functions. As I don't want to pollute the cognitive load of developers I do offer integrations for well known existing frameworks. One of them will be [php-mock-prophecy](https://github.com/php-mock/php-mock-prophecy). However there's one offending line of code in upstream which prevents me from implementing prophecies for built-ins which use pass-by-reference (e.g. `exec()`). This can only be fixed in upstream, however the [current discussion](https://github.com/phpspec/prophecy/issues/225) reveals that upstream considers prophecies for pass-by-reference as a design smell and won't support that. This is a very valid opinion for their use case. But as I'm targeting prophecies for PHP built-ins the existence of pass-by-reference is a hard fact. A very experimental [monkey patch](https://github.com/php-mock/php-mock-prophecy/commit/c9cd844fcf4a364d021817acaea5fc031abf7e86#diff-b5d0ee8c97c7abd7e3fa29b9a27d1780) enabled me to provide the full functionality.
",False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/167644690,Add explicit possibility to selectively replace vendor classes,alcohol,8,123798414,7,167644690,0,167642790,2015-12-28T20:13:24Z,"Well, technically I guess this can already be done. If Composer detects a duplicate class (namespace+classname), it will only load one of the available choices. If you simply make sure your class is detected before the one from the other library, you should be good to go. Not sure how you can make sure of that though... :d
",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/169898157,Add explicit possibility to selectively replace vendor classes,hackel,8,123798414,8,169898157,0,167644690,2016-01-08T05:10:18Z,"I've been trying to make this work as well.  I thought that Composer loaded dependencies in order: classpath, psr-0, psr-4, but recently (with a composer update?) I started getting ""Ambiguous class resolution"" warnings, and the vendor class (psr-4) was getting loaded instead of my class (defined in classpath).  I think we just need some consistency here.

My particular use-case is that the vendor library I'm using calls ""new Someclass"" instead of injecting it, and that class has a critical error.  I would have to overload so many different classes in the library to get it to work, that I might as well just maintain my own fork.  I realise this isn't the best approach, but sometimes we just need to move faster than upstream and maintaining a ton of independent forks is an unnecessary nuisance when it's something this simple.

Edit: I was able to solve my particular case by excluding the vendor class, adding it to autoload.exclude-from-class-map.
",False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/186834692,Add explicit possibility to selectively replace vendor classes,Seldaek,8,123798414,9,186834692,0,169898157,2016-02-21T14:52:24Z,"AFAIK, if your package defines a psr-0 or psr-4 autoload rule that is either more specific or just clashes with a dependency's rule, the root package's rule will be loaded first and hence you can override classes easily that way.
",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/4733,Composer uses non-ssl url for Packagist,atheken,5,123816536,1,123816536,0,0,2015-12-24T15:56:04Z,"On OS X, El Capitan. Composer was installed via homebrew-php.

Result of `Composer -V` is `Composer version 1.0.0-alpha11`

Running a require for a Packagist package:

`composer require guzzle/guzzle`

Results in an error:

``` bash
The 'http://packagist.org/p/provider-latest%24ff1218e3af7e0f57eb0143c2fc5110b458f3c72d3ecab327f4fe697410d17019.json' URL could not be accessed: HTTP/1.1 400 Bad Request

http://packagist.org could not be fully loaded, package information was loaded from the local cache and may be out of date
```

Forcing the packagist url to use SSL resolves the issue:

`composer config repo.packagist composer https://packagist.org`
",True,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/167130664,Composer uses non-ssl url for Packagist,atheken,5,123816536,2,167130664,0,123816536,2015-12-24T15:56:28Z,"Here's a verbose log for this:

`test-composer  composer require guzzle/guzzle -vvv`

``` bash
Reading ./composer.json
Loading config file ./composer.json
Executing command (/Users/atheken/TempCode/test-composer): git describe --exact-match --tags
Executing command (/Users/atheken/TempCode/test-composer): git branch --no-color --no-abbrev -v
Executing command (/Users/atheken/TempCode/test-composer): hg branch
Executing command (/Users/atheken/TempCode/test-composer): svn info --xml
Failed to initialize global composer: Composer could not find the config file: /Users/atheken/.composer/composer.json
To initialize a project, please create a composer.json file as described in the https://getcomposer.org/ ""Getting Started"" section
Downloading https://packagist.org/packages.json
Writing /Users/atheken/.composer/cache/repo/https---packagist.org/packages.json into cache
Reading /Users/atheken/.composer/cache/repo/https---packagist.org/p-provider-2013.json from cache
Reading /Users/atheken/.composer/cache/repo/https---packagist.org/p-provider-2014.json from cache
Reading /Users/atheken/.composer/cache/repo/https---packagist.org/p-provider-2015-01.json from cache
Reading /Users/atheken/.composer/cache/repo/https---packagist.org/p-provider-2015-04.json from cache
Reading /Users/atheken/.composer/cache/repo/https---packagist.org/p-provider-2015-07.json from cache
Reading /Users/atheken/.composer/cache/repo/https---packagist.org/p-provider-2015-10.json from cache
Reading /Users/atheken/.composer/cache/repo/https---packagist.org/p-provider-archived.json from cache
Downloading http://packagist.org/p/provider-latest%2478cc4211348e7338a095ef33d5bae723328f7864f4b162f20762d0f312418b42.json
Downloading http://packagist.org/p/provider-latest%2478cc4211348e7338a095ef33d5bae723328f7864f4b162f20762d0f312418b42.json
Downloading http://packagist.org/p/provider-latest%2478cc4211348e7338a095ef33d5bae723328f7864f4b162f20762d0f312418b42.json
Reading /Users/atheken/.composer/cache/repo/https---packagist.org/p-provider-latest.json from cache
The 'http://packagist.org/p/provider-latest%2478cc4211348e7338a095ef33d5bae723328f7864f4b162f20762d0f312418b42.json' URL could not be accessed: HTTP/1.1 400 Bad Request

http://packagist.org could not be fully loaded, package information was loaded from the local cache and may be out of date
Downloading http://packagist.org/p/guzzle/guzzle%2496f3e4a54a54dc1c3cfe4eb6b5df48192fc5b9c286da8c8ab797bdc69d36ac1d.json
Downloading http://packagist.org/p/guzzle/guzzle%2496f3e4a54a54dc1c3cfe4eb6b5df48192fc5b9c286da8c8ab797bdc69d36ac1d.json
Downloading http://packagist.org/p/guzzle/guzzle%2496f3e4a54a54dc1c3cfe4eb6b5df48192fc5b9c286da8c8ab797bdc69d36ac1d.json



  [Composer\Downloader\TransportException]                                                                                                                            
  The 'http://packagist.org/p/guzzle/guzzle%2496f3e4a54a54dc1c3cfe4eb6b5df48192fc5b9c286da8c8ab797bdc69d36ac1d.json' URL could not be accessed: HTTP/1.1 400 Bad Req  
  uest                                                                                                                                                                



Exception trace:
 () at phar:///usr/local/Cellar/composer/1.0.0-alpha11/libexec/composer.phar/src/Composer/Util/RemoteFilesystem.php:340
 Composer\Util\RemoteFilesystem->callbackGet() at n/a:n/a
 file_get_contents() at phar:///usr/local/Cellar/composer/1.0.0-alpha11/libexec/composer.phar/src/Composer/Util/RemoteFilesystem.php:179
 Composer\Util\RemoteFilesystem->get() at phar:///usr/local/Cellar/composer/1.0.0-alpha11/libexec/composer.phar/src/Composer/Util/RemoteFilesystem.php:84
 Composer\Util\RemoteFilesystem->getContents() at phar:///usr/local/Cellar/composer/1.0.0-alpha11/libexec/composer.phar/src/Composer/Repository/ComposerRepository.php:601
 Composer\Repository\ComposerRepository->fetchFile() at phar:///usr/local/Cellar/composer/1.0.0-alpha11/libexec/composer.phar/src/Composer/Repository/ComposerRepository.php:304
 Composer\Repository\ComposerRepository->whatProvides() at phar:///usr/local/Cellar/composer/1.0.0-alpha11/libexec/composer.phar/src/Composer/DependencyResolver/Pool.php:199
 Composer\DependencyResolver\Pool->computeWhatProvides() at phar:///usr/local/Cellar/composer/1.0.0-alpha11/libexec/composer.phar/src/Composer/DependencyResolver/Pool.php:188
 Composer\DependencyResolver\Pool->whatProvides() at phar:///usr/local/Cellar/composer/1.0.0-alpha11/libexec/composer.phar/src/Composer/Package/Version/VersionSelector.php:54
 Composer\Package\Version\VersionSelector->findBestCandidate() at phar:///usr/local/Cellar/composer/1.0.0-alpha11/libexec/composer.phar/src/Composer/Command/InitCommand.php:602
 Composer\Command\InitCommand->findBestVersionForPackage() at phar:///usr/local/Cellar/composer/1.0.0-alpha11/libexec/composer.phar/src/Composer/Command/InitCommand.php:334
 Composer\Command\InitCommand->determineRequirements() at phar:///usr/local/Cellar/composer/1.0.0-alpha11/libexec/composer.phar/src/Composer/Command/RequireCommand.php:107
 Composer\Command\RequireCommand->execute() at phar:///usr/local/Cellar/composer/1.0.0-alpha11/libexec/composer.phar/vendor/symfony/console/Command/Command.php:256
 Symfony\Component\Console\Command\Command->run() at phar:///usr/local/Cellar/composer/1.0.0-alpha11/libexec/composer.phar/vendor/symfony/console/Application.php:838
 Symfony\Component\Console\Application->doRunCommand() at phar:///usr/local/Cellar/composer/1.0.0-alpha11/libexec/composer.phar/vendor/symfony/console/Application.php:189
 Symfony\Component\Console\Application->doRun() at phar:///usr/local/Cellar/composer/1.0.0-alpha11/libexec/composer.phar/src/Composer/Console/Application.php:147
 Composer\Console\Application->doRun() at phar:///usr/local/Cellar/composer/1.0.0-alpha11/libexec/composer.phar/vendor/symfony/console/Application.php:120
 Symfony\Component\Console\Application->run() at phar:///usr/local/Cellar/composer/1.0.0-alpha11/libexec/composer.phar/src/Composer/Console/Application.php:82
 Composer\Console\Application->run() at phar:///usr/local/Cellar/composer/1.0.0-alpha11/libexec/composer.phar/bin/composer:43
 require() at /usr/local/Cellar/composer/1.0.0-alpha11/libexec/composer.phar:24
```
",False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/167516047,Composer uses non-ssl url for Packagist,stof,5,123816536,3,167516047,0,167130664,2015-12-28T08:49:54Z,"by default, composer uses HTTPS for the initial download from packagist, and then uses HTTP for the next downloads (but checks for integrity because it has a hash of the file in the previous download). The goal is to avoid doing the SSL handshake each time.
If forcing it to use HTTPS (which is done in your case by registering Packagist again explicitly without allowing the downgrade to HTTP) makes it work, it means that the issue is probably related to a proxy server altering the request or response (but unable to alter HTTPS requests)
",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/167580964,Composer uses non-ssl url for Packagist,atheken,5,123816536,4,167580964,0,167516047,2015-12-28T14:30:27Z,"Thanks @stof - as you mentioned, this was due to a proxy-type application (in my case, the VPN client we use also does some traffic filtering).
",False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/375893450,Composer uses non-ssl url for Packagist,dexhunter,5,123816536,5,375893450,0,167580964,2018-03-24T14:30:30Z,Hi! I wonder how did you solve this problem? @atheken Thanks!,False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/401837547,Composer uses non-ssl url for Packagist,cmeschin,5,123816536,6,401837547,0,375893450,2018-07-02T15:10:00Z,"Hi, Forcing the packagist url to use SSL resolves the issue:

composer config repo.packagist composer https://packagist.org",False,0,NONE
https://api.github.com/repos/composer/composer/issues/4734,Issue with Yii2,TanglerDS,7,123900156,1,123900156,0,0,2015-12-25T22:54:12Z,"Hello, I have a strange problem here. Composer loads and installs Yii 1.1.16 perfectly, but absolutely refuses to load Yii2. Says ""could not find stable version"". Tried to set minimum-stability to ""dev"" - nothing. Server: apache. What could cause such an issue?
",True,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/167323101,Issue with Yii2,alcohol,7,123900156,2,167323101,0,123900156,2015-12-26T13:06:06Z,"Please provide some actual information. 
- What command did you try to run? 
- What was the output Composer returned? 
- What does your composer.json look like?
",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/167325865,Issue with Yii2,TanglerDS,7,123900156,3,167325865,0,167323101,2015-12-26T13:38:12Z,"First, I try it as it is stated on yii official site: composer create-project yiisoft/yii2-app-basic basic 2.0.6
Then I try the following:
composer create-project yiisoft/yii2
composer create-project yiisoft/yii2-app-basic
composer create-project yiisoft/yii2-app-basic 2.0.*
composer require ""yiisoft/yii2-app-basic"" : ""@dev""
Nothing seems to work, the output is: could not find package, check your spelling or minimum-stability.
However, the commend: composer create-project yiisoft/yii - works perfectly and installs Yii 1.1.16
json file in root has this in it:
{
    ""minimum-stability"": ""dev"", ""require"": {
        ""fxp/composer-asset-plugin"": ""~1.1.1""
    }
}
First I thought it may be issue with minimum-stability, but the current version of Yii2 looks to be stable
Thanks in advance
",False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/167363572,Issue with Yii2,osavchenko,7,123900156,4,167363572,0,167325865,2015-12-26T21:05:34Z,"@TanglerDS could you show extended error message?
",False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/167439009,Issue with Yii2,xabbuh,7,123900156,5,167439009,0,167363572,2015-12-27T20:08:21Z,"It looks like Yii2 needs the Composer Asset plugin (see https://github.com/yiisoft/yii2-framework#installation) to be able to install Bower packages through Composer. Imho that's more a documentation issue of Yii itself. They should make it more clear that you need the plugin. At least, it's not related to Composer itself.
",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/167453651,Issue with Yii2,lichunqiang,7,123900156,6,167453651,0,167439009,2015-12-28T01:34:35Z,"You should delete the `vendor` folder firstly and run:
- composer self-update
- composer global require  fxp/composer-asset-plugin=~1.1.1 
- composer install
",False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/167576715,Issue with Yii2,TanglerDS,7,123900156,7,167576715,0,167453651,2015-12-28T13:56:30Z,"Problem solved - my PHP version was outdated. Thank you all for your answers
",False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/167578083,Issue with Yii2,xabbuh,7,123900156,8,167578083,0,167576715,2015-12-28T14:10:46Z,"@TanglerDS Please close the issue then.
",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/4735,Versions aren't properly resolved when a replaced package is used,wouterj,3,123984558,1,123984558,0,0,2015-12-27T16:04:21Z,"There is a strange bug in Composer causing unexpected behaviour when at least 2 packages are required and one replaces the other package (e.g. `symfony/symfony` and `symfony/framework-bundle`).

When using the tidle operator or the OR operator, the package isn't replaced and both packages are resolved as if they were 2 standalone packages (using OR with `x.y.*` results in unexplainable version resolving).
## Reproducable Examples

```
+============================+====================================+===============================+
| `symfony/framework-bundle` |                                    |                               |
|     version constraint     |             Installed              |            Expected           |
+============================+====================================+===============================+
| `2.6.*`                    |  `symfony/symfony` v2.6.12         | As expected                   |
+----------------------------+------------------------------------+-------------------------------+
| `2.3.*|2.8.*`              | `symfony/framework-bundle` v2.3.36 | No `symfony/framework-bundle` |
|                            | `symfony/symfony` v2.7.8           | `symfony/symfony` v2.8.1      |
+----------------------------+------------------------------------+-------------------------------+
| `~2.3.3`                   | `symfony/framework-bundle` v2.3.36 | No `symfony/framework-bundle` |
|                            | `symfony/symfony` v2.8.1           | `symfony/symfony` v2.3.36     |
+----------------------------+------------------------------------+-------------------------------+
| `~2.3.3|~2.6.6`            | `symfony/framework-bundle` v2.6.12 | No `symfony/framework-bundle` |
|                            | `symfony/symfony` v2.8.1           | `symfony/symfony` v2.6.12     |
+----------------------------+------------------------------------+-------------------------------+
| `^2.6.6`                   |  `symfony/symfony` v2.8.1          | As expected                   |
+----------------------------+------------------------------------+-------------------------------+
| `~2.3.3|^2.6.6`            | `symfony/framework-bundle` v2.6.12 | No `symfony/framework-bundle` |
|                            | `symfony/symfony` v2.6.5           | `symfony/symfony` v2.6.12     |
+============================+====================================+===============================+
```

``` bash
$ composer require --no-update symfony/framework-bundle ""<CONSTRAINT FROM TABLE>""
$ composer require --no-update symfony/symfony ""*""
$ composer update
$ composer show -i | grep symfony
```
",True,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/167440456,Versions aren't properly resolved when a replaced package is used,xabbuh,3,123984558,2,167440456,0,123984558,2015-12-27T20:47:45Z,"I guess this is probably related to #3754.
",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/167516798,Versions aren't properly resolved when a replaced package is used,alcohol,3,123984558,3,167516798,0,167440456,2015-12-28T08:54:33Z,"Yes, `replace` has not been working ""properly"" for quite some time already. This is known. See the issue @xabbuh referenced.
",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/186842055,Versions aren't properly resolved when a replaced package is used,Seldaek,3,123984558,4,186842055,0,167516798,2016-02-21T15:18:34Z,"Closing as duplicate of #3754
",False,0,MEMBER
https://api.github.com/repos/sparklemotion/nokogiri/issues/1490,Mix XML with filled and empty namespaces,majioa,3,160639226,1,160639226,0,0,2016-06-16T11:28:41Z,"I have an XML like:

```
<ns2:doc>
   <field>
       ...
   </field>
</ns2:doc>
```

How can I address it in a single line query? I tried:

```
context.search(""doc field"")
# => []
context.search(""ns2:doc field"")
# => exception
context.xpath(""//ns2:doc/:field"")
# => []
context.css(""doc field"")
# => []
context.css(""ns2:doc field"")
# => exception
```

Exactly I need to use xpath with relational search from top of node: `/field` or `field`, but `//field` searches always from root of document:

```
context.xpath(""//ns2:doc/:field"")
# => [field]
```

or I need to find with css but over namespace tags:

```
context.css(""ns2:doc field"")
# => [field]
```
",True,0,NONE
https://api.github.com/repos/sparklemotion/nokogiri/issues/comments/251031783,Mix XML with filled and empty namespaces,flavorjones,3,160639226,2,251031783,0,160639226,2016-10-03T05:55:12Z,"Hello!

Thanks for asking this question! Your request for assistance using
Nokogiri will not go unanswered!

However, Nokogiri's Github Issues is reserved for reporting bugs or
submitting patches. If you ask your question on the mailing list, Team
Nokogiri promises someone will provide you with an answer in a timely
manner.

If you'd like to read up on Team Nokogiri's rationale for this policy,
please go to http://bit.ly/nokohelp.

Thank you so much for understanding! And thank you for using Nokogiri.
",False,0,MEMBER
https://api.github.com/repos/sparklemotion/nokogiri/issues/comments/251897228,Mix XML with filled and empty namespaces,majioa,3,160639226,3,251897228,0,251031783,2016-10-06T08:21:26Z,"@flavorjones it is not a question explicitly, it is a bug report.
",False,0,NONE
https://api.github.com/repos/sparklemotion/nokogiri/issues/comments/252124497,Mix XML with filled and empty namespaces,flavorjones,3,160639226,4,252124497,0,251897228,2016-10-07T00:25:02Z,"I disagree, please email the list for support.
",False,0,MEMBER
https://api.github.com/repos/sparklemotion/nokogiri/issues/1492,Attribute names sometimes have namespace prepended under jruby,torcido,3,161100349,1,161100349,0,0,2016-06-20T00:40:01Z,"Sorry, I don't yet have a minimal test case (the setup that reveals this issue is quite large), but after some manipulation of the DOM, I'm seeing an element that looks like this:

```
#(Element:0x21da {
  name = ""annotation-end"",
  namespace = #(Namespace:0x20fa { prefix = ""office"", href = ""urn:oasis:names:tc:opendocument:xmlns:office:1.0"" }),
  attributes = [ #(Attr:0x21de { name = ""office:name"", value = ""__Annotation__65_977956481"" })]
  }),
```

This is a problem, because the namespace is now included as part of the name in the attribute, and my xpath expressions no longer find the element.

This only happens under jruby and only started happening with 1.6.8. Version 1.6.7.2 was fine (still different from MRI, but the namespace was kept separate from the attribute name).

In 1.6.7.2, the element looks like:

```
#(Element:0x20d0 {
  name = ""annotation-end"",
  namespace = #(Namespace:0x2066 { prefix = ""office"", href = ""urn:oasis:names:tc:opendocument:xmlns:office:1.0"" }),
  attributes = [
    #(Attr:0x20d4 {
      name = ""name"",
      namespace = #(Namespace:0x2066 { prefix = ""office"", href = ""urn:oasis:names:tc:opendocument:xmlns:office:1.0"" }),
      value = ""__Annotation__65_977956481""
      })]
  }),
```

I find that when I first load the document the attributes look OK - it's only after some amount of processing (adding, unlinking and duplicating elements) that the issue occurs. I haven't yet been able to narrow it down to a minimal test case.

I suspect that this particular element was already unlinked, then added back into the DOM, probably using add_previous_sibling (though it may have been added from the parent using add_child).

I'll try to write a test case over the next few weeks, but I was hoping this information may be enough to spark a thought in someone reading this :)
",True,0,NONE
https://api.github.com/repos/sparklemotion/nokogiri/issues/comments/251031440,Attribute names sometimes have namespace prepended under jruby,flavorjones,3,161100349,2,251031440,0,161100349,2016-10-03T05:51:27Z,"Any luck getting a reproducible test case?
",False,0,MEMBER
https://api.github.com/repos/sparklemotion/nokogiri/issues/comments/278908964,Attribute names sometimes have namespace prepended under jruby,flavorjones,3,161100349,3,278908964,0,251031440,2017-02-10T10:25:32Z,"I'd like to close this issue, unless you can provide a reproducible test case.",False,0,MEMBER
https://api.github.com/repos/sparklemotion/nokogiri/issues/comments/279287237,Attribute names sometimes have namespace prepended under jruby,torcido,3,161100349,4,279287237,0,278908964,2017-02-13T03:35:22Z,"Sorry - please feel free to close. We ended up switching to oga to do this manipulation in a way consistent between mri and jruby.
Thanks!",False,0,NONE
https://api.github.com/repos/sparklemotion/nokogiri/issues/1493,line numbers not working as expected,flavorjones,3,161318188,1,161318188,0,0,2016-06-20T23:25:12Z,"(reported on nokogiri-talk by @justinthec)

I haven't had time to look into this, but wanted to capture it so that it wouldn't get forgotten.

---

> Hello,
> 
> Preface/libxml2
> 
> I've come across a bug that popped up once before in libxml2 back in 2008 where XML_TEXT_NODEs would always return 0 as their line number.
> 
> Link: https://mail.gnome.org/archives/xml/2008-July/msg00017.html
> 
> It was however patched that day and should have been fixed.
> 
> Commit: https://git.gnome.org/browse/libxml2/commit/?id=45efd0878aa56efa4291eec2ecdcff66d2f52fc3
> 
> Those three lines that he added still exist in the most current version of libxml2 now just under a conditional check for a (ctxt->linenumbers) flag.
> 
> Current Day libxml2: https://git.gnome.org/browse/libxml2/tree/SAX2.c?id=4472c3a5a5b516aaf59b89be602fbce52756c3e9#n1905
> 
> Nokogiri
> 
> This bug is currently present in Nokogiri 1.6.8.
> 
> I've been looking through the source in an attempt to find a fix and I'd appreciate some guidance:
> 
> Possibly relevant files:
> https://github.com/sparklemotion/nokogiri/blob/8e305e4e3d0ab697d1c6bc506398fb3007baf874/ext/nokogiri/xml_node.c#L1258
> https://github.com/sparklemotion/nokogiri/blob/027a151102083258f5e297c4fecfddca56904a2a/ext/nokogiri/xml_sax_parser_context.c#L171
> 
> Any ideas?
> 
> Thanks in advance,
> 
> Justin
",True,0,MEMBER
https://api.github.com/repos/sparklemotion/nokogiri/issues/comments/227303287,line numbers not working as expected,justinthec,3,161318188,2,227303287,0,161318188,2016-06-20T23:49:48Z,"Thanks Mike, if you have any ideas but don't have time to try them out I'd be happy to take it on.

The farthest I've gotten so far is `xmlGetLineNo()` being called, but the source for that function is nowhere to be found, most likely in the compiled source of whichever version of libxml you guys are using.
",False,0,NONE
https://api.github.com/repos/sparklemotion/nokogiri/issues/comments/331811993,line numbers not working as expected,Xliff,3,161318188,3,331811993,0,227303287,2017-09-25T08:28:15Z,"I have been working on a project that uses libxml2, so in my searches I found this issue. Since this is still marked as open, I hope this is still relevant.

It looks like xmlGetLineNo just returns the results of xmlGetLineNoInternal, which you can find, here:
https://github.com/GNOME/libxml2/blob/master/tree.c#L4593",False,0,NONE
https://api.github.com/repos/sparklemotion/nokogiri/issues/comments/898930510,line numbers not working as expected,flavorjones,3,161318188,4,898930510,0,331811993,2021-08-14T17:01:38Z,This will be fixed in v1.13.,False,0,MEMBER
https://api.github.com/repos/sparklemotion/nokogiri/issues/1496,Please drop the pkg-config dependency from the precompiled gems,voxik,3,162143997,1,162143997,0,0,2016-06-24T13:14:17Z,"Not sure if that is possible, but there is no reason the precompiled versions of gem should depend on pkg-config. The java version does not depend on it, so hopefully this dependency can be avoided also for the other platforms.
",True,0,CONTRIBUTOR
https://api.github.com/repos/sparklemotion/nokogiri/issues/comments/228365751,Please drop the pkg-config dependency from the precompiled gems,flavorjones,3,162143997,2,228365751,0,162143997,2016-06-24T14:46:09Z,"There's another issue opened objecting to the license, and so we may remove
it entirely. Stay tuned.
On Jun 24, 2016 9:14 AM, ""Vít Ondruch"" notifications@github.com wrote:

> Not sure if that is possible, but there is no reason the precompiled
> versions of gem should depend on pkg-config. The java version does not
> depend on it, so hopefully this dependency can be avoided also for the
> other platforms.
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/sparklemotion/nokogiri/issues/1496, or mute the
> thread
> https://github.com/notifications/unsubscribe/AAAgD68H--rrqthcOmOs5b_yp3jm2aIHks5qO9gqgaJpZM4I9wOo
> .
",False,0,MEMBER
https://api.github.com/repos/sparklemotion/nokogiri/issues/comments/228368335,Please drop the pkg-config dependency from the precompiled gems,md5,3,162143997,3,228368335,0,228365751,2016-06-24T14:55:23Z,"@voxik The other issue is #1488 
",False,0,NONE
https://api.github.com/repos/sparklemotion/nokogiri/issues/comments/251020625,Please drop the pkg-config dependency from the precompiled gems,flavorjones,3,162143997,4,251020625,0,228368335,2016-10-03T03:41:41Z,"Will be fixed in 1.6.8.1
",False,0,MEMBER
https://api.github.com/repos/nvm-sh/nvm/issues/1519,--reinstall-packages-from fails when local repositories are npm link'd,patrickhulce,19,224872518,1,224872518,0,0,2017-04-27T18:27:32Z,"- Operating system and version: macOS Sierra 10.12.4

- `nvm debug` output: 
<details>
<!-- do not delete the following blank line -->

```sh
nvm --version: v0.33.0
$SHELL: /bin/zsh
$HOME: /Users/phulce
$NVM_DIR: '$HOME/.nvm'
$PREFIX: ''
$NPM_CONFIG_PREFIX: ''
nvm current: v7.9.0
which node: $NVM_DIR/versions/node/v7.9.0/bin/node
which iojs: iojs not found
which npm: $NVM_DIR/versions/node/v7.9.0/bin/npm
npm config get prefix: $NVM_DIR/versions/node/v7.9.0
npm root -g: $NVM_DIR/versions/node/v7.9.0/lib/node_modules
```
</details>

- `nvm ls` output:
<details>
<!-- do not delete the following blank line -->

```sh
         v6.9.5
         v7.2.1
->       v7.9.0
default -> v7.2.1
node -> stable (-> v7.9.0) (default)
stable -> 7.9 (-> v7.9.0) (default)
iojs -> N/A (default)
lts/* -> lts/boron (-> N/A)
lts/argon -> v4.8.2 (-> N/A)
lts/boron -> v6.10.2 (-> N/A)
```
</details>

- How did you install `nvm`? (e.g. install script in readme, homebrew): 

homebrew

- What steps did you perform? 

Ran `nvm install v7.9.0 --reinstall-packages-from=v7.2.1`

- What happened? 

Saw errors in the console and no globally installed packages were reinstalled (`yarn` for example).
<details>

```sh
Downloading and installing node v7.9.0...
Downloading https://nodejs.org/dist/v7.9.0/node-v7.9.0-darwin-x64.tar.xz...
######################################################################## 100.0%
Computing checksum with shasum -a 256
Checksums matched!
Now using node v7.9.0 (npm v4.2.0)
VERSION=''
xargs: unterminated quote
Reinstalling global packages from v7.2.1...
Linking global packages from v7.2.1...
nvm_cd:cd:2: no such file or directory: /Users/phulce/Code/npm-linked-package-a\n/Users/phulce/Code/npm-linked-package-b\n/Users/phulce/Code/npm-linked-package-c\n/Users/phulce/Code/npm-linked-package-d\n/Users/phulce/Code/npm-linked-package-e
```
</details>

- What did you expect to happen?

No errors printed to console and globally installed packages from my previous version are available in the new installation (re-linking local packages that are `npm link`'d would be a nice bonus but I did not expect it :) )

- Is there anything in any of your profile files (`.bashrc`, `.bash_profile`, `.zshrc`, etc) that modifies the `PATH`? 

Yes before the `nvm.sh` eval I add a few local 
",True,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/297845750,--reinstall-packages-from fails when local repositories are npm link'd,ljharb,19,224872518,2,297845750,0,224872518,2017-04-27T21:34:33Z,What's your IFS env var contain?,False,0,MEMBER
https://api.github.com/repos/nvm-sh/nvm/issues/comments/297848303,--reinstall-packages-from fails when local repositories are npm link'd,patrickhulce,19,224872518,3,297848303,0,297845750,2017-04-27T21:46:35Z,"Glad I still have that shell open! It's empty...
```sh
printf %q ""$IFS""
''%
```

All other open shells have the default
```sh
printf %q ""$IFS""
\ $'\t'$'\n'%
```
",False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/297848420,--reinstall-packages-from fails when local repositories are npm link'd,ljharb,19,224872518,4,297848420,0,297848303,2017-04-27T21:47:14Z,"aha - if, in that same shell, you set it to the default, is the problem fixed?",False,0,MEMBER
https://api.github.com/repos/nvm-sh/nvm/issues/comments/297850323,--reinstall-packages-from fails when local repositories are npm link'd,patrickhulce,19,224872518,5,297850323,0,297848420,2017-04-27T21:56:25Z,"nope, I get the same result. The `nvm install` command seems to be the culprit for setting IFS to empty

```sh
> printf %q ""$IFS""
\ $'\t'$'\n'%
> nvm install v7.9.0 --reinstall-packages-from=v7.2.1
Downloading and installing node v7.9.0...
Local cache found: $NVM_DIR/.cache/bin/node-v7.9.0-darwin-x64/node-v7.9.0-darwin-x64.tar.xz
Checksums match! Using existing downloaded archive $NVM_DIR/.cache/bin/node-v7.9.0-darwin-x64/node-v7.9.0-darwin-x64.tar.xz
Now using node v7.9.0 (npm v4.2.0)
VERSION=''
xargs: unterminated quote
Reinstalling global packages from v7.2.1...
Linking global packages from v7.2.1...
nvm_cd:cd:2: no such file or directory: ...
> printf %q ""$IFS""
''%
```",False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/297856055,--reinstall-packages-from fails when local repositories are npm link'd,ljharb,19,224872518,6,297856055,0,297850323,2017-04-27T22:25:18Z,"Seems like #1518 is related, but that's not the entirety of the problem.

Can you provide the output of `nvm use 7.2.1 ; npm ls -g ; nvm_npm_global_modules`?",False,0,MEMBER
https://api.github.com/repos/nvm-sh/nvm/issues/comments/297857226,--reinstall-packages-from fails when local repositories are npm link'd,ljharb,19,224872518,7,297857226,0,297856055,2017-04-27T22:31:27Z,(There's a totally separate issue where IFS isn't reset inside `nvm reinstall-packages` if `npm link` fails),False,0,MEMBER
https://api.github.com/repos/nvm-sh/nvm/issues/comments/297865178,--reinstall-packages-from fails when local repositories are npm link'd,patrickhulce,19,224872518,8,297865178,0,297857226,2017-04-27T23:18:54Z,"Ah progress! Looks like I had one `npm link` directory leftover that I had since deleted which showed up in `npm ls -g`. After removing that link, it successfully installed my regular packages 👍  I still got the error on trying to do the linking on the new version though
```bash
Linking global packages from v7.2.1...
nvm_cd:cd:2: no such file or directory: /path/to/link-a\n/path/to/link-b\n/path/to/link-c...
```",False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/297878864,--reinstall-packages-from fails when local repositories are npm link'd,ljharb,19,224872518,9,297878864,0,297865178,2017-04-28T00:57:41Z,@patrickhulce i'd still have needed to see the original output of those commands to fix the problem :-/ can you provide the output requested in https://github.com/creationix/nvm/issues/1519#issuecomment-297856055 ?,False,0,MEMBER
https://api.github.com/repos/nvm-sh/nvm/issues/comments/298097250,--reinstall-packages-from fails when local repositories are npm link'd,patrickhulce,19,224872518,10,298097250,0,297878864,2017-04-28T20:20:50Z,"`nvm use 7.2.1`

<details>

```sh
Now using node v7.2.1 (npm v3.10.10)
```
</details>

`npm ls -g`
[log of output](https://drive.google.com/open?id=0B-5_rLPhfB8eLTVVbHN5T2IwTjA) plus the stderr below
<details>

```sh
npm ERR! extraneous: mocha@3.2.0 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/generator-npm-package/node_modules/mocha
npm ERR! extraneous: @types/node@6.0.46 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/lighthouse/node_modules/@types/node
npm ERR! extraneous: coveralls@2.11.14 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/lighthouse/node_modules/coveralls
npm ERR! extraneous: eslint@3.12.0 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/lighthouse/node_modules/eslint
npm ERR! extraneous: eslint-config-google@0.7.1 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/lighthouse/node_modules/eslint-config-google
npm ERR! extraneous: google-closure-compiler@20161201.0.0 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/lighthouse/node_modules/google-closure-compiler
npm ERR! extraneous: gulp@3.9.1 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/lighthouse/node_modules/gulp
npm ERR! extraneous: gulp-concat@2.6.1 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/lighthouse/node_modules/gulp-concat
npm ERR! extraneous: gulp-declare@0.3.0 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/lighthouse/node_modules/gulp-declare
npm ERR! extraneous: gulp-define-module@0.1.5 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/lighthouse/node_modules/gulp-define-module
npm ERR! extraneous: gulp-handlebars@4.0.0 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/lighthouse/node_modules/gulp-handlebars
npm ERR! extraneous: gulp-replace@0.5.4 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/lighthouse/node_modules/gulp-replace
npm ERR! extraneous: istanbul@0.4.5 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/lighthouse/node_modules/istanbul
npm ERR! extraneous: jsdom@9.12.0 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/lighthouse/node_modules/jsdom
npm ERR! extraneous: mocha@3.2.0 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/lighthouse/node_modules/mocha
npm ERR! extraneous: zone.js@0.7.3 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/lighthouse/node_modules/zone.js
npm ERR! extraneous: ava@0.14.0 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/speedline/node_modules/ava
npm ERR! extraneous: fs-promise@0.5.0 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/speedline/node_modules/fs-promise
npm ERR! extraneous: jimp@0.2.27 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/speedline/node_modules/jimp
npm ERR! extraneous: node-pre-gyp@0.6.34 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/speedline/node_modules/node-pre-gyp
npm ERR! extraneous: sobel@0.0.7 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/speedline/node_modules/sobel
npm ERR! extraneous: xo@0.14.0 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/speedline/node_modules/xo
npm ERR! extraneous: ava@0.18.2 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/xo/node_modules/ava
npm ERR! extraneous: babel-eslint@7.1.1 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/xo/node_modules/babel-eslint
npm ERR! extraneous: coveralls@2.11.16 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/xo/node_modules/coveralls
npm ERR! extraneous: eslint-config-xo-react@0.10.0 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/xo/node_modules/eslint-config-xo-react
npm ERR! extraneous: eslint-import-resolver-webpack@0.8.1 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/xo/node_modules/eslint-import-resolver-webpack
npm ERR! extraneous: eslint-plugin-react@6.10.0 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/xo/node_modules/eslint-plugin-react
npm ERR! extraneous: nyc@8.4.0 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/xo/node_modules/nyc
npm ERR! extraneous: proxyquire@1.7.11 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/xo/node_modules/proxyquire
npm ERR! extraneous: temp-write@2.1.0 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/xo/node_modules/temp-write
npm ERR! extraneous: xo@0.16.0 /Users/phulce/.nvm/versions/node/v7.2.1/lib/node_modules/xo/node_modules/xo
```
</details>


`nvm_npm_global_modules `

<details>
Seemingly errors
```sh
nvm_npm_global_modules
No .nvmrc file found

Node Version Manager

Note: <version> refers to any version-like string nvm understands. This includes:
  - full or partial version numbers, starting with an optional ""v"" (0.10, v0.1.2, v1)
  - default (built-in) aliases: node, stable, unstable, iojs, system
  - custom aliases you define with `nvm alias foo`

 Any options that produce colorized output should respect the `--no-colors` option.

Usage:
  nvm --help                                Show this message
  nvm --version                             Print out the latest released version of nvm
  nvm install [-s] <version>                Download and install a <version>, [-s] from source. Uses .nvmrc if available
    --reinstall-packages-from=<version>     When installing, reinstall packages installed in <node|iojs|node version number>
    --lts                                   When installing, only select from LTS (long-term support) versions
    --lts=<LTS name>                        When installing, only select from versions for a specific LTS line
  nvm uninstall <version>                   Uninstall a version
  nvm uninstall --lts                       Uninstall using automatic LTS (long-term support) alias `lts/*`, if available.
  nvm uninstall --lts=<LTS name>            Uninstall using automatic alias for provided LTS line, if available.
  nvm use [--silent] <version>              Modify PATH to use <version>. Uses .nvmrc if available
    --lts                                   Uses automatic LTS (long-term support) alias `lts/*`, if available.
    --lts=<LTS name>                        Uses automatic alias for provided LTS line, if available.
  nvm exec [--silent] <version> [<command>] Run <command> on <version>. Uses .nvmrc if available
    --lts                                   Uses automatic LTS (long-term support) alias `lts/*`, if available.
    --lts=<LTS name>                        Uses automatic alias for provided LTS line, if available.
  nvm run [--silent] <version> [<args>]     Run `node` on <version> with <args> as arguments. Uses .nvmrc if available
    --lts                                   Uses automatic LTS (long-term support) alias `lts/*`, if available.
    --lts=<LTS name>                        Uses automatic alias for provided LTS line, if available.
  nvm current                               Display currently activated version
  nvm ls                                    List installed versions
  nvm ls <version>                          List versions matching a given <version>
  nvm ls-remote                             List remote versions available for install
    --lts                                   When listing, only show LTS (long-term support) versions
  nvm ls-remote <version>                   List remote versions available for install, matching a given <version>
    --lts                                   When listing, only show LTS (long-term support) versions
    --lts=<LTS name>                        When listing, only show versions for a specific LTS line
  nvm version <version>                     Resolve the given description to a single local version
  nvm version-remote <version>              Resolve the given description to a single remote version
    --lts                                   When listing, only select from LTS (long-term support) versions
    --lts=<LTS name>                        When listing, only select from versions for a specific LTS line
  nvm deactivate                            Undo effects of `nvm` on current shell
  nvm alias [<pattern>]                     Show all aliases beginning with <pattern>
  nvm alias <name> <version>                Set an alias named <name> pointing to <version>
  nvm unalias <name>                        Deletes the alias named <name>
  nvm reinstall-packages <version>          Reinstall global `npm` packages contained in <version> to current version
  nvm unload                                Unload `nvm` from shell
  nvm which [<version>]                     Display path to installed node version. Uses .nvmrc if available
  nvm cache dir                             Display path to the cache directory for nvm
  nvm cache clear                           Empty cache directory for nvm

Example:
  nvm install v0.10.32                  Install a specific version number
  nvm use 0.10                          Use the latest available 0.10.x release
  nvm run 0.10.32 app.js                Run app.js using node v0.10.32
  nvm exec 0.10.32 node app.js          Run `node app.js` with the PATH pointing to node v0.10.32
  nvm alias default 0.10.32             Set default node version on a shell

Note:
  to remove, delete, or uninstall nvm - just remove the `$NVM_DIR` folder (usually `~/.nvm`)

 ////
```
</details>

",False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/298118015,--reinstall-packages-from fails when local repositories are npm link'd,ljharb,19,224872518,11,298118015,0,298097250,2017-04-28T22:09:00Z,"whoops, my bad. @patrickhulce can you run `nvm_npm_global_modules $(nvm current)` instead?",False,0,MEMBER
https://api.github.com/repos/nvm-sh/nvm/issues/comments/298121479,--reinstall-packages-from fails when local repositories are npm link'd,patrickhulce,19,224872518,12,298121479,0,298118015,2017-04-28T22:31:54Z,"that makes more sense :) looks like those are expecting to be space delimited?
```bash
bower@1.8.0 diff-so-fancy@0.11.4 google-closure-compiler-js@20170124.0.0 gulp@3.9.1 http-server@0.9.0 imagemin-cli@3.0.0 mocha@3.2.0 prettier@0.22.0 semantic-release-cli@3.0.3 typescript@2.2.1 webpack@1.14.0 webpack-dev-server@1.16.2 yarn@0.20.3 yo@1.8.5 //// /Users/phulce/Code/OpenSource/lint
/Users/phulce/Code/OpenSource/generator-npm-package
/Users/phulce/Code/Chrome/lighthouse
/Users/phulce/Code/OpenSource/speedline
/Users/phulce/Code/OpenSource/xo
```",False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/298124628,--reinstall-packages-from fails when local repositories are npm link'd,ljharb,19,224872518,13,298124628,0,298121479,2017-04-28T22:54:27Z,"actually that output looks correct (the first half is space-delimited, the last half is newline-delimited)

However, I'm wondering if your IFS setting caused the same issue. What happens if you set IFS to the default (`$' \t\n'`), or unset it entirely?",False,0,MEMBER
https://api.github.com/repos/nvm-sh/nvm/issues/comments/298129147,--reinstall-packages-from fails when local repositories are npm link'd,patrickhulce,19,224872518,14,298129147,0,298124628,2017-04-28T23:30:18Z,"Oh I should've clarified above that 2nd run was with IFS explicitly set back to default, I get identical results when unsetting it entirely",False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/298129249,--reinstall-packages-from fails when local repositories are npm link'd,ljharb,19,224872518,15,298129249,0,298129147,2017-04-28T23:31:18Z,"I see that you're on zsh; any chance it's oh-my-zsh, or that you have some nondefault options set?

zsh options often break nvm; if that's the case, what's the output of your `setopt`?",False,0,MEMBER
https://api.github.com/repos/nvm-sh/nvm/issues/comments/298130710,--reinstall-packages-from fails when local repositories are npm link'd,patrickhulce,19,224872518,16,298130710,0,298129249,2017-04-28T23:45:34Z,"Ah ok, yes it's oh-my-zsh.

```
alwaystoend
autocd
autopushd
completeinword
extendedhistory
noflowcontrol
histexpiredupsfirst
histignoredups
histignorespace
histverify
incappendhistory
interactive
interactivecomments
login
longlistjobs
monitor
nonomatch
promptsubst
pushdignoredups
pushdminus
sharehistory
shinstdin
zle
```",False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/298142079,--reinstall-packages-from fails when local repositories are npm link'd,ljharb,19,224872518,17,298142079,0,298130710,2017-04-29T02:38:16Z,"The options that I don't have set on my stock `zsh` are:
```sh
alwaystoend
autocd
autopushd
completeinword
extendedhistory
noflowcontrol
histexpiredupsfirst
histignoredups
histignorespace
histverify
incappendhistory
interactivecomments
login
longlistjobs
promptsubst
pushdignoredups
pushdminus
sharehistory
```

The best way to figure this out quickly is for you to do a binary search - in other words, unset half of them, try again, then go back to only having half the failing half set, try again, etc, until we've narrowed it down.

Once that's done, I can fix it by wrapping the command in ""unset the opt, do the command, restore the opt"".",False,0,MEMBER
https://api.github.com/repos/nvm-sh/nvm/issues/comments/298383228,--reinstall-packages-from fails when local repositories are npm link'd,patrickhulce,19,224872518,18,298383228,0,298142079,2017-05-01T17:39:00Z,"Alright I'll give that a shot later this week, it became considerably less urgent once the regular globals were brought over :) thanks for the help!",False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/298461909,--reinstall-packages-from fails when local repositories are npm link'd,ljharb,19,224872518,19,298461909,0,298383228,2017-05-01T23:45:43Z,"Thanks, no hurry, but it's exceedingly hard to reproduce issues like this, so it'd be very very helpful for you to help me narrow it down to a single option :-)",False,0,MEMBER
https://api.github.com/repos/nvm-sh/nvm/issues/comments/320195373,--reinstall-packages-from fails when local repositories are npm link'd,kerryChen95,19,224872518,20,320195373,0,298461909,2017-08-04T08:54:05Z,"I also got `nvm xargs: unterminated quote` when run `nvm reinstall-packages v8.1.2`.

Then I run `npm list -g` and got an error saying something wrong about `$NVM_DIR/versions/node/v8.1.2/lib/node_modules/@mi/.DS_Store`, the error log indeed contains non-closing quotes, unfortunately I cleared that log.

But after `rm -fr $NVM_DIR/versions/node/v8.1.2/lib/node_modules/@mi/.DS_Store`, I fixed this problem, `nvm reinstall-packages v8.1.2` run as expected.

So maybe you can run `npm list -g` to see is there any error?",False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/1520,install script fails when username is different than root home directory,compwron,7,224925160,1,224925160,0,0,2017-04-27T21:59:09Z,"<!-- Thank you for being interested in nvm! Please help us by filling out the following form if you‘re having trouble. If you have a feature request, or some other question, please feel free to clear out the form. Thanks! -->

- Operating system and version:
OSX 10.11.6
<details>

```sh
➜ curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.0/install.sh | bash
######################################################################## 100.0%
=> Downloading nvm from git to '/Users/lgoldstein/.nvm'
=> mkdir: /Users/lgoldstein/.nvm: Permission denied
ls: /Users/lgoldstein/.nvm: No such file or directory
fatal: could not create leading directories of '/Users/lgoldstein/.nvm': Permission denied
Failed to clone nvm repo. Please report this!
➜ pwd
/Users/lgoldste/repositories/foo
➜
```
</details>

- What steps did you perform?
curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.0/install.sh | bash

- What happened?
Install failed with a path error

- What did you expect to happen?
Install to succeed

- Is there anything in any of your profile files (`.bashrc`, `.bash_profile`, `.zshrc`, etc) that modifies the `PATH`?
yes
<details>

```sh
➜  ~ grep PATH .bashrc .bash_profile .zshrc
.bashrc:export PATH=""$PATH:$HOME/.rvm/bin"" # Add RVM to PATH for scripting
.bash_profile:export GOPATH=""$HOME/.go""
.bash_profile:export PATH=$PATH:/usr/local/sbin
.bash_profile:export PATH=""$PATH:~/bin""
.bash_profile:export PATH=""/usr/local/bin:$PATH""
.bash_profile:export PATH=""$PATH:~/bc/release-options/bin""
.bash_profile:export PATH=""/usr/local/opt/gnu-tar/libexec/gnubin:$PATH"" # If you really need to use it as ""tar"", you can add a ""gnubin"" directory to your PATH from your bashrc like:
.bash_profile:alias path='echo -e ${PATH//:/\\n}' # view $PATH with linebreaks
.zshrc:export GOPATH=""$HOME/.go""
.zshrc:export PATH=$PATH:/usr/local/sbin
.zshrc:export PATH=""$PATH:~/bin""
.zshrc:export PATH=""/usr/local/bin:$PATH""
.zshrc:export PATH=""$PATH:~/bc/release-options/bin""
.zshrc:export PATH=""/usr/local/opt/gnu-tar/libexec/gnubin:$PATH"" # If you really need to use it as ""tar"", you can add a ""gnubin"" directory to your PATH from your bashrc like:
.zshrc:alias path='echo -e ${PATH//:/\\n}' # view $PATH with linebreaks
.zshrc:export PATH=""$PATH:$HOME/.rvm/bin"" # Add RVM to PATH for scripting
.zshrc:export PATH=""/usr/local/opt/qt5/bin:$PATH""
➜  ~ 
```
</details>

- If you are having installation issues, or getting ""N/A"", what does `curl -I --compressed -v https://nodejs.org/dist/` print out?
<details>

```sh
➜  ~ curl -I --compressed -v https://nodejs.org/dist/
*   Trying 104.20.23.46...
* Connected to nodejs.org (104.20.23.46) port 443 (#0)
* TLS 1.2 connection using TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256
* Server certificate: *.nodejs.org
* Server certificate: COMODO RSA Domain Validation Secure Server CA
* Server certificate: COMODO RSA Certification Authority
* Server certificate: AddTrust External CA Root
> HEAD /dist/ HTTP/1.1
> Host: nodejs.org
> User-Agent: curl/7.43.0
> Accept: */*
> Accept-Encoding: deflate, gzip
> 
< HTTP/1.1 200 OK
HTTP/1.1 200 OK
< Date: Thu, 27 Apr 2017 21:58:51 GMT
Date: Thu, 27 Apr 2017 21:58:51 GMT
< Content-Type: text/html
Content-Type: text/html
< Connection: keep-alive
Connection: keep-alive
< Set-Cookie: __cfduid=d1172ebbe328a61b78461a2980f24970c1493330331; expires=Fri, 27-Apr-18 21:58:51 GMT; path=/; domain=.nodejs.org; HttpOnly
Set-Cookie: __cfduid=d1172ebbe328a61b78461a2980f24970c1493330331; expires=Fri, 27-Apr-18 21:58:51 GMT; path=/; domain=.nodejs.org; HttpOnly
< CF-Cache-Status: HIT
CF-Cache-Status: HIT
< Vary: Accept-Encoding
Vary: Accept-Encoding
< Expires: Fri, 28 Apr 2017 01:58:51 GMT
Expires: Fri, 28 Apr 2017 01:58:51 GMT
< Cache-Control: public, max-age=14400
Cache-Control: public, max-age=14400
< Server: cloudflare-nginx
Server: cloudflare-nginx
< CF-RAY: 35650ba9dc3b1e77-SJC
CF-RAY: 35650ba9dc3b1e77-SJC
< Content-Encoding: gzip
Content-Encoding: gzip

< 
* Connection #0 to host nodejs.org left intact
➜  ~ 
```
</details>
",True,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/297857604,install script fails when username is different than root home directory,ljharb,7,224925160,2,297857604,0,224925160,2017-04-27T22:33:28Z,@compwron what does `echo $HOME` and `whoami` print out?,False,0,MEMBER
https://api.github.com/repos/nvm-sh/nvm/issues/comments/298094254,install script fails when username is different than root home directory,compwron,7,224925160,3,298094254,0,297857604,2017-04-28T20:06:05Z,"```
➜ echo $HOME 
/Users/lgoldste
➜  whoami
lgoldste
➜
 ```",False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/298117032,install script fails when username is different than root home directory,ljharb,7,224925160,4,298117032,0,298094254,2017-04-28T22:03:10Z,"@compwron ok, so then why is `$HOME` `/Users/lgoldstein/` and not `/Users/lgoldste/`?

What's `echo $NVM_DIR` output?",False,0,MEMBER
https://api.github.com/repos/nvm-sh/nvm/issues/comments/298117361,install script fails when username is different than root home directory,compwron,7,224925160,5,298117361,0,298117032,2017-04-28T22:05:12Z,"➜  echo $NVM_DIR
/Users/lgoldstein/.nvm

➜  echo $HOME
/Users/lgoldste
",False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/298117770,install script fails when username is different than root home directory,ljharb,7,224925160,6,298117770,0,298117361,2017-04-28T22:07:33Z,"@compwron is there any possibility that your username used to be `lgoldstein` (previously, or on another computer) such that `NVM_DIR` remained set to it in one of your profile files? Otherwise, I can't see how that would ever have been set in the first place.",False,0,MEMBER
https://api.github.com/repos/nvm-sh/nvm/issues/comments/298118609,install script fails when username is different than root home directory,compwron,7,224925160,7,298118609,0,298117770,2017-04-28T22:12:32Z,"My username did used to be lgoldstein but I didn't see it in my dotfiles but I went looking and it is there. Oops, my bad. Sorry! Thanks for the debugging help!

➜  ~ grep NVM_DIR .bashrc .bash_profile .zshrc

.bash_profile:export NVM_DIR=""/Users/lgoldstein/.nvm""

.bash_profile:[ -s ""$NVM_DIR/nvm.sh"" ] && . ""$NVM_DIR/nvm.sh""  # This loads
nvm

.zshrc:export NVM_DIR=""$HOME/.nvm""

.zshrc:[ -s ""$NVM_DIR/nvm.sh"" ] && . ""$NVM_DIR/nvm.sh"" # This loads nvm",False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/298118743,install script fails when username is different than root home directory,ljharb,7,224925160,8,298118743,0,298118609,2017-04-28T22:13:27Z,Glad we figured it out :-) Happy to reopen if that doesn't fix it.,False,0,MEMBER
https://api.github.com/repos/nvm-sh/nvm/issues/1522,Documentation for use in Docker container,ORESoftware,15,226122807,1,226122807,0,0,2017-05-03T21:39:22Z,"Not sure if using NVM in a Docker container is best practice, but should be the fastest way to get both npm and node installed? (Fastest if you don't use FROM node:7 or whatever, because you use a different image - a common scenario is needing both Java and Node, in my experience, so you have to pick, either `FROM java` or `FROM node`).

I have this in a Dockerfile

```bash
RUN curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.2/install.sh | bash
ENV NVM_DIR ""$HOME/.nvm""
RUN [ -s ""$NVM_DIR/nvm.sh"" ] && . ""$NVM_DIR/nvm.sh""   # exits with non-zero code
RUN nvm install 6
RUN nvm use 6
```

but the problem is that the third line exits with non zero code and I do not know why",True,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/299044759,Documentation for use in Docker container,ORESoftware,15,226122807,2,299044759,0,226122807,2017-05-03T21:45:04Z,"Since $HOME is just /root

then I have this:

```
RUN curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.2/install.sh | bash
RUN . /root/.nvm/nvm.sh
RUN nvm install 6
RUN nvm use 6
```
But for some reason, nvm is not recognized at the command line, so nvm install fails.

by the way I much prefer

`source nvm.sh`

instead of

`. nvm.sh`

I have been and will continue to rail against (stupid) shorthand for the rest of my life :)

Once I change it to `source`, it says the source command is not recognized...so maybe something about Docker may make this not feasible?",False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/299046593,Documentation for use in Docker container,ljharb,15,226122807,3,299046593,0,299044759,2017-05-03T21:53:15Z,"`.` is more portable than `source`, the one is not simple shorthand for the other in all shells.

Is your docker running a login shell? I don't use docker, so I'm not sure. What shell is it using?",False,0,MEMBER
https://api.github.com/repos/nvm-sh/nvm/issues/comments/299047316,Documentation for use in Docker container,ORESoftware,15,226122807,4,299047316,0,299046593,2017-05-03T21:56:46Z,"yeah that makes sense regarding `.` vs. `source`.

Docker uses 

`/bin/sh -c `

to execute commands",False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/299048293,Documentation for use in Docker container,ljharb,15,226122807,5,299048293,0,299047316,2017-05-03T22:01:34Z,"ok. so that's normal `sh` (which doesn't have `source` at all, so you must use `.`).

You'd need `-/bin/sh -c` or `/bin/sh -c --login`, iirc, to get a login shell.",False,0,MEMBER
https://api.github.com/repos/nvm-sh/nvm/issues/comments/299048367,Documentation for use in Docker container,ljharb,15,226122807,6,299048367,0,299048293,2017-05-03T22:01:55Z,"Separately, does docker open a new shell for every ""RUN"" command? if so, you'd need to source nvm.sh in *any* command that uses nvm.",False,0,MEMBER
https://api.github.com/repos/nvm-sh/nvm/issues/comments/299049527,Documentation for use in Docker container,ORESoftware,15,226122807,7,299049527,0,299048367,2017-05-03T22:07:40Z,"ah yes, maybe that's the case, let me try it",False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/305523757,Documentation for use in Docker container,webguywalker,15,226122807,8,305523757,0,299049527,2017-06-01T15:10:21Z,"**In addition:**
I went down the same path as @ORESoftware in setting ENV and separate RUNs

**Tested and Worked:**
```
RUN curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.2/install.sh | bash
RUN . /root/.nvm/nvm.sh && nvm --version
```
👍 

Simple Note in the README.md on ""Documentation for use in Docker Image"" would save anyone a few minutes and be pretty helpful.",False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/305578829,Documentation for use in Docker container,ORESoftware,15,226122807,9,305578829,0,305523757,2017-06-01T18:26:18Z,I will submit a PR for this,False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/305587214,Documentation for use in Docker container,webguywalker,15,226122807,10,305587214,0,305578829,2017-06-01T18:57:17Z,"@ORESoftware - I actually ended up just installing Node directly (old fashion way ;) ), I saw something funky that I didn't have time to debug this morning, for sake of discussion and helpful PR

- build is successful
- nvm is on the container
- node version files added `stat /bin/versions/node/v8.0.0/` and its really there
but nvm's reference to node is ""broken"" after jumping in the container 

**Test Dockerfile:**
```
FROM ubuntu:14.04

RUN apt-get update
RUN apt-get -y install curl
RUN curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.2/install.sh | bash

RUN . /root/.nvm/nvm.sh && nvm install v8
```

**Build Image:**
`docker build -t test:node_nvm .`

**Enter Container:**
`docker run -it --name ""jimmy"" test:node_nvm bash`

**Run: (`nvm ls`)**
```
root@44a98d6fc128:/# nvm ls
            N/A
node -> stable (-> N/A) (default)
iojs -> N/A (default)
```
nvm loss reference to node

**More Info:**
```
root@49f3abde31c4:/# env | grep -Ei ""nvm|home|path|term""
NVM_RC_VERSION=
NVM_CD_FLAGS=
TERM=xterm
NVM_DIR=/root/.nvm
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
HOME=/root
```

**Image should of had:**
```
root@118f68c41ac4:/# nvm install v8 && nvm ls
......
default -> v8 (-> v8.0.0)
node -> stable (-> v8.0.0) (default)
stable -> 8.0 (-> v8.0.0) (default)
iojs -> N/A (default)
lts/* -> lts/boron (-> N/A)
lts/argon -> v4.8.3 (-> N/A)
lts/boron -> v6.10.3 (-> N/A)
```
i'll circle back on a solution a little later

",False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/305595387,Documentation for use in Docker container,ORESoftware,15,226122807,11,305595387,0,305587214,2017-06-01T19:26:54Z,"good work yeah I think it's important to have clear directions on how to use NVM in Docker. Many people will use FROM X where is X is not node...and in that case will need any easy way to install node.js on the image, especially 1 particular version with Node.js...thus NVM.",False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/355725501,Documentation for use in Docker container,maackle,15,226122807,12,355725501,0,305595387,2018-01-06T05:47:43Z,"@webguywalker I'm seeing the same problem, the `nvm install` during the Dockerfile build doesn't seem to ""stick"" once you hop inside the container. Did you find a solution?",False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/356636689,Documentation for use in Docker container,webguywalker,15,226122807,13,356636689,0,355725501,2018-01-10T15:29:30Z,"@maackle - hey looked at it and just realized it was installing in an undesired directory
```
Step 6/7 : RUN . /root/.nvm/nvm.sh && nvm install v8 && which node
 ...
/.nvm/versions/node/v8.9.4/bin/node
```

**Setting the NVM_DIR sorted it out** 
`ENV NVM_DIR=/root/.nvm`
> chose ""/root"" only because this is test, use at your own discretion

**Sample Dockerfile**
```
FROM ubuntu:xenial

RUN apt-get update
RUN apt-get -y install curl
RUN curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.2/install.sh | bash

ENV NVM_DIR=/root/.nvm
RUN . /root/.nvm/nvm.sh && nvm install v8
```

**Note:**
>use at your own discretion
This is just an example Dockerfile, I personally would add add nvm as a user/group and then add root to the group or the user running the main processes the ""box"". [Here is a start](https://github.com/creationix/nvm/blob/master/Dockerfile#L73-L100) for keeping nvm locked down in terms of permissions

cc: @ORESoftware @maackle ",False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/356638463,Documentation for use in Docker container,webguywalker,15,226122807,14,356638463,0,356636689,2018-01-10T15:35:14Z,**Ref:** https://github.com/creationix/nvm/pull/1542,False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/356698970,Documentation for use in Docker container,maackle,15,226122807,15,356698970,0,356638463,2018-01-10T18:49:18Z,Yes I had the same problem @webguywalker! And I used the same solution. I wonder if there's a better way than hardcoding the home directory but maybe not.,False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/357056734,Documentation for use in Docker container,webguywalker,15,226122807,16,357056734,0,356698970,2018-01-11T20:48:59Z,"@maackle - I was close but couldn't figure it out

**Roadblocks:**
- `${PATH}` doesn't really expand well in the Dockerfile
- NVM dynamically updates the the PATH to switch node version

**As far as I was able to get:**
> 1. got suck on the ENTRYPOINT & CMD
> 2. even tried to update .bashrc
```
FROM ubuntu:xenial

RUN apt-get update
RUN apt-get -y install curl

# Add user ""nvm"" as non-root user w/ sudo privileges
RUN useradd -ms /bin/bash nvm
RUN echo 'nvm ALL=(ALL) NOPASSWD: ALL' >> /etc/sudoers
USER nvm
RUN curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.2/install.sh | bash
ENV NVM_DIR=/home/nvm/.nvm
RUN . /home/nvm/.nvm/nvm.sh && nvm install v8 && which node && ls -alh /home/nvm/.nvm/
RUN ls -alh /home/nvm/.nvm/

# Add Desired user to `nvm` group
USER root
RUN adduser root nvm

ENTRYPOINT ['/bin/bash', '-c', '. /home/nvm/.nvm/nvm.sh']
#RUN echo "". /home/nvm/.nvm/nvm.sh"" >> /root/.bashrc
```

",False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/1524,nvm.sh does not do anything,phil123456,18,227599044,1,227599044,0,0,2017-05-10T08:11:15Z,"I installed node js with nvm but now I cant get it to work again

I finaly found that the bashrc lines were not executed when I was taking a session on the machine

[ -s ""$NVM_DIR/nvm.sh"" ] && . ""$NVM_DIR/nvm.sh"" had to be manualy executed

```
$ nvm
-bash: nvm: command not found

$ .nvm/nvm.sh 

$ .nvm/nvm.sh debug

$ [ -s ""$NVM_DIR/nvm.sh"" ] && . ""$NVM_DIR/nvm.sh""

$ nvm

Node Version Manager

Note: <version> refers to any version-like string nvm understands. This includes:
  - full or partial version numbers, starting with an optional ""v"" (0.10, v0.1.2, v1)
  - default (built-in) aliases: node, stable, unstable, iojs, system
  - custom aliases you define with `nvm alias foo`

...

```

- How did you install `nvm`? (e.g. install script in readme, homebrew):

this used to work :

```
wget https://raw.githubusercontent.com/creationix/nvm/v0.32.0/install.sh
bash install.sh
chmod +x .nvm/nvm.sh 
nvm ls-remote
 
nvm install 6.10.1

```
",True,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/300525557,nvm.sh does not do anything,ljharb,18,227599044,2,300525557,0,227599044,2017-05-10T15:47:24Z,nvm.sh is not executable and should not be given +x. It should be *sourced* with `.`.,False,0,MEMBER
https://api.github.com/repos/nvm-sh/nvm/issues/comments/300687336,nvm.sh does not do anything,phil123456,18,227599044,3,300687336,0,300525557,2017-05-11T05:37:37Z,"- many examples show nvm as a command

- as mentioned above, once [ -s ""$NVM_DIR/nvm.sh"" ] && . ""$NVM_DIR/nvm.sh"" is ran, then nvm command is accessible

",False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/300690576,nvm.sh does not do anything,ljharb,18,227599044,4,300690576,0,300687336,2017-05-11T05:59:13Z,"`nvm` is a command. `nvm.sh` is not, it's a file that, when sourced, provides `nvm` as a shell function.

Indeed, `. ""$NVM_DIR/nvm.sh""` (which does not require the file to be executable) is correct, which is what all the examples and documentation states. The `chmod` command was not necessary before, and in your original post, `.nvm/nvm.sh` should be `. .nvm/nvm.sh` (note the `.` and space before it).",False,0,MEMBER
https://api.github.com/repos/nvm-sh/nvm/issues/comments/300730898,nvm.sh does not do anything,phil123456,18,227599044,5,300730898,0,300690576,2017-05-11T09:10:39Z," [ -s ""$NVM_DIR/nvm.sh"" ] && . ""$NVM_DIR/nvm.sh"" is in the bashrc so it should be executed
I should not have to launch it manualy

after the ""nvm"" works, no need for ""source"" or anything

this one show examples of nvm without needing to use source : https://www.digitalocean.com/community/tutorials/how-to-install-node-js-on-debian-8

they source ./profile but not nvm",False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/300799820,nvm.sh does not do anything,ljharb,18,227599044,6,300799820,0,300730898,2017-05-11T14:05:40Z,"Ah, ok - so the confusion about sourcing and executing nvm.sh is a red herring; you're saying that the problem is that `nvm` is not available when you open a new shell after running the install script?",False,0,MEMBER
https://api.github.com/repos/nvm-sh/nvm/issues/comments/300992481,nvm.sh does not do anything,phil123456,18,227599044,7,300992481,0,300799820,2017-05-12T06:11:34Z,yes,False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/300993062,nvm.sh does not do anything,ljharb,18,227599044,8,300993062,0,300992481,2017-05-12T06:16:03Z,"Have you tried the troubleshooting and ""manual install"" steps in the readme?

Could you fill out the issue template, including `nvm debug` output?",False,0,MEMBER
https://api.github.com/repos/nvm-sh/nvm/issues/comments/301709347,nvm.sh does not do anything,phil123456,18,227599044,9,301709347,0,300993062,2017-05-16T08:15:15Z,"```
nvm --version: v0.32.0
$SHELL: /bin/bash
$HOME: /home/eradmin
$NVM_DIR: '$HOME/.nvm'
$PREFIX: ''
$NPM_CONFIG_PREFIX: ''
nvm current: v6.10.3
which node: $NVM_DIR/versions/node/v6.10.3/bin/node
which iojs: 
which npm: $NVM_DIR/versions/node/v6.10.3/bin/npm
npm config get prefix: $NVM_DIR/versions/node/v6.10.3
npm root -g: $NVM_DIR/versions/node/v6.10.3/lib/node_modules
```",False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/301902355,nvm.sh does not do anything,ljharb,18,227599044,10,301902355,0,301709347,2017-05-16T20:16:34Z,"@phil123456 do you have any nvm-related lines in `~/.bashrc`, `~/.bash_profile`, or `~/.profile`?",False,0,MEMBER
https://api.github.com/repos/nvm-sh/nvm/issues/comments/301990751,nvm.sh does not do anything,phil123456,18,227599044,11,301990751,0,301902355,2017-05-17T05:37:52Z,"```sh
export NVM_DIR=""/home/******/.nvm""
[ -s ""$NVM_DIR/nvm.sh"" ] && . ""$NVM_DIR/nvm.sh""  # This loads nvm
```",False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/301991540,nvm.sh does not do anything,ljharb,18,227599044,12,301991540,0,301990751,2017-05-17T05:43:51Z,And which file is that in?,False,0,MEMBER
https://api.github.com/repos/nvm-sh/nvm/issues/comments/302030677,nvm.sh does not do anything,phil123456,18,227599044,13,302030677,0,301991540,2017-05-17T09:04:17Z,.bashrc,False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/302228353,nvm.sh does not do anything,ljharb,18,227599044,14,302228353,0,302030677,2017-05-17T20:53:14Z,"If you run `nvm alias default node`, and then open a new terminal, does that solve the issue?",False,0,MEMBER
https://api.github.com/repos/nvm-sh/nvm/issues/comments/302710207,nvm.sh does not do anything,phil123456,18,227599044,15,302710207,0,302228353,2017-05-19T13:58:40Z,"no

```
nvm alias default node
default -> node (-> v6.10.3)
```

then I open anew ssh connection to the box

```
nvm

command not found

```

but the first line of bashrc says, so maybe the nvm setup lines should be put somewhere else ... like rclocal or something ?

`# ~/.bashrc: executed by bash(1) for non-login shells.`
",False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/302844986,nvm.sh does not do anything,ljharb,18,227599044,16,302844986,0,302710207,2017-05-20T02:24:49Z,"ahhh - yes, when you ssh in, you need to specify `-l` so it starts a login shell.",False,0,MEMBER
https://api.github.com/repos/nvm-sh/nvm/issues/comments/303002363,nvm.sh does not do anything,phil123456,18,227599044,17,303002363,0,302844986,2017-05-22T05:26:56Z,"then why not add those lines to .bash_profile upon installation ?

maybe it would be nice to add it to the installation process",False,0,NONE
https://api.github.com/repos/nvm-sh/nvm/issues/comments/303006245,nvm.sh does not do anything,ljharb,18,227599044,18,303006245,0,303002363,2017-05-22T05:59:24Z,I'm not sure what you mean - the install script automatically adds those lines to one of your profile files. The expectation is that `nvm` will only ever be used on a login shell - it's on you to create one when sshing in.,False,0,MEMBER
https://api.github.com/repos/nvm-sh/nvm/issues/comments/303070687,nvm.sh does not do anything,phil123456,18,227599044,19,303070687,0,303006245,2017-05-22T11:12:34Z,ok,False,0,NONE
https://api.github.com/repos/coleifer/peewee/issues/1284,Facilitate case insensitive searches,Naatan,4,231424375,1,231424375,0,0,2017-05-25T18:44:59Z,"The docs state:

> LIKE and ILIKE with SQLite
> Because SQLite’s LIKE operation is case-insensitive by default, peewee will use the SQLite GLOB operation for case-sensitive searches. The glob operation uses asterisks for wildcards as opposed to the usual percent-sign. If you are using SQLite and want case-sensitive partial string matching, remember to use asterisks for the wildcard.

Unfortunately it does not touch on the not at all unlikely scenario of wanting to do case insensitive LIKE queries. It would be nice if peewee touched in its docs, ideally facilitating it, otherwise just stating that you should use `SQL()`.",True,0,NONE
https://api.github.com/repos/coleifer/peewee/issues/comments/304129758,Facilitate case insensitive searches,coleifer,4,231424375,2,304129758,0,231424375,2017-05-25T21:28:13Z,For case-insensitive LIKE you would just use ILIKE.,False,0,OWNER
https://api.github.com/repos/coleifer/peewee/issues/comments/304131075,Facilitate case insensitive searches,Naatan,4,231424375,3,304131075,0,304129758,2017-05-25T21:34:18Z,"You should make that clearer in the docs, this currently isn't evident.",False,0,NONE
https://api.github.com/repos/coleifer/peewee/issues/comments/304131644,Facilitate case insensitive searches,coleifer,4,231424375,4,304131644,0,304131075,2017-05-25T21:37:09Z,ILIKE is called ILIKE because it's case-insensitive.,False,0,OWNER
https://api.github.com/repos/coleifer/peewee/issues/comments/304131936,Facilitate case insensitive searches,Naatan,4,231424375,5,304131936,0,304131644,2017-05-25T21:38:44Z,"I get that now, but that's not self-evident. And it's not something you can search the docs for because nowhere does it say the word ""insensitive"".",False,0,NONE
https://api.github.com/repos/coleifer/peewee/issues/1291,Inspecting query column names,josePhoenix,3,235304957,1,235304957,0,0,2017-06-12T17:29:07Z,"I have some code that spits out an HTML table from some query results:

```python
    <table>
      <tr>{% for column in columns %}<th>{{ column }}</th>{% endfor %}<th>
    {% for result in results %}
      <tr>{% for column in columns %}<td>{{ result[column] }}</td>{% endfor %}</tr>
    {% endfor %}
    </table>
```

The best way I've found so far to get the `columns` from the query is:

```
results = query.execute()
first_row = results.next()
columns = first_row._meta.sorted_field_names
```

Is there a better way? (Incidentally, it's surprising to me that `list(results)` acts the same whether or not I call `results.next()`...)",True,0,NONE
https://api.github.com/repos/coleifer/peewee/issues/comments/307917435,Inspecting query column names,coleifer,3,235304957,2,307917435,0,235304957,2017-06-12T20:40:27Z,"This type of question is more appropriate to stackoverflow.

However...when you create a query, you necessarily know what columns are being selected. So how can there be a problem?",False,0,OWNER
https://api.github.com/repos/coleifer/peewee/issues/comments/307935542,Inspecting query column names,josePhoenix,3,235304957,3,307935542,0,307917435,2017-06-12T21:33:00Z,"Because you may want to write your code in such a way that it can be reused without passing the names of columns explicitly, especially because this information is already part of the results object.

It appears that you get a different API depending on whether speedups are enabled. With speedups disabled, there is a `column_meta` attribute on peewee.NaiveQueryResultWrapper that exposes all the metadata.

```
>>> type(results)
<class 'peewee.NaiveQueryResultWrapper'>
>>> for f in results.column_meta: print(f.name)
obsid
pi_last_name
obs_date
exptime
```",False,0,NONE
https://api.github.com/repos/coleifer/peewee/issues/comments/309140011,Inspecting query column names,coleifer,3,235304957,4,309140011,0,307935542,2017-06-16T21:37:50Z,"> Because you may want to write your code in such a way that it can be reused without passing the names of columns explicitly, especially because this information is already part of the results object.

I definitely get that...especially in a template, like your example.

I've updated the speedups module to expose the column_meta attribute, see f11802807f5e05dddeb32f93b8c84703b49bb498",False,0,OWNER
https://api.github.com/repos/coleifer/peewee/issues/1292,there is two foreign keys in table A related to table B，how can I get table B's columns within one query?,linxi-1214,4,236113683,1,236113683,0,0,2017-06-15T08:26:57Z,"TABLE contract: 

column | type | constraint
------- | -----|  ------
id | int | primary key
contract_no | int | unique
customer| int | Foreign key to Table User
salesman | int | Foreign key to Table User

Table User:

column | type | constraint
------- | ---- | ------
id | int | Primary key
name| varchar | 

I want to get contract_no, customer's name , salesman's name in one query?

I have saw the section ""avoid N+1 querying"", so my expression is \:

```python
Customer = User.alias()
Salesman = User.alias()

contracts = (Contract
           .select(Contract, Customer.name, Salesman.name)
           .join(Customer, on=(Contract.customer == Customer.id))
           .join(Salesman, JOIN.LEFT_OUTER, on=(Contract.salesman == Salesman.id))
           .where(Contract.customer == 1)
           )
``` 

I wonder whether it's right or not?",True,0,NONE
https://api.github.com/repos/coleifer/peewee/issues/comments/308778186,there is two foreign keys in table A related to table B，how can I get table B's columns within one query?,coleifer,4,236113683,2,308778186,0,236113683,2017-06-15T15:45:25Z,"Yeah actually that looks good! You can verify by turning query logging on:

```python
import logging
logger = logging.getLogger('peewee')
logger.addHandler(logging.StreamHandler())
logger.setLevel(logging.DEBUG)
```",False,0,OWNER
https://api.github.com/repos/coleifer/peewee/issues/comments/308926826,there is two foreign keys in table A related to table B，how can I get table B's columns within one query?,linxi-1214,4,236113683,3,308926826,0,308778186,2017-06-16T03:58:01Z,"I got the query log as the way you told me, and the log are as below
__Note: This happened when I fetch both contract.customer.name and contract.salesman.name .  And just the first query executed if I only fetch the contract.customer.name .__

```sql
--------------------------------------------------------------------------------
('SELECT `t1`.`id`, `t1`.`contract_no`, `t1`.`customer_id`, `t1`.`salesman_id`, `t1`.`total_price`, `t1`.`is_internal`, `t1`.`company`, `t1`.`project`, `t1`.`sign_time`, `t1`.`effective_time`, `t1`.`expired_time`, `t1`.`notes`, `t1`.`timestamp`, `t2`.`username`, `t2`.`mphone`, `t3`.`username` FROM `t_contract` AS t1 INNER JOIN `t_user` AS t2 ON (`t1`.`customer_id` = `t2`.`id`) LEFT OUTER JOIN `t_user` AS t3 ON (`t1`.`salesman_id` = `t3`.`id`) WHERE (`t1`.`customer_id` = %s)', [u'1'])
('SELECT `t1`.`id`, `t1`.`username`, `t1`.`role_id`, `t1`.`email`, `t1`.`mphone`, `t1`.`is_disable`, `t1`.`is_admin`, `t1`.`is_enterprise`, `t1`.`credits`, `t1`.`created_time`, `t1`.`updated_time` FROM `t_user` AS t1 WHERE (`t1`.`id` = %s) LIMIT 1', [u'345'])
('SELECT `t1`.`id`, `t1`.`username`, `t1`.`role_id`, `t1`.`email`, `t1`.`mphone`, `t1`.`is_disable`, `t1`.`is_admin`, `t1`.`is_enterprise`, `t1`.`credits`, `t1`.`created_time`, `t1`.`updated_time` FROM `t_user` AS t1 WHERE (`t1`.`id` = %s) LIMIT 1', [u'346'])
('SELECT `t1`.`id`, `t1`.`username`, `t1`.`role_id`, `t1`.`email`, `t1`.`mphone`, `t1`.`is_disable`, `t1`.`is_admin`, `t1`.`is_enterprise`, `t1`.`credits`, `t1`.`created_time`, `t1`.`updated_time` FROM `t_user` AS t1 WHERE (`t1`.`id` = %s) LIMIT 1', [u'345'])
('SELECT `t1`.`id`, `t1`.`username`, `t1`.`role_id`, `t1`.`email`, `t1`.`mphone`, `t1`.`is_disable`, `t1`.`is_admin`, `t1`.`is_enterprise`, `t1`.`credits`, `t1`.`created_time`, `t1`.`updated_time` FROM `t_user` AS t1 WHERE (`t1`.`id` = %s) LIMIT 1', [u'345'])
('SELECT `t1`.`id`, `t1`.`username`, `t1`.`role_id`, `t1`.`email`, `t1`.`mphone`, `t1`.`is_disable`, `t1`.`is_admin`, `t1`.`is_enterprise`, `t1`.`credits`, `t1`.`created_time`, `t1`.`updated_time` FROM `t_user` AS t1 WHERE (`t1`.`id` = %s) LIMIT 1', [u'345'])
('SELECT `t1`.`id`, `t1`.`username`, `t1`.`role_id`, `t1`.`email`, `t1`.`mphone`, `t1`.`is_disable`, `t1`.`is_admin`, `t1`.`is_enterprise`, `t1`.`credits`, `t1`.`created_time`, `t1`.`updated_time` FROM `t_user` AS t1 WHERE (`t1`.`id` = %s) LIMIT 1', [u'345'])
('SELECT `t1`.`id`, `t1`.`username`, `t1`.`role_id`, `t1`.`email`, `t1`.`mphone`, `t1`.`is_disable`, `t1`.`is_admin`, `t1`.`is_enterprise`, `t1`.`credits`, `t1`.`created_time`, `t1`.`updated_time` FROM `t_user` AS t1 WHERE (`t1`.`id` = %s) LIMIT 1', [u'345'])
('SELECT `t1`.`id`, `t1`.`username`, `t1`.`role_id`, `t1`.`email`, `t1`.`mphone`, `t1`.`is_disable`, `t1`.`is_admin`, `t1`.`is_enterprise`, `t1`.`credits`, `t1`.`created_time`, `t1`.`updated_time` FROM `t_user` AS t1 WHERE (`t1`.`id` = %s) LIMIT 1', [u'345'])
('SELECT `t1`.`id`, `t1`.`username`, `t1`.`role_id`, `t1`.`email`, `t1`.`mphone`, `t1`.`is_disable`, `t1`.`is_admin`, `t1`.`is_enterprise`, `t1`.`credits`, `t1`.`created_time`, `t1`.`updated_time` FROM `t_user` AS t1 WHERE (`t1`.`id` = %s) LIMIT 1', [u'345'])
('SELECT `t1`.`id`, `t1`.`username`, `t1`.`role_id`, `t1`.`email`, `t1`.`mphone`, `t1`.`is_disable`, `t1`.`is_admin`, `t1`.`is_enterprise`, `t1`.`credits`, `t1`.`created_time`, `t1`.`updated_time` FROM `t_user` AS t1 WHERE (`t1`.`id` = %s) LIMIT 1', [u'345'])
```

I got N+1 queries",False,0,NONE
https://api.github.com/repos/coleifer/peewee/issues/comments/308948231,there is two foreign keys in table A related to table B，how can I get table B's columns within one query?,linxi-1214,4,236113683,4,308948231,0,308926826,2017-06-16T06:50:56Z,"Finally I resolved this problem by Calling the SelectQuery instance's method `dicts()`.

``` python
        Customer = User.alias()
        Salesman = User.alias()

        contracts = (Contract
                     .select(Contract.id,
                             Contract.contract_no,
                             Contract.total_price,
                             Contract.company,
                             Contract.project,
                             Contract.sign_time,
                             Contract.is_internal,
                             Customer.mphone,
                             Customer.name.alias('customer_name'),
                             Salesman.name.alias('salesman_name')
                             )
                     .join(Customer, on=(Contract.customer == Customer.id))
                     .join(Salesman, JOIN.LEFT_OUTER, on=(Contract.salesman == Salesman.id))
                     .where(Contract.customer == user_id)
                     )
       for contract in contracts.dicts():
             contract.get('salesman_name')
             contract.get('customer_name')
```

Is there a cool way ?",False,0,NONE
https://api.github.com/repos/coleifer/peewee/issues/comments/309033644,there is two foreign keys in table A related to table B，how can I get table B's columns within one query?,coleifer,4,236113683,5,309033644,0,308948231,2017-06-16T14:00:34Z,"Ahh shit I missed something in your initial query. In order to access related models, you will need to assign an alias to the join predicate. Additionally, after joining on Customer you need to switch the join context back to Contract so that when you join on Salesman peewee knows how to reconstruct the model graph. This code works as expected:

```python
contracts = (Contract
             .select(Contract, Customer.name, Salesman.name)
             .join(Customer,
                   on=(Contract.customer == Customer.id).alias('customer'))
             .switch(Contract)
             .join(Salesman,
                   on=(Contract.salesman == Salesman.id).alias('salesman'))
             .order_by(Contract.contract_no))
for contract in contracts:
    print contract.contract_no, contract.customer.name, contract.salesman.name
```",False,0,OWNER
https://api.github.com/repos/coleifer/peewee/issues/1294,Checking record exist,kadnan,5,236345089,1,236345089,0,0,2017-06-15T23:56:58Z,"I know about exception thrown in this regard, just want to know whether there's some `count` or `exists()` method to check whether some record returned or not?",True,0,NONE
https://api.github.com/repos/coleifer/peewee/issues/comments/308923129,Checking record exist,coleifer,5,236345089,2,308923129,0,236345089,2017-06-16T03:26:24Z,"ffs man documentation

* http://docs.peewee-orm.com/en/latest/peewee/api.html#SelectQuery.exists
* http://docs.peewee-orm.com/en/latest/peewee/api.html#SelectQuery.count",False,0,OWNER
https://api.github.com/repos/coleifer/peewee/issues/comments/432980653,Checking record exist,dsmurrell,5,236345089,3,432980653,0,308923129,2018-10-25T09:28:23Z,I was searching for the same thing (I don't usually RTFM right away either). Just to let you know that your links don't take you to the right place on the page as I assume the # is supposed to do.,False,0,NONE
https://api.github.com/repos/coleifer/peewee/issues/comments/433029195,Checking record exist,coleifer,5,236345089,4,433029195,0,432980653,2018-10-25T12:21:57Z,"* http://docs.peewee-orm.com/en/latest/peewee/api.html#SelectBase.exists
* http://docs.peewee-orm.com/en/latest/peewee/api.html#SelectBase.count

tl/dr

```python

query = User.select().where(User.username == 'reads-the-manual')
if query.exists():
    print('there are %s users who %s' (query.count(), 'read the manual'))
```",False,0,OWNER
https://api.github.com/repos/coleifer/peewee/issues/comments/778749038,Checking record exist,kadnan,5,236345089,5,778749038,0,433029195,2021-02-14T09:05:07Z,Funny thing is that I had to google something similar after 4 years and I found my own opened issue 😆 ,False,0,NONE
https://api.github.com/repos/coleifer/peewee/issues/comments/778783307,Checking record exist,coleifer,5,236345089,6,778783307,0,778749038,2021-02-14T14:10:48Z,Hell yeah. I've had that happen once or twice myself.,False,0,OWNER
https://api.github.com/repos/ansible/ansible/issues/26178,added instance type to output,Constantin07,4,239122479,1,239122479,0,0,2017-06-28T10:38:09Z,"##### SUMMARY
This PR fixes issue reported in #26176

##### ISSUE TYPE
 - Bugfix Pull Request

##### COMPONENT NAME
ansible/lib/ansible/modules/cloud/amazon/ec2_remote_facts.py

##### ANSIBLE VERSION

```
ansible 2.4.0
  config file = /etc/ansible/ansible.cfg
  configured module search path = [u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/lib/python2.7/site-packages/ansible
  executable location = /usr/bin/ansible
  python version = 2.7.5 (default, Nov  6 2016, 00:28:07) [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)]
```


##### ADDITIONAL INFORMATION
Now instance type is included in the output.

```
ok: [localhost] => {
    ""failed"": false,
    ""instance_res"": {
        ""changed"": false,
        ""failed"": false,
        ""instances"": [
            {
                ""ami_launch_index"": ""0"",
                ""architecture"": ""x86_64"",
                ""block_device_mapping"": [
                    {
                        ""attach_time"": ""2017-02-07T10:35:18.000Z"",
                        ""delete_on_termination"": true,
                        ""device_name"": ""/dev/sda1"",
                        ""status"": ""attached"",
                        ""volume_id"": ""vol-01f17b3af6b399bf9""
                    }
                ],
                ""client_token"": ""AVDmz1496463717033"",
                ""ebs_optimized"": false,
                ""groups"": [
                    {
                        ""id"": ""sg-f203cf94"",
                        ""name"": ""CHR1QVBY2P4P""
                    },
                    {
                        ""id"": ""sg-fe03cf98"",
                        ""name"": ""A2429UBEAMN2""
                    }
                ],
                ""hypervisor"": ""xen"",
                ""id"": ""i-01d7c3b14f3b47b17"",
                ""image_id"": ""ami-3d51d3fe"",
                ""instance_profile"": null,
                ""instance_type"": ""t2.small"",
                ""interfaces"": [
                    {
                        ""id"": ""eni-9f96a633"",
                        ""mac_address"": ""02:33:e0:28:15:15""
                    }
                ],
                ""kernel"": null,
                ""key_name"": ""ky"",
                ""launch_time"": ""2017-02-08T11:31:38.000Z"",
                ""monitoring_state"": ""disabled"",
                ""persistent"": false,
                ""placement"": {
                    ""tenancy"": ""default"",
                    ""zone"": ""eu-west-1a""
                },
                ""private_dns_name"": ""ip-10-216-128-180.example.com"",
                ""private_ip_address"": ""10.176.128.181"",
                ""public_dns_name"": """",
                ""public_ip_address"": null,
                ""ramdisk"": null,
                ""region"": ""eu-west-1"",
                ""requester_id"": null,
                ""root_device_type"": ""ebs"",
                ""source_destination_check"": ""true"",
                ""spot_instance_request_id"": null,
                ""state"": ""stopped"",
                ""tags"": {
                    ""Environment"": ""DEV""
                },
                ""virtualization_type"": ""hvm"",
                ""vpc_id"": ""vpc-12cf5e4f""
            }
        ]
    }
}
```
",True,0,CONTRIBUTOR
https://api.github.com/repos/ansible/ansible/issues/comments/311656851,added instance type to output,ansibot,4,239122479,2,311656851,0,239122479,2017-06-28T13:17:13Z,"cc @willthames @michaeljs1990 @wimnat
[click here for bot help](https://github.com/ansible/ansibullbot/blob/master/ISSUE_HELP.md)
<!--- boilerplate: notify --->",False,0,CONTRIBUTOR
https://api.github.com/repos/ansible/ansible/issues/comments/311774232,added instance type to output,sergey-trukhin,4,239122479,3,311774232,0,311656851,2017-06-28T20:10:25Z,Looks like duplicate of [this PR](https://github.com/ansible/ansible/pull/26160),False,0,CONTRIBUTOR
https://api.github.com/repos/ansible/ansible/issues/comments/311812094,added instance type to output,wimnat,4,239122479,4,311812094,0,311774232,2017-06-28T22:39:52Z,This would also solve your problem https://github.com/ansible/ansible/pull/22937,False,0,CONTRIBUTOR
https://api.github.com/repos/ansible/ansible/issues/comments/328118395,added instance type to output,s-hertel,4,239122479,5,328118395,0,311812094,2017-09-08T14:29:04Z,Fixed in d1652ae.,False,0,CONTRIBUTOR
https://api.github.com/repos/ansible/ansible/issues/26181,apt: autoremove doesn't remove,SethosII,5,239163194,1,239163194,0,0,2017-06-28T13:25:37Z,"##### ISSUE TYPE
 - Bug Report

##### COMPONENT NAME
`apt` module

##### ANSIBLE VERSION
```
ansible 2.3.1.0
  config file = /home/paul/.ansible.cfg
  configured module search path = Default w/o overrides
  python version = 2.7.12 (default, Nov 19 2016, 06:48:10) [GCC 5.4.0 20160609]
```

##### CONFIGURATION
`cow_selection = tux` but nothing else ;)

##### OS / ENVIRONMENT
Ubuntu 16.04.2 for everything

##### SUMMARY
Using the `apt` module with only the `autoremove` option doesn't  remove anything allthough there are plenty of old packages.

##### STEPS TO REPRODUCE
<!--- Paste example playbooks or commands between quotes below -->
```yaml
- hosts: ""all""
  remote_user: ""paul""
  become: yes
  tasks:
    - name: ""test""
      apt:
        autoremove: yes
```

Then run with `ansible-playbook autoremove.yaml -i localhost,`.

##### EXPECTED RESULTS
```
 _____________
< TASK [test] >
 -------------
   \
    \
        .--.
       |o_o |
       |:_/ |
      //   \ \
     (|     | )
    /'\_   _/`\
    \___)=(___/


changed: [localhost]
```

(and all autoremovable packages removed)

##### ACTUAL RESULTS
```
 _____________
< TASK [test] >
 -------------
   \
    \
        .--.
       |o_o |
       |:_/ |
      //   \ \
     (|     | )
    /'\_   _/`\
    \___)=(___/


ok: [localhost]
```

verbose (`-vvvv`) output:

```
 _____________
< TASK [test] >
 -------------
   \
    \
        .--.
       |o_o |
       |:_/ |
      //   \ \
     (|     | )
    /'\_   _/`\
    \___)=(___/


task path: /home/paul/ansible/oneshot/maintenance.yaml:11
Using module file /usr/lib/python2.7/dist-packages/ansible/modules/packaging/os/apt.py
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: paul
<localhost> EXEC /bin/sh -c 'echo ~ && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p ""` echo /home/paul/.ansible/tmp/ansible-tmp-1498656125.19-167288942852198 `"" && echo ansible-tmp-1498656125.19-167288942852198=""` echo /home/paul/.ansible/tmp/ansible-tmp-1498656125.19-167288942852198 `"" ) && sleep 0'
<localhost> PUT /tmp/tmptD5FQy TO /home/paul/.ansible/tmp/ansible-tmp-1498656125.19-167288942852198/apt.py
<localhost> EXEC /bin/sh -c 'chmod u+x /home/paul/.ansible/tmp/ansible-tmp-1498656125.19-167288942852198/ /home/paul/.ansible/tmp/ansible-tmp-1498656125.19-167288942852198/apt.py && sleep 0'
<localhost> EXEC /bin/sh -c 'sudo -H -S -n -u root /bin/sh -c '""'""'echo BECOME-SUCCESS-wrefiaqbhytaaorhgcnytrlhopgjzhvt; /usr/bin/python /home/paul/.ansible/tmp/ansible-tmp-1498656125.19-167288942852198/apt.py; rm -rf ""/home/paul/.ansible/tmp/ansible-tmp-1498656125.19-167288942852198/"" > /dev/null 2>&1'""'""' && sleep 0'
ok: [localhost] => {
    ""cache_update_time"": 1498653337, 
    ""cache_updated"": false, 
    ""changed"": false, 
    ""invocation"": {
        ""module_args"": {
            ""allow_unauthenticated"": false, 
            ""autoremove"": true, 
            ""cache_valid_time"": 0, 
            ""deb"": null, 
            ""default_release"": null, 
            ""dpkg_options"": ""force-confdef,force-confold"", 
            ""force"": false, 
            ""install_recommends"": null, 
            ""only_upgrade"": false, 
            ""package"": null, 
            ""purge"": false, 
            ""state"": ""present"", 
            ""update_cache"": null, 
            ""upgrade"": null
        }
    }
}
META: ran handlers
META: ran handlers
```

See also https://github.com/ansible/ansible/issues/21472.",True,0,NONE
https://api.github.com/repos/ansible/ansible/issues/comments/312118530,apt: autoremove doesn't remove,resmo,5,239163194,2,312118530,0,239163194,2017-06-29T21:50:42Z,most likely fixed by 2af5556901f0847d835af60f58769a8dd94c4415,False,0,CONTRIBUTOR
https://api.github.com/repos/ansible/ansible/issues/comments/312251952,apt: autoremove doesn't remove,SethosII,5,239163194,3,312251952,0,312118530,2017-06-30T12:15:50Z,"I tried the specific commit https://github.com/ansible/ansible/commit/2af5556901f0847d835af60f58769a8dd94c4415 and the current development branch but found the same problem. How exactly am I supposed to ""build"" ansible? I tried with the bare files, `make`, and `python setup.py build`.",False,0,NONE
https://api.github.com/repos/ansible/ansible/issues/comments/312254260,apt: autoremove doesn't remove,resmo,5,239163194,4,312254260,0,312251952,2017-06-30T12:28:06Z,the easiest way is to git clone/git checkout the devel branch and run `source ./hacking/env-setup`. You then have ansible from devel in this terminal (for this session).,False,0,CONTRIBUTOR
https://api.github.com/repos/ansible/ansible/issues/comments/312279846,apt: autoremove doesn't remove,SethosII,5,239163194,5,312279846,0,312254260,2017-06-30T14:19:46Z,"Thanks, it worked with this setup and the development branch. In which release will the fix be included?

One odd thing is that it also reports `changed` when there was nothing removed. Is this intended/should I open a new issue for this?",False,0,NONE
https://api.github.com/repos/ansible/ansible/issues/comments/312295436,apt: autoremove doesn't remove,resmo,5,239163194,6,312295436,0,312279846,2017-06-30T15:17:17Z,"It will be in 2.4.0 once released. 

Yes, let's close this issue as resolved and create an new issue for anything else.

Thanks for your report!",False,0,CONTRIBUTOR
https://api.github.com/repos/ansible/ansible/issues/26182,Cannot default an undefined variable to another defined variable inside a dictionary,jean-christophe-manciot,7,239167786,1,239167786,0,0,2017-06-28T13:40:42Z,"##### ISSUE TYPE
- Bug Report

##### COMPONENT NAME

default filter

##### ANSIBLE VERSION

**Both latest stable & unstable** versions:
```
ansible 2.3.2.0 (detached HEAD 7424e1c417) last updated 2017/06/28 14:37:25 (GMT +200)
  config file = /etc/ansible/ansible.cfg
  configured module search path = [u'/home/actionmystique/Ansible/git-yang-networkop/ansible-101/library']
  python version = 2.7.13 (default, Jan 19 2017, 14:48:08) [GCC 6.3.0 20170118]

ansible 2.4.0 (devel a5b905c941) last updated 2017/06/28 15:03:00 (GMT +200)
  config file = /etc/ansible/ansible.cfg
  configured module search path = [u'/home/actionmystique/Ansible/git-yang-networkop/ansible-101/library']
  ansible python module location = /home/actionmystique/src/Ansible/git-ansible/lib/ansible
  executable location = /home/actionmystique/src/Ansible/git-ansible/bin/ansible
  python version = 2.7.13 (default, Jan 19 2017, 14:48:08) [GCC 6.3.0 20170118]
```
##### CONFIGURATION

inventory   = ./hosts
library        = /home/actionmystique/Ansible/git-yang-networkop/ansible-101/library
forks = 1000
gathering = explicit
gather_timeout = 30
roles_path = /home/actionmystique/Ansible/Roles/roles
private_role_vars = yes
hash_behaviour = merge
log_path = /var/log/ansible.log
retry_files_enabled = False
show_custom_stats = True
timeout = 60
pipelining = True
connect_timeout = 60
connect_retries = 30
connect_interval = 1

##### OS / ENVIRONMENT
- host: **Ubuntu 17.04 4.10**
- target: **IOS-XEv 16.5.1**

##### SUMMARY

The generic {{ undefined_variable | default(defined_variable) }} does not work inside a dictionary, although it follows what is described in this [post](https://github.com/ansible/ansible/issues/9867#issuecomment-67689161) from @bcoca in a slightly different context: dictionary vs inventory file.
Maybe the expected feature is not defined yet, in which case I can change this bug report into a feature request.

##### STEPS TO REPRODUCE

Structure passed as ""**provider**"": connections.ssh (the arrow is absent from the original dictionary)

```
connections
...
        ssh:
          transport: cli 
--------->host: ""{{ ansible_host | default(inventory_hostname) }}""
          # ansible_port
          port: 22
          # ansible_user
          username: admin
          # ansible_ssh_pass
          password: xxxxxxxxxxx
          authorize: yes
          # enable_secret_password
          auth_pass: xxxxxxxxxxx
          # private_key_file
          ssh_keyfile: ""~/.ssh/id_rsa""
          version: 2
          timeout: 10
```

**Role**: ios_push_config:

```
- include_vars: ""../defaults/{{ os_family }}/connections.yml""
  when: (connections is undefined)
...
- name: Pushing adapted config to remote node
  ios_config:
        provider: ""{{ connections.ssh }}""
        src: ""{{ role_path }}/templates/{{ inventory_hostname }}/startup-config.txt""
        save: yes
  register: result
```

**Playbook**:

```
- name: Pushing IOS/IOSv/IOSv-L2/IOS-XE/IOS-XEv configs
  hosts:
    - ios
    - iosv
    - iosv_l2
    - ios_xe
    - ios_xev
  gather_facts: no
  roles:
    - ios_push_config
```

##### EXPECTED RESULTS

inventory_hostname should be used instead of the undefined ansible_host in ""connections.yml"" & startup configurations should be pushed to the target nodes.

##### ACTUAL RESULTS: Log

```
...
/ TASK [ios_push_config : Pushing adapted config to remote \
\ node]                                                    /
 ----------------------------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

task path: /home/actionmystique/Ansible/Roles/roles/ios_push_config/tasks/main.yml:79
fatal: [XEv_Spine_11]: FAILED! => {
    ""failed"": true, 
    ""msg"": ""the field 'connection' has an invalid value, which appears to include a variable that is undefined.The error was: {u'protocol': u'ssh', u'xeapi': {u'username': u'admin', u'authorize': True, u'auth_pass': u'Cisco2016$', u'host': u'{{ ansible_host }}', u'use_ssl': False, u'password': u'Cisco2016$', u'port': 80, u'transport': u'xeapi'}, u'compute': u'local', u'target': u'cisco', u'ssh': {u'username': u'admin', u'authorize': True, u'ssh_keyfile': u'~/.ssh/id_rsa', u'auth_pass': u'Cisco2016$', u'host': u'{{ ansible_host | default(inventory_hostname) }', u'version': 2, u'timeout': 60, u'password': u'Cisco2016$', u'port': 22, u'transport': u'cli'}}: 'ansible_host' is undefined\nexception type: <class 'ansible.errors.AnsibleUndefinedVariable'>\nexception: {u'protocol': u'ssh', u'xeapi': {u'username': u'admin', u'authorize': True, u'auth_pass': u'Cisco2016$', u'host': u'{{ ansible_host }}', u'use_ssl': False, u'password': u'Cisco2016$', u'port': 80, u'transport': u'xeapi'}, u'compute': u'local', u'target': u'cisco', u'ssh': {u'username': u'admin', u'authorize': True, u'ssh_keyfile': u'~/.ssh/id_rsa', u'auth_pass': u'Cisco2016$', u'host': u'{{ ansible_host | default(inventory_hostname) }', u'version': 2, u'timeout': 60, u'password': u'Cisco2016$', u'port': 22, u'transport': u'cli'}}: 'ansible_host' is undefined""
}
...
```
##### ACTUAL RESULTS: Successful Manual SSH with inventory_hostname content
```
# ssh admin@XEv_Spine_11
CC
**************************************************************************
* IOSv is strictly limited to use for evaluation, demonstration and IOS  *
* education. IOSv is provided as-is and is not supported by Cisco's      *
* Technical Advisory Center. Any use or disclosure, in whole or in part, *
* of the IOSv Software or Documentation to any third party for any       *
* purposes is expressly prohibited except as otherwise authorized by     *
* Cisco in writing.                                                      *
**************************************************************************CC
XEv_Spine_11# #sh ver
Cisco IOS XE Software, Version 16.05.01b
Cisco IOS Software [Everest], Virtual XE Software (X86_64_LINUX_IOSD-UNIVERSALK9-M), Version 16.5.1b, RELEASE SOFTWARE (fc1)
...
```",True,0,NONE
https://api.github.com/repos/ansible/ansible/issues/comments/311664950,Cannot default an undefined variable to another defined variable inside a dictionary,bcoca,7,239167786,2,311664950,0,239167786,2017-06-28T13:47:31Z,"List Information
================

Hi!

Thanks very much for your interest in Ansible.  It sincerely means a lot to us. 

This appears to be a user question, and we'd like to direct these kinds of things to either the mailing list or the IRC channel.

   * IRC: #ansible on irc.freenode.net   
   * mailing list: https://groups.google.com/forum/#!forum/ansible-project

In any case, it seems you use `{{ansible_host}}` w/o a default and that is triggering the error previous to the line you highlight, which is also incorrect as it is missing a `}` at the end to form an actual template.

If you can stop by there, we'd appreciate it.  This allows us to keep the issue tracker for bugs, pull requests, RFEs and the like.

Thank you once again and we look forward to seeing you on the list or IRC.  Thanks!",False,0,MEMBER
https://api.github.com/repos/ansible/ansible/issues/comments/311667255,Cannot default an undefined variable to another defined variable inside a dictionary,jean-christophe-manciot,7,239167786,3,311667255,0,311664950,2017-06-28T13:55:24Z,"@bcoca It is just a **typo** in my report: my ""connections.yml"" file has a **double curly braces** at the end and **the issue is still there**.
```
host: ""{{ ansible_host | default(inventory_hostname) }}""
```
I've corrected my original post.
Are you saying that this use case should not work?",False,0,NONE
https://api.github.com/repos/ansible/ansible/issues/comments/311668393,Cannot default an undefined variable to another defined variable inside a dictionary,bcoca,7,239167786,4,311668393,0,311667255,2017-06-28T13:59:33Z,"It has single brace in the error response, but  that is still not relevant as the undefined error you are getting is caused by an earlier use of a `{{ansible_host}}` .. seen in the error response, not by the line you highlight.",False,0,MEMBER
https://api.github.com/repos/ansible/ansible/issues/comments/311677197,Cannot default an undefined variable to another defined variable inside a dictionary,jean-christophe-manciot,7,239167786,5,311677197,0,311668393,2017-06-28T14:29:37Z,"Sorry, my bad.

However, there is still an issue with that filter:
```
2017-06-28 16:19:21,392 p=1120 u=root |  connecting to host XEv_Spine_12 returned an error
2017-06-28 16:19:21,392 p=1120 u=root |  (14, 'Bad address')
2017-06-28 16:19:21,393 p=1119 u=root |  connecting to host XEv_Spine_11 returned an error
2017-06-28 16:19:21,393 p=1119 u=root |  (14, 'Bad address')
2017-06-28 16:19:21,458 paramiko.transport EOF in transport thread
2017-06-28 16:19:21,458 paramiko.transport EOF in transport thread
2017-06-28 16:19:50,912 p=1120 u=root |  number of connection attempts exceeded, unable to connect to control socket
2017-06-28 16:19:50,912 p=1120 u=root |  persistent_connect_interval=1, persistent_connect_retries=30
2017-06-28 16:19:50,915 p=1119 u=root |  number of connection attempts exceeded, unable to connect to control socket
2017-06-28 16:19:50,916 p=1119 u=root |  persistent_connect_interval=1, persistent_connect_retries=30
2017-06-28 16:19:50,936 p=857 u=root |  open_shell() returned 255  failed to connect to control socket
2017-06-28 16:19:50,939 p=857 u=root |  fatal: [XEv_Spine_12]: FAILED! => {
    ""changed"": false, 
    ""failed"": true, 
    ""msg"": ""unable to open shell. Please see: https://docs.ansible.com/ansible/network_debug_troubleshooting.html#unable-to-open-shell"", 
    ""rc"": 255
}
```
Although I have no issue connecting manually to the same hosts with the same hostnames as shown in my first post. They are both defined in /etc/hosts:
```
172.21.100.111 XEv_Spine_11.actionmystique.net XEv_Spine_11
172.21.100.112 XEv_Spine_12.actionmystique.net XEv_Spine_12
```

If you try it, you should encounter the same issue with the same ansible version(s).
Also, I use **paramiko 2.0.6**.
",False,0,NONE
https://api.github.com/repos/ansible/ansible/issues/comments/311711810,Cannot default an undefined variable to another defined variable inside a dictionary,jean-christophe-manciot,7,239167786,6,311711810,0,311677197,2017-06-28T16:19:33Z,"@bcoca 
Do you need a new bug report to be open with a different title?",False,0,NONE
https://api.github.com/repos/ansible/ansible/issues/comments/311896445,Cannot default an undefined variable to another defined variable inside a dictionary,jean-christophe-manciot,7,239167786,7,311896445,0,311711810,2017-06-29T08:19:16Z,A new bug report has been posted [here](https://github.com/ansible/ansible/issues/26224).,False,0,NONE
https://api.github.com/repos/ansible/ansible/issues/comments/357253407,Cannot default an undefined variable to another defined variable inside a dictionary,yuskul,7,239167786,8,357253407,0,311896445,2018-01-12T14:33:19Z,"@bcoca 
Nice to see such a kind support of Ansible! Though the ticket is closed, but the described issue persists in Ansible 2.4.2. When I use an arg `vpc_subnet_id: ""{{ vpc.subnets.id | default(item.subnet) }}""` in `ec2` module, it throws me a fail:

> fatal: [localhost]: FAILED! => {""msg"": ""The task includes an option with an undefin variable. The error was: 'ansible.parsing.yaml.objects.AnsibleUnicode object' has  attribute 'subnets'\n\nThe error appears to have been in '/home/ec2-user/test/dashats-test.yml': line 39, column 5, but may\nbe elsewhere in the file depending on thexact syntax problem.\n\nThe offending line appears to be:\n\n\n  - name: Start thenstances\n    ^ here\n\nexception type: <class 'ansible.errors.AnsibleUndefinedVarile'>\nexception: 'ansible.parsing.yaml.objects.AnsibleUnicode object' has no attribe 'subnets'""}


 But if I pass the (undefined) var with a one value (not nested in another value, as above), `vpc_subnet_id: ""{{ vpc.subnets_id | default(item.subnet) }}""`, it runs well:

> TASK [Start the instances] ********************************************************
> ok: [localhost] => (item={u'subnet': u'subnet-43f0ee0a', u'group': [u'SSH'], u'ec2_ype': u't2.micro', u'tags': {u'type': u'ELB', u'Name': u'instance-01'}})


 Correct me, if I'm wrong.",False,0,NONE
https://api.github.com/repos/ansible/ansible/issues/26183,New module: manage Citrix Netscaler servicegroup configuration (network/netscaler/netscaler_servicegroup)) ,giorgos-nikolopoulos,4,239169859,1,239169859,0,0,2017-06-28T13:47:36Z,"##### SUMMARY
<!--- Describe the change, including rationale and design decisions -->
This PR adds a new module for Netscaler. netscaler_servicegroup
<!---
If you are fixing an existing issue, please include ""Fixes #nnn"" in your
commit message and your description; but you should still explain what
the change does.
-->

##### ISSUE TYPE
<!--- Pick one below and delete the rest: -->
 - New Module Pull Request

##### COMPONENT NAME
<!--- Name of the module/plugin/module/task -->
lib/ansible/modules/network/netscaler/netscaler_servicegroup.py
##### ANSIBLE VERSION
<!--- Paste verbatim output from “ansible --version” between quotes below -->
```
ansible 2.4.0 (netscaler_servicegroup 81cb0664ba) last updated 2017/06/28 16:42:31 (GMT +300)
  config file = /home/georgen/.ansible.cfg
  configured module search path = ['/home/georgen/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/georgen/repos/ansible_fork/lib/ansible
  executable location = /home/georgen/repos/ansible_fork/bin/ansible
  python version = 3.5.2 (default, Nov 17 2016, 17:05:23) [GCC 5.4.0 20160609]
```


##### ADDITIONAL INFORMATION
<!---
Include additional information to help people understand the change here.
For bugs that don't have a linked bug report, a step-by-step reproduction
of the problem is helpful.
  -->
Unit tests are provided.
Integration tests are provided.",True,0,CONTRIBUTOR
https://api.github.com/repos/ansible/ansible/issues/comments/311671319,New module: manage Citrix Netscaler servicegroup configuration (network/netscaler/netscaler_servicegroup)) ,giorgos-nikolopoulos,4,239169859,2,311671319,0,239169859,2017-06-28T14:10:06Z,"I triggered the build twice and I had the same error.

I think the error is unrelated to the module's code.

Let me know if it is otherwise.",False,0,CONTRIBUTOR
https://api.github.com/repos/ansible/ansible/issues/comments/311673933,New module: manage Citrix Netscaler servicegroup configuration (network/netscaler/netscaler_servicegroup)) ,ansibot,4,239169859,3,311673933,0,311671319,2017-06-28T14:18:54Z,"<!-- job_id: 5953b6278af8ef0700f2aabb -->
<!-- job_id: 5953b62c94c3d20700e2dbef -->
<!-- job_id: /testresults/ansible-test-failure.json -->

[click here for bot help](https://github.com/ansible/ansibullbot/blob/master/ISSUE_HELP.md)
<!--- boilerplate: shippable_test_result --->",False,0,CONTRIBUTOR
https://api.github.com/repos/ansible/ansible/issues/comments/311714455,New module: manage Citrix Netscaler servicegroup configuration (network/netscaler/netscaler_servicegroup)) ,ansibot,4,239169859,4,311714455,0,311673933,2017-06-28T16:29:06Z,"@chiradeep


As a maintainer of a module in the same namespace this new module has been submitted to, your vote counts for shipits. Please review this module and add `shipit` if you would like to see it merged.

[click here for bot help](https://github.com/ansible/ansibullbot/blob/master/ISSUE_HELP.md)
<!--- boilerplate: community_shipit_notify --->",False,0,CONTRIBUTOR
https://api.github.com/repos/ansible/ansible/issues/comments/316112597,New module: manage Citrix Netscaler servicegroup configuration (network/netscaler/netscaler_servicegroup)) ,giorgos-nikolopoulos,4,239169859,5,316112597,0,311714455,2017-07-18T16:03:53Z,This is a bump for review.,False,0,CONTRIBUTOR
https://api.github.com/repos/pallets/jinja/issues/741,"Template caching uses only template name, ignores path",radiantone,13,241828372,1,241828372,0,0,2017-07-10T19:55:37Z,"Jinja2 now caches templates using the name of the template. If I have many templates located in different paths with the same name 'template.html' or something, then Jinja2 always returns the firsts one that was retrieved. This behavior differs from past versions. Now I must rename all my templates to different names, which breaks my design pattern.

---

## Expected Behavior
Templates should be cached based on full path to template. not just filename

## Actual Behavior
Only template name is used for caching and different templates in different paths with same filename are ignored after the first one is cached.


```

## Your Environment
* Python version:  2.7
* Jinja version: 2
",True,0,NONE
https://api.github.com/repos/pallets/jinja/issues/comments/314217244,"Template caching uses only template name, ignores path",ThiefMaster,13,241828372,2,314217244,0,241828372,2017-07-10T19:57:00Z,"> * Jinja version: 2

That's not a jinja version...",False,0,MEMBER
https://api.github.com/repos/pallets/jinja/issues/comments/314218083,"Template caching uses only template name, ignores path",ThiefMaster,13,241828372,3,314218083,0,314217244,2017-07-10T20:00:05Z,I just checked the code and it uses a *template* name. This does not mean *file* name. Can you shown an example where the problem you describe supposedly happens?,False,0,MEMBER
https://api.github.com/repos/pallets/jinja/issues/comments/314219084,"Template caching uses only template name, ignores path",radiantone,13,241828372,4,314219084,0,314218083,2017-07-10T20:03:35Z,"Hi,
  Thank you for quick response. So in my system, I have modules that I load at runtime. Each module is a directory with  module/view.html (template), module/view.json, module/view.js etc.

When the system loads all the modules, it updates the template path to the directory of each module and the rendering module puts itself first. This may seem out of the ordinary, but it allows me to do inheritance of views. Anyway, it used to work fine. but now whenever the first view.html is rendered, then that becomes the template returned regardless of the jinja path pointing to a different view.html in a different directory.",False,0,NONE
https://api.github.com/repos/pallets/jinja/issues/comments/314219550,"Template caching uses only template name, ignores path",radiantone,13,241828372,5,314219550,0,314219084,2017-07-10T20:04:38Z,"Regardless of my system design, Jinja should know the different between somedirA/view.html and somedirB/view.html. Currently, it does not.",False,0,NONE
https://api.github.com/repos/pallets/jinja/issues/comments/314220969,"Template caching uses only template name, ignores path",ThiefMaster,13,241828372,6,314220969,0,314219550,2017-07-10T20:07:41Z,"No, it shouldn't. Because to Jinja it doesn't matter where a template comes from - it could be the file system, a dict, or anything else. The template path (or ""template name"") in the environment, on the other hand, is something that does uniquely identify a template.

Right now it sounds like something like `env.get_template('foo')` may reference different templates depending on some other criteria. Sorry to say, but if that's what you are doing it's just wrong! Ping me in #pocoo on IRC if you want a suggestion on how to do something like this in a much saner way.",False,0,MEMBER
https://api.github.com/repos/pallets/jinja/issues/comments/314222563,"Template caching uses only template name, ignores path",radiantone,13,241828372,7,314222563,0,314220969,2017-07-10T20:13:30Z,"No. That's not the case. Let me clarify.

Let's say jinja.path is set to ['moduleA/','moduleB/'] directories.

```
moduleA/
    view.html
moduleB/
    view.html
```

I then ask jinja to render_template('view.html'). It renders moduleA/view.html

If later I want it to render moduleB/view.html, I always get back moduleA/view.html because it only sees ""view.html"" in the cache. Again, this worked as I expected it to before recent (month or so) releases.

Does this make more sense?

The reason I have to jump through these path hoops is because jinja doesn't let me simply do:

render_template(""moduleB/view.html"") which would be the most sane thing to do.",False,0,NONE
https://api.github.com/repos/pallets/jinja/issues/comments/314224948,"Template caching uses only template name, ignores path",ThiefMaster,13,241828372,8,314224948,0,314222563,2017-07-10T20:22:54Z,"OK, now I understand. I don't think that's really a supported usecase...

Why not use a custom loader based on PrefixLoader that gets the prefix to use from whatever code you have to determine the active module? Then it'd just dispatch to FileSystemLoaders pointing to the various module template folders.",False,0,MEMBER
https://api.github.com/repos/pallets/jinja/issues/comments/314226151,"Template caching uses only template name, ignores path",radiantone,13,241828372,9,314226151,0,314224948,2017-07-10T20:27:24Z,"The way my system is setup is that I am loading modules of my application using Flask blueprints. At load time, I don't know where or what templates those loaded blueprint modules might define. They are defined in a json descriptor, including the directory where these templates reside. Thus my app rebuilds the jinja paths on the fly to render views as layers. It's a beautiful system and worked fine before recent jinja changes. I would consider this use case in your future code updates. It's quite powerful.

For now, I just rename all my templates:

moduleA/moduleA.html
moduleB/moduleB.html

 which breaks the ""pattern"" a bit but is not too cumbersome.
If at least jinja uses the path to the template (which it must have under the covers) in the cache id, then this problem goes away and jinja is a little smarter for it.",False,0,NONE
https://api.github.com/repos/pallets/jinja/issues/comments/314226669,"Template caching uses only template name, ignores path",davidism,13,241828372,10,314226669,0,314226151,2017-07-10T20:29:18Z,Jinja templates are not necessarily files. We can't use the file path because some templates do not have file paths. That's an implementation detail of the individual loaders.,False,0,MEMBER
https://api.github.com/repos/pallets/jinja/issues/comments/314227183,"Template caching uses only template name, ignores path",davidism,13,241828372,11,314227183,0,314226669,2017-07-10T20:31:18Z,"Clear the cache if you want to modify what's available to `ChoiceLoader` after loading a template.

If I'm understanding your description, it would be better to adjust your app to fully enumerate the path while registering blueprints, before any rendering happens. It sounds like right now you're only loading paths on demand, which isn't really going to get you anything.",False,0,MEMBER
https://api.github.com/repos/pallets/jinja/issues/comments/314229153,"Template caching uses only template name, ignores path",radiantone,13,241828372,12,314229153,0,314227183,2017-07-10T20:37:27Z,"Ok, I see that templates are sometimes not files, but given whatever kind of template is being accessed the cache can choose the most unique possible key for it. IF its a file, then the absolute path is easily had.

Is there a way to disable the cache? I already use a decorated cache on my flask routes. I don't need jinja also doing it. In fact, it creates a problem.",False,0,NONE
https://api.github.com/repos/pallets/jinja/issues/comments/314240702,"Template caching uses only template name, ignores path",davidism,13,241828372,13,314240702,0,314229153,2017-07-10T21:01:21Z,Duplicate of #298 #153 ,False,0,MEMBER
https://api.github.com/repos/pallets/jinja/issues/comments/314283739,"Template caching uses only template name, ignores path",radiantone,13,241828372,14,314283739,0,314240702,2017-07-11T00:02:58Z,So is there a work around? I think those other tickets are related but not duplicates. This behavior changed recently. So my ticket was created due to this change. I will revert to older version of Jinja and document the change. But I think the general problem here is that template names do not uniquely define the template. That would force a single template namespace which is a bad design on systems. It would be similar to have one directory only in a filesystem and having to name every file different. ,False,0,NONE
https://api.github.com/repos/pallets/jinja/issues/742,Jinja caches 2nd-level macros too aggressively,RichardCochrane,4,242284209,1,242284209,0,0,2017-07-12T07:24:20Z,"## Expected Behavior
When using a template that calls a macro (let's call this a 1st-level macro) that calls another macro (2nd-level macro), changes to the template and macros should reflect immediately on rendering.

## Actual Behavior
Changes to the 2nd-level macro are not reflecting without first saving (even without any changes) either the template or 1st-level macro.

## Template Code
```jinja
From `dashboard.jinja2`:

    {% from '_widgets.jinja2' import widgets %}

    <div>
        ...
        {{ widgets(args) }}
        ....
    </div>

From _widgets.jinja2:

    {% from '_my_chart.jinja2' import my_chart %}
    
    {% macro widgets(args) -%}
        <div class=""sv-section sv-section--mastery"">
            {{ my_chart(args) }}
        </div>
    {%- endmacro %}

From _my_chart.jinja2:

    {% macro my_chart(args) -%}
        <div>
            <!-- Beautiful Chart Code -->
        </div>
    {%- endmacro %}

```

## Full Traceback
```pytb
No traceback - error is seen in unexpected caching.
```

## Your Environment
* Python version: 2.7.10
* Jinja version: 2.9.6
* pyramid-jinja2: 2.3.3
",True,0,NONE
https://api.github.com/repos/pallets/jinja/issues/comments/314679351,Jinja caches 2nd-level macros too aggressively,ThiefMaster,4,242284209,2,314679351,0,242284209,2017-07-12T07:26:26Z,Duplicate of #253?,False,0,MEMBER
https://api.github.com/repos/pallets/jinja/issues/comments/314730976,Jinja caches 2nd-level macros too aggressively,RichardCochrane,4,242284209,3,314730976,0,314679351,2017-07-12T10:53:03Z,"@ThiefMaster I think you're right. I did search the repo for dups and although that issue relates to imports and includes, the symptoms (and probable cause) of both do appear to be the same. Do I just close this off or should I add a reference to this issue on that issue (so that macros are specifically included in the problem definition)?",False,0,NONE
https://api.github.com/repos/pallets/jinja/issues/comments/423227497,Jinja caches 2nd-level macros too aggressively,torian257x,4,242284209,4,423227497,0,314730976,2018-09-20T15:29:50Z,"it would be awesome to see some progress, this bug has been lying around for 5 years, and it affects everyone developing with nested macros, which basically should be everyone developing with jinja.",False,0,NONE
https://api.github.com/repos/pallets/jinja/issues/comments/546448333,Jinja caches 2nd-level macros too aggressively,davidism,4,242284209,5,546448333,0,423227497,2019-10-25T17:47:47Z,Duplicate of #253,False,0,MEMBER
https://api.github.com/repos/pallets/jinja/issues/743,Variable doesn't work in included templates if isn't used anywhere after in parent template,vlad0337187,4,242551758,1,242551758,0,0,2017-07-13T00:18:50Z,"Hello.

Sorry me please, maybe I understood wrong the documentation, or the problem is in Pelican static website generator, which I use. Also sorry that I had not asked about it on stackoverflow and that I paste images instead of templates. I's because of lack of time, If I'll not do it - I'll forget about it and will do never. Hope, it will help to correct bug in Jinja2, if it's present.


## Expected Behavior
If I declared variable in parent template, it must be available in all included template.

## Actual Behavior
I declared variable in parent template, it's available in all included template only in case, when this variable was used anywhere in parent template, but lower, that that include statements are placed.

## Template Code
Base template:
![screenshot from 2017-07-13 03-08-13](https://user-images.githubusercontent.com/12682937/28145173-d2526782-6778-11e7-8302-20fd6dfd5dfb.png)
Here variable was declared on line 2.

Child template:
![screenshot from 2017-07-13 03-08-35](https://user-images.githubusercontent.com/12682937/28145193-e88b331c-6778-11e7-8a19-b819eed313f8.png)

Now ""root_relative"" would not be rendered. But it would be rendered in case, when I'll place this variable into parent template somewhere below than include statements:
![screenshot from 2017-07-13 03-09-11](https://user-images.githubusercontent.com/12682937/28145215-1eada024-6779-11e7-9a24-b4d3563a1415.png)


## Full Traceback
There were no errors in logs when I called rendering of my website with:
`pelican`, `pelican --debug`, `pelican --vebrose`


## Your Environment
* Python version: 2.7.12 (also I have 3.5.2, but Pelican uses 2.7.12)
* Jinja version: 2.8-1 (from Linux Mint's repository)
* OS: Linux Mint 18.2
* Pelican: 3.6.3-1

Sorry another time for I didn't checked out more about this behavior and didn't asked about it on Stackoverflow. It's because of lack of time.

Best regards, Vladislav.",True,0,NONE
https://api.github.com/repos/pallets/jinja/issues/comments/314936840,Variable doesn't work in included templates if isn't used anywhere after in parent template,davidism,4,242551758,2,314936840,0,242551758,2017-07-13T00:41:21Z,"Please paste code, not pictures of code.",False,0,MEMBER
https://api.github.com/repos/pallets/jinja/issues/comments/315320284,Variable doesn't work in included templates if isn't used anywhere after in parent template,vlad0337187,4,242551758,3,315320284,0,314936840,2017-07-14T09:53:02Z,"@davidism , ok. I made some example.
Also I figured out, that such bug appears only when templates, that include other templates, extend some other template.

Template base.html:
```
<html>
<head>
	<title>{{ SITENAME }}</title>
</head>


{% block body %}
{% endblock body %}
</html>
```

Template a.html:
```
{% extends ""base.html"" %}
{% set var_a = ""variable_text"" %}


{% block body %}
<body>

	{% include ""c.html"" %}
	{{ var_a }}

</body>
{% endblock body %}
```


Template b.html:
```
{% extends ""base.html"" %}
{% set var_a = ""variable_text"" %}


{% block body %}
<body>

	{% include ""c.html"" %}

</body>
{% endblock body %}
```

Template c.html:
```
This is template c.html. Here must be variable: {{ var_a }}. Template finished.
```




Output a.html:
```
<html>
<head>
	<title>Bug example</title>
</head>


<body>

This is template c.html. Here must be variable: variable_text. Template finished.	variable_text

</body>
</html>
```



Output b.html:
```
<html>
<head>
	<title>Bug example</title>
</head>


<body>

This is template c.html. Here must be variable: . Template finished.
</body>
</html>
```

Here is pelican's project archive:
[jinja-bug-example.tar.gz](https://github.com/pallets/jinja/files/1148047/jinja-bug-example.tar.gz)


Source templates are located in ./sources/theme_general/templates
Output templates are located in ./output

To build project you need **pelican** package (apt install pelican).
Then open root folder of a project in terminal and write ""pelican"".",False,0,NONE
https://api.github.com/repos/pallets/jinja/issues/comments/317125602,Variable doesn't work in included templates if isn't used anywhere after in parent template,vlad0337187,4,242551758,4,317125602,0,315320284,2017-07-21T22:17:48Z,"@davidism , sorry for disturbing, had you seen my additions to related to this bug ?",False,0,NONE
https://api.github.com/repos/pallets/jinja/issues/comments/388864841,Variable doesn't work in included templates if isn't used anywhere after in parent template,ricky-undeadcoders,4,242551758,5,388864841,0,317125602,2018-05-14T15:45:33Z,"I can't reproduce this in version 2.10. It looks to have been solved with #619. 

Can this be closed?",False,0,NONE
https://api.github.com/repos/pallets/jinja/issues/745,`_compat.py` fails flake8 tests on Python 3,cclauss,3,242927260,1,242927260,0,0,2017-07-14T08:09:22Z,"`_compat.py` fails flake8 tests on Python 3 so other projects that replicate `_compat.py` also fail flake8 tests on Python 3.

`# stop the build if there are Python syntax errors or undefined names`
$ __flake8 . --count --select=E901,E999,F821,F822,F823 --show-source --statistics__


```
./jinja2/_compat.py:51:17: F821 undefined name 'unicode'
    text_type = unicode
                ^

./jinja2/_compat.py:52:18: F821 undefined name 'xrange'
    range_type = xrange
                 ^

./jinja2/_compat.py:53:26: F821 undefined name 'unicode'
    string_types = (str, unicode)
                         ^

./jinja2/_compat.py:54:27: F821 undefined name 'long'
    integer_types = (int, long)
                          ^

./jinja2/_compat.py:80:33: F821 undefined name 'unicode'
        if isinstance(filename, unicode):
                                ^
```",True,0,CONTRIBUTOR
https://api.github.com/repos/pallets/jinja/issues/comments/315299272,`_compat.py` fails flake8 tests on Python 3,ThiefMaster,3,242927260,2,315299272,0,242927260,2017-07-14T08:10:02Z,Shouldn't this whole file be excluded from flake8 tests?,False,0,MEMBER
https://api.github.com/repos/pallets/jinja/issues/comments/315300309,`_compat.py` fails flake8 tests on Python 3,cclauss,3,242927260,3,315300309,0,315299272,2017-07-14T08:15:06Z,"Flake8 can catch issues that are useful to know about when submitting pull requests.  Taking the blanket approach hides those issues from the contributor.  Taking the targeted approach (`noqa: F821`) is more verbose but it signals a conscious choice (""Kinda like: Yes, I am over 18, I know what I am doing..."")",False,0,CONTRIBUTOR
https://api.github.com/repos/pallets/jinja/issues/comments/340890811,`_compat.py` fails flake8 tests on Python 3,davidism,3,242927260,4,340890811,0,315300309,2017-10-31T20:06:36Z,"I don't find the changes here compelling. If other projects want a `_compat` that passes Flask8, but want to copy this one, they can do that however they desire after the copy.",False,0,MEMBER
https://api.github.com/repos/WedgeServer/wedge/issues/4,Plugin picker support,lol768,7,257507626,1,257507626,0,0,2017-09-13T20:16:46Z,"As far as I can see the `buildworker` and `devportal` repositories have been removed on Caddy's side. That's fine, happy to build this functionality myself - it will replace the existing releases system.",True,0,NONE
https://api.github.com/repos/WedgeServer/wedge/issues/comments/329299211,Plugin picker support,librecc,7,257507626,2,329299211,0,257507626,2017-09-13T21:15:29Z,"There are cached versions

https://sourcegraph.com/github.com/caddyserver/releaser/

https://sourcegraph.com/github.com/caddyserver/buildworker/",False,0,NONE
https://api.github.com/repos/WedgeServer/wedge/issues/comments/329299566,Plugin picker support,librecc,7,257507626,3,329299566,0,329299211,2017-09-13T21:16:59Z,@mholt,False,0,NONE
https://api.github.com/repos/WedgeServer/wedge/issues/comments/329304615,Plugin picker support,mholt,7,257507626,4,329304615,0,329299566,2017-09-13T21:38:47Z,"Just note that those repositories were never licensed for external use, not even under an OSS license. We close sourced the repos because they were only used as internal Caddy infrastructure, not anything else. (I am the only person who uses the releaser.) The maintenance burden is lower to close the source on these ancillary repos.",False,0,NONE
https://api.github.com/repos/WedgeServer/wedge/issues/comments/329439336,Plugin picker support,librecc,7,257507626,5,329439336,0,329304615,2017-09-14T10:18:55Z,"@mholt I understand your point, but the builderworker is an amazing tool. The community can use it to build the open source version of Caddy in an automated fashion.",False,0,NONE
https://api.github.com/repos/WedgeServer/wedge/issues/comments/329450618,Plugin picker support,mholt,7,257507626,6,329450618,0,329439336,2017-09-14T11:11:54Z,"Thanks, but at this point we have no plans to grant any license for others to use the buildworker (or releaser), and these remain internal tools.",False,0,NONE
https://api.github.com/repos/WedgeServer/wedge/issues/comments/329465895,Plugin picker support,lol768,7,257507626,7,329465895,0,329450618,2017-09-14T12:25:29Z,"Thanks for your input both. It's not a problem that the official build infrastructure is closed, and I'll work on a solution to this.",False,0,NONE
https://api.github.com/repos/WedgeServer/wedge/issues/comments/344124175,Plugin picker support,extraymond,7,257507626,8,344124175,0,329465895,2017-11-14T02:17:26Z,Dude you are awesome.,False,0,NONE
https://api.github.com/repos/WedgeServer/wedge/issues/5,Header has been removed in upstream,emersion,15,257935981,1,257935981,0,0,2017-09-15T06:04:29Z,See https://github.com/mholt/caddy/pull/1866,True,0,NONE
https://api.github.com/repos/WedgeServer/wedge/issues/comments/329771593,Header has been removed in upstream,lol768,15,257935981,2,329771593,0,257935981,2017-09-15T12:41:25Z,"Thanks, @emersion. Just caught up on the notifications on my PR there.

Whilst I'm happy to see the ads gone (though I'm incredibly surprised Matt didn't get explicit consent from the sponsors before doing this), it's unfortunate it took a sponsor pulling out for this to happen. As I've mentioned before, I do like Caddy and want it to succeed going forward.

The issue of the binaries and the restrictive EULA on those binaries remains, I guess. The fact that Mozilla contributed $50k to Caddy under [MOSS](https://www.mozilla.org/en-US/moss/) leaves a bit of a bad taste in my mouth in light of all of the restrictions that are now being applied. I'm of the belief that _everyone_ (regardless of technical ability) should be able to easily set-up HTTPS, whether it's for a personal blog, a sole trader's webstore, a small business or a huge corporation. Forcing all commercial users regardless of nature/size to purchase a license is detrimental to the goal of getting HTTPS deployed everywhere. As an example, if I were to add Google Ads to my blog to try and cover my $5 DigitalOcean droplet costs would I then need to pay over $1000 a year just to be able to use the webserver? Isn't it easier to just not bother, use Apache and keep it being served in plaintext?

With that said, the header was what annoyed me the most here (as I explained on HackerNews). This fork would become redundant if the Caddy folks allowed for unofficial builds to be distributed under the Caddy name - but they've made it clear that they're intending to enforce their trademark once it is registered.

So, at present I'm undecided on what to do. I'd like to see less restrictive terms on the binaries, so that may mean developing a tool that offers ""free as in freedom"" Wedge binaries (because I can't use the Caddy name) to everyone but with no support. At the same time I'm conscious this undermines what Matt and Cory are trying to do with restricting the binaries.",False,0,NONE
https://api.github.com/repos/WedgeServer/wedge/issues/comments/329917598,Header has been removed in upstream,mr-tcan,15,257935981,3,329917598,0,329771593,2017-09-15T22:22:12Z,"Just like you, I liked Caddy. But this situation leaves a bit of a bad taste in my mouth, as you sad.
Can you maintain this project, make it an official fork and build a community arround it?

Do you know Owncloud? They were forked by Nextcloud and now people use Nextcloud instead Owncloud. 

I think we could do the same. ",False,0,NONE
https://api.github.com/repos/WedgeServer/wedge/issues/comments/330201364,Header has been removed in upstream,bugrakoc,15,257935981,4,330201364,0,329917598,2017-09-18T12:13:36Z,"This header and EULA incident is what made me aware of Caddy in the first place. It is particularly useful for low traffic applications. However Caddy is unusable in its current form. With the performance being much behind Nginx and Lighttpd, and the EULA limiting its use, I'd be better off sticking to Lighttpd for small servers. Caddy's only advantage is its ease of use, so building it from source to work around the EULA also doesn't make sense.

That being said, Wedge can overcome this problem by providing usable clean binaries. Nextcloud-Owncloud example of @tscangussu might be far fetched, however you can at least make Wedge like CentOS-RHEL.",False,0,NONE
https://api.github.com/repos/WedgeServer/wedge/issues/comments/330663440,Header has been removed in upstream,lol768,15,257935981,5,330663440,0,330201364,2017-09-19T20:27:57Z,"> Caddy's only advantage is its ease of use, so building it from source to work around the EULA also doesn't make sense.
>That being said, Wedge can overcome this problem by providing usable clean binaries.

> I think we could do the same.

Agreed. I've talked this over with a few people and the state of the binaries and EULA is far from ideal and in my opinion, detrimental to a goal of getting HTTPS deployed everywhere. Let's do it.

Here's a long overdue update on things:

------

@SirCmpwn has been a great help with the build automation side of things. I've started work on a site for the project (FOSS of course, code available here: https://github.com/WedgeServer/website) which will soon be live on `wedgeserver.co.uk`. Aim is to make the binaries *easily* obtainable - tick some checkboxes and get a free (as in freedom) binary to deploy with no strings attached. It's also important to me that a copyable/curlable URL is exposed too to aid in automating updates. The website will handle caching builds, interfacing with the build service (see below) and currently contains information on the nature of the project.

Builds will take place on @SirCmpwn's infrastructure and this aspect of the work is still in progress. Happy to report that it's successfully managed to build Wedge already for a variety of platforms :smile: Next step is plugin support and the deployment/plumbing with the site to make things work nicely.",False,0,NONE
https://api.github.com/repos/WedgeServer/wedge/issues/comments/375405351,Header has been removed in upstream,scalp42,15,257935981,6,375405351,0,330663440,2018-03-22T18:09:03Z,"Any updates on this @lol768 do you know if it still behind maintained?

Trying to prevent more forks.

Thanks in advance!",False,0,NONE
https://api.github.com/repos/WedgeServer/wedge/issues/comments/375487290,Header has been removed in upstream,Raboo,15,257935981,7,375487290,0,375405351,2018-03-22T23:10:41Z,"The header is gone, so one doesn't need to have a forked project.
And it already appears that Wedge is lagging behind.
Yes, the binaries and EULA is still a problem.
So one can build binaries from the official Caddy code and distribute those freely according to Apache 2.0.

So some sort of automated builder that will host compiled Caddy binaries that doesn't  fall under the EULA from https://caddyserver.com/. So just like on https://caddyserver.com/ but without the EULA.

One difficulty would be to get and keep a updated list of available plugins. But I did find this project which seems to have a nice way to get a list of available plugins, https://github.com/abiosoft/caddyplug one could use a similar approach to get a list of plugins.

But then there's still the problem of creating a on-demand compiling backend and a front-end web ui for it..
But it would be a cool project.
",False,0,NONE
https://api.github.com/repos/WedgeServer/wedge/issues/comments/375487565,Header has been removed in upstream,ddevault,15,257935981,8,375487565,0,375487290,2018-03-22T23:12:02Z,The offer of free infrastructure for builds still stands.,False,0,NONE
https://api.github.com/repos/WedgeServer/wedge/issues/comments/375735909,Header has been removed in upstream,lol768,15,257935981,9,375735909,0,375487565,2018-03-23T17:09:05Z,"> And it already appears that Wedge is lagging behind.

Indeed. I started consulting work a few months back which impacted my ability to work on this and other projects. I still think the licensing situation is not ideal and it'd be great to see a working plugin frontend for this - but I don't anticipate being able to implement this.",False,0,NONE
https://api.github.com/repos/WedgeServer/wedge/issues/comments/376684922,Header has been removed in upstream,Raboo,15,257935981,10,376684922,0,375735909,2018-03-27T21:40:15Z,"I e-mailed the author behind https://github.com/abiosoft/caddyplug. Perhaps he can help with making a Caddy Builder. If he decides to make the back-end, we can probably cook up a frond-end for it.",False,0,NONE
https://api.github.com/repos/WedgeServer/wedge/issues/comments/376704789,Header has been removed in upstream,abiosoft,15,257935981,11,376704789,0,376684922,2018-03-27T23:08:49Z,"I think it is better to respond here than to the email. 

Caddyplug was an experiment for Go plugins and it actually works but Go plugins are very much unstable. I don't know if the case is different now, I haven't monitored it since then.

With regards to build server, I already made a generic cross platform Caddy binary builder https://github.com/abiosoft/caddy-docker/blob/master/BUILDER.md which leverages Docker. It works for any combinations of plugins and supports all architecture that Go supports. The only limitation it has is that it only builds off master branch of the plugin repositories. The stable version info of plugins are exclusive to [caddyserver.com](https://caddyserver.com/download).

I have to be honest here and let you guys know I have been very much involved with Caddy since its early days. So obviously, I have a bias for Caddy over any fork of it. However, I do not mind if any of my tools are beneficial to this project, just like the Caddy project itself is. I am also open to making anything new that works for Caddy and in turn Wedge, as long as it improves the experience of the users.

That being said, if I may ask, what is the goal of this project? The main reason this fork was created has been reversed. I may be wrong but I think the effort in maintaining this fork can be diverted into still having a community managed build server but for Caddy. Core Caddy contributors are still small in numbers and would benefit from the creative thinking happening here.",False,0,NONE
https://api.github.com/repos/WedgeServer/wedge/issues/comments/376726205,Header has been removed in upstream,ddevault,15,257935981,12,376726205,0,376704789,2018-03-28T01:09:54Z,The marketing website is still really misleading and employs dark patterns to get people to buy the paid product.,False,0,NONE
https://api.github.com/repos/WedgeServer/wedge/issues/comments/376899081,Header has been removed in upstream,Raboo,15,257935981,13,376899081,0,376726205,2018-03-28T14:05:51Z,"@abiosoft I can't answer for @lol768 in my opinion I would say that the priorities have shifted, it's no longer interesting have a fork of Caddy.. Just a nice way to build binaries like caddyserver.com without the commercial EULA.

And having free Caddy binaries would be beneficial to Caddy, but perhaps not to the author or company behind Caddy as it would go against their vision..
It's beneficial in the way that people tend to choose the path of least resistance. 
Last week at work I was setting up a small webserver to host some static assets. I was going to use Caddy, but since I saw it was forbidden to use binaries from caddyserver.com without opening your wallet I went with nginx.
So it's beneficial that more people use Caddy as it results in more plugins, bug reports, mentions, Github stars etc.

And the fact that their EULA change pisses me off. A big part of Caddys success is because it is Open Source and it had a free and easy way to download Caddy like most Open Source projects. It has resulted in that people wrote plugins, mentioned it in blogs, etc. I don't believe for one second that there would be so many plugins to Caddy if it weren't for that.",False,0,NONE
https://api.github.com/repos/WedgeServer/wedge/issues/comments/377034407,Header has been removed in upstream,lol768,15,257935981,14,377034407,0,376899081,2018-03-28T20:58:56Z,">@abiosoft I can't answer for @lol768 in my opinion I would say that the priorities have shifted, it's no longer interesting have a fork of Caddy.. Just a nice way to build binaries like caddyserver.com without the commercial EULA.

You can't answer for me, but our opinions are very similar :smile:

Wedge (the Caddy fork) served its purpose in removing mandatory advertisements - which the advertisers never even consented to! - from a previously pretty decent piece of software.

As long as such anti-features aren't reintroduced, the necessity of a fork is decreased and the EULA is the only issue. However I would warn anyone considering an alternative plugin/build service to think very carefully about branding. I think #2 illustrates the sort of kneejerk reaction you can expect here very well.  ",False,0,NONE
https://api.github.com/repos/WedgeServer/wedge/issues/comments/377075293,Header has been removed in upstream,Raboo,15,257935981,15,377075293,0,377034407,2018-03-28T23:49:23Z,"> However I would warn anyone considering an alternative plugin/build service to think very carefully about branding. I think #2 illustrates the sort of kneejerk reaction you can expect here very well.

I believe Apache 2.0 License protects us

Caddy plugin makers should pick a license that prohibits distribution of commercial binaries. That would be fun. Forcing them to build Caddy without certain plugins.",False,0,NONE
https://api.github.com/repos/WedgeServer/wedge/issues/comments/377076131,Header has been removed in upstream,Raboo,15,257935981,16,377076131,0,377075293,2018-03-28T23:54:02Z,"..or a license that requires commercial distribution to provide a 25% kickback of the price.
Plugin makers have equal rights to make profit on caddyserver.com binaries.",False,0,NONE
https://api.github.com/repos/WedgeServer/wedge/issues/7,Fix failing tests,peteretelej,3,258283802,1,258283802,0,0,2017-09-17T06:45:10Z,"Corrects invalid test values at `caddyhttp/errors/errors_test.go`: test assumed working directory and log print values. Change does not delete test, only updates it to will correct check.

Adds tests deps to vendor/
* gopkg.in/mcuadros/go-syslog.v2 required by caddyhttp/httpserver/logger_test.go
* golang.org/x/net/websocket required by caddyhttp/proxy/proxy_test.go

<!--
Thank you for contributing to Wedge! Please fill this out to help us make the most of your pull request.
-->

### 1. What does this change do, exactly?
Fixes failing `go test ./...` by correcting a bad test value and adding test dependencies to vendor/

### 2. Please link to the relevant issues.
N/A

### 3. Which documentation changes (if any) need to be made because of this PR?
None.

### 4. Checklist

- [x]  I have written tests and verified that they fail without my change
- [x]  I have squashed any insignificant commits
- [x] This change has comments for package types, values, functions, and non-obvious lines of code
- [x]  I am willing to help maintain this change if there are issues with it later
",True,0,NONE
https://api.github.com/repos/WedgeServer/wedge/issues/comments/330043379,Fix failing tests,lol768,3,258283802,2,330043379,0,258283802,2017-09-17T13:18:53Z,Is this test failing upstream too?,False,0,NONE
https://api.github.com/repos/WedgeServer/wedge/issues/comments/330046512,Fix failing tests,kashike,3,258283802,3,330046512,0,330043379,2017-09-17T13:52:20Z,https://github.com/WedgeServer/wedge/blob/master/caddyhttp/errors/errors.go#L131-L135,False,0,NONE
https://api.github.com/repos/WedgeServer/wedge/issues/comments/330053882,Fix failing tests,lol768,3,258283802,4,330053882,0,330046512,2017-09-17T14:44:14Z,Cheers kashike.,False,0,NONE
https://api.github.com/repos/pypa/pipenv/issues/952,`pip install` from Pypi does not install dependencies,gsemet,12,267630078,1,267630078,0,0,2017-10-23T11:18:12Z,"Hello

I really prefer pipenv to handle `Pipfile` and `Pipfile.lock` over the old `requirements.txt`, however, my packages that uses pipenv (ex: [here](https://pypi.python.org/pypi/txrwlock/)), when installed with `pip install txrwlock`, get no dependency at all.

I wonder if, for the moment at least, auto-generating a `requirements.txt` is not necessary, at least waiting for official support of `Pipfile` by `pip` (and other tools such as ReadTheDoc or Pyup that only support `requirements.txt`).

What's your thoughts?",True,0,CONTRIBUTOR
https://api.github.com/repos/pypa/pipenv/issues/comments/338704442,`pip install` from Pypi does not install dependencies,vphilippon,12,267630078,2,338704442,0,267630078,2017-10-23T15:49:42Z,"I do not see a need to auto-generate `requirements.txt`, that could actually cause some conflict with an existing `requirements.txt` in the directory and such.

We can generate a `requirements.txt` with `pipenv lock --requirements > requirements.txt`, so the option is there for anyone needing a `requirements.txt` for system on which they can't install `Pipenv`, until `pip` supports `Pipfile`/`Pipfile.lock`.",False,0,MEMBER
https://api.github.com/repos/pypa/pipenv/issues/comments/338709346,`pip install` from Pypi does not install dependencies,gsemet,12,267630078,3,338709346,0,338704442,2017-10-23T16:04:21Z,"I agree, this should be done on purpose (no auto generation). For my issue, so every modules pushed to Pypi should have this requirements.txt automatically done during build before building sdist/bdist/wheel ? Because for the moment, I don't have the dependencies of my package installed when I do `pip install mypackage`

The issue with `pipenv lock --requirements > requirements.txt` is that is freeze ALL dependencies (default and develop). I have written a little tool to keep 2 requirements files (`requirements.txt` and `requirements-dev.txt`) from the `Pipfile`: [pipenv-to-requirements](https://github.com/Stibbons/pipenv-to-requirements)",False,0,CONTRIBUTOR
https://api.github.com/repos/pypa/pipenv/issues/comments/338749605,`pip install` from Pypi does not install dependencies,vphilippon,12,267630078,4,338749605,0,338709346,2017-10-23T18:16:17Z,"First:
> Because for the moment, I don't have the dependencies of my package installed when I do `pip install mypackage`

I'm not sure I follow what you're expecting here, maybe I'm missing something. 
I've read the description of `pipenv-to-requirements`, and I have the feeling you're aware of the following, but I'll but it there anyway:
Even if a `requirements.txt` was shipped with your package, doing `pip install mypackage` would not read anything from the `requirements.txt`: it's still all part of the abstract dependencies defined in the `setup.py` (and `txrwlock`, for instance, defines none). You would still have to do `pip install -r requirements.txt`. Of course, with `Pipfile`, nothing of that changes: it doesn't define any dependencies of the package itself. Its a replacement to the `requirements.txt`
Like I said, if you were aware of all this, what did I miss in your question?

Second:
> The issue with `pipenv lock --requirements > requirements.txt` is that is freeze ALL dependencies (default and develop).

Ah, yes, that's discussed in https://github.com/kennethreitz/pipenv/issues/942.
It might not be that easy though to deal with though.

Finally:
> I have written a little tool to keep 2 requirements files (`requirements.txt` and `requirements-dev.txt`) from the `Pipfile`

Personal idea: You could use that tool to obtain those 2 separate requirements file from the Pipfile, and then use [pip-tools](https://github.com/jazzband/pip-tools) to perform the dependency resolution (lock) on the `requirements.txt` alone (at the moment `pipenv` uses a patched version of `pip-tools` to perform dependency resolution itself) before shipping it.
That's a bit of work, its not perfect, but that's a workaround if you want to start working and promoting the use of `Pipfile` while still working with other systems.",False,0,MEMBER
https://api.github.com/repos/pypa/pipenv/issues/comments/338786507,`pip install` from Pypi does not install dependencies,gsemet,12,267630078,5,338786507,0,338749605,2017-10-23T20:28:42Z,"I use PBR that does all of this automatically. But it does not support Pipfile yet, apparently.",False,0,CONTRIBUTOR
https://api.github.com/repos/pypa/pipenv/issues/comments/338803770,`pip install` from Pypi does not install dependencies,gsemet,12,267630078,6,338803770,0,338786507,2017-10-23T21:34:53Z,"Weirdly, I get the following with `requirements.txt` and `Pipfile` both aligned:
- `pip install txrwlock` does install `future` on Python 2.6
- `pipenv install txrwlock` does not

`future` is under markers in the dependency [Pipfile](https://github.com/Stibbons/pipenv-to-requirements/blob/master/Pipfile) and [requirements.txt](https://github.com/Stibbons/pipenv-to-requirements/blob/master/requirements.txt). So, there must be something related to conditional installation (markers) with `setup.py` dependency declaration (here, done automatically by [PBR](https://pypi.python.org/pypi/pbr))",False,0,CONTRIBUTOR
https://api.github.com/repos/pypa/pipenv/issues/comments/338827594,`pip install` from Pypi does not install dependencies,techalchemy,12,267630078,7,338827594,0,338803770,2017-10-23T23:39:59Z,Hmmm @vphilippon haven't we seen this bug before? Doesn't this depend on how _pipenv_ is installed and whether it will respect environment markers?  The details are a bit murky at the moment but I'm pretty sure this might relate to #857 ,False,0,MEMBER
https://api.github.com/repos/pypa/pipenv/issues/comments/338895160,`pip install` from Pypi does not install dependencies,erinxocon,12,267630078,8,338895160,0,338827594,2017-10-24T07:08:39Z,"I should note that we do not officially support python 2.6.  Not that it's causing this, just wanted to acknowledge it.  ",False,0,CONTRIBUTOR
https://api.github.com/repos/pypa/pipenv/issues/comments/338895635,`pip install` from Pypi does not install dependencies,erinxocon,12,267630078,9,338895635,0,338895160,2017-10-24T07:10:59Z,@Stibbons can you post an automatically generated `setup.py` from pbr?  I'm not familiar with PBR.,False,0,CONTRIBUTOR
https://api.github.com/repos/pypa/pipenv/issues/comments/338896376,`pip install` from Pypi does not install dependencies,gsemet,12,267630078,10,338896376,0,338895635,2017-10-24T07:14:06Z,"I have fixed this by ensuring i don’t use markers in my library. If i resume:
- a lib A uses à markers such as python_version < 3.0
- both requirements.txt and Pipfile have the same content with their respective syntax
- setup.py référence the dependencies (I use PBR to do it, i have not tested with find_packages, but in both cases I don’t see how the markers can be described in it)
- symptom is: pip install mypackage does install the conditioned dependency on python 2.7, pipenv install mypackage does not",False,0,CONTRIBUTOR
https://api.github.com/repos/pypa/pipenv/issues/comments/338897212,`pip install` from Pypi does not install dependencies,gsemet,12,267630078,11,338897212,0,338896376,2017-10-24T07:17:42Z,"PBR does not generate a setup.py, it is pluged into it and does everything « magically ». But it definitely support « requirements.txt », it is described on their doc, I have opened an issue on their side to support Pipfile as well.

By the way, parsing à Pipfile using pipenv adds so many dependencies (ex: flake8), is it possible to split the parsing part from the pipenv CLI in two different packages?). That could help other projects to read Pipfile ",False,0,CONTRIBUTOR
https://api.github.com/repos/pypa/pipenv/issues/comments/339037564,`pip install` from Pypi does not install dependencies,vphilippon,12,267630078,12,339037564,0,338897212,2017-10-24T15:50:05Z,"@techalchemy I think you're right, especially if I take @Stibbons comment:
>symptom is: `pip install mypackage` does install the conditioned dependency on python 2.7, `pipenv install mypackage does not`

This might be yet another case of ""the python version running `pipenv` *itself* is impacting the actual dependency resolution"".
@Stibbons Could you tell us which python version you used globally to install `pipenv` itself?
Bonus question: are you using `pyenv`?

And finally
> By the way, parsing à Pipfile using pipenv adds so many dependencies (ex: flake8), is it possible to split the parsing part from the pipenv CLI in two different packages?). That could help other projects to read Pipfile

That should be discussed in a separate issue. Tracking becomes impossible otherwise 😄 .
",False,0,MEMBER
https://api.github.com/repos/pypa/pipenv/issues/comments/339045990,`pip install` from Pypi does not install dependencies,gsemet,12,267630078,13,339045990,0,339037564,2017-10-24T16:15:32Z,"Donc in #967 :)

I don't use pyenv, only brew python on my mac and default python 2.7 on ubuntu 16.04. I have seen this behavior on both the [Travis build](https://travis-ci.org/Stibbons/txwebbackendbase/builds/291696093) and my local machine.
I also have some instabilities of `pipenv` on Python 2.7 (see the various executions [in here](https://travis-ci.org/Stibbons/txrwlock/builds/291729103)), but if you tell me it is not officially supported that would be a totally acceptable response. I am not sure this instability on the Travis build is due to pipenv of by travis it self (bad infra?)",False,0,CONTRIBUTOR
https://api.github.com/repos/pypa/pipenv/issues/953,Simple commands (such as autocompletion and --version) take a relatively long time,xremming,26,267695504,1,267695504,0,0,2017-10-23T14:43:04Z,"Evaluating the autocomplete takes a very long time (closer to a second).
`eval ""$(env _PIPENV_COMPLETE=source-bash pipenv)""`

Autocompletions also take closer to a second, as does running pretty much any command (no matter how simple).

I had to disable the autocompletion as it adds too much time to my terminals startup (actually I just took the output of the command to my .bashrc for now).

##### Describe you environment

1. Linux (Ubuntu 17.04)
1. Python version: Python 3.5.3
1. Pipenv version: pipenv, version 8.2.7

##### Expected result

These simple commands shouldn't take more than a few milliseconds.

##### Steps to replicate

```bash
$ time env _PIPENV_COMPLETE=source-bash pipenv --verbose

_pipenv_completion() {
    local IFS=$'\t'
    COMPREPLY=( $( env COMP_WORDS=""${COMP_WORDS[*]}"" \
                   COMP_CWORD=$COMP_CWORD \
                   _PIPENV_COMPLETE=complete-bash $1 ) )
    return 0
}

complete -F _pipenv_completion -o default pipenv

real    0m0,763s
user    0m0,708s
sys     0m0,056s
```

```bash
$ time pipenv --version
pipenv, version 8.2.7

real    0m0,646s
user    0m0,600s
sys     0m0,040s
```",True,0,NONE
https://api.github.com/repos/pypa/pipenv/issues/comments/338763415,Simple commands (such as autocompletion and --version) take a relatively long time,techalchemy,26,267695504,2,338763415,0,267695504,2017-10-23T19:03:24Z,I don't know much about completion but this seems slow. /cc  @erinxocon @nateprewitt ,False,0,MEMBER
https://api.github.com/repos/pypa/pipenv/issues/comments/338764497,Simple commands (such as autocompletion and --version) take a relatively long time,nateprewitt,26,267695504,3,338764497,0,338763415,2017-10-23T19:07:23Z,"@techalchemy it is slower than it needs to be. I fixed this a few months back and it looks like the big wave of changes in the last month reintroduced it.

It's just that the cli method has become so overloaded it does a lot of checks with every call that aren't necessary in cases like this.

We can fix it again but at best I think we'll be around 400ms just because of click and imports.",False,0,MEMBER
https://api.github.com/repos/pypa/pipenv/issues/comments/338826616,Simple commands (such as autocompletion and --version) take a relatively long time,techalchemy,26,267695504,4,338826616,0,338764497,2017-10-23T23:33:42Z,@nateprewitt Is there some way we can pare down imports or pre-compile autocompletion or something like that? Maybe that's just a massive refactor though?,False,0,MEMBER
https://api.github.com/repos/pypa/pipenv/issues/comments/338894473,Simple commands (such as autocompletion and --version) take a relatively long time,erinxocon,26,267695504,5,338894473,0,338826616,2017-10-24T07:05:18Z,"@nateprewitt @techalchemy I think the cli might need a bit of a refactor, or at least the options each command can accept needs to be looked at.  

@PolarPayne Can I ask what kind of hardware you are running on?",False,0,CONTRIBUTOR
https://api.github.com/repos/pypa/pipenv/issues/comments/338991686,Simple commands (such as autocompletion and --version) take a relatively long time,xremming,26,267695504,6,338991686,0,338894473,2017-10-24T13:34:41Z,"I'm running on a new Lenovo X1 Carbon, it has an SSD and is pretty fast (it's not a potato).",False,0,NONE
https://api.github.com/repos/pypa/pipenv/issues/comments/339023613,Simple commands (such as autocompletion and --version) take a relatively long time,erinxocon,26,267695504,7,339023613,0,338991686,2017-10-24T15:09:26Z,@PolarPayne Just curious.  I'll try and spin up a VM on my computer later with ubuntu and see if I experience any slowdowns.  ,False,0,CONTRIBUTOR
https://api.github.com/repos/pypa/pipenv/issues/comments/339206821,Simple commands (such as autocompletion and --version) take a relatively long time,erinxocon,26,267695504,8,339206821,0,339023613,2017-10-25T03:55:17Z,"On a bare metal ubuntu machine running an i7 770k, I'm getting a little under half a second.  A bit long...",False,0,CONTRIBUTOR
https://api.github.com/repos/pypa/pipenv/issues/comments/339231946,Simple commands (such as autocompletion and --version) take a relatively long time,xremming,26,267695504,9,339231946,0,339206821,2017-10-25T06:50:16Z,"I tried changing `__main__.py` to:
```python
if __name__ == '__main__':
    import os

    pipenv_complete = os.environ.get(""_PIPENV_COMPLETE"")
    if pipenv_complete:
        import click_completion
        click_completion._shellcomplete(None, ""pipenv"")
    else:
        from .cli import cli
        cli()
```
But this only lowered the time by ~100ms.

The problem seems to be that in `__init__.py` on line 17, `cli` is getting imported and it's taking long. If that import is just moved inside the `if __name__ == '__main__':` block in there everything works _much_ faster (when you also have the change above). With these changes it's only taking ~200ms (which I think is still ~190ms too long,  but much better).

If these are fine changes, I can make them into a pull request later today.",False,0,NONE
https://api.github.com/repos/pypa/pipenv/issues/comments/339233837,Simple commands (such as autocompletion and --version) take a relatively long time,xremming,26,267695504,10,339233837,0,339231946,2017-10-25T07:00:26Z,I'll gladly also just refactor that autocomplete code to be lightning fast.,False,0,NONE
https://api.github.com/repos/pypa/pipenv/issues/comments/339234665,Simple commands (such as autocompletion and --version) take a relatively long time,erinxocon,26,267695504,11,339234665,0,339233837,2017-10-25T07:04:05Z,I don;t know as much about the autocomplete.  @nateprewitt or @kennethreitz?,False,0,CONTRIBUTOR
https://api.github.com/repos/pypa/pipenv/issues/comments/339235816,Simple commands (such as autocompletion and --version) take a relatively long time,xremming,26,267695504,12,339235816,0,339234665,2017-10-25T07:09:13Z,"Anyways, the main problem is that `from .cli import cli` takes long (around 500ms on my machine).",False,0,NONE
https://api.github.com/repos/pypa/pipenv/issues/comments/342678575,Simple commands (such as autocompletion and --version) take a relatively long time,techalchemy,26,267695504,13,342678575,0,339235816,2017-11-08T01:19:59Z,"@PolarPayne I'd be curious to see your changes here, I was messing around a bit today and did what you described and didn't have immediate success",False,0,MEMBER
https://api.github.com/repos/pypa/pipenv/issues/comments/343411526,Simple commands (such as autocompletion and --version) take a relatively long time,xremming,26,267695504,14,343411526,0,342678575,2017-11-10T08:40:05Z,I'll put my changes (with a few other ideas related to this) into a pull request as soon as I have some time (next week?).,False,0,NONE
https://api.github.com/repos/pypa/pipenv/issues/comments/343689511,Simple commands (such as autocompletion and --version) take a relatively long time,tedmiston,26,267695504,15,343689511,0,343411526,2017-11-11T19:46:46Z,"I think I'm experiencing the same issue.  If there's a clear opportunity to jump in to help, I'd be interested.

Having auto-completion on in my `.bashrc` makes launching a new shell lag quite a bit.

```bash
$ time eval ""$(pipenv --completion)""

real	0m1.371s
user	0m1.224s
sys	0m0.134s
```

For comparison with the above results, here are my results with completion off:

```bash
$ time pipenv --version
pipenv, version 8.3.2

real	0m0.619s
user	0m0.535s
sys	0m0.075s
```

And with completion on:

```bash
$ time pipenv --version
pipenv, version 8.3.2

real	0m0.673s
user	0m0.573s
sys	0m0.089s
```

Versions:

```bash
$ python --version
Python 3.6.3
```

```bash
$ pipenv --version
pipenv, version 8.3.2
```

My hardware is a 2016 15"" MBP with 16 GB of RAM running macOS 10.13.1.
",False,0,CONTRIBUTOR
https://api.github.com/repos/pypa/pipenv/issues/comments/344690739,Simple commands (such as autocompletion and --version) take a relatively long time,xremming,26,267695504,16,344690739,0,343689511,2017-11-15T18:50:55Z,"I just realized, after creating the pull request, that first of all it doesn't seem to work (I guess it messes up something).  
But that there is now the `--completion`, and it doesn't account for that.

If someone can give me a nudge in the right direction of what might be the correct way to fix this one so I could look into implementing it.",False,0,NONE
https://api.github.com/repos/pypa/pipenv/issues/comments/346204648,Simple commands (such as autocompletion and --version) take a relatively long time,kennethreitz,26,267695504,17,346204648,0,344690739,2017-11-22T00:26:54Z,known,False,0,CONTRIBUTOR
https://api.github.com/repos/pypa/pipenv/issues/comments/400545326,Simple commands (such as autocompletion and --version) take a relatively long time,beigna,26,267695504,18,400545326,0,346204648,2018-06-27T05:16:22Z,"Hi! I'm a newcomer. I'm using `pipenv shell` and/or `pipes` as replacement of virtualenvwrapper's workon.

I'm facing some lags in my terminal:
a) pipenv autocompletion feels slow
b) exit from shell sometimes take ~2[s] to return to the prompt (or hangs until a keystroke)

Is this related to the second `BASH` instance or maybe `pipes` adds some overhead?

Thanks for your time.

OS: ArchLinux; Python 3.6.5; pipenv, version 2018.05.18
Hardware: i5-6300U CPU @ 2.40GHz; 16GB RAM; NVMe SSD",False,0,NONE
https://api.github.com/repos/pypa/pipenv/issues/comments/400776930,Simple commands (such as autocompletion and --version) take a relatively long time,tedmiston,26,267695504,19,400776930,0,400545326,2018-06-27T18:04:37Z,What is pipes?,False,0,CONTRIBUTOR
https://api.github.com/repos/pypa/pipenv/issues/comments/400793776,Simple commands (such as autocompletion and --version) take a relatively long time,beigna,26,267695504,20,400793776,0,400776930,2018-06-27T19:00:26Z,@tedmiston https://github.com/gtalarico/pipenv-pipes/,False,0,NONE
https://api.github.com/repos/pypa/pipenv/issues/comments/400819617,Simple commands (such as autocompletion and --version) take a relatively long time,techalchemy,26,267695504,21,400819617,0,400793776,2018-06-27T20:33:14Z,"For sure the autocomplete is an issue, it's a constant battle. There are some suggestions in https://github.com/pypa/pipenv/issues/497 regarding that.  We are reworking our subshell implementation (in the next release) so that should bring some performance improvements as well.",False,0,MEMBER
https://api.github.com/repos/pypa/pipenv/issues/comments/437759913,Simple commands (such as autocompletion and --version) take a relatively long time,dimaqq,26,267695504,22,437759913,0,400819617,2018-11-12T05:21:25Z,"Indeed, `pipenv` startup time is quite a bit:

```
> time pipenv --help
[snip]
        0.51 real         0.41 user         0.08 sys
```

Which explains subcommand autocomplete expansion lag.

I wonder if, perhaps, pipenv has grown large enough that it needs a dedicated autocompletion path?
For example, 2 processes.
Or a microcache.
Or something...",False,0,NONE
https://api.github.com/repos/pypa/pipenv/issues/comments/438253156,Simple commands (such as autocompletion and --version) take a relatively long time,techalchemy,26,267695504,23,438253156,0,437759913,2018-11-13T12:44:55Z,"@dimaqq it is already quite a challenge to stay at this time, but it is something I check regularly. As for alternate approaches, I’m not personally that focused on this beyond what I already do so if someone else has ideas they want to propose and implement I’d be happy do review them",False,0,MEMBER
https://api.github.com/repos/pypa/pipenv/issues/comments/438895911,Simple commands (such as autocompletion and --version) take a relatively long time,dimaqq,26,267695504,24,438895911,0,438253156,2018-11-15T02:40:39Z,"@techalchemy yes I can imagine!

I wish there was a better protocol for shell autocomplete, akin to switch from cgi to fastcgi.

I suppose none stops a dedicated developer from spawning a long-lived background task from at first autocomplete and communicating with said task from then on. Though that sounds like a slippery slope -- what's to stop other tools from doing same, and then if someone has N shells and M tools, would they end up with N*M background processes that do nothing most of the time?

The good news is that this ""lag"" is cpu-bound, which means it will get twice shorter in 1.5 years or so :D 

Or perhaps someone writes an autocomplete-caching-proxy in let's say golang and solves this for us :)",False,0,NONE
https://api.github.com/repos/pypa/pipenv/issues/comments/438977212,Simple commands (such as autocompletion and --version) take a relatively long time,xremming,26,267695504,25,438977212,0,438895911,2018-11-15T09:35:35Z,"I think this a problem beyond just the autocompletion, the thing is that **all** commands have this around half a second startup time which is not really acceptable for a CLI tool like pipenv.

I'd love to contribute and help with this, but I'm guessing it's most likely a rather large change.",False,0,NONE
https://api.github.com/repos/pypa/pipenv/issues/comments/439048713,Simple commands (such as autocompletion and --version) take a relatively long time,techalchemy,26,267695504,26,439048713,0,438977212,2018-11-15T13:59:00Z,@PolarPayne I am in 100% agreement and it likely requires some substantial restructuring which I’m happy to review but the smaller the changes the better of course,False,0,MEMBER
https://api.github.com/repos/pypa/pipenv/issues/comments/1157219579,Simple commands (such as autocompletion and --version) take a relatively long time,ktavabi,26,267695504,27,1157219579,0,439048713,2022-06-16T04:29:33Z,"> What is pipes?

@tedmiston  that's one 10-20 repos necessary for `pipenv` to supposedly do its thing.",False,0,NONE
https://api.github.com/repos/pypa/pipenv/issues/954,What does the lock file actually lock?,rwillmer,5,267720560,1,267720560,0,0,2017-10-23T15:49:28Z,"I don't understand what the Pipfile.lock file actually does. 

I can see that it stores the hashes of the installed versions, and I can see that from that I can create a pinned requirements.txt file to use with pip.

But I don't see what it prevents from happening, if you don't use pip and only use pipenv.

There's mention of how it can be used to deploy to production, but an example would be great.

If some kind soul could explain what the ""dev -> deploy to production"" workflow is supposed to be here, I'd happily turn it into a Pull Request for the documentation.

P.S. Thanks for this, @kennethreitz , I love the graph and secure options...",True,0,NONE
https://api.github.com/repos/pypa/pipenv/issues/comments/338753615,What does the lock file actually lock?,vphilippon,5,267720560,2,338753615,0,267720560,2017-10-23T18:29:30Z,"The `Pipfile.lock` is the equivalent of a *fully pinned requirements.txt*. All the dependencies, including the transitive dependencies, are pinned to an exact version. Than means that using that file with `pipenv`, you can re-create the *exact same virtual environnement* with no change in the transitive dependencies.
That means if you install a venv using an existing `Pipfile.lock`, you won't have any surprise like ""oh, this installation is broken because the package `foobar` has a new version that broke the compatibility"".

For the ""dev -> deploy to production"" workflow example, I'll leave the example to one of the maintainer, as there's a thing or two I'm unsure in term of going from ""dev mode"" to ""prod mode"" myself.",False,0,MEMBER
https://api.github.com/repos/pypa/pipenv/issues/comments/338777638,What does the lock file actually lock?,rwillmer,5,267720560,3,338777638,0,338753615,2017-10-23T19:55:45Z,"Thanks, @vphilippon. I understand the principle of it recording the exact versions; but I hadn't seen any example of how you can actually use that file once created, that is, how do you install those versions from that file?

With a bit more digging around, I've found the ""pipenv install --ignore-pipfile"" option which I *think* it does the install from the lockfile; but that really isn't obvious. 

I'll do a PR in the hope of making it a bit clearer.",False,0,NONE
https://api.github.com/repos/pypa/pipenv/issues/comments/405223118,What does the lock file actually lock?,asmaier,5,267720560,4,405223118,0,338777638,2018-07-16T11:53:58Z,"@rwillmer Unfortunately your change to the documentation was removed by the following commit:

https://github.com/pypa/pipenv/commit/21eab5abbbe673a5ac6d7588ee174c5d490e9eb9#diff-aff83a71607de84151c1cf4e0a893472

Maybe your example should be added again to the documentation. It made this important point much clearer. 
",False,0,NONE
https://api.github.com/repos/pypa/pipenv/issues/comments/405224696,What does the lock file actually lock?,uranusjr,5,267720560,5,405224696,0,405223118,2018-07-16T12:01:25Z,"The correct way to install from the lock file (without any input from Pipfile) is actually `pipenv sync`. The logic works like this:

* The user edits Pipfile to express what is wanted for the app
* `pipenv lock` takes that the user wants (from Pipfile), and resolve them into locked dependencies (Pipfile.lock)
* `pipenv sync` takes the locked dependencies (from Pipfile.lock), and install them into the environment.

`pipenv install` (without other arguments) is essentially `lock` + `sync`, so it is more like installing from *Pipfile* instead.

I would also like to mention that documentation contributions are very welcomed.",False,0,MEMBER
https://api.github.com/repos/pypa/pipenv/issues/comments/984017107,What does the lock file actually lock?,55stella,5,267720560,6,984017107,0,405224696,2021-12-01T20:12:12Z,how does pip lock work. ,False,0,NONE
https://api.github.com/repos/pypa/pipenv/issues/956,SyntaxError around async keyword on Python 3.7,jacebrowning,8,267765397,1,267765397,0,0,2017-10-23T18:13:38Z," `async` cannot be used as an argument name in Python 3.7:

https://github.com/kennethreitz/pipenv/blob/d89696e36da1277067c055ca83f786f762f02091/pipenv/vendor/pexpect/spawnbase.py#L224 

##### Describe you environment

1. OS Type: Alpine Linux 3.6
1. Python version: 3.7-rc
1. Pipenv version: N/A

##### Expected result

I can install pipenv.

##### Actual result

```
Traceback (most recent call last):
  File ""/usr/local/bin/pipenv"", line 7, in <module>
    from pipenv import cli
  File ""/usr/local/lib/python3.7/site-packages/pipenv/__init__.py"", line 17, in <module>
    from .cli import cli
  File ""/usr/local/lib/python3.7/site-packages/pipenv/cli.py"", line 19, in <module>
    import delegator
  File ""/usr/local/lib/python3.7/site-packages/pipenv/vendor/delegator.py"", line 8, in <module>
    from pexpect.popen_spawn import PopenSpawn
  File ""/usr/local/lib/python3.7/site-packages/pipenv/vendor/pexpect/__init__.py"", line 75, in <module>
    from .pty_spawn import spawn, spawnu
  File ""/usr/local/lib/python3.7/site-packages/pipenv/vendor/pexpect/pty_spawn.py"", line 14, in <module>
    from .spawnbase import SpawnBase
  File ""/usr/local/lib/python3.7/site-packages/pipenv/vendor/pexpect/spawnbase.py"", line 224
    def expect(self, pattern, timeout=-1, searchwindowsize=-1, async=False):
                                                                   ^
SyntaxError: invalid syntax
```


##### Steps to replicate

`pip install pipenv` with Python 3.7.
",True,0,CONTRIBUTOR
https://api.github.com/repos/pypa/pipenv/issues/comments/338750145,SyntaxError around async keyword on Python 3.7,AlJohri,8,267765397,2,338750145,0,267765397,2017-10-23T18:18:04Z,This should be raised on https://github.com/pexpect/pexpect/ I imagine this change in 3.7 is going to break a whole lot of code though.,False,0,CONTRIBUTOR
https://api.github.com/repos/pypa/pipenv/issues/comments/338751894,SyntaxError around async keyword on Python 3.7,jacebrowning,8,267765397,3,338751894,0,338750145,2017-10-23T18:23:55Z,It looks like they have already fixed this issue upstream (`async` => `async_`): https://github.com/pexpect/pexpect/blob/c741080a46445e5b2dec037c4856617f679d4546/pexpect/spawnbase.py,False,0,CONTRIBUTOR
https://api.github.com/repos/pypa/pipenv/issues/comments/338753733,SyntaxError around async keyword on Python 3.7,jacebrowning,8,267765397,4,338753733,0,338751894,2017-10-23T18:29:56Z,So I think the vendored pexpect just needs to be updated.,False,0,CONTRIBUTOR
https://api.github.com/repos/pypa/pipenv/issues/comments/338762007,SyntaxError around async keyword on Python 3.7,nateprewitt,8,267765397,5,338762007,0,338753733,2017-10-23T18:58:33Z,I closed #957 because I don't think we want the noise from tests failing until 3.7 is at least into a beta phase. I'll get pexpect updated tonight. Thanks everyone!,False,0,MEMBER
https://api.github.com/repos/pypa/pipenv/issues/comments/338892401,SyntaxError around async keyword on Python 3.7,erinxocon,8,267765397,6,338892401,0,338762007,2017-10-24T06:55:03Z,This is fixed on master by PR #962 ,False,0,CONTRIBUTOR
https://api.github.com/repos/pypa/pipenv/issues/comments/410129384,SyntaxError around async keyword on Python 3.7,nayanmshah,8,267765397,7,410129384,0,338892401,2018-08-03T02:55:39Z,I am facing the same issue as well. Please advise.,False,0,NONE
https://api.github.com/repos/pypa/pipenv/issues/comments/410428655,SyntaxError around async keyword on Python 3.7,tomanizer,8,267765397,8,410428655,0,410129384,2018-08-04T06:48:37Z,the async as variable issue also breaks apache-airflow on python 3.7.,False,0,NONE
https://api.github.com/repos/pypa/pipenv/issues/comments/410432983,SyntaxError around async keyword on Python 3.7,uranusjr,8,267765397,9,410432983,0,410428655,2018-08-04T08:13:28Z,"The pexpect issue has been fixed long ago. If you see this exact problem, you should upgrade Pipenv. If Pipenv is already up-to-date, or if you’re experiencing this *for a package you want to install with Pipenv*, this is a problem of that package, not Pipenv. Please report this problem to them instead.

Locking this since the problem is obviously resolved, and any claim of having this exact issue is always wrong.",False,0,MEMBER
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/295,Pluralize 'dependency' in bundle output,kjperry,4,265601368,1,265601368,0,0,2017-10-15T20:31:14Z,I apologize in advance for my pedantry,True,0,CONTRIBUTOR
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/337528037,Pluralize 'dependency' in bundle output,MikeMcQuaid,4,265601368,2,337528037,0,265601368,2017-10-18T09:42:53Z,"Your pedantry is very much welcome, thanks! Unfortunately `rubocop` has responded with pedantry in kind and `brew style homebrew/bundle` is now failing. Can you fix that up? Thanks!",False,0,MEMBER
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/341911562,Pluralize 'dependency' in bundle output,MikeMcQuaid,4,265601368,3,341911562,0,337528037,2017-11-04T16:46:12Z,@kjperry Gentle ping on the comments.,False,0,MEMBER
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/341978314,Pluralize 'dependency' in bundle output,kjperry,4,265601368,4,341978314,0,341911562,2017-11-05T14:44:58Z,"@MikeMcQuaid Whoops, this slipped my mind in a deluge of GitHub notifications, sorry! Should be good now.",False,0,CONTRIBUTOR
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/341984496,Pluralize 'dependency' in bundle output,MikeMcQuaid,4,265601368,5,341984496,0,341978314,2017-11-05T16:12:04Z,"Thanks for your first contribution to Homebrew/bundle, @kjperry! Without people like you submitting PRs we couldn't run this project. You rock!",False,0,MEMBER
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/297,add formulae descriptions (if available) when dumping Brewfile,phallstrom,8,269261234,1,269261234,0,0,2017-10-27T23:14:42Z,"This patch makes it so that when one runs `brew bundle dump` it will
append the formulae's descriptions as comments to the generated
Brewfile.

Comments are padded to align with the longest ""brew line.""

For example:

    ...
    tap ""homebrew/bundle""
    brew ""libyaml""                       # YAML Parser
    brew ""consul"", restart_service: true # Tool for service discovery, monitoring and configuration
    brew ""eot-utils""
    brew ""pick""                          # Utility to choose one option from a set of choices
    ...",True,0,CONTRIBUTOR
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/340203285,add formulae descriptions (if available) when dumping Brewfile,phallstrom,8,269261234,2,340203285,0,269261234,2017-10-28T16:33:07Z,"The specs are passing. Rubocop is annoyed. One I could agree with the other are line lengths due to the JSON test setup (one of those isn't even in my patch so maybe you don't care too much about that). Let me know if you want the others fixed up.

```
== /usr/local/Homebrew/Library/Taps/homebrew/homebrew-bundle/lib/bundle/brew_dumper.rb ==
C: 35:  7: Avoid multi-line chains of blocks.
== /usr/local/Homebrew/Library/Taps/homebrew/homebrew-bundle/spec/brew_dumper_spec.rb ==
C:  6:  1: Block has too many lines. [566/144]
C: 81:  3: Block has too many lines. [196/144]
C:252:  7: Redundant curly braces around a hash parameter.
== /usr/local/Homebrew/Library/Taps/homebrew/homebrew-bundle/spec/brew_installer_spec.rb ==
C:  5:  1: Block has too many lines. [242/144]
```",False,0,CONTRIBUTOR
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/340210404,add formulae descriptions (if available) when dumping Brewfile,MikeMcQuaid,8,269261234,3,340210404,0,340203285,2017-10-28T18:23:29Z,"@phallstrom Yeh, please fix them all up, thanks.",False,0,MEMBER
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/340278826,add formulae descriptions (if available) when dumping Brewfile,phallstrom,8,269261234,4,340278826,0,340210404,2017-10-29T17:25:19Z,"@MikeMcQuaid I didn't look too closely at the rubocop errors, but the 'too many lines' ones are complaining about Rspecs' ""describe do"" block. Doesn't seem right to break those up merely to satisfy rubocop. But I also see you aren't excluding any of them with inline disabling of rubocop. Makes me think this rubocop thing is relatively new.  Please advise...",False,0,CONTRIBUTOR
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/341911802,add formulae descriptions (if available) when dumping Brewfile,MikeMcQuaid,8,269261234,5,341911802,0,340278826,2017-11-04T16:49:08Z,@phallstrom As I think about this more I think it should probably be an optional parameter to `brew dump`. What do you think?,False,0,MEMBER
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/343541627,add formulae descriptions (if available) when dumping Brewfile,MikeMcQuaid,8,269261234,6,343541627,0,341911802,2017-11-10T17:53:50Z,@phallstrom Any thoughts?,False,0,MEMBER
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/345395426,add formulae descriptions (if available) when dumping Brewfile,phallstrom,8,269261234,7,345395426,0,343541627,2017-11-17T23:43:18Z,"Sorry @MikeMcQuaid, I was out of town. I'll admit to being new to using this tool, but kind of feel it should be the default.  I'm basing that off the assumption that if you're already setup with it you're going to manage the file yourself. If you're not, you probably want to dump it to get started and if you're like me have a million things you can't remember what they are. Not sure I'd look to see if there was a flag for it.  But you could certainly convince me that's the right way :)",False,0,CONTRIBUTOR
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/345521461,add formulae descriptions (if available) when dumping Brewfile,MikeMcQuaid,8,269261234,8,345521461,0,345395426,2017-11-19T14:38:35Z,@phallstrom I think it's better to not change the format of everyone's Brewfile's and e.g. Gemfiles and similar do not have this behaviour.,False,0,MEMBER
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/350554582,add formulae descriptions (if available) when dumping Brewfile,stale[bot],8,269261234,9,350554582,0,345521461,2017-12-10T15:06:37Z,"This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs.
",False,0,NONE
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/306,Only clean up build dependencies for bottles,wendorf,3,275190612,1,275190612,0,0,2017-11-19T20:42:14Z,"If a formula has not been poured from a bottle, its build dependency will be used for upgrades and should be kept around.

There's an argument for getting rid of build dependencies during a cleanup (they're not needed for runtime), but it was unexpected for me. Upgrading a formula built from source is very likely, so it seems like a good idea to keep build dependencies around.",True,0,CONTRIBUTOR
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/345551248,Only clean up build dependencies for bottles,MikeMcQuaid,3,275190612,2,345551248,0,275190612,2017-11-19T21:30:07Z,"This makes a lot of sense to me 👍. One comment; let me know your thoughts (and update if you agree) and I'll merge tomorrow. Thanks again, more fantastic work @wendorf! I hope to see more of you!",False,0,MEMBER
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/345551790,Only clean up build dependencies for bottles,wendorf,3,275190612,3,345551790,0,345551248,2017-11-19T21:38:00Z,Your comment makes sense—just pushed the change now. Thanks for taking a look!,False,0,CONTRIBUTOR
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/345622269,Only clean up build dependencies for bottles,MikeMcQuaid,3,275190612,4,345622269,0,345551790,2017-11-20T08:21:11Z,"Thanks again @wendorf, doing great work here!",False,0,MEMBER
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/309,Update/Upgrade of Xcode didn't work as expected via `mas` via `brew bundle`,janpio,4,279455822,1,279455822,0,0,2017-12-05T17:09:25Z,"README says:

> If a dependency is already installed and there is an update available it will be upgraded.

But:

```
Virtuals-Mac:~ foo$ brew bundle
Using homebrew/core
Using homebrew/bundle
Using caskroom/cask
Using mas
Using google-chrome
Using Xcode
Using visual-studio-code
Using sourcetree
Using android-studio
Using genymotion
Installing TextWrangler
Using dockutil
Using fastlane
Homebrew Bundle complete! 13 Brewfile dependencies now installed.
Virtuals-Mac:~ foo$ mas outdated
497799835 Xcode (9.1 -> 9.2)
Virtuals-Mac:~ foo$ mas upgrade
Upgrading 1 outdated application:
Xcode (9.2)
==> Downloading Xcode
------------------------------------------------------------ 0.0% Waiting
```

Did I do something wrong or shouldn't the Xcode upgrade already have happened with `brew bundle`?

`Brewfile`:
```
tap ""homebrew/core""
tap ""homebrew/bundle""
tap ""caskroom/cask""

# Config
cask_args appdir: ""/Applications""

# Internal
brew ""mas""

# Basics
cask ""google-chrome""

# Programming
mas ""Xcode"", id: 497799835
cask ""visual-studio-code""
cask ""sourcetree""
cask ""android-studio""
mas ""TextWrangler"", id: 404010395

# CLI Tools
brew ""dockutil""
cask ""fastlane""

# Special cases that will fail first!
cask ""genymotion""
```",True,0,NONE
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/349376319,Update/Upgrade of Xcode didn't work as expected via `mas` via `brew bundle`,MikeMcQuaid,4,279455822,2,349376319,0,279455822,2017-12-05T17:22:30Z,Xcode is not a dependency so will not be upgraded. Is it listed in your `Brewfile`? If it is and it is not upgraded: that could be something cool to submit a pull request implementing.,False,0,MEMBER
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/349377210,Update/Upgrade of Xcode didn't work as expected via `mas` via `brew bundle`,janpio,4,279455822,3,349377210,0,349376319,2017-12-05T17:25:27Z,"`<details>` tag seems to have hidden my `Brewfile` to well, I edited my post so the `Brewfile` is visible by default.

Doesn't mean having `mas ""Xcode"", id: 497799835` in there that it is a dependency?
Why a pull request - shouldn't this already work if I believe the README?",False,0,NONE
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/349632067,Update/Upgrade of Xcode didn't work as expected via `mas` via `brew bundle`,MikeMcQuaid,4,279455822,4,349632067,0,349377210,2017-12-06T12:57:40Z,"> Why a pull request - shouldn't this already work if I believe the README?

We don't ever attempt to use `mas upgrade` but I think we should so reopening this.",False,0,MEMBER
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/349638295,Update/Upgrade of Xcode didn't work as expected via `mas` via `brew bundle`,janpio,4,279455822,5,349638295,0,349632067,2017-12-06T13:24:14Z,"Ok, thanks for confirming this is indeed unwanted behavior. 

Hope someone that actually knows ruby can take a shot at solving this.",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/5975,xmb: Allow menu scale of 200%,RobLoach,3,284822263,1,284822263,0,0,2017-12-28T01:15:46Z,"## Description

This allows you to scale your menu to 200%. I've wanted it at 120% before.... This is helpful on super large monitors, TVs or projectors.

## Reviewers

- @fr500 
- @Kivutar ",True,0,MEMBER
https://api.github.com/repos/libretro/RetroArch/issues/comments/354209479,xmb: Allow menu scale of 200%,RobLoach,3,284822263,2,354209479,0,284822263,2017-12-28T01:17:44Z,"While we're at it, should we set the minimum value to 25% so that people don't make their menu disappear? ",False,0,MEMBER
https://api.github.com/repos/libretro/RetroArch/issues/comments/354209909,xmb: Allow menu scale of 200%,inactive123,3,284822263,3,354209909,0,354209479,2017-12-28T01:21:55Z,I think the latter suggestion is not necessary.,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/354219516,xmb: Allow menu scale of 200%,anyputer,3,284822263,4,354219516,0,354209909,2017-12-28T03:01:51Z,Window opacity can already make RetroArch disappear... hehe,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/5980,RetroArch reports there is only 1 CPU on 3DS when there is 4(Old) or 6(New),meepingsnesroms,3,284970513,1,284970513,0,0,2017-12-28T18:53:29Z,"The New 3DS has 6, 4 usable by RetroArch the Old 3DS has 4, 2 usable.

There is 1 arm7, 1 arm9, 2 arm11 and the new 3DS adds 2 more arm11.

Since we can only use the arm11 CPUs saying 2 or 4 would be acceptable but it seems that we only use 1 arm11 CPU which puts an unnecessary constraint on emulated games.

Summary: RetroArch should be using all the devices arm11 CPUs, its only using 1.",True,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/354339456,RetroArch reports there is only 1 CPU on 3DS when there is 4(Old) or 6(New),ghost,3,284970513,2,354339456,0,284970513,2017-12-28T19:05:20Z,"It's just a hardcoded number:

https://github.com/libretro/RetroArch/blob/709c7de40fdcab0d968d454e6aa2c2614bd5799e/libretro-common/features/features_cpu.c#L476-L477

But even if it weren't, what kind of multi-threading (besides tasks like scanning/networking) are you expecting RA to be able to do? We also don't build in rthreads support for 3DS either.",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/354343265,RetroArch reports there is only 1 CPU on 3DS when there is 4(Old) or 6(New),meepingsnesroms,3,284970513,3,354343265,0,354339456,2017-12-28T19:25:26Z,"I am adding networking right now, sound/video/input processing and some emulators support threads(dosbox).",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/354470363,RetroArch reports there is only 1 CPU on 3DS when there is 4(Old) or 6(New),meepingsnesroms,3,284970513,4,354470363,0,354343265,2017-12-29T16:49:22Z,Fixed,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/5983,config.libs.sh: reintroduce HAVE_X11 check,psyke83,3,285019638,1,285019638,0,0,2017-12-29T01:43:14Z,"Current behaviour would force check_val to check for X11 even if explicitly disabled.

Fixes Raspberry Pi build (which requires --disable-x11).",True,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/354386797,config.libs.sh: reintroduce HAVE_X11 check,psyke83,3,285019638,2,354386797,0,285019638,2017-12-29T01:59:58Z,Looks to be more problems with building on Raspberry Pi due to the introduction of the check_val function - not detecting EGL libs. Will close until I've got it sorted fully.,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/354388182,config.libs.sh: reintroduce HAVE_X11 check,psyke83,3,285019638,3,354388182,0,354386797,2017-12-29T02:19:42Z,"OK, PR looks good now. Can confirm RetroArch builds and runs properly on Pi again.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/354388627,config.libs.sh: reintroduce HAVE_X11 check,psyke83,3,285019638,4,354388627,0,354388182,2017-12-29T02:25:50Z,"The commit that introduced check_val was not the original culprit of this issue, it was this: https://github.com/libretro/RetroArch/commit/82db21ed0bfe33b041e197a92db463ae5046517c#diff-6d652c25f55557158a25711c0009c21bR409

Line 409 introduced a bug in which x11 was being unconditionally tested even if disabled, and the later change introducing check_val merely preserved the bug.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/5988,[Linux] [flatpak] Keyboard controls aren't working properly,ArclightMat,4,285100164,1,285100164,0,0,2017-12-29T14:15:37Z,"## Description

Keyboard input doesn't work in the interface properly, while certain keys such as arrow keys, enter and ESC are working, pressing any other input key (such as 'X', which is mapped to 'a') seems to be ineffective. This makes the menus impossible to navigate properly, since you can't go back after selecting an option with ENTER. Using a controller and manually mapping it works perfectly.

### Expected behavior

Being able to select an option using a keyboard-mapped key such as 'X' or 'Z'.

### Actual behavior

Unable to select anything using a keyboard-mapped key, basic navigation (enter, arrow keys) works fine, a controller is fully working.

### Steps to reproduce the bug

1. Install flatpak.
2. Install RetroArch from [flathub](https://flathub.org/).
3. Run RetroArch and try to use a ""default"" key.

### Bisect Results

After a fresh 1.6.9 install (later updated to 1.7.0), input does work fine on a core such as Nestopia UE, so it is likely a issue with RetroArch itself, manually mapping it to a controller also works fine and it seems to receive input on ""Input User 1 Bind"" when you map it to keyboard again, but it doesn't work inside the RetroArch UI.
Running it with --verbose on flatpak throws normal output even when loading it:
```[matheus@HarpNote ~]$ flatpak run --verbose org.libretro.RetroArch 
F: No installations directory in /etc/flatpak/installations.d. Skipping
F: Opening user flatpak installation at path /home/matheus/.local/share/flatpak
F: Opening system flatpak installation at path /var/lib/flatpak
F: Opening user flatpak installation at path /home/matheus/.local/share/flatpak
F: Opening system flatpak installation at path /var/lib/flatpak
F: Allowing host-fs access
F: Allowing x11 access
F: Allowing wayland access
F: Allowing pulseaudio access```

### Version/Commit

- RetroArch: [1.7.0/0a2b442]

### Environment information

- OS: [Fedora 27]
- Flatpak version: [0.10.2.1]
",True,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/354451586,[Linux] [flatpak] Keyboard controls aren't working properly,ArclightMat,4,285100164,2,354451586,0,285100164,2017-12-29T14:18:48Z,"As an additional note, I also found this bug on Debian 9 + flatpak, using the outdated version from its repository seems to be working, so it might be caused by flatpak or it is a RetroArch regression, I might end up trying to compile RetroArch directly if needed.",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/354503490,[Linux] [flatpak] Keyboard controls aren't working properly,i30817,4,285100164,3,354503490,0,354451586,2017-12-29T21:39:11Z,"turn on unified controls on the cfg file (maybe it's on the menu too).

I was also triggered by this a while ago, where they made the menu shortcuts different from in-game shortcuts without a way to reconfigure menu shortcuts (i have some broken keys on the portable). This was done because they didn't want for their 'unified' controls to interfere with text input on the RA menus.

(though, honestly, they just need a text input focus system for the menus instead).",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/354506556,[Linux] [flatpak] Keyboard controls aren't working properly,i30817,4,285100164,4,354506556,0,354503490,2017-12-29T22:14:02Z,"Also don't forget to turn on / use 'game_focus' toggle key. It will save you a lot of head-aches if you're going to use a keyboard (it toggles on/off all 'system' RA shortcuts while running a core. Not the 'input keybinds', the menus shortcuts). Its default is a bit hard to get on my keyboard (scroll lock) so i managed to miss it.

Since you want to use this when you use a core that uses text extensively, even certain bindings being set to a usable key in the core (keyboard 'x' serving as controller 'x' for instance) aren't that much of a problem in the cores because on most of them you won't be doing text input and using the controller at the same time, and on those that you are, they have text focus so the 'controller key' should be ignored while entering text (just remember tab cycles focus out if you get in trouble).

Probably also a good idea to turn a 'open menu' controller combination.

I personally also set several keys to """" (empty) on the main retroarch.cfg. Expecially the 'esc quits retroarch' default.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/354613470,[Linux] [flatpak] Keyboard controls aren't working properly,ArclightMat,4,285100164,5,354613470,0,354506556,2017-12-31T16:40:56Z,"Woah, you are indeed right, toggling unified controls on did the trick, I was going crazy thinking it was some weird bug with it interacting through flatpak since it was working fine on Windows and an old version on Debian.
Thanks for the advice with keyboard mapping, I don't use the keyboard (RetroArch is best suited for a controller after all) that often but it is really nice for some quick 2/3-button controller platforms (NES, Genesis, GBx, etc) when I can't be bothered to get a controller.",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/7180,receive of raw encrypted incrimental backup caused stacktrace and D state,prometheanfire,12,297861707,1,297861707,0,0,2018-02-16T17:27:01Z,"<!--
Thank you for reporting an issue.

*IMPORTANT* - Please search our issue tracker *before* making a new issue.
If you cannot find a similar issue, then create a new issue.
https://github.com/zfsonlinux/zfs/issues 

*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.
Please search the wiki and the mailing list archives before asking 
questions on the mailing list.
https://github.com/zfsonlinux/zfs/wiki/Mailing-Lists

Please fill in as much of the template as possible.
-->

### System information
<!--  add version after ""|"" character -->
Type                                | Version/Name
  ---                                  |     --- 
Distribution Name       | Gentoo
Distribution Version    | latest
Linux Kernel                 | 4.14.18-gentoo
Architecture                 | x86_64
ZFS Version                  | built from master on the 8th, somwhere around https://github.com/zfsonlinux/zfs/commit/f54976dc881549cc3222887188b110f2e8d05f0b
SPL Version                  | similliarly built from master on the 8th

### Describe the problem you're observing
Kernel backtrace and receive hanging in d state.

### Describe how to reproduce the problem
    zfs send -Lwecp -I LOCAL_POOL@backup-201802091942 LOCAL_POOL@backup-201802161114 | ssh 1.2.3.4 zfs recv -duvs -o canmount=off REMOTE_POOL/remote-backups/LOCAL_POOL

### Include any warning/errors/backtraces from the system logs

```
[400296.285606] VERIFY3(0 == zap_add(mos, dsobj, spa_feature_table[f].fi_guid, sizeof (zero), 1, &zero, tx)) failed (0 == 17)
[400296.285712] PANIC at dsl_dataset.c:802:dsl_dataset_activate_feature()
[400296.285803] Showing stack for process 9102
[400296.285807] CPU: 4 PID: 9102 Comm: txg_sync Not tainted 4.14.18-gentoo #1
[400296.285809] Hardware name: Supermicro X10SLH-F/X10SLM+-F/X10SLH-F/X10SLM+-F, BIOS 1.1 07/19/2013
[400296.285810] Call Trace:
[400296.285823]  dump_stack+0x46/0x65
[400296.285830]  spl_panic+0xc8/0x110
[400296.285841]  ? zap_add_impl+0x96/0x150
[400296.285845]  ? zap_add+0x78/0xa0
[400296.285853]  dsl_dataset_activate_feature+0x104/0x160
[400296.285858]  dsl_crypto_recv_key_sync+0x548/0x950
[400296.285864]  dsl_sync_task_sync+0xac/0x110
[400296.285868]  dsl_pool_sync+0x355/0x4c0
[400296.285874]  spa_sync+0x449/0xd80
[400296.285880]  txg_sync_thread+0x2de/0x540
[400296.285884]  ? txg_delay+0x1e0/0x1e0
[400296.285887]  ? __thread_exit+0x20/0x20
[400296.285890]  thread_generic_wrapper+0x6f/0x80
[400296.285897]  kthread+0x119/0x130
[400296.285901]  ? kthread_create_on_node+0x70/0x70
[400296.285905]  ? kthread_create_on_node+0x70/0x70
[400296.285910]  ret_from_fork+0x35/0x40
```",True,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/366302356,receive of raw encrypted incrimental backup caused stacktrace and D state,prometheanfire,12,297861707,2,366302356,0,297861707,2018-02-16T17:27:55Z,"additional info, the kernel on the sender and receiver are the exact same (built and reused).",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/366302854,receive of raw encrypted incrimental backup caused stacktrace and D state,prometheanfire,12,297861707,3,366302854,0,366302356,2018-02-16T17:29:45Z,"@tcaputi you may want in on this, am I using an unsupported option when sending?",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/366340549,receive of raw encrypted incrimental backup caused stacktrace and D state,tcaputi,12,297861707,4,366340549,0,366302854,2018-02-16T19:50:13Z,Can you tell me what datasets are encrypted on each system? Specifically is the sent dataset encrypted and are any parents of the received dataset encrypted?,False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/366347600,receive of raw encrypted incrimental backup caused stacktrace and D state,prometheanfire,12,297861707,5,366347600,0,366340549,2018-02-16T20:21:16Z,"All datasets on the source system are encrypted, pool created with the following:

    zpool create -O encryption=on -O keyformat=passphrase zfstest /dev/zvol/slaanesh-zp00/zfstest

The destination systems has no encrypted datasets, just the raw receive from the first send to it (which it received correctly).  ZFS commands are hanging, so I can't get the output of zfs list on the destination system, but the send/receive command set was as follows.

    zfs send -Lwecp LOCAL_POOL@backup-201802091942 | ssh 10.0.1.14 zfs recv -duvsF -o canmount=off REMOTE_POOL/remote-backups/LOCAL_POOL",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/366348552,receive of raw encrypted incrimental backup caused stacktrace and D state,tcaputi,12,297861707,6,366348552,0,366347600,2018-02-16T20:25:03Z,"OK. I think this is probably related to #7117. This manifestation of it doesn't seem to be a very serious ASSERT and we could probably just ignore it, but I'd like to know why it's happening before I say so for sure.",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/366348754,receive of raw encrypted incrimental backup caused stacktrace and D state,tcaputi,12,297861707,7,366348754,0,366348552,2018-02-16T20:25:54Z,"Did your original pool have any clones, by the way?

EDIT: nevermind. I see this is just a single dataset being sent, so this shouldn't matter.",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/366349670,receive of raw encrypted incrimental backup caused stacktrace and D state,prometheanfire,12,297861707,8,366349670,0,366348754,2018-02-16T20:29:46Z,"Any way to work around it (other than sending non-raw, unencrypted)?",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/366350680,receive of raw encrypted incrimental backup caused stacktrace and D state,tcaputi,12,297861707,9,366350680,0,366349670,2018-02-16T20:34:07Z,looking into it now.don't want to tell you something that causes permanent damage...,False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/366497936,receive of raw encrypted incrimental backup caused stacktrace and D state,tcaputi,12,297861707,10,366497936,0,366350680,2018-02-18T07:32:47Z,"So basically, this ASSERT is being caused because the code is confused about whether or not your dataset is encrypted. I have not been able to replicate your exact error, but i have replicated a couple other small issues and I have a patch to fix them (which I will be making a PR for soon).

The 2 bugs I found have to do with `zfs recv -F` and the way it replaces existing datasets if necessary. Can I ask why you added that into your command? Was there an existing dataset before that was preventing the receive from working? If so, the patch might fix this as well.",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/366500403,receive of raw encrypted incrimental backup caused stacktrace and D state,prometheanfire,12,297861707,11,366500403,0,366497936,2018-02-18T08:29:46Z,Honestly my workflow for creating a new backup was to create the dataset then receive -F over it.  It's probably just paranoia or stupidity on my part but a I've never been able to create a dataset on initial receive.  I'll watch for your PR though and let you know how it goes (on 4.14.20 with master as of a few hours ago).,False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/369653589,receive of raw encrypted incrimental backup caused stacktrace and D state,tcaputi,12,297861707,12,369653589,0,366500403,2018-03-01T16:44:33Z,@prometheanfire Any thoughts for how we might go about getting this issue closed? I'm not sure if we were ever able to replicate the issue after these patches went through.,False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/369657247,receive of raw encrypted incrimental backup caused stacktrace and D state,prometheanfire,12,297861707,13,369657247,0,369653589,2018-03-01T16:55:31Z,"I haven't been able to retest (I'm traveling), I'm going to close it and will reopen (or make a new one if I have to) if needed.",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/7183,"""zpool status -c temp"" not working across various disks",bunder2015,4,297989523,1,297989523,0,0,2018-02-17T08:32:27Z,"<!--
Thank you for reporting an issue.

*IMPORTANT* - Please search our issue tracker *before* making a new issue.
If you cannot find a similar issue, then create a new issue.
https://github.com/zfsonlinux/zfs/issues 

*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.
Please search the wiki and the mailing list archives before asking 
questions on the mailing list.
https://github.com/zfsonlinux/zfs/wiki/Mailing-Lists

Please fill in as much of the template as possible.
-->

### System information
<!--  add version after ""|"" character -->
Type                                | Version/Name
  ---                                  |     --- 
Distribution Name       | gentoo
Distribution Version    | n/a
Linux Kernel                 | n/a
Architecture                 | n/a
ZFS Version                  | various 0.7.x git
SPL Version                  | various 0.7.x git
<!-- 
Commands to find ZFS/SPL versions:
modinfo zfs | grep -iw version
modinfo spl | grep -iw version 
-->

### Describe the problem you're observing
`zpool status -c temp` doesn't appear to work on Samsung SSDs or NVMEs, possibly other makes/models of disks.  This is actually fairly common with `hddtempd`, [they maintain a database](http://mirror.csclub.uwaterloo.ca/nongnu/hddtemp/hddtemp.db) of attributes to look for when probing temperatures.  In the case of the SSDs below, they use `190 Airflow_Temperature_Cel` instead of `194 Temperature_Celsius`.  The NVME doesn't list attribute numbers, and actually reports 3 sensors, ""Temperature"", ""Temperature Sensor 1"" and 2.
### Describe how to reproduce the problem
Run `zpool status -c temp` on a pool with various disks installed
### Include any warning/errors/backtraces from the system logs
<!-- 
*IMPORTANT* - Please mark logs and text output from terminal commands 
or else Github will not display them correctly. 
An example is provided below.

Example:
```
this is an example how log text should be marked (wrap it with ```)
```
-->
```
bloomfield ~ # ZPOOL_SCRIPTS_PATH=/etc/zfs/zpool.d/ ZPOOL_SCRIPTS_AS_ROOT=1 zpool status -c temp
  pool: b-pool
 state: ONLINE
status: Some supported features are not enabled on the pool. The pool can
        still be used, but some features are unavailable.
action: Enable all features using 'zpool upgrade'. Once this is done,
        the pool may no longer be accessible by software that does not support
        the features. See zpool-features(5) for details.
  scan: scrub repaired 0B in 0 days 00:30:03 with 0 errors on Fri Feb 16 04:00:04 2018
config:

        NAME                                                     STATE     READ WRITE CKSUM  temp
        b-pool                                                   ONLINE       0     0     0
          raidz2-0                                               ONLINE       0     0     0
            ata-WDC_WD1003FBYZ-010FB0-part1WD-WCAW37498843       ONLINE       0     0     0    28
            ata-WDC_WD1003FBYZ-010FB0-part1WD-WCAW3KUDTD5S       ONLINE       0     0     0    29
            ata-WDC_WD1003FBYZ-010FB0-part1WD-WCAW3REX5UK3       ONLINE       0     0     0    30
            ata-WDC_WD1003FBYZ-010FB0-part1WD-WCAW37357425       ONLINE       0     0     0    30
            ata-WDC_WD1003FBYZ-010FB0-part1WD-WCAW37439816       ONLINE       0     0     0    33
        logs
          mirror-1                                               ONLINE       0     0     0
            ata-Samsung_SSD_850_EVO_120GB_S21TNXAGB04076F-part2  ONLINE       0     0     0     -
            ata-Samsung_SSD_850_EVO_120GB_S21TNXAGB06637N-part2  ONLINE       0     0     0     -
        cache
          ata-Samsung_SSD_850_EVO_120GB_S21TNXAGB04076F-part1    ONLINE       0     0     0     -
          ata-Samsung_SSD_850_EVO_120GB_S21TNXAGB06637N-part1    ONLINE       0     0     0     -

errors: No known data errors
```

```
firewall ~ # ZPOOL_SCRIPTS_PATH=/etc/zfs/zpool.d/ ZPOOL_SCRIPTS_AS_ROOT=1 zpool status -c temp
  pool: fw-pool
 state: ONLINE
status: Some supported features are not enabled on the pool. The pool can
        still be used, but some features are unavailable.
action: Enable all features using 'zpool upgrade'. Once this is done,
        the pool may no longer be accessible by software that does not support
        the features. See zpool-features(5) for details.
  scan: scrub repaired 0B in 0 days 00:00:13 with 0 errors on Fri Feb 16 03:30:14 2018
config:

        NAME                                                     STATE     READ WRITE CKSUM  temp
        fw-pool                                                  ONLINE       0     0     0
          mirror-0                                               ONLINE       0     0     0
            ata-Samsung_SSD_850_EVO_250GB_S2R5NX0J505885R-part2  ONLINE       0     0     0     -
            ata-Samsung_SSD_850_EVO_250GB_S2R5NX0J505886X-part2  ONLINE       0     0     0     -

errors: No known data errors
```

```
gazelle ~ # ZPOOL_SCRIPTS_PATH=/etc/zfs/zpool.d/ ZPOOL_SCRIPTS_AS_ROOT=1 zpool status -c temp
  pool: g-pool
 state: ONLINE
status: Some supported features are not enabled on the pool. The pool can
        still be used, but some features are unavailable.
action: Enable all features using 'zpool upgrade'. Once this is done,
        the pool may no longer be accessible by software that does not support
        the features. See zpool-features(5) for details.
  scan: scrub repaired 0B in 0 days 00:00:24 with 0 errors on Fri Feb 16 03:30:25 2018
config:

        NAME         STATE     READ WRITE CKSUM  temp
        g-pool       ONLINE       0     0     0
          nvme0n1p2  ONLINE       0     0     0     -

errors: No known data errors
```",True,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/366604407,"""zpool status -c temp"" not working across various disks",loli10K,4,297989523,2,366604407,0,297989523,2018-02-19T07:05:09Z,"@bunder2015 thank you for reporting this.

Are you already working on a fix? If so, would you mind if this issue gets assigned to you?",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/366604553,"""zpool status -c temp"" not working across various disks",bunder2015,4,297989523,3,366604553,0,366604407,2018-02-19T07:06:12Z,"I think I have something working for SSD, but I'm trying to see if I can get NVME working as well.

edit: I should note that appears that sudo is required for these scripts to work, although you won't see any errors indicating that.",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/366604916,"""zpool status -c temp"" not working across various disks",loli10K,4,297989523,4,366604916,0,366604553,2018-02-19T07:09:00Z,"Nice, thanks. I've seen you edit your report multiple times, it looked to me you were onto something.",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/367075022,"""zpool status -c temp"" not working across various disks",tonyhutter,4,297989523,5,367075022,0,366604916,2018-02-20T18:36:20Z,"> I should note that appears that sudo is required for these scripts to work, 
> although you won't see any errors indicating that.

Yea, unfortunately the `-c` error reporting is non-existent at this time.  We do provide a sudoers rule that people can use to allow `smartctl` for unprivilaged users (`etc/sudoers.d/zfs` mentioned in `zpool(8)`)",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/7184,"""metadata is corrupted"" 'fixed' by removing a Device file...",Celmor,8,298006223,1,298006223,0,0,2018-02-17T13:51:30Z,"### System information
<!--  add version after ""|"" character -->
Type                                | Version/Name
  ---                                  |     ---
Distribution Name       | Linux NixOS
Linux Kernel            | 4.9.77
Architecture            | x86_64
ZFS Version             | 0.7.0-1 (commit [4c46b99](https://github.com/zfsonlinux/zfs/commit/4c46b99d24a6e71b3c72462c11cb051d0930ad60))`*`
SPL Version             | 0.7.0-1 (commit [23602fd](https://github.com/zfsonlinux/spl/commit/23602fdb39e1254c669707ec9d2d0e6bcdbf1771))

`*` added patches to ZFS ([expression](https://paste.simplylinux.ch/view/2c94b9be)):
- [Mic92's patches updated for current zfs master](https://github.com/sjau/zfs/commit/72591199b36e4b4bddb6650717b5bb3121d508da.patch)
- [Stability patch #6864](https://patch-diff.githubusercontent.com/raw/zfsonlinux/zfs/pull/6864.patch)

SPL [expression](https://paste.simplylinux.ch/view/6206107b)/[patches](https://github.com/NixOS/nixpkgs/tree/master/pkgs/os-specific/linux/spl)

### Describe the problem you're observing
Wasn't able to import DataBackup pool because of ""**metadata is corrupted**"" with zpool suggesting ""_Destroy and re-create the pool from a backup source_.""

### Describe how to reproduce the problem
- Removing Device file for one of the disks of the mirrored vdev makes pool importable
- Commented '_#..._' out output relating to other pool
```
# uname -a
Linux nixos 4.9.77 #1-NixOS SMP Wed Jan 17 08:39:00 UTC 2018 x86_64 GNU/Linux

# zpool import -No readonly=on DataBackup
cannot import 'DataBackup': I/O error
	Destroy and re-create the pool from
	a backup source.

# zpool import
   pool: DataBackup
     id: 15297398777247163884
  state: FAULTED
 status: The pool metadata is corrupted.
 action: The pool cannot be imported due to damaged devices or data.
   see: http://zfsonlinux.org/msg/ZFS-8000-72
 config:

	DataBackup                                   FAULTED  corrupted data
	  mirror-0                                   ONLINE
	    ata-HGST_HDN724040ALE640_PK1338P4HVX34B  ONLINE
	    sdd                                      ONLINE
#...

# lsblk -f | grep zfs
#...                
├─sdc1 zfs_member  DataBackup 15297398777247163884                 
├─sdd1 zfs_member  DataBackup 15297398777247163884

# lsblk | grep $(basename $(readlink /dev/disk/by-id/ata-HGST_HDN724040ALE640_PK1338P4HVX34B))
sdc      8:32   0   3.7T  0 disk 
├─sdc1   8:33   0   3.7T  0 part 
└─sdc9   8:41   0     8M  0 part

# rm /dev/sdc1

# zpool import DataBackup

# zpool status DataBackup
  pool: DataBackup
 state: DEGRADED
status: One or more devices could not be used because the label is missing or
	invalid.  Sufficient replicas exist for the pool to continue
	functioning in a degraded state.
action: Replace the device using 'zpool replace'.
   see: http://zfsonlinux.org/msg/ZFS-8000-4J
  scan: resilvered 1.21T in 0 days 03:50:19 with 0 errors on Sat Jan 27 06:02:23 2018
config:

	NAME                     STATE     READ WRITE CKSUM
	DataBackup               DEGRADED     0     0     0
	  mirror-0               DEGRADED     0     0     0
	    6204277785589605098  UNAVAIL      0     0     0  was /dev/disk/by-id/ata-HGST_HDN724040ALE640_PK1338P4HVX34B-part1
	    sdd                  ONLINE       0     0     0

errors: No known data errors
```
Considering to run `partprobe /dev/sdc && zpool labelclear /dev/sdc1 && zpool replace DataBackup 6204277785589605098 /dev/sdc1` now to fix the data on the other disk, but not sure if these are the right commands yet (haven't received an answer on the irc channel so far), alternatively would dd the _good_ disk over the _bad_ disk.",True,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/366443281,"""metadata is corrupted"" 'fixed' by removing a Device file...",loli10K,8,298006223,2,366443281,0,298006223,2018-02-17T14:00:03Z,This will (hopefully) be fixed by https://github.com/openzfs/openzfs/commit/619c0123a513678d5824d6b1c4d7e8fad3c63e76 (_9075 Improve ZFS pool import/load process and corrupted pool recovery_) once it gets merged.,False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/366444515,"""metadata is corrupted"" 'fixed' by removing a Device file...",Celmor,8,298006223,3,366444515,0,366443281,2018-02-17T14:21:22Z,"Not sure but I might have overwritten `/dev/disk/by-id/ata-HGST_HDN724040ALE640_PK1338P4HVX34B-part1` with the same data as sdd at some point (have a 3rd disk from which I often duplicated a disk of DataBackup)
This is the zdb output for each disk:
```
# zdb -l  /dev/disk/by-id/ata-HGST_HDN724040ALE640_PK1338P4HVX34B-part1 | grep guid
    pool_guid: 15297398777247163884
    top_guid: 17479763665280800965
    guid: 7688493249387590645
        guid: 17479763665280800965
            guid: 6204277785589605098
            guid: 7688493249387590645
    pool_guid: 15297398777247163884
    top_guid: 17479763665280800965
    guid: 6204277785589605098
        guid: 17479763665280800965
            guid: 6204277785589605098
            guid: 7688493249387590645
# zdb -l /dev/sdd1 | grep guid
    pool_guid: 15297398777247163884
    top_guid: 17479763665280800965
    guid: 7688493249387590645
        guid: 17479763665280800965
            guid: 6204277785589605098
            guid: 7688493249387590645
```
Even if the disks contain the same data and zfs thinks one of them was the other disk of the mirrored vdev, it shouldn't say that the zpool is corrupt and I need to restore from backup if it still has a good disk.

Import while only one disk is available:
```
# rm /dev/sdd1

# zpool import -o readonly=on -d /dev DataBackup
cannot import 'DataBackup': I/O error
	Destroy and re-create the pool from
	a backup source.

# partprobe /dev/sdd && rm /dev/sdc1

# zpool import -o readonly=on -d /dev DataBackup
```

Gonna luksFormat the 'bad disk' (`sdc1` aka `/dev/disk/by-id/ata-HGST_HDN724040ALE640_PK1338P4HVX34B-part1`) now and replace `6204277785589605098` with it.",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/429475708,"""metadata is corrupted"" 'fixed' by removing a Device file...",behlendorf,8,298006223,4,429475708,0,366444515,2018-10-12T22:05:26Z,"This may be resolved in master by 6cb8e5306d9696d155ae7a808f56c4e46d69b64c, but I'm leaving it open until we can confirm or deny this.",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/446706060,"""metadata is corrupted"" 'fixed' by removing a Device file...",samuelxhu,8,298006223,5,446706060,0,429475708,2018-12-12T19:07:22Z,"@behlendorf  Hi, Brian, I tried to cherry-pick 6cb8e53 to ZFS 0.7.12, but unfortunately failed as there are so many Hunk failures. It seems not straightforward to backport it to 0.7.12.

As being able to import a pool is extremely important in any case, could it possble for you to arrange an official backport this fix to 0.7.X, say potentially 0.7.13? That would be very benificial to all 0.7.X users.

thanks in advance for kind considerations",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/446768164,"""metadata is corrupted"" 'fixed' by removing a Device file...",behlendorf,8,298006223,6,446768164,0,446706060,2018-12-12T22:28:01Z,"@samuelxhu we considered it but decided against it.  As you found out 6cb8e53 is a significant change and backporting it would likely be destabilizing to the 0.7.x series.  If this change is absolutely required to import a pool, the pool can be imported with the latest 0.8.0-rcX series and then exported.  At which point it can be imported with the previous version.  ",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/446904188,"""metadata is corrupted"" 'fixed' by removing a Device file...",samuelxhu,8,298006223,7,446904188,0,446768164,2018-12-13T09:41:18Z,"Understood, thanks a lot for the clarification.

On Wed, Dec 12, 2018 at 11:28 PM Brian Behlendorf <notifications@github.com>
wrote:

> @samuelxhu <https://github.com/samuelxhu> we considered it but decided
> against it. As you found out 6cb8e53
> <https://github.com/zfsonlinux/zfs/commit/6cb8e5306d9696d155ae7a808f56c4e46d69b64c>
> is a significant change and backporting it would likely be destabilizing to
> the 0.7.x series. If this change is absolutely required to import a pool,
> the pool can be imported with the latest 0.8.0-rcX series and then
> exported. At which point it can be imported with the previous version.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/zfsonlinux/zfs/issues/7184#issuecomment-446768164>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ALDBAZhAMRIkWic98fbMDi1SfqN3EmfNks5u4YMBgaJpZM4SJUS3>
> .
>
",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/446905323,"""metadata is corrupted"" 'fixed' by removing a Device file...",samuelxhu,8,298006223,8,446905323,0,446904188,2018-12-13T09:44:40Z,"Hope a pool exported by the final 0.8.0 version can be imported by 0.7.X as
well:-)

On Thu, Dec 13, 2018 at 10:41 AM Xiaoyu Hu <samuel.xhu@gmail.com> wrote:

> Understood, thanks a lot for the clarification.
>
> On Wed, Dec 12, 2018 at 11:28 PM Brian Behlendorf <
> notifications@github.com> wrote:
>
>> @samuelxhu <https://github.com/samuelxhu> we considered it but decided
>> against it. As you found out 6cb8e53
>> <https://github.com/zfsonlinux/zfs/commit/6cb8e5306d9696d155ae7a808f56c4e46d69b64c>
>> is a significant change and backporting it would likely be destabilizing to
>> the 0.7.x series. If this change is absolutely required to import a pool,
>> the pool can be imported with the latest 0.8.0-rcX series and then
>> exported. At which point it can be imported with the previous version.
>>
>> —
>> You are receiving this because you were mentioned.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/zfsonlinux/zfs/issues/7184#issuecomment-446768164>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/ALDBAZhAMRIkWic98fbMDi1SfqN3EmfNks5u4YMBgaJpZM4SJUS3>
>> .
>>
>
",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/725132819,"""metadata is corrupted"" 'fixed' by removing a Device file...",stale[bot],8,298006223,9,725132819,0,446905323,2020-11-11T03:38:34Z,"This issue has been automatically marked as ""stale"" because it has not had any activity for a while. It will be closed in 90 days if no further activity occurs.  Thank you for your contributions.
",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/7185,Test SPL #685,DeHackEd,3,298019785,1,298019785,0,0,2018-02-17T17:08:20Z,"Requires-spl: refs/pull/685/head
Signed-off-by: DHE <git@dehacked.net>

### Description
The current implementation in SPL evaluates its parameters twice if the condition fails. This might lead to unexpected results, from hangs to the error message reported to `dmesg` having the wrong return code. I have seen `VERIFY3 failed (0 == 0)` today.

### Motivation and Context
Someone in IRC had the `(0 == 0)` scenario happen. That needs fixing.

### How Has This Been Tested?
Build test only for now. Buildbots can run a kernel test plz.

### Types of changes
- [X] Bug fix (non-breaking change which fixes an issue)
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Performance enhancement (non-breaking change which improves efficiency)
- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)
- [ ] Breaking change (fix or feature that would cause existing functionality to change)
- [ ] Documentation (a change to man pages or other documentation)

### Checklist:
- [X] My code follows the ZFS on Linux code style requirements.
- [ ] I have updated the documentation accordingly.
- [ ] I have read the **CONTRIBUTING** document.
- [ ] I have added tests to cover my changes.
- [ ] All new and existing tests passed.
- [X] All commit messages are properly formatted and contain `Signed-off-by`.
- [ ] Change has been approved by a ZFS on Linux member.
",True,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/366479228,Test SPL #685,codecov[bot],3,298019785,2,366479228,0,298019785,2018-02-17T23:27:44Z,"# [Codecov](https://codecov.io/gh/zfsonlinux/zfs/pull/7185?src=pr&el=h1) Report
> Merging [#7185](https://codecov.io/gh/zfsonlinux/zfs/pull/7185?src=pr&el=desc) into [master](https://codecov.io/gh/zfsonlinux/zfs/commit/e921f6508b212c61fcedd0eeb2f9cf9da1abc4d1?src=pr&el=desc) will **increase** coverage by `0.08%`.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/zfsonlinux/zfs/pull/7185/graphs/tree.svg?src=pr&token=NGfxvvG2io&width=650&height=150)](https://codecov.io/gh/zfsonlinux/zfs/pull/7185?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master    #7185      +/-   ##
==========================================
+ Coverage   76.39%   76.48%   +0.08%     
==========================================
  Files         327      327              
  Lines      103768   103767       -1     
==========================================
+ Hits        79278    79361      +83     
+ Misses      24490    24406      -84
```

| Flag | Coverage Δ | |
|---|---|---|
| #kernel | `75.98% <0%> (+0.04%)` | :arrow_up: |
| #user | `65.95% <0%> (+0.06%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/zfsonlinux/zfs/pull/7185?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/zfsonlinux/zfs/pull/7185?src=pr&el=footer). Last update [e921f65...a56af67](https://codecov.io/gh/zfsonlinux/zfs/pull/7185?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/367505880,Test SPL #685,DeHackEd,3,298019785,3,367505880,0,366479228,2018-02-21T22:55:38Z,Closing since Brian merged the SPL PR.,False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/367509068,Test SPL #685,behlendorf,3,298019785,4,367509068,0,367505880,2018-02-21T23:06:47Z,Thanks!,False,0,CONTRIBUTOR
https://api.github.com/repos/npm/npm/issues/19873,Possible to silence npx `installed in` output?,zeke,7,298806127,1,298806127,0,0,2018-02-21T01:01:53Z,"#### I'm opening this issue because:

  - [ ] npm is crashing.
  - [ ] npm is producing an incorrect install.
  - [ ] npm is doing something I don't understand.
  - [x] Other (_see below for feature requests_):

Hi! I love `npx`. I'm just wondering if there's an easy way to silence output like `npx: installed 60 in 3.968s`.

Here's an example of what I'm seeing

```
$ npx wikipedia-tldr snuggy
npx: installed 60 in 3.968s
A sleeved blanket is a body-length blanket with sleeves usually made of fleece or nylon material. ...
```

and here's what I'd like to see:

```
$ npx wikipedia-tldr snuggy
A sleeved blanket is a body-length blanket with sleeves usually made of fleece or nylon material. ...
```

Is it a log level thing? Thanks!

### supporting information:

 - `npm -v` prints: 5.6.0
 - `node -v` prints: v8.4.0
 - `npm config get registry` prints:
 - Windows, OS X/macOS, or Linux?: macOS",True,0,CONTRIBUTOR
https://api.github.com/repos/npm/npm/issues/comments/367188817,Possible to silence npx `installed in` output?,legodude17,7,298806127,2,367188817,0,298806127,2018-02-21T02:02:32Z,I think `-s` should work for that.,False,0,CONTRIBUTOR
https://api.github.com/repos/npm/npm/issues/comments/367192631,Possible to silence npx `installed in` output?,zeke,7,298806127,3,367192631,0,367188817,2018-02-21T02:24:06Z,"Thanks @legodude17.  It's not actually `-s` but `-q` and `--quiet` work for one-off commands 👍 

Wondering if there's an `npm config set` invocation that will turn this off and persist it as a preference.",False,0,CONTRIBUTOR
https://api.github.com/repos/npm/npm/issues/comments/367358326,Possible to silence npx `installed in` output?,kenany,7,298806127,4,367358326,0,367192631,2018-02-21T15:13:28Z,`--quiet` is equivalent to `npm config set loglevel warn`,False,0,CONTRIBUTOR
https://api.github.com/repos/npm/npm/issues/comments/367398361,Possible to silence npx `installed in` output?,zeke,7,298806127,5,367398361,0,367358326,2018-02-21T17:08:24Z,"Thanks @KenanY. I see it is documented as such: https://docs.npmjs.com/misc/config#shorthands-and-other-cli-niceties, but npx doesn't seem to honor that:

```
$ npm config set loglevel warn 

$ npx wikipedia-tldr motherlode
npx: installed 61 in 4.538s
Mother lode is a principal vein or zone of gold or silver ore. The term is also
used colloquially to refer to the real or imaginary origin of something
valuable or in great abundance.

$ npm config get loglevel
warn
```

",False,0,CONTRIBUTOR
https://api.github.com/repos/npm/npm/issues/comments/367442955,Possible to silence npx `installed in` output?,kenany,7,298806127,6,367442955,0,367398361,2018-02-21T19:31:06Z,"Based on [this](https://github.com/npm/npm/blob/66ff2cacde4a1d83ee0020f0dda69fb91b78cfdd/bin/npx-cli.js#L8) I don't think npm config gets passed to `npx`, just CLI flags. In that case, all you can really utilize are [`npx`'s flags](https://github.com/zkat/npx/blob/357e6abc49077d7e4325406852d182220816e4f2/parse-args.js#L211).",False,0,CONTRIBUTOR
https://api.github.com/repos/npm/npm/issues/comments/368116167,Possible to silence npx `installed in` output?,Taz8du29,7,298806127,7,368116167,0,367442955,2018-02-23T19:34:34Z,"Isn't piping stdout to `grep --invert-match ""npx\: installed""` possible under macOS ?",False,0,NONE
https://api.github.com/repos/npm/npm/issues/comments/368126471,Possible to silence npx `installed in` output?,zeke,7,298806127,8,368126471,0,368116167,2018-02-23T20:14:57Z,"@Taz8du29 apparently not:

```
$ npx wikipedia-tldr ""nova scotia"" | grep --invert-match ""npx\: installed""
npx: installed 61 in 4.345s
Nova Scotia (/ˌnoʊvə ˈskoʊʃə/; Latin for ""New Scotland""...
```",False,0,CONTRIBUTOR
https://api.github.com/repos/npm/npm/issues/19875,Bring back nomnom 🙏,astorije,4,298817176,1,298817176,0,0,2018-02-21T02:06:09Z,"https://www.npmjs.com/package/nomnom has been deprecated, while hundreds of packages rely on it. I have noticed this because https://www.npmjs.com/package/jsonlint is now broken (see https://github.com/zaach/jsonlint/issues/103, https://github.com/zaach/jsonlint/pull/105) and since the package is not actively maintained, it is bound to be broken forever.

`nomnom` is downloaded [between 30k times per day during weekends and 150k times per day during weekdays](https://npm-stat.com/charts.html?package=nomnom), so it's very likely a lot of projects are suffering from this.

FYI, I have [pinged you on Twitter](https://twitter.com/astorije/status/965460128446205953) before opening an issue on the repo.",True,0,NONE
https://api.github.com/repos/npm/npm/issues/comments/367357642,Bring back nomnom 🙏,kenany,4,298817176,2,367357642,0,298817176,2018-02-21T15:11:29Z,Perhaps this should be moved to <https://github.com/npm/registry>?,False,0,CONTRIBUTOR
https://api.github.com/repos/npm/npm/issues/comments/367413001,Bring back nomnom 🙏,j-brown,4,298817176,3,367413001,0,367357642,2018-02-21T17:54:53Z,"I find this curious, as nomnom is #365 on the top 1000 most depended upon packages: https://gist.github.com/anvaka/8e8fa57c7ee1350e3491

Was nomnom owned/maintained by npm? ",False,0,NONE
https://api.github.com/repos/npm/npm/issues/comments/367417011,Bring back nomnom 🙏,ehsalazar,4,298817176,4,367417011,0,367413001,2018-02-21T18:07:20Z,👋 https://github.com/zaach/jsonlint/issues/103#issuecomment-367416531,False,0,NONE
https://api.github.com/repos/npm/npm/issues/comments/367571637,Bring back nomnom 🙏,astorije,4,298817176,5,367571637,0,367417011,2018-02-22T05:27:18Z,"Thanks for taking action, @ehsalazar!",False,0,NONE
https://api.github.com/repos/npm/npm/issues/19876,How to Publish customized react-native component in npm. Before that do we need to run 'npm run build' command? How to build the component?,aithashi,3,298905113,1,298905113,0,0,2018-02-21T09:56:45Z,"#### I'm opening this issue because:
Am unable to build the component before publishing. And what are al the steps/commands and procedures need to follow to publish to npm. Currently am unable to build.

  - [x] npm is producing an incorrect install.
  - [x] npm is doing something I don't understand.
  - [ ] Other (_see below for feature requests_):

#### What's going wrong?
PS C:\Users\aithashi\Sample-native\Newfolder> npm run build
npm ERR! Windows_NT 10.0.16299
npm ERR! argv ""C:\\Program Files\\nodejs\\node.exe"" ""C:\\Program 
     Files\\nodejs\\node_modules\\npm\\bin\\npm-cli.js"" ""run"" ""build""
npm ERR! node v7.10.0
npm ERR! npm  v4.2.0

npm ERR! missing script: build
#### How can the CLI team reproduce the problem?

<!--
    Please a complete description of how to reproduce the problem.
    Include a gist of your npm-debug.log file.
    If you've never used gist.github.com, start here:
      https://github.com/EmmaRamirez/how-to-submit-your-npm-debug-log
-->

### supporting information:

 - `npm -v` prints:
 - `node -v` prints:
 - `npm config get registry` prints:
 - Windows, OS X/macOS, or Linux?:
 - Network issues:
   - Geographic location where npm was run:
   - [ ] I use a proxy to connect to the npm registry.
   - [ ] I use a proxy to connect to the web.
   - [ ] I use a proxy when downloading Git repos.
   - [ ] I access the npm registry via a VPN
   - [ ] I don't use a proxy, but have limited or unreliable internet access.
 - Container:
   - [ ] I develop using Vagrant on Windows.
   - [ ] I develop using Vagrant on OS X or Linux.
   - [ ] I develop / deploy using Docker.
   - [ ] I deploy to a PaaS (Triton, Heroku).

<!--
    Thank you for contributing to npm! Please review this checklist
    before submitting your issue.

    - Please check if there's a solution in the troubleshooting wiki:
      https://github.com/npm/npm/blob/latest/TROUBLESHOOTING.md

    - Also ensure that your new issue conforms to npm's contribution guidelines:
      https://github.com/npm/npm/blob/latest/CONTRIBUTING.md

    - Participation in this open source project is subject to the npm Code of Conduct:
      https://www.npmjs.com/policies/conduct

    For feature requests, delete the above and uncomment the section following this one. But first, review the existing feature requests
    and make sure there isn't one that already describes the feature
    you'd like to see added:
      https://github.com/npm/npm/issues?q=is%3Aopen+is%3Aissue+label%3Afeature-request+label%3Aalready-looked-at
-->

<!--

#### What's the feature?

#### What problem is the feature intended to solve?

#### Is the absence of this feature blocking you or your team? If so, how?

#### Is this feature similar to an existing feature in another tool?

#### Is this a feature you're prepared to implement, with support from the npm CLI team?

-->
",True,0,NONE
https://api.github.com/repos/npm/npm/issues/comments/367538275,How to Publish customized react-native component in npm. Before that do we need to run 'npm run build' command? How to build the component?,zixuan75,3,298905113,2,367538275,0,298905113,2018-02-22T01:37:44Z,@aithashi You need add your npm version and node version includes your npm registry.,False,0,NONE
https://api.github.com/repos/npm/npm/issues/comments/367538437,How to Publish customized react-native component in npm. Before that do we need to run 'npm run build' command? How to build the component?,zixuan75,3,298905113,3,367538437,0,367538275,2018-02-22T01:38:37Z,What are you using on your computer? it looks like Windows.,False,0,NONE
https://api.github.com/repos/npm/npm/issues/comments/367570278,How to Publish customized react-native component in npm. Before that do we need to run 'npm run build' command? How to build the component?,aithashi,3,298905113,4,367570278,0,367538437,2018-02-22T05:17:00Z,"Thanks @zixuan75 , Yes am using windows. By the way i wanted in detail steps, what are the set up need to be done , and how to build and what are the supporting files before publishing. Also noticed that like in ReactJS am unable to use 'npm run build' command in React-native.",False,0,NONE
https://api.github.com/repos/npm/npm/issues/19877,Hoisting dependencies with peerDependencies can lead to unmet peer dependencies,filipesilva,7,298965480,1,298965480,0,0,2018-02-21T13:15:28Z,"#### I'm opening this issue because:

  - [ ] npm is crashing.
  - [x] npm is producing an incorrect install.
  - [ ] npm is doing something I don't understand.
  - [ ] Other (_see below for feature requests_):

#### What's going wrong?

There seems to be a problem with how `npm@5.6.0` hoists dependencies that have peer dependencies.

I have prepare a repro at https://github.com/filipesilva/ajv-peerdep-issue. Running `npm install` in this repository will show the following warning:
```
npm WARN ajv-keywords@3.1.0 requires a peer of ajv@^6.0.0 but none is installed. You must install peer dependencies yourself.
```

The following dependencies are relevant:
- this repro itself depends on two packages: `ajv@5.5.2` and `webpack@3.11.0`.
- `webpack@3.11.0` depends on `ajv@^6.1.0` and `ajv-keywords@^3.1.0`.
- `ajv-keywords@3.1.0` has a peer dependency on `ajv@^6.0.0`


When `npm` resolves these dependencies they end up looking like this:
```
ajv-peerdep-issue@1.0.0 D:\sandbox\ajv-peerdep-issue
`-- ajv@5.5.2
`-- ajv-keywords@3.1.0
`-- webpack@3.11.0
  `-- ajv@6.1.0
```

This is a problem because the hoisted `ajv-keywords@3.1.0` will not have its peer dependency on `ajv@^6.0.0` met.

#### How can the CLI team reproduce the problem?
```
git clone https://github.com/filipesilva/ajv-peerdep-issue
cd ajv-peerdep-issue
npm i
```

```
npm WARN ajv-keywords@3.1.0 requires a peer of ajv@^6.0.0 but none is installed. You must install peer dependencies yourself.
```

### supporting information:

 - `npm -v` prints: 5.6.0
 - `node -v` prints: 8.9.4
 - `npm config get registry` prints: https://registry.npmjs.org/
 - Windows, OS X/macOS, or Linux?: Windows 10
",True,0,NONE
https://api.github.com/repos/npm/npm/issues/comments/367904694,Hoisting dependencies with peerDependencies can lead to unmet peer dependencies,bjornstar,7,298965480,2,367904694,0,298965480,2018-02-23T04:12:02Z,"I have also created a simplified reproduction of this issue: @peer-deps-repro/main

This looks like another example of #15708
",False,0,NONE
https://api.github.com/repos/npm/npm/issues/comments/367944094,Hoisting dependencies with peerDependencies can lead to unmet peer dependencies,filipesilva,7,298965480,3,367944094,0,367904694,2018-02-23T08:35:10Z,"@bjornstar it does look like the same, yes. I added a comment there.",False,0,NONE
https://api.github.com/repos/npm/npm/issues/comments/368718136,Hoisting dependencies with peerDependencies can lead to unmet peer dependencies,not-an-aardvark,7,298965480,4,368718136,0,367944094,2018-02-27T01:50:49Z,We encountered this issue in ESLint too: https://github.com/eslint/eslint/pull/10022,False,0,CONTRIBUTOR
https://api.github.com/repos/npm/npm/issues/comments/368965759,Hoisting dependencies with peerDependencies can lead to unmet peer dependencies,ghost,7,298965480,5,368965759,0,368718136,2018-02-27T17:49:43Z,Encountered this issue in standard too: https://github.com/standard/standard/issues/1078#issuecomment-368962798,False,0,NONE
https://api.github.com/repos/npm/npm/issues/comments/368981968,Hoisting dependencies with peerDependencies can lead to unmet peer dependencies,billyjanitsch,7,298965480,6,368981968,0,368965759,2018-02-27T18:40:42Z,"This has been the case for awhile -- the npm hoisting algorithm doesn't currently consider whether a package's peer dependencies will be satisfied when hoisting it.

There was a [quick/dirty fix](https://github.com/npm/npm/pull/17678) in npm 5.2.0 but it was [rolled back](https://github.com/npm/npm/issues/17717#issuecomment-314599702) in 5.3.0 because they wanted to fix it properly & the naive fix broke users with [questionable dependency workflows](https://github.com/npm/npm/pull/17678#issuecomment-314397354).

It's an uncommon scenario but once in awhile it comes up in a popular package (in this case, eslint). The npm CLI team is aware of it.",False,0,NONE
https://api.github.com/repos/npm/npm/issues/comments/370663841,Hoisting dependencies with peerDependencies can lead to unmet peer dependencies,jeffora,7,298965480,7,370663841,0,368981968,2018-03-06T05:05:12Z,"It's also possible to hit this with `@angular/cli` with the following:

```
""devDependencies"": {
  ""@angular/cli"": ""^1.7.2"",
  ""@angular-devkit/core"": ""0.2.0""
}
```

This will cause `@schematics/*` packages to complain about missing peer dependency `@angular-devkit/core` and for `ng *` commands to crash.

Tested with `npm@5.6.0` and `npm@5.7.1`.

Works correctly with `yarn`.",False,0,NONE
https://api.github.com/repos/npm/npm/issues/comments/373153253,Hoisting dependencies with peerDependencies can lead to unmet peer dependencies,1st,7,298965480,8,373153253,0,370663841,2018-03-14T19:52:48Z,"I see the red highlight on this part:

```
  │ ├─┬ table@4.0.3
  │ │ ├─┬ UNMET PEER DEPENDENCY ajv@6.2.1
  │ │ │ ├── fast-deep-equal@1.1.0 deduped
  │ │ │ ├── fast-json-stable-stringify@2.0.0 deduped
  │ │ │ └── json-schema-traverse@0.3.1 deduped
  │ │ ├── ajv-keywords@3.1.0
  │ │ ├─┬ chalk@2.3.2
  │ │ │ ├── ansi-styles@3.2.1 deduped
  │ │ │ ├── escape-string-regexp@1.0.5 deduped
  │ │ │ └── supports-color@5.3.0 deduped
  │ │ ├── lodash@4.17.5 deduped
  │ │ ├─┬ slice-ansi@1.0.0
  │ │ │ └── is-fullwidth-code-point@2.0.0 deduped
  │ │ └── string-width@2.1.1 deduped
  │ └── text-table@0.2.0
```

and this message in the end:
```
npm ERR! peer dep missing: ajv@^6.0.0, required by ajv-keywords@3.1.0
```",False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/4650,Clearly document the behavior of multiple finalizer tasks,asarkar,3,303592806,1,303592806,0,0,2018-03-08T18:59:22Z,"When a task has multiple finalizers, as `finalizedBy(t2, t1)`, there are various unknowns. The current implementation seems to be sorting the tasks alphabetically, so `t1` would run before `t2`. However, it's not clear if they are fired parallely, or if `t2` runs even if `t1` fails.
",True,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/433079336,Clearly document the behavior of multiple finalizer tasks,jlstrater,3,303592806,2,433079336,0,303592806,2018-10-25T14:44:23Z,"when updating this section of the documentation, please also add clarification around the text 

```
On the other hand, finalizer tasks are not executed if the finalized task didn’t do any work, for example if it is considered up to date or if a dependent task fails.
```
The confusion happens when the task it finalizes is not up to date. One proposal was to change the text to 'if they are up-to-date themselves'",False,0,CONTRIBUTOR
https://api.github.com/repos/gradle/gradle/issues/comments/669336939,Clearly document the behavior of multiple finalizer tasks,stale[bot],3,303592806,3,669336939,0,433079336,2020-08-05T17:51:50Z,"This issue has been automatically marked as stale because it has not had recent activity. Given the limited bandwidth of the team, it will be automatically closed if no further activity occurs. If you're interested in how we try to keep the backlog in a healthy state, please read our [blog post on how we refine our backlog](https://blog.gradle.org/stale-issue-backlog). If you feel this is something you could contribute, please have a look at our [Contributor Guide](https://github.com/gradle/gradle/blob/master/CONTRIBUTING.md). Thank you for your contribution.
",False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/681050870,Clearly document the behavior of multiple finalizer tasks,stale[bot],3,303592806,4,681050870,0,669336939,2020-08-26T18:32:34Z,"This issue has been automatically closed due to inactivity. If you can reproduce this on a recent version of Gradle or if you have a good use case for this feature, please feel free to reopen the issue with steps to reproduce, a quick explanation of your use case or a high-quality pull request.
",False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/4655,Use polymorphic nested inputs for copy specs,lptr,5,303682329,1,303682329,0,0,2018-03-09T00:29:12Z,"Previously we used the runtime TaskInputs API to register copy specs as inputs by listening for child specs being added. Once we wanted to know the actual files to copy, or the final state of inherited the properties, CopySpecResolvers were created to do that job. This code was hard to follow, somewhat redundant and inefficient in places.

This commit introduces the immutable ResolvedCopySpec and ResolvedCopySpecNode types that capture the resolved properties and sources used by both input snapshotting and the execution of the copy actions. The resolved root spec is exposed as a `@Nested` property on the AbstractCopyTask type.
",True,0,MEMBER
https://api.github.com/repos/gradle/gradle/issues/comments/371672597,Use polymorphic nested inputs for copy specs,lptr,5,303682329,2,371672597,0,303682329,2018-03-09T00:29:52Z,Branch build: https://builds.gradle.org/viewQueued.html?itemId=11511080,False,0,MEMBER
https://api.github.com/repos/gradle/gradle/issues/comments/374308487,Use polymorphic nested inputs for copy specs,lptr,5,303682329,3,374308487,0,371672597,2018-03-19T18:00:41Z,Build: https://builds.gradle.org/viewQueued.html?itemId=11698744,False,0,MEMBER
https://api.github.com/repos/gradle/gradle/issues/comments/374504204,Use polymorphic nested inputs for copy specs,lptr,5,303682329,4,374504204,0,374308487,2018-03-20T07:45:22Z,Build: https://builds.gradle.org/viewQueued.html?itemId=11718956,False,0,MEMBER
https://api.github.com/repos/gradle/gradle/issues/comments/376420337,Use polymorphic nested inputs for copy specs,blindpirate,5,303682329,5,376420337,0,374504204,2018-03-27T07:09:01Z,"Are we still going to make it in `4.7RC1`? If not, please remove the milestone.",False,0,COLLABORATOR
https://api.github.com/repos/gradle/gradle/issues/comments/376424099,Use polymorphic nested inputs for copy specs,lptr,5,303682329,6,376424099,0,376420337,2018-03-27T07:25:11Z,"Thanks for the reminder, no, we are not doing this at all.",False,0,MEMBER
https://api.github.com/repos/gradle/gradle/issues/4661,Avoid deadlock between output event renderer and listener manager,ldaley,4,303724074,1,303724074,0,0,2018-03-09T04:53:19Z,"The addition of emitting build operation notifications for output events caused deadlock between OutputEventRenderer and the ListenerManager (an output listener now tries to notify other listeners). This change avoids the deadlock by not requiring acquisition of the listener manager lock to notify build operation listeners. Instead, we use a bespoke listener management implementation.

CI: https://builds.gradle.org/project.html?projectId=Gradle&tab=projectOverview&branch_Gradle=ldaley%2Favoid-logging-buildop-deadlock",True,0,MEMBER
https://api.github.com/repos/gradle/gradle/issues/comments/371785097,Avoid deadlock between output event renderer and listener manager,eskatos,4,303724074,2,371785097,0,303724074,2018-03-09T11:15:16Z,FTR see https://github.com/gradle/gradle/pull/4537#issuecomment-371476662 for how the problem was observed,False,0,MEMBER
https://api.github.com/repos/gradle/gradle/issues/comments/372004706,Avoid deadlock between output event renderer and listener manager,ldaley,4,303724074,3,372004706,0,371785097,2018-03-10T05:32:29Z,"This failed performance tests, until apply either of the following changes:

1. https://github.com/gradle/gradle/pull/4661/commits/ffef983c7c6e36b2ebefc531500923be00c99567
2. https://github.com/gradle/gradle/pull/4666/commits/c82bfcbf011ac76edbe962f3c86dc5516d1697d8

The margins involved are less than 100ms in all cases. 

@oehme @adammurdoch please advise what to do here:

1. Merge the simplest version that marginally regressed performance
2. Include both optimisations 
3. Include the adhoc listener optimisation only
4. Include the lock contention reduction  changes in OutputEventRenderer
",False,0,MEMBER
https://api.github.com/repos/gradle/gradle/issues/comments/372019343,Avoid deadlock between output event renderer and listener manager,oehme,4,303724074,4,372019343,0,372004706,2018-03-10T10:22:23Z,"I'd add the ad hoc listener optimisation and merge this fix. 

The lock contention problem deserves a more thorough cleanup I think. It's already hard to understand and it would be great if we could achieve an overall simplification there. E.g. if we have a queue in the OutputEventRenderer, we shouldn't need another one in the LogToClient class.",False,0,CONTRIBUTOR
https://api.github.com/repos/gradle/gradle/issues/comments/372163685,Avoid deadlock between output event renderer and listener manager,ldaley,4,303724074,5,372163685,0,372019343,2018-03-12T00:30:30Z," @oehme I also think that's the best option.

Currently, the output event renderer and the general mechanism for listening to output events are intertwined. This does not seem to be intentional based on the code and some other comments circulating this issue. Therefore, I think we should merge _this_ PR (which doesn't change `OutputEventRenderer`) and subsequently invest some more work in separating the output event listening infrastructure from the “rendering” infrastructure, which is likely to yield some performance optimisations.

@adammurdoch I'm pausing here to wait for confirmation from you.
",False,0,MEMBER
https://api.github.com/repos/gradle/gradle/issues/4668,Convert a bunch of subprojects build scripts to Kotlin,eskatos,3,303795025,1,303795025,0,0,2018-03-09T10:31:37Z,"- `:*-internal-*-testing`
- the 6 smaller remaining

Part of #4649",True,0,MEMBER
https://api.github.com/repos/gradle/gradle/issues/comments/371775919,Convert a bunch of subprojects build scripts to Kotlin,eskatos,3,303795025,2,371775919,0,303795025,2018-03-09T10:33:10Z,Feedback build https://builds.gradle.org/viewQueued.html?itemId=11520427,False,0,MEMBER
https://api.github.com/repos/gradle/gradle/issues/comments/375274416,Convert a bunch of subprojects build scripts to Kotlin,eskatos,3,303795025,3,375274416,0,371775919,2018-03-22T11:38:51Z,New feedback build https://builds.gradle.org/viewQueued.html?itemId=11789389,False,0,MEMBER
https://api.github.com/repos/gradle/gradle/issues/comments/375580533,Convert a bunch of subprojects build scripts to Kotlin,eskatos,3,303795025,4,375580533,0,375274416,2018-03-23T08:38:00Z,@bamboo ready for another round,False,0,MEMBER
https://api.github.com/repos/gradle/gradle/issues/4670,Introduce dependency locking in Gradle,ljacomet,7,303825095,1,303825095,0,0,2018-03-09T12:26:54Z,"* Configuration locking needs to be enabled, per configuration:
   * Locking a configuration that cannot be resolved has no effect.
```
configurations {
    compileClasspath {
        resolutionStrategy.activateDependencyLocking()
    }
}
```
or
```
dependencyLocking {
    lockAllConfigurations()
}
```
* Lockfiles are generated when the flag `--write-locks` is added to the command line.
A lock file will be generated for each resolved configuration.
* Existing lockfiles are read and used
  * A module part of the lockfile but resolved with a different version causes an error
* Upgrading a lockfile is done by doing `--write-locks` as in this case the lockfile is not consumed for resolution.

This represents the minimal set of locking to make it already usable. Improvements will be added as follow ups, including finer validation of the lock file to detect added or removed dependencies.",True,0,MEMBER
https://api.github.com/repos/gradle/gradle/issues/comments/373120046,Introduce dependency locking in Gradle,ljacomet,7,303825095,2,373120046,0,303825095,2018-03-14T18:04:56Z,"I have removed the WIP and started a build. This is functionally complete and before spending more time looking at performance, I would prefer getting an approval on the design / feature set.",False,0,MEMBER
https://api.github.com/repos/gradle/gradle/issues/comments/373122271,Introduce dependency locking in Gradle,ljacomet,7,303825095,3,373122271,0,373120046,2018-03-14T18:11:38Z,"Damn, forgot to run checks ... will be done tomorrow, sorry.",False,0,MEMBER
https://api.github.com/repos/gradle/gradle/issues/comments/376654230,Introduce dependency locking in Gradle,ljacomet,7,303825095,4,376654230,0,373122271,2018-03-27T19:56:46Z,Pushed a major update that gets rid of the plugin approach and leverages `strictly` constraints.,False,0,MEMBER
https://api.github.com/repos/gradle/gradle/issues/comments/376808348,Introduce dependency locking in Gradle,melix,7,303825095,5,376808348,0,376654230,2018-03-28T08:41:27Z,Also missing coverage: make sure that published metadata does **not** contain constraints from the lock file.,False,0,CONTRIBUTOR
https://api.github.com/repos/gradle/gradle/issues/comments/376856161,Introduce dependency locking in Gradle,ljacomet,7,303825095,6,376856161,0,376808348,2018-03-28T11:38:56Z,Pushed an update to the PR addressing specific comments. The next step is indeed to seriously improve test coverage. ,False,0,MEMBER
https://api.github.com/repos/gradle/gradle/issues/comments/376856515,Introduce dependency locking in Gradle,ljacomet,7,303825095,7,376856515,0,376856161,2018-03-28T11:40:39Z,"Regarding the addition of a task, not sure it is really needed as `./gradlew --write-locks dependencies --configuration <configurationName>` should do what's needed for a configuration. Unless I miss context where this is not a valid solution.",False,0,MEMBER
https://api.github.com/repos/gradle/gradle/issues/comments/376857196,Introduce dependency locking in Gradle,melix,7,303825095,8,376857196,0,376856515,2018-03-28T11:43:42Z,"> ./gradlew --write-locks dependencies --configuration <configurationName>

That's indeed an interesting way to do this!",False,0,CONTRIBUTOR
https://api.github.com/repos/gradle/gradle/issues/4671,Make multiple-origin processors incremental,oehme,6,303851098,1,303851098,0,0,2018-03-09T14:03:45Z,"Multiple origin processors can aggregate multiple source
elements into one output element or create warnings/errors
for such combinations of elements. They need to be provided
with all their elements of interest in the next compilation
when any of them has changed.

We handle this with a very simple approach: If a processor
registers itself for ""*"" (a.k.a all root elements), then we
always do a full recompile. If a processor only registers itself
for specific annotations, then we treat all elements with those
annotations as dirty on every compilation. This means that multiple
origin processors create small non-incremental clusters of code.",True,0,CONTRIBUTOR
https://api.github.com/repos/gradle/gradle/issues/comments/372265273,Make multiple-origin processors incremental,oehme,6,303851098,2,372265273,0,303851098,2018-03-12T10:41:51Z,@melix Could you give this a look or should I assign someone else for review?,False,0,CONTRIBUTOR
https://api.github.com/repos/gradle/gradle/issues/comments/372265634,Make multiple-origin processors incremental,melix,6,303851098,3,372265634,0,372265273,2018-03-12T10:43:15Z,I'd appreciate if you can find someone else because we have a pretty tight schedule in the dependency management team. If not possible I'll take a look.,False,0,CONTRIBUTOR
https://api.github.com/repos/gradle/gradle/issues/comments/372269993,Make multiple-origin processors incremental,oehme,6,303851098,4,372269993,0,372265634,2018-03-12T10:59:29Z,Thanks for letting me know! @eriwen @blindpirate may I ask for your review of this feature?,False,0,CONTRIBUTOR
https://api.github.com/repos/gradle/gradle/issues/comments/372944273,Make multiple-origin processors incremental,blindpirate,6,303851098,5,372944273,0,372269993,2018-03-14T08:41:00Z,"Really awesome work @oehme ! 

I have only one question: when a generated file is deleted, a complete recompile (even the unrelated files) will be performed, can you clarify why this is the expected behavior?",False,0,COLLABORATOR
https://api.github.com/repos/gradle/gradle/issues/comments/372948739,Make multiple-origin processors incremental,oehme,6,303851098,6,372948739,0,372944273,2018-03-14T08:58:59Z,"> I have only one question: when a generated file is deleted, a complete recompile (even the unrelated files) will be performed, can you clarify why this is the expected behavior?

That's unrelated to incremental compile, it's just how outputs work in Gradle. If you mess with a task's output files in any way, the task will not be incremental. This could certainly be improved in the future. So the test is documenting the current, not necessarily the best behavior.",False,0,CONTRIBUTOR
https://api.github.com/repos/gradle/gradle/issues/comments/372948888,Make multiple-origin processors incremental,blindpirate,6,303851098,7,372948888,0,372948739,2018-03-14T08:59:34Z,Thanks for clarifying!,False,0,COLLABORATOR
https://api.github.com/repos/gradle/gradle/issues/4675,Setting executableDir might make the start script unusable,Vampire,9,303921441,1,303921441,0,0,2018-03-09T17:37:23Z,"### Expected Behavior
If you set `executableDir` to `''` or to `'i/love/subdirectories/bin'`, the start scripts should still work as expected and if not feasible at least a validation of the value should be done and the build fail, but having it working would be more expected and wanted.

### Current Behavior
The calculateion of `APP_HOME` in the start scripts assume that the start script is exactly one directory layer below the distribution directory and thus fails to work properly if there are more or less layers.

### Your Environment
Gradle 4.6
",True,0,CONTRIBUTOR
https://api.github.com/repos/gradle/gradle/issues/comments/374498484,Setting executableDir might make the start script unusable,blindpirate,9,303921441,2,374498484,0,303921441,2018-03-20T07:15:59Z,"Sorry for the late response, but I don't think so. According to https://github.com/gradle/gradle/blob/ecd4e22675a2d79adc02cafea1975508fd12cbf4/subprojects/plugins/src/main/resources/org/gradle/api/internal/plugins/unixStartScript.txt#L23 and https://github.com/gradle/gradle/blob/a41ab5a643bef06bd01fec04f770023c7316324f/subprojects/plugins/src/main/java/org/gradle/api/internal/plugins/StartScriptTemplateBindingFactory.java#L178

We do render the start script with correct relative path. And I tried with `i/love/subdirectories/bin`, then run `installDist` and the generated script, all works well. Could you please provide a sample and detailed steps?",False,0,COLLABORATOR
https://api.github.com/repos/gradle/gradle/issues/comments/375719950,Setting executableDir might make the start script unusable,Vampire,9,303921441,3,375719950,0,374498484,2018-03-23T16:19:16Z,"I'm sorry, I was wrong about `'i/love/subdirectories/bin'`, that works fine.
But `''` does not work. In that case there is one `..` too much.",False,0,CONTRIBUTOR
https://api.github.com/repos/gradle/gradle/issues/comments/375826492,Setting executableDir might make the start script unusable,blindpirate,9,303921441,4,375826492,0,375719950,2018-03-23T23:46:18Z,I see. Thanks for reporting and sorry for missing that.,False,0,COLLABORATOR
https://api.github.com/repos/gradle/gradle/issues/comments/488086272,Setting executableDir might make the start script unusable,tomas-pluskal,9,303921441,5,488086272,0,375826492,2019-04-30T19:36:29Z,"It seems setting ```executableDir``` to ```''``` still does not work with Gradle 5.4.1. 
Is there any workaround for that?
",False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/489776122,Setting executableDir might make the start script unusable,tomas-pluskal,9,303921441,6,489776122,0,488086272,2019-05-06T21:04:18Z,"FYI, I opened a new issue for this problem (#9351) and I submitted a pull request with the fix.
",False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/489818874,Setting executableDir might make the start script unusable,Vampire,9,303921441,7,489818874,0,489776122,2019-05-06T23:05:52Z,"Opening a PR is great @tomas-pluskal, but why did you open the exact same issue again as duplicate when you already know it is reported in this issue here? o_O

Besides that, the workaround is to either use a custom start script template or to post-process the existing one.

With Kotlin you can do it for example like

```kotlin
application {
    executableDir = """"
    mainClassName = ""my.main.Class""
}

tasks.startScripts {
    doLast {
        unixScript.writeText(unixScript.readText()
                .replace(""cd \""`dirname \\\""\$PRG\\\""`/..\"" >/dev/null"", ""cd \""`dirname \\\""\$PRG\\\""`\"" >/dev/null"")
        )
        windowsScript.writeText(windowsScript.readText()
                .replace(""set APP_HOME=%DIRNAME%.."", ""set APP_HOME=%DIRNAME%"")
        )
    }
}
```
or accordingly with Gradle.",False,0,CONTRIBUTOR
https://api.github.com/repos/gradle/gradle/issues/comments/489822212,Setting executableDir might make the start script unusable,tomas-pluskal,9,303921441,8,489822212,0,489818874,2019-05-06T23:22:02Z,"Strange question, considering that nobody touched this issue for more than a year.. o_O

How about the PR? I would prefer to fix the issue rather than use workarounds.",False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/489822677,Setting executableDir might make the start script unusable,Vampire,9,303921441,9,489822677,0,489822212,2019-05-06T23:24:19Z,"As I said, PR is great (per-se, didn't review).
Just wait some time, usually the Gradle guys are relatively fast in accepting PRs, or at least looking at them.",False,0,CONTRIBUTOR
https://api.github.com/repos/gradle/gradle/issues/comments/532380047,Setting executableDir might make the start script unusable,tomas-pluskal,9,303921441,10,532380047,0,489822677,2019-09-17T20:04:57Z,"It seems the commit that was supposed to fix this issue only fixed the unix start script, but not the Windows start script. This issue still remains on Windows. See #10387",False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/4678,Support capturing logs from JavaCompile tasks,davidburstromspotify,6,303999619,1,303999619,0,0,2018-03-09T22:23:03Z,"### Expected Behavior
Much like it is possible to capture process output from JavaExec tasks, it should be possible to capture output from JavaCompile. The means of specifying the output sink with the DSL is up to Gradle to decide upon.

### Current Behavior
Using the logging configuration for JavaCompile tasks to add output listeners does not work the way users expect. During parallel execution of JavaCompile tasks, each output listener added to each task will see the output of the other tasks.
It is also not possible to use the ""-Xstdout"" flag in javac, as it is not supported by the supplied compiler in Gradle.

### Context
To provide the most value from a CI build, it is useful to specify ""--continue"". The problem is that compilation issues for a given task is difficult to find in a lengthy build log, and because of parallel execution, it can even be difficult to correlate the output with the correct task. In a CI setting, we would like to export the output from each failed task into individual files and report them at developer convenience.
",True,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/378438204,Support capturing logs from JavaCompile tasks,stephanenicolas,6,303999619,2,378438204,0,303999619,2018-04-04T00:09:10Z,"Thx so much for opening this issue. On our side we are trying to filter the deprecation warnings and store them in a file. But there is no way to prevent a JavaCompile task from.logging. 

It is probably due to the daemonesque nature of compilation, but it would really nice to have this working or -Xstdout being supported.",False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/378654000,Support capturing logs from JavaCompile tasks,stephanenicolas,6,303999619,3,378654000,0,378438204,2018-04-04T16:02:29Z,"I checked the source code and the issue with `-Xstdout` comes from javac itself. The only solution would be to redirect the output stream of the compiler, which seems possible. It could be added to the JavaCompileSpec and passed to `org.gradle.api.internal.tasks.compile.JdkJavaCompiler#createCompileTask`. The first argument is a writer that receives the errors.",False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/460812099,Support capturing logs from JavaCompile tasks,stephanenicolas,6,303999619,4,460812099,0,378654000,2019-02-05T21:32:45Z,Great to see this getting prioritized ! @ghale ,False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/498108672,Support capturing logs from JavaCompile tasks,hakanai,6,303999619,5,498108672,0,460812099,2019-06-03T04:27:33Z,"Ah, is there absolutely no way to do this right now? I am looking for a workaround for there being no obvious way to capture and count warnings. :(
",False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/704587057,Support capturing logs from JavaCompile tasks,stale[bot],6,303999619,6,704587057,0,498108672,2020-10-06T22:29:36Z,"This issue has been automatically marked as stale because it has not had recent activity. Given the limited bandwidth of the team, it will be automatically closed if no further activity occurs. If you're interested in how we try to keep the backlog in a healthy state, please read our [blog post on how we refine our backlog](https://blog.gradle.org/stale-issue-backlog). If you feel this is something you could contribute, please have a look at our [Contributor Guide](https://github.com/gradle/gradle/blob/master/CONTRIBUTING.md). Thank you for your contribution.
",False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/717627712,Support capturing logs from JavaCompile tasks,stale[bot],6,303999619,7,717627712,0,704587057,2020-10-28T00:53:23Z,"This issue has been automatically closed due to inactivity. If you can reproduce this on a recent version of Gradle or if you have a good use case for this feature, please feel free to reopen the issue with steps to reproduce, a quick explanation of your use case or a high-quality pull request.
",False,0,NONE
https://api.github.com/repos/Automattic/mongoose/issues/6217,Deprecation warning when connecting with 4.13.11,srlowe,9,303410903,1,303410903,0,0,2018-03-08T09:27:09Z,"<!-- *Before creating an issue please make sure you are using the latest version of mongoose -->

**Do you want to request a *feature* or report a *bug*?**

Bug.

**What is the current behavior?**

I'm getting this message when I connect with latest release of v4:

```
`open()` is deprecated in mongoose >= 4.11.0, use `openUri()` instead, or set the `useMongoClient` option if using `connect()` or `createConnection()`. See http://mongoosejs.com/docs/connections.html#use-mongo-client
```

I found a previous report, but the issue was closed and the comments were locked.  

I checked the document link in the warning, but all I can see about this issue (under heading 'Option Changes in v5.x') relates to v5.  Please could you clarify what the situation is for latest v4?  Should I be adding useMongoClient in options?

**Please mention your node.js, mongoose and MongoDB version.**

Node 4.8.2, Mongoose 4.13.11, Mongodb 3.2, 

",True,0,NONE
https://api.github.com/repos/Automattic/mongoose/issues/comments/371446018,Deprecation warning when connecting with 4.13.11,lineus,9,303410903,2,371446018,0,303410903,2018-03-08T10:24:53Z,"Hi @bgSosh. 
to get around this issue you can add an options object as the 2nd arg to .connect() with useMongoClient: true.

here is an example:
`mongoose.connect('mongodb://localhost:27017/test', { useMongoClient: true })`

Thanks for pointing out the issue with the error message. I'll submit a pull request to update it to point to the 4.x docs [here](http://mongoosejs.com/docs/4.x/docs/connections.html#use-mongo-client).",False,0,COLLABORATOR
https://api.github.com/repos/Automattic/mongoose/issues/comments/371448932,Deprecation warning when connecting with 4.13.11,srlowe,9,303410903,3,371448932,0,371446018,2018-03-08T10:36:02Z,Thanks @lineus - all clear now!,False,0,NONE
https://api.github.com/repos/Automattic/mongoose/issues/comments/371453831,Deprecation warning when connecting with 4.13.11,srlowe,9,303410903,4,371453831,0,371448932,2018-03-08T10:56:16Z,"@lineus Hmm, ran into an issue with this - is there perhaps no createConnection that accepts both an option and a callback?

This works:
```
 dbConnection = mongoose.createConnection(connectionString_Forum, function(err) { 
       //Called back
 });
```
But this doesn't:
```
 dbConnection = mongoose.createConnection(connectionString_Forum, { useMongoClient: true }, function(err) { 
       //Not called back
 });
```",False,0,NONE
https://api.github.com/repos/Automattic/mongoose/issues/comments/371467457,Deprecation warning when connecting with 4.13.11,lineus,9,303410903,5,371467457,0,371453831,2018-03-08T12:00:17Z,createConnection() doesn't take a callback. it only takes a uri and options and returns an instance of the native driver connection. Are you connecting to multiple dbs or is there some other compelling reason to use mongoose.createConnection() instead of mongoose.connect()?,False,0,COLLABORATOR
https://api.github.com/repos/Automattic/mongoose/issues/comments/371470249,Deprecation warning when connecting with 4.13.11,srlowe,9,303410903,6,371470249,0,371467457,2018-03-08T12:13:43Z,"Exactly, we need to connect to multiple dbs, and need a reference to the non-default connections.

Thanks for the clarification on createConnection().  Though, I can confirm that the callback is definitely called (when cb is the second parameter), but perhaps that's some unintended effect?  

Is there any reason why connect() and createConnection() should have these differences?

Could you tell me the correct way to get an async notification of the connection event for createConnection in v4?

Thanks for your help.
",False,0,NONE
https://api.github.com/repos/Automattic/mongoose/issues/comments/371476640,Deprecation warning when connecting with 4.13.11,lineus,9,303410903,7,371476640,0,371470249,2018-03-08T12:44:42Z,"it looks like when you call createConnection(), whatever options is, it gets passed to connection.openUri, which checks if options is a function and conditionally reassigns it to the callback option. 
I'm probably not the best person to speak to the reasoning for historical decisions, so I'll leave that up to @vkarpov15 or @varunjayaraman. 

you can listen for the open event of the connection thusly:
```
const conn = mongoose.createConnection(uri, options)
conn.on('open', callback)
```

I'm also reasonably sure that you can  just use the Model calls without listening for the event, as long as you attach the Model to the conn. 

here is a contrived example of this:
```
#!/usr/bin/env node
'use strict'

const mongoose = require('mongoose')
mongoose.Promise = global.Promise
const Schema = mongoose.Schema
const options = { useMongoClient: true }
const aConn = mongoose.createConnection('mongodb://localhost:27017/test', options)
const bConn = mongoose.createConnection('mongodb://localhost:27018/test', options)

const userSchema = new Schema({
  name: String
})

const AModel = aConn.model('users', userSchema)
const BModel = bConn.model('users', userSchema)

const aUser = new AModel({ name: 'Jose' })
const bUser = new BModel({ name: 'Jane' })

function saved (err, doc) {
  if (err) { return console.error(err) }
  console.log(doc)
}

aUser.save(saved)
bUser.save(saved)
```
output:
```
$ ./6217.js 
{ __v: 0, name: 'Jose', _id: 5aa153de19604f3d00010a99 }
{ __v: 0, name: 'Jane', _id: 5aa153de19604f3d00010a9a }
^C
$ mongo test --port 27017 --quiet
> db.users.find()
{ ""_id"" : ObjectId(""5aa153de19604f3d00010a99""), ""name"" : ""Jose"", ""__v"" : 0 }
> 
$ mongo test --port 27018 --quiet
> db.users.find()
{ ""_id"" : ObjectId(""5aa153de19604f3d00010a9a""), ""name"" : ""Jane"", ""__v"" : 0 }
> 
$ 

```",False,0,COLLABORATOR
https://api.github.com/repos/Automattic/mongoose/issues/comments/371483274,Deprecation warning when connecting with 4.13.11,srlowe,9,303410903,8,371483274,0,371476640,2018-03-08T13:15:47Z,Thanks again @lineus.  Might be nice to have createConnection() match the supported signatures of connect() - maybe the devs you linked could comment on the feasibility of that.,False,0,NONE
https://api.github.com/repos/Automattic/mongoose/issues/comments/371722249,Deprecation warning when connecting with 4.13.11,vkarpov15,9,303410903,9,371722249,0,371483274,2018-03-09T06:04:45Z,@lineus the fact that `useMongoClient` + `createConnection()` means you can't pass a callback is an unintentional bug. Will fix for 4.13.12 :+1: ,False,0,COLLABORATOR
https://api.github.com/repos/Automattic/mongoose/issues/comments/371740433,Deprecation warning when connecting with 4.13.11,srlowe,9,303410903,10,371740433,0,371722249,2018-03-09T07:58:33Z,"Ah, great! thanks @vkarpov15, @lineus ",False,0,NONE
https://api.github.com/repos/Automattic/mongoose/issues/6220,Skip and limit doesn't work,alpmusti,5,303501715,1,303501715,0,0,2018-03-08T14:37:52Z,"I've upgraded mongoose `4.13.11` to `5.0.9` and below code returns all of the collection data no matter what `skip` and `limit` parameters are

```
const searchQuery = {name: name , device_id : deviceId};
VariableTransactions.find(searchQuery , callback).skip(skip).limit(take).sort({time_stamp : (sort == 'asc') ? 1 : -1});    
```

I've just tried simply : 

```
VariableTransactions.find({device_id: deviceId} , callback).limit(1);
```
Didn't work with this way either. Returned all data this collection has.

Node.js version : `6.11.4`
mongoose version: `5.0.9` 
MongoDB version: `3.4.10`
",True,0,NONE
https://api.github.com/repos/Automattic/mongoose/issues/comments/371587824,Skip and limit doesn't work,lineus,5,303501715,2,371587824,0,303501715,2018-03-08T18:58:58Z,"if you move your callback from within find, to an exec on the end of your chain, it should work. I created the following example:
```
#!/usr/bin/env node
'use strict'

const mongoose = require('mongoose')
mongoose.connect('mongodb://localhost/test')
const Schema = mongoose.Schema
const faker = require('faker')

const testSchema = new Schema({
  name: String,
  age: Number,
  status: String
})

const Test = mongoose.model('test', testSchema)

const tests = []
for (let i = 0; i < 100; i++) {
  let pushName = (i % 2 === 0) ? 'billy' : 'jane'
  tests.push(new Test({
    name: pushName,
    age: faker.random.number({ min: 1, max: 80 }),
    status: faker.company.bsAdjective()
  }))
}

function findCallBack (err, docs) {
  if (err) { return console.error(err) }
  mongoose.connection.close()
  return console.log(docs.length)
}

Test.remove({}).then(() => {
  Test.create(tests, (err, created) => {
    if (err) { return console.error(err) }
    let query = { name: 'billy' }
    return Test.find(query).skip(10).limit(25).exec(findCallBack)
  })
})
```
### output with Test.find(query).skip(10).limit(25).exec(findCallBack):
```
InspiredMacPro:mongoose5 lineus$ ./6220.js 
25
InspiredMacPro:mongoose5 lineus$ 
```
### output with Test.find(query, findCallBack).skip(10).limit(25)
```
InspiredMacPro:mongoose5 lineus$ ./6220.js 
50
InspiredMacPro:mongoose5 lineus$
```",False,0,COLLABORATOR
https://api.github.com/repos/Automattic/mongoose/issues/comments/371592021,Skip and limit doesn't work,lineus,5,303501715,3,371592021,0,371587824,2018-03-08T19:12:41Z,"From reading both the version 4 and version 5 docs, it doesn't seem like the chained queries **and** a find callback should have worked in version 4, but I ran my test script above with the callback passed into find instead of an exec and it returned the skipped and limited data set (25 instead of 50). The docs are pretty clear that passing a callback into find will cause the query to execute immediately, so I can't say that this a bug, but the behavior is clearly different between 4 and 5. 

### here's the code I ran on mongoose 4.13.11:
```
#!/usr/bin/env node
'use strict'

const mongoose = require('mongoose')
mongoose.Promise = global.Promise
mongoose.connect('mongodb://localhost/test', { useMongoClient: true })
const Schema = mongoose.Schema
const faker = require('faker')

const testSchema = new Schema({
  name: String,
  age: Number,
  status: String
})

const Test = mongoose.model('test', testSchema)

const tests = []
for (let i = 0; i < 100; i++) {
  let pushName = (i % 2 === 0) ? 'billy' : 'jane'
  tests.push(new Test({
    name: pushName,
    age: faker.random.number({ min: 1, max: 80 }),
    status: faker.company.bsAdjective()
  }))
}

function findCallBack (err, docs) {
  if (err) { return console.error(err) }
  mongoose.connection.close()
  return console.log(docs.length)
}

Test.remove({}).then(() => {
  Test.create(tests, (err, created) => {
    if (err) { return console.error(err) }
    let query = { name: 'billy' }
    return Test.find(query, findCallBack).skip(10).limit(25)
  })
})

```
### output:
```
InspiredMacPro:mongoose4 lineus$ ./6220.js 
25
InspiredMacPro:mongoose4 lineus$
```",False,0,COLLABORATOR
https://api.github.com/repos/Automattic/mongoose/issues/comments/371790481,Skip and limit doesn't work,alpmusti,5,303501715,4,371790481,0,371592021,2018-03-09T11:42:07Z,I've tried with `exec(callback);` and it worked for me. Thank your for help.,False,0,NONE
https://api.github.com/repos/Automattic/mongoose/issues/comments/372823510,Skip and limit doesn't work,vkarpov15,5,303501715,5,372823510,0,371790481,2018-03-13T21:24:09Z,"@lineus is correct. Please make sure your query is fully constructed before passing a callback, because passing a callback actually executes the query.",False,0,COLLABORATOR
https://api.github.com/repos/Automattic/mongoose/issues/comments/621794828,Skip and limit doesn't work,HomyeeKing,5,303501715,6,621794828,0,372823510,2020-04-30T12:13:49Z,"thank u guys, it helps ,that's what I need",False,0,NONE
https://api.github.com/repos/Automattic/mongoose/issues/6222,Date is not storing correctly,sam-rusty,3,303572885,1,303572885,0,0,2018-03-08T17:54:01Z,"I have setup schema correctly for `created_on` to `Date` Type but for some reasons instead of storing ISODate format it store date object incorrectly like this:
`'date': {
        '_isAMomentObject': '1',
        '_isUTC': '',
        '_pf': {
            'empty': '',
            'unusedTokens': [  ],
            'unusedInput': [  ],
            'overflow': -2,
            'charsLeftOver': 0,
            'nullInput': '',
            'invalidMonth': '',
            'invalidFormat': '',
            'userInvalidated': '',
            'iso': '',
            'parsedDateParts': [  ],
            'meridiem': '',
            'rfc2822': '',
            'weekdayMismatch': ''
        },
......... 
`

when inserting new document i use `new Date()` I have tried different version of mongoose but no luck.
Anyone can help?
`mongoose: 5.6.0`
`Node: 9.4.0`
`MongoDB: 3.2.4`",True,0,NONE
https://api.github.com/repos/Automattic/mongoose/issues/comments/371573015,Date is not storing correctly,lineus,3,303572885,2,371573015,0,303572885,2018-03-08T18:08:47Z,"@iridiumsoft have you tried Date.now() ? if that doesn't work, please include your schema and the code where you create and save a new document here and we'll help you figure it out.",False,0,COLLABORATOR
https://api.github.com/repos/Automattic/mongoose/issues/comments/371851539,Date is not storing correctly,JasonCust,3,303572885,3,371851539,0,371573015,2018-03-09T15:50:06Z,"@iridiumsoft I'd recommend posting this on SO and tagging it with ""mongoose"". Include your schema and the applicable code for creating and saving the record.",False,0,NONE
https://api.github.com/repos/Automattic/mongoose/issues/comments/375464099,Date is not storing correctly,sobafuchs,3,303572885,4,375464099,0,371851539,2018-03-22T21:29:58Z,@iridiumsoft we cant do much more without a schema. Please post a schema so we can help resolve this issue,False,0,CONTRIBUTOR
https://api.github.com/repos/Automattic/mongoose/issues/6224,pre.remove middleware of objects in array are never called (with 5.0.9),jmcollin78,10,303603562,1,303603562,0,0,2018-03-08T19:34:07Z,"**Do you want to request a *feature* or report a *bug*?**
A bug

**What is the current behavior?**
I create an Embedded object named FileSpace into an array of object named Space. When removing FileSpace, pre remove middleware is never call (but pre validate middleware is called)

**If the current behavior is a bug, please provide the steps to reproduce.**
<!-- If you can, provide a standalone script / gist to reproduce your issue -->
Here is a repro code:
<pre>
'use strict';

var mongoose = require('mongoose'),
	Schema = mongoose.Schema;

mongoose.set('debug', true);


/**
 *  A file
 */
var FileSpaceSchema = new Schema({
	fileKey: {
		type: String,
		required: true
	}
});

// Normally called 
FileSpaceSchema.pre('validate', function (next) {
	console.log('Calling FileSpace.pre.validate me=""%s""', this.fileKey);
	next();
});

// Never called !
FileSpaceSchema.pre('remove', function(next) {
	console.log(' !!! Calling FileSpace.pre.remove fileKey=""%s""', this.fileKey);
	next();
});

let FileSpace = mongoose.model('FileSpace', FileSpaceSchema);

/**
 * A space containing an array of files
 */
var SpaceDocSchema = new Schema({
	label: {
		type: 'string',
		required: true
	},
	files: [FileSpaceSchema]
});

SpaceDocSchema.pre('validate', function (next) {
	console.log('Calling SpaceDocSchema.preValidate hook spaceDoc is ""%s""', this.label);
	next();
});

SpaceDocSchema.pre('remove', function (next) {
	console.log('Calling Space.post.remove spaceDoc is ""%s""', this.label);
	next();
});

let SpaceDoc = mongoose.model('SpaceDoc', SpaceDocSchema);

console.log('--> Starting');

console.log('--> Creating a space');
let space = new SpaceDoc({
	label: 'The SpaceDoc'
}),
	removedFile;

// connect to mongo
mongoose.connect('mongodb://mongodbsrv/clouderialTestDB?w=1&j=true');

mongoose.connection.on('open', () => {
	console.log('Connection to MongoDB is effective');
	
	space.save()
		.then((s) => {
			space = s;
			console.log('Created space is ""%s""', s.label);
			
			console.log('--> Creating a FileSpace');
			return new FileSpace({fileKey : 'fileSpace', spaceLabel:'The space label'}).save();
		})
		.then((fs) => {
			console.log('Created FileSpace is ""%s""', fs.fileKey);
			console.log('--> Add fileSpace into SpaceDoc.files');
			space.files.push(fs);
			space.markModified('files');
			return space.save();
		})
		.then((s) => {
			space = s;
			console.log('Updated space is ""%s"", nbFiles=""%d""', space.label, space.files.length);
			console.log('--> Remove fileSpace from space');
			removedFile = space.files[0];
			space.files.splice(0, 1);
//			space.files = [];
			space.markModified('files');
			console.log('--> Update space without file');
			return space.save();
		})
		.then((s) => {
			space = s;
			console.log('Updated space is ""%s"", nbFiles=""%d""', space.label, space.files.length);
			console.log('--> Remove fileSpace');
			return removedFile.remove();
		})
		.then(() => {
			console.log('--> Should see the call to pre.remove of FileSpace');
			console.log('--> Remove space');
			return space.remove();
		})
		.catch(console.error);
});

setTimeout(() => {
	console.log('--> Close MongoDB connection');
	mongoose.connection.close();
}, 3000);
</pre>

The output is the following:
<pre>
$ npm start

> test@0.0.1 start /datas/cld-apps/test
> NODE_PATH=/home/vagrant/cld-apps/node_modules:. TZ=Europe/Paris node test.js

--> Starting
--> Creating a space
Connection to MongoDB is effective
Calling SpaceDocSchema.preValidate hook spaceDoc is ""The SpaceDoc""
Mongoose: spacedocs.insert({ label: 'The SpaceDoc', files: [], _id: ObjectId(""5aa18e47f13311778fdc3beb""), __v: 0 })
Created space is ""The SpaceDoc""
--> Creating a FileSpace
Calling FileSpace.pre.validate me=""fileSpace""
Mongoose: filespaces.insert({ fileKey: 'fileSpace', _id: ObjectId(""5aa18e47f13311778fdc3bec""), __v: 0 })
Created FileSpace is ""fileSpace""
--> Add fileSpace into SpaceDoc.files
Calling SpaceDocSchema.preValidate hook spaceDoc is ""The SpaceDoc""
Calling FileSpace.pre.validate me=""fileSpace""
Mongoose: spacedocs.update({ _id: ObjectId(""5aa18e47f13311778fdc3beb""), __v: 0 }, { '$set': { files: [ { fileKey: 'fileSpace', _id: ObjectId(""5aa18e47f13311778fdc3bec""), __v: 0 } ] }, '$inc': { __v: 1 } })
Updated space is ""The SpaceDoc"", nbFiles=""1""
--> Remove fileSpace from space
--> Update space without file
Calling SpaceDocSchema.preValidate hook spaceDoc is ""The SpaceDoc""
Mongoose: spacedocs.update({ _id: ObjectId(""5aa18e47f13311778fdc3beb""), __v: 1 }, { '$set': { files: [] }, '$inc': { __v: 1 } })
Updated space is ""The SpaceDoc"", nbFiles=""0""
--> Remove fileSpace
--> Should see the call to pre.remove of FileSpace
--> Remove space
Calling Space.post.remove spaceDoc is ""The SpaceDoc""
Mongoose: spacedocs.remove({ _id: ObjectId(""5aa18e47f13311778fdc3beb"") }, {})
--> Close MongoDB connection
</pre>

**What is the expected behavior?**
We should see the log line:
<pre>!!! Calling FileSpace.pre.remove fileKey</pre>

**Please mention your node.js, mongoose and MongoDB version.**
Node 9.5.0, Mongoose 5.0.9, MongoDB 3.6.3, Mongo driver: 3.0.3

EDIT: try with 5.0.9.",True,0,NONE
https://api.github.com/repos/Automattic/mongoose/issues/comments/372117698,pre.remove middleware of objects in array are never called (with 5.0.9),lineus,10,303603562,2,372117698,0,303603562,2018-03-11T14:00:07Z,"Hi @jmcollin78 Thanks for the thorough repro script! 

In your example you are calling .remove() on an embedded document. Which [according to the docs](http://mongoosejs.com/docs/subdocs.html) is equivalent to calling pull on the subdocument. This does not fire a remove event. The subdocs .remove() middleware will only run when you call .remove() on the parent document. Here is an example:
```
'use strict'

const mongoose = require('mongoose')
mongoose.connect('mongodb://localhost/test')
const Schema = mongoose.Schema

const subSchema = new Schema({
  name: String
})

subSchema.pre('save', (next) => {
  console.log('subSchema.pre:save on', this)
  next()
})

subSchema.pre('remove', (next) => {
  console.log('subSchema.pre:remove!')
  next()
})

const schema = new Schema({
  name: String,
  subs: [subSchema]
})

schema.pre('save', (next) => {
  console.log('schema.pre:save!', this)
  next()
})

schema.pre('remove', (next) => {
  console.log('schema.pre:remove!', this)
  next()
})

const Test = mongoose.model('tests', schema)

const obj = {
  name: 'Outer',
  subs: [{
    name: 'Franklin'
  }]
}

const test1 = new Test(obj)
const test2 = new Test(obj)

test1.save((err, doc) => {
  if (err) { return console.error(err) }
  console.log('calling remove on subdoc:')
  doc.subs[0].remove()
  doc.save()
})

test2.save((err, doc) => {
  if (err) { return console.error(err) }
  console.log('calling remove on doc:')
  doc.remove()
  mongoose.connection.close()
})
```
output:
```
InspiredMacPro:6224 lineus$ node index.js
subSchema.pre:save on {}
subSchema.pre:save on {}
schema.pre:save! {}
schema.pre:save! {}
calling remove on subdoc:
schema.pre:save! {}
calling remove on doc:
subSchema.pre:remove!
schema.pre:remove! {}
InspiredMacPro:6224 lineus$
```
as you can see, the remove hooks only get run when you call remove on the parent document. but in both cases, remove and save, the subdoc's hooks get run first, then the parents.

",False,0,COLLABORATOR
https://api.github.com/repos/Automattic/mongoose/issues/comments/372219810,pre.remove middleware of objects in array are never called (with 5.0.9),jmcollin78,10,303603562,3,372219810,0,372117698,2018-03-12T07:50:36Z,"Many thanks for this !
I understand your repro case, and in fact you have confirm my observation. But you don't give an explanation but only ""it is like that"".

If I remove a doc or a subdoc, I guess it should be removed, and subsequently, remove hooks should be called.
I can't understand why doc.subs[0].remove() don't call the pre.remove hook. Do you think it's normal and if yes, what can be the reason ?

Thanks for your explanation.
",False,0,NONE
https://api.github.com/repos/Automattic/mongoose/issues/comments/372278295,pre.remove middleware of objects in array are never called (with 5.0.9),lineus,10,303603562,4,372278295,0,372219810,2018-03-12T11:26:49Z,"@jmcollin78 I'm pretty new to mongoose and mongodb, rather than guess or make assumptions, I'll CC some folks that will have the answer.

@vkarpov15 @varunjayaraman What is the reasoning behind only hooking a subdocument's remove when the parent is removed and not when the remove call is made on just the subdoc? 

I looked for existing open/closed bugs that reference this specific question, but if they exist I couldn't find them. Thanks!",False,0,COLLABORATOR
https://api.github.com/repos/Automattic/mongoose/issues/comments/372820945,pre.remove middleware of objects in array are never called (with 5.0.9),vkarpov15,10,303603562,5,372820945,0,372278295,2018-03-13T21:15:16Z,"Because the alternative would be to make `doc.subs[0].remove()` call `doc.save()`, which is weird if you need to remove multiple docs. In general, the subdoc isn't removed until you call `doc.remove()` or `doc.save()`, because there's no way to remove a subdoc without updating the parent doc.",False,0,COLLABORATOR
https://api.github.com/repos/Automattic/mongoose/issues/comments/373981846,pre.remove middleware of objects in array are never called (with 5.0.9),jmcollin78,10,303603562,6,373981846,0,372820945,2018-03-18T08:44:39Z,"If I add a subdoc and call doc.save() the pre('save') callback is called.
If I remove a subdoc, I suppose that pre('remove') will be called too.
There is something missing in my understanding. It's pretty confusing to have two different behaviours (that makes me think about a bug initially).

",False,0,NONE
https://api.github.com/repos/Automattic/mongoose/issues/comments/383299660,pre.remove middleware of objects in array are never called (with 5.0.9),pascallemoine,10,303603562,7,383299660,0,373981846,2018-04-21T14:19:14Z,"Hi there,

I agree with @jmcollin78 : pre/post('remove') should be triggered on subdocuments.

Here is why, each child has a file attached like so :

```js
const Child = new Schema({
  filename: String
})

Child.post('remove', () => {
  fs.unlink(this.filename)
})

const Parent = new Schema({
  children: [Child]
})

```

So now, if I call `parent.remove()` the children's `post('remove')` hook is triggered and delete the file.

But If I call `parent.children.id(id).remove()`, no hook is triggered and I have to delete the file manually, which is weird according to the code.

So in my opinion it could be an improvement of the hook feature.

What's your opinion @vkarpov15 ?
",False,0,NONE
https://api.github.com/repos/Automattic/mongoose/issues/comments/383482244,pre.remove middleware of objects in array are never called (with 5.0.9),jmcollin78,10,303603562,8,383482244,0,383299660,2018-04-23T07:35:57Z,"Thx @pascallemoine, I feel so lonely with my problem....
When @vkarpov15 says ""there's no way to remove a subdoc without updating the parent doc"", I agree with that but updating the parent list (with a subdoc removed from the list) don't call the hook also.
This lead to confusion and makes some resources not cleaned after removal.",False,0,NONE
https://api.github.com/repos/Automattic/mongoose/issues/comments/620703757,pre.remove middleware of objects in array are never called (with 5.0.9),georgehess,10,303603562,9,620703757,0,383482244,2020-04-28T16:09:39Z,"@jmcollin78 did you ever get an adequate answer to your question? My project was using mongoose v4 and it supported post-remove middleware for subdocuments in the exact way you described. It wasn't until we upgraded to v5 that we lost the ability to run middleware whenever a subdocument was removed. Seems strange to me that they would remove that piece of functionality, but as far as I can tell, they have.",False,0,NONE
https://api.github.com/repos/Automattic/mongoose/issues/comments/621397723,pre.remove middleware of objects in array are never called (with 5.0.9),georgehess,10,303603562,10,621397723,0,620703757,2020-04-29T18:53:06Z,"For what it's worth, I noticed that mongoose uses kareem for middleware hooks which can be executed manually. There is a reference to kareem in the subdoc's schema (`subdoc.schema.s.hooks`). So we created our own plugin which executes a subdoc's pre/post middleware when it is removed. We use bluebird for our promise library and it has a helpful `fromCallback` function that resolves a promise when the middleware calls `next()` or rejects the promise if it is passed an arg `next(new Error())`
```
Bluebird.fromCallback(callback =>
	subdoc.schema.s.hooks.execPre(""remove"", subdoc, callback)
)
.then(() => {
	subdoc.remove();
	return doc.save();
})
.then(() =>
	Bluebird.fromCallback(callback =>
		subdoc.schema.s.hooks.execPost(""remove"", query, [subdoc], callback)
	)
)
.return(doc);
```",False,0,NONE
https://api.github.com/repos/Automattic/mongoose/issues/comments/623175956,pre.remove middleware of objects in array are never called (with 5.0.9),vkarpov15,10,303603562,11,623175956,0,621397723,2020-05-03T20:25:57Z,@georgehess can you please open a new issue and follow the issue template?,False,0,COLLABORATOR
https://api.github.com/repos/jekyll/jekyll/issues/6831,Partially output a collection,cameronmcefee,3,302811547,1,302811547,0,0,2018-03-06T18:18:47Z,"Hello! In a collection we can specify:

```
collections:
  my_collection:
    output: true
```

This will cause all of the documents in the collection to generate pages, however, I'd like to be able to selectively enable generation. Anyone have a suggestion for how to do that, that isn't a post-build script that deletes the ones I don't want? I'm open to a plugin option, if that is a solution (I don't know enough about the lifecycle to know if this is viable). `published: false` is not an option, because I still need the data to be accessible.

In context, I have an ""events"" collection which represents the events our company sponsors/sends speakers too/hosts/etc. For all the 3rd party events, I just want the collection to be data objects, but for the events we host, I'd like those to output their own pages.",True,0,NONE
https://api.github.com/repos/jekyll/jekyll/issues/comments/370879177,Partially output a collection,pathawks,3,302811547,2,370879177,0,302811547,2018-03-06T18:25:07Z,"It seems like splitting the collection into two collections would be a natural way to organize things. One would be output and the other not.

I don’t know if Liquid has a simple way to union two collections to iterate through both together.",False,0,MEMBER
https://api.github.com/repos/jekyll/jekyll/issues/comments/370879573,Partially output a collection,cameronmcefee,3,302811547,3,370879573,0,370879177,2018-03-06T18:26:19Z,"Cool, I figured that'd probably be the case. Liquid can concat arrays now so it's possible that way.",False,0,NONE
https://api.github.com/repos/jekyll/jekyll/issues/comments/370923709,Partially output a collection,pathawks,3,302811547,4,370923709,0,370879573,2018-03-06T20:51:17Z,"If there were some common use cases here, I could see hierarchical collections to fill this role.",False,0,MEMBER
https://api.github.com/repos/jekyll/jekyll/issues/6833,Add `jekyll-random` plugin to docs,codecalm,7,303526807,1,303526807,0,0,2018-03-08T15:44:59Z,"Hi!
I've created a Jekyll plugin to generate a large amount of random data. The data is generated based on `forloop.index`, so that every time when you run `jekyll build` the generated data is the same.

It would be nice to list it on plugins page. 
Thanks!
",True,0,CONTRIBUTOR
https://api.github.com/repos/jekyll/jekyll/issues/comments/377585591,Add `jekyll-random` plugin to docs,DirtyF,7,303526807,2,377585591,0,303526807,2018-03-30T18:07:46Z,@jekyllbot: merge +docs,False,0,MEMBER
https://api.github.com/repos/jekyll/jekyll/issues/comments/377585994,Add `jekyll-random` plugin to docs,codecalm,7,303526807,3,377585994,0,377585591,2018-03-30T18:09:32Z,thanks!,False,0,CONTRIBUTOR
https://api.github.com/repos/jekyll/jekyll/issues/comments/378309726,Add `jekyll-random` plugin to docs,chrisfinazzo,7,303526807,4,378309726,0,377585994,2018-04-03T16:23:01Z,"@parkr,

This would still be in the [Directory][] repo, correct? If so, I can submit a PR.

I suppose you could just point from the current page to Directory's site, which has the full list. Not sure if you think it  needs be migrated yet, but I assume this is where it probably should end up.

[Directory]: https://github.com/jekyll/directory",False,0,CONTRIBUTOR
https://api.github.com/repos/jekyll/jekyll/issues/comments/378310334,Add `jekyll-random` plugin to docs,DirtyF,7,303526807,5,378310334,0,378309726,2018-04-03T16:24:55Z,"@chrisfinazzo yes, we haven't figure out an automated solution to list all themes and plugins, so for now you'll have to [follow the README](https://github.com/jekyll/directory#adding-your-plugin-or-your-theme)",False,0,MEMBER
https://api.github.com/repos/jekyll/jekyll/issues/comments/378356986,Add `jekyll-random` plugin to docs,chrisfinazzo,7,303526807,6,378356986,0,378310334,2018-04-03T18:49:51Z,"See Directory [#44][] for the associated PR.

[#44]: https://github.com/jekyll/directory/pull/44",False,0,CONTRIBUTOR
https://api.github.com/repos/jekyll/jekyll/issues/comments/378362357,Add `jekyll-random` plugin to docs,DirtyF,7,303526807,7,378362357,0,378356986,2018-04-03T19:07:15Z,"@chrisfinazzo https://jekyll.github.io/directory/plugins/jekyll-random/

If people start adding plugins there, that might give me some motivation to work on this :)",False,0,MEMBER
https://api.github.com/repos/jekyll/jekyll/issues/comments/378722987,Add `jekyll-random` plugin to docs,DirtyF,7,303526807,8,378722987,0,378362357,2018-04-04T19:48:01Z,@parkr work in progres on https://jekyll-directory.netlify.com/ 😉 ,False,0,MEMBER
https://api.github.com/repos/jekyll/jekyll/issues/6838,Update windows.md to explain an issue with jekyll new.,nuket,7,304009149,1,304009149,0,0,2018-03-09T23:09:34Z,,True,0,CONTRIBUTOR
https://api.github.com/repos/jekyll/jekyll/issues/comments/371980762,Update windows.md to explain an issue with jekyll new.,nuket,7,304009149,2,371980762,0,304009149,2018-03-10T00:07:42Z,How about the full text of the fix in troubleshooting.md and a link to it from windows.md?,False,0,CONTRIBUTOR
https://api.github.com/repos/jekyll/jekyll/issues/comments/371982807,Update windows.md to explain an issue with jekyll new.,pathawks,7,304009149,3,371982807,0,371980762,2018-03-10T00:22:48Z,"> How about the full text of the fix in troubleshooting.md and a link to it from windows.md?

I love that idea",False,0,MEMBER
https://api.github.com/repos/jekyll/jekyll/issues/comments/372046272,Update windows.md to explain an issue with jekyll new.,nuket,7,304009149,4,372046272,0,371982807,2018-03-10T17:19:13Z,"Ok, I've made the changes, let me know if there are any other thoughts on the PR.",False,0,CONTRIBUTOR
https://api.github.com/repos/jekyll/jekyll/issues/comments/372075653,Update windows.md to explain an issue with jekyll new.,nuket,7,304009149,5,372075653,0,372046272,2018-03-10T23:26:42Z,"Makes sense to me, I added an anchor to troubleshooting.md and modified windows.md to link to that.",False,0,CONTRIBUTOR
https://api.github.com/repos/jekyll/jekyll/issues/comments/372090746,Update windows.md to explain an issue with jekyll new.,nuket,7,304009149,6,372090746,0,372075653,2018-03-11T05:26:36Z,Ok.,False,0,CONTRIBUTOR
https://api.github.com/repos/jekyll/jekyll/issues/comments/372091299,Update windows.md to explain an issue with jekyll new.,DirtyF,7,304009149,7,372091299,0,372090746,2018-03-11T05:42:28Z,@jekyllbot: merge +docs,False,0,MEMBER
https://api.github.com/repos/jekyll/jekyll/issues/comments/372096378,Update windows.md to explain an issue with jekyll new.,pathawks,7,304009149,8,372096378,0,372091299,2018-03-11T07:52:05Z,"Thank you so much @nuket! I’m really excited about this addition, as it makes explicit what I have been informally recommending for some time 👍🏼 ",False,0,MEMBER
https://api.github.com/repos/jekyll/jekyll/issues/6848,Improve regex usage in `Tags::IncludeTag`,ashmaroli,4,305429071,1,305429071,0,0,2018-03-15T06:23:26Z,"Summary of changes:
- moved locally initialized regexps in frequently called methods to class constants
- `INVALID_SEQUENCES` now flag sequences of *multiple adjacent periods* `(..)` and *multiple adjacent forward slashes* `(//)` along with original sequences of *dot-slash* `(./)` and *slash-dot* `(/.)`
- `:validate_file_name` now first checks for `INVALID_SEQUENCES` and then proceeds to check for `VALID_FILENAME_CHARS` to `raise` sooner
- use `String#=~` over slower `String#match`",True,0,MEMBER
https://api.github.com/repos/jekyll/jekyll/issues/comments/374670942,Improve regex usage in `Tags::IncludeTag`,pathawks,4,305429071,2,374670942,0,305429071,2018-03-20T16:46:47Z,This needs to be `3.8.0`?,False,0,MEMBER
https://api.github.com/repos/jekyll/jekyll/issues/comments/374673895,Improve regex usage in `Tags::IncludeTag`,ashmaroli,4,305429071,3,374673895,0,374670942,2018-03-20T16:54:28Z,"> This needs to be `3.8.0`?

We can't introduce class constants in a patch release..",False,0,MEMBER
https://api.github.com/repos/jekyll/jekyll/issues/comments/374674585,Improve regex usage in `Tags::IncludeTag`,pathawks,4,305429071,4,374674585,0,374673895,2018-03-20T16:56:18Z,"Sorry, what I meant was: does this need to be a blocker for `3.8.0` instead of maybe being slated for `3.9.0`? No matter.",False,0,MEMBER
https://api.github.com/repos/jekyll/jekyll/issues/comments/374959105,Improve regex usage in `Tags::IncludeTag`,pathawks,4,305429071,5,374959105,0,374674585,2018-03-21T14:36:06Z,@jekyllbot: :ship: +minor,False,0,MEMBER
https://api.github.com/repos/git-tfs/git-tfs/issues/1167,fetch does not fetch all files from change set,vzabavnov,5,293947595,1,293947595,0,0,2018-02-02T16:34:28Z,"Recently I started to experience problems that files I got from TFS via bridge not the same as I have in TFS change set. that is really disturbing me because now I cannot use git repository at all!
Initially I just use regular fetch to fetch up to latest. but at one day source code stop compiling and when I analyze and compilation issue - some type has a method that not declare in the source of that type. So, I compare in TFS - the type contains all method and when I got files via TFS - all works fine.
So, I did some investigation and found: 
bridge uses method Worspace.Get to update workspace. that usage wrapped around to continue, until method not finished successfully. So, what I see: as soon TFS has some issue and raise exception - the file, currently loaded - will be missing.
The part where all files in workspace is getting need to be rewriten
",True,0,NONE
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/362718665,fetch does not fetch all files from change set,vzabavnov,5,293947595,2,362718665,0,293947595,2018-02-02T21:53:32Z,"I found cause the issue. So, the code:
`Retry.Do(() => DoUntilNoFailures(() => _workspace.Get(new ChangesetVersionSpec(changeset), GetOptions.Overwrite | GetOptions.GetAll)));`
does not handle failure. The _workspace.Get returns status where specified what is wrong. currently it is not handled anyhow. in my case - it failed by server timeout and files just missed.
I am working on some prototype to handle it as retrievable  batch get.
Is any one around wish to help me to find and check other ares in code where Workspace.Get method need to modify to handle status?",False,0,NONE
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/362956776,fetch does not fetch all files from change set,pmiossec,5,293947595,3,362956776,0,362718665,2018-02-05T01:09:24Z,"Thanks a lot for the investigation. There is indeed a known lack of reliability somewhere and perhaps you found it.

But let me understand exactly. Where is the bad behavior?

Is it in the TFS api (with `NumFailures` still equal to 0 in `GetStatus`)?
Or is it in the code of `DoUntilNoFailures()` ( https://github.com/git-tfs/git-tfs/blob/master/src/GitTfs.VsCommon/Wrappers.cs#L455 ) ? Because the code seems good to me...

>Is any one around wish to help me to find and check other ares in code where Workspace.Get method need to modify to handle status?

Unfortunately, there is not a lot of users willing to help. I will be very happy if someone could help you solve this problem.
 As far as I am concerned, even if I am a maintainer of git-tfs, I am no more a user and have no TFVC repository to use :(

I hope you will be able to solve that problem or do a pull request for other to test it!

Thanks again!



",False,0,MEMBER
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/362957580,fetch does not fetch all files from change set,pmiossec,5,293947595,4,362957580,0,362956776,2018-02-05T01:18:17Z,Is the problem that there is an exception raised by the `Get()`?,False,0,MEMBER
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/362971855,fetch does not fetch all files from change set,vzabavnov,5,293947595,5,362971855,0,362957580,2018-02-05T03:24:07Z,"Hello Philippe,

Well, the source of issues – is out TFS server. There is many problems started with how branches organized and continue to slow connection. Sometimes I see speed around 30Kbs.

But this one – when server is busy or something else is going on – the TFS server returns – timeout. Sometimes the TFS API even gave me “No server found”. When such things happened – the problems begun. As I understand for now, Workstation.Get, where all files should be placed to workspace folder, when exception happened – the failure file is corrupted, and second call of Get with same argument – just continue to download and the failed file – will be just missed. I did some pretests, and see if I do Get for each file, and handle GetResult where if it failed to reload file – it works. It could be a bad performance because of plenty requests for each file. As I see – the Visual Studio does download each file individually.

 With Best regards
",False,0,NONE
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/363103112,fetch does not fetch all files from change set,vzabavnov,5,293947595,6,363103112,0,362971855,2018-02-05T14:38:58Z,"Hello Philippe,

I found in existing code another weakness. It is at method 

void Retry.DoWhile(Func<bool> action, TimeSpan retryInterval, int retryCount = 10)

 

The exception handler doesn’t wrap the action, so in first exception in the action – no retry happened

So, the method should be like:

	public static void DoWhile(Func<bool> action, TimeSpan retryInterval, int retryCount = 10)
	{
		int count = 0;
		while (count < retryCount)
		{
			try
			{
				if (action())
				{
					return;
				}
			}
			catch (Exception e)
			{
				Trace.WriteLine(string.Format(""The exception raised by action: {0}"", e.Message));
			}
			count++;
			Thread.Sleep(retryInterval);
		}
		if (count > retryCount)
		{
			throw new GitTfsException(""error: Action failed after "" + retryCount + "" retries!"");
		}
	}

With Best Regards
",False,0,NONE
https://api.github.com/repos/git-tfs/git-tfs/issues/1169,patch for command line option to select location of debug-logging file,dgtlrift,3,294762325,1,294762325,0,0,2018-02-06T13:38:57Z,"Patch to allow selection of logfile location
[0001-Add-command-line-logging-paramters.zip](https://github.com/git-tfs/git-tfs/files/1699226/0001-Add-command-line-logging-paramters.zip)
",True,0,NONE
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/363426568,patch for command line option to select location of debug-logging file,pmiossec,3,294762325,2,363426568,0,294762325,2018-02-06T13:46:41Z,"Thanks but could you create a pull request (instead of a patch)? 
That will trigger the CI and permit an easier review...",False,0,MEMBER
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/363436536,patch for command line option to select location of debug-logging file,dgtlrift,3,294762325,3,363436536,0,363426568,2018-02-06T14:22:21Z,Added pull request #1170 ,False,0,NONE
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/369912789,patch for command line option to select location of debug-logging file,pmiossec,3,294762325,4,369912789,0,363436536,2018-03-02T12:50:55Z,I close (comments will be done in the pull request),False,0,MEMBER
https://api.github.com/repos/git-tfs/git-tfs/issues/1171,StackOverflow Exception,levalencia,8,295083733,1,295083733,0,0,2018-02-07T10:28:42Z,"Hello

I searched for this exception on the issues but I found none. I am trying to clone an existing (HUGE) TFVC repository with this tool, and after 2 hours (getting the first commit from 2014 which has more than 2000 files), the tool crashes with stackoverflow exception.

![gittfserror](https://user-images.githubusercontent.com/6962857/35911195-6cc44af4-0bf9-11e8-90cb-ed72c3c0b2e6.png)

I am using:
git version 2.11.0.windows.1

git-tfs version 0.28.0.0 (TFS client library 14.0.0.0 (MS)) (64-bit)

In a separate reply I will paste what I get with the debug option

",True,0,NONE
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/363728145,StackOverflow Exception,pmiossec,8,295083733,2,363728145,0,295083733,2018-02-07T10:38:18Z,"I think you should already have a log file in folder `%userprofile%\AppData\local\git-tfs` (or something very approaching because I don't remember exactly).

But I think that is a known case of a deleted and recreated branch and git-tfs fail to find the root changeset. :-(",False,0,MEMBER
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/363729303,StackOverflow Exception,levalencia,8,295083733,3,363729303,0,363728145,2018-02-07T10:42:18Z,I guess if I dont use the branches all option it might work?,False,0,NONE
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/363731238,StackOverflow Exception,pmiossec,8,295083733,4,363731238,0,363729303,2018-02-07T10:49:41Z,"Maybe.....

If you remove the option, most likely it will fail because git-tfs try to initialize the branches that are merged in the branch cloned. So you will have the same problem.

You should use `--branches=none`",False,0,MEMBER
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/363752394,StackOverflow Exception,levalencia,8,295083733,5,363752394,0,363731238,2018-02-07T12:21:10Z,"It worked with branches none, Thank you",False,0,NONE
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/366618277,StackOverflow Exception,stevebeauge,8,295083733,6,366618277,0,363752394,2018-02-19T08:27:19Z,"@pmiossec, you said 

> But I think that is a known case of a deleted and recreated branch and git-tfs fail to find the root changeset. :-(

Can you elaborate? (I'm facing the same Stackoverflow exception issue)

thx",False,0,NONE
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/366678217,StackOverflow Exception,pmiossec,8,295083733,7,366678217,0,366618277,2018-02-19T12:24:13Z,"I just remember that we had for some long problems with difficult branch hierarchy (perhaps when branches are deleted and recreated with the same name) and git-tfs fails to find the good root commit (because that there is no good TFS api to retrieve this information). So git-tfs ends up in a loop until stackoverflow happens.

See for example (there are some other issues I think) :
#1144 (that should fix #848) which is not in the last version released (v0.28). You should test the version built by AppVeyor
#787
",False,0,MEMBER
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/366692843,StackOverflow Exception,stevebeauge,8,295083733,8,366692843,0,366678217,2018-02-19T13:27:42Z,Having rebuilt the project from the latest version solved my issue.,False,0,NONE
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/366693851,StackOverflow Exception,pmiossec,8,295083733,9,366693851,0,366692843,2018-02-19T13:31:54Z,">Having rebuilt the project from the latest version solved my issue 

So, huge thanks to @lukas-ais",False,0,MEMBER
https://api.github.com/repos/git-tfs/git-tfs/issues/1173,Fix errors during fetch #1167 ,vzabavnov,20,296412919,1,296412919,0,0,2018-02-12T15:22:16Z,"Hello everyone,
So, I found solution and fix it. it works on all my scenarios. Unfortunately I have only 2015 and 2017 VSs, not prior. Could any one help me to transfer and check the solution I provided for 2010 2012 and 2013 versions? 

Should fix #1167",True,0,NONE
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/364993272,Fix errors during fetch #1167 ,pmiossec,20,296412919,2,364993272,0,296412919,2018-02-12T17:13:10Z,"Thanks a lot for the effort and the pull request!

>Unfortunately I have only 2015 and 2017 VSs, not prior. Could any one help me to transfer and check the solution I provided for 2010 2012 and 2013 versions?

You could forget VS 2010, I have removed the support because we are no more able to build it.

For 2012 and 2013,there are 2 packages (Team Foundation Server Object Model) that you could install to be able to build the projects. 

You will find the links in the ""note"" paragraph of the link (that is really easy to install with chocolatey or by hand) 
https://github.com/git-tfs/git-tfs/blob/master/README.md#get-the-source-code-and-build

If would be really great if you could do that 😍 ",False,0,MEMBER
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/364993691,Fix errors during fetch #1167 ,pmiossec,20,296412919,3,364993691,0,364993272,2018-02-12T17:14:41Z,But that should be OK and you just have to verify that it builds... ,False,0,MEMBER
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/367470078,Fix errors during fetch #1167 ,vzabavnov,20,296412919,4,367470078,0,364993691,2018-02-21T20:59:19Z,"Hello Philippe,

I am still testing the changes I provide and now facing another one. strange one. I’d like to ask you about your suggestions.

So, I have TFS branch mapped to git repository. It works fine. Now I did:
git-tfs init URL path -I MyName

Now I see by command git-tfs branch – the branch MyName initialized but refs/remote/… is 0, I expected that.

 

Now I do the 

fetch -I MyName 

and see no commit coming in. I checked the history in TFS – plenty of change sets. 

In debugger, I see the strange value of InitialChangeset. It has a change set number that is not part pf any changes set I should have in my repository.

It gets value by call:

int? initialChangeset = _loader.Get(GitTfsConstants.InitialChangeset, -1);

with deeper code trace to call:
var entry = _repository.Config.Get<T>(key);

where key is git-tfs.initial-changeset

 

as I see the changes set number – the first change set number for current (active) branch, not that one I specified in “-i”

please give me some suggestion where it could be wrong

With Best Regards
",False,0,NONE
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/369049969,Fix errors during fetch #1167 ,pmiossec,20,296412919,5,369049969,0,367470078,2018-02-27T22:29:22Z,"Sorry for the late answer... I really appreciate what you did!

`where key is git-tfs.initial-changeset`

what was the `git-tfs clone` command you used? It should have come from the clone command when you tell git-tfs not to clone before a specific changeset... 

https://github.com/git-tfs/git-tfs/blob/master/doc/commands/clone.md
`-c, --changeset=VALUE      The changeset to clone from (must be a number)`",False,0,MEMBER
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/369111867,Fix errors during fetch #1167 ,vzabavnov,20,296412919,6,369111867,0,369049969,2018-02-28T03:43:50Z,"Hello Philippe,

No, I did not use the Clone command. It was pair: Init and Fetch.

When I used –c flag for Fetch – it was working just fine, but when no –c, just fetch after init – that happened.

 

BTW, I have 2013 Visual Studio installed. Soon I’ll check my changes on this version

 

 

With Best regards

 <mailto:zabavno@gmail.com> Vadim Zabavnov

 

From: Philippe Miossec [mailto:notifications@github.com] 
Sent: Tuesday, February 27, 2018 5:29 PM
To: git-tfs/git-tfs <git-tfs@noreply.github.com>
Cc: Vadim Zabavnov <zabavnov@gmail.com>; Author <author@noreply.github.com>
Subject: Re: [git-tfs/git-tfs] Fix errors during fetch #1167 (#1173)

 

Sorry for the late answer... I really appreciate what you did!

where key is git-tfs.initial-changeset

what was the git-tfs clone command you used? It should have come from the clone command when you tell git-tfs not to clone before a specific changeset...

https://github.com/git-tfs/git-tfs/blob/master/doc/commands/clone.md
-c, --changeset=VALUE The changeset to clone from (must be a number)

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub <https://github.com/git-tfs/git-tfs/pull/1173#issuecomment-369049969> , or mute the thread <https://github.com/notifications/unsubscribe-auth/ACjG1FyyvV7CR6pcZNe8IZfsTPXCjBhvks5tZIHEgaJpZM4SCVbK> .  <https://github.com/notifications/beacon/ACjG1PReYE3swpa-JbDP3pMmM6jn-H98ks5tZIHEgaJpZM4SCVbK.gif> 

",False,0,NONE
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/369229515,Fix errors during fetch #1167 ,pmiossec,20,296412919,7,369229515,0,369111867,2018-02-28T12:49:55Z,">When I used –c flag for Fetch – it was working just fine, but when no –c, just fetch after init – that happened.

So, you used the `-c` flag?
Because the value is stored when used...
I didn't think about a case where we would like to set it and unset it after.

So it seems you are in an expected behavior. That perhaps we should have to make evolve... Add a way to easily unset it !?! (and add warning to tell the user that we won't look before this changeset)",False,0,MEMBER
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/369254126,Fix errors during fetch #1167 ,vzabavnov,20,296412919,8,369254126,0,369229515,2018-02-28T14:22:06Z,"Hello Philippe,

I use that scenario many times in past, I meant Init/Fetch. 

In our company, even admins named it TFS branch – it is not real branch, it is a copy with some changes. To have my own “branches”, I used that technique Init/Fetch. Some time it doesn’t work, but mostly – works. I also found it doesn’t work if the first change set in the “branch” (I mentioned earlier what I meant) is renamed change set – it doesn’t work. But it works if I do quick clone.

As I see in the code, the app uses different approaches to get changes in different scenarios. In some cases, in my opinion, better to use different approach that the app currently has.

 

BTW, I’d like to propose new feature: fetch based on Label, not just change set. I’d like to recommend “-l” flag, but it already taken.

What do you think?

 

 

 

 

With Best Regards

Vadim Zabavnov <mailto:zabavnov@gmail.com> 

 

From: Philippe Miossec [mailto:notifications@github.com] 
Sent: Wednesday, February 28, 2018 7:50 AM
To: git-tfs/git-tfs <git-tfs@noreply.github.com>
Cc: Vadim Zabavnov <zabavnov@gmail.com>; Author <author@noreply.github.com>
Subject: Re: [git-tfs/git-tfs] Fix errors during fetch #1167 (#1173)

 

When I used –c flag for Fetch – it was working just fine, but when no –c, just fetch after init – that happened.

So, you used the -c flag?
Because the value is stored when used...
I didn't think about a case where we would like to set it and unset it after.

So it seems you are in an expected behavior. That perhaps we should have to make evolve... Add a way to easily unset it !?! (and add warning to tell the user that we won't look before this changeset)

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub <https://github.com/git-tfs/git-tfs/pull/1173#issuecomment-369229515> , or mute the thread <https://github.com/notifications/unsubscribe-auth/ACjG1CLiRLPyemqS1mN0zMvRrZFTm2vpks5tZUt1gaJpZM4SCVbK> .  <https://github.com/notifications/beacon/ACjG1O-nvJ3Sy7G1dJfeECma97FYNkgxks5tZUt1gaJpZM4SCVbK.gif> 

",False,0,NONE
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/370486891,Fix errors during fetch #1167 ,vzabavnov,20,296412919,9,370486891,0,369254126,2018-03-05T16:57:16Z,"Hello everyone.
I was able to check my changes against VS 2013. once again, I was checking only scenario that I had an issue.
is anyone has VS 2012 to check?",False,0,NONE
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/370488261,Fix errors during fetch #1167 ,pmiossec,20,296412919,10,370488261,0,370486891,2018-03-05T17:01:11Z,"That build with vs 2012, so assume it works with it (2012 and 2013 are very similar).

No need to verify... ",False,0,MEMBER
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/381562811,Fix errors during fetch #1167 ,pmiossec,20,296412919,11,381562811,0,370488261,2018-04-16T11:05:58Z,@vzabavnov Did you finished your work and do you think it could be merged as it is?,False,0,MEMBER
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/381590842,Fix errors during fetch #1167 ,vzabavnov,20,296412919,12,381590842,0,381562811,2018-04-16T13:00:36Z,"Hello,

Well, I use my code locally from that time and do not see any problems. I check it on 2013, and 2015 versions.  I’d like if someone else will try to use it, but in my organization not many people use git-tfs bridge and I cannot ask them to use it. Who I be able to ask – asked and they use my code. 

With Best Regards
",False,0,NONE
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/382190016,Fix errors during fetch #1167 ,pmiossec,20,296412919,13,382190016,0,381590842,2018-04-17T23:28:17Z,Seems good for me. Thanks a lot,False,0,MEMBER
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/382393888,Fix errors during fetch #1167 ,vzabavnov,20,296412919,14,382393888,0,382190016,2018-04-18T13:52:35Z,"Thanks, Philippe.

 

From time to time I see another issue. It is related to change set in TFS that is first in a branch and is renamed. When the bridge started from this kind of changes set – it has no files, but should have all files.

I happened couple of times, but I cannot catch up what and why, and I did not create bug (yet :) ). I am still monitoring such situation.

 

 

 

With Best Regards

",False,0,NONE
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/382524714,Fix errors during fetch #1167 ,pmiossec,20,296412919,15,382524714,0,382393888,2018-04-18T20:49:43Z,"Yes, the case of a branch rename is not well handled and somes had a problem with it but I never was able to reproduce it :-(",False,0,MEMBER
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/382527521,Fix errors during fetch #1167 ,pmiossec,20,296412919,16,382527521,0,382524714,2018-04-18T20:59:31Z,"I just saw that you tried something to fix that a long time ago in #666 

Perhaps rebase it and fix conflicts and try it again...",False,0,MEMBER
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/382725648,Fix errors during fetch #1167 ,vzabavnov,20,296412919,17,382725648,0,382527521,2018-04-19T13:01:35Z,"Yes, I found work around.

Now if something similar happened I will try to create a “unit” test, to go through all change sets from our TFS repository and will try to initiate new GIT repository based on each. If failed -  we’ve got the situation.

 

 

 

With Best Regards

Vadim Zabavnov <mailto:zabavnov@gmail.com> 

 

From: Philippe Miossec [mailto:notifications@github.com] 
Sent: Wednesday, April 18, 2018 5:00 PM
To: git-tfs/git-tfs <git-tfs@noreply.github.com>
Cc: Vadim Zabavnov <zabavnov@gmail.com>; Mention <mention@noreply.github.com>
Subject: Re: [git-tfs/git-tfs] Fix errors during fetch #1167 (#1173)

 

I just saw that you tried something to fix that a long time ago in #666 <https://github.com/git-tfs/git-tfs/pull/666> 

Perhaps rebase it and fix conflicts and try it again...

—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub <https://github.com/git-tfs/git-tfs/pull/1173#issuecomment-382527521> , or mute the thread <https://github.com/notifications/unsubscribe-auth/ACjG1Mwl3nLY9sgdG_kvnYu-Em9Y84Ojks5tp6k2gaJpZM4SCVbK> .  <https://github.com/notifications/beacon/ACjG1InV7okAXJ4ACjeGjLCRL4kT5m1Oks5tp6k2gaJpZM4SCVbK.gif> 

",False,0,NONE
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/418860829,Fix errors during fetch #1167 ,vzabavnov,20,296412919,18,418860829,0,382725648,2018-09-05T19:56:05Z,"Hello Philippe,

I just each that issue again with the latest git-tfs bridge: fetch from new branch to existing repository. Som first change set contains only changed items, but supposed to have all items because it is first item from that branch.

 

I will do investigation

 

 

",False,0,NONE
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/418907504,Fix errors during fetch #1167 ,pmiossec,20,296412919,19,418907504,0,418860829,2018-09-05T22:54:57Z,Great! Have fun! ;-),False,0,MEMBER
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/439509392,Fix errors during fetch #1167 ,vzabavnov,20,296412919,20,439509392,0,418907504,2018-11-16T19:58:09Z,"Hello Philippe,

Well, I was fired from the company for very stupid reason: they claim I used to download torrent from company computer.

But anyhow – I don’t have access to the repository anymore  L

Sorry

 

With Best regards

 <mailto:zabavno@gmail.com> Vadim Zabavnov

 

From: Philippe Miossec [mailto:notifications@github.com] 
Sent: Wednesday, September 5, 2018 6:55 PM
To: git-tfs/git-tfs <git-tfs@noreply.github.com>
Cc: Vadim Zabavnov <zabavnov@gmail.com>; Mention <mention@noreply.github.com>
Subject: Re: [git-tfs/git-tfs] Fix errors during fetch #1167 (#1173)

 

Great! Have fun! ;-)

—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub <https://github.com/git-tfs/git-tfs/pull/1173#issuecomment-418907504> , or mute the thread <https://github.com/notifications/unsubscribe-auth/ACjG1IgvhrZg7OyoF82IO4rF-J9-woa3ks5uYFZEgaJpZM4SCVbK> .  <https://github.com/notifications/beacon/ACjG1NyGJCrVcTS8BBLUbbt4clFiLx-rks5uYFZEgaJpZM4SCVbK.gif> 

",False,0,NONE
https://api.github.com/repos/git-tfs/git-tfs/issues/comments/439551020,Fix errors during fetch #1167 ,pmiossec,20,296412919,21,439551020,0,439509392,2018-11-16T22:39:54Z,">Well, I was fired from the company for very stupid reason: they claim I used to download torrent from company computer.

oO
:flushed:
I hope it won't be too difficult for you. I wish you the best for the future. Good luck! ",False,0,MEMBER
https://api.github.com/repos/arduino/Arduino/issues/7437,[Library Manager] Please add library for Grove - Barometer Sensor (BMP280),lanselambor,3,312425613,1,312425613,0,0,2018-04-09T07:39:07Z,"github: https://github.com/Seeed-Studio/Grove_BMP280
release: https://github.com/Seeed-Studio/Grove_BMP280/releases/tag/1.0.0

Thanks!",True,0,NONE
https://api.github.com/repos/arduino/Arduino/issues/comments/379734120,[Library Manager] Please add library for Grove - Barometer Sensor (BMP280),cmaglie,3,312425613,2,379734120,0,312425613,2018-04-09T12:27:14Z,"parenthesis are not allowed on the name:

`Grove - Barometer Sensor (BMP280)`

could you remove them?
Remeber also to remove& redo the release tag after pushing the change to the repository.
",False,0,MEMBER
https://api.github.com/repos/arduino/Arduino/issues/comments/379947949,[Library Manager] Please add library for Grove - Barometer Sensor (BMP280),lanselambor,3,312425613,3,379947949,0,379734120,2018-04-10T01:50:51Z,"@cmaglie Have fixed that, thank you!",False,0,NONE
https://api.github.com/repos/arduino/Arduino/issues/comments/381525604,[Library Manager] Please add library for Grove - Barometer Sensor (BMP280),cmaglie,3,312425613,4,381525604,0,379947949,2018-04-16T08:46:36Z,done,False,0,MEMBER
https://api.github.com/repos/arduino/Arduino/issues/7447,Bug with auto-selecting the right board and port when switching between two scripts,mirkosaiu,4,312540170,1,312540170,0,0,2018-04-09T13:53:25Z,"As you can see in the image below I have two scripts opened and I'm working on them contemporarily. They belong to two different boards respectively. When I switch between them the IDE tries to update the port and the board but without success. In fact, in the Tools panel the preview shows something different from what is actually selected.

<img width=""1133"" alt=""screen shot 2018-04-09 at 15 45 47"" src=""https://user-images.githubusercontent.com/36299249/38501363-1a735986-3c0d-11e8-8a76-8c6f7da50975.png"">
",True,0,NONE
https://api.github.com/repos/arduino/Arduino/issues/comments/380005847,Bug with auto-selecting the right board and port when switching between two scripts,facchinm,4,312540170,2,380005847,0,312540170,2018-04-10T07:43:00Z,"Hi @mirkosaiu ,
this looks like the bug is only graphical; can you confirm this? If you press compile on either window does it retain the correct target?",False,0,MEMBER
https://api.github.com/repos/arduino/Arduino/issues/comments/380392690,Bug with auto-selecting the right board and port when switching between two scripts,mirkosaiu,4,312540170,3,380392690,0,380005847,2018-04-11T09:43:51Z,What is selected in the list of the available boards and ports is what is actually selected for real. But I think that the feature that automatically switches between the respective boards and ports of the scripts would be great!,False,0,NONE
https://api.github.com/repos/arduino/Arduino/issues/comments/380404665,Bug with auto-selecting the right board and port when switching between two scripts,facchinm,4,312540170,4,380404665,0,380392690,2018-04-11T10:27:51Z,"The feature you are referring to is already merged into the Beta channel (from https://github.com/arduino/Arduino/commit/6112d0455ea66a3318739f2bd5de11ea504dec00) but it only works if the serial port has an unique vid/pid combination (unlike most ESP boards).
Feel free to test it (https://www.arduino.cc/en/Main/Software#beta) and report your impressions :wink: ",False,0,MEMBER
https://api.github.com/repos/arduino/Arduino/issues/comments/380418527,Bug with auto-selecting the right board and port when switching between two scripts,mirkosaiu,4,312540170,5,380418527,0,380404665,2018-04-11T11:25:41Z,"Ok, thanks :)",False,0,NONE
https://api.github.com/repos/arduino/Arduino/issues/7453,Added labels to legend,chromhelm,12,313075125,1,313075125,0,0,2018-04-10T20:21:35Z,"Supports CSV style header and colon separated <label>:<value>.
It is enough to send the label once they are kept until a new label is send.
Multiply values should be separated by space character.  <label1>:<value1> <label2>:<value2> ...
If can send values only or mixed width labels like this:
  <label1>:<value1> <value2> <value3>  <label4>:<value4> ...
If you send one value you have to send al values. It will corrupt the visualisation.
 !!! NOT ALLOWED !!! <label1>:  <value2> <value3>  <label4>:<value4> ...
Labels can be set without sending data:
   <label1>: <label2>: ...

When using the CSV header style you just send space separated. OBS number only headers do not work. they are only allowed with colon separated style.",True,0,CONTRIBUTOR
https://api.github.com/repos/arduino/Arduino/issues/comments/380352742,Added labels to legend,facchinm,12,313075125,2,380352742,0,313075125,2018-04-11T07:19:26Z,@ArduinoBot build this please,False,0,MEMBER
https://api.github.com/repos/arduino/Arduino/issues/comments/380362069,Added labels to legend,ArduinoBot,12,313075125,3,380362069,0,380352742,2018-04-11T07:54:41Z,":white_check_mark: Build completed.

Please test this code using one of the following:

:arrow_down: http://downloads.arduino.cc/javaide/pull_requests/arduino-PR-7453-BUILD-748-linux32.tar.xz
:arrow_down: http://downloads.arduino.cc/javaide/pull_requests/arduino-PR-7453-BUILD-748-linux64.tar.xz
:arrow_down: http://downloads.arduino.cc/javaide/pull_requests/arduino-PR-7453-BUILD-748-windows.zip
:arrow_down: http://downloads.arduino.cc/javaide/pull_requests/arduino-PR-7453-BUILD-748-macosx.zip
:arrow_down: http://downloads.arduino.cc/javaide/pull_requests/arduino-PR-7453-BUILD-748-linuxarm.tar.xz

:information_source: The `linuxarm` build is still experimental and may not be always available.
",False,0,CONTRIBUTOR
https://api.github.com/repos/arduino/Arduino/issues/comments/469036879,Added labels to legend,jottr,12,313075125,4,469036879,0,380362069,2019-03-03T16:06:52Z,@facchinm will this be merged at some point? ,False,0,NONE
https://api.github.com/repos/arduino/Arduino/issues/comments/469182500,Added labels to legend,facchinm,12,313075125,5,469182500,0,469036879,2019-03-04T09:33:58Z,"I think we can merge it, but some documentation must be added too
",False,0,MEMBER
https://api.github.com/repos/arduino/Arduino/issues/comments/469207719,Added labels to legend,per1234,12,313075125,6,469207719,0,469182500,2019-03-04T10:48:22Z,"@facchinm I'm guessing you mean user-targeted documentation rather than just comments in the source code. I completely agree that it's important do document this feature, otherwise the users will not know it's there.


There is some that mentions Serial Plotter, but I don't consider any of this to be a substitute for documentation of the plotter itself:

### Built-in examples

- https://github.com/arduino/arduino-examples/blob/main/examples/01.Basics/AnalogReadSerial/AnalogReadSerial.ino
  - https://www.arduino.cc/en/Tutorial/BuiltInExamples/AnalogReadSerial
  - https://docs.arduino.cc/built-in-examples/basics/AnalogReadSerial
- https://github.com/arduino/arduino-examples/blob/main/examples/01.Basics/ReadAnalogVoltage/ReadAnalogVoltage.ino
  - https://www.arduino.cc/en/Tutorial/BuiltInExamples/ReadAnalogVoltage

### Library examples

- https://github.com/arduino/ArduinoCore-samd/blob/master/libraries/I2S/examples/InputSerialPlotter/InputSerialPlotter.ino
  - https://www.arduino.cc/en/Tutorial/LibraryExamples/I2SInputSerialPlotter
- https://github.com/arduino-libraries/ArduinoSound/blob/master/examples/SpectrumSerialPlotter/SpectrumSerialPlotter.ino
  - https://www.arduino.cc/en/Tutorial/ArduinoSoundSpectrumSerialPlotter
- https://github.com/arduino-libraries/ArduinoSound/blob/master/examples/AmplitudeSerialPlotter/AmplitudeSerialPlotter.ino
  - https://www.arduino.cc/en/Tutorial/ArduinoSoundAmplitudeSerialPlotter

### Library reference

- ArduinoSound
  - https://www.arduino.cc/en/Reference/FFTAnalyzerRead
  - https://www.arduino.cc/en/Reference/FFTAnalyzerInput
  - https://www.arduino.cc/en/Reference/AmpliudeInput
  - https://www.arduino.cc/reference/en/libraries/arduinosound/amplitudeanalyzer.available/
  - https://www.arduino.cc/reference/en/libraries/arduinosound/fftanalyzer.available/

### Hardware

- https://docs.arduino.cc/tutorials/mkr-wifi-1010/connecting-sensors
  - https://www.arduino.cc/en/Guide/MKRWiFi1010/connecting-sensors
- https://docs.arduino.cc/tutorials/nano-33-ble/imu_accelerometer
- https://docs.arduino.cc/tutorials/nano-33-ble-sense/imu_accelerometer
- https://docs.arduino.cc/tutorials/nano-33-ble-sense/imu_gyroscope
- https://docs.arduino.cc/tutorials/nano-33-ble-sense/microphone_sensor
- https://docs.arduino.cc/tutorials/nano-33-iot/imu_accelerometer
- https://docs.arduino.cc/tutorials/nano-33-iot/imu_gyroscope
- https://docs.arduino.cc/tutorials/nano-rp2040-connect/rp2040-microphone-basics

### Other

- https://www.arduino.cc/en/IoT-Prime/Experiment02
- https://support.arduino.cc/hc/en-us/articles/360021222000
- https://docs.arduino.cc/tutorials/nano-33-ble-sense/get-started-with-machine-learning
  - https://blog.arduino.cc/2019/10/15/get-started-with-machine-learning-on-arduino/
- https://edu-content-preview.arduino.cc/content-preview/middle_school/lesson/CONTENTPREVIEW+AESK


I feel that adding a demonstration of the label feature to either of those built-in examples might overly complicate them since they're in the ""Basics"" section.

It would be more appropriate in the library examples, but that is hiding the label documentation pretty deeply.

I have thought it would be good to provide some formal documentation of the Serial Plotter (https://github.com/arduino/docs-content/issues/668). Where do you envision the documentation of the new label functionality being added? I was thinking the IDE guide was the best place for it, but perhaps the more detailed documentation of the Serial Plotter (allowed delimiters, labels) will be too much for that page and deserves a page of its own, which would be linked to from the summary description of the Serial Plotter on the IDE guide page.

I'm happy to help with this. I would be limited to providing suggested text for the documentation, which would need to be implemented by someone else, since I don't have edit access to the documentation content. Even so, that would take care of some of the job.",False,0,COLLABORATOR
https://api.github.com/repos/arduino/Arduino/issues/comments/469222236,Added labels to legend,facchinm,12,313075125,7,469222236,0,469207719,2019-03-04T11:39:40Z,"Serial plotter surely needs some love, both from the ""inline"" documentation and from the website doc. We should coordinate with @SimonePDA to find the right spot where these documentation should be added but I really like the way you want to tackle it!",False,0,MEMBER
https://api.github.com/repos/arduino/Arduino/issues/comments/469480057,Added labels to legend,chromhelm,12,313075125,8,469480057,0,469222236,2019-03-05T00:12:15Z,"Hi
I have uploaded a small protocol description for the label functionality.
https://github.com/chromhelm/Arduino/commit/cdd66b63f686ebe3535dd5fc5f6b9cc592ce8263 ",False,0,CONTRIBUTOR
https://api.github.com/repos/arduino/Arduino/issues/comments/469480918,Added labels to legend,chromhelm,12,313075125,9,469480918,0,469480057,2019-03-05T00:16:22Z,The legend is right now only shown when there is more than one data set. Should I change that so it is always shown ?,False,0,CONTRIBUTOR
https://api.github.com/repos/arduino/Arduino/issues/comments/474147891,Added labels to legend,chromhelm,12,313075125,10,474147891,0,469480918,2019-03-19T00:06:15Z,"Hi
Thank you for the feedback.
One way to get an arm build is to clone the repository to your am bord and run it from there, but i have newer tried it by myself.

I think it is an good idear to add '|' sign as additional part seperator.

I think the arduino team has do decide what diretion the serialPlotter should take.

[Open PR on SerialPlotter](https://github.com/arduino/Arduino/pulls?utf8=%E2%9C%93&q=is%3Apr+is%3Aopen+Plotter+OR+SerialPlotter+OR+Ringbuffer)  
[Open issues on SerialPlotter](https://github.com/arduino/Arduino/issues?utf8=%E2%9C%93&q=is%3Aissue+is%3Aopen+Plotter+OR+SerialPlotter+)

Regards
",False,0,CONTRIBUTOR
https://api.github.com/repos/arduino/Arduino/issues/comments/474150933,Added labels to legend,per1234,12,313075125,11,474150933,0,474147891,2019-03-19T00:22:34Z,">Where can I find an ARM Build to test?

@rin67630 assuming you mean 32-bit ARM Linux, it's the last link in the list of builds provided by ArduinoBot:
https://github.com/arduino/Arduino/pull/7453#issuecomment-380362069

The only changes made to this PR since that build are the addition of documentation files, so it is functionally identical.",False,0,COLLABORATOR
https://api.github.com/repos/arduino/Arduino/issues/comments/477780007,Added labels to legend,rin67630,12,313075125,12,477780007,0,474150933,2019-03-28T21:35:10Z,"
> I think it is an good idear to add '|' sign as additional part seperator.
> 

It currently works well with "" | "" (pipe sign between spaces), no need to write additional code.
If possible, ignoring what is between /* ... */ would have been more useful.",False,0,NONE
https://api.github.com/repos/arduino/Arduino/issues/comments/512726567,Added labels to legend,facchinm,12,313075125,13,512726567,0,477780007,2019-07-18T08:51:20Z,"Rebased and manually merged, thanks!",False,0,MEMBER
https://api.github.com/repos/arduino/Arduino/issues/7454,Make serial plotter ringbuffer size configurable,chromhelm,7,313096908,1,313096908,0,0,2018-04-10T21:32:03Z,,True,0,CONTRIBUTOR
https://api.github.com/repos/arduino/Arduino/issues/comments/380351945,Make serial plotter ringbuffer size configurable,facchinm,7,313096908,2,380351945,0,313096908,2018-04-11T07:16:27Z,@ArduinoBot build this please,False,0,MEMBER
https://api.github.com/repos/arduino/Arduino/issues/comments/380357491,Make serial plotter ringbuffer size configurable,ArduinoBot,7,313096908,3,380357491,0,380351945,2018-04-11T07:37:22Z,":white_check_mark: Build completed.

Please test this code using one of the following:

:arrow_down: http://downloads.arduino.cc/javaide/pull_requests/arduino-PR-7454-BUILD-747-linux32.tar.xz
:arrow_down: http://downloads.arduino.cc/javaide/pull_requests/arduino-PR-7454-BUILD-747-linux64.tar.xz
:arrow_down: http://downloads.arduino.cc/javaide/pull_requests/arduino-PR-7454-BUILD-747-windows.zip
:arrow_down: http://downloads.arduino.cc/javaide/pull_requests/arduino-PR-7454-BUILD-747-macosx.zip
:arrow_down: http://downloads.arduino.cc/javaide/pull_requests/arduino-PR-7454-BUILD-747-linuxarm.tar.xz

:information_source: The `linuxarm` build is still experimental and may not be always available.
",False,0,CONTRIBUTOR
https://api.github.com/repos/arduino/Arduino/issues/comments/610291555,Make serial plotter ringbuffer size configurable,madsdyd,7,313096908,4,610291555,0,380357491,2020-04-07T09:52:40Z,"Just a note for others, and to stop myself from keep opening this issue: The PR (I think this should have been in the description):

> Contains code to add a spinner to the Serial Plotter GUI, that allow to change the number of retained data points from the existing fixed 500 to a user chosen value between 10 and 5000.

However, the quality check fails, because there is:
* An unused local variable `legendLenght` in `paintComponent`
* The method `setNewBufferCapacity` assigns a new value to its parameter.

Both of these should be trivial to fix, but are there any maintainer (person with write access) that would be willing to merge this change? ",False,0,NONE
https://api.github.com/repos/arduino/Arduino/issues/comments/610314584,Make serial plotter ringbuffer size configurable,madsdyd,7,313096908,5,610314584,0,610291555,2020-04-07T10:43:44Z,"So, does arduino/Arduino#7461 actually contain all the code in this issue as well?",False,0,NONE
https://api.github.com/repos/arduino/Arduino/issues/comments/611500915,Make serial plotter ringbuffer size configurable,chromhelm,7,313096908,6,611500915,0,610314584,2020-04-09T12:28:46Z,Do not pull it yet. I have made faulty merge.,False,0,CONTRIBUTOR
https://api.github.com/repos/arduino/Arduino/issues/comments/613232425,Make serial plotter ringbuffer size configurable,per1234,7,313096908,7,613232425,0,611500915,2020-04-14T05:23:47Z,This partially fixes https://github.com/arduino/arduino-serial-plotter-webapp/issues/29 (and the remaining part may be wontfix),False,0,COLLABORATOR
https://api.github.com/repos/arduino/Arduino/issues/comments/816669595,Make serial plotter ringbuffer size configurable,CLAassistant,7,313096908,8,816669595,0,613232425,2021-04-09T13:08:19Z,"[![CLA assistant check](https://cla-assistant.io/pull/badge/not_signed)](https://cla-assistant.io/arduino/Arduino?pullRequest=7454) <br/>Thank you for your submission! We really appreciate it. Like many open source projects, we ask that you all sign our [Contributor License Agreement](https://cla-assistant.io/arduino/Arduino?pullRequest=7454) before we can accept your contribution.<br/>**2** out of **3** committers have signed the CLA.<br/><br/>:white_check_mark: chromhelm<br/>:white_check_mark: facchinm<br/>:x: Wilhelm Wiens<br/><hr/>**Wilhelm Wiens** seems not to be a GitHub user. You need a GitHub account to be able to sign the CLA. If you have already a GitHub account, please [add the email address used for this commit to your account](https://help.github.com/articles/why-are-my-commits-linked-to-the-wrong-user/#commits-are-not-linked-to-any-user).<br/><sub>You have signed the CLA already but the status is still pending? Let us [recheck](https://cla-assistant.io/check/arduino/Arduino?pullRequest=7454) it.</sub>",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/7180,commit order must consider non-nullability of join columns as prioritised over nullable join columns: Take 2,bendavies,28,312321697,1,312321697,0,0,2018-04-08T17:02:08Z,"This is a resubmission of https://github.com/doctrine/doctrine2/pull/6533, which attempted to fix https://github.com/doctrine/doctrine2/issues/6499 (also https://github.com/doctrine/doctrine2/issues/7006)

Note that that I consulted Marco on slack before doing this.

I don't want to step on anyones toes, but the original PR has seemed to have gone stale and come to a halt. Maybe the original submitter has lost interest/moved on (his fork appears to be gone) or whatever (not judging), but regardless, I'd like to pick this back again and try and get it over the line.

I've maintained the original commits from the PR as well as some of Marco's styling fixes.

#6533 was merged and then reverted (https://github.com/doctrine/doctrine2/pull/6533#issuecomment-321911821). 
The Tests reveal the problem, `CascadeRemoveOrderTest`. If anyone has any idea how this can be fixed before I start poking around, please give me a heads up.",True,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/379758005,commit order must consider non-nullability of join columns as prioritised over nullable join columns: Take 2,Ocramius,28,312321697,2,379758005,0,312321697,2018-04-09T13:47:45Z,Restarted zeh build,False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/379821546,commit order must consider non-nullability of join columns as prioritised over nullable join columns: Take 2,bendavies,28,312321697,3,379821546,0,379758005,2018-04-09T16:58:26Z,"taking a look at the commit order of the entities in `CascadeRemoveOrderTest`, they are reversed with this patch on the `remove -> flush`.",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/379993633,commit order must consider non-nullability of join columns as prioritised over nullable join columns: Take 2,bendavies,28,312321697,4,379993633,0,379821546,2018-04-10T06:52:59Z,"Ok, I've taken a deeper look at why `CascadeRemoveOrderTest` is failing, and it is as follows:

1. `CascadeRemoveOrderEntityO` has a nullable FK to `CascadeRemoveOrderEntityG`
2. `CascadeRemoveOrderEntityG` has a nullable FK to `CascadeRemoveOrderEntityO`

This results in the `CommitOrderCalculator` having a node list of
`CascadeRemoveOrderEntityO -> CascadeRemoveOrderEntityG`, weight 0
`CascadeRemoveOrderEntityG -> CascadeRemoveOrderEntityO`, weight 0.

i.e this graph as 2 valid commit orders. It just so happens that with the fix in this PR, the ""wrong"" one is chosen, but we have no way of knowing it's the wrong/right one. 

It seems that `CascadeRemoveOrderTest` only passes currently on 2.6 by depending on the bug that a non defined `nullable` is treated as `nullable=false`.
Indeed, if you add `@JoinColumn(nullable=true)` to `CascadeRemoveOrderEntityG::$ownerO`, (essentially changing nothing), `CascadeRemoveOrderTest` will fail on 2.6/master.

So it seems we need to do something about the test. the fix in this PR seems valid.

Guidance appreciated @Ocramius @lcobucci @guilhermeblanco ",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/380841413,commit order must consider non-nullability of join columns as prioritised over nullable join columns: Take 2,arnaud-lb,28,312321697,5,380841413,0,379993633,2018-04-12T15:14:57Z,"I believe that the changes proposed in the PR are not enough to fix the problem, unfortunately.

With this PR applied, the code at https://gist.github.com/arnaud-lb/2ac4a3007bba08ca5f8fa78cfc353cf5 will generate the following graph:

```
<?php

$calc = new CommitOrderCalculator();

$calc->addNode('A', 'A');
$calc->addNode('B', 'B');
$calc->addNode('C', 'C');

// B referenced by A
$calc->addDependency('B', 'A', 1);

// A referenced by B (nullable)
$calc->addDependency('A', 'B', 0);

// A referenced by C
$calc->addDependency('A', 'C', 1);
```

The output of `$calc->sort()` is C, B, A. Since C has a non-nullable reference to A, trying to insert C will not work.

The problems seems to arise from the fact that we are trying to sort a cyclic graph topologically. When the execution reaches a state that shouldn't happen in the orignal algorithm (`case self::IN_PROGRESS`), the implementation doesn't abort, and nodes may be added to the sorted node list prematurely.

Ignoring the nullable references when building the graph seems to creates an acyclic graph in my case (Is a cycle of non-null references possible?), and the commit order is correct (on a quite complex schema). The order may not be optimal, though, and I don't know if it works for entity removal.",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/380861440,commit order must consider non-nullability of join columns as prioritised over nullable join columns: Take 2,bendavies,28,312321697,6,380861440,0,380841413,2018-04-12T16:14:59Z,"thanks for that @arnaud-lb.
I'll add failing test cases to this PR.",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/380871915,commit order must consider non-nullability of join columns as prioritised over nullable join columns: Take 2,lcobucci,28,312321697,7,380871915,0,380861440,2018-04-12T16:48:07Z,"@bendavies I think that we might consider to have a more complicated logic to calculate the weight of the dependencies. I mean, the `CommitOrderCalculator` is flexible enough to deal with other values (not only `0` and `1`) and we might be able to solve this issue by increasing the weight based on certain criteria, like:

```php
$weight = 0;

if ($joinColumnIsNullable) {
    ++$weight;
}

if ($isSomethingElse) {
    ++$weight;
}

// ...

return $weight;
```",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/380970947,commit order must consider non-nullability of join columns as prioritised over nullable join columns: Take 2,bendavies,28,312321697,8,380970947,0,380871915,2018-04-12T23:06:49Z,"hah, i managed to hack in a fix for @arnaud-lb test/problem.",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/380972101,commit order must consider non-nullability of join columns as prioritised over nullable join columns: Take 2,bendavies,28,312321697,9,380972101,0,380970947,2018-04-12T23:13:44Z,"@lcobucci I'm thinking that `CascadeRemoveOrderTest` is unsolvable by the `CommitOrderCalculator`.
`CascadeRemoveOrderEntityO` has a nullable FK to `CascadeRemoveOrderEntityG`
`CascadeRemoveOrderEntityG` has a nullable FK to `CascadeRemoveOrderEntityO`

O's FK could be populated, which means we need to delete O first, then G.
G's FK could be populated, which means we need to delete G first, then O.
Both O's and G's FK could be populated, in which case neither can be deleted first - It must be a 2 phase flush.

EDIT: I've just seen that `CascadeRemoveOrderEntityO` has `onDelete=""SET NULL""` on it's FK. Could the CommitOrderCalculator take that into account? However, if it didn't have `onDelete=""SET NULL""`, the problem goes back to being unsolvable?

The only think i can think of (but i'm not very familiar with UOW) is to add `scheduleExtraUpdate` support for nullable foreign keys when removing entities, so you first null the FK, then remove the entity. I'm sure someone more experienced can tell me why that's a stupid idea.",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/381056170,commit order must consider non-nullability of join columns as prioritised over nullable join columns: Take 2,arnaud-lb,28,312321697,10,381056170,0,380972101,2018-04-13T07:58:37Z,"> hah, i managed to hack in a fix for @arnaud-lb test/problem.

Awesome! Will it handle cycles involving more than 2 nodes, though?",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/381058241,commit order must consider non-nullability of join columns as prioritised over nullable join columns: Take 2,bendavies,28,312321697,11,381058241,0,381056170,2018-04-13T08:07:11Z,"It's probably not robust at all. Like I said, a quick hack 😁.  can you
provide an example for a more complex graph?",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/381067448,commit order must consider non-nullability of join columns as prioritised over nullable join columns: Take 2,arnaud-lb,28,312321697,12,381067448,0,381058241,2018-04-13T08:42:29Z,"Sure, here is a new failing test with a 3 nodes cycle: https://github.com/arnaud-lb/doctrine2/commit/c7facacefc3448f2af621c4c10579eb9829aca32",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/381068124,commit order must consider non-nullability of join columns as prioritised over nullable join columns: Take 2,bendavies,28,312321697,13,381068124,0,381067448,2018-04-13T08:44:58Z,"Thanks @arnaud-ld. What is the correct commit order for that, to save me trying to work it out?",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/381070823,commit order must consider non-nullability of join columns as prioritised over nullable join columns: Take 2,arnaud-lb,28,312321697,14,381070823,0,381068124,2018-04-13T08:55:03Z,"F, E, D, G would work as a commit order. Removing the addDependency() call when $joinColumnsNullable is true yields this order. However, I believe that doing this would cause more `scheduleExtraUpdate` than necessary with real world entities.",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/381107381,commit order must consider non-nullability of join columns as prioritised over nullable join columns: Take 2,Ocramius,28,312321697,15,381107381,0,381070823,2018-04-13T11:29:32Z," > @bendavies I think that we might consider to have a more complicated logic to calculate the weight of the dependencies. I mean, the `CommitOrderCalculator` is flexible enough to deal with other values (not only `0` and `1`)

@lcobucci that opens a can of worms IMO, as we start defining weights without having a clear idea of what the weights actually are.

 > It must be a 2 phase flush.

These are scenarios in which the ORM should probably kick in at metadata validation time... Would be interesting to see how far we can go with defining the commit order before runtime: possibly a completely different project?

 > EDIT: I've just seen that `CascadeRemoveOrderEntityO` has `onDelete=""SET NULL""` on it's FK. Could the CommitOrderCalculator take that into account? However, if it didn't have `onDelete=""SET NULL""`, the problem goes back to being unsolvable?

In short: no. Not all RDBMSs in use support `onDelete` or foreign keys in general. To take a simple one: MySQL's `onDelete` is already limited to 16 cascades, so it can't really be safely relied upon. We can't rely on that for now, sorry.",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/381110257,commit order must consider non-nullability of join columns as prioritised over nullable join columns: Take 2,bendavies,28,312321697,16,381110257,0,381107381,2018-04-13T11:43:30Z,"@ocramius thanks for that. Do you have any opinion on `CascadeRemoveOrderTest` specifically? I still don't think the commit order calculator can determine the correct order for the classes in that test from class metadata alone, as it stands.",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/381128945,commit order must consider non-nullability of join columns as prioritised over nullable join columns: Take 2,Ocramius,28,312321697,17,381128945,0,381110257,2018-04-13T13:05:43Z," > Do you have any opinion on `CascadeRemoveOrderTest` specifically? 

It seems like the test was faulty due to missing explicit `nullable=true` there. Not much to do there: we simply unveiled a hidden issue here. I don't think it should be changed for now, as users might be affected.",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/381341943,commit order must consider non-nullability of join columns as prioritised over nullable join columns: Take 2,bendavies,28,312321697,18,381341943,0,381128945,2018-04-14T16:37:18Z,"I've taken in @arnaud-lb failing tests and added the same scenario to the commit order calculator.
The graph is this:
![image](https://user-images.githubusercontent.com/625392/38770387-5e1cf088-400a-11e8-9684-7512b6f785b1.png)
It's obvious what the path should be from looking at it: `F, E, D, G`. The commit order calculator isn't currently clever enough to work this out.",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/381362496,commit order must consider non-nullability of join columns as prioritised over nullable join columns: Take 2,bendavies,28,312321697,19,381362496,0,381341943,2018-04-14T21:39:58Z,"As above, at the moment the `CommitOrderCalculator` is too naive to work out some quite simple graphs.
I have a POC that fixes the above issues and improves the `CommitOrderCalculator` so that it solves the above graph and more complex ones.

Basically:
1. Find the [Minimum spanning tree](https://en.wikipedia.org/wiki/Minimum_spanning_tree) of the Graph.
2. Perform a [Topological Sort](https://en.wikipedia.org/wiki/Topological_sorting) of this graph to get your commit order.

Edit: I'm not sure this is appropriate actually. MST is for unidirected graphs while ours is directed.

However, there is a slight complication in that the `CommitOrderCalculator` could contain multiple unconnected graphs. MST requires a connected graph to perform on.
So before performing MST and sort, the distinct graphs need to be identified, and the above steps performed on each graph.

The sorts of these unconnected graphs can then be returned in any order as they are not dependent.

The above is a not a trivial undertaking so I don't want pursue it if someone thinks it's a bad idea or can see a really simple fix to the current impl that I've overlooked.

If @guilhermeblanco could provide some feedback before I try and take this any further, that would be great, since he implemented the `CommitOrderCalculator` in its current form. ",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/381362533,commit order must consider non-nullability of join columns as prioritised over nullable join columns: Take 2,lcobucci,28,312321697,20,381362533,0,381362496,2018-04-14T21:40:47Z,"> The commit order calculator isn't currently clever enough to work this out.

@bendavies @Ocramius the commit order calculator knows only about the `weight`, it wasn't designed to know about the association mapping:

https://github.com/doctrine/doctrine2/blob/77e3e5c96c1beec7b28443c5b59145eeadbc0baf/lib/Doctrine/ORM/Internal/CommitOrderCalculator.php#L143-L148

It may indeed open a can of worms, but if we have issues with the logic which is sending data to the commit order calculator we shouldn't simply change the class (`CommitOrderCalculator`) but rather that logic.",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/381362874,commit order must consider non-nullability of join columns as prioritised over nullable join columns: Take 2,bendavies,28,312321697,21,381362874,0,381362533,2018-04-14T21:47:43Z,@lcobucci i think the data provided to the calculator is fine. This graph is simple but isn't solved correctly: https://github.com/doctrine/doctrine2/pull/7180#issuecomment-381341943,False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/392716639,commit order must consider non-nullability of join columns as prioritised over nullable join columns: Take 2,arnaud-lb,28,312321697,22,392716639,0,381362874,2018-05-29T09:41:01Z,What's the status of this bug ? @bendavies you seemed to be on the right path.,False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/392717187,commit order must consider non-nullability of join columns as prioritised over nullable join columns: Take 2,bendavies,28,312321697,23,392717187,0,392716639,2018-05-29T09:42:56Z,"My solution wasn't good because `MST is for unidirected graphs while ours is directed.`

I was waiting for @guilhermeblanco's feedback/help, really.",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/427745422,commit order must consider non-nullability of join columns as prioritised over nullable join columns: Take 2,bendavies,28,312321697,24,427745422,0,392717187,2018-10-08T07:42:40Z,maybe fixed by https://github.com/doctrine/doctrine2/pull/7260,False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/428146093,commit order must consider non-nullability of join columns as prioritised over nullable join columns: Take 2,bendavies,28,312321697,25,428146093,0,427745422,2018-10-09T10:45:37Z,rebased after #7260 was merged,False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/428486204,commit order must consider non-nullability of join columns as prioritised over nullable join columns: Take 2,bendavies,28,312321697,26,428486204,0,428146093,2018-10-10T08:35:16Z,"thought i'd take a look at how hibernate handles this. They do it a bit differently.
 
Doctrine deduces **table** insert ordering from class metadata, while hibernate orders the inserted entities themselves.",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/513041497,commit order must consider non-nullability of join columns as prioritised over nullable join columns: Take 2,ndench,28,312321697,27,513041497,0,428486204,2019-07-19T00:18:44Z,@bendavies how did you go with this?,False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/513215192,commit order must consider non-nullability of join columns as prioritised over nullable join columns: Take 2,bendavies,28,312321697,28,513215192,0,513041497,2019-07-19T12:45:36Z,"no further sorry. I think the proper fix would be to copy Hibernate.

> Doctrine deduces **table** insert ordering from class metadata, while hibernate orders the inserted entities themselves.

",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/1447100121,commit order must consider non-nullability of join columns as prioritised over nullable join columns: Take 2,mpdude,28,312321697,29,1447100121,0,513215192,2023-02-27T21:15:08Z,"Still remember what you did 5 years ago? If so, maybe you can help to review #10547.",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/7181,Add BETWEEN() expr and fix the PHPDoc. 2.5,frag-seb,5,312462476,1,312462476,0,0,2018-04-09T09:43:39Z,"The parameters $x and $y can also be a string, for example a date.",True,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/379720492,Add BETWEEN() expr and fix the PHPDoc. 2.5,holtkamp,5,312462476,2,379720492,0,312462476,2018-04-09T11:28:50Z,"Nice, maybe this can be combined with resolving https://github.com/doctrine/doctrine2/issues/6450",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/379746263,Add BETWEEN() expr and fix the PHPDoc. 2.5,Ocramius,5,312462476,3,379746263,0,379720492,2018-04-09T13:10:56Z,"Closing as `invalid`.

`Improvement` patches are to be sent to `master` only: we will only fix bugs on `2.x`, and `2.5` will only receive security fixes.",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/379755533,Add BETWEEN() expr and fix the PHPDoc. 2.5,frag-seb,5,312462476,4,379755533,0,379746263,2018-04-09T13:40:12Z,Does it make sense to send this PullRequest for the master?,False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/379756706,Add BETWEEN() expr and fix the PHPDoc. 2.5,Ocramius,5,312462476,5,379756706,0,379755533,2018-04-09T13:43:43Z,"@frag-seb yes, if it improves `master` :+1: ",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/392537236,Add BETWEEN() expr and fix the PHPDoc. 2.5,holtkamp,5,312462476,6,392537236,0,379756706,2018-05-28T14:09:51Z,@frag-seb did this eventually land in `master`? I am asking because I am wondering about the status of https://github.com/doctrine/doctrine2/issues/6450,False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/7183,Autowire problem ?,public0,4,312822347,1,312822347,0,0,2018-04-10T08:31:48Z,"We decided to use work with YAML instead of Annotations and also not use autowire but instead register our services in services.yaml.

I made a custom query in a repo which i'm calling in a service which in turn is called in the controller.

Controller:
```
public function search($name)
    {
        $result = $this->tagService->search($name);
        var_dump($result);

        $response = [];
        return new ResponseService($response);
   }
```

TagService
```
    public function search($search)
    {
        try {
            return $this->entityManager->getRepository(Tag::class)->search($search);
        } catch (\Exception $e) {
            echo $e->getMessage();
        }
    }


```
TagRepository

```
class TagRepository extends ServiceEntityRepository
{
     public function __construct(RegistryInterface $registry)
     {
         parent::__construct($registry, Tag::class);
     }

    public function search($value)
    {
        return $this->createQueryBuilder('t')
            ->where('t.name LIKE :value')->setParameter('value', $value)
            ->orderBy('t.id', 'ASC')
            ->setMaxResults(10)
            ->getQuery()
            ->getResult()
        ;
    }
}

```
App\Entity\Tag

> App\Entity\Tag:
> type: entity
> repositoryClass: App\Repository\TagRepository
> id:
> id:
> type: integer
> generator: { strategy: AUTO }
> fields:
> 
> name:
> type: string
> length: 100
> 

If my repo extends ServiceEntityRepository i get this where it says it can't find this service

The ""App\Repository\TagRepository"" entity repository implements ""Doctrine\Bundle\DoctrineBundle\Repository\ServiceEntityRepositoryInterface"", but its service could not be found. Make sure the service exists and is tagged with ""doctrine.repository_service"".

But if i extend EntityRepository instead of ServiceEntityRepository it works

",True,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/380046085,Autowire problem ?,Nek-,4,312822347,2,380046085,0,312822347,2018-04-10T10:06:13Z,"Hello,

This problem is not related to Doctrine itself but to the [DoctrineBundle](https://github.com/doctrine/DoctrineBundle) of Symfony.

If you have questions, consider [StackOverflow or the Slack chat of Symfony](https://symfony.com/community). Also please give more information next time because without your service definition and namespaces it's not possible to help you on a problem of service declaration :) .

Please close this issue as it is not related to Doctrine at all.

_PS: You can enable syntax coloration of the code by using better the markdown. That would be great for your next messages._",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/380064471,Autowire problem ?,Ocramius,4,312822347,3,380064471,0,380046085,2018-04-10T11:22:25Z,Closing as per @Nek-'s comment,False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/522049201,Autowire problem ?,sewi-cpan,4,312822347,4,522049201,0,380064471,2019-08-16T15:25:46Z,"@Nek- An answer would have been great instead of linking to a chat. There's no answer on StackOverflow and no usable documentation. Could you edit and enhance your reply, please?",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/523975517,Autowire problem ?,Nek-,4,312822347,5,523975517,0,522049201,2019-08-22T16:19:14Z,"@sewi-cpan a problem relative to user code without user code or reproducer is not resolvable. Sorry. I mentioned it btw.

> Also please give more information next time because without your service definition and namespaces it's not possible to help you on a problem of service declaration :) .

Please, be kind with OSS contributors. We do our best, for free.",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/7186,[request] option to only use SQL in dumped schema information,holtkamp,6,312857665,1,312857665,0,0,2018-04-10T10:11:09Z,"Currently the dumped information of the [UpdateCommand](https://github.com/doctrine/doctrine2/blob/c4c59df1b4251f5030a08bd1253a0e472e4bdb7e/lib/Doctrine/ORM/Tools/Console/Command/SchemaTool/UpdateCommand.php#L87) also includes non-SQL text:

_""The following SQL statements will be executed:""_

Is there a specific reason to do this? We currently store the output in a .sql file, which can then be easily executed, for example when spinning up a Docker instance. But the generated SQL is now ""invalid"" due to the help text. 

Of course this text can be stripped after generation, but still, it feels awkward. ",True,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/380060880,[request] option to only use SQL in dumped schema information,Ocramius,6,312857665,2,380060880,0,312857665,2018-04-10T11:06:49Z,"Good question, but a few problems arise: 

 1. changing this may break existing hacks. I don't mind that much, but it can really introduce problems
 2. the `dump` command is, as it says, to `dump` information, not to generate an actually usable SQL string. For that, using the diffing tools directly would be more appropriate.",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/380077228,[request] option to only use SQL in dumped schema information,holtkamp,6,312857665,3,380077228,0,380060880,2018-04-10T12:15:28Z,"> changing this may break existing hacks. I don't mind that much, but it can really introduce problems

True, also saw some commented ""stripping"" functionality in my scripts from the time [when the warnings were printed](https://github.com/doctrine/doctrine2/blob/c4c59df1b4251f5030a08bd1253a0e472e4bdb7e/lib/Doctrine/ORM/Tools/Console/Command/SchemaTool/UpdateCommand.php#L116-L119) in the beginning of the output, just re-activated /re-used that 😉 

 >the dump command is, as it says, to dump information, not to generate an actually usable SQL string. For that, using the diffing tools directly would be more appropriate.

Also true. Maye a dedicated Command is required to write the output to a SQL file...

I kind of triggered when I saw this warning is [not printed when being dumped / forced](https://github.com/doctrine/doctrine2/blob/c4c59df1b4251f5030a08bd1253a0e472e4bdb7e/lib/Doctrine/ORM/Tools/Console/Command/SchemaTool/UpdateCommand.php#L110-L112).

For now closing issue and stripping the first three lines from the outputted information.

",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/380085083,[request] option to only use SQL in dumped schema information,Nek-,6,312857665,4,380085083,0,380077228,2018-04-10T12:44:57Z,"I think this feature may be discussed as it's interesting. Of course it's easy to use the `SchemaTools` to get the queries we want. But it could also be provided by default using some arguments or option to the command.

Maybe adding a ""non-verbose"" option is a good idea?

Suggestion for names:
- `--simple`
- `--sql-only`
- `--dump-only`

Or in Doctrine3 it could be just change with adding a value to the dump arg. What do you think about?

It is a simple contribution that could be done at events like hacktoberfest fest.",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/380095011,[request] option to only use SQL in dumped schema information,holtkamp,6,312857665,5,380095011,0,380085083,2018-04-10T13:19:08Z,"Aah, I now see I referenced the UpdateCommand. That should be the [CreateCommand](https://github.com/doctrine/doctrine2/blob/967d34473e2d566d6f1beb3aca9a7da07f8fafe6/lib/Doctrine/ORM/Tools/Console/Command/SchemaTool/CreateCommand.php#L48) 😊

I guess `--sql-only` would be my choice, since it seems semantically most correct:

```
./vendor/bin/doctrine orm:schema-tool:create --dump-sql --sql-only
```",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/380101678,[request] option to only use SQL in dumped schema information,Nek-,6,312857665,6,380101678,0,380095011,2018-04-10T13:40:05Z,Both may be modifiy in this way. What do you think @Ocramius ?,False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/381163110,[request] option to only use SQL in dumped schema information,Ocramius,6,312857665,7,381163110,0,380101678,2018-04-13T14:59:48Z,Adding a flag that excludes all output and disables colors implicitly seems fine :+1: ,False,0,MEMBER
https://api.github.com/repos/dokuwiki/dokuwiki/issues/2309,DokuHTTPClient: Add handling for 204: No Content responses,micgro42,3,314117541,1,314117541,0,0,2018-04-13T13:57:22Z,"This fixes a bug that would occur if the DokuHTTPClient receives a 204 response, e.g. as a result for a request to delete something. It would still try to read the body, which fails, thus producing a timeout and
finally throwing an exception.

This fix instructs the HTTPClient to not read the (not existing) body if it receives a 204.

This fixes #2308 ",True,0,COLLABORATOR
https://api.github.com/repos/dokuwiki/dokuwiki/issues/comments/381261976,DokuHTTPClient: Add handling for 204: No Content responses,splitbrain,3,314117541,2,381261976,0,314117541,2018-04-13T21:13:02Z,Could we have a test against https://httpbin.org/status/204,False,0,COLLABORATOR
https://api.github.com/repos/dokuwiki/dokuwiki/issues/comments/381275106,DokuHTTPClient: Add handling for 204: No Content responses,micgro42,3,314117541,3,381275106,0,381261976,2018-04-13T22:25:40Z,"No, because this error only occurs if there is no `Content-Length` header. But https://httpbin.org/status/204 sends an `Content-Length: 0` header, which is incorrect:

> A server MUST NOT send a Content-Length header field in any response
   with a status code of 1xx (Informational) or 204 (No Content).

Hypertext Transfer Protocol (HTTP/1.1): Message Syntax and Routing -- RFC7320 
https://tools.ietf.org/html/rfc7230#section-3.3.2

If there is a server that reliably sends 204 without that header, I'll gladly write a test :slightly_smiling_face: ",False,0,COLLABORATOR
https://api.github.com/repos/dokuwiki/dokuwiki/issues/comments/381276360,DokuHTTPClient: Add handling for 204: No Content responses,micgro42,3,314117541,4,381276360,0,381275106,2018-04-13T22:33:50Z,I opened an issue upstream: kennethreitz/httpbin#437,False,0,COLLABORATOR
https://api.github.com/repos/dokuwiki/dokuwiki/issues/2314,Fix invalid HTML,selfthinker,9,314419373,1,314419373,0,0,2018-04-15T14:16:18Z,"This fixes some invalid HTML which mostly sneaked in with #2286.
The semantics of the search results page are a bit tricky. I nearly changed the existing description list to a normal unordered list, but I think it still makes sense the way it is now, i.e. a `dl` with 1 `dt` and 2 `dd`. Semantically I think it might make more sense to move the ""[number of] Hits"" also into its own `dd` or add it to the 'last modified' line.
",True,0,COLLABORATOR
https://api.github.com/repos/dokuwiki/dokuwiki/issues/comments/381432094,Fix invalid HTML,micgro42,9,314419373,2,381432094,0,314419373,2018-04-15T19:35:44Z,"Thank you for checking and fixing the invalid html. Having this as part of the CI would indeed be very helpful! :+1: 
I feel also a bit strange about this being an description list, both semantically and with the restriction in puts on the html that is allowed.
We should also modify the new `SEARCH_RESULT_FULLPAGE` event so it wraps the elements of the `resultBody` key in `dd` tags. Since they are basically the only valid element in this context, it doesn't make sense to leave that up to the plugin author.",False,0,COLLABORATOR
https://api.github.com/repos/dokuwiki/dokuwiki/issues/comments/381441733,Fix invalid HTML,selfthinker,9,314419373,3,381441733,0,381432094,2018-04-15T22:04:26Z,"Being a description list is fine-ish, although it's a bit of an edge case and some other semantics could fit as well or maybe even better. I think two things are important for the semantics here: 1. the results are some form of list and 2. the page name is highlighted as being the descriptor of each item. That relationship can be achieved either with dt and dd or a heading in an li. Just divs would also work but would be inferior.

The ""[number of] Hits"" and ""Last modified"" are sort of meta data, although the number of hits is more important as that informs the importance (and order) of the results. I guess that can only really be conveyed via context. Whichever the semantics, I think the number of hits and last modified date should be on the same line.

What do you think are the kind of things people would put into the resultBody of SEARCH_RESULT_FULLPAGE? I wonder if it makes more sense to only allow to add stuff to the line between the ""heading"" and the snippet?
",False,0,COLLABORATOR
https://api.github.com/repos/dokuwiki/dokuwiki/issues/comments/381513428,Fix invalid HTML,micgro42,9,314419373,4,381513428,0,381441733,2018-04-16T08:01:12Z,"> The ""[number of] Hits"" and ""Last modified"" are sort of meta data, although the number of hits is more important as that informs the importance (and order) of the results. I guess that can only really be conveyed via context. Whichever the semantics, I think the number of hits and last modified date should be on the same line.

Currently, we still show the number of hits for all results but we drop the last modified when we drop the snippet (iirc the cutoff is 15). Do you think it would be better to show both last mod and number of hits for all results or drop both for the later results?


> What do you think are the kind of things people would put into the resultBody of SEARCH_RESULT_FULLPAGE? I wonder if it makes more sense to only allow to add stuff to the line between the ""heading"" and the snippet?

One specific implementation would be the [watchcycle](https://www.dokuwiki.org/plugin:watchcycle) maintenance plugin, which shows just an icon to indicate maintenace status on some pages.
Other small examples could be the rating of the rater plugin, quality score by the qc plugin or tags from a tagging plugin. However, some struct plugin might also add some struct data to the search results. This could look similar to the wikipedia result of the Avengers film: 

![screenshot-2018-4-16 avengers - google search](https://user-images.githubusercontent.com/7372507/38796773-b5ccf884-415c-11e8-82ff-6a42ff102d5e.png)
https://www.google.com/search?q=Avengers.

There is also precedence for even more added information/links:

![screenshot-2018-4-16 dokuwiki - google search](https://user-images.githubusercontent.com/7372507/38796796-c7352d4e-415c-11e8-94f0-241554aa0fdd.png)
https://www.google.com/search?q=DokuWiki

Now that I think of it, it might be sensible to add the search result's position to the event data, since some modifications are maybe only intended for the first n results? 🤔
",False,0,COLLABORATOR
https://api.github.com/repos/dokuwiki/dokuwiki/issues/comments/381621874,Fix invalid HTML,splitbrain,9,314419373,5,381621874,0,381513428,2018-04-16T14:38:02Z,:+1: for the position in the event data,False,0,COLLABORATOR
https://api.github.com/repos/dokuwiki/dokuwiki/issues/comments/381774172,Fix invalid HTML,selfthinker,9,314419373,6,381774172,0,381621874,2018-04-16T22:48:39Z,"Because we can't be sure what to expect in the resultBody, I guess it makes more sense to change the `dl` to a `ul` or `ol`. (As the order of the results mean something, I'm leaning towards `ol`, although the numbers wouldn't be showing.)

> Do you think it would be better to show both last mod and number of hits for all results or drop both for the later results?

I think the latter makes more sense. When you only have the page name (or first heading, depending on config) to go by because the snippet has been removed, the number of hits and last modified date help to decide which results might be relevant.

> it might be sensible to add the search result's position to the event data, since some modifications are maybe only intended for the first n results?

Maybe that can be simplified by only passing if they will be part of the first, more prominent results before the cutoff or after?

If no-one objects or has a better idea I will make the following changes tomorrow:
* change dl to ol
* move number of hits and last modified date onto the same line (independent of snippet cutoff)
* change dt to heading
* fix heading hierarchy while I'm at it (current h3s should be h2, making the new item headings h3s)",False,0,COLLABORATOR
https://api.github.com/repos/dokuwiki/dokuwiki/issues/comments/381880335,Fix invalid HTML,splitbrain,9,314419373,7,381880335,0,381774172,2018-04-17T07:36:29Z,"1) Personally, I think the DL fits the search results better. They are ordered, yes but this order is not necessarily correct (the correct hit for what the user was searching for might be the 5th result, not the 1st) and everything currently in DDs does describe the DT (the hit). With the change proposed by Michael to not pass the DD wrapper inside the event data but instead wrap the results coming from the event in DDs, we ensure the DL stays correct.
2) I'm fine with moving the hits into the same line as the lastmod (I would rename the class from `lastmod` to `meta`)",False,0,COLLABORATOR
https://api.github.com/repos/dokuwiki/dokuwiki/issues/comments/382183438,Fix invalid HTML,selfthinker,9,314419373,8,382183438,0,381880335,2018-04-17T22:58:47Z,"Sorry, I thought I would have time today, but it looks more like I will make the changes Thursday or Friday. (I'm aware this is the last issue left in the milestone.)",False,0,COLLABORATOR
https://api.github.com/repos/dokuwiki/dokuwiki/issues/comments/382424295,Fix invalid HTML,micgro42,9,314419373,9,382424295,0,382183438,2018-04-18T15:18:51Z,@selfthinker Just a quick heads-up: We have already made some changes to this pull request and we have partially implemented the above points. Please check the last commits on this branch so that no work is performed twice. :slightly_smiling_face: ,False,0,COLLABORATOR
https://api.github.com/repos/dokuwiki/dokuwiki/issues/comments/382904293,Fix invalid HTML,selfthinker,9,314419373,10,382904293,0,382424295,2018-04-19T22:51:03Z,"I'm nearly happy with how it is now. I would prefer an `ol` or `ul` but don't feel very strongly about it.

There are only two things left: Apart from the comments I just left, I also changed the meta items to be separated by punctuation instead of just spacing. That is more natural, makes sense with CSS switched off and makes screenreaders add a little pause.

I don't think this is really important, but it looks weird that the ""Last modified"" starts with uppercase (although it already looked weird before) and I was tempted to add a `lcfirst` but then I thought it could make something worse in other languages and didn't do it.",False,0,COLLABORATOR
https://api.github.com/repos/dokuwiki/dokuwiki/issues/2326,Greebo: new code in parser/xhtml.php results in error message with include plugin,turnermm,6,316630309,1,316630309,0,0,2018-04-23T01:02:45Z,"New Code in Greebo, parse/xhtml.php:
```
        if (!is_array($data)) {
            msg(
                sprintf(
                    'startSectionEdit: $data ""%s"" is NOT an array! One of your plugins needs an update.',
                    hsc((string) $data)
                ), -1
            );
ll. 79-86 parser/xhtml.php
```
This new code outputs the error message in response to include/syntax/wrap.php, ll. 39-46.  No error is issued to the server error log.  First reported on the forum: https://forum.dokuwiki.org/thread/15764.  This does not happen in Frusterick M (or earlier).


",True,0,CONTRIBUTOR
https://api.github.com/repos/dokuwiki/dokuwiki/issues/comments/383447223,Greebo: new code in parser/xhtml.php results in error message with include plugin,kvnyang,6,316630309,2,383447223,0,316630309,2018-04-23T03:54:28Z,"My dokuwiki shows the following error at the top of the welcome page every time I log out and log in:
```
startSectionEdit: $data ""plugin_include_start"" is NOT an array! One of your plugins needs an update.
startSectionEdit: $data ""plugin_include_end"" is NOT an array! One of your plugins needs an update.
startSectionEdit: $data ""plugin_include_start"" is NOT an array! One of your plugins needs an update.
...
```",False,0,NONE
https://api.github.com/repos/dokuwiki/dokuwiki/issues/comments/383482056,Greebo: new code in parser/xhtml.php results in error message with include plugin,selfthinker,6,316630309,3,383482056,0,383447223,2018-04-23T07:35:03Z,"As the message says, the plugin ""needs an update"". This has already been fixed in the include plugin (dokufreaks/plugin-include#224), please update the plugin.
It's mentioned in the [changelog](https://www.dokuwiki.org/changes#release_2018-04-22_release_greebo), see #2290 for more info.",False,0,COLLABORATOR
https://api.github.com/repos/dokuwiki/dokuwiki/issues/comments/383547598,Greebo: new code in parser/xhtml.php results in error message with include plugin,turnermm,6,316630309,4,383547598,0,383482056,2018-04-23T11:48:34Z,"I think the issue yesterday was that the update wasn’t showing up in the extension manager.

 

",False,0,CONTRIBUTOR
https://api.github.com/repos/dokuwiki/dokuwiki/issues/comments/383679251,Greebo: new code in parser/xhtml.php results in error message with include plugin,tmo26,6,316630309,5,383679251,0,383547598,2018-04-23T18:39:41Z,"Re-Installing the include plugin via the Extension Manager solved the _""plugin_include_start"" is NOT an array!_ error, but it still doesn't show up as updatable.

Even after re-installing it reports _""Installed version:   2017-08-24""_",False,0,NONE
https://api.github.com/repos/dokuwiki/dokuwiki/issues/comments/383811174,Greebo: new code in parser/xhtml.php results in error message with include plugin,micgro42,6,316630309,6,383811174,0,383679251,2018-04-24T05:49:10Z,"While the include plugin already contains the fixes, I just now updated its version number. Hopefully it will start showing up as updateable to people.",False,0,COLLABORATOR
https://api.github.com/repos/dokuwiki/dokuwiki/issues/comments/384403025,Greebo: new code in parser/xhtml.php results in error message with include plugin,tmo26,6,316630309,7,384403025,0,383811174,2018-04-25T19:17:04Z,"Yes, now it does show up as updatable.
Thanks for fixing this!",False,0,NONE
https://api.github.com/repos/dokuwiki/dokuwiki/issues/2327,Greebo: not compatible with refnotes plugin,kvnyang,3,316651213,1,316651213,0,0,2018-04-23T03:35:27Z,See: dwp-forge/refnotes#44,True,0,NONE
https://api.github.com/repos/dokuwiki/dokuwiki/issues/comments/383545262,Greebo: not compatible with refnotes plugin,splitbrain,3,316651213,2,383545262,0,316651213,2018-04-23T11:38:10Z,should be fixed in plugin,False,0,COLLABORATOR
https://api.github.com/repos/dokuwiki/dokuwiki/issues/comments/385625166,Greebo: not compatible with refnotes plugin,lpaulsen93,3,316651213,3,385625166,0,383545262,2018-05-01T08:33:26Z,Also see https://forum.dokuwiki.org/post/60673.,False,0,COLLABORATOR
https://api.github.com/repos/dokuwiki/dokuwiki/issues/comments/385676351,Greebo: not compatible with refnotes plugin,lpaulsen93,3,316651213,4,385676351,0,385625166,2018-05-01T13:56:09Z,Fixed in plugin refnotes release 2018-05-01.,False,0,COLLABORATOR
https://api.github.com/repos/gatling/gatling/issues/3461,Provide access to Session in transformResponse,asaarilahti,4,322339244,1,322339244,0,0,2018-05-11T15:29:55Z,"Background:
We are testing a service which also calls other services. We would like to subtract the response times of these dependent services from the total response time Gatling sees. This would allow to test the service in somewhat isolated fashion, where slowdowns of dependent services would not be accounted to the service under test.

We can currently adjust the response end time by using transformResponse. However, to do the adjustment we would need to access data from the session. To my understanding that is not possible currently.

I'd be happy to provide a PR, if a change to include the session would be welcome. I have currently a draft version, which just changes PartialFunction[Response, Response] to Function2[Response, Session, Response]. However, that won't be backwards compatible and will lose the benefits of a partial function. Couple of question related to that:
- Should the change be kept backwards compatible with 2.3 (this would target 3.0)?
- Does the proposed solution to use Function2 look ok, or would some other approach like a Trait be preferable?",True,0,NONE
https://api.github.com/repos/gatling/gatling/issues/comments/388409303,Provide access to Session in transformResponse,slandelle,4,322339244,2,388409303,0,322339244,2018-05-11T16:07:50Z,"> Should the change be kept backwards compatible with 2.3 (this would target 3.0)?

Definitively impossible in 2.3. And I don't think there will be a new release on this branch anyway.

> Does the proposed solution to use Function2 look ok, or would some other approach like a Trait be preferable?

> However, to do the adjustment we would need to access data from the session.

Why is that so? You'll be passing the dependent services time in the same response, but you won't be able to grab it from checks as transformer is applied **before the checks**. And there's no way to change that, as transformers are mainly intended for deserializing binary payloads such as protobuf.

I advice you pass this time as an HTTP header (typically [Server-Timing](https://w3c.github.io/server-timing/)) instead of inside a JSON payload so it's easy to grab directly from Response without any complex parsing.",False,0,MEMBER
https://api.github.com/repos/gatling/gatling/issues/comments/388421018,Provide access to Session in transformResponse,asaarilahti,4,322339244,3,388421018,0,388409303,2018-05-11T16:51:12Z,"> You'll be passing the dependent services time in the same response

Seems I didn't mention a key point - in our case the data to the session is already provided by a feeder, so it's not coming from the response. We are replaying traffic from production so we know the expected dependent service response time for every request in advance (and the mock services will respond honoring that, with minor variances in practice).

It sounds that our use case might be quite unconventional, so not sure if the change would be generally useful. What do you think?",False,0,NONE
https://api.github.com/repos/gatling/gatling/issues/comments/388430747,Provide access to Session in transformResponse,asaarilahti,4,322339244,4,388430747,0,388421018,2018-05-11T17:27:33Z,At the end I think the use case is too special to warrant the change - closing.,False,0,NONE
https://api.github.com/repos/gatling/gatling/issues/comments/388448340,Provide access to Session in transformResponse,slandelle,4,322339244,5,388448340,0,388430747,2018-05-11T18:30:49Z,Agree :),False,0,MEMBER
https://api.github.com/repos/gatling/gatling/issues/3463,Lookup JMS Queues and Topics via JNDI,sventorben,5,324052074,1,324052074,0,0,2018-05-17T14:36:58Z,"JEE recommends to lookup JMS Queues and Topics via JNDI instead of using
createQueue/createTopic.

see https://docs.oracle.com/javaee/7/api/javax/jms/Session.html#createQueue-java.lang.String-",True,0,NONE
https://api.github.com/repos/gatling/gatling/issues/comments/389898679,Lookup JMS Queues and Topics via JNDI,slandelle,5,324052074,2,389898679,0,324052074,2018-05-17T15:02:48Z,"Thanks for contributing.
Is there any actual issue with using create? You might have realized that the patch you suggest doesn’t work as is on master/Gatling 3 where we support JMS providers that don’t support JNDI, such as AWS SQS.",False,0,MEMBER
https://api.github.com/repos/gatling/gatling/issues/comments/389903687,Lookup JMS Queues and Topics via JNDI,sventorben,5,324052074,3,389903687,0,389898679,2018-05-17T15:17:46Z,"I am facing an issue when using Gatling with RabbitMQ. There is an outdated plugin (see https://github.com/maiha/gatling-amqp). However, I could not get it to work with current versions of Gatling.
So, I thought of using the RabbitMQ JMS client (https://github.com/rabbitmq/rabbitmq-jms-client) which allows bridging from JMS to AMQP. This only works when using non-standard JMS API for configuring Queues and Topics. Therefore, it is recommended to configure the queues/topics an make them available via JNDI. 
Since the ConnectionFactory is looked up via JNDI, I thought this would be reasonable to lookup queues/topics the same way.
",False,0,NONE
https://api.github.com/repos/gatling/gatling/issues/comments/390010588,Lookup JMS Queues and Topics via JNDI,slandelle,5,324052074,4,390010588,0,389903687,2018-05-17T21:03:14Z,"> This only works when using non-standard JMS API for configuring Queues and Topics. Therefore, it is recommended to configure the queues/topics an make them available via JNDI.

Could you please elaborate? [RMQSession seems to implement createQueue](https://github.com/rabbitmq/rabbitmq-jms-client/blob/master/src/main/java/com/rabbitmq/jms/client/RMQSession.java#L782).

> Since the ConnectionFactory is looked up via JNDI, I thought this would be reasonable to lookup queues/topics the same way.

Now ConnectionFactory can be directly created and some providers only support this way.",False,0,MEMBER
https://api.github.com/repos/gatling/gatling/issues/comments/390102063,Lookup JMS Queues and Topics via JNDI,sventorben,5,324052074,5,390102063,0,390010588,2018-05-18T05:53:18Z,"Naturally the RMQSession implements createQueue, because it is part of the JMS spec. [createQueue calls](https://github.com/rabbitmq/rabbitmq-jms-client/blob/v1.9.0/src/main/java/com/rabbitmq/jms/client/RMQSession.java#L782) `RMQDestination dest = new RMQDestination(queueName, true, false)`, but that constructor does not support AMQP compatibility. For AMQP compatibility RMQSession has an [additional constructor](https://github.com/rabbitmq/rabbitmq-jms-client/blob/v1.9.0/src/main/java/com/rabbitmq/jms/admin/RMQDestination.java#L94) 
`public RMQDestination(String destName, String amqpExchangeName, String amqpRoutingKey, String amqpQueueName)`

Of course, AMQP compatibility is not part of the JMS API. RabbitMQ JMS Client works around that problem by allowing to lookup AMQP compatible queues from JNDI. That feature is implemented in [RMQObjectFactory](https://github.com/rabbitmq/rabbitmq-jms-client/blob/v1.9.0/src/main/java/com/rabbitmq/jms/admin/RMQObjectFactory.java#L215) that implements [ObjectFactory](https://docs.oracle.com/javase/7/docs/api/javax/naming/spi/ObjectFactory.html). This allows JNDI framework to load object implementations dynamically.

When you are saying that other JMS providers do not support JNDI lookups, I assume you are referring to [Amazons SQS library](https://github.com/awslabs/amazon-sqs-java-messaging-lib), right?
From my point of view, libraries like SQS lib do not fully comply to the [JMS spec](http://download.oracle.com/otndocs/jcp/7195-jms-1.1-fr-spec-oth-JSpec/), which demands JNDI support:

> 1.4.6 Java Naming and Directory InterfaceTM (JNDI) API
> JMS clients look up configured JMS objects using the JNDI API. JMS
> administrators use provider-specific facilities for creating and configuring
> these objects.

and

> 2.6.1 Developing a JMS Client
> A typical JMS client executes the following JMS setup procedure:
> - Use JNDI to find a ConnectionFactory object
> - Use JNDI to find one or more Destination objects

and

> 9.1.2 Getting a Destination
> An administrator has created and configured a Queue named “StockSource”
> which is where stock quote messages are sent and received. Again, the
> destination can be looked up using the JNDI API.
> ```
> Queue stockQueue;
> stockQueue = (Queue)messaging.lookup(""StockSource"")
> ```

From my point of view it would be reasonable to change the behaviour as I proposed. In additional implementations like the AWS SQS lib should be fixed accordingly. This can easily be done by providing a ConnectionFactory and ObjectFactory, e.g. like it is done by the RabbitMQ client [over here](https://github.com/rabbitmq/rabbitmq-jms-client/tree/v1.9.0/src/main/java/com/rabbitmq/jms/admin).",False,0,NONE
https://api.github.com/repos/gatling/gatling/issues/comments/390118657,Lookup JMS Queues and Topics via JNDI,slandelle,5,324052074,6,390118657,0,390102063,2018-05-18T07:21:35Z,"The change you suggest is really not straightforward to implement on master (where it should go) as the place where queues and topics are created is not aware of a possible InitialContext.
Feel free to give it a try but I expect it would be pretty cumbersome. Moreover, I don’t think it’s really worth it as it boils down to a complex workaround for the AMQT plugin you mentioned not being updated. It would défini better to contribute an update there.",False,0,MEMBER
https://api.github.com/repos/gatling/gatling/issues/3464,"Not possible to pass  credentials (username,pwd) with file based MQ-JNDI",brandshaide,5,324307231,1,324307231,0,0,2018-05-18T07:55:43Z,"Version of Gatling being used: 2.3.0 

I do have a JMS scenario against a IBM MQ using a file based MQ-JNDI in conjunction with a `bindingsfile` containing all required infomation about my MQ objects (e. g. Hostname, Channel etc.) 
From a security perspective, of course IBM does not allow to have values for username/password in the `bindingsfile` which is just a plain text file. 

So when starting the scenario, the connection attempt is being desclined. 
I'd expect the JNDI lookup to pass values for username/pwd while establishng the ConnectionFactory like so: 

```
QueueConnectionFactory qcf = (QueueConnectionFactory) ctx.lookup(""myQCF"");
QueueConnection qc = qcf.createQueueConnection(userID, password);
```

This is my scenario: 

```
import io.gatling.core.Predef._
import io.gatling.core.structure.ScenarioBuilder
import io.gatling.jms.Predef._
import io.gatling.jms.protocol.JmsProtocolBuilderBase.connectionFactoryName

import scala.concurrent.duration._

class GPRSForwarderTest extends Simulation {

  val JNDI_CONTEXT = ""com.sun.jndi.fscontext.RefFSContextFactory""

  val DEFAULT_QCF_NAME = ""GPRSF""

  val message254 = ""00001100E033102C20EBB51CC1C036EFFFF00010002323802000200FE05001400000000FFFFFFFF01FFFFFFFFFFFFFFFFFFFFF10F37298C""



  val jmsConfig = connectionFactoryName(DEFAULT_QCF_NAME)
    .url(""file:///Users/brandsheide/Documents"")
    .credentials(""mqm"", ""mqm"")
    .contextFactory(JNDI_CONTEXT)
    .listenerCount(1)
    .usePersistentDeliveryMode

    println(""filepath = "" + jmsConfig)


  val scn = scenario(""Load testing GPRS InboundQueue"").repeat(1) {
    exec(jms(""F&F testing"").send
      .queue(""COMPANY.GPRS_MESSAGES.QUEUE"")
      .textMessage(message254)
    )
  }
```
Apparently the values being passed with `.credentials(""mqm"",""mqm"")`are being ingored. 
As of now the only way to run load tests against IBM MQ is to deactivate authentication (?) 
",True,0,NONE
https://api.github.com/repos/gatling/gatling/issues/comments/390131614,"Not possible to pass  credentials (username,pwd) with file based MQ-JNDI",slandelle,5,324307231,2,390131614,0,324307231,2018-05-18T08:15:51Z,"In Gatling 2.3, connecting to queues is [anonymous by default](https://github.com/gatling/gatling/blob/2.3/gatling-jms/src/main/scala/io/gatling/jms/protocol/JmsProtocolBuilder.scala#L44). This feature is being dropped in Gatling 3 and connecting will always use provided credentials if present.",False,0,MEMBER
https://api.github.com/repos/gatling/gatling/issues/comments/390144143,"Not possible to pass  credentials (username,pwd) with file based MQ-JNDI",brandshaide,5,324307231,3,390144143,0,390131614,2018-05-18T09:03:28Z,"@slandelle thanks, when is Gatling 3.0 going to be released? And If I'd like to fix this on my instance of v. 2.3 I'll just have to 

`anonymousConnect: Boolean = true` to `false` instead? 

Or, another way, set `def disableAnonymousConnect = copy(anonymousConnect = false)` to `true` - compile - and invoke the scenario again? Thanks for  your support. ",False,0,NONE
https://api.github.com/repos/gatling/gatling/issues/comments/390144620,"Not possible to pass  credentials (username,pwd) with file based MQ-JNDI",slandelle,5,324307231,4,390144620,0,390144143,2018-05-18T09:05:06Z,"> when is Gatling 3.0 going to be released?
Hopefully first RC in July.

disableAnonymousConnect",False,0,MEMBER
https://api.github.com/repos/gatling/gatling/issues/comments/391298174,"Not possible to pass  credentials (username,pwd) with file based MQ-JNDI",brandshaide,5,324307231,5,391298174,0,390144620,2018-05-23T10:23:06Z,@slandelle thanks. Shall I submit a PR - or has this already been introduced on a feature-branch for v. 3.0 (which I was not able to see on GitHub)?  ,False,0,NONE
https://api.github.com/repos/gatling/gatling/issues/comments/391370731,"Not possible to pass  credentials (username,pwd) with file based MQ-JNDI",slandelle,5,324307231,6,391370731,0,391298174,2018-05-23T14:36:08Z,"Connect is never anonymous in Gatling 3, and AFAIK, there's no reason to make this behavior configurable.",False,0,MEMBER
https://api.github.com/repos/gatling/gatling/issues/3470,Incorrect graph data for Active Users over a long time period,LilSebastian5000,5,329086591,1,329086591,0,0,2018-06-04T14:44:41Z,"Make sure these checkboxes are checked before submitting your issue. Thanks you!

* [*] Don't post questions here. This bugtracker is for issues and feature requests only. Use the [community mailing list](https://groups.google.com/forum/#!forum/gatling) instead.
* Regarding issues:
  * [*] Check that you can reproduce your issue with latest Gatling version
  * [* ] Search this bugtracker for any similar issue that might have already been reported (and possibly fixed and available as a SNAPSHOT version)
  * [*] Provide a way for Gatling developers to reproduce your problem, e.g. step-by-step instructions against a public facing website, or a sample application that demonstrates your problem.
* Regarding feature requests:
  * [*] Explain your use case, not the implementation you have in mind.

I have a script that should ramp up 5 users in a single second, with a 10 second gap in between, over a 2 hour period. Doing the math out, that should be about 3600 users. 

However, the graph is telling me that only 1 user was ramped up every 10-20 seconds, but ~3300 users were ramped up. 

If there really was only 1 user ramped up every 10-20 seconds like the graph shows, there should only be a max of 720 users ramped, so there is an innacuracy between the graph and the number of users called. Has anyone else ran into a similar issue?

Example call (does nothing for 2 sec to wait for an OAUTH token):
```  
val synchronousScenario = List(
    OAuthRequest.inject(atOnceUsers(1)),
    endpt.inject(nothingFor(2 seconds),
      splitUsers(3600) into (5) over (1 seconds)) separatedBy (10 seconds)));

  // Kicks off the scenario
  setUp(synchronousScenario).protocols(httpConf).maxDuration(2 hours);
```


When I halt the script early after maybe 2 minutes and use Gatling command line to generate a report from the simulation log, the graph actually looks accurate, showing 5 users ramping at once with approx 10 seconds in between, so it seems something weird happens to the graph when it's left uninterrupted for a long period of time.

Gatling version 2.3.0
Scala maven plugin version 3.2.2",True,0,NONE
https://api.github.com/repos/gatling/gatling/issues/comments/394438024,Incorrect graph data for Active Users over a long time period,slandelle,5,329086591,2,394438024,0,329086591,2018-06-04T17:39:46Z,"How do you measure the number of injected users? The reports display the number of active users over time, which is entirely different: https://gatling.io/docs/current/general/reports/#active-users-over-time.

Closing as I think you misunderstood the stats.

Then, if you really found an issue, please provide a reproducer we can action on our side.",False,0,MEMBER
https://api.github.com/repos/gatling/gatling/issues/comments/394440210,Incorrect graph data for Active Users over a long time period,LilSebastian5000,5,329086591,3,394440210,0,394438024,2018-06-04T17:46:41Z,"@slandelle I see the number of injected users in the statistics chart that shows 3274 users with OK status.

When looking at the Active Users graph, it shows 1 user under ""All Users"" when hovering over the peaks. However, if I halt the script early after maybe 5 minutes, it shows 5 users under ""All Users"" when hovering over each of the peaks. 

Why would this information differ depending on when the script is halted, then? What am I misunderstanding between these two graphs?

![1 user_3200reqs](https://user-images.githubusercontent.com/5996311/40933195-c9d8b43a-67fe-11e8-80fb-0a2ad58ca46a.png)
![5 user_100reqs](https://user-images.githubusercontent.com/5996311/40933196-c9e9a664-67fe-11e8-9450-c5d8067ef7d2.png)

",False,0,NONE
https://api.github.com/repos/gatling/gatling/issues/comments/394443404,Incorrect graph data for Active Users over a long time period,slandelle,5,329086591,4,394443404,0,394440210,2018-06-04T17:56:45Z,">  I see the number of injected users in the statistics chart that shows 3274 users with OK status.

OK, so the stats in the table are, as column header states, **Requests**, not users.",False,0,MEMBER
https://api.github.com/repos/gatling/gatling/issues/comments/394444685,Incorrect graph data for Active Users over a long time period,LilSebastian5000,5,329086591,5,394444685,0,394443404,2018-06-04T18:01:00Z,"@slandelle Okay thank you, got it. But why would the graph itself not show 5 users being ramped up at once, unless I halt it early? That doesn't seem like a bug, based on the code I gave in the initial post?

Regardless of when the script's execution ends, I'd think the ramped users should be the same...",False,0,NONE
https://api.github.com/repos/gatling/gatling/issues/comments/394446499,Incorrect graph data for Active Users over a long time period,slandelle,5,329086591,6,394446499,0,394444685,2018-06-04T18:07:10Z,"> But why would the graph itself not show 5 users being ramped up at once, unless I halt it early?

Because this stats is not ""User arrival rate"" (available in FrontLine btw), but ""Active users"", which is computed as:
```
number_of_users_alive_bucket(n)
- number_of_users_alive_bucket(n-1)
- number_of_users_dead_in_bucket(n-1)
```

The larger the time windows, the larger the buckets (IIRC, we compute 1000 plots by default), which can cause variations.",False,0,MEMBER
https://api.github.com/repos/mrdoob/three.js/issues/14405,Refraction with custom geometry,CesarVonc,8,337285194,1,337285194,0,0,2018-07-01T11:51:44Z,"##### Description of the problem

Hello,

I noticed an issue with the Refraction example :

https://threejs.org/examples/?q=refr#webgl_refraction

If I change the plane by a box and rotate it, some times the shader show weird things :

![image](https://i.imgur.com/rPdvldj.gif)


Modifications of the example :

Line 81 :
`var refractorGeometry = new THREE.BoxBufferGeometry( 4, 4, 4 );`

	function render() { 

		refractor.material.uniforms.time.value += clock.getDelta();
	
		refractor.rotation.y += 0.02;
	
		renderer.render( scene, camera );

	}


##### Three.js version

- [x] r94

##### Browser

- [x] All of them

##### OS

- [x] All of them
",True,0,NONE
https://api.github.com/repos/mrdoob/three.js/issues/comments/401617968,Refraction with custom geometry,Mugen87,8,337285194,2,401617968,0,337285194,2018-07-01T16:38:42Z,`Reflector` and `Refractor` are intended to be used with a planar geometry.,False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/401819579,Refraction with custom geometry,WestLangley,8,337285194,3,401819579,0,401617968,2018-07-02T14:15:10Z,">Reflector and Refractor are intended to be used with PlaneGeometry.

Actually, in `webgl_mirror.html`, a `CircleBufferGeometry` is used.",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/401895455,Refraction with custom geometry,Mugen87,8,337285194,4,401895455,0,401819579,2018-07-02T18:36:32Z,@mrdoob Should I correct your edit? 😉 ,False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/401913353,Refraction with custom geometry,WestLangley,8,337285194,5,401913353,0,401895455,2018-07-02T19:46:22Z,"You can also use an arbitrary shape:
```javascript
var shape = new THREE.Shape( points );
var geometry = new THREE.ShapeBufferGeometry( shape );
```",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/401916923,Refraction with custom geometry,CesarVonc,8,337285194,6,401916923,0,401913353,2018-07-02T20:01:15Z,"I noticed that all kind of geometry seems to work if we keep the camera looking at the Z object axis.

Might be a nice feature to have it working for all point of view ?

I tried to fix it, but I don't really understang how it works, especially with the refractorPlane thing.",False,0,NONE
https://api.github.com/repos/mrdoob/three.js/issues/comments/402048295,Refraction with custom geometry,mrdoob,8,337285194,7,402048295,0,401916923,2018-07-03T07:59:50Z,"> @mrdoob Should I correct your edit? 😉

Hehe, ops! I tried to make it more clear. I should have said `PlaneGeometry`, `CircleGeometry`, `ShapeGeometry`, ...",False,0,OWNER
https://api.github.com/repos/mrdoob/three.js/issues/comments/402050452,Refraction with custom geometry,mrdoob,8,337285194,8,402050452,0,402048295,2018-07-03T08:07:56Z,"> I noticed that all kind of geometry seems to work if we keep the camera looking at the Z object axis.
>
> Might be a nice feature to have it working for all point of view ?

@Mugen87 Have you investigated this?",False,0,OWNER
https://api.github.com/repos/mrdoob/three.js/issues/comments/402079730,Refraction with custom geometry,Mugen87,8,337285194,9,402079730,0,402050452,2018-07-03T09:37:57Z,The algorithm of `Reflector` and `Refractor` assumes there is a single reflection/refraction plane. I think you need a different approach if you want to support an arbitrary amount of planes defined by a group of planar polygon faces.,False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/14406,lights_pars_maps -> envmap_physical_pars_fragment,WestLangley,3,337370653,1,337370653,0,0,2018-07-02T05:00:59Z,"`lights_pars_maps` is environment mapping code specific to the physical fragment shader.

Also reordered the chunks a bit.",True,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/401673426,lights_pars_maps -> envmap_physical_pars_fragment,WestLangley,3,337370653,2,401673426,0,337370653,2018-07-02T05:04:47Z,"/ping @sunag 
",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/403345052,lights_pars_maps -> envmap_physical_pars_fragment,WestLangley,3,337370653,3,403345052,0,401673426,2018-07-09T02:49:30Z,I think this can be merged. @sunag is aware and can update Node accordingly.,False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/403664379,lights_pars_maps -> envmap_physical_pars_fragment,mrdoob,3,337370653,4,403664379,0,403345052,2018-07-10T00:52:26Z,Thanks!,False,0,OWNER
https://api.github.com/repos/mrdoob/three.js/issues/14408,GLTFLoader: Ensure LoadingManager onLoad is supported.,donmccurdy,4,337557052,1,337557052,0,0,2018-07-02T15:06:17Z,"Fixes #14256.

/cc @takahirox ",True,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/408890021,GLTFLoader: Ensure LoadingManager onLoad is supported.,donmccurdy,4,337557052,2,408890021,0,337557052,2018-07-30T14:48:21Z,@takahirox any concerns on this? 😇,False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/411964213,GLTFLoader: Ensure LoadingManager onLoad is supported.,donmccurdy,4,337557052,3,411964213,0,408890021,2018-08-10T03:23:56Z,"Updated to track using the same URL, and added a comment explaining the reason for this.",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/416839119,GLTFLoader: Ensure LoadingManager onLoad is supported.,mrdoob,4,337557052,4,416839119,0,411964213,2018-08-29T06:25:44Z,"Ops, sorry.",False,0,OWNER
https://api.github.com/repos/mrdoob/three.js/issues/comments/416839182,GLTFLoader: Ensure LoadingManager onLoad is supported.,mrdoob,4,337557052,5,416839182,0,416839119,2018-08-29T06:26:02Z,Thanks!,False,0,OWNER
https://api.github.com/repos/mrdoob/three.js/issues/14411,WebGLRenderer: Removed WebGLSpriteRenderer,Mugen87,10,337822219,1,337822219,0,0,2018-07-03T09:44:02Z,"This is a first attempt to remove `WebGLSpriteRenderer` and integrate sprite rendering in `WebGLRenderer`.  Right now, `WebGLSpriteRenderer` does not support `ArrayCamera` and many other performance features (like uniform caching) of `WebGLRenderer`. Besides, the sprite material does not use any shader chunks from `three.js` shader lib. The PR should solve all this problems.

Should also fix #13073",True,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/402083739,WebGLRenderer: Removed WebGLSpriteRenderer,Mugen87,10,337822219,2,402083739,0,337822219,2018-07-03T09:49:09Z,Not sure if the shader programs are okay like that. We might want to remove/add certain chunks...,False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/402099094,WebGLRenderer: Removed WebGLSpriteRenderer,WestLangley,10,337822219,3,402099094,0,402083739,2018-07-03T10:30:44Z,">Not sure if the shader programs are okay like that. We might want to remove/add certain chunks...

I think we can worry about that later.

This is looking pretty good to me.
",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/402106393,WebGLRenderer: Removed WebGLSpriteRenderer,WestLangley,10,337822219,4,402106393,0,402099094,2018-07-03T10:50:05Z,"I would not change it in this PR, but sprites are still rendered last -- even though they may, or may not, be transparent.

Is there a downside to rendering sprites along with the other transparent and opaque objects? Or would the use of sprite atlases make that approach too inefficient?

Maybe a solution is to continue to render sprites as a group, but have `opaqueSprites` and `transparentSprites` as separate arrays.",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/402119888,WebGLRenderer: Removed WebGLSpriteRenderer,Mugen87,10,337822219,5,402119888,0,402106393,2018-07-03T11:27:54Z,"> Is there a downside to rendering sprites along with the other transparent and opaque objects? Or would the use of sprite atlases make that approach too inefficient?

I think sprite objects tend to share a common or at least similar rendering state. In order to achieve less WebGL state changes and more uniform cache hits, it might easier to achieve better performance if we manage sprites in a separate rendering list.",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/402131319,WebGLRenderer: Removed WebGLSpriteRenderer,WestLangley,10,337822219,6,402131319,0,402119888,2018-07-03T12:03:58Z,">I think sprite objects tend to share a common or at least similar rendering state. In order to achieve less WebGL state changes and more uniform cache hits, it might easier to achieve better performance if we manage sprites in a separate rendering list.

Well-stated.

However, I am still inclined to think we may need to render `opaqueObjects` first, then `opaqueSprites`, then `transparentObjects`, and finally `transparentSprites`.

If so, it can wait for a later PR.

---

EDIT: Actually, `transparentObjects` and `transparentSprites` should be combined, and sorted together.",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/402147805,WebGLRenderer: Removed WebGLSpriteRenderer,Mugen87,10,337822219,7,402147805,0,402131319,2018-07-03T12:58:06Z,"The PR should also fix #13539, #6098, #5744, #5133, #14287

I would also close #7956 since it contains many issues at once. If there are open tasks after the PR is merged, I suggest to create for each task a new issue.",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/403231990,WebGLRenderer: Removed WebGLSpriteRenderer,mrdoob,10,337822219,8,403231990,0,402147805,2018-07-07T17:40:58Z,Great stuff!,False,0,OWNER
https://api.github.com/repos/mrdoob/three.js/issues/comments/403232001,WebGLRenderer: Removed WebGLSpriteRenderer,mrdoob,10,337822219,9,403232001,0,403231990,2018-07-07T17:41:09Z,Thanks!,False,0,OWNER
https://api.github.com/repos/mrdoob/three.js/issues/comments/403232941,WebGLRenderer: Removed WebGLSpriteRenderer,Mugen87,10,337822219,10,403232941,0,403232001,2018-07-07T17:57:38Z,"Yay! 🎉 

@WestLangley Thank you for triggering this change 😊 ",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/403261802,WebGLRenderer: Removed WebGLSpriteRenderer,sunag,10,337822219,11,403261802,0,403232941,2018-07-08T04:38:22Z,Very good. It seems an great opportunity for me update `sprites_nodes`,False,0,COLLABORATOR
https://api.github.com/repos/gradle/gradle/issues/5898,jacoco hard requires test.exec,fabienrenaud,15,339255201,1,339255201,0,0,2018-07-08T20:30:33Z,"### Summary

`jacocoTestReport` task fails on projects only defining custom test sets (and no ""regular"" tests in src/test/java). For example, create tests in an integration-test folder (src/integration-test/java) and have no src/test/java folder. The error:
> Unable to read execution data file path/to/build/jacoco/test.exec

### Expected Behavior

Jacoco should have no hard requirements on the existence of test.exec.
Additionally, jacoco should automatically discover any *.exec files in build/jacoco and not bail when test.exec is missing.

### Current Behavior

jacocoTestReport fails processing *.exec files when test.exec is missing
jacocoTestReport needs custom configuration of the executionData attribute when test.exec does not exists. 

### Context

jacocoTestReport completely fails for projects that define integration tests but no (unit) test in src/test.
I reserve test for unit tests. integration tests always go in the integration-test folder by convention.

### Steps to Reproduce (for bugs)

Full and simple repro: https://github.com/fabienrenaud/gradle-jacoco-notestexec

Steps:
1. Create a project, use the `org.unbroken-dome.test-sets plugin` to configure an _integration test_ directory (e.g: integration-test)
1. Don't write tests in src/test/java. Write tests in src/integration-test/java
1. Run `gradle integrationTest jacocoTestReport`. Notice jacocoTestReport did nothing.
1. Add the following config to gradle:
    ```
    jacocoTestReport {
        sourceSets sourceSets.main
        executionData fileTree(buildDir).include(""/jacoco/*.exec"")
    }
    ```
1. Run `gradle integrationTest jacocoTestReport`. Notice jacocoTestReport failing and requiring a test.exec file.

```
~ gradle jacocoTestReport
> Task :jacocoTestReport FAILED

FAILURE: Build failed with an exception.

* What went wrong:
Execution failed for task ':jacocoTestReport'.
> Unable to read execution data file /Users/frenaud/projects/me/gradle-jacoco-notestexec/build/jacoco/test.exec
```

### Your Environment

```
------------------------------------------------------------
Gradle 4.8.1
------------------------------------------------------------

Build time:   2018-06-21 07:53:06 UTC
Revision:     0abdea078047b12df42e7750ccba34d69b516a22

Groovy:       2.4.12
Ant:          Apache Ant(TM) version 1.9.11 compiled on March 23 2018
JVM:          1.8.0_131 (Oracle Corporation 25.131-b11)
OS:           Mac OS X 10.12.6 x86_64
```",True,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/403461796,jacoco hard requires test.exec,marcphilipp,15,339255201,2,403461796,0,339255201,2018-07-09T12:27:59Z,"The JaCoCo plugin creates the `jacocoTestReport` task and wires it to the default `test` task. I know it's not obvious, but calling [`executionData(Object...)`](https://docs.gradle.org/current/javadoc/org/gradle/testing/jacoco/tasks/JacocoReportBase.html#executionData-java.lang.Object...-) adds files to the default `FileCollection` which already contains `test.exec`.

Calling `setExectionData(FileCollection)` avoids this issue (note the `=`):

```gradle
jacocoTestReport {
    sourceSets sourceSets.main
    executionData = fileTree(buildDir).include(""/jacoco/*.exec"")
}
```",False,0,CONTRIBUTOR
https://api.github.com/repos/gradle/gradle/issues/comments/403513947,jacoco hard requires test.exec,fabienrenaud,15,339255201,3,403513947,0,403461796,2018-07-09T15:13:03Z,"Even if it wires to the default test task:
 * why failing jacocoTestReport if test.exec is missing? isn't there a state from the test task jacoco could read to check there are no tests for the test task?
 * why not wiring automatically to all tasks of Test type?
 * why wiring to any task of Test type at all? why not just reading all *.exec files in build/jacoco/ ?",False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/403803307,jacoco hard requires test.exec,marcphilipp,15,339255201,4,403803307,0,403513947,2018-07-10T12:24:50Z,"> why failing jacocoTestReport if test.exec is missing? isn't there a state from the test task jacoco could read to check there are no tests for the test task?

It already has a `onlyIf` condition to only run if any of the configured `executionData` files exists:
https://github.com/gradle/gradle/blob/4f0dbbf637ae2c726714f0a6474b7b1be8f82409/subprojects/jacoco/src/main/java/org/gradle/testing/jacoco/tasks/JacocoReportBase.java#L58-L70

Thus, given the default configuration, without tests it will be skipped:

```
./gradlew --console=verbose integrationTest jacocoTestReport
> Task :compileJava UP-TO-DATE
> Task :processResources NO-SOURCE
> Task :classes UP-TO-DATE
> Task :compileIntegrationTestJava UP-TO-DATE
> Task :processIntegrationTestResources NO-SOURCE
> Task :integrationTestClasses UP-TO-DATE
> Task :integrationTest UP-TO-DATE
> Task :jacocoTestReport SKIPPED

BUILD SUCCESSFUL in 0s
3 actionable tasks: 3 up-to-date
```

It will only fail, if you configure `test.exec` and `integrationTest.exec` as `executionData`.

> why not wiring automatically to all tasks of Test type?

We could theoretically create a `jacoco${capitalize(task.name)}Report` task for every `Test` task. However, that's rarely what users want. Usually, but not always, they want a report of the aggregated coverage of multiple tasks.

> why wiring to any task of Test type at all? why not just reading all *.exec files in build/jacoco/ ?

IMHO such a catch all report is not a sensible default for most users. However, Gradle makes it really easy to define a custom task for it in your own buildscript where you know more about what things get executed with JaCoCo.",False,0,CONTRIBUTOR
https://api.github.com/repos/gradle/gradle/issues/comments/487404911,jacoco hard requires test.exec,liorhar,15,339255201,5,487404911,0,403803307,2019-04-28T18:41:26Z,"I believe I run into the same issue. I'm trying to split the DB tests from the main test task. I added a `dbTest` task and jacoco generates dbTest.exec file successfully. I configured the `executionData` property to include `*.exec` files. However, when running `gradle dbTest jacocoTestReport` it will fail on the missing `test.exec` file.
Is there a way to generate the jacoco report for an alternate test task without running the main test task?",False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/494230499,jacoco hard requires test.exec,arvindn05,15,339255201,6,494230499,0,487404911,2019-05-21T03:59:39Z,"Doings the following worked for me. Note the '=' like mentioned above.
Basically i include both test and integration test data by default and while generating the report i filter the execution data to only pick coverage files which exist.
```
subprojects {
    jacocoTestReport {
        executionData(test, integrationTest)
    }
}

def allTestCoverageFile = ""$buildDir/jacoco/allTestCoverage.exec""
task jacocoMergeTestData(type: JacocoMerge) {
    destinationFile = file(""$buildDir/jacoco/testCombo.exec"")
    executionData = files(subprojects.jacocoTestReport.executionData).filter { f -> f.exists() }
}
task jacocoRootReport(type: JacocoReport) {
    dependsOn jacocoMergeTestData
    description = 'Generates an aggregate report from all subprojects'

    additionalSourceDirs = files(subprojects.sourceSets.main.allSource.srcDirs)
    sourceDirectories = files(subprojects.sourceSets.main.allSource.srcDirs)
    classDirectories = files(subprojects.sourceSets.main.output)
    executionData = files(subprojects.jacocoTestReport.executionData).filter { f -> f.exists() }
    
    reports {
        xml.enabled = false
        html.enabled = true
    }
}
```
Hope this helps :)",False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/546896042,jacoco hard requires test.exec,ghilainm,15,339255201,7,546896042,0,494230499,2019-10-28T11:01:25Z,"This does not work anymore in Gradle 6.0. This is forbidden to override executionData. 

> The JacocoReportBase.setExecutionData(FileCollection) method has been deprecated. This is scheduled to be removed in Gradle 6.0. Use getExecutionData().from(...)

What is the recommended way of overriding execution data then?",False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/554600486,jacoco hard requires test.exec,RothAndrew,15,339255201,8,554600486,0,546896042,2019-11-16T03:41:32Z,"@ghilainm 

> What is the recommended way of overriding execution data then?

```
jacocoTestReport {
    getExecutionData().setFrom(fileTree(buildDir).include(""/jacoco/*.exec""))
}
```",False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/563410722,jacoco hard requires test.exec,wujek-srujek,15,339255201,9,563410722,0,554600486,2019-12-09T20:02:04Z,"I have recently been hit by this issue, and dug deeper (the workaround didn't work for me immediately as our project structure is a bit more complex than the example) and found out that the Test Sets plugin creates a JacocoReport task for each new source set. Each such new task uses its own *.exec file as input from the corresponding custom Test tasks, and generates its own report. (the reports use inconsistent destination file/folder naming, see https://github.com/unbroken-dome/gradle-testsets-plugin/issues/100).
This knowledge helped me understand what is going on and implement a solution working for our project.",False,0,CONTRIBUTOR
https://api.github.com/repos/gradle/gradle/issues/comments/592062930,jacoco hard requires test.exec,yuvalprtn,15,339255201,10,592062930,0,563410722,2020-02-27T16:52:14Z,@wujek-srujek  can you share the solution?,False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/592109641,jacoco hard requires test.exec,wujek-srujek,15,339255201,11,592109641,0,592062930,2020-02-27T18:32:02Z,"
Yes. Our project is a multimodule project. Here are the most relevant parts, in Kotlin DLS:

gradle.build.kts:

    apply(plugin = ""jacoco"")

    val aggregateJacocoTestReport = tasks.create(""aggregateJacocoTestReport"", JacocoReport::class) {
        executionData.setFrom(fileTree(projectDir).include(""**/*.exec""))
        // will further be configured by subprojects loop
    }

    tasks.create(""build"") {
        dependsOn(aggregateJacocoTestReport)
    }

    subprojects notLeaf@{
        // apply the configuration to leaf modules only, i.e. not 'grouping' folders
        if (subprojects.size > 0) {
            return@notLeaf
        }

        apply(plugin = ""jacoco"")
        apply(plugin = ""org.unbroken-dome.test-sets"")

        configure<TestSetContainer> {
            ""integrationTest""()
        }

        val check by tasks
        val build by tasks

        tasks.withType<Test> {
            useJUnitPlatform()
            check.dependsOn(this)
        }

        // all test tasks have their own JaCoCo report, so let's create one that aggregates them
        val jacocoAllTestReport = tasks.create(""jacocoAllTestReport"", JacocoReport::class) {
            executionData.setFrom(fileTree(buildDir).include(""**/*.exec""))
        }

        // add current project's production source set to the custom JaCoCo report tasks
        // jacocoAllTestReport gets the source set from the project it's in
        // aggregateJacocoTestReport gets all production source sets
        project.configure<SourceSetContainer> {
            val mainSourceSet = getByName(SourceSet.MAIN_SOURCE_SET_NAME)
            jacocoAllTestReport.sourceSets(mainSourceSet)
            aggregateJacocoTestReport.sourceSets(mainSourceSet)
        }

        jacocoAllTestReport.dependsOn(check)
        build.dependsOn(jacocoAllTestReport)

        aggregateJacocoTestReport.dependsOn(check)
    }

To sum up:
* We have a global custom JaCoCo report for the whole project and the custom 'build' task depends on it. This causes calls to './gradlew build' also execute the root 'build' task, which in turn executes the global report task.
* Every submodule gets a custom 'jacocoAllTestReport'. It is made dependent on the 'check' task, which in turn is dependent on all 'test' tasks (like 'integrationTest' in our case).
* The global report task gets the main source set from each module, and is made dependent on each submodule's 'check'.
* When we want coverage report for a module, we call its 'jacocoAllTestReport' task. We can still the other tasks if we need a report for each test source set separately, be we normally don't need it.",False,0,CONTRIBUTOR
https://api.github.com/repos/gradle/gradle/issues/comments/597463105,jacoco hard requires test.exec,ashwini-desai,15,339255201,12,597463105,0,592109641,2020-03-11T06:18:14Z,"Our's is also a multi-module gradle project with integration tests in one of them. We ran into the same problem of not being able to merge ```**/jacoco/test.exec``` files. 

Solution below worked for us:
```
subprojects {
    apply(plugin: 'org.jetbrains.kotlin.jvm')

    repositories {
        jcenter()
        mavenCentral()
   }
}

task codeCoverageReport(type: JacocoReport) {

    // Gather execution data from all subprojects
    executionData fileTree(project.rootDir.absolutePath).include(""**/build/jacoco/*.exec"")

    // Add all relevant sourcesets from the subprojects
    subprojects.each {
        sourceSets it.sourceSets.main
    }

    reports {
        xml.enabled true
        html.enabled true
        csv.enabled false
    }
}

// always run the tests before generating the report
codeCoverageReport.dependsOn {
    subprojects*.test
}
```

Run ```gradle codeCoverageReport```.  We tried making available all source-sets to the integration test module in many ways but nothing other than the above solution worked. To make available sourcesets of all modules, looping over subprojects and accumulating sourcesets worked. **subprojects.sourceSets.main.allSource.srcDirs** did not work.",False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/749153615,jacoco hard requires test.exec,ddsultan,15,339255201,13,749153615,0,597463105,2020-12-21T19:24:11Z,"> The JaCoCo plugin creates the `jacocoTestReport` task and wires it to the default `test` task. I know it's not obvious, but calling [`executionData(Object...)`](https://docs.gradle.org/current/javadoc/org/gradle/testing/jacoco/tasks/JacocoReportBase.html#executionData-java.lang.Object...-) adds files to the default `FileCollection` which already contains `test.exec`.
> 
> Calling `setExectionData(FileCollection)` avoids this issue (note the `=`):
> 
> ```groovy-gradle
> jacocoTestReport {
>     sourceSets sourceSets.main
>     executionData = fileTree(buildDir).include(""/jacoco/*.exec"")
> }
> ```

I am getting the following error with `gradle 6.1` and `jacoco  0.8.5`:

```bash
Cannot set the value of read-only property 'executionData' for task ':jacocoTestReport'
```",False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/760584176,jacoco hard requires test.exec,JMartinetti20,15,339255201,14,760584176,0,749153615,2021-01-15T01:28:48Z,"> > The JaCoCo plugin creates the `jacocoTestReport` task and wires it to the default `test` task. I know it's not obvious, but calling [`executionData(Object...)`](https://docs.gradle.org/current/javadoc/org/gradle/testing/jacoco/tasks/JacocoReportBase.html#executionData-java.lang.Object...-) adds files to the default `FileCollection` which already contains `test.exec`.
> > Calling `setExectionData(FileCollection)` avoids this issue (note the `=`):
> > ```
> > jacocoTestReport {
> >     sourceSets sourceSets.main
> >     executionData = fileTree(buildDir).include(""/jacoco/*.exec"")
> > }
> > ```
> 
> I am getting the following error with `gradle 6.1` and `jacoco 0.8.5`:
> 
> ```shell
> Cannot set the value of read-only property 'executionData' for task ':jacocoTestReport'
> ```

This was answered in the thread:



> @ghilainm
> 
> > What is the recommended way of overriding execution data then?
> 
> ```
> jacocoTestReport {
>     getExecutionData().setFrom(fileTree(buildDir).include(""/jacoco/*.exec""))
> }
> ```

This is working for me now and my multi-test gradle project.",False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/1102774543,jacoco hard requires test.exec,hpatel123,15,339255201,15,1102774543,0,760584176,2022-04-19T15:12:42Z,@ashwini-desai I would request you to provide whole code base for jacoco as I'm trying to fix but nothing works for me.,False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/1108157501,jacoco hard requires test.exec,pa1maurya,15,339255201,16,1108157501,0,1102774543,2022-04-25T07:09:08Z,@hpatel123 is your error fixed ? Its not solved for me as well,False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/5908,LinkageError when compiling Groovy code using custom BytecodeExpression in AST Transformation,leonard84,6,339456108,1,339456108,0,0,2018-07-09T13:45:39Z,"<!--- 
Please follow the instructions below. We receive dozens of issues every week, so to stay productive, we will close issues that don't provide enough information. 

Please open Android-related issues on the Android Issue Tracker at https://source.android.com/source/report-bugs
Please open Kotlin DSL-related issues at https://github.com/gradle/kotlin-dsl/issues
Please open Gradle Native-related issues at https://github.com/gradle/gradle-native/issues
-->

<!--- Provide a brief summary of the issue in the title above -->
## Summary

When using this custom `BytecodeExpression` 
```java
import groovyjarjarasm.asm.*;
import org.codehaus.groovy.ast.ClassHelper;
import org.codehaus.groovy.classgen.BytecodeExpression;

class ClosureReferenceExpression extends BytecodeExpression {

  ClosureReferenceExpression() {super(ClassHelper.CLOSURE_TYPE);}

  @Override
  public void visit(MethodVisitor methodVisitor) {
    methodVisitor.visitVarInsn(Opcodes.ALOAD,0);
  }
}
```
in an AST transformation, the compilation fails with `java.lang.LinkageError: loader constraint violation: loader (instance of groovy/lang/GroovyClassLoader) previously initiated loading for a different type with name ""groovyjarjarasm/asm/MethodVisitor""`. I checked with the `dependencies` task that only a single groovy version is present.

### Expected Behavior
<!--- If you're describing a bug, tell us what should happen -->
<!--- If you're suggesting a change/improvement, tell us how it should work -->
It should compile without issue.

Using IntelliJ to compile and run the tests works without issue.

### Current Behavior
<!--- If describing a bug, tell us what happens instead of the expected behavior -->
<!--- If suggesting a change/improvement, explain the difference from current behavior -->
Can be seen here https://travis-ci.org/spockframework/spock/builds/401275894

### Context
<!--- How has this issue affected you? What are you trying to accomplish? -->
<!--- Providing context helps us come up with a solution that is most useful in the real world -->
Currently Spock uses a hacky workaround to get a reference to the current closure. This `BytecodeExpression` is the clean way to get it.

See also http://groovy.329449.n5.nabble.com/Get-reference-to-enclosing-closure-td5744668.html

### Steps to Reproduce (for bugs)
<!--- Provide a self-contained example project (as an attached archive or a Github project). -->
<!--- In the rare cases where this is infeasible, we will also accept a detailed set of instructions. -->
Checkout https://github.com/spockframework/spock/commit/e78bd761b92c7ab82588a1166611fc6ce692ac01 and run `./gradlew build`

### Your Environment
<!--- Include as many relevant details about the environment you experienced the bug in -->
<!--- A build scan `https://scans.gradle.com/get-started` is ideal -->
 * Build scan URL: 
    * https://gradle.com/s/hkcz2bqu2wiyo 
    * https://gradle.com/s/xvlzrvggytga2 
    * https://gradle.com/s/tkis2ojpbzq5m 
    * https://gradle.com/s/d4cnkpxxhsyvs
",True,0,MEMBER
https://api.github.com/repos/gradle/gradle/issues/comments/403507241,LinkageError when compiling Groovy code using custom BytecodeExpression in AST Transformation,marcphilipp,6,339456108,2,403507241,0,339456108,2018-07-09T14:54:10Z,"Looks like a Groovy issue after looking at it briefly.

@melix Do you have time to take a look?",False,0,CONTRIBUTOR
https://api.github.com/repos/gradle/gradle/issues/comments/403509279,LinkageError when compiling Groovy code using custom BytecodeExpression in AST Transformation,melix,6,339456108,3,403509279,0,403507241,2018-07-09T14:59:44Z,"There are chances that it's a problem in classloading isolation of the Groovy runtime in Gradle. We have some magic to hide the groovy classes, but I'm not sure they hide things starting with `groovyjarajar`",False,0,CONTRIBUTOR
https://api.github.com/repos/gradle/gradle/issues/comments/403788027,LinkageError when compiling Groovy code using custom BytecodeExpression in AST Transformation,leonard84,6,339456108,4,403788027,0,403509279,2018-07-10T11:18:12Z,@melix so no easy fix then?,False,0,MEMBER
https://api.github.com/repos/gradle/gradle/issues/comments/403793043,LinkageError when compiling Groovy code using custom BytecodeExpression in AST Transformation,melix,6,339456108,5,403793043,0,403788027,2018-07-10T11:41:06Z,Not without deeper investigation.,False,0,CONTRIBUTOR
https://api.github.com/repos/gradle/gradle/issues/comments/669336838,LinkageError when compiling Groovy code using custom BytecodeExpression in AST Transformation,stale[bot],6,339456108,6,669336838,0,403793043,2020-08-05T17:51:47Z,"This issue has been automatically marked as stale because it has not had recent activity. Given the limited bandwidth of the team, it will be automatically closed if no further activity occurs. If you're interested in how we try to keep the backlog in a healthy state, please read our [blog post on how we refine our backlog](https://blog.gradle.org/stale-issue-backlog). If you feel this is something you could contribute, please have a look at our [Contributor Guide](https://github.com/gradle/gradle/blob/master/CONTRIBUTING.md). Thank you for your contribution.
",False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/672041649,LinkageError when compiling Groovy code using custom BytecodeExpression in AST Transformation,leonard84,6,339456108,7,672041649,0,669336838,2020-08-11T15:57:05Z,"This seems to have been fixed by the PR, thx.",False,0,MEMBER
https://api.github.com/repos/gradle/gradle/issues/5912,feature: dependency lock workflows,xenoterracide,4,339558213,1,339558213,0,0,2018-07-09T18:26:15Z,"Started looking at the dependency locking and thinking about how I want to use it... what occurs to me is that I'm looking at it for solving 2 problems, but I need it to stay out of the way as number 3 & 4.

1. repeatable release builds
1. documenting versions at time of build
1. detect backwards upstream incompatibilities ASAP
1. ensure that the defined required range of deps does in fact work throughout (e.g. 1.+ means, 1.0, 1.1, 1.0.9, 1.2.3 all have to work, currently I don't see any nice way to do this currently.

This list, I believe satifsies my ""Acceptance Criteria"", and is indeed important for libraries

I think this can mainly be achieved by running `gradle --write-locks build` every time gradle is run... though the problem I see is remembering it. This makes me wonder if it's possible to tell gradle to always do this instead of simply having it be an option... Though then comes the problem of how does one get CI to commit back... which is another issue... problems with this are fairly simple.

I question though, whether with 3, simply doing `--write-locks` is the right answer, vs say doing an `--unlock` or `--ignore-locks`, I originally thought of just committing new deps with the release, and then immediately blowing them away.

with 4,  you would need a ""random in range"" dependency version resolver, to allow fuzz testing what gradle considers to be a valid version (this is another feature I'd like to see added and can open an issue), however the only way I could see this working is with an `--ignore-locks` feature, where if toggled the locks will not be taken into account during that run, and normal resolution would apply.
",True,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/417252823,feature: dependency lock workflows,ljacomet,4,339558213,2,417252823,0,339558213,2018-08-30T09:26:02Z,"Regarding 3, the idea of having a way to ignore dependency lock state has been discussed but no work happened yet. Right now, it feels like we are missing solid use cases for it.
In this specific example, and because I assume that detection would happen on CI, something like `--update-locks *:*` should do the trick.",False,0,MEMBER
https://api.github.com/repos/gradle/gradle/issues/comments/727222484,feature: dependency lock workflows,xenoterracide,4,339558213,3,727222484,0,417252823,2020-11-14T15:23:07Z,still would like to see this,False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/1076504772,feature: dependency lock workflows,stale[bot],4,339558213,4,1076504772,0,727222484,2022-03-23T15:50:23Z,"This issue has been automatically marked as stale because it has not had recent activity. Given the limited bandwidth of the team, it will be automatically closed if no further activity occurs. If you're interested in how we try to keep the backlog in a healthy state, please read our [blog post on how we refine our backlog](https://blog.gradle.org/stale-issue-backlog). If you feel this is something you could contribute, please have a look at our [Contributor Guide](https://github.com/gradle/gradle/blob/master/CONTRIBUTING.md). Thank you for your contribution.
",False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/1101960496,feature: dependency lock workflows,stale[bot],4,339558213,5,1101960496,0,1076504772,2022-04-19T03:38:30Z,"This issue has been automatically closed due to inactivity. If you can reproduce this on a recent version of Gradle or if you have a good use case for this feature, please feel free to to let know so we can reopen the issue. Please try to provide steps to reproduce, a quick explanation of your use case or a high-quality pull request.
",False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/5914,Received complete event for an unknown operation in 4.8-RC1,aj-jaswanth,11,339685573,1,339685573,0,0,2018-07-10T04:05:33Z,"<!--- 
Please follow the instructions below. We receive dozens of issues every week, so to stay productive, we will close issues that don't provide enough information. 

Please open Android-related issues on the Android Issue Tracker at https://source.android.com/source/report-bugs
Please open Kotlin DSL-related issues at https://github.com/gradle/kotlin-dsl/issues
Please open Gradle Native-related issues at https://github.com/gradle/gradle-native/issues
-->

<!--- Provide a brief summary of the issue in the title above -->
After upgrading from `4.7` to `4.8.1` gradle throws `Received complete event for an unknown operation` error and stops.
### Expected Behavior
<!--- If you're describing a bug, tell us what should happen -->
Gradle build should succeed in running all tasks.
<!--- If you're suggesting a change/improvement, tell us how it should work -->

### Current Behavior
<!--- If describing a bug, tell us what happens instead of the expected behavior -->
The error is thrown irrespective of parallel builds or running the daemon.
<!--- If suggesting a change/improvement, explain the difference from current behavior -->

### Context
<!--- How has this issue affected you? What are you trying to accomplish? -->
I have a reproducible sample at https://gist.github.com/aj-jaswanth/de1f847da7a36ead9d58106a6a3c6ff3. Run using `gradle -b blah.gradle runThis`.
This doesn't happen almost always, please try running multiple times.
<!--- Providing context helps us come up with a solution that is most useful in the real world -->
The issue is not present in version `4.7` but is present in `4.8-RC1`. After doing a bisect I found that the above error started at the commit `https://github.com/gradle/gradle/commit/f18da336e9aae1a68594b7f56e32da6cccbb0eb9`.
### Your Environment
<!--- Include as many relevant details about the environment you experienced the bug in -->
<!--- A build scan `https://scans.gradle.com/get-started` is ideal -->
I am using macOS 10.13.5, java 1.8.0_162.",True,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/403707481,Received complete event for an unknown operation in 4.8-RC1,ldaley,11,339685573,2,403707481,0,339685573,2018-07-10T05:46:16Z,/cc @wolfs ,False,0,MEMBER
https://api.github.com/repos/gradle/gradle/issues/comments/403752108,Received complete event for an unknown operation in 4.8-RC1,lptr,11,339685573,3,403752108,0,403707481,2018-07-10T09:00:40Z,/cc @gradle/build-cache ,False,0,MEMBER
https://api.github.com/repos/gradle/gradle/issues/comments/403763852,Received complete event for an unknown operation in 4.8-RC1,wolfs,11,339685573,4,403763852,0,403752108,2018-07-10T09:41:37Z,"@aj-jaswanth Thank you for reporting. The problem is caused by the commit you posted and your build script using `TaskInternal.execute` (even nested). Started with Gradle 4.8, we events with `Task.execute` as if Gradle would have executed the task.

Can you move away from using `TaskInternal.execute`? Looking at your code, you could use `Project.exec` directly and replace the tasks with functions. Then you wouldn't need to use `TaskInternal.execute()`. Alternatively, you can use `dependsOn` to model the relationship between the tasks. Would that work for you?

Note that `TaskInternal.execute` will be removed with Gradle 5.0.",False,0,MEMBER
https://api.github.com/repos/gradle/gradle/issues/comments/403767739,Received complete event for an unknown operation in 4.8-RC1,wolfs,11,339685573,5,403767739,0,403763852,2018-07-10T09:55:26Z,"It seems like running Gradle with `--console=plain` makes the build work. Does that fix your problem?
You can set add [this](https://docs.gradle.org/current/userguide/build_environment.html#sec:gradle_configuration_properties) to your `gradle.properties` file to use `plain` console logging as default:
```
org.gradle.console=plain
```",False,0,MEMBER
https://api.github.com/repos/gradle/gradle/issues/comments/403806401,Received complete event for an unknown operation in 4.8-RC1,aj-jaswanth,11,339685573,6,403806401,0,403767739,2018-07-10T12:36:17Z,"@wolfs Yes, plain console solves it. We'll move away from `TaskInternal.execute()`. 
Thanks for the help.",False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/404219845,Received complete event for an unknown operation in 4.8-RC1,wolfs,11,339685573,7,404219845,0,403806401,2018-07-11T15:51:48Z,I'll close this issue since there is a workaround and it is caused by using a deprecated API.,False,0,MEMBER
https://api.github.com/repos/gradle/gradle/issues/comments/404233647,Received complete event for an unknown operation in 4.8-RC1,aj-jaswanth,11,339685573,8,404233647,0,404219845,2018-07-11T16:35:35Z,Sure. I'll close it.,False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/422208010,Received complete event for an unknown operation in 4.8-RC1,marcellodesales,11,339685573,9,422208010,0,404233647,2018-09-17T23:53:01Z,"@wolfs I'm getting this on `Gradle 4.10.1` release... :( 
@aj-jaswanth Have you tried with latest Gradle?",False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/422272483,Received complete event for an unknown operation in 4.8-RC1,wolfs,11,339685573,10,422272483,0,422208010,2018-09-18T06:36:11Z,"@marcellodesales Does it work if you use `--console=plain` (i.e. the workaround described above)? Can you describe your use-case for using `Task.execute()`? Note that this method will be removed in Gradle 5.0, so you need to migrate away from it anyway.",False,0,MEMBER
https://api.github.com/repos/gradle/gradle/issues/comments/432253768,Received complete event for an unknown operation in 4.8-RC1,XeZZoR,11,339685573,11,432253768,0,422272483,2018-10-23T13:47:20Z,"I think I get this error cause of:
assemble.doLast({ copyConf.execute() })

Where copyConf:

  task copyConf(type: Copy) {
    from 'config'
    into 'build/libs/config'
    doLast {
      def props = new File(""$buildDir/libs/config/application-default.properties"")
      props.createNewFile()
      props.write ""build.version=$version\n""
      props << other_build_stuff
    }
  }

Got a multi module project. Some projects have their own configs and those call that copyConf Task after assemble. Is there a more elegant way?",False,0,NONE
https://api.github.com/repos/gradle/gradle/issues/comments/436153758,Received complete event for an unknown operation in 4.8-RC1,wolfs,11,339685573,12,436153758,0,432253768,2018-11-06T07:16:10Z,"@XeZZoR Yes, there is. Use `project.copy` directly. For questions/discussions please head over to the [forum](https://discuss.gradle.org/).",False,0,MEMBER
https://api.github.com/repos/mojolicious/mojo/issues/1223,Mojolicious does not check SSL certificates by default,jes,12,323775442,1,323775442,0,0,2018-05-16T20:31:34Z,"* Mojolicious version: 7.79
* Perl version: 5.22.1
* Operating system: Ubuntu Xenial

### Steps to reproduce the behavior
mojofetch:

```
#!/usr/bin/perl

use strict;
use warnings;

use Mojo::UserAgent;

my $url = shift or die ""usage: mojofetch URL\n"";

my $ua = Mojo::UserAgent->new();

$ua->get($url, sub {
    my ($ua, $tx) = @_;
    print $tx->res->body, ""\n"";
    exit 0;
});

Mojo::IOLoop->start;
```

### Expected behavior

`./mojofetch https://expired.badssl.com/` should not return the content of the page and should trigger some sort of error, because the certificate is expired. Similar applies for self-signed.badssl.com, wrong.host.badssl.com etc., see the list on https://badssl.com/ for more test cases.

### Actual behavior

`./mojofetch https://expired.badssl.com/` does return the content of the page, and doesn't print any errors or warnings.

### More

I looked in `Mojo::IOLoop::TLS` and it appears as though the `_expand` function is responsible for this problem. In the event that something inside Mojolicious doesn't explicitly set `tls_*` options, `_expand` defaults them all to off and no verification. This even overrides `IO::Socket::SSL`'s defaults. Even if you set defaults using `IO::Socket::SSL->set_defaults`, they are overridden to the no-verification behaviour that Mojo defaults to.

This is really serious, but I don't know enough about Mojo to know the most effective way to fix it without breaking other features. Hopefully somebody else can do so.
",True,0,NONE
https://api.github.com/repos/mojolicious/mojo/issues/comments/389661622,Mojolicious does not check SSL certificates by default,kraih,12,323775442,2,389661622,0,323775442,2018-05-16T20:52:13Z,"This is something we'd consider if there was a well thought out proposal. The topic keeps coming up every now and then, but nobody ever follows up, so i wouldn't get my hopes up.",False,0,MEMBER
https://api.github.com/repos/mojolicious/mojo/issues/comments/389661921,Mojolicious does not check SSL certificates by default,jes,12,323775442,3,389661921,0,389661622,2018-05-16T20:53:16Z,"In the absence of any actual fix, I would think a good first step would be a big scary warning in all the relevant documentation.

I for one had *no idea* that Mojolicious treats certificate verification as optional.",False,0,NONE
https://api.github.com/repos/mojolicious/mojo/issues/comments/389662544,Mojolicious does not check SSL certificates by default,kraih,12,323775442,4,389662544,0,389661921,2018-05-16T20:55:36Z,"Note that this is not considered a bug, we depend on the current defaults for built-in HTTPS/WSS testing. Any proposal would not be a ""fix"", but merely a change in default behaviour.",False,0,MEMBER
https://api.github.com/repos/mojolicious/mojo/issues/comments/389664226,Mojolicious does not check SSL certificates by default,jes,12,323775442,5,389664226,0,389662544,2018-05-16T21:01:03Z,"I strongly urge you to reconsider.

This insecure-by-default policy is causing real people to write real software that is vulnerable to MITM attacks, while they have no idea about it because it's not documented, just to make built-in HTTPS testing easier?

I also contend that where the defaults are so obviously broken, a change in the defaults is required.

IO::Socket::SSL went through a similar change a few years ago. The default verify mode used to be SSL_VERIFY_NONE, and then for many years it would print a big scary warning (which, incidentally, Mojolicious disables by setting the verify mode *explicitly* to SSL_VERIFY_NONE), and now the default mode is SSL_VERIFY_PEER, as it should be.

All Mojolicious needs to do to do the correct thing (on modern IO::Socket::SSL, at least) is not disable the IO::Socket::SSL defaults.",False,0,NONE
https://api.github.com/repos/mojolicious/mojo/issues/comments/389665458,Mojolicious does not check SSL certificates by default,kraih,12,323775442,6,389665458,0,389664226,2018-05-16T21:05:29Z,"Don't get me wrong, i'm just telling why it is the way it is right now. Not that i want it to be that way. If you know how to improve the situation, then please, by all means, get involved and send us pull requests!",False,0,MEMBER
https://api.github.com/repos/mojolicious/mojo/issues/comments/389668107,Mojolicious does not check SSL certificates by default,jberger,12,323775442,7,389668107,0,389665458,2018-05-16T21:15:04Z,"Even if we wanted to flip the default to SSL_VERIFY_PEER, we'd need a way to disable it again, both for our testing and for clients who use mojo against say self-signed certs. This means that any change will need a full proposal with new pass through arguments to IO::Socket::SSL (and at several levels I suspect). There could also be knock-on breakage if cpan modules test using self-signed certs too, though I don't know how many of those there are.

N.B. ""proposal"" here is used as a specific term meaning a PR with tests and documentation as specified in our documentation.",False,0,MEMBER
https://api.github.com/repos/mojolicious/mojo/issues/comments/389668617,Mojolicious does not check SSL certificates by default,shadowcat-mst,12,323775442,8,389668617,0,389668107,2018-05-16T21:16:54Z,"> I also contend that where the defaults are so obviously broken, a change in the defaults is required.

Then please make a proposal as to what to do instead - remembering that it's entirely possible that within people's infrastructure many users likely consider allowing self-signed certs to be a feature rather than a security risk.

""Obviously broken"" massively depends on the point of view - ""strict-by-default"" would seem preferable to me, but it'd need to be a strict-by-default that allows people to ask for non-strict if they want to, in an easy way.",False,0,CONTRIBUTOR
https://api.github.com/repos/mojolicious/mojo/issues/comments/389669591,Mojolicious does not check SSL certificates by default,jes,12,323775442,9,389669591,0,389668617,2018-05-16T21:20:42Z,"I wholeheartedly agree that having a way to disable certificate checking is a must.

All I'm arguing for is having certificate checking enabled by default, so that if somebody just writes code in the most straightforward way possible, it is secure rather than insecure.

I also acknowledge the difficulty in transitioning from the current system to a secure-by-default system, but I am surprised that I seem to be the only one here who thinks doing so would be beneficial.

I will try to work out a good way to fix this without breaking anything else, and start a pull request.",False,0,NONE
https://api.github.com/repos/mojolicious/mojo/issues/comments/389670233,Mojolicious does not check SSL certificates by default,jberger,12,323775442,10,389670233,0,389669591,2018-05-16T21:23:08Z,"> I am surprised that I seem to be the only one here who thinks doing so would be beneficial

Please don't make assumptions of our thinking. I think if you read back you'll see that we see the value but as you say, there are difficulties.",False,0,MEMBER
https://api.github.com/repos/mojolicious/mojo/issues/comments/389670270,Mojolicious does not check SSL certificates by default,shadowcat-mst,12,323775442,11,389670270,0,389670233,2018-05-16T21:23:15Z,"> I also acknowledge the difficulty in transitioning from the current system to a secure-by-default system, but I am surprised that I seem to be the only one here who thinks doing so would be beneficial.

I have no idea why you think that's the case.

Three people, one of them the project founder, one of them a core team member, and one of them an irrelevant blowhard, have all encouraged you to make a proposal to do it and look at creating a PR, and the project founder specifically bemoaned the fact that people who care about this have not, to date, got as far as creating a PR.

That would seem to me like a pretty unanimous vote for ""this would absolutely be beneficial if we can pull it off"".",False,0,CONTRIBUTOR
https://api.github.com/repos/mojolicious/mojo/issues/comments/389670453,Mojolicious does not check SSL certificates by default,jes,12,323775442,12,389670453,0,389670270,2018-05-16T21:23:54Z,"OK, great :)

The vibe I was picking up was ""this isn't really a big deal"". Glad I was wrong.",False,0,NONE
https://api.github.com/repos/mojolicious/mojo/issues/comments/389671518,Mojolicious does not check SSL certificates by default,shadowcat-mst,12,323775442,13,389671518,0,389670453,2018-05-16T21:28:03Z,"I think everybody was more aiming for ""this would be good, but somebody needs to do it, and every time previously somebody's said they were going to attempt it they've ghosted, and none of us have it at the top of our yak stack so it's either you or nobody, which kinda sucks but well, open source"", but that's a lot of typing when the last twenty times you typed it the person you typed it to ghosted.

I really really hope you can find time to make enough of a start for us to discuss things (or at least, the two qualified people in this thread to discuss things with you ;)",False,0,CONTRIBUTOR
https://api.github.com/repos/mojolicious/mojo/issues/1224,prepend in Mojo::DOM > 7.77 looses elements,qyz,4,324276129,1,324276129,0,0,2018-05-18T05:35:29Z,"* Mojolicious version: 7.78
* Perl version: 5.26.0
* Operating system: Debian 9

### Steps to reproduce the behavior
I am using Mojo::DOM to modify an XML document. Please see the example document below. As one step of the process I need to copy the first row before the body tag. This works perfectly up to 7.77. In Mojolicious 7.78 the `row`-Tag gets stripped from `prepend`ed elements.
```
$ cat test.pl
#!/usr/bin/env perl

use Modern::Perl;
use Mojo::DOM;

use Mojolicious;
say Mojolicious->VERSION;

my $dom = Mojo::DOM->new('
  <table>
    <body>
      <row>
        <cell>1</cell>
      </row>
      <row>
        <cell>2</cell>
      </row>
    </body>
  </table>
');
$dom->at('body')->prepend($dom->at('body > row'));
say $dom->to_string;
```

### Expected behavior
Mojo 7.77 behaves correctly:
```
$ cpanm -n -L .cpan/ Mojolicious@7.77 ; PERL5LIB=.cpan/lib/perl5 /opt/perl/5.26.0/bin/perl test.pl 
--> Working on Mojolicious
Fetching http://www.cpan.org/authors/id/S/SR/SRI/Mojolicious-7.77.tar.gz ... OK
Configuring Mojolicious-7.77 ... OK
Building Mojolicious-7.77 ... OK
Successfully installed Mojolicious-7.77 (downgraded from 7.78)
1 distribution installed
7.77

  <table>
    <row>
        <cell>1</cell>
      </row><body>
      <row>
        <cell>1</cell>
      </row>
      <row>
        <cell>2</cell>
      </row>
    </body>
  </table>
```

### Actual behavior
From Mojo 7.78 on the `row`-Tag is missing in the copied elements.
```
$ cpanm -n -L .cpan/ Mojolicious@7.78 ; PERL5LIB=.cpan/lib/perl5 /opt/perl/5.26.0/bin/perl test.pl 
--> Working on Mojolicious
Fetching http://www.cpan.org/authors/id/S/SR/SRI/Mojolicious-7.78.tar.gz ... OK
Configuring Mojolicious-7.78 ... OK
Building Mojolicious-7.78 ... OK
Successfully installed Mojolicious-7.78 (upgraded from 7.77)
1 distribution installed
7.78

  <table>
    
        <cell>1</cell>
      <body>
      <row>
        <cell>1</cell>
      </row>
      <row>
        <cell>2</cell>
      </row>
    </body>
  </table>

```
",True,0,NONE
https://api.github.com/repos/mojolicious/mojo/issues/comments/390155292,prepend in Mojo::DOM > 7.77 looses elements,kraih,4,324276129,2,390155292,0,324276129,2018-05-18T09:46:04Z,"Yes, this is a bug in the new DOM tree cloning code.",False,0,MEMBER
https://api.github.com/repos/mojolicious/mojo/issues/comments/390157492,prepend in Mojo::DOM > 7.77 looses elements,kraih,4,324276129,3,390157492,0,390155292,2018-05-18T09:54:35Z,"A fix could look something like:
```diff
diff --git a/lib/Mojo/DOM.pm b/lib/Mojo/DOM.pm
index c3870a992..78ccf00e9 100644
--- a/lib/Mojo/DOM.pm
+++ b/lib/Mojo/DOM.pm
@@ -289,8 +289,13 @@ sub _parent { $_[0]->[$_[0][0] eq 'tag' ? 3 : 2] }
 
 sub _parse {
   my ($self, $input) = @_;
-  return dclone $input->tree if blessed $input && $input->isa('Mojo::DOM');
-  return Mojo::DOM::HTML->new(xml => $self->xml)->parse($input)->tree;
+
+  return Mojo::DOM::HTML->new(xml => $self->xml)->parse($input)->tree
+    unless blessed $input && $input->isa('Mojo::DOM');
+
+  my $tree = dclone $input->tree;
+  $tree = ['root', $tree] if $tree->[0] eq 'tag';
+  return $tree;
 }
 
 sub _replace {
```
Just without the borked DOM tree. 😉",False,0,MEMBER
https://api.github.com/repos/mojolicious/mojo/issues/comments/390187626,prepend in Mojo::DOM > 7.77 looses elements,qyz,4,324276129,4,390187626,0,390157492,2018-05-18T12:12:21Z,I can confirm that this change fixes both the small test case and my larger real-world case. Thank You!,False,0,NONE
https://api.github.com/repos/mojolicious/mojo/issues/comments/390309968,prepend in Mojo::DOM > 7.77 looses elements,kraih,4,324276129,5,390309968,0,390187626,2018-05-18T19:31:57Z,"The current fix is not ideal, since only `root` nodes benefit from fast cloning and everything else will be slower. But at least it works.",False,0,MEMBER
https://api.github.com/repos/mojolicious/mojo/issues/1226,Enable SSL verification by default,jes,8,324615930,1,324615930,0,0,2018-05-19T09:24:59Z,"### Summary
Enable SSL verification by default by not setting SSL_verify_mode to 0x00. Add an option to Mojo::UserAgent (""verify"") to allow people to explicitly choose non-verifying behaviour. Make Test::Mojo automatically turn off verification so SSL testing still works as before.

I don't expect this is enough to merge straight away, but I think it's a good starting point.

### Motivation
Prevent people from inadvertently writing insecure software.

### References
Issue #1223 ""Mojolicious does not check SSL certificates by default"".
",True,0,NONE
https://api.github.com/repos/mojolicious/mojo/issues/comments/390397609,Enable SSL verification by default,kraih,8,324615930,2,390397609,0,324615930,2018-05-19T11:06:08Z,You forgot `Mojolicious::Command::get` and `ojo`.,False,0,MEMBER
https://api.github.com/repos/mojolicious/mojo/issues/comments/390397851,Enable SSL verification by default,kraih,8,324615930,3,390397851,0,390397609,2018-05-19T11:10:59Z,How is the CA situation after this change? On which operating systems are system certs used by default? Where do we need to configure and use something like `Mozilla::CA`? How should we document the situation?,False,0,MEMBER
https://api.github.com/repos/mojolicious/mojo/issues/comments/390398494,Enable SSL verification by default,kraih,8,324615930,4,390398494,0,390397851,2018-05-19T11:24:57Z,And please squash your commits.,False,0,MEMBER
https://api.github.com/repos/mojolicious/mojo/issues/comments/390399773,Enable SSL verification by default,kraih,8,324615930,5,390399773,0,390398494,2018-05-19T11:50:33Z,"We usually require a deprecation period for breaking changes, and this is going to break some applications. But this change also falls under the security exception in our rules, so we are a little more flexible. https://mojolicious.org/perldoc/Mojolicious/Guides/Contributing#Rules",False,0,MEMBER
https://api.github.com/repos/mojolicious/mojo/issues/comments/390428848,Enable SSL verification by default,kraih,8,324615930,6,390428848,0,390399773,2018-05-19T19:58:45Z,"Btw. I do welcome competing pull requests for this. If anyone else has more time to finish a polished proposal, please do. Right now this issue has momentum in the community, we shouldn't risk letting it go stale and forgotten.",False,0,MEMBER
https://api.github.com/repos/mojolicious/mojo/issues/comments/390429785,Enable SSL verification by default,kraih,8,324615930,7,390429785,0,390428848,2018-05-19T20:14:31Z,"And for the record, after this patch has been applied on openSUSE Tumbleweed and macOS all requests to HTTPS sites with **valid** certificates do no longer work by default.
```
$ mojo get https://mojolicious.org
SSL connect attempt failed error:14090086:SSL routines:ssl3_get_server_certificate:certificate verify failed
 at lib/Mojolicious/Command/get.pm line 76.
```",False,0,MEMBER
https://api.github.com/repos/mojolicious/mojo/issues/comments/390465470,Enable SSL verification by default,jes,8,324615930,8,390465470,0,390429785,2018-05-20T08:20:02Z,"Many thanks for fixing this!

I wasn't ignoring your feedback, I was going to get to it next time I worked on this. Glad it's all sorted now :)",False,0,NONE
https://api.github.com/repos/mojolicious/mojo/issues/comments/390465529,Enable SSL verification by default,jes,8,324615930,9,390465529,0,390465470,2018-05-20T08:21:18Z,"Btw I think the new test case was a new test case, as evidenced by the fact that the existing tests all passed before even though the certificates were not being checked.",False,0,NONE
https://api.github.com/repos/mojolicious/mojo/issues/1227,Protocol specific IOLoop streams,anparker,6,327361942,1,327361942,0,0,2018-05-29T15:03:32Z,"### Summary
Implementing Mojo::IOLoop::Stream subclasses for HTTP and WebSocket connections.

### Motivation
An attempt to implement feature required for an issue.

### References
https://github.com/kraih/mojo/issues/423#issuecomment-376509948
",True,0,CONTRIBUTOR
https://api.github.com/repos/mojolicious/mojo/issues/comments/392830286,Protocol specific IOLoop streams,kraih,6,327361942,2,392830286,0,327361942,2018-05-29T15:55:08Z,"For those not following IRC, i was the one who recommended the change from `MOJO_USERAGENT_DEBUG` and `MOJO_DAEMON_DEBUG` to `MOJO_CLIENT_DEBUG` and `MOJO_SERVER_DEBUG`. Since the debug code would have to span multiple classes on different layers after this pull request, it just makes more sense this way.",False,0,MEMBER
https://api.github.com/repos/mojolicious/mojo/issues/comments/393901088,Protocol specific IOLoop streams,kraih,6,327361942,3,393901088,0,392830286,2018-06-01T14:38:59Z,"I've removed the `work in progress` label, since i think this pull request has reached the state where it could be merged.",False,0,MEMBER
https://api.github.com/repos/mojolicious/mojo/issues/comments/393903804,Protocol specific IOLoop streams,kraih,6,327361942,4,393903804,0,393901088,2018-06-01T14:48:04Z,@jberger @marcusramberg @jhthorsen I'm calling for a formal vote on this pull request.,False,0,MEMBER
https://api.github.com/repos/mojolicious/mojo/issues/comments/393905384,Protocol specific IOLoop streams,kraih,6,327361942,5,393905384,0,393903804,2018-06-01T14:53:12Z,"I've reviewed the code and it looks good. The new stream APIs are very minimalistic and seem future proof. A performance difference is barely measurable. The new `transition` method in `Mojo::IOLoop` is not exactly elegant, but it does its job and i can't really think of something better either. So this pull request gets a 👍 from me.

P.S.: I think there might even be more code in `Mojo::UserAgent` that could be moved into stream classes.",False,0,MEMBER
https://api.github.com/repos/mojolicious/mojo/issues/comments/393992284,Protocol specific IOLoop streams,kraih,6,327361942,6,393992284,0,393905384,2018-06-01T19:55:27Z,"Thanks, applied.",False,0,MEMBER
https://api.github.com/repos/mojolicious/mojo/issues/comments/413823431,Protocol specific IOLoop streams,kraih,6,327361942,7,413823431,0,393992284,2018-08-17T10:21:58Z,Unfortunately this change had to be reverted. https://github.com/kraih/mojo/commit/61f6cbf22c7bf8eb4787bd1014d91ee2416c73e7,False,0,MEMBER
https://api.github.com/repos/rails/rails/issues/33666,Fail more gracefully from ActiveStorage missing file exceptions,cbothner,3,352175657,1,352175657,0,0,2018-08-20T15:03:13Z,"This PR translates service-specific missing object exceptions into one generic `ActiveStorage::FileNotFoundError` so that the application can fail more gracefully when a missing file is accessed. Specifically, this PR lets `DiskController` rescue this error and respond with 404 instead of 500. This improves the development experience especially when working, in `development`, with a database of Blob records that point to files in the `production` service.

### Outstanding question
`RepresentationsController` does not presently handle `ActiveStorage::FileNotFoundError`, since @georgeclaghorn argued it truly is exceptional for the service not to have a file that corresponds to a specific blob in the database. I don’t disagree with this, but hope we can nevertheless find a way to reduce the flood of stack traces that fill our `development` logs when loading an index view that tries to display many thumbnails of images stored in our `production` service.

### Related issue

Resolves #33647",True,0,CONTRIBUTOR
https://api.github.com/repos/rails/rails/issues/comments/414697607,Fail more gracefully from ActiveStorage missing file exceptions,georgeclaghorn,3,352175657,2,414697607,0,352175657,2018-08-21T14:38:32Z,"Last thing: can you please squash your commits? I think two are appropriate: one for rescuing `Errno::ENOENT` in `DiskController` and one for translating service-specific missing object exceptions.

I also think these changes merit separate changelog entries, since they're independent:

* `ActiveStorage::Blob#download` and `ActiveStorage::Blob#open` raise `ActiveStorage::FileNotFoundError` when the corresponding file is missing from the storage service. Services translate service-specific missing object exceptions (e.g. `Google::Cloud::NotFoundError` for the GCS service and `Errno::ENOENT` for the disk service) into `ActiveStorage::FileNotFoundError`.

* `ActiveStorage::DiskController#show` generates a 404 Not Found response when the requested file is missing from the disk service. It previously raised `Errno::ENOENT`.",False,0,CONTRIBUTOR
https://api.github.com/repos/rails/rails/issues/comments/414796903,Fail more gracefully from ActiveStorage missing file exceptions,cbothner,3,352175657,3,414796903,0,414697607,2018-08-21T19:40:47Z,"Done 👍 

Is there anything to do about the errors raised in `RepresentationsController` for the sake of developer experience, or is that inappropriate to handle at the framework level? ",False,0,CONTRIBUTOR
https://api.github.com/repos/rails/rails/issues/comments/415266365,Fail more gracefully from ActiveStorage missing file exceptions,georgeclaghorn,3,352175657,4,415266365,0,414796903,2018-08-23T02:55:14Z,"The [`DebugExceptions`](https://github.com/rails/rails/blob/master/actionpack/lib/action_dispatch/middleware/debug_exceptions.rb) middleware logs the full backtrace if none of the lines in the trace come from the application, which is the case for `ActiveStorage::FileNotFoundError`s triggered by requests to `RepresentationsController`:

https://github.com/rails/rails/blob/cdee52079cdd88d376d9664a61a40348d45e819c/actionpack/lib/action_dispatch/middleware/debug_exceptions.rb#L179-L188

I’m not immediately sure what we can do about that. I’m going to think about it and merge this in the meantime.",False,0,CONTRIBUTOR
https://api.github.com/repos/rails/rails/issues/33667,Handle only specifically relevant Azure HTTPErrors in ActiveStorage::Service::AzureStorageService,cbothner,7,352177721,1,352177721,0,0,2018-08-20T15:08:14Z,"The Azure gem uses `Azure::Core::Http::HTTPError` for everything:
checksum mismatch, missing object, network unavailable, and many more
(https://www.rubydoc.info/github/yaxia/azure-storage-ruby/Azure/Core/Http/HTTPError).
Rescuing that class obscures all sorts of configuration errors. We
should check the type of error in those rescue blocks, and reraise when
needed.",True,0,CONTRIBUTOR
https://api.github.com/repos/rails/rails/issues/comments/414350779,Handle only specifically relevant Azure HTTPErrors in ActiveStorage::Service::AzureStorageService,rails-bot,7,352177721,2,414350779,0,352177721,2018-08-20T15:08:18Z,"Thanks for the pull request, and welcome! The Rails team is excited to review your changes, and you should hear from @rafaelfranca (or someone else) soon.

If any changes to this PR are deemed necessary, please add them as extra commits. This ensures that the reviewer can see what has changed since they last reviewed the code. Due to the way GitHub handles out-of-date commits, this should also make it reasonably obvious what issues have or haven't been addressed. Large or tricky changes may require several passes of review and changes.

This repository is being automatically checked for code quality issues using <a href=""https://codeclimate.com"">Code Climate</a>. You can see results for this analysis in the PR status below. Newly introduced issues should be fixed before a Pull Request is considered ready to review.

Please see [the contribution instructions](http://edgeguides.rubyonrails.org/contributing_to_ruby_on_rails.html) for more information.
",False,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/415568510,Handle only specifically relevant Azure HTTPErrors in ActiveStorage::Service::AzureStorageService,georgeclaghorn,7,352177721,3,415568510,0,414350779,2018-08-23T20:57:01Z,Can you please rebase this against master?,False,0,CONTRIBUTOR
https://api.github.com/repos/rails/rails/issues/comments/415585766,Handle only specifically relevant Azure HTTPErrors in ActiveStorage::Service::AzureStorageService,cbothner,7,352177721,4,415585766,0,415568510,2018-08-23T22:03:43Z,👍  I also went ahead and made some changes to be consistent with the merged version of #33666.,False,0,CONTRIBUTOR
https://api.github.com/repos/rails/rails/issues/comments/415594140,Handle only specifically relevant Azure HTTPErrors in ActiveStorage::Service::AzureStorageService,georgeclaghorn,7,352177721,5,415594140,0,415585766,2018-08-23T22:42:15Z,Thank you!,False,0,CONTRIBUTOR
https://api.github.com/repos/rails/rails/issues/comments/415602223,Handle only specifically relevant Azure HTTPErrors in ActiveStorage::Service::AzureStorageService,georgeclaghorn,7,352177721,6,415602223,0,415594140,2018-08-23T23:13:28Z,"Sorry, I had to revert this because the Azure Storage service tests [failed](https://travis-ci.org/rails/rails/jobs/419883696) in master. It’s my fault for forgetting that those tests don’t run for PRs.

It looks like `Azure::Core::Http::HTTPError#type` is always `""Unknown""` for missing-blob exceptions, which is particularly unhelpful.

/cc two frequent committers to [Azure/azure-ruby-asm-core](https://github.com/Azure/azure-ruby-asm-core): @katmsft @yaxia",False,0,CONTRIBUTOR
https://api.github.com/repos/rails/rails/issues/comments/415609520,Handle only specifically relevant Azure HTTPErrors in ActiveStorage::Service::AzureStorageService,cbothner,7,352177721,7,415609520,0,415602223,2018-08-23T23:59:19Z,"That is very strange. I did make an Azure account and ran the tests on my machine before submitting the PR… but I guess I made other changes afterwards and forgot. My apologies for the oversight.

Turning individual changes on and off:

- `#upload` with an invalid checksum is failing with `""Md5Mismatch""` without the rescue
- `#delete` is failing with `""BlobNotFound""` without the rescue
- `#blob_for`, which calls `Azure::Storage::Blob#get_blob_properties`, is where we get `""Unknown""`

It seems that the error types are less consistent from Azure than I had thought.

I do think it would be ideal if the Azure gem set `Azure::Core::Http::HTTPError#type` to `BlobNotFound` in `get_blob_properties`. But if you’re comfortable continuing to rescue indiscriminately in  `#blob_for` (which makes the tests pass) we do get value from this change simply by checking the type in `#upload` and `#delete`. `""InvalidResourceName""` and `""AuthenticationFailed""` are then correctly surfaced, where before they presented as a confusing `ActiveStorage::IntegrityError` or were swallowed completely.

Let me know how you’d like to proceed and I’ll resubmit as needed.",False,0,CONTRIBUTOR
https://api.github.com/repos/rails/rails/issues/comments/415613742,Handle only specifically relevant Azure HTTPErrors in ActiveStorage::Service::AzureStorageService,georgeclaghorn,7,352177721,8,415613742,0,415609520,2018-08-24T00:28:17Z,"If you don’t mind, please open a new PR with the `#upload` and `#delete` changes and put “r? @georgeclaghorn” at the end of the description. Thanks!",False,0,CONTRIBUTOR
https://api.github.com/repos/rails/rails/issues/33668,Ensure references creates id before type,al2o3cr,14,352264316,1,352264316,0,0,2018-08-20T19:25:12Z,"Prior to https://github.com/rails/rails/commit/d26704a15f88d384dd282425daa832affdb5f8c1, using `references` with `polymorphic: true` in a migration created an id column before creating the  corresponding type column.

After that commit, the order is reversed.

This PR restores the previous order and adds a test to prevent regressions.

I'm not aware of any production impact for the column ordering change, but it broke the schema linting on github/github.

/cc @tenderlove @eileencodes ",True,0,CONTRIBUTOR
https://api.github.com/repos/rails/rails/issues/comments/414433489,Ensure references creates id before type,rails-bot,14,352264316,2,414433489,0,352264316,2018-08-20T19:25:25Z,"r? @schneems

(@rails-bot has picked a reviewer for you, use r? to override)",False,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/414441048,Ensure references creates id before type,al2o3cr,14,352264316,3,414441048,0,414433489,2018-08-20T19:50:43Z,"@tenderlove CI found something I missed, let's hope this new push fixes it :)",False,0,CONTRIBUTOR
https://api.github.com/repos/rails/rails/issues/comments/414449923,Ensure references creates id before type,al2o3cr,14,352264316,4,414449923,0,414441048,2018-08-20T20:21:07Z,Added some tweaks to ensure the changes from https://github.com/rails/rails/commit/3fea23171248fb419925501492d174a1ae419ff8 and https://github.com/rails/rails/pull/14143 aren't disturbed by this.,False,0,CONTRIBUTOR
https://api.github.com/repos/rails/rails/issues/comments/414527109,Ensure references creates id before type,kamipo,14,352264316,5,414527109,0,414449923,2018-08-21T02:14:37Z,"I'm curious about the purpose of linting the column order in github/github.

I personally think there is no benefit to change the column order in Rails 6.0.",False,0,MEMBER
https://api.github.com/repos/rails/rails/issues/comments/414712677,Ensure references creates id before type,al2o3cr,14,352264316,6,414712677,0,414527109,2018-08-21T15:19:22Z,"@kamipo Github currently runs migrations from an empty DB in CI and verifies that the expected structures are produced, as old migrations need to be runnable for on-premises installs that only update periodically. We're currently working to reduce the number of migrations we keep around (nobody needs ancient ones like `002_private_repos.rb` anymore) but that work also relies on the linting to ensure correctness.

I'm not certain what the significance of column order is, but it's clearly important for *somebody* (thus column options like `after` and `first`). The order was reversed in the 4.2 -> 5.0 upgrade without a changelog entry or any other notice.",False,0,CONTRIBUTOR
https://api.github.com/repos/rails/rails/issues/comments/415425207,Ensure references creates id before type,kamipo,14,352264316,7,415425207,0,414712677,2018-08-23T14:03:12Z,"Isn't enough implementing migration compatibility for 4.2?

| version | column order             | index column order       |   
|---------|--------------------------|--------------------------|
| 4.1     | `[""foo_id"", ""foo_type""]` | `[""foo_id"", ""foo_type""]` |
| 4.2     | `[""foo_id"", ""foo_type""]` | `[""foo_type"", ""foo_id""]` |
| 5.0     | `[""foo_type"", ""foo_id""]` | `[""foo_type"", ""foo_id""]` |
| 5.1     | `[""foo_type"", ""foo_id""]` | `[""foo_type"", ""foo_id""]` |
| 5.2     | `[""foo_type"", ""foo_id""]` | `[""foo_type"", ""foo_id""]` |

That was already made in the latest three release series.
So I don't think there is any benefit to change the column order in Rails 6.0 for most Rails 5 users.",False,0,MEMBER
https://api.github.com/repos/rails/rails/issues/comments/415430230,Ensure references creates id before type,matthewd,14,352264316,8,415430230,0,415425207,2018-08-23T14:16:42Z,"> That was already made in the latest three release series.

+1. We _might've_ considered changing a few versions ago (though I'm not sure how much it matters), but at this point, the current behaviour is the well-established one: I don't see how any argument that it _does_ matter could overcome the fact that it's now been this way for years.",False,0,MEMBER
https://api.github.com/repos/rails/rails/issues/comments/417468875,Ensure references creates id before type,al2o3cr,14,352264316,9,417468875,0,415430230,2018-08-30T21:12:34Z,"@matthewd FWIW, passing `after:` to `references` produces the opposite column order on 5.2, as tested [here](https://github.com/rails/rails/blob/d48f4ddfc8dd38b65f7a040c5c9c7d1468114d2d/activerecord/test/cases/migration/column_positioning_test.rb#L58) for instance.

""That bug's been there a long time"" doesn't feel persuasive to me, especially since it was introduced with zero announcement / discussion / etc by a refactoring of code that lacked test coverage.

As an alternative, I can split out the refactoring & new test added here, leaving the existing behavior with a guard against future regressions and a clear extension point to override to get the old behavior for us at Github.",False,0,CONTRIBUTOR
https://api.github.com/repos/rails/rails/issues/comments/417535681,Ensure references creates id before type,matthewd,14,352264316,10,417535681,0,417468875,2018-08-31T02:56:56Z,"> ""That bug's been there a long time"" doesn't feel persuasive

Of course not; a bug is a bug. ""That arbitrary behaviour has been there a long time"" is rather different, though. The previous ordering was also ""introduced with zero announcement / discussion / etc, by [addition] of code that [clearly] lacked test coverage"".

In fact, I can go further, and declare that the change was itself a bug fix: the natural order is [type, id] because that matches the [actually important] order in the index. 4.2 intentionally changed the index order, and inadvertently failed to change the table order to match; 5.0 (consciously or not) corrected that oversight.

Although we don't generally version bugfixes, if you really want to restore the behaviour *for 4.2 migrations* as @kamipo suggested, that seems unobjectionable.

I'm happy to lock in the current behaviour with a test; I'd have to look at the refactoring on its own merits.

But wouldn't it be easier to solve your internal problem by changing the affected migrations to define the two columns individually? It's clearly safe to do so, because you have a tool that will ensure your changes produce the same schema.",False,0,MEMBER
https://api.github.com/repos/rails/rails/issues/comments/418411434,Ensure references creates id before type,al2o3cr,14,352264316,11,418411434,0,417535681,2018-09-04T15:28:05Z,"@matthewd If there's a ""natural order"", then using `after:` results in the ""wrong"" order. ",False,0,CONTRIBUTOR
https://api.github.com/repos/rails/rails/issues/comments/418420324,Ensure references creates id before type,matthewd,14,352264316,12,418420324,0,418411434,2018-09-04T15:52:11Z,"Yeah; presumably that (""using `after:` results in the opposite order to normal"") would've been true on 4.2 as well? That does sound like a possibly-compelling argument for your refactoring.",False,0,MEMBER
https://api.github.com/repos/rails/rails/issues/comments/424092579,Ensure references creates id before type,al2o3cr,14,352264316,13,424092579,0,418420324,2018-09-24T19:17:30Z,"@matthewd In 4.2, passing `after` to `references` meant it was passed to both the ID and type columns, resulting in type before ID. [ref](https://github.com/rails/rails/blob/4-2-stable/activerecord/lib/active_record/connection_adapters/abstract/schema_definitions.rb#L325)

The refactor in https://github.com/rails/rails/commit/d26704a15f88d384dd282425daa832affdb5f8c1 introduced a bug in 5.0.0, reported as https://github.com/rails/rails/issues/30496 and fixed in https://github.com/rails/rails/commit/3fea23171248fb419925501492d174a1ae419ff8 (released in 5.2) which also added tests that verified the column order was ID then type.
",False,0,CONTRIBUTOR
https://api.github.com/repos/rails/rails/issues/comments/566937750,Ensure references creates id before type,rails-bot[bot],14,352264316,14,566937750,0,424092579,2019-12-18T08:52:52Z,"This pull request has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs.
Thank you for your contributions.
",False,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/567046761,Ensure references creates id before type,eileencodes,14,352264316,15,567046761,0,566937750,2019-12-18T14:09:03Z,We ended up handling this at GitHub by deleting old migrations. ,False,0,MEMBER
https://api.github.com/repos/rails/rails/issues/33669,Reduce memory bloat on new ActiveRecord connections (When DB has large number of tables),jonathan-wheeler,5,352311498,1,352311498,0,0,2018-08-20T21:58:45Z,"### Summary
Continuation of 
#28369 (Merged but reverted)
#28834 (Open but stale) 

#query_conditions_for_initial_load currently loads many more
records than it needs. Including the children of composite types
when the parent composites themselves were not loaded.

In the current query a record is returned for each table in the DB
but is not used, while this is normally pretty minimal overhead;
In databases with a large number of tables (eg. tenanted app with
multiple schemas) the issue is exacerbated and results in memory
bloat each time a connection is established.

This attempts to reduce the bloat by amending the query to not
include the children of composite types (including the records
for each table) as suggested [here in #28834](https://github.com/rails/rails/pull/28834#issuecomment-312422423)

### Other Information

Created 2 dummy databases using the following [script](
https://gist.github.com/jonathan-wheeler/db266d98c4d61ecd942e3cd466baefdc)
one single tenant with 100 tables and one large multitenant with
1000 schemas each with 100 tables. They contain no data but it
should still illustrate the issue.

10.times { ActiveRecord::Base.establish_connection(....).connection }
[Full benchmark scripts](https://gist.github.com/jonathan-wheeler/c4c8726773311f9785f22d4d1ca24eeb)
#### Memory
##### Single tenant
```
Calculating -------------------------------------
master_single_tenant_test
                        20.982M memsize (    18.984M retained)
                        23.535k objects (     1.109k retained)
                        50.000  strings (    50.000  retained)

patch_single_tenant_test
                        11.938M memsize (    10.559M retained)
                        16.082k objects (   811.000  retained)
                        50.000  strings (    50.000  retained)

Comparison:
patch_single_tenant_test:   11938187 allocated
master_single_tenant_test:   20982362 allocated - 1.76x more
```
##### Multitenant
```
Calculating -------------------------------------
master_large_multi_tenant_tenant_test
                       493.410M memsize (    18.983M retained)
                         5.069M objects (     1.099k retained)
                        50.000  strings (    50.000  retained)
patch_large_multi_tenant_tenant_test
                        12.843M memsize (    11.337M retained)
                        23.825k objects (     7.024k retained)
                        50.000  strings (    50.000  retained)

Comparison:
patch_large_multi_tenant_tenant_test:   12843438 allocated
master_large_multi_tenant_tenant_test:  493410349 allocated - 38.42x more
```

Not in the same league of improvement seen in #28834 as this patch is
less aggressive so still includes some clutter but still a
sizeable reduction in allocations to be made. Not a huge difference
in retained memory but initial bloat maybe more of an issue as the
number of tables scale (example 10,000 schemas is not huge).

#### Speed
##### Single tenant
```
Rehearsal -------------------------------------------------------------
master_single_tenant_test   0.043770   0.019775   0.063545 (  0.227460)
patch_single_tenant_test    0.039852   0.009767   0.049619 (  0.191569)
---------------------------------------------------- total: 0.113164sec

                                user     system      total        real
master_single_tenant_test   0.034316   0.006944   0.041260 (  0.195248)
patch_single_tenant_test    0.027595   0.006390   0.033985 (  0.179472)
```

##### Multitenant
```
Rehearsal -------------------------------------------------------------------------
master_large_multi_tenant_tenant_test   4.232676   0.268989   4.501665 ( 12.966424)
patch_large_multi_tenant_tenant_test    0.027335   0.006216   0.033551 ( 13.238648)
---------------------------------------------------------------- total: 4.535216sec

                                            user     system      total        real
master_large_multi_tenant_tenant_test   0.026196   0.005952   0.032148 ( 12.977751)
patch_large_multi_tenant_tenant_test    0.027290   0.006186   0.033476 ( 13.293085)
```

No substantial differences.

",True,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/414477057,Reduce memory bloat on new ActiveRecord connections (When DB has large number of tables),rails-bot,5,352311498,2,414477057,0,352311498,2018-08-20T21:58:47Z,"Thanks for the pull request, and welcome! The Rails team is excited to review your changes, and you should hear from @georgeclaghorn (or someone else) soon.

If any changes to this PR are deemed necessary, please add them as extra commits. This ensures that the reviewer can see what has changed since they last reviewed the code. Due to the way GitHub handles out-of-date commits, this should also make it reasonably obvious what issues have or haven't been addressed. Large or tricky changes may require several passes of review and changes.

This repository is being automatically checked for code quality issues using <a href=""https://codeclimate.com"">Code Climate</a>. You can see results for this analysis in the PR status below. Newly introduced issues should be fixed before a Pull Request is considered ready to review.

Please see [the contribution instructions](http://edgeguides.rubyonrails.org/contributing_to_ruby_on_rails.html) for more information.
",False,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/415253315,Reduce memory bloat on new ActiveRecord connections (When DB has large number of tables),matthewd,5,352311498,3,415253315,0,414477057,2018-08-23T01:52:55Z,"> ```
> Calculating -------------------------------------
> master_large_multi_tenant_tenant_test
>                          5.069M objects (     1.099k retained)
> patch_large_multi_tenant_tenant_test
>                         23.825k objects (     7.024k retained)
> ```

Are we expecting retained to increase like that? :confused:

Otherwise, this looks great, thanks! ❤️

Do we have any test coverage of what gets loaded here, and/or the fact that skipped types are still later loaded on demand? (Maybe it's too hard to see without digging deep into the internals..)",False,0,MEMBER
https://api.github.com/repos/rails/rails/issues/comments/416049482,Reduce memory bloat on new ActiveRecord connections (When DB has large number of tables),jonathan-wheeler,5,352311498,4,416049482,0,415253315,2018-08-26T16:05:20Z,"> Are we expecting retained to increase like that? 😕

Nope, can't explain what it could be, the query returns less records and the rest of the processing is exactly the same. For example an app I'm running locally with just over 200 tables the query returns 124 records but without the patch 365 records are returned.

Think it may be a something wrong with my benchmark script?

```
y = 10
Benchmark.memory do |x|
 x.report(:master_large_multi_tenant_tenant_test) do
   y.times do
     ActiveRecord::Base.establish_connection(adapter: :postgresql, database: :large_multi_tenant_tenant_test).connection
     ActiveRecord::Base.clear_active_connections!
   end
 end

 x.report(:patch_large_multi_tenant_tenant_test) do
   require 'active_record_postgresql_adapter_ext'
   y.times do
     ActiveRecord::Base.establish_connection(adapter: :postgresql, database: :large_multi_tenant_tenant_test).connection
     ActiveRecord::Base.clear_active_connections!
   end
 end
x.compare!
end
``` 

As when run in isolation the retained value is more akin to normal.
```
Calculating -------------------------------------
patch_large_multi_tenant_tenant_test
                        20.526M memsize (    18.984M retained)
                        18.705k objects (     1.112k retained)
                        50.000  strings (    50.000  retained)
```

>Do we have any test coverage of what gets loaded here, and/or the fact that skipped types are still later loaded on demand? (Maybe it's too hard to see without digging deep into the internals..)

I don't think so, have had a good look and the closest specs to covering this are the [postgres/type_lookup](https://github.com/rails/rails/blob/6d5eefd453c641c317f3cdfa1286f07cfc5b11e7/activerecord/test/cases/adapters/postgresql/type_lookup_test.rb) tests, wasn't sure if that was on purpose but can write a spec if needed?",False,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/566937755,Reduce memory bloat on new ActiveRecord connections (When DB has large number of tables),rails-bot[bot],5,352311498,5,566937755,0,416049482,2019-12-18T08:52:53Z,"This pull request has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs.
Thank you for your contributions.
",False,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/567609096,Reduce memory bloat on new ActiveRecord connections (When DB has large number of tables),jonathan-wheeler,5,352311498,6,567609096,0,566937755,2019-12-19T18:33:44Z,"Closing as the gains in practice, although present were minimal. So probably not worth the adding complexity to account for a relatively edge use-case.

I think for apps with thousands of schemas, possible issues in postgres (high memory use) would be the bottleneck long before this became a significant issue. But could always apply something similar as a patch if needed.

Would suggest #28834 be closed to ",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/7849,Mount namespaces can make ZFS snapshots not automountable by normal processes,siebenmann,15,355385564,1,355385564,0,0,2018-08-30T01:02:34Z,"### System information
<!--  add version after ""|"" character -->
Type | Version/Name
 --- | --- 
Distribution Name	|  Fedora, also Ubuntu
Distribution Version	|  28 (Fedora), 18.04 LTS (Ubuntu)
Linux Kernel	|  4.17.18-200.fc28.x86_64 (Fedora), 4.15.0-32-generic (Ubuntu)
Architecture	|  x86_64
ZFS Version	|  0.7.0-1530_g5097b4e42 (Fedora; almost git tip), 0.7.5-1ubuntu15 (Ubuntu)
SPL Version	|  0.7.0-1530_g5097b4e42 (Fedora), 0.7.5-1ubuntu1 (Ubuntu)
<!-- 
Commands to find ZFS/SPL versions:
modinfo zfs | grep -iw version
modinfo spl | grep -iw version 
-->

### Describe the problem you're observing

Cloned mount namespaces can 'trap' ZFS snapshot automounts, making them mostly inaccessible to regular processes in the regular host namespace after ZFS expires the initial automount because ZFS will refuse to re-automount them. Under some circumstances this can lead to a panic in the NFS server code (see issue #7764), although it's not the only way to cause or reproduce that particular panic.

### Describe how to reproduce the problem

1. Cause a snapshot to be automounted in the regular (PID 1) mount namespace. `ls /tank/tst/.zfs/snapshot/snap`.
2. Create a new cloned mount namespace, for example with `PS1=""newns# "" unshare -m sh`. This cloned mount namespace inherits the automounted snapshot.
3. Wait for the automounted snapshot's unmount timer to come up (five minutes by default). ZFS will attempt to unmount it by ultimately running `umount` in the regular mount namespace; if the snapshot is unused there, this will succeed. However, this doesn't unmount the snapshot in the cloned mount namespace.
4. Attempt to access the snapshot again to re-automount it, again with `ls /tank/tst/.zfs/snapshot/snap`. However, this time around it will fail with the error of 'Too many symbolic links'.

This happens because `zfsctl_snapshot_mount()` refuses to automount a snapshot if it is already mounted, but the actual check is implicitly merely 'is the snapshot mounted anywhere in any namespace' (implemented as 'is this still on our internal list of snapshots that are mounted' in `zfsctl_snapshot_ismounted()`). The specific error is `ELOOP` for reasons explained in the comments further down in `zfsctl_snapshot_mount()`.

Unfortunately it's not clear to me what (if anything) can be done about this. It might be possible to make it so that ZFS snapshot automounts can only be present in the main (PID 1) mount namespace, but that feels like overkill because there are some situations where this works right in additional mount namespaces. I don't know if there's a way to make a re-mount work right if the snapshot is mounted but not in the main mount namespace, or if that would cause explosions.

(The good news is that systemd's handling of mount namespaces for regular units with things like `DynamicUser` or `PrivateTmp` doesn't appear to have this problem; unmounts propagate into the modified mount namespace used by the service.)",True,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/417183654,Mount namespaces can make ZFS snapshots not automountable by normal processes,loli10K,15,355385564,2,417183654,0,355385564,2018-08-30T04:08:17Z,"> However, this doesn't unmount the snapshot in the cloned mount namespace.

I don't see this happening on 0.7.9:
```
root@linux:~# echo 5 > /sys/module/zfs/parameters/zfs_expire_snapshot 
root@linux:~# 
root@linux:~# zfs create $POOLNAME/fs
root@linux:~# zfs snap $POOLNAME/fs@snap
root@linux:~# ls -l /$POOLNAME/fs/.zfs/snapshot/snap
total 0
root@linux:~# df -t zfs
Filesystem       1K-blocks  Used Available Use% Mounted on
testpool             57216     0     57216   0% /testpool
testpool/fs          57216     0     57216   0% /testpool/fs
testpool/fs@snap     57216     0     57216   0% /testpool/fs/.zfs/snapshot/snap
root@linux:~# PS1='newns# ' unshare -m sh
newns# sleep 10
newns# df -t zfs
Filesystem     1K-blocks  Used Available Use% Mounted on
testpool           57216     0     57216   0% /testpool
testpool/fs        57216     0     57216   0% /testpool/fs
newns# 
root@linux:~# df -t zfs
Filesystem     1K-blocks  Used Available Use% Mounted on
testpool           57216     0     57216   0% /testpool
testpool/fs        57216     0     57216   0% /testpool/fs
root@linux:~# ls -l /$POOLNAME/fs/.zfs/snapshot/snap
total 0
root@linux:~# df -t zfs
Filesystem       1K-blocks  Used Available Use% Mounted on
testpool             57216     0     57216   0% /testpool
testpool/fs          57216     0     57216   0% /testpool/fs
testpool/fs@snap     57216     0     57216   0% /testpool/fs/.zfs/snapshot/snap
root@linux:~# 
```",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/417254470,Mount namespaces can make ZFS snapshots not automountable by normal processes,Ukko-Ylijumala,15,355385564,3,417254470,0,417183654,2018-08-30T09:30:58Z,Maybe something keeps the snapshot mounted in the cloned namespace?,False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/417344339,Mount namespaces can make ZFS snapshots not automountable by normal processes,siebenmann,15,355385564,4,417344339,0,417254470,2018-08-30T14:41:37Z,"I was just able to reproduce my issue with 0.7.9 on Fedora 28 (with the latest, just-released kernel). I used a 15 second `zfs_expire_snapshot`, though, since I wasn't sure I could type all the necessary commands in within five seconds, and I confirmed that the snapshot was mounted in `newns#` before the `sleep` (with `df -t zfs`). @loli10K, is it possible that in your case the snapshot expired in the main namespace before your `unshare`? What kernel and Linux distribution were you using here?",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/417419288,Mount namespaces can make ZFS snapshots not automountable by normal processes,loli10K,15,355385564,5,417419288,0,417344339,2018-08-30T18:22:26Z,"@siebenmann Debian8 with stock kernel:

```
root@linux:~# cat /tmp/issue-7849.sh 
#!/bin/bash

echo 50 > /sys/module/zfs/parameters/zfs_expire_snapshot
# misc functions
function is_linux() {
   if [[ ""$(uname)"" == ""Linux"" ]]; then
      return 0
   else
      return 1
   fi
}
# setup
POOLNAME='testpool'
if is_linux; then
   TMPDIR='/var/tmp'
   mountpoint -q $TMPDIR || mount -t tmpfs tmpfs $TMPDIR
   zpool destroy $POOLNAME
   rm -f $TMPDIR/disk*
   truncate -s 128m $TMPDIR/disk{0,1}
   zpool create $POOLNAME $TMPDIR/disk0
else
   TMPDIR='/tmp'
   zpool destroy $POOLNAME
   rm -f $TMPDIR/zpool_$POOLNAME.dat
   mkfile 128m $TMPDIR/zpool_$POOLNAME.dat
   zpool create $POOLNAME $TMPDIR/zpool_$POOLNAME.dat
fi
zfs create $POOLNAME/fs
zfs snap $POOLNAME/fs@snap
ls -l /$POOLNAME/fs/.zfs/snapshot/snap
df -t zfs
echo 'unshare ->'
PS1='newns# ' unshare -m sh -c ""df -t zfs && echo sleep && sleep 60 && echo slept && df -t zfs""
echo 'unshare <-'
df -t zfs

root@linux:~# /tmp/issue-7849.sh 
total 0
Filesystem       1K-blocks  Used Available Use% Mounted on
testpool             57216     0     57216   0% /testpool
testpool/fs          57216     0     57216   0% /testpool/fs
testpool/fs@snap     57216     0     57216   0% /testpool/fs/.zfs/snapshot/snap
unshare ->
Filesystem       1K-blocks  Used Available Use% Mounted on
testpool             57216     0     57216   0% /testpool
testpool/fs          57216     0     57216   0% /testpool/fs
testpool/fs@snap     57216     0     57216   0% /testpool/fs/.zfs/snapshot/snap
sleep
slept
Filesystem     1K-blocks  Used Available Use% Mounted on
testpool           57216     0     57216   0% /testpool
testpool/fs        57216     0     57216   0% /testpool/fs
unshare <-
Filesystem     1K-blocks  Used Available Use% Mounted on
testpool           57216     0     57216   0% /testpool
testpool/fs        57216     0     57216   0% /testpool/fs
root@linux:~# uname -a
Linux linux 3.16.0-4-amd64 #1 SMP Debian 3.16.51-3 (2017-12-13) x86_64 GNU/Linux
root@linux:~# 
```",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/417435397,Mount namespaces can make ZFS snapshots not automountable by normal processes,siebenmann,15,355385564,6,417435397,0,417419288,2018-08-30T19:16:18Z,"Thank you for the script! I ran it on my test Fedora 28 machine and it reproduced the problem:

````
[...]
unshare ->
Filesystem       1K-blocks   Used Available Use% Mounted on
tank                558592      0    558592   0% /tank
tank/fs             900864 342272    558592  38% /tank/fs
testpool             57216      0     57216   0% /testpool
testpool/fs          57216      0     57216   0% /testpool/fs
testpool/fs@snap     57216      0     57216   0% /testpool/fs/.zfs/snapshot/snap
sleep
slept
Filesystem       1K-blocks   Used Available Use% Mounted on
tank                558592      0    558592   0% /tank
tank/fs             900864 342272    558592  38% /tank/fs
testpool             57216      0     57216   0% /testpool
testpool/fs          57216      0     57216   0% /testpool/fs
testpool/fs@snap     57216      0     57216   0% /testpool/fs/.zfs/snapshot/snap
unshare <-
[...]
````

This is with 0.7.9 straight from the official ZoL Fedora repo, so all I can think of is some difference in either the kernel's behavior or the `unshare` command on Debian 8 vs Fedora.",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/417734950,Mount namespaces can make ZFS snapshots not automountable by normal processes,loli10K,15,355385564,7,417734950,0,417435397,2018-08-31T17:24:39Z,">my test Fedora 28 machine and it reproduced the problem

@siebenmann does this happen _only_ with ZFS automounted snapshots? Please try the following script on that Fedora28 machine:

```
#!/bin/bash

mountpoint -q /mnt && umount /mnt
truncate -s 64m /var/tmp/file
yes | mkfs.ext4 /var/tmp/file
mount /var/tmp/file /mnt
df /mnt
(sleep 10 && echo 'umounting' && umount /mnt && echo 'umounted') &
echo 'unshare ->'
PS1='newns# ' unshare -m sh -c ""df /mnt && echo sleep && sleep 20 && echo slept && df /mnt""
echo 'unshare <-'
df /mnt
```",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/417737374,Mount namespaces can make ZFS snapshots not automountable by normal processes,siebenmann,15,355385564,8,417737374,0,417734950,2018-08-31T17:33:50Z,"The held-in-namespace mount also happens with the /dev/loop0 mount:

````
unshare ->
Filesystem     1K-blocks  Used Available Use% Mounted on
/dev/loop0         59365  1294     53485   3% /mnt
sleep
umounting
umounted
slept
Filesystem     1K-blocks  Used Available Use% Mounted on
/dev/loop0         59365  1294     53485   3% /mnt
unshare <-
````

Just to be sure, I tested a variant of your script that did a `df /mnt` in the regular namespace after unmounting `/mnt` (so between 'unmounted' and 'slept') and it showed that the mount was indeed gone there.",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/417924984,Mount namespaces can make ZFS snapshots not automountable by normal processes,loli10K,15,355385564,9,417924984,0,417737374,2018-09-02T11:46:56Z,"It is the `unshare` binary:

* tested Kernel 4.18.5 on the same Debian8 with ZFS 0.7.9+0.7.10 patches without issues.
* copied `unshare` from Fedora24 to the same Debian8 and it reproduced the issue
* copied `unshare` from Ubuntu16 to the same Debian8 and it reproduced the issue

""util-linux"" versions:

Distribution | Version
 --- | --- 
Debian8 | 2.25.2-6
Ubuntu16	| 2.27.1-6ubuntu3.3
Fedora24 | 2.28.2-1.fc24

By default newer versions execute an additional

```mount(""none"", ""/"", NULL, MS_REC|MS_PRIVATE, NULL)```

when unsharing the mount namespace : specifying `--propagation unchanged` (default is `private`) seems to avoid this specific issue. The man page confirm this:

>        mount namespace
>              Mounting and unmounting filesystems will not affect the rest of the system (CLONE_NEWNS flag), except for filesystems which are explicitly marked as  shared  (with  mount  --make-shared;  see
>              /proc/self/mountinfo or findmnt -o+PROPAGATION for the shared flags).
>
>              unshare since util-linux version 2.27 automatically sets propagation to private in a new mount namespace to make sure that the new namespace is really unshared.  It's possible to disable this
>              feature with option --propagation unchanged.  Note that private is the kernel default.

The issue here is we don't get to properly cleanup all the references (`zfs_snapshots_by_name` and `zfs_snapshots_by_objsetid` avl trees) to the mounted snapshot when we (auto)umount the one in the ""parent"" namespace.

The cleanup code path is `deactivate_super -> deactivate_locked_super -> zpl_kill_sb -> zfs_preumount -> zfsctl_destroy -> zfsctl_snapshot_remove`. With a cloned, private namespace `zpl_kill_sb` is never called because we hold an additional reference (`sb->s_active`) to the mounted snapshot.

Tracing relevant function calls via systemtap, without private mount:

```
 -> call_usermodehelper ""/usr/bin/env"" ""umount"" ""-t"" ""zfs"" ""-n"" ""/testpool/fs/.zfs/snapshot/snap""           (null)
 cleanup_mnt <- deactivate_super
 kretprobe_trampoline -> deactivate_super {.counter=2}
 task_work_run <- deactivate_super
 cleanup_mnt <- deactivate_super
 kretprobe_trampoline -> deactivate_super {.counter=1}
 kretprobe_trampoline <- deactivate_locked_super
 deactivate_locked_super <- zpl_kill_sb
 zfsctl_destroy -> zfsctl_snapshot_remove se={.se_name=""testpool/fs@snap"", .se_path=""/testpool/fs/.zfs/snapshot/snap"", ....
 zfs_preumount <- zfsctl_snapshot_remove 
 kretprobe_trampoline <- zpl_kill_sb
 task_work_run <- deactivate_locked_super
 task_work_run <- deactivate_super
```

and with private mount:

```
 -> call_usermodehelper ""/usr/bin/env"" ""umount"" ""-t"" ""zfs"" ""-n"" ""/testpool/fs/.zfs/snapshot/snap""           (null)
 cleanup_mnt <- deactivate_super
 kretprobe_trampoline -> deactivate_super {.counter=2}
 task_work_run <- deactivate_super
```
this is confirmed by the fact that we keep trying to umount the snapshot on the parent namespace (because after a ""failed"" umount we get ""rescheduled"" in `snapentry_expire`):

```
 -> call_usermodehelper ""/usr/bin/env"" ""umount"" ""-t"" ""zfs"" ""-n"" ""/testpool/fs/.zfs/snapshot/snap""           (null)
 cleanup_mnt <- deactivate_super
 kretprobe_trampoline -> deactivate_super {.counter=2}
 task_work_run <- deactivate_super
 -> call_usermodehelper ""/usr/bin/env"" ""umount"" ""-t"" ""zfs"" ""-n"" ""/testpool/fs/.zfs/snapshot/snap""           (null)
 -> call_usermodehelper ""/usr/bin/env"" ""umount"" ""-t"" ""zfs"" ""-n"" ""/testpool/fs/.zfs/snapshot/snap""           (null)
 -> call_usermodehelper ""/usr/bin/env"" ""umount"" ""-t"" ""zfs"" ""-n"" ""/testpool/fs/.zfs/snapshot/snap""           (null)
 -> call_usermodehelper ""/usr/bin/env"" ""umount"" ""-t"" ""zfs"" ""-n"" ""/testpool/fs/.zfs/snapshot/snap""           (null)
 -> call_usermodehelper ""/usr/bin/env"" ""umount"" ""-t"" ""zfs"" ""-n"" ""/testpool/fs/.zfs/snapshot/snap""           (null)
 -> call_usermodehelper ""/usr/bin/env"" ""umount"" ""-t"" ""zfs"" ""-n"" ""/testpool/fs/.zfs/snapshot/snap""           (null)
 -> call_usermodehelper ""/usr/bin/env"" ""umount"" ""-t"" ""zfs"" ""-n"" ""/testpool/fs/.zfs/snapshot/snap""           (null)
 -> call_usermodehelper ""/usr/bin/env"" ""umount"" ""-t"" ""zfs"" ""-n"" ""/testpool/fs/.zfs/snapshot/snap""           (null)
 -> call_usermodehelper ""/usr/bin/env"" ""umount"" ""-t"" ""zfs"" ""-n"" ""/testpool/fs/.zfs/snapshot/snap""           (null)
 -> call_usermodehelper ""/usr/bin/env"" ""umount"" ""-t"" ""zfs"" ""-n"" ""/testpool/fs/.zfs/snapshot/snap""           (null)
 -> call_usermodehelper ""/usr/bin/env"" ""umount"" ""-t"" ""zfs"" ""-n"" ""/testpool/fs/.zfs/snapshot/snap""           (null)
 -> call_usermodehelper ""/usr/bin/env"" ""umount"" ""-t"" ""zfs"" ""-n"" ""/testpool/fs/.zfs/snapshot/snap""           (null)
 -> call_usermodehelper ""/usr/bin/env"" ""umount"" ""-t"" ""zfs"" ""-n"" ""/testpool/fs/.zfs/snapshot/snap""           (null)
 -> call_usermodehelper ""/usr/bin/env"" ""umount"" ""-t"" ""zfs"" ""-n"" ""/testpool/fs/.zfs/snapshot/snap""           (null)
 -> call_usermodehelper ""/usr/bin/env"" ""umount"" ""-t"" ""zfs"" ""-n"" ""/testpool/fs/.zfs/snapshot/snap""           (null)
```
",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/418616955,Mount namespaces can make ZFS snapshots not automountable by normal processes,brandonhaberfeld,15,355385564,10,418616955,0,417924984,2018-09-05T06:42:00Z,Would this be the root cause of the ELOOP error which ultimately cause the issues in #7764 fixed in #7864 ?,False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/419301548,Mount namespaces can make ZFS snapshots not automountable by normal processes,lundman,15,355385564,11,419301548,0,418616955,2018-09-07T02:33:34Z,"We have this problem with snapshot where we get `ELOOP` error, which could be related to this bug report. Is there an easy way to test if we are having this problem? How do we pass `--propagation unchanged` to `unshare` to see if it stops happening?

",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/679586519,Mount namespaces can make ZFS snapshots not automountable by normal processes,stale[bot],15,355385564,12,679586519,0,419301548,2020-08-25T04:21:43Z,"This issue has been automatically marked as ""stale"" because it has not had any activity for a while. It will be closed in 90 days if no further activity occurs.  Thank you for your contributions.
",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/699136511,Mount namespaces can make ZFS snapshots not automountable by normal processes,coolhaircut,15,355385564,13,699136511,0,679586519,2020-09-25T20:21:54Z,"The disk device type now specifies the `propagation` key which seems like it would resolve this and several related issues. Probably can be proactively closed as resolved before autoclosed as stale.

Can you confirm this fixes @siebenmann ?",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/702815769,Mount namespaces can make ZFS snapshots not automountable by normal processes,siebenmann,15,355385564,14,702815769,0,699136511,2020-10-02T15:58:19Z,"I will need to build a test environment and rebuild my familiarity with this bug, so it will be a few days before I can give you an answer here.",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/729796658,Mount namespaces can make ZFS snapshots not automountable by normal processes,siebenmann,15,355385564,15,729796658,0,702815769,2020-11-18T16:31:57Z,"The current state of git tip on Fedora 32 is confusing me but the issue is still present; the snapshot remains mounted in the second namespace even if it has been unmounted in the PID 1 namespace. Under some circumstances the snapshot seems to also remain mounted in the PID 1 namespace even though the timer has theoretically expired, but if I set a fast enough unmount time in @loli10K 's ZFS test script, I can see the snapshot mount  disappear and then attempting to access it gets the same error. When the snapshot remains mounted in the PID 1 namespace, it appears to become slow to automatically unmount or perhaps doesn't really automatically unmount at all any more (I've waited several multiples of a 50 second unmount timeout and it is still mounted).

(With the script's timing settings of a 50 second unmount timer and a 60 second sleep, the snapshot remains mounted in the PID 1 namespace. With a 15 second timeount it doesn't, although it stays mounted in the unshared namespace.)",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/973201729,Mount namespaces can make ZFS snapshots not automountable by normal processes,stale[bot],15,355385564,16,973201729,0,729796658,2021-11-18T19:44:54Z,"This issue has been automatically marked as ""stale"" because it has not had any activity for a while. It will be closed in 90 days if no further activity occurs.  Thank you for your contributions.
",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/7850,DKMS package is looking pretty in Ubuntu,Redsandro,3,355578053,1,355578053,0,0,2018-08-30T13:09:45Z,"### System information
Type | Version/Name
 --- | --- 
Distribution Name	| Ubuntu, Linux Mint
Distribution Version	| 16.04 LTS, 18.04 LTS, Linux Mint 18, Linux Mint 19
Linux Kernel	| 4.9.0 up to 4.15.0
Architecture	| x86_64
ZFS Version	| 0.7.*
SPL Version	| 0.7.*

### Describe the problem you're observing

There is this issue that I'm observing with different ZFS- and Linux versions since I started to compile from master. Everything works. However, I do need to manually recompile on every kernel update. I assume the DKMS package is supposed to handle this, but, well, it doesn't (on my test environments).

I'm wondering if I'm missing a step; if the documentation (see below) might be outdated or incomplete. Perhaps there's this one obvious undocumented prerequisite for making this work that I'm just oblivious about.

Note that there are no error messages during compilation or installing the .deb packages.

### Describe how to reproduce the problem

After compiling as described in the [Building ZFS](https://github.com/zfsonlinux/zfs/wiki/Building-ZFS) section with `make deb` as the final step, you end up with a couple of packages including a [DKMS package](https://github.com/zfsonlinux/zfs/wiki/Custom-Packages).

The instructions end there, so here's that obvious step I might be doing wrong:

```
# SPL
for i in *.deb; do gdebi $i; done

# ZFS
for i in lib*.deb; do gdebi $i; done
for i in zfs*.deb; do gdebi $i; done
echo zfs >> /etc/modules
modprobe zfs
```

Please note that everything is working fine, except for DKMS. I have to recompile after every kernel upgrade.

---

I'm also wondering if these steps can be simplified by a single line as mentioned in the [Casual Build Instructions](https://github.com/zfsonlinux/pkg-zfs#casual-build-instructions), but I haven't touched that yet, because (almost) everything is working and I don't want to jeopardize that by running steps I don't really understand.",True,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/417432661,DKMS package is looking pretty in Ubuntu,rincebrain,3,355578053,2,417432661,0,355578053,2018-08-30T19:06:37Z,"You may notice that the packaging there hasn't been updated in 3 years.

Also, the instructions don't include ""install the packages"" because some people need different packages.

This would be better asked and answered on a mailing list or IRC than here, because it doesn't immediately appear to be a bug in the packages themselves or the documentation.",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/426276305,DKMS package is looking pretty in Ubuntu,Redsandro,3,355578053,3,426276305,0,417432661,2018-10-02T13:36:56Z,"> Perhaps there's this one obvious undocumented prerequisite for making this work that I'm just oblivious about.

I think the problem is that the suggested `make deb` creates conflicting packages. The docs aren't clear (enough) about what packages need to be installed when. The answer (for DKMS) is `deb-utils` and `deb-dkms`.

For completeness, this is how I got ZFS on Linux running (with DKMS) on Linux Mint 19 and Ubuntu 18.04.

## Building and installing ZFS+DKMS

```bash
wget https://github.com/zfsonlinux/zfs/releases/download/zfs-0.8.0-rc1/zfs-0.8.0-rc1.tar.gz
tar -xzf zfs-0.8.0-rc1.tar.gz
mv zfs-0.8.0{,-rc1}
cd zfs-0.8.0-rc1
./configure
make -s -j$(nproc) && make deb-utils deb-dkms && spd-say ""ZFS packages are ready"" || spd-say ""ZFS compilation error""
for DEB in *.deb; do gdebi --non-interactive $DEB; done
```

> __Note:__ `spd-say` is unnecessary. I use it so I don't have to keep track of the progress. It provides an audio cue for when the compilation is finished (or failed).

## Enable ZFS now

So you don't have to reboot before using ZFS.

```bash
sudo modprobe zfs
```

## Enable services

So your pools and shares are there after a reboot.

```bash
sudo systemctl enable zfs-import-cache
sudo systemctl enable zfs-import-scan
sudo systemctl enable zfs-import.target
sudo systemctl enable zfs-mount
sudo systemctl enable zfs-share
sudo systemctl enable zfs-zed
sudo systemctl enable zfs.target
```

---

It is worth noting that these (simplified) steps work only from `zfs-0.8.0-rc1` and up, because:

> As of this release the spl is included in the zfs tarball and is no longer provided separately.

This helps, because for the separate spl compilation step and referencing the result, there were also many different examples, which made it confusing to choose how to compile the two to someone who doesn't exactly know _how_ it should be used.

Thanks to whomever decided to integrate the two, so we can now use one `make` command. I think it was @behlendorf. :+1: 

---

My final question would be: Why do we have to modprobe and enable all these services? deb packages should be able to take care of this. Are there build switches to instruct the deb packages to do all this for us, so the steps could be even simpler?

Either way, I'm leaving this open. I know how to build things properly now, but the documentation still needs maintenance by someone who knows what is actually obsolete and what is important.

Perhaps the 0.8 release branch is a nice moment to revamp (the compilation/installation part of) the documentation.",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/679457067,DKMS package is looking pretty in Ubuntu,stale[bot],3,355578053,4,679457067,0,426276305,2020-08-25T01:58:59Z,"This issue has been automatically marked as ""stale"" because it has not had any activity for a while. It will be closed in 90 days if no further activity occurs.  Thank you for your contributions.
",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/7852,Add zfs_arc_shrinker_enabled module option,behlendorf,5,355735509,1,355735509,0,0,2018-08-30T20:09:14Z,"### Motivation and Context

Investigate ARC collapse described in issue #7820.  

### Description

The idea here is to allow the `arc_reclaim` thread to solely manage
the indirect memory reclaim from the ARC.  Only direct memory reclaim
requests by the kernel will result in memory being freed.  These
indicate that the kernel needs memory immediately and should not
be ignored by the ARC.

When disabled this should prevent the ARC from collapsing due to
the shrinker.  By default, the indirect shrinker remains enabling
and there is no change is behavior pending performance results.

### How Has This Been Tested?

Locally built, pending additional performance analysis.  Submitted to buildbot for additional test coverage.

### Types of changes
<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->
- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] New feature (non-breaking change which adds functionality)
- [x] Performance enhancement (non-breaking change which improves efficiency)
- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)
- [ ] Breaking change (fix or feature that would cause existing functionality to change)
- [ ] Documentation (a change to man pages or other documentation)

### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [x] My code follows the ZFS on Linux [code style requirements](https://github.com/zfsonlinux/zfs/blob/master/.github/CONTRIBUTING.md#coding-conventions).
- [x] I have updated the documentation accordingly.
- [x] I have read the [**contributing** document](https://github.com/zfsonlinux/zfs/blob/master/.github/CONTRIBUTING.md).
- [ ] I have added [tests](https://github.com/zfsonlinux/zfs/tree/master/tests) to cover my changes.
- [ ] All new and existing tests passed.
- [x] All commit messages are properly formatted and contain [`Signed-off-by`](https://github.com/zfsonlinux/zfs/blob/master/.github/CONTRIBUTING.md#signed-off-by).
- [ ] Change has been approved by a ZFS on Linux member.
",True,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/417472570,Add zfs_arc_shrinker_enabled module option,richardelling,5,355735509,2,417472570,0,355735509,2018-08-30T21:26:29Z,"I have tested this on a representative and reproducible workload: create a zvol and fill it.
On the left is ""before"" (zfs_arc_shrinker_enabled=1) and right is ""after"" (zfs_arc_shrinker_enabled=0)
![image](https://user-images.githubusercontent.com/867533/44880203-a3d0ad00-ac60-11e8-92aa-791724ef2fc7.png)
 ",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/417475097,Add zfs_arc_shrinker_enabled module option,behlendorf,5,355735509,3,417475097,0,417472570,2018-08-30T21:37:03Z,"Thanks for the speedy testing results.  Interestingly, I checked our systems and we haven't observed the bad ARC behavior with the 3.10 CentOS/RHEL kernel.  So this may only impact newer kernels.  Since this PR does not change the default behavior at all we'll pull it in to master and 0.7.10.  Then it will be easily available for those who need it and the performance analyzed.",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/417510657,Add zfs_arc_shrinker_enabled module option,behlendorf,5,355735509,4,417510657,0,417475097,2018-08-31T00:27:56Z,"Yes of course, added.",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/417845183,Add zfs_arc_shrinker_enabled module option,codecov[bot],5,355735509,5,417845183,0,417510657,2018-09-01T09:13:10Z,"# [Codecov](https://codecov.io/gh/zfsonlinux/zfs/pull/7852?src=pr&el=h1) Report
> Merging [#7852](https://codecov.io/gh/zfsonlinux/zfs/pull/7852?src=pr&el=desc) into [master](https://codecov.io/gh/zfsonlinux/zfs/commit/e927fc8a522e1c0db89955cc555841aa23bbd634?src=pr&el=desc) will **increase** coverage by `0.2%`.
> The diff coverage is `100%`.

[![Impacted file tree graph](https://codecov.io/gh/zfsonlinux/zfs/pull/7852/graphs/tree.svg?width=650&token=NGfxvvG2io&height=150&src=pr)](https://codecov.io/gh/zfsonlinux/zfs/pull/7852?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##           master    #7852     +/-   ##
=========================================
+ Coverage    78.3%   78.51%   +0.2%     
=========================================
  Files         374      374             
  Lines      112935   112936      +1     
=========================================
+ Hits        88439    88667    +228     
+ Misses      24496    24269    -227
```

| Flag | Coverage Δ | |
|---|---|---|
| #kernel | `78.8% <100%> (+0.03%)` | :arrow_up: |
| #user | `67.65% <ø> (+0.28%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/zfsonlinux/zfs/pull/7852?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/zfsonlinux/zfs/pull/7852?src=pr&el=footer). Last update [e927fc8...9be368a](https://codecov.io/gh/zfsonlinux/zfs/pull/7852?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/418803029,Add zfs_arc_shrinker_enabled module option,behlendorf,5,355735509,6,418803029,0,417845183,2018-09-05T16:54:30Z,Closing since this doesn't address the root cause.  Additional investigation is needed.,False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/7853,Allow ECKSUM in vdev_checkpoint_sm_object(),behlendorf,8,355761141,1,355761141,0,0,2018-08-30T21:28:49Z,"### Motivation and Context

Resolve #7809, which has been observed during automated testing.
The proposed fix does revert the change to log the error number,
but it's the cleanest way to keep the check.

### Description

The checkpoint space map object may not be accessible from the
vdev's ZAP when it has been damaged.  This may be the case when
when rewinding the pool a large number of TXGs or when the pool
has been damaged.

### How Has This Been Tested?

Locally compiled.  Pending buildbot results.

### Types of changes
<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->
- [x] Bug fix (non-breaking change which fixes an issue)
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Performance enhancement (non-breaking change which improves efficiency)
- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)
- [ ] Breaking change (fix or feature that would cause existing functionality to change)
- [ ] Documentation (a change to man pages or other documentation)

### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [x] My code follows the ZFS on Linux [code style requirements](https://github.com/zfsonlinux/zfs/blob/master/.github/CONTRIBUTING.md#coding-conventions).
- [ ] I have updated the documentation accordingly.
- [x] I have read the [**contributing** document](https://github.com/zfsonlinux/zfs/blob/master/.github/CONTRIBUTING.md).
- [ ] I have added [tests](https://github.com/zfsonlinux/zfs/tree/master/tests) to cover my changes.
- [x] All new and existing tests passed.
- [x] All commit messages are properly formatted and contain [`Signed-off-by`](https://github.com/zfsonlinux/zfs/blob/master/.github/CONTRIBUTING.md#signed-off-by).
- [ ] Change has been approved by a ZFS on Linux member.
",True,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/417486105,Allow ECKSUM in vdev_checkpoint_sm_object(),sdimitro,8,355761141,2,417486105,0,355761141,2018-08-30T22:21:01Z,"Also, as I was rereading the description of the bug -> `This may be the case when rewinding the pool a large number of TXGs or ..`.

By `rewinding` do you mean using the checkpoint's rewind functionality or pool import extreme rewind? Checkpoint rewind is not supposed to be limited by the number of TXGs.",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/417489829,Allow ECKSUM in vdev_checkpoint_sm_object(),behlendorf,8,355761141,3,417489829,0,417486105,2018-08-30T22:37:42Z,"@sdimitro I could have worded that more clearly.  The one instance I have of this failing was from the bots and it was during the `import_rewind_config_changed` test.  So it was doing an extreme pool rewind to a specific TXG and checksum failures are not unexpected, as noted by the comment:

```
# DISCLAIMER:
#       This test can fail since nothing guarantees that old MOS blocks aren't
#       overwritten. Snapshots protect datasets and data files but not the MOS.
#       sync_some_data_a_few_times interleaves file data and MOS data for a few
#       txgs, thus increasing the odds that some txgs will have their MOS data
#       left untouched.
```",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/417490342,Allow ECKSUM in vdev_checkpoint_sm_object(),sdimitro,8,355761141,4,417490342,0,417489829,2018-08-30T22:39:53Z,That makes sense. Thanks for jumping on this Brian,False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/417492647,Allow ECKSUM in vdev_checkpoint_sm_object(),behlendorf,8,355761141,5,417492647,0,417490342,2018-08-30T22:51:06Z,@sdimitro thanks for the speedy review!  I've refreshed the PR as requested and cleared up the wording in the commit message.,False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/417782302,Allow ECKSUM in vdev_checkpoint_sm_object(),behlendorf,8,355761141,6,417782302,0,417492647,2018-08-31T20:35:47Z,"@dweeezil good thought, I've reordered it.",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/417802702,Allow ECKSUM in vdev_checkpoint_sm_object(),sdimitro,8,355761141,7,417802702,0,417782302,2018-08-31T22:14:43Z,"As a question for future reference: How does this reordering help in terms of the information being provided?

If we were to have a panic due to the assertion before showing the `vdev_dbgmsg`, wouldn't we have the exact same info from the assertion? (e.g. both the value of `err` and the codepath that got us there from the stacktrace)",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/417814594,Allow ECKSUM in vdev_checkpoint_sm_object(),behlendorf,8,355761141,8,417814594,0,417802702,2018-08-31T23:40:42Z,On Linux when the assertion is hit by default only the offending thread is halted.  The entire system will not panic unless `/sys/module/spl/parameters/spl/spl_panic_halt` is set.  Putting the  `vdev_dbgmsg()` first allows you to potentially extract the full internal debug log from the system with the error and additional information about the vdev.  This might be useful if the console log was disabled. wrapped or otherwise lost.,False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/417835259,Allow ECKSUM in vdev_checkpoint_sm_object(),codecov[bot],8,355761141,9,417835259,0,417814594,2018-09-01T05:47:47Z,"# [Codecov](https://codecov.io/gh/zfsonlinux/zfs/pull/7853?src=pr&el=h1) Report
> Merging [#7853](https://codecov.io/gh/zfsonlinux/zfs/pull/7853?src=pr&el=desc) into [master](https://codecov.io/gh/zfsonlinux/zfs/commit/adb726eb0ed69e7331ddd308da8fec9316f6426d?src=pr&el=desc) will **increase** coverage by `0.03%`.
> The diff coverage is `33.33%`.

[![Impacted file tree graph](https://codecov.io/gh/zfsonlinux/zfs/pull/7853/graphs/tree.svg?width=650&token=NGfxvvG2io&height=150&src=pr)](https://codecov.io/gh/zfsonlinux/zfs/pull/7853?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master    #7853      +/-   ##
==========================================
+ Coverage   78.44%   78.47%   +0.03%     
==========================================
  Files         374      374              
  Lines      112934   112936       +2     
==========================================
+ Hits        88588    88624      +36     
+ Misses      24346    24312      -34
```

| Flag | Coverage Δ | |
|---|---|---|
| #kernel | `78.68% <33.33%> (-0.12%)` | :arrow_down: |
| #user | `67.7% <33.33%> (+0.25%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/zfsonlinux/zfs/pull/7853?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/zfsonlinux/zfs/pull/7853?src=pr&el=footer). Last update [adb726e...36d1670](https://codecov.io/gh/zfsonlinux/zfs/pull/7853?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/7946,task txg_sync:4579 blocked for more than 120 seconds,jumbi77,7,362900347,1,362900347,0,0,2018-09-22T23:58:10Z,"<!--
Thank you for reporting an issue.

*IMPORTANT* - Please search our issue tracker *before* making a new issue.
If you cannot find a similar issue, then create a new issue.
https://github.com/zfsonlinux/zfs/issues 

*IMPORTANT* - This issue tracker is for *bugs* and *issues* only.
Please search the wiki and the mailing list archives before asking 
questions on the mailing list.
https://github.com/zfsonlinux/zfs/wiki/Mailing-Lists

Please fill in as much of the template as possible.
-->

### System information
<!--  add version after ""|"" character -->
Type | Version/Name
 --- | --- 
Distribution Name	|  Proxmox
Distribution Version	| 5.2-2
Linux Kernel	| Linux proxmox 4.15.18-3-pve
Architecture	| x64
ZFS Version	| 0.7.9-pve1~bpo9
SPL Version	| 0.7.9-pve1~bpo9
<!-- 
Commands to find ZFS/SPL versions:
modinfo zfs | grep -iw version
modinfo spl | grep -iw version 
-->

### Describe the problem you're observing

I have a zpool with a single drive (ata-ST3000DM001) and some datasets. One dataset is used for downloading big iso and tar files. Downloadspeed is at around 25-30 mb/s, because i set copies=2 i guess the hdd has to handle about 60 mb/s of writes (which should be not to much data for the hdd). After beginning the write load (downloading) i almost always get some call traces after 1-3 minutes. If i manually limit the download speed at around 11 mb/s or set copies=1 no call traces appears. So what is causing the error? Is the hdd to slow (which i dont expect) or is it zfs related? I can reproduce the call trace and can log some other metrics if you want.
Thanks

### Include any warning/errors/backtraces from the system logs
<!-- 
*IMPORTANT* - Please mark logs and text output from terminal commands 
or else Github will not display them correctly. 
An example is provided below.

Example:
```
this is an example how log text should be marked (wrap it with ```)
```
-->

DMESG output:
```
[53893.145953] INFO: task txg_sync:4579 blocked for more than 120 seconds.
[53893.145975]       Tainted: P           O     4.15.18-3-pve #1
[53893.145987] ""echo 0 > /proc/sys/kernel/hung_task_timeout_secs"" disables this message.
[53893.146005] txg_sync        D    0  4579      2 0x80000000
[53893.146006] Call Trace:
[53893.146013]  __schedule+0x3e0/0x870
[53893.146015]  schedule+0x36/0x80
[53893.146017]  io_schedule+0x16/0x40
[53893.146023]  cv_wait_common+0xb2/0x140 [spl]
[53893.146025]  ? wait_woken+0x80/0x80
[53893.146027]  __cv_wait_io+0x18/0x20 [spl]
[53893.146062]  zio_wait+0x103/0x1b0 [zfs]
[53893.146081]  dsl_pool_sync+0xb8/0x430 [zfs]
[53893.146103]  spa_sync+0x42d/0xd50 [zfs]
[53893.146125]  txg_sync_thread+0x2d4/0x4a0 [zfs]
[53893.146147]  ? txg_quiesce_thread+0x3f0/0x3f0 [zfs]
[53893.146149]  thread_generic_wrapper+0x74/0x90 [spl]
[53893.146151]  kthread+0x105/0x140
[53893.146153]  ? __thread_exit+0x20/0x20 [spl]
[53893.146155]  ? kthread_create_worker_on_cpu+0x70/0x70
[53893.146157]  ret_from_fork+0x35/0x40
[53893.146273] INFO: task java:2481 blocked for more than 120 seconds.
[53893.146288]       Tainted: P           O     4.15.18-3-pve #1
[53893.146300] ""echo 0 > /proc/sys/kernel/hung_task_timeout_secs"" disables this message.
[53893.146317] java            D    0  2481  24602 0x00000120
[53893.146318] Call Trace:
[53893.146320]  __schedule+0x3e0/0x870
[53893.146322]  schedule+0x36/0x80
[53893.146323]  io_schedule+0x16/0x40
[53893.146326]  cv_wait_common+0xb2/0x140 [spl]
[53893.146327]  ? wait_woken+0x80/0x80
[53893.146330]  __cv_wait_io+0x18/0x20 [spl]
[53893.146352]  zio_wait+0x103/0x1b0 [zfs]
[53893.146374]  zil_commit.part.14+0x4df/0x8b0 [zfs]
[53893.146395]  zil_commit+0x17/0x20 [zfs]
[53893.146416]  zfs_fsync+0x77/0xf0 [zfs]
[53893.146437]  zpl_fsync+0x68/0xa0 [zfs]
[53893.146439]  vfs_fsync_range+0x51/0xb0
[53893.146440]  do_fsync+0x3d/0x70
[53893.146441]  SyS_fsync+0x10/0x20
[53893.146443]  do_syscall_64+0x73/0x130
[53893.146444]  entry_SYSCALL_64_after_hwframe+0x3d/0xa2
[53893.146446] RIP: 0033:0x7fd25cbfbad0
[53893.146446] RSP: 002b:00007fd238277340 EFLAGS: 00000293 ORIG_RAX: 000000000000004a
[53893.146447] RAX: ffffffffffffffda RBX: 000000000000006e RCX: 00007fd25cbfbad0
[53893.146448] RDX: 0000000000000000 RSI: 00007fd2382773f8 RDI: 000000000000006e
[53893.146449] RBP: 00007fd238277370 R08: 0000000671ba4f48 R09: 00000006000f4c78
[53893.146449] R10: 0000000000003658 R11: 0000000000000293 R12: 0000000000000001
[53893.146450] R13: 00007fd2592b63e8 R14: 00007fd2382773f8 R15: 00007fd188042000
[54255.649091] INFO: task txg_sync:4579 blocked for more than 120 seconds.
[54255.649143]       Tainted: P           O     4.15.18-3-pve #1
[54255.649220] ""echo 0 > /proc/sys/kernel/hung_task_timeout_secs"" disables this message.
[54255.649295] txg_sync        D    0  4579      2 0x80000000
[54255.649297] Call Trace:
[54255.649305]  __schedule+0x3e0/0x870
[54255.649307]  schedule+0x36/0x80
[54255.649309]  io_schedule+0x16/0x40
[54255.649317]  cv_wait_common+0xb2/0x140 [spl]
[54255.649321]  ? wait_woken+0x80/0x80
[54255.649327]  __cv_wait_io+0x18/0x20 [spl]
[54255.649373]  zio_wait+0x103/0x1b0 [zfs]
[54255.649405]  dsl_pool_sync+0xb8/0x430 [zfs]
[54255.649439]  spa_sync+0x42d/0xd50 [zfs]
[54255.649475]  txg_sync_thread+0x2d4/0x4a0 [zfs]
[54255.649509]  ? txg_quiesce_thread+0x3f0/0x3f0 [zfs]
[54255.649514]  thread_generic_wrapper+0x74/0x90 [spl]
[54255.649517]  kthread+0x105/0x140
[54255.649521]  ? __thread_exit+0x20/0x20 [spl]
[54255.649523]  ? kthread_create_worker_on_cpu+0x70/0x70
[54255.649525]  ret_from_fork+0x35/0x40
[54255.649627] INFO: task java:22601 blocked for more than 120 seconds.
[54255.649652]       Tainted: P           O     4.15.18-3-pve #1
[54255.649672] ""echo 0 > /proc/sys/kernel/hung_task_timeout_secs"" disables this message.
[54255.649697] java            D    0 22601  24602 0x00000120
[54255.649699] Call Trace:
[54255.649702]  __schedule+0x3e0/0x870
[54255.649704]  schedule+0x36/0x80
[54255.649705]  io_schedule+0x16/0x40
[54255.649710]  cv_wait_common+0xb2/0x140 [spl]
[54255.649712]  ? wait_woken+0x80/0x80
[54255.649716]  __cv_wait_io+0x18/0x20 [spl]
[54255.649742]  zio_wait+0x103/0x1b0 [zfs]
[54255.649765]  zil_commit.part.14+0x4df/0x8b0 [zfs]
[54255.649787]  zil_commit+0x17/0x20 [zfs]
[54255.649808]  zfs_fsync+0x77/0xf0 [zfs]
[54255.649830]  zpl_fsync+0x68/0xa0 [zfs]
[54255.649832]  vfs_fsync_range+0x51/0xb0
[54255.649833]  do_fsync+0x3d/0x70
[54255.649834]  SyS_fsync+0x10/0x20
[54255.649837]  do_syscall_64+0x73/0x130
[54255.649838]  entry_SYSCALL_64_after_hwframe+0x3d/0xa2
[54255.649839] RIP: 0033:0x7fd25cbfbad0
[54255.649840] RSP: 002b:00007fd1c7afb340 EFLAGS: 00000293 ORIG_RAX: 000000000000004a
[54255.649841] RAX: ffffffffffffffda RBX: 000000000000006e RCX: 00007fd25cbfbad0
[54255.649842] RDX: 0000000000000000 RSI: 00007fd1c7afb3f8 RDI: 000000000000006e
[54255.649842] RBP: 00007fd1c7afb370 R08: 00000005fffce188 R09: 00000005c98a36c8
[54255.649843] R10: 00000000000036de R11: 0000000000000293 R12: 0000000000000001
[54255.649843] R13: 00007fd2592b63e8 R14: 00007fd1c7afb3f8 R15: 00007fd18800c800
[54376.483434] INFO: task txg_sync:4579 blocked for more than 120 seconds.
[54376.483455]       Tainted: P           O     4.15.18-3-pve #1
[54376.483468] ""echo 0 > /proc/sys/kernel/hung_task_timeout_secs"" disables this message.
[54376.483485] txg_sync        D    0  4579      2 0x80000000
[54376.483487] Call Trace:
[54376.483493]  __schedule+0x3e0/0x870
[54376.483495]  schedule+0x36/0x80
[54376.483497]  io_schedule+0x16/0x40
[54376.483503]  cv_wait_common+0xb2/0x140 [spl]
[54376.483505]  ? wait_woken+0x80/0x80
[54376.483508]  __cv_wait_io+0x18/0x20 [spl]
[54376.483540]  zio_wait+0x103/0x1b0 [zfs]
[54376.483559]  dsl_pool_sync+0xb8/0x430 [zfs]
[54376.483581]  spa_sync+0x42d/0xd50 [zfs]
[54376.483603]  txg_sync_thread+0x2d4/0x4a0 [zfs]
[54376.483625]  ? txg_quiesce_thread+0x3f0/0x3f0 [zfs]
[54376.483628]  thread_generic_wrapper+0x74/0x90 [spl]
[54376.483630]  kthread+0x105/0x140
[54376.483632]  ? __thread_exit+0x20/0x20 [spl]
[54376.483634]  ? kthread_create_worker_on_cpu+0x70/0x70
[54376.483635]  ret_from_fork+0x35/0x40
[54376.483740] INFO: task java:22601 blocked for more than 120 seconds.
[54376.483753]       Tainted: P           O     4.15.18-3-pve #1
[54376.483766] ""echo 0 > /proc/sys/kernel/hung_task_timeout_secs"" disables this message.
[54376.483781] java            D    0 22601  24602 0x00000124
[54376.483783] Call Trace:
[54376.483784]  __schedule+0x3e0/0x870
[54376.483786]  schedule+0x36/0x80
[54376.483787]  io_schedule+0x16/0x40
[54376.483790]  cv_wait_common+0xb2/0x140 [spl]
[54376.483791]  ? wait_woken+0x80/0x80
[54376.483794]  __cv_wait_io+0x18/0x20 [spl]
[54376.483834]  zio_wait+0x103/0x1b0 [zfs]
[54376.483864]  zil_commit.part.14+0x4df/0x8b0 [zfs]
[54376.483920]  zil_commit+0x17/0x20 [zfs]
[54376.483964]  zfs_fsync+0x77/0xf0 [zfs]
[54376.484006]  zpl_fsync+0x68/0xa0 [zfs]
[54376.484010]  vfs_fsync_range+0x51/0xb0
[54376.484012]  do_fsync+0x3d/0x70
[54376.484018]  SyS_fsync+0x10/0x20
[54376.484020]  do_syscall_64+0x73/0x130
[54376.484022]  entry_SYSCALL_64_after_hwframe+0x3d/0xa2
[54376.484024] RIP: 0033:0x7fd25cbfbad0
[54376.484025] RSP: 002b:00007fd1c7afb340 EFLAGS: 00000293 ORIG_RAX: 000000000000004a
[54376.484026] RAX: ffffffffffffffda RBX: 000000000000006e RCX: 00007fd25cbfbad0
[54376.484027] RDX: 0000000000000000 RSI: 00007fd1c7afb3f8 RDI: 000000000000006e
[54376.484028] RBP: 00007fd1c7afb370 R08: 00000005fffce188 R09: 00000005c98a36c8
[54376.484029] R10: 00000000000036de R11: 0000000000000293 R12: 0000000000000001
[54376.484030] R13: 00007fd2592b63e8 R14: 00007fd1c7afb3f8 R15: 00007fd18800c800
[54625.040569] vmbr1: port 13(tap1250i0) entered disabled state
```


ZFS GET ALL mypool/ds1:
```
mypool/ds1  type                   filesystem                 -
mypool/ds1  creation               Mon Feb 12 21:54 2018      -
mypool/ds1  used                   1.97T                      -
mypool/ds1  available              672G                       -
mypool/ds1  referenced             945G                       -
mypool/ds1  compressratio          1.01x                      -
mypool/ds1  mounted                yes                        -
mypool/ds1  quota                  none                       default
mypool/ds1  reservation            none                       default
mypool/ds1  recordsize             1M                         local
mypool/ds1  mountpoint             /mypool/ds1                default
mypool/ds1  sharenfs               off                        default
mypool/ds1  checksum               fletcher4                  local
mypool/ds1  compression            lz4                        local
mypool/ds1  atime                  on                         local
mypool/ds1  devices                on                         default
mypool/ds1  exec                   on                         default
mypool/ds1  setuid                 on                         default
mypool/ds1  readonly               off                        default
mypool/ds1  zoned                  off                        default
mypool/ds1  snapdir                hidden                     default
mypool/ds1  aclinherit             passthrough                local
mypool/ds1  createtxg              28                         -
mypool/ds1  canmount               on                         default
mypool/ds1  xattr                  sa                         local
mypool/ds1  copies                 2                          local
mypool/ds1  version                5                          -
mypool/ds1  utf8only               on                         -
mypool/ds1  normalization          formD                      -
mypool/ds1  casesensitivity        sensitive                  -
mypool/ds1  vscan                  off                        default
mypool/ds1  nbmand                 off                        default
mypool/ds1  sharesmb               off                        default
mypool/ds1  refquota               none                       default
mypool/ds1  refreservation         none                       default
mypool/ds1  guid                   1095692504750449694        -
mypool/ds1  primarycache           all                        local
mypool/ds1  secondarycache         all                        local
mypool/ds1  usedbysnapshots        1.05T                      -
mypool/ds1  usedbydataset          945G                       -
mypool/ds1  usedbychildren         0B                         -
mypool/ds1  usedbyrefreservation   0B                         -
mypool/ds1  logbias                latency                    default
mypool/ds1  dedup                  off                        default
mypool/ds1  mlslabel               none                       default
mypool/ds1  sync                   standard                   default
mypool/ds1  dnodesize              legacy                     default
mypool/ds1  refcompressratio       1.01x                      -
mypool/ds1  written                9.30G                      -
mypool/ds1  logicalused            1.33T                      -
mypool/ds1  logicalreferenced      678G                       -
mypool/ds1  volmode                default                    default
mypool/ds1  filesystem_limit       none                       default
mypool/ds1  snapshot_limit         none                       default
mypool/ds1  filesystem_count       none                       default
mypool/ds1  snapshot_count         none                       default
mypool/ds1  snapdev                hidden                     default
mypool/ds1  acltype                posixacl                   local
mypool/ds1  context                none                       default
mypool/ds1  fscontext              none                       default
mypool/ds1  defcontext             none                       default
mypool/ds1  rootcontext            none                       default
mypool/ds1  relatime               off                        default
mypool/ds1  redundant_metadata     all                        local
mypool/ds1  overlay                off                        default
mypool/ds1  com.sun:auto-snapshot  false                      inherited from mypool
```",True,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/423781842,task txg_sync:4579 blocked for more than 120 seconds,jumbi77,7,362900347,2,423781842,0,362900347,2018-09-23T00:03:50Z,@kpande So i can safely ignore this message although it's a call trace?,False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/423782230,task txg_sync:4579 blocked for more than 120 seconds,jumbi77,7,362900347,3,423782230,0,423781842,2018-09-23T00:13:38Z,"Thanks for the quick answer. Just let me understand it: So when the hdd is somehow too slow to handle that load, does the data still get completely written to disk (it just takes more time than usual) or is the call trace an evidence that not all data is written completely/correctly? thanks in advance",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/424085335,task txg_sync:4579 blocked for more than 120 seconds,behlendorf,7,362900347,4,424085335,0,423782230,2018-09-24T18:54:14Z,"@jumbi77 everything will always be written safely.  The ' blocked for more than 120 seconds' warning indicates that there was a kernel thread blocked for longer than expected.  The warning is advisory, and is useful for debugging/troubleshooting.   It is often caused by a slow disk or oversubscribed subsystem.",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/424119223,task txg_sync:4579 blocked for more than 120 seconds,bunder2015,7,362900347,5,424119223,0,424085335,2018-09-24T20:47:10Z,"Just to clarify, I had considered writing an article on it, but I don't really have much to add to something like [this](https://helpful.knobs-dials.com/index.php/INFO:_task_blocked_for_more_than_120_seconds.), other than to add that `failmode=wait` and the sudden loss of pool disks can also cause this same issue.",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/7947,Relatime is always turned on temporarily on ZFS root.,crocket,25,362997547,1,362997547,0,0,2018-09-24T01:48:52Z,"### System information

Type | Version/Name
 --- | --- 
Distribution Name	| Gentoo
Distribution Version	| None
Linux Kernel	| 4.14.65-gentoo
Architecture	| x86_64
ZFS Version	| 0.7.11-r0-gentoo
SPL Version	| 0.7.11-r0-gentoo

### Describe the problem you're observing

I want to apply noatime to every single mount, but `/` is resisting my will.

```
$ findmnt | grep zfs
/                             os/ROOT/gentoo    zfs         rw,relatime,xattr,noacl
├─/home                       os/HOME           zfs         rw,noatime,xattr,noacl
├─/mnt/data                   user-data/data    zfs         rw,noatime,xattr,posixacl
├─/root                       os/HOME/root      zfs         rw,noatime,xattr,noacl
├─/usr/portage                os/GENTOO/portage zfs         rw,nosuid,noatime,xattr,noacl
```

```
$ cat /proc/mounts | grep zfs
os/ROOT/gentoo / zfs rw,relatime,xattr,noacl 0 0
os/HOME /home zfs rw,noatime,xattr,noacl 0 0
user-data/data /mnt/data zfs rw,noatime,xattr,posixacl 0 0
os/HOME/root /root zfs rw,noatime,xattr,noacl 0 0
os/GENTOO/portage /usr/portage zfs rw,nosuid,noatime,xattr,noacl 0 0
```

```
$ /sbin/zfs get all os/ROOT/gentoo | grep time
os/ROOT/gentoo  atime                 off                    inherited from os
os/ROOT/gentoo  relatime              on                     temporary
```

```
$ cat /etc/fstab
PARTUUID=""e271ef53-7377-0545-9f0e-8467fafd1202"" none swap sw 0 0
PARTUUID=""d5179cfd-ea96-4183-8c0b-9ffc20a9b990"" none swap sw 0 0
tmpfs /var/tmp/portage tmpfs size=14G,uid=portage,gid=portage,mode=775,noatime 0 0
tmpfs /tmp tmpfs size=8G,mode=1777,noatime 0 0
PARTUUID=""7e95e77c-f08c-f34d-a2d3-9d540ff191c4"" /boot btrfs rw,noatime,discard 0 0
PARTUUID=""17485930-4257-41fc-bc1a-5921ea09c2a4"" /boot/efi vfat rw,noatime,discard 0 0
```

```
$ /sbin/zfs list
NAME                           USED  AVAIL  REFER  MOUNTPOINT
os                            63.7G  46.7G    96K  none
os/GENTOO                     33.4G  46.7G    96K  none
os/GENTOO/portage             33.4G  46.7G  33.4G  /usr/portage
os/HOME                       20.9G  46.7G  19.8G  /home
os/HOME/root                  23.5M  46.7G  23.5M  /root
os/ROOT                       9.41G  46.7G    96K  none
os/ROOT/gentoo                9.41G  46.7G  9.41G  /
user-data                     1.23T  1.40T    96K  none
user-data/data                1.23T  1.40T  1.22T  /mnt/data
```

### Describe how to reproduce the problem

Install root on a dataset, and set `bootfs` to that dataset. grub-mkconfig will take care of the rest.",True,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/423870619,Relatime is always turned on temporarily on ZFS root.,crocket,25,362997547,2,423870619,0,362997547,2018-09-24T03:31:57Z,I don't think it is a question. It is an issue that requires modification of zfs.,False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/423871799,Relatime is always turned on temporarily on ZFS root.,rlaager,25,362997547,3,423871799,0,423870619,2018-09-24T03:48:46Z,"I can reproduce this on Ubuntu 18.04 too. Unless we have some universal fix, I think the initramfs script should work around this.",False,0,MEMBER
https://api.github.com/repos/openzfs/zfs/issues/comments/423884739,Relatime is always turned on temporarily on ZFS root.,GregorKopka,25,362997547,4,423884739,0,423871799,2018-09-24T06:19:54Z,"man zpool states:

> When a file system is mounted, either through mount(8) for legacy mounts or the zfs mount command for normal file systems, its mount options are set according to its properties.  The correlation between properties and mount options is as follows:
>
>PROPERTY                MOUNT OPTION
atime                   atime/noatime
canmount                auto/noauto
devices                 dev/nodev
exec                    exec/noexec
readonly                ro/rw
relatime                relatime/norelatime
setuid                  suid/nosuid
xattr                   xattr/noxattr

what's happening is
```
# zfs create tank/test -o atime=off -o canmount=noauto -o readonly=on
# mkdir /tmp/test
# mount -o zfsutil -t zfs tank/test /tmp/test/
# mount | grep test
tank/test on /tmp/test type zfs (rw,relatime,xattr,noacl)
```
The *mount options are set according to its properties* isn't happening as advertised when mounting using mount(8). Also
```
# umount /tmp/test/
# zfs set canmount=off tank/test
# mount -t zfs tank/test /tmp/test/
# mount | grep test
tank/test on /tmp/test type zfs (rw,relatime,xattr,noacl)
```
Which means also 
> canmount=on|off|noauto
If this property is set to off, the file system cannot be mounted, and is ignored by zfs mount -a.

as stated in man zfs isn't enforced (which it should, at least that's what I expect when reading that sentence).",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/423932611,Relatime is always turned on temporarily on ZFS root.,bunder2015,25,362997547,5,423932611,0,423884739,2018-09-24T10:30:02Z,"FWIW, I've seen this on gentoo as well.  I had hacked around it with a local.d script and I don't remember what turns relatime on.

```
#!/bin/bash

# Disable relatime=temporary on pool rootfs
ROOTFS=$(zpool get -o value -H bootfs)

zfs set relatime=off $ROOTFS
```",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/423979961,Relatime is always turned on temporarily on ZFS root.,beren12,25,362997547,6,423979961,0,423932611,2018-09-24T13:46:15Z,"I believe the summary for your issue is: it doesn't matter. If atime is off, relatime has no meaning, because it is also off.",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/424038773,Relatime is always turned on temporarily on ZFS root.,ghfields,25,362997547,7,424038773,0,423979961,2018-09-24T16:30:35Z,"@kpande You are right.  It acts as relatime=on. Confirmed on Ubuntu 18.04 rpool exhibiting the relatime temporary issue.  Of course it returned to noatime after issuing ""mount -o remount -o noatime /""",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/565768206,Relatime is always turned on temporarily on ZFS root.,rlaager,25,362997547,8,565768206,0,424038773,2019-12-15T01:23:51Z,"Basically, we need to revive https://github.com/zfsonlinux/zfs/pull/7948, support the other mount options, and extend that to the initramfs.",False,0,MEMBER
https://api.github.com/repos/openzfs/zfs/issues/comments/932950810,Relatime is always turned on temporarily on ZFS root.,quicktrick,25,362997547,9,932950810,0,565768206,2021-10-03T13:24:43Z,"I confirm the issue on Void Linux. I used the workaround suggested by @bunder2015 : I added to `/etc/rc.local` the following command:

```
zfs set relatime=off $(zpool get -o value -H bootfs)

```",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/943427971,Relatime is always turned on temporarily on ZFS root.,bghira,25,362997547,10,943427971,0,932950810,2021-10-14T14:44:02Z,"i submitted a fix but no one wanted it:

```diff --git a/contrib/dracut/90zfs/zfs-lib.sh.in b/contrib/dracut/90zfs/zfs-lib.sh.in
index 23c07af9e86..9bf80e14599 100755
--- a/contrib/dracut/90zfs/zfs-lib.sh.in
+++ b/contrib/dracut/90zfs/zfs-lib.sh.in
@@ -74,14 +74,22 @@ import_pool() {
 # mount_dataset DATASET
 #   mounts the given zfs dataset.
 mount_dataset() {
-        dataset=""${1}""
+    dataset=""${1}""
     mountpoint=""$(zfs get -H -o value mountpoint ""${dataset}"")""
-
+    mountopts=""strictatime""
+    ATIME_OPTION=$(zfs get -H -o value -s default,local,inherited atime ${dataset})
+    if [ ""${ATIME_OPTION}"" = ""off"" ]; then
+        mountopts=""noatime""
+    fi
+    RELATIME_OPTION=$(zfs get -H -o value -s default,local,inherited relatime ${dataset})
+    if [ ""${RELATIME_OPTION}"" = ""on"" ]; then
+        mountopts=""relatime""
+    fi
     # We need zfsutil for non-legacy mounts and not for legacy mounts.
     if [ ""${mountpoint}"" = ""legacy"" ] ; then
-        mount -t zfs ""${dataset}"" ""${NEWROOT}""
+        mount -t zfs -o ${mountopts} ""${dataset}"" ""${NEWROOT}""
     else
-        mount -o zfsutil -t zfs ""${dataset}"" ""${NEWROOT}""
+        mount -o zfsutil -t zfs -o ${mountopts} ""${dataset}"" ""${NEWROOT}""
     fi
 
     return $?
```

correction: it was viewed as a good idea, but people asked for waaaayyyy too many out-of-scope changes, so I withdrew the PR and said anyone could take the work up who wanted / needed it fixed. I've been maintaining my own local patch for this purpose.

",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/943429298,Relatime is always turned on temporarily on ZFS root.,bghira,25,362997547,11,943429298,0,943427971,2021-10-14T14:45:31Z,"@rlaager assigned it to himself and then did nothing with it, must have forgotten.",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/943444807,Relatime is always turned on temporarily on ZFS root.,rlaager,25,362997547,12,943444807,0,943429298,2021-10-14T15:02:21Z,"That patch looks reasonable.

1. I'm not sure why the `-s default,local,inherited`.
2. I'm not sure how the mounting in `_mount_dataset_cb()` fits into this. Does that need to be modified too?
3. Theoretically, we should support other mount options. The list is: `zfs list -H -o atime,relatime,devices,exec,readonly,setuid,nbmand` That said, I realize that at least exec,readonly,setuid are extremely unlikely to be anything but defaults on the root fs. Though if we are mounting children (see 2 above), that could be different.
4. This is for dracut. We need support in initramfs too. I'm in a position to test that piece, so I can handle that piece if dracut is done.

This is probably what you meant by the change requests?",False,0,MEMBER
https://api.github.com/repos/openzfs/zfs/issues/comments/943446334,Relatime is always turned on temporarily on ZFS root.,bghira,25,362997547,13,943446334,0,943444807,2021-10-14T15:03:58Z,"yep. i just wanted to fix one issue and everyone suggested changes that were well outside of both what i wanted to fix and what i was able to test. i've rewritten my patch for master:

```bash
diff --git a/contrib/dracut/90zfs/zfs-lib.sh.in b/contrib/dracut/90zfs/zfs-lib.sh.in
index defc0bfc8..2e09559d7 100755
--- a/contrib/dracut/90zfs/zfs-lib.sh.in
+++ b/contrib/dracut/90zfs/zfs-lib.sh.in
@@ -76,19 +76,26 @@ _mount_dataset_cb() {
 # mount_dataset DATASET
 #   mounts the given zfs dataset.
 mount_dataset() {
+    ret=0
     dataset=""${1}""
     mountpoint=""$(zfs get -H -o value mountpoint ""${dataset}"")""
-    ret=0
-
+    mountopts=""strictatime""
+    ATIME_OPTION=$(zfs get -H -o value -s default,local,inherited atime ${dataset})
+    if [ ""${ATIME_OPTION}"" = ""off"" ]; then
+        mountopts=""noatime""
+    fi
+    RELATIME_OPTION=$(zfs get -H -o value -s default,local,inherited relatime ${dataset})
+    if [ ""${RELATIME_OPTION}"" = ""on"" ]; then
+        mountopts=""relatime""
+    fi
     # We need zfsutil for non-legacy mounts and not for legacy mounts.
     if [ ""${mountpoint}"" = ""legacy"" ] ; then
-        mount -t zfs ""${dataset}"" ""${NEWROOT}"" || ret=$?
+       mount -t zfs -o ${mountopts} ""${dataset}"" ""${NEWROOT}"" || ret=$?
     else
-        mount -o zfsutil -t zfs ""${dataset}"" ""${NEWROOT}"" || ret=$?
-
-        if [ ""$ret"" = ""0"" ]; then
-            for_relevant_root_children ""${dataset}"" _mount_dataset_cb || ret=$?
-        fi
+       mount -o zfsutil -t zfs -o ${mountopts} ""${dataset}"" ""${NEWROOT}"" || ret=$?
+    fi
+    if [ ""$ret"" = ""0"" ]; then
+        for_relevant_root_children ""${dataset}"" _mount_dataset_cb || ret=$?
     fi
 
     return ${ret}

```",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/943446925,Relatime is always turned on temporarily on ZFS root.,bghira,25,362997547,14,943446925,0,943446334,2021-10-14T15:04:36Z,"it's been 3 years so I don't know why I used the `-s` arguments other than... something didn't work, and then it did.",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/945577494,Relatime is always turned on temporarily on ZFS root.,szubersk,25,362997547,15,945577494,0,943446925,2021-10-18T09:24:20Z,"> ```shell
> diff --git a/contrib/dracut/90zfs/zfs-lib.sh.in b/contrib/dracut/90zfs/zfs-lib.sh.in
> index defc0bfc8..2e09559d7 100755
> --- a/contrib/dracut/90zfs/zfs-lib.sh.in
> +++ b/contrib/dracut/90zfs/zfs-lib.sh.in
> @@ -76,19 +76,26 @@ _mount_dataset_cb() {
>  # mount_dataset DATASET
>  #   mounts the given zfs dataset.
>  mount_dataset() {
> +    ret=0
>      dataset=""${1}""
>      mountpoint=""$(zfs get -H -o value mountpoint ""${dataset}"")""
> -    ret=0
> -
> +    mountopts=""strictatime""
> ```
Why injecting here strictatime? It could overwrite the default mount options coming from the ZFS driver.
> ```shell
> +    ATIME_OPTION=$(zfs get -H -o value -s default,local,inherited atime ${dataset})
> ```
Why `-s` in here?
> ```shell
> +    if [ ""${ATIME_OPTION}"" = ""off"" ]; then
> +        mountopts=""noatime""
> +    fi
> +    RELATIME_OPTION=$(zfs get -H -o value -s default,local,inherited relatime ${dataset})
> +    if [ ""${RELATIME_OPTION}"" = ""on"" ]; then
> +        mountopts=""relatime""
> +    fi
> ```
`noatime` trumps `relatime` - those two `if`statements should be in a reverse order.
> ```shell
>      # We need zfsutil for non-legacy mounts and not for legacy mounts.
>      if [ ""${mountpoint}"" = ""legacy"" ] ; then
> -        mount -t zfs ""${dataset}"" ""${NEWROOT}"" || ret=$?
> +       mount -t zfs -o ${mountopts} ""${dataset}"" ""${NEWROOT}"" || ret=$?
>      else
> -        mount -o zfsutil -t zfs ""${dataset}"" ""${NEWROOT}"" || ret=$?
> -
> -        if [ ""$ret"" = ""0"" ]; then
> -            for_relevant_root_children ""${dataset}"" _mount_dataset_cb || ret=$?
> -        fi
> +       mount -o zfsutil -t zfs -o ${mountopts} ""${dataset}"" ""${NEWROOT}"" || ret=$?
> +    fi
> +    if [ ""$ret"" = ""0"" ]; then
> +        for_relevant_root_children ""${dataset}"" _mount_dataset_cb || ret=$?
>      fi
>  
>      return ${ret}
> ```",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/962468619,Relatime is always turned on temporarily on ZFS root.,szubersk,25,362997547,16,962468619,0,945577494,2021-11-06T15:35:55Z,"@rlaager I slept on this issue and decided to run few experiments. Looks like this issue is not strictly connected to initrd, boot process or root-on-ZFS. This is a problem in `atime` and `relatime` property handling within ZFS. The testscript was run on my laptop booted to `graphical.target`. Would you point the right direction to investigate this further?

**System**
```
% uname -a     
Linux laptop.local 5.14.0-2-amd64 #1 SMP Debian 5.14.9-2 (2021-10-03) x86_64 GNU/Linux
% zfs --version
zfs-2.0.6-1
zfs-kmod-2.1.1-1
```

**Results**
```
before mount
test/noatime-relatime   atime           off     local
test/noatime-relatime   relatime        on      local

after mount
test/noatime-relatime   atime           off     local
test/noatime-relatime   relatime        on      local

what Linux reports
test/noatime-relatime /tmp/noatime-relatime zfs rw,relatime,xattr,noacl 0 0
-----------------
before mount
test/noatime-norelatime atime           off     local
test/noatime-norelatime relatime        off     local

after mount
test/noatime-norelatime atime           off     local
test/noatime-norelatime relatime        on      temporary

what Linux reports
test/noatime-norelatime /tmp/noatime-norelatime zfs rw,relatime,xattr,noacl 0 0
-----------------
before mount
test/atime-relatime     atime           on      local
test/atime-relatime     relatime        on      local

after mount
test/atime-relatime     atime           on      local
test/atime-relatime     relatime        on      local

what Linux reports
test/atime-relatime /tmp/atime-relatime zfs rw,relatime,xattr,noacl 0 0
-----------------
before mount
test/atime-norelatime   atime           on      local
test/atime-norelatime   relatime        off     local

after mount
test/atime-norelatime   atime           on      local
test/atime-norelatime   relatime        on      temporary

what Linux reports
test/atime-norelatime /tmp/atime-norelatime zfs rw,relatime,xattr,noacl 0 0
-----------------
```

**Test script**
```
#!/bin/bash

set -euo pipefail

main() {
  umount noatime-relatime noatime-norelatime atime-relatime atime-norelatime &>/dev/null ||:
  zpool export -f test &>/dev/null ||:

  truncate -s 100M ./disk
  mkdir -p noatime-relatime noatime-norelatime atime-relatime atime-norelatime
  zpool create -f -O canmount=off -O mountpoint=none test $(pwd)/./disk
  zfs create -o canmount=noauto -o mountpoint=none -o atime=off -o relatime=on test/noatime-relatime
  zfs create -o canmount=noauto -o mountpoint=none -o atime=off -o relatime=off test/noatime-norelatime
  zfs create -o canmount=noauto -o mountpoint=none -o atime=on -o relatime=on test/atime-relatime
  zfs create -o canmount=noauto -o mountpoint=none -o atime=on -o relatime=off test/atime-norelatime

  for m in noatime-relatime noatime-norelatime atime-relatime atime-norelatime; do
    echo before mount
    zfs get atime,relatime -H -r test/$m
    mount -t zfs -o zfsutil test/$m $m

    echo
    echo after mount
    zfs get atime,relatime -H -r test/$m
    echo
    echo what Linux reports
    awk ""/test\/$m/"" /proc/mounts
    echo -----------------
  done

  echo
  echo DONE
}

main ""$@""
```",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/962498535,Relatime is always turned on temporarily on ZFS root.,rlaager,25,362997547,17,962498535,0,962468619,2021-11-06T19:25:29Z,"If you use the low level interface to mount, then you have to handle converting the properties into mount options yourself. That’s not a bug.

Ordinary mounting by users should be done using `zfs mount`.",False,0,MEMBER
https://api.github.com/repos/openzfs/zfs/issues/comments/962664125,Relatime is always turned on temporarily on ZFS root.,szubersk,25,362997547,18,962664125,0,962498535,2021-11-07T19:06:57Z,"Richard, I agree that `zfs mount` should be used for all mounts but those with `mountpoint=legacy`. Our demise in here start with
https://github.com/openzfs/zfs/blob/4b87c1981d47655fd2eec2fb95179818240c4945/contrib/initramfs/scripts/zfs#L925-L934
(initramfs and dracut share their fate). That behavior makes us use `mount -t zfs -o zfsutil` to circumvent the `mountpoint` propagation.

Is it really true that we need to use `mount -t zfs -o zfsutil` instead of `zfs mount` there? If there's a way to use native ZFS solution, we should go for it. https://github.com/openzfs/zfs/pull/2087 was written in 2014 and I'm not sure if all assumptions in there are still relevant in 2021. Could you, guys, come up with test cases to validate `zfs mount` usage in initrd scripts?

EDIT
I just run few tests and indeed, `zpool import -R` into `zfs mount` leads to wrong mountpoint property values in the imported pools after `pivot_root` call (pre-pivot value stays) causing further mount/remount operations to fail.

EDIT2
One the the most consistent ways of going about this issue is https://github.com/szubersk/zfs/commit/200ffbff306971b84b8ee24fb7ca32796a399ae9
It would enforce the `zfs mount` behavior for all but `legacy` `mountpoints`.",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/964424569,Relatime is always turned on temporarily on ZFS root.,rlaager,25,362997547,19,964424569,0,962664125,2021-11-09T18:34:43Z,@szubersk I don't really know much about all the low-level mount stuff.,False,0,MEMBER
https://api.github.com/repos/openzfs/zfs/issues/comments/965722147,Relatime is always turned on temporarily on ZFS root.,szubersk,25,362997547,20,965722147,0,964424569,2021-11-10T20:31:01Z,@rlaager Would you mind suggesting a project Member who could help evaluating this? Should I create a pull request to start the discussion?,False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/965938175,Relatime is always turned on temporarily on ZFS root.,rlaager,25,362997547,21,965938175,0,965722147,2021-11-11T02:38:55Z,"@szubersk Yeah, a PR would be a good way to go.",False,0,MEMBER
https://api.github.com/repos/openzfs/zfs/issues/comments/1000701197,Relatime is always turned on temporarily on ZFS root.,quicktrick,25,362997547,22,1000701197,0,965938175,2021-12-24T07:35:53Z,"Is there any progress on this? Fresh installation of Void Linux, and the same problem again.",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/1000907364,Relatime is always turned on temporarily on ZFS root.,bghira,25,362997547,23,1000907364,0,1000701197,2021-12-24T17:43:27Z,"yeah, every time someone makes a suggested change, a few others come along to say it needs a huge number of unrelated changes. and those people are never the ones who are going to do that work. I've opened two PRs for this one and both times someone else asks for changes and we can currently blame @rlaager (or yourself, you didn't do much with the patch I proposed here)",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/1001536118,Relatime is always turned on temporarily on ZFS root.,szubersk,25,362997547,24,1001536118,0,1000907364,2021-12-27T12:06:26Z,"@bghira Would you mind sharing the PR you mentioned were rejected? I'm very interested in fixing this once and for all, I'm tired to rebasing local patches each time initramfs is updated.",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/1035902561,Relatime is always turned on temporarily on ZFS root.,szubersk,25,362997547,25,1035902561,0,1001536118,2022-02-11T05:50:41Z,"@rlaager, @bghira, @quicktrick and others in this thread please check if openzfs#13021 (the most recent master) fixed the issue for you. I hope we did not leave any loose ends.",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/1078220579,Relatime is always turned on temporarily on ZFS root.,behlendorf,25,362997547,26,1078220579,0,1035902561,2022-03-24T20:34:39Z,"Closing, as mentioned above this should be resolved in the master branch.",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/7950,Fix flake8 errors in test_libzfs_core.py,GregorKopka,3,363298070,1,363298070,0,0,2018-09-24T20:00:09Z,"### Motivation and Context
https://github.com/zfsonlinux/zfs/pull/7929#issuecomment-424052348

### Description
Compatibility with python 3 for contrib/pyzfs/libzfs_core/test/test_libzfs_core.py

Upgraded `print` statements to `print()` functions.

Simplified the loop in `_print()`, __this function dosn't seem to be used__.

Python 3 no longer has a `long` type, added `integer_types` indirection so `unittest.Testrunner.assertIsInstance()` works for both versions,
see http://python3porting.com/differences.html#long.
The `# noqa: F821` keeps flake8 from complaining about the `(int, long,)` comparison list in the python 2 codepath.

Replaced deprecated `unittest.Testrunner.assertEquals()` aliases with `.assertEqual()`,
see https://docs.python.org/2/library/unittest.html#deprecated-aliases.

### How Has This Been Tested?
flake8 reports no more warnings.

### Types of changes
<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->
- [ ] Bug fix (non-breaking change which fixes an issue)
- [X] New feature (non-breaking change which adds functionality)
- [ ] Performance enhancement (non-breaking change which improves efficiency)
- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)
- [ ] Breaking change (fix or feature that would cause existing functionality to change)
- [ ] Documentation (a change to man pages or other documentation)

### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [X] My code follows the ZFS on Linux [code style requirements](https://github.com/zfsonlinux/zfs/blob/master/.github/CONTRIBUTING.md#coding-conventions).
- [ ] I have updated the documentation accordingly.
- [X] I have read the [**contributing** document](https://github.com/zfsonlinux/zfs/blob/master/.github/CONTRIBUTING.md).
- [ ] I have added [tests](https://github.com/zfsonlinux/zfs/tree/master/tests) to cover my changes.
- [X] All new and existing tests passed.
- [X] All commit messages are properly formatted and contain [`Signed-off-by`](https://github.com/zfsonlinux/zfs/blob/master/.github/CONTRIBUTING.md#signed-off-by).
- [ ] Change has been approved by a ZFS on Linux member.
",True,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/424127216,Fix flake8 errors in test_libzfs_core.py,behlendorf,3,363298070,2,424127216,0,363298070,2018-09-24T21:13:52Z,We'll need to reconcile this with @aerusso's work with #7828.,False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/424128591,Fix flake8 errors in test_libzfs_core.py,codecov[bot],3,363298070,3,424128591,0,424127216,2018-09-24T21:18:39Z,"# [Codecov](https://codecov.io/gh/zfsonlinux/zfs/pull/7950?src=pr&el=h1) Report
> Merging [#7950](https://codecov.io/gh/zfsonlinux/zfs/pull/7950?src=pr&el=desc) into [master](https://codecov.io/gh/zfsonlinux/zfs/commit/36e369ecb847570d6939073663c4e95406223c7f?src=pr&el=desc) will **increase** coverage by `0.23%`.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/zfsonlinux/zfs/pull/7950/graphs/tree.svg?width=650&token=NGfxvvG2io&height=150&src=pr)](https://codecov.io/gh/zfsonlinux/zfs/pull/7950?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master    #7950      +/-   ##
==========================================
+ Coverage   43.95%   44.19%   +0.23%     
==========================================
  Files         318      318              
  Lines      103561   103561              
==========================================
+ Hits        45521    45764     +243     
+ Misses      58040    57797     -243
```

| Flag | Coverage Δ | |
|---|---|---|
| #kernel | `7.61% <ø> (ø)` | :arrow_up: |
| #user | `50.22% <ø> (+0.28%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/zfsonlinux/zfs/pull/7950?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/zfsonlinux/zfs/pull/7950?src=pr&el=footer). Last update [36e369e...a29a3d2](https://codecov.io/gh/zfsonlinux/zfs/pull/7950?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/424143785,Fix flake8 errors in test_libzfs_core.py,GregorKopka,3,363298070,4,424143785,0,424128591,2018-09-24T22:16:30Z,"> We'll need to reconcile this with @aerusso's work with #7828.

Meh, completely forgot about that one. Added a review there and closing this one.",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/7951,"Discard operations on empty zvols are ""slow""",ryao,10,363314678,1,363314678,0,0,2018-09-24T20:48:39Z,"I was trying to produce a counter example for #7937, but I ended up discovering a ""deficiency"" in our zvol code. I ran two commands:

```
zfs create -V 1E -s rpool/example
mkfs.xfs /dev/zvol/rpool/example
```

The first created a 1EB sparse zvol. The second was to make a XFS filesystem on it. Unfortunately, `mkfs.xfs` will do a discard before its format operation by default. This blocked on a discard operation:

```
[<0>] ___preempt_schedule+0x16/0x18
[<0>] taskq_dispatch+0x81/0x3d0 [spl]
[<0>] zvol_request+0x2b0/0x3f0 [zfs]
[<0>] generic_make_request+0x1d8/0x3c0
[<0>] submit_bio+0x73/0x140
[<0>] next_bio+0x38/0x40
[<0>] __blkdev_issue_discard+0x16f/0x220
[<0>] blkdev_issue_discard+0x6c/0xd0
[<0>] blk_ioctl_discard+0xc7/0x110
[<0>] blkdev_ioctl+0x8db/0x950
[<0>] block_ioctl+0x3d/0x50
[<0>] do_vfs_ioctl+0xa8/0x620
[<0>] ksys_ioctl+0x75/0x80
[<0>] __x64_sys_ioctl+0x1a/0x20
[<0>] do_syscall_64+0x5f/0x120
[<0>] entry_SYSCALL_64_after_hwframe+0x49/0xbe
[<0>] 0xffffffffffffffff
```

 `iostat` claims that we are writing to the zvol at 82354484213.86 kB/sec, which is ~82TB/sec. On a 1EB zvol, this will take 3 to 4 hours to complete. `mkfs.xfs` also cannot be killed until the discard operation has completed.

Anyway, there are a few things wrong here:

1. We are not making the operation a no-op on an empty zvol.
2. Userspace cannot interrupt this.",True,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/424123187,"Discard operations on empty zvols are ""slow""",trisk,10,363314678,2,424123187,0,363314678,2018-09-24T21:00:21Z,Seems possible this is blocked by some other operation using the zvol_taskq. I wonder if the queue is full at the time?,False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/424128801,"Discard operations on empty zvols are ""slow""",ryao,10,363314678,3,424128801,0,424123187,2018-09-24T21:19:21Z,"@trisk This is the only zvol on this system and nothing else is touching it. The IO queue is definitely full though:

```
Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util
zd0               0.00     0.00    0.00 639943.00     0.00 83878608896.00 262144.00    31.50    0.05    0.00    0.05   0.00 100.40
```

The zvol threads are also taking up all CPU time.",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/424139111,"Discard operations on empty zvols are ""slow""",richardelling,10,363314678,4,424139111,0,424128801,2018-09-24T21:56:56Z,"perhaps the default value of zvol_max_discard_blocks is too high?
",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/424173640,"Discard operations on empty zvols are ""slow""",ryao,10,363314678,5,424173640,0,424139111,2018-09-25T01:05:41Z,@richardelling The issue is two fold. One is that there is no way for the code to respond to a signal from userspace and exit early. The other is that the code doesn't check to see if the zvol is already empty and turn the discard into a no-op.,False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/424175051,"Discard operations on empty zvols are ""slow""",ryao,10,363314678,6,424175051,0,424173640,2018-09-25T01:15:15Z,"@richardelling Actually, I see what you are saying. It is likely the reverse. `__blkdev_issue_discard` will break discard operations into `max_discard_sectors` sized chunks, which prevents us from optimizing this use case.",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/424419834,"Discard operations on empty zvols are ""slow""",richardelling,10,363314678,7,424419834,0,424175051,2018-09-25T16:52:28Z,"Two things:
1. the default for zvol_max_discard_blocks is likely a SWAG, dunno if it should be changed, but likely a lower value makes sense
2. we could be smarter about this for empty zvols, if that helps
",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/424426082,"Discard operations on empty zvols are ""slow""",alek-p,10,363314678,8,424426082,0,424419834,2018-09-25T17:11:19Z,perhaps this is a dup of https://github.com/zfsonlinux/zfs/issues/6728 ? @ryao you could try setting `zfs_per_txg_dirty_frees_percent=0` and seeing if that helps,False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/424480285,"Discard operations on empty zvols are ""slow""",ryao,10,363314678,9,424480285,0,424426082,2018-09-25T19:58:05Z,"In the scenario that I described where a discard is done on the entirety of an empty zvol that is 1EB, assuming the default volblocksie, zvol_request will be called approximately 7.6 billion times. That is the cause of the slow down. The DMU is great at making sure that we don’t actually write anything, taking less than 2 microseconds per operation on average, but we still run through the motions of trying to free data billions of times in a non-interruptible context. I do not believe that any amount of tweaking that does not involve getting the kernel to pass the entire discard to zvol_request will make this quick.

In that respect, I think that this is different than #6728. Here the zvol is empty, which is a special case. In the other issue, the state of the zvol is unclear. It could include zvols that have data. Formatting a zvol right after making it is a fairly common operation and apparently, the discard as part of the format is a common operation too, so we probably should change this. The fix for that won’t necessarily help a zvol that has data.",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/679456950,"Discard operations on empty zvols are ""slow""",stale[bot],10,363314678,10,679456950,0,424480285,2020-08-25T01:58:41Z,"This issue has been automatically marked as ""stale"" because it has not had any activity for a while. It will be closed in 90 days if no further activity occurs.  Thank you for your contributions.
",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/907721713,"Discard operations on empty zvols are ""slow""",stale[bot],10,363314678,11,907721713,0,679456950,2021-08-29T03:11:50Z,"This issue has been automatically marked as ""stale"" because it has not had any activity for a while. It will be closed in 90 days if no further activity occurs.  Thank you for your contributions.
",False,0,NONE
https://api.github.com/repos/diaspora/diaspora/issues/7877,@Mentions in Comments do not pop up picklist,lunagloaming,4,367047600,1,367047600,0,0,2018-10-05T03:34:05Z,"Although @mentions in comments work (e.g. @{user@pod}), they do not appear to pull up the helpful pick list like they do in new posts, at least on my pod.

I would expect @mentions to work the same in both posts and comments.",True,0,CONTRIBUTOR
https://api.github.com/repos/diaspora/diaspora/issues/comments/427290403,@Mentions in Comments do not pop up picklist,Flaburgan,4,367047600,2,427290403,0,367047600,2018-10-05T08:42:54Z,"Hi @lunagloaming and thank you for reporting a possible bug in diaspora*.

First of all, the autocomplete mention feature isn't implemented in the mobile version of diaspora* (see https://github.com/diaspora/diaspora/issues/4817) but I guess you were using the desktop version.

Mentions in comments are a bit different than mentions in posts because of content visibility.
You should be able to mention anyone in a comment made **on a public post** but you can only mention a user **who already interacted with a post** for a limited post. This limitation is there to be sure to not mention someone who doesn't have access to the post. There surely is room for improvement there but that's the current situation.

Can you confirm you're not falling in that case by trying to mention someone in a comment on a public post? Thank you.
",False,0,MEMBER
https://api.github.com/repos/diaspora/diaspora/issues/comments/427538479,@Mentions in Comments do not pop up picklist,lunagloaming,4,367047600,3,427538479,0,427290403,2018-10-06T02:15:04Z,"OK, here is the use case... there is a post which I feel another friend might be interested in.  I do not know the limits of the original post, nor should I (aspect names being private), however there is a chance that the mutual friend might have access and I'd like to call their attention to the post.

On Facebook, I can @mention them regardless of the original post's visibility... it might not do anything if they don't have access, but it is allowed.  And if they do have access, they'll see the mention and be directed to the relevant post.",False,0,CONTRIBUTOR
https://api.github.com/repos/diaspora/diaspora/issues/comments/427574884,@Mentions in Comments do not pop up picklist,goobertron,4,367047600,4,427574884,0,427538479,2018-10-06T13:42:18Z,"By design, diaspora\* respects the wishes of the original poster as to who will be able to see what they have posted. It therefore doesn't allow another person to change that scope. Mentioning someone not in the original scope, if it gave that person access to the content, would 'leak' the content to someone whom the original poster didn't intend to see it. This is a case where what Facebook allows is, although it might be convenient, not necessarily a good thing.

As it's not possible to give someone access to limited content in this way, there's no point having a UI that mimics the 'mention' UI but performs no function. So it was decided not to enable the act of @-linking an account in a comment on a limited post unless that person had already interacted with the content, thereby demonstrating that they are part of the scope of that content.

You can read how the decision was reached to limit mentions in comments in this way in [this discussion](https://discourse.diasporafoundation.org/t/mention-users-in-comment/177/22).

Hope that helps clear things up!",False,0,NONE
https://api.github.com/repos/diaspora/diaspora/issues/comments/429594194,@Mentions in Comments do not pop up picklist,denschub,4,367047600,5,429594194,0,427574884,2018-10-14T03:47:24Z,"This isn't a bug, and although this could resolve into a feature request, this discussion is best started/continued in Discourse. See the previous comment for a link.",False,0,MEMBER
https://api.github.com/repos/diaspora/diaspora/issues/7878,Directly pasting image into a post when composing,HankG,9,367593997,1,367593997,0,0,2018-10-07T21:06:56Z,"A feature I use on a lot of places which I can't do in Diaspora right now is copy/pasting an image from the clipboard into the composition area and have it become part of the post automatically.  In the current Diaspora a user needs to save it to the disk then add upload it to attach it to the post...

",True,0,CONTRIBUTOR
https://api.github.com/repos/diaspora/diaspora/issues/comments/427699130,Directly pasting image into a post when composing,HankG,9,367593997,2,427699130,0,367593997,2018-10-08T00:16:26Z,It turns out that the FineUploader we are already using supports this option.  You just have to set up the paste options and it works.  The big question is if we want the paste-focus to be on the text area or the entire page.  I coded it up against the text area first.  Thoughts?,False,0,CONTRIBUTOR
https://api.github.com/repos/diaspora/diaspora/issues/comments/427737209,Directly pasting image into a post when composing,Flaburgan,9,367593997,3,427737209,0,427699130,2018-10-08T07:01:21Z,It has to be the textarea as you can have the publisher open several times in the page to comment.,False,0,MEMBER
https://api.github.com/repos/diaspora/diaspora/issues/comments/427737441,Directly pasting image into a post when composing,Flaburgan,9,367593997,4,427737441,0,427737209,2018-10-08T07:02:38Z,"We also have the drag and drop feature to upload an image. It currently only works on the camera icon, maybe you can extend it to works on the whole textarea.",False,0,MEMBER
https://api.github.com/repos/diaspora/diaspora/issues/comments/427789676,Directly pasting image into a post when composing,HankG,9,367593997,5,427789676,0,427737441,2018-10-08T10:44:18Z,I'll look into that.  Right now drag and drop into the text area drops the file path to text box. ,False,0,CONTRIBUTOR
https://api.github.com/repos/diaspora/diaspora/issues/comments/427928281,Directly pasting image into a post when composing,HankG,9,367593997,6,427928281,0,427789676,2018-10-08T18:07:37Z,@Flaburgan yes I got your suggestion working but had to bring in a bit more of the FineUploader library (we only brought in the core before). It's only a net couple hundred K if I'm reading it correctly.  I've tested this manually and am looking at if I need to make an update to the Jasmine tests.  ,False,0,CONTRIBUTOR
https://api.github.com/repos/diaspora/diaspora/issues/comments/427965459,Directly pasting image into a post when composing,HankG,9,367593997,7,427965459,0,427928281,2018-10-08T20:17:41Z,I'm seeing an inconsistency between the mobile and desktop calls into the photos service.  This goes back to the earliest versions of both.  The mobile one adds the aspects fields to the POST arguments while the desktop one does not when calling the photos upload service.  I'm going to do some experimenting but does this discrepancy make any sense to anybody?  At same point the settings are correct because in my testing a user not in the Aspects it was shared to doesn't have visibility to photos that I shouldn't.   If I make the mobile call look aspect-less like the desktop one it all works too (in my testing).  It's just a weird inconsistency in the code.,False,0,CONTRIBUTOR
https://api.github.com/repos/diaspora/diaspora/issues/comments/427974907,Directly pasting image into a post when composing,HankG,9,367593997,8,427974907,0,427965459,2018-10-08T20:51:02Z,"I have a PR that captures the original request, plus the enhanced drag and drop requested by @Flaburgan , and with the change to more consistently call into the file uploaded between the two. https://github.com/diaspora/diaspora/pull/7883",False,0,CONTRIBUTOR
https://api.github.com/repos/diaspora/diaspora/issues/comments/429268336,Directly pasting image into a post when composing,Siedlerchr,9,367593997,9,429268336,0,427974907,2018-10-12T09:42:01Z,Drag and Drop  Support as an intermediate step would be also nice.,False,0,NONE
https://api.github.com/repos/diaspora/diaspora/issues/comments/429352638,Directly pasting image into a post when composing,HankG,9,367593997,10,429352638,0,429268336,2018-10-12T14:51:15Z,@Siedlerchr the PR for this does drag and drop as well. Drag and drop already worked if you put it on top of the camera icon.  In the current version it works if you drop it into the text field or the thumbnail bar too.,False,0,CONTRIBUTOR
https://api.github.com/repos/diaspora/diaspora/issues/7881,Add to string when pass integer to person model function,VitorRibeiroCustodio,5,367757051,1,367757051,0,0,2018-10-08T12:00:57Z,"Fixing function find_by_substring in Person model. When pass a integer to the function, that method doesnt, because, strip is a string method. ",True,0,NONE
https://api.github.com/repos/diaspora/diaspora/issues/comments/427807162,Add to string when pass integer to person model function,VitorRibeiroCustodio,5,367757051,2,427807162,0,367757051,2018-10-08T12:01:14Z,"Fixing function find_by_substring in Person model. When pass a integer to the function, that method doesnt, because, strip is a string method.",False,0,NONE
https://api.github.com/repos/diaspora/diaspora/issues/comments/427850972,Add to string when pass integer to person model function,jhass,5,367757051,3,427850972,0,427807162,2018-10-08T14:14:16Z,"Which issue is this fixing? 

Semantic wise I think it's fine for a method called `search_by_substring` to expect being passed a string or something that quacks like it.",False,0,MEMBER
https://api.github.com/repos/diaspora/diaspora/issues/comments/428684523,Add to string when pass integer to person model function,CSammy,5,367757051,4,428684523,0,427850972,2018-10-10T18:38:43Z,"Does it break if you search for a number in the frontend? If it doesn't, we might not need this.",False,0,CONTRIBUTOR
https://api.github.com/repos/diaspora/diaspora/issues/comments/434872339,Add to string when pass integer to person model function,HankG,5,367757051,5,434872339,0,428684523,2018-10-31T22:41:31Z,"@CSammy  I have confirmed that the UI doesn't have an error.  I've looked at the logs and it is processed internally as a string from the REST handler so a path where the UI feeds it an integer doesn't exist.  The way I'd be coding up the search on API would also not have this artifact.  

@VitorRibeiroCustodio was there a code execution path you saw that this to error like this?  ",False,0,CONTRIBUTOR
https://api.github.com/repos/diaspora/diaspora/issues/comments/436862265,Add to string when pass integer to person model function,denschub,5,367757051,6,436862265,0,434872339,2018-11-08T03:35:40Z,"This hasn't received more info within a month. @VitorRibeiroCustodio, please answer the questions asked in this PR if you ever come back. If this turns out to be a valid fix, we can reopen this PR.",False,0,MEMBER
https://api.github.com/repos/diaspora/diaspora/issues/7882,#7841 Post Unlike sets status icon correctly,HankG,6,367873152,1,367873152,0,0,2018-10-08T16:50:39Z,,True,0,CONTRIBUTOR
https://api.github.com/repos/diaspora/diaspora/issues/comments/427976550,#7841 Post Unlike sets status icon correctly,jeremyf,6,367873152,2,427976550,0,367873152,2018-10-08T20:57:01Z,👍 ,False,0,NONE
https://api.github.com/repos/diaspora/diaspora/issues/comments/427979007,#7841 Post Unlike sets status icon correctly,HankG,6,367873152,3,427979007,0,427976550,2018-10-08T21:05:38Z,@denschub OK that makes sense. ,False,0,CONTRIBUTOR
https://api.github.com/repos/diaspora/diaspora/issues/comments/428209418,#7841 Post Unlike sets status icon correctly,HankG,6,367873152,4,428209418,0,427979007,2018-10-09T14:16:10Z,"I've updated the unit test to capture the errant behavior as well as to be as robust as the one for ""like"". ",False,0,CONTRIBUTOR
https://api.github.com/repos/diaspora/diaspora/issues/comments/428543592,#7841 Post Unlike sets status icon correctly,HankG,6,367873152,5,428543592,0,428209418,2018-10-10T11:55:53Z,"Are there additional changes after my latest commit where I addressed the unit test or is something out of sync with the status?  I thought when I submitted new code it would reset the status with the new commit.  If I am looking at the main board view it looks like nothing has changed for two days and this needs changes, but in reality the PR changed a day ago and the new changes haven't been reviewed.  PS this is not meant as ""why haven't the changes been reviewed?"" this is a question about potentially stale status (or stale looking status) on the main PR view.",False,0,CONTRIBUTOR
https://api.github.com/repos/diaspora/diaspora/issues/comments/429846165,#7841 Post Unlike sets status icon correctly,HankG,6,367873152,6,429846165,0,428543592,2018-10-15T13:08:27Z,This is ready for review.,False,0,CONTRIBUTOR
https://api.github.com/repos/diaspora/diaspora/issues/comments/436868096,#7841 Post Unlike sets status icon correctly,denschub,6,367873152,7,436868096,0,429846165,2018-11-08T04:16:45Z,Merged!,False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/2346,Allow driver specific escape methods in rlm_sql,herwinw,8,376883482,1,376883482,0,0,2018-11-02T16:35:08Z,"After a discussion on the mailing list these last two days: this patch backports the driver specific escape modules for SQL from master to v3.0.x.

This change will break backwards compatibility, since the escape mechanism will be changed. It will need an extra config option, turn the new behaviour on in the default config, turn it off in the defaults in the code, so new installations will use the improved escape methods, while current installations keep using the old version.",True,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/435440221,Allow driver specific escape methods in rlm_sql,herwinw,8,376883482,2,435440221,0,376883482,2018-11-02T16:42:49Z,"By the way: I have not tested this in any way, it's just a very selective copy-paste from master, and it compiles.",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/435468882,Allow driver specific escape methods in rlm_sql,alandekok,8,376883482,3,435468882,0,435440221,2018-11-02T18:28:46Z,"This patch is probably worth merging, as it doesn't do much.

The next step would be to *selectively* enable the new behavior.  e.g. if `safe_characters = auto`, or something like that.

We don't want to change the existing behavior in v3, of course.  But selectively allowing new behavior is OK.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/435490572,Allow driver specific escape methods in rlm_sql,herwinw,8,376883482,4,435490572,0,435468882,2018-11-02T19:54:03Z,"I've fixed a bug, and seen it working as well:

Database:
```
mysql> select * from radcheck;
+----+----------+--------------------+----+---------+
| id | username | attribute          | op | value   |
+----+----------+--------------------+----+---------+
|  1 | bob      | Cleartext-Password | := | hello   |
|  2 | bob'     | Cleartext-Password | := | goodbye |
+----+----------+--------------------+----+---------+
```

Request:
```
bin/radtest ""bob'"" goodbye 127.0.0.1 0 testing123
```

Some loglines:

```
Fri Nov  2 20:49:52 2018 : Debug: (0) sql: EXPAND SELECT id, username, attribute, value, op FROM radcheck WHERE username = '%{SQL-User-Name}' ORDER BY id
Fri Nov  2 20:49:52 2018 : Debug: (0) sql:    --> SELECT id, username, attribute, value, op FROM radcheck WHERE username = 'bob\'' ORDER BY id
Fri Nov  2 20:49:52 2018 : Debug: (0) sql: Executing select query: SELECT id, username, attribute, value, op FROM radcheck WHERE username = 'bob\'' ORDER BY id
Fri Nov  2 20:49:52 2018 : Debug: (0) sql: User found in radcheck table
Fri Nov  2 20:49:52 2018 : Debug: (0) sql: Conditional check items matched, merging assignment check items
Fri Nov  2 20:49:52 2018 : Debug: (0) sql:   Cleartext-Password := ""goodbye""
...
Fri Nov  2 20:49:52 2018 : Debug: (0) sql: EXPAND INSERT INTO radpostauth (username, pass, reply, authdate) VALUES ( '%{SQL-User-Name}', '%{%{User-Password}:-%{Chap-Password}}', '%{reply:Packet-Type}', '%S')
Fri Nov  2 20:49:52 2018 : Debug: (0) sql:    --> INSERT INTO radpostauth (username, pass, reply, authdate) VALUES ( 'bob\'', 'goodbye', 'Access-Accept', '2018-11-02 20:49:52')
Fri Nov  2 20:49:52 2018 : Debug: (0) sql: Executing query: INSERT INTO radpostauth (username, pass, reply, authdate) VALUES ( 'bob\'', 'goodbye', 'Access-Accept', '2018-11-02 20:49:52')
```

I can see `bob'` in the `radpostauth`  table as well.",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/435493614,Allow driver specific escape methods in rlm_sql,arr2036,8,376883482,5,435493614,0,435490572,2018-11-02T20:06:04Z,"Agreed.  This needs to be selectively enabled, else you'll probably break any installs that have consumers of the data from the MySQL database.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/435502368,Allow driver specific escape methods in rlm_sql,herwinw,8,376883482,6,435502368,0,435493614,2018-11-02T20:40:22Z,Added the config option as well. That should wrap it up,False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/435511866,Allow driver specific escape methods in rlm_sql,arr2036,8,376883482,7,435511866,0,435502368,2018-11-02T21:17:21Z,Can you sign your commits and force push them to the branch,False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/435568683,Allow driver specific escape methods in rlm_sql,herwinw,8,376883482,8,435568683,0,435511866,2018-11-03T07:56:58Z,Rebased and signed,False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/435967571,Allow driver specific escape methods in rlm_sql,arr2036,8,376883482,9,435967571,0,435568683,2018-11-05T17:45:47Z,"Looks fine, just need that abort statement to ensure the correct argument is always passed in.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/2351,Python 3 support,MisterErwin,45,378091553,1,378091553,0,0,2018-11-07T00:27:04Z,"With the soon(ish) deprecation of python 2 (January 2020) a python 3 supporting module would be very nice. 
Be it by plain replacing the python 2 module or adding a python 3 one. But py2to3 should be usable for most cases (imho).

Apparently there already have been PRs (e.g. #1686 ) but those were closed due to inactivity.",True,0,NONE
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/436566119,Python 3 support,herwinw,45,378091553,2,436566119,0,378091553,2018-11-07T09:47:49Z,"It feels like the current `rlm_python` has support for Python 3, but needs a bit of work to make it really work.

Configure works (output truncated to relevant parts):
```
~/freeradius-server/src/modules/rlm_python$ ./configure --with-rlm-python-bin=$(which python3.6)
configure: Python sys.prefix ""/usr""
configure: Python sys.exec_prefix ""/usr""
configure: Python sys.version ""3.6""
checking for Python.h in /usr/include/python3.6/... yes
checking for Py_Initialize in -lpython3.6m in /usr/lib/python3.6/config... yes
```

Make generates a few warnings that need fixing (but it might be Python 3.6 is too new)

```
src/modules/rlm_python/rlm_python.c:228:19: warning: implicit declaration of function ‘PyString_AsString’; did you mean ‘PyBytes_AsString’? [-Wimplicit-function-declaration]
src/modules/rlm_python/rlm_python.c:287:9: warning: implicit declaration of function ‘PyString_CheckExact’; did you mean ‘PyLong_CheckExact’? [-Wimplicit-function-declaration]
src/modules/rlm_python/rlm_python.c:303:15: warning: implicit declaration of function ‘PyInt_Check’; did you mean ‘PySet_Check’? [-Wimplicit-function-declaration]
src/modules/rlm_python/rlm_python.c:304:10: warning: implicit declaration of function ‘PyInt_AsLong’; did you mean ‘PyLong_AsLong’? [-Wimplicit-function-declaration]
src/modules/rlm_python/rlm_python.c:367:10: warning: implicit declaration of function ‘PyString_FromFormat’; did you mean ‘PyBytes_FromFormat’? [-Wimplicit-function-declaration]
src/modules/rlm_python/rlm_python.c:996:18: warning: implicit declaration of function ‘Py_InitModule3’; did you mean ‘Py_Initialize’? [-Wimplicit-function-declaration]
```",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/436623440,Python 3 support,arr2036,45,378091553,3,436623440,0,436566119,2018-11-07T13:32:34Z,"Not closed due to inactivity, closed due to v4.0.x being renamed if the OP could reopen against master branch that'd be great.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/436847123,Python 3 support,m-blanke,45,378091553,4,436847123,0,436623440,2018-11-08T02:06:04Z,"> It feels like the current `rlm_python` has support for Python 3, but needs a bit of work to make it really work.

Well, it has been admittedly about two years since I've worked on the PR, but as far as I can recall, the changes are quite not trivial. The internal cpython implementation for - among others - strings and global interpreter lock have changes substantially. The work of porting the rlm_python to Python3 is basically done (see PR #1686 ), however it fails with more than one instance of the module at the same time. I recall there being similar (or even the same?) issue with rlm_python for Python2. With one module it has been running quite stable for about two years in our production system ;-) 

@arr2036 Would it be an acceptable intermediate solution to change the travis checks such that only one instance is made, merge the PR #1686 (after a rebase by me of course), and expand to two module support at a later time? Just ",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/436849785,Python 3 support,alandekok,45,378091553,5,436849785,0,436847123,2018-11-08T02:20:42Z,"I would suggest just creating two modules.  `rlm_python3` and `rlm_python2`.

If we want to have just an `rlm_python`, it should likely be python3.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/436950650,Python 3 support,herwinw,45,378091553,6,436950650,0,436849785,2018-11-08T10:40:27Z,"Before forking the module to create a `rlm_python3`, please keep in mind that #2334 contains some very useful changes for `rlm_python`. ",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/437812724,Python 3 support,alejandro-perez,45,378091553,7,437812724,0,436950650,2018-11-12T09:28:59Z,"Indeed, if we went for rlm_python3, I would vote for getting rid of the tuple-based interface in favor of the dict-based one, taking advantage that backwards compatibility would not be an issue.",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/438312008,Python 3 support,cipherboy,45,378091553,8,438312008,0,437812724,2018-11-13T15:41:05Z,"It'd be nice if these changes were considered for the `v3.0.x` branch as well. It is unlikely we'll be ship `v4.0.x` any time soon at Red Hat or in Fedora, so we'll need Python 3 support in the `v3.0.x`...",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/438320828,Python 3 support,arr2036,45,378091553,9,438320828,0,438312008,2018-11-13T16:03:12Z,"I'm not sure we should really concern ourselves with the released schedules of RedHat and Fedora, especially as we provide our own packages.  I'm generally against adding new functionality to older branches, and am definitely against maintaining two versions of rlm_python.  Python's C API is poorly documented and there are existing threading issues with the current rlm_python module.  IMHO this should go into v4.0.x, and we should stick with one python version.  People are going to be reworking their configs during the upgrade anyway.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/438335975,Python 3 support,cipherboy,45,378091553,10,438335975,0,438320828,2018-11-13T16:26:19Z,"Duly noted. I'm not trying to suggest a time frame to have this done by, merely that I'm watching and will fit it into our releases as it gets done. I'll keep this as something I'll likely have to backport.

Thanks!",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/462160932,Python 3 support,cfrademan,45,378091553,11,462160932,0,438335975,2019-02-10T18:56:50Z,"Hi there. We implementing some third party software with FreeRadius. We running a bit low on time here and happy to go forward using python2 for time being. However what is the plans moving forward with python3 support? I do not see in the milestones for the 4x branch? We got less than a year left on python2. It makes sense that 4.x only supports python3 and sticking with one module rlm_python. 

",False,0,NONE
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/462161535,Python 3 support,alandekok,45,378091553,12,462161535,0,462160932,2019-02-10T19:04:08Z,"If you can verify PR #1686, we can pull it into v4.  With a note that rlm_python in v4 is only Python3.

If anyone has time to create an rlm_python3 for v3, we're happy to look at it.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/505659060,Python 3 support,MisterErwin,45,378091553,13,505659060,0,462161535,2019-06-25T23:27:31Z,"Hating to be that guy that only bumps issues (and not really providing anything useful), but after ""testing"" Deisuans PR (by using it in prod) and the EOF for python2 being in roughly 6 months.... is there any progress?
",False,0,NONE
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/505904282,Python 3 support,alandekok,45,378091553,14,505904282,0,505659060,2019-06-26T14:37:19Z,"My $0.02 is to add a `rlm_python3` module to v3.  For backwards compatibility, we don't want to change the existing `rlm_python`.  In v4, `rlm_python` can just be Python3.

The core FreeRADIUS team doesn't have time to do this right now, plus we don't use Python much. 
 So testing is hard.  Patches are welcome.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/529580079,Python 3 support,aren,45,378091553,15,529580079,0,505904282,2019-09-09T17:18:11Z,We built an `rlm_python3` module for v3 (based off of `rlm_python` from v4). We'll submit a PR soon.,False,0,NONE
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/529589106,Python 3 support,alandekok,45,378091553,16,529589106,0,529580079,2019-09-09T17:41:21Z,"> We built an `rlm_python3` module for v3 (based off of `rlm_python` from v4). We'll submit a PR soon.

Great news, thanks!",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/529976076,Python 3 support,jeffersonchua,45,378091553,17,529976076,0,529589106,2019-09-10T14:58:08Z,"On Tue, Sep 10, 2019 at 1:41 AM Alan DeKok <notifications@github.com> wrote:

> We built an rlm_python3 module for v3 (based off of rlm_python from v4).
> We'll submit a PR soon.
>
> Great news, thanks!
>
Will be happy to test it!
Thanks,
Jeff.
",False,0,NONE
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/530005058,Python 3 support,alejandro-perez,45,378091553,18,530005058,0,529976076,2019-09-10T16:00:11Z,"Yeah, me too.
",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/530027912,Python 3 support,arr2036,45,378091553,19,530027912,0,530005058,2019-09-10T16:57:47Z,"Honestly I didn't think the changes were that invasive to support Python 3.  I'd be interested to see what changes you made to the python module in v4, because I thought a lot of the support necessary was already there.  Most of the changes were to support the use of wchar_t which is either a 16bit or 32bit character type.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/530028254,Python 3 support,arr2036,45,378091553,20,530028254,0,530027912,2019-09-10T16:58:39Z,"and it follows if that's the case, then there's probably no need for an rlm_python3, and we can just use the module from v4 backported to v3...",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/530029503,Python 3 support,alandekok,45,378091553,21,530029503,0,530028254,2019-09-10T17:01:44Z,"My only concern is compatibility.  Many, many, people use rlm_python with python2.  Changing that in v3 is a non-starter.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/530031987,Python 3 support,arr2036,45,378091553,22,530031987,0,530029503,2019-09-10T17:08:00Z,"Sure, so have the configure script prefer Python 2.7?",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/530032500,Python 3 support,arr2036,45,378091553,23,530032500,0,530031987,2019-09-10T17:09:21Z,My main concern is duplicating an entire module when it can already handle the version differences in the library it's being linked to.  Another option would be multiple configure scripts and multiple all.mk files but using the same source?,False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/530080102,Python 3 support,arr2036,45,378091553,24,530080102,0,530032500,2019-09-10T19:14:41Z,"rlm_python should now build against Python >= 3.5.  There does appear to be an issue with how the C module is presented in the Python environment which means it's not found.  Hopefully @aren already discovered this and found a fix :)

If someone more familiar with the Python C API than me could look over the changes it'd be much appreciated.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/530174327,Python 3 support,jeffersonchua,45,378091553,25,530174327,0,530080102,2019-09-11T00:52:45Z,"Compiled fine. Next it to test running it.

My best.,
Jeff


On Wed, Sep 11, 2019 at 3:14 AM Arran Cudbard-Bell <notifications@github.com>
wrote:

> 520d06a
> <https://github.com/FreeRADIUS/freeradius-server/commit/520d06a2150dcfcf912ce48e9498895832e60b3a>
> 8c95806
> <https://github.com/FreeRADIUS/freeradius-server/commit/8c9580662a08afa5cdd79cb17ad2ea586cde467a>
> 0f9ebec
> <https://github.com/FreeRADIUS/freeradius-server/commit/0f9ebec4ac044053ba8a58791470ee6bb6503886>
> 4831db4
> <https://github.com/FreeRADIUS/freeradius-server/commit/4831db429997318e78f748762ecd2b4fb245919c>
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/FreeRADIUS/freeradius-server/issues/2351?email_source=notifications&email_token=AD3RVPZG7PCYMGYCKYZMYYLQI7W2PA5CNFSM4GCGGU32YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD6MGCZQ#issuecomment-530080102>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AD3RVP62TQ3AR4PMAUVMWO3QI7W2PANCNFSM4GCGGU3Q>
> .
>
",False,0,NONE
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/530459365,Python 3 support,arr2036,45,378091553,26,530459365,0,530174327,2019-09-11T16:29:33Z,"OK as of 2c6d2331bf6761aeff21f880ce6600dac3893875

Tests show rlm_python is still functional for Python 2.7 (all tests pass).  Support for Python 3 strips out ""cext_compat"" mode, because the upcoming Python 3.8 release should fix the underlying issue, and potentially provide a way of improving multi-threaded performance significantly where GIL contention is an issue.

The only remaining issue for Python 3 is that radiusd.config injection, which allows you to create Python dicts from the rlm_python module config is not working, not sure why.  It works fine with Python 2.7.
",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/531029986,Python 3 support,aren,45,378091553,27,531029986,0,530459365,2019-09-12T22:24:00Z,"I mis-spoke earlier, our python3 module was based off of the now-closed #1686 (which was based on the existing rlm_python but intended for v4).

You can see our diffs here: https://github.com/foxpass/freeradius-server/compare/v3.0.x...foxpass:python3_for_30x. We've been running it in production for a while without an issue. (Note, too, that we allow threading and have no trouble. Though we only run one instance of the module.)

Sounds like a PR from us will not be necessary if you're going to back-port your py2+py3 compatible module from v4 back to v3. If so, we will help test it. Or even spear-head the backport.",False,0,NONE
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/531033049,Python 3 support,arr2036,45,378091553,28,531033049,0,531029986,2019-09-12T22:37:04Z,"So the essence of your code is similar to what I had in master.  Are you sure the config functionality works with Python 3, i.e. `radiusd.config.get(<param>)` returns a value from the configuration section of the python module? That's the only outstanding bit we have in master.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/531348272,Python 3 support,aren,45,378091553,29,531348272,0,531033049,2019-09-13T18:42:43Z,We just tested and that seems to work fine in our module. It looks for an inner section called `config` in the `python` module config file.,False,0,NONE
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/531443436,Python 3 support,arr2036,45,378091553,30,531443436,0,531348272,2019-09-14T03:08:26Z,Yeah figured out what the problem was. Misunderstanding of how the inittab should work,False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/544358550,Python 3 support,robertpenz,45,378091553,31,544358550,0,531443436,2019-10-21T05:47:55Z,"Can you please integrate the changes foxpass provided into the 3.0.x, as Python 2.7 will not be supported after 31.12.2019 and the current released version (at the time of writing thats 3.0.19) of a big project like Freeradius does not support Python 3.  I talked with Redhat hat thats also the reason no python binding is provided with RHEL 8.",False,0,NONE
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/2360,rlm_mschap: Freeradius looks for wrong message when a user password  is expired (ntlm_auth),Serophos,3,383803201,1,383803201,0,0,2018-11-23T12:13:01Z,"# Issue type
- Defect - Unexpected behaviour (obvious or verified by project member).

# Defect passchange does not work in all enviroments. 
In a windows domain enviroment when a user password has expired ntlm_auth returns a different message so the check the mschap module does, will not work.

ntlm_auth returns with the message 

""Program returned code (1) and output 'The user password must be changed before logging on the first time. (0x0000224)'

or ""... The password has expired ...""

The following patch for src/modules/rlm_mschap/rlm_mschap.c will fix the issue.

@@ -1115,8 +1115,11 @@ static int CC_HINT(nonnull (1, 2, 4, 5 , 6)) do_mschap(rlm_mschap_t const *inst,
 			/*
			 *	look for ""Password expired"", or ""Must change password"".
			 *      Fix: Some enviroments report ""Password has expired"" or ""password must be changed""
			 */
			if (strcasestr(buffer, ""Password expired"") ||
			    strcasestr(buffer, ""Password has expired"") ||
			    strcasestr(buffer, ""password must be changed"") ||
			    strcasestr(buffer, ""Must change password"")) {
				REDEBUG2(""%s"", buffer);
				return -648;

(https://github.com/Serophos/freeradius-server/commit/2d8f717312f788a3e36a50c6459fbde692b9862a#diff-57f94b2beb1d6fdbe34c85de3f13690d)",True,0,NONE
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/441293596,rlm_mschap: Freeradius looks for wrong message when a user password  is expired (ntlm_auth),alandekok,3,383803201,2,441293596,0,383803201,2018-11-23T17:41:59Z,"I've pushed commit 8ef4848c3 which should help.  It adds the text messages.  And, simplifies some of the checks so that they're less expensive.

Please test and verify that this works.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/441433198,rlm_mschap: Freeradius looks for wrong message when a user password  is expired (ntlm_auth),Serophos,3,383803201,3,441433198,0,441293596,2018-11-25T11:22:53Z,"Lol, love your code comment (""Else fall through to more ridiculous checks""), using the returned error code is of course the more obvious check. I don't do much programming. I will check your patch next week at work and report back.",False,0,NONE
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/444859812,rlm_mschap: Freeradius looks for wrong message when a user password  is expired (ntlm_auth),Serophos,3,383803201,4,444859812,0,441433198,2018-12-06T12:47:39Z,The patch is working correctly. Thank you.,False,0,NONE
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/2368,"nasipaddress unset if connection dies early, leading to stale leased IPs with sqlippool",Jayd603,5,389449924,1,389449924,0,0,2018-12-10T19:24:50Z,"When a connection is lost unexpectedly during initial authentication, sqlippool's queries no longer work (missing nasipaddress) leaving the IP that was leased stuck.

Strongswan is on the other end and something is broken with how the connection is being set up (this is because of an incompatible VPN client and possibly strongswan not handling it gracefully), however RADIUS should still be able to clear the IP that was assigned as Acct-Status-Type = Stop is correctly sent by the VPN server.

The IP stays leased to the failed login in the sql radippool table after certain failed logins on the VPN server.  This is a potential DoS issue as an attacker could use up all available IPs by flooding with failed logins.  Assuming a small pool of IPs, someone merely trying to make a client machine work could also use up all available IPs and block further logins from other users.

The good news is if the lease time expires the IPs become available again.

--- SPECIFIC failing query

rlm_sql (sql): Reserved connection (7)
(7) sqlippool_ipv4: EXPAND %{%{Stripped-User-Name}:-%{%{User-Name}:-DEFAULT}}
(7) sqlippool_ipv4:    --> jd
(7) sqlippool_ipv4: SQL-User-Name set to 'jd'
(7) sqlippool_ipv4: EXPAND START TRANSACTION
(7) sqlippool_ipv4:    --> START TRANSACTION
(7) sqlippool_ipv4: Executing query: START TRANSACTION
(7) sqlippool_ipv4: EXPAND UPDATE radippool SET nasipaddress = '', pool_key = 0, callingstationid = '', username = '', expiry_time = NULL WHERE nasipaddress = '%{%{Nas-IP-Address}:-%{Nas-IPv6-Address}}' AND pool_key = '%{NAS-Port}' AND username = '%{User-Name}' AND callingstationid = '%{Calling-Station-Id}' AND framedipaddress = '%{Framed-IP-Address}'
(7) sqlippool_ipv4:    --> UPDATE radippool SET nasipaddress = '', pool_key = 0, callingstationid = '', username = '', expiry_time = NULL WHERE nasipaddress = 'x.x.x.135' AND pool_key = '4' AND username = 'jd' AND callingstationid = 'y.y.y.102=5B58665=5D' AND framedipaddress = ''
(7) sqlippool_ipv4: Executing query: UPDATE radippool SET nasipaddress = '', pool_key = 0, callingstationid = '', username = '', expiry_time = NULL WHERE nasipaddress = 'x.x.x.135' AND pool_key = '4' AND username = 'jd' AND callingstationid = 'y.y.y.102=5B58665=5D' AND framedipaddress = ''
rlm_sql_mysql: Rows matched: 0  Changed: 0  Warnings: 0
(7) sqlippool_ipv4: EXPAND COMMIT
(7) sqlippool_ipv4:    --> COMMIT
(7) sqlippool_ipv4: Executing query: COMMIT
(7) sqlippool_ipv4: EXPAND Released IP Framed-IP-Address (did %{Called-Station-Id} cli %{Calling-Station-Id} user %{User-Name})
(7) sqlippool_ipv4:    --> Released IP Framed-IP-Address (did x.x.x.135[4500] cli y.y.y.102[58665] user jd)
rlm_sql (sql): Released connection (7)

----- FULL -X dump 

ATTACHED in file
[radiusdsqlip_bug_dump_jd.txt](https://github.com/FreeRADIUS/freeradius-server/files/2664577/radiusdsqlip_bug_dump_jd.txt)




",True,0,NONE
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/445940528,"nasipaddress unset if connection dies early, leading to stale leased IPs with sqlippool",arr2036,5,389449924,2,445940528,0,389449924,2018-12-10T19:26:29Z,"Stop packet is missing the NAS-IP-Address, so that'd be a bug on the Strongswan side?",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/445942292,"nasipaddress unset if connection dies early, leading to stale leased IPs with sqlippool",Jayd603,5,389449924,3,445942292,0,445940528,2018-12-10T19:31:31Z,"The stop record does appear to have the nas IP?  ..or do you mean another packet outside of the accounting stop?

(7) Received Accounting-Request Id 65 from 127.0.0.1:49280 to 127.0.0.1:1813 length 179
(7)   Acct-Status-Type = Stop
(7)   Acct-Session-Id = ""1544462872-4""
(7)   NAS-Port-Type = Virtual
(7)   Service-Type = Framed-User
(7)   NAS-Port = 4
(7)   NAS-Port-Id = ""radius-pubkey-ike2""
(7)   NAS-IP-Address = x.x.x.135
(7)   Called-Station-Id = ""x.x.x.135[4500]""
(7)   Calling-Station-Id = ""y.y.y.102[58665]""
(7)   User-Name = ""jd""
(7)   Acct-Output-Octets = 0
(7)   Acct-Output-Packets = 0
(7)   Acct-Input-Octets = 0
(7)   Acct-Input-Packets = 0
(7)   Acct-Session-Time = 0
(7)   Acct-Terminate-Cause = User-Request
(7)   NAS-Identifier = ""strongSwan""",False,0,NONE
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/445953935,"nasipaddress unset if connection dies early, leading to stale leased IPs with sqlippool",alandekok,5,389449924,4,445953935,0,445942292,2018-12-10T20:06:25Z,"The ""stop"" packet doesn't have a `Framed-IP-Address` attribute:

> (7) sqlippool_ipv4: --> UPDATE radippool SET nasipaddress = '', pool_key = 0, callingstationid = '', username = '', expiry_time = NULL WHERE nasipaddress = 'x.x.x.135' AND pool_key = '4' AND username = 'jd' AND callingstationid = 'y.y.y.102=5B58665=5D' AND framedipaddress = ''

So that's why it's failing.  Strongswan should be sending the `Framed-IP-Address` that was assigned during authentication.

The default queries include `Framed-IP-Address` because it's possible for the user to have multiple sessions, and to be assigned multiple IPs.  That means the accounting packet *must* contain the correct `Framed-IP-Address`, so we know which IP to release.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/445954757,"nasipaddress unset if connection dies early, leading to stale leased IPs with sqlippool",Jayd603,5,389449924,5,445954757,0,445953935,2018-12-10T20:08:56Z,"Ok, missed that, i'll open an issue on strongswans board.",False,0,NONE
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/445958320,"nasipaddress unset if connection dies early, leading to stale leased IPs with sqlippool",Jayd603,5,389449924,6,445958320,0,445954757,2018-12-10T20:20:21Z,Closed,False,0,NONE
https://api.github.com/repos/magit/magit/issues/3695,Missing autoload for `magit-log-popup`,Alexander-Shukaev,3,391422094,1,391422094,0,0,2018-12-16T00:00:33Z,https://github.com/magit/magit/blob/e50dac59e4d608e807c69cd1e231a30cd4be1433/lisp/magit-log.el#L494-L496,True,0,NONE
https://api.github.com/repos/magit/magit/issues/comments/447659421,Missing autoload for `magit-log-popup`,Alexander-Shukaev,3,391422094,2,447659421,0,391422094,2018-12-16T17:09:32Z,Thanks! 👍 ,False,0,NONE
https://api.github.com/repos/magit/magit/issues/comments/468089397,Missing autoload for `magit-log-popup`,Alexander-Shukaev,3,391422094,3,468089397,0,447659421,2019-02-28T00:41:54Z,"After #3728, we now have only `magit-log`, i.e.:

```emacs-lisp
(define-transient-command magit-log ()
  ""Show a commit or reference log.""
  ...
```

Is there any particular reason why it's not marked as `autoload` now?",False,0,NONE
https://api.github.com/repos/magit/magit/issues/comments/468206330,Missing autoload for `magit-log-popup`,tarsius,3,391422094,4,468206330,0,468089397,2019-02-28T09:44:41Z,"I've removed them by mistake, probably during a rebase. Added them back now.",False,0,MEMBER
https://api.github.com/repos/magit/magit/issues/3704,invalid-function error,seagle0128,5,395069039,1,395069039,0,0,2019-01-01T09:35:02Z,"` Magit 20181229.1434, Git 2.20.1, Emacs 26.1, darwin`

Please refer 
https://github.com/alphapapa/magit-todos/issues/62#event-2049276355


```elisp
Debugger entered--Lisp error: (invalid-function (value (run-hook-with-args-until-success 'magit-section-set-visibility-hook section7)))
  (value (run-hook-with-args-until-success 'magit-section-set-visibility-hook section7))()
  magit-todos--insert-group(:depth 1 :type todos :items (#s(magit-todos-item :filename ""./doom-modeline.el"" :org-level nil :line 1306 :column nil :position nil :keyword ""HACK"" :suffix "":"" :description ""`ace-window-display-mode' should respect the ignore buffers."")) :heading ""TODOs (1)"")
  magit-todos--insert-groups(:type todos :heading ""TODOs (1)"" :group-fns nil :items (#s(magit-todos-item :filename ""./doom-modeline.el"" :org-level nil :line 1306 :column nil :position nil :keyword ""HACK"" :suffix "":"" :description ""`ace-window-display-mode' should respect the ignore buffers."")) :depth 0)
  magit-todos--insert-items(#<buffer magit: doom-modeline> (#s(magit-todos-item :filename ""./doom-modeline.el"" :org-level nil :line 1306 :column nil :position nil :keyword ""HACK"" :suffix "":"" :description ""`ace-window-display-mode' should respect the ignore buffers."")))
  magit-todos--scan-callback(#<buffer magit: doom-modeline> ""\\(?:^\\(?8:[^:]+\\):\\(?2:[[:digit:]]+\\):\\(?:\\(?1:\\*+\\)[[:blank:]]+\\(?4:\\(?:\\?\\?\\?\\|BUG\\|D\\(?:\\(?:EFEC\\|ON\\)T\\)\\|F\\(?:AIL\\|IXME\\)\\|H\\(?:ACK\\|OLD\\)\\|ISSUE\\|KLUDGE\\|NEXT\\|OKAY\\|PROG\\|T\\(?:EMP\\|HEM\\|ODO\\)\\|WORKAROUND\\|XXXX?\\)\\)[[:blank:]]+\\(?5:.+\\)\\|\\(?:.+\\)?\\(?4:\\(?:\\?\\?\\?\\|BUG\\|D\\(?:\\(?:EFEC\\|ON\\)T\\)\\|F\\(?:AIL\\|IXME\\)\\|H\\(?:ACK\\|OLD\\)\\|ISSUE\\|KLUDGE\\|NEXT\\|OKAY\\|PROG\\|T\\(?:EMP\\|HEM\\|ODO\\)\\|WORKAROUND\\|XXXX?\\)\\)\\(?6:\\(?:([^)]+)\\)?:\\)?\\(?:[[:blank:]]+\\)?\\(?5:.+\\)?\\)\\)"" #<process magit-todos--scan-with-rg>)
  apply(magit-todos--scan-callback (#<buffer magit: doom-modeline> ""\\(?:^\\(?8:[^:]+\\):\\(?2:[[:digit:]]+\\):\\(?:\\(?1:\\*+\\)[[:blank:]]+\\(?4:\\(?:\\?\\?\\?\\|BUG\\|D\\(?:\\(?:EFEC\\|ON\\)T\\)\\|F\\(?:AIL\\|IXME\\)\\|H\\(?:ACK\\|OLD\\)\\|ISSUE\\|KLUDGE\\|NEXT\\|OKAY\\|PROG\\|T\\(?:EMP\\|HEM\\|ODO\\)\\|WORKAROUND\\|XXXX?\\)\\)[[:blank:]]+\\(?5:.+\\)\\|\\(?:.+\\)?\\(?4:\\(?:\\?\\?\\?\\|BUG\\|D\\(?:\\(?:EFEC\\|ON\\)T\\)\\|F\\(?:AIL\\|IXME\\)\\|H\\(?:ACK\\|OLD\\)\\|ISSUE\\|KLUDGE\\|NEXT\\|OKAY\\|PROG\\|T\\(?:EMP\\|HEM\\|ODO\\)\\|WORKAROUND\\|XXXX?\\)\\)\\(?6:\\(?:([^)]+)\\)?:\\)?\\(?:[[:blank:]]+\\)?\\(?5:.+\\)?\\)\\)"" #<process magit-todos--scan-with-rg>))
  #f(compiled-function (&rest args2) #<bytecode 0x43b0e139>)(#<process magit-todos--scan-with-rg>)
  async-when-done(#<process magit-todos--scan-with-rg> ""finished\n"")
```",True,0,NONE
https://api.github.com/repos/magit/magit/issues/comments/450747716,invalid-function error,alphapapa,5,395069039,2,450747716,0,395069039,2019-01-01T18:16:33Z,"This is a configuration error, not a bug in Magit or `magit-todos`..  I've asked you twice to start from a clean `~/.emacs.d` and you still have not done so.  Jonas is busy working on Magit and Forge.  Please close this issue and fix your Emacs configuration.",False,0,CONTRIBUTOR
https://api.github.com/repos/magit/magit/issues/comments/450755310,invalid-function error,seagle0128,5,395069039,3,450755310,0,450747716,2019-01-01T20:36:06Z,"@alphapapa I tried with a fresh config indeed and did not upgrade from previous version. I don't know the root cause yet since it doesn't occur every time. But it's deserved to investigate. If you don't want to do that, just leave it there. I'm fine with it.",False,0,NONE
https://api.github.com/repos/magit/magit/issues/comments/450755865,invalid-function error,alphapapa,5,395069039,4,450755865,0,450755310,2019-01-01T20:47:39Z,It is *not* a bug in Magit.  Please close this issue and seek help with your configuration elsewhere.,False,0,CONTRIBUTOR
https://api.github.com/repos/magit/magit/issues/comments/450768823,invalid-function error,tarsius,5,395069039,5,450768823,0,450755865,2019-01-02T00:38:19Z,"I agree with @alphapapa: this is not a bug in Magit and the cause like is outdated byte-code files, which can be fixed by recompiling `magit` and `magit-todo`, in that order.",False,0,MEMBER
https://api.github.com/repos/magit/magit/issues/comments/451516305,invalid-function error,seagle0128,5,395069039,6,451516305,0,450768823,2019-01-04T17:46:57Z,"Thank you @tarsius, @alphapapa !
Finally I found the root cause (maybe not). If I enable `async-bytecomp-package-mode` and install `magit-todos` package, the issue occurs. I have to disable it.",False,0,NONE
https://api.github.com/repos/magit/magit/issues/3705,add subdirectory .gitignore support,ensc,6,395098527,1,395098527,0,0,2019-01-01T17:10:30Z,"It would be nice to have an option to add files to `.gitignore` within subdirectories.  E.g. when selecting `bar` in a dirtree like

```
.
|-- .gitignore
|-- foo
`-- subdir/
    |-- .gitignore
    `--  bar
```

and pressing e.g. `i + s`, `bar` would be added to `subdir/.gitignore` instead of adding an entry `/subdir/bar` in toplevel `.gitignore`.

This resembles the ""ignore"" operation of the deprecated `git-status`.",True,0,NONE
https://api.github.com/repos/magit/magit/issues/comments/455659613,add subdirectory .gitignore support,tarsius,6,395098527,2,455659613,0,395098527,2019-01-18T19:25:00Z,"Well to be honest I think the whole feature is unnecessary.

Personally I edit `.gitignore` manually, which isn't a problem because I have to do that very seldom.

I also think that users that have to add new ignore rules often should take a moment to reflect on what they are doing and if there is a better way.  My guess is that these users ignore new individual files as they are created and I think that it would be better to setup future proof rules that also cover future ignore-worthy files.  For example one should use the pattern `*.o` instead of adding `foo.o` and then later `bar.o`.

While the `magit-gitignore` commands allow specifying patterns I still think these commands are a mistake because the encourage sloppy rules.  To add good rules one has to look add the existing rules and that one can only do by looking at the relevant files.

These commands are here to stay, but I don't intend to improve them because I think users are better of not using them.",False,0,MEMBER
https://api.github.com/repos/magit/magit/issues/comments/455722084,add subdirectory .gitignore support,tarsius,6,395098527,3,455722084,0,455659613,2019-01-18T23:39:11Z,Well that ship has sailed. I might add this after all.,False,0,MEMBER
https://api.github.com/repos/magit/magit/issues/comments/456963747,add subdirectory .gitignore support,tarsius,6,395098527,4,456963747,0,455722084,2019-01-23T20:59:09Z,"Done on the `transient` branch, which will be merged later this month.",False,0,MEMBER
https://api.github.com/repos/magit/magit/issues/comments/457206158,add subdirectory .gitignore support,ensc,6,395098527,5,457206158,0,456963747,2019-01-24T14:00:13Z,thanks for adding this feature... I use it especially in cases like test suites where I have a subdirectory with lot of small programs (e.g. `test-foo.c`) which create binaries (e.g. `test-foo`) which can not be classified by patterns.,False,0,NONE
https://api.github.com/repos/magit/magit/issues/comments/457218371,add subdirectory .gitignore support,tarsius,6,395098527,6,457218371,0,457206158,2019-01-24T14:35:41Z,"How about

```
test-*
!test-*.c
```",False,0,MEMBER
https://api.github.com/repos/magit/magit/issues/comments/457243124,add subdirectory .gitignore support,ensc,6,395098527,7,457243124,0,457218371,2019-01-24T15:41:49Z,"Will work in a lot of cases.  But sometimes, there are hand-written `test-script` scripts or generated `.c` files.  Ignoring the binaries with `i` in old `git-status` was a fast way to filter out the generated files.",False,0,NONE
https://api.github.com/repos/magit/magit/issues/3706,Setup xfuncname for elisp and other filetypes,alphapapa,6,395397820,1,395397820,0,0,2019-01-02T22:12:26Z,"By default, git's `funcname` regexp, which is responsible for determining the containing function for diff hunk context, does not work with elisp.  This can be fixed by:

1.  Add to `repo/.gitattributes`:
```
*.el diff=elisp
```
2.  Add to `repo/.git/config`:
```ini
[diff ""elisp""]
      xfuncname = ^\\(def.*$
```

Emacs lisp is not the only language that may need this kind of change, but it's especially helpful, as it adds `(defun ...` headers to diff hunks.

It seems like it would be a useful feature for Magit to have a way to easily adjust these settings, perhaps with a few common filetypes built-in, so that with a few keypresses, a repo could be configured for elisp.

What do you think?  If this would be a useful addition, I might be able to work on a PR, although it would probably be good to discuss some basic design first, so that whatever I come up with would be ""idiomatically magit"".  :)

Thanks for your work on Magit!",True,0,CONTRIBUTOR
https://api.github.com/repos/magit/magit/issues/comments/451140310,Setup xfuncname for elisp and other filetypes,basil-conto,6,395397820,2,451140310,0,395397820,2019-01-03T13:18:20Z,"See also the corresponding configuration in the Emacs source tree itself: search for ""xfuncname"" in [`autogen.sh`](http://git.savannah.gnu.org/cgit/emacs.git/tree/autogen.sh).",False,0,CONTRIBUTOR
https://api.github.com/repos/magit/magit/issues/comments/451155245,Setup xfuncname for elisp and other filetypes,tarsius,6,395397820,3,451155245,0,451140310,2019-01-03T14:17:04Z,"I think adding some sort of setup wizard is not the best way.  Users who don't know about this feature won't go looking for it and users who know about it but need help setting it up will instead go looking for the documentation.

So I propose we improve the documentation instead.  Personally I would go straight for the Git documentation, but improving the Magit documentation might help some users.

This is what I think we should do:

1. Write a text that explains how the feature works in Git and how Magit uses that. Additionally it should provide some examples and link to the relevant Git documentation.
2. Add the text to the manual and/or wiki.
3. Publish a blog post, which could be identical or just similar to that text.
4. Locate the relevant doc-strings and parts of the manual and link to that text.

Another reason why I don't think any *code* should be added to Magit is that I think each user should use it at most one time.  This should be configured once per language in a global configuration file.

So in summary, I propose that we improve the documentation and make one or more public service announcement, instead of adding code.",False,0,MEMBER
https://api.github.com/repos/magit/magit/issues/comments/452454618,Setup xfuncname for elisp and other filetypes,phil-s,6,395397820,4,452454618,0,451155245,2019-01-08T21:17:30Z,Is there an upstream git issue for this?  It would be good if future git versions supported elisp OOTB.,False,0,CONTRIBUTOR
https://api.github.com/repos/magit/magit/issues/comments/452747154,Setup xfuncname for elisp and other filetypes,kyleam,6,395397820,5,452747154,0,452454618,2019-01-09T15:55:18Z,"> Is there an upstream git issue for this?

Searching ""lisp xfuncname"" at https://public-inbox.org/git/ doesn't suggest that any requests have been made or patches submitted.

>  It would be good if future git versions supported elisp OOTB.

I think it'd be good to add a lisp pattern to userdiff.c, though I believe users would still need to add the gitattributes line.

For anyone interested in submitting a patch, here's an example of a patch that added support for golang: https://public-inbox.org/git/20180301111907.17607-1-alban.gruin@gmail.com/
",False,0,MEMBER
https://api.github.com/repos/magit/magit/issues/comments/455410899,Setup xfuncname for elisp and other filetypes,tarsius,6,395397820,6,455410899,0,452747154,2019-01-18T02:59:26Z,Closing since I am not gonna add any code.,False,0,MEMBER
https://api.github.com/repos/magit/magit/issues/comments/455782624,Setup xfuncname for elisp and other filetypes,tarsius,6,395397820,7,455782624,0,455410899,2019-01-19T14:01:28Z,I've added this to https://github.com/magit/magit/wiki/Important-Git-settings.,False,0,MEMBER
https://api.github.com/repos/spring/spring/issues/416,Cleanup,gajop,3,378837238,1,378837238,0,0,2018-11-08T17:22:56Z,"A few issues are unresolved (left in FIXMEs, hoping for some comment before I tackle it), but other than that this gets me to 0 clang-tidy warnings with my current (uncommitted) check setup, yey.

Some fixes might not be super obvious (like reorganizing constructor parameters in `GameServer.cpp` to satisfy `-Wreorder`), so feel free to open up a discussion.",True,0,MEMBER
https://api.github.com/repos/spring/spring/issues/comments/437568305,Cleanup,gajop,3,378837238,2,437568305,0,378837238,2018-11-10T08:37:31Z,Thanks for the review as usual! I'll wait for your response and then do any additional fixes as necessary.,False,0,MEMBER
https://api.github.com/repos/spring/spring/issues/comments/437748525,Cleanup,gajop,3,378837238,3,437748525,0,437568305,2018-11-12T04:14:59Z,Anything else left (for me to do)? Is it ready for merge?,False,0,MEMBER
https://api.github.com/repos/spring/spring/issues/comments/438752007,Cleanup,rtri,3,378837238,4,438752007,0,437748525,2018-11-14T17:41:24Z,"Nope, thanks.",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/422,SAT based collision detection (develop branch),sanguinariojoe,4,386137186,1,386137186,0,0,2018-11-30T10:53:27Z,"A collision detector based on Separable Axes Theorem (SAT). It is a bit more expensive than the radial check, but make possible to model outstretched bodies:

https://youtu.be/L2W0SO9i62w

Comments:
* WARNING! Very little tested!
* Since the model is more precise, I would say is better to take the unitDef footprint values, and in case they are not available, the moveDef ones. That way, default values can be set by means of the move type, and per-unit overridden. This should be backward compatible, provided that in documentation it's stated that both values shall match. 
* The repulsion model (when a collision is detected) is not affected. But in my tests the effect of the approximations seems negligible.
* The y-direction (bottom-up) interactions are not affected at all, i.e. in that case the radial chek is still used to determine if 2 solids are colliding.",True,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/443173292,SAT based collision detection (develop branch),ashdnazg,4,386137186,2,443173292,0,386137186,2018-11-30T11:17:25Z,"maintenance should only get commits by cherry-picking, so we should only work on this PR.
If this is tested to be ok, I suspect caching {x,z}size * 0.5f * SQUARE_SIZE for each unit can save some computations, but that might need profiling.
Also it's worth noting that if a unit is above another unit, you will use the radius rather than height. (this might be ok, just writing it here so it doesn't surprise anyone).",False,0,MEMBER
https://api.github.com/repos/spring/spring/issues/comments/443176550,SAT based collision detection (develop branch),sanguinariojoe,4,386137186,3,443176550,0,443173292,2018-11-30T11:31:20Z,"> maintenance should only get commits by cherry-picking, so we should only work on this PR.

I'm agree!

> I suspect caching {x,z}size * 0.5f * SQUARE_SIZE for each unit can save some computations

Related to that, I'm not sure if I messed up with x/z directions... It is working with our s44 GERMal model...

> Also it's worth noting that if a unit is above another unit, you will use the radius rather than height. (this might be ok, just writing it here so it doesn't surprise anyone).

Thanks! I updated the description",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/443448819,SAT based collision detection (develop branch),rtri,4,386137186,4,443448819,0,443176550,2018-12-01T18:48:50Z,"The SA test should probably not be enabled unless at least one party wants the extra precision. You can implement this as a boolean flag for now, set to true when an object's footprint is non-square and a global modrule allows using it.

I'll have to think about letting one type of *Def override values from another.",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/443630585,SAT based collision detection (develop branch),sanguinariojoe,4,386137186,5,443630585,0,443448819,2018-12-03T08:40:04Z,"Sorry, I messed up with the branches... I'm reopening it again soon to continue discussing",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/438,"Fix #1382, draw calls see too much under ceasefire",sprunk,4,423508732,1,423508732,0,0,2019-03-20T22:57:25Z,,True,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/475225252,"Fix #1382, draw calls see too much under ceasefire",ashdnazg,4,423508732,2,475225252,0,423508732,2019-03-21T13:19:43Z,"I suspect you haven't tested it locally, and this is the kind of change that might have loads of unintended consequences, so until someone tests this, the PR will wait",False,0,MEMBER
https://api.github.com/repos/spring/spring/issues/comments/477072199,"Fix #1382, draw calls see too much under ceasefire",ashdnazg,4,423508732,3,477072199,0,475225252,2019-03-27T09:59:43Z,"The engine seems quite in conflict with itself whether you should or shouldn't see units of ceasefired allyteams:
https://github.com/spring/spring/blob/develop/rts/Sim/Units/Unit.cpp#L1595",False,0,MEMBER
https://api.github.com/repos/spring/spring/issues/comments/477082609,"Fix #1382, draw calls see too much under ceasefire",sprunk,4,423508732,4,477082609,0,477072199,2019-03-27T10:23:56Z,This PR just makes LuaGL calls consistent with regular unit rendering by making it only look at the LOS_INLOS bit. Whether the engine is inconsistent about setting that bit is orthogonal IMO.,False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/477083714,"Fix #1382, draw calls see too much under ceasefire",ashdnazg,4,423508732,5,477083714,0,477082609,2019-03-27T10:26:31Z,so it should just remove the entire allycheck variable...,False,0,MEMBER
https://api.github.com/repos/spring/spring/issues/442,"Get*Info(id, false) -> no customkeys table alloc",sprunk,5,426539004,1,426539004,0,0,2019-03-28T14:54:52Z,,True,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/477667820,"Get*Info(id, false) -> no customkeys table alloc",rtri,5,426539004,2,477667820,0,426539004,2019-03-28T16:20:32Z,"edit: nm, didn't see the income multiplier arg. Please change `GetTeamInfo`'s order so the options table gets pushed last.",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/477718306,"Get*Info(id, false) -> no customkeys table alloc",sprunk,5,426539004,3,477718306,0,477667820,2019-03-28T18:28:55Z,Why? That would break every existing widget that uses either the table or the multiplier.,False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/477735635,"Get*Info(id, false) -> no customkeys table alloc",rtri,5,426539004,4,477735635,0,477718306,2019-03-28T19:19:02Z,"1) API consistency with `GetPlayerInfo`
2) anyone wanting to take advantage of this (which should be everybody maintaining an active project) will have to adjust calls regardless, two birds one stone etc",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/477739831,"Get*Info(id, false) -> no customkeys table alloc",sprunk,5,426539004,5,477739831,0,477735635,2019-03-28T19:31:43Z,It is done.,False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/477741775,"Get*Info(id, false) -> no customkeys table alloc",rtri,5,426539004,6,477741775,0,477739831,2019-03-28T19:37:38Z,ty,False,0,CONTRIBUTOR
https://api.github.com/repos/tidyverse/lubridate/issues/745,Ceiling date failing,bart1,8,397409578,1,397409578,0,0,2019-01-09T14:59:54Z,"I just encountered this issue (both with devel and current cran, I cant reproduce it on linux with R 3.4.3). The ceiling date of `1970-01-01 00:00:00 UTC` becomes `1969-12-02 UTC`. I will tonight try on a different machine.

```r
> require(lubridate)
> t<-structure(c(0, 86.4864864864865, 172.972972972973, 259.459459459459, 345.945945945946, 432.432432432432), class = 
+ c(""POSIXct"", ""POSIXt""), tzone = ""UTC"")   
> floor_date(t, unit='day')
[1] ""1970-01-01 UTC"" ""1970-01-01 UTC"" ""1970-01-01 UTC"" ""1970-01-01 UTC""
[5] ""1970-01-01 UTC"" ""1970-01-01 UTC""
> ceiling_date(t, unit='day')
[1] ""1969-12-02 UTC"" ""1970-01-02 UTC"" ""1970-01-02 UTC"" ""1970-01-02 UTC""
[5] ""1970-01-02 UTC"" ""1970-01-02 UTC""
> sessionInfo()
R version 3.5.1 (2018-07-02)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: OS X El Capitan 10.11.6

Matrix products: default
BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
LAPACK: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libLAPACK.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] lubridate_1.7.4.9000

loaded via a namespace (and not attached):
[1] compiler_3.5.1 Rcpp_1.0.0
```",True,0,NONE
https://api.github.com/repos/tidyverse/lubridate/issues/comments/452792035,Ceiling date failing,bart1,8,397409578,2,452792035,0,397409578,2019-01-09T17:57:54Z,"For the record the bug reproduces on a indepentent osx system
```r
> require(lubridate)
Loading required package: lubridate

Attaching package: ‘lubridate’

The following object is masked from ‘package:base’:

    date

> t<-structure(c(0, 86.4864864864865, 172.972972972973, 259.459459459459, 345.945945945946, 432.432432432432), class = c(""POSIXct"", ""POSIXt""), tzone = ""UTC"") 
> ceiling_date(t, unit='day')
[1] ""1969-12-02 UTC"" ""1970-01-02 UTC"" ""1970-01-02 UTC"" ""1970-01-02 UTC""
[5] ""1970-01-02 UTC"" ""1970-01-02 UTC""
> sessionInfo()
R version 3.5.1 (2018-07-02)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: macOS High Sierra 10.13.6

Matrix products: default
BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] lubridate_1.7.4

loaded via a namespace (and not attached):
[1] compiler_3.5.1 magrittr_1.5   tools_3.5.1    yaml_2.2.0     Rcpp_1.0.0    
[6] stringi_1.2.4  stringr_1.3.1 
```",False,0,NONE
https://api.github.com/repos/tidyverse/lubridate/issues/comments/452807489,Ceiling date failing,bart1,8,397409578,3,452807489,0,452792035,2019-01-09T18:37:47Z,"An ubuntu system works correctly
```r
> require(lubridate)
Loading required package: lubridate

Attaching package: ‘lubridate’

The following object is masked from ‘package:base’:

    date

> t<-structure(c(0, 86.4864864864865, 172.972972972973, 259.459459459459, 345.945945945946, 432.432432432432), class = c(""POSIXct"", ""POSIXt""), tzone = ""UTC"") 
> ceiling_date(t, unit='day')
[1] ""1970-01-01 UTC"" ""1970-01-02 UTC"" ""1970-01-02 UTC"" ""1970-01-02 UTC""
[5] ""1970-01-02 UTC"" ""1970-01-02 UTC""
> sessionInfo()
R version 3.5.2 (2018-12-20)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 18.04.1 LTS

Matrix products: default
BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.7.1
LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.7.1

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=de_CH.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=de_CH.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=de_CH.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=de_CH.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] lubridate_1.7.4

loaded via a namespace (and not attached):
[1] compiler_3.5.2 magrittr_1.5   tools_3.5.2    Rcpp_1.0.0     stringi_1.2.4 
[6] stringr_1.3.1 
```",False,0,NONE
https://api.github.com/repos/tidyverse/lubridate/issues/comments/453635266,Ceiling date failing,vspinu,8,397409578,4,453635266,0,452807489,2019-01-11T19:44:17Z,"Looks like OS dependent issue. Would you mind installing `timechange` package and trying 

```R
timechange::time_ceiling(ymd(""1970-01-01"", tz = ""UTC""), ""day"")
```

I had in plan to move lubridate on top of timechange for a while but just couldn't find time. If it works for you I will make it a higher priority. Thanks. ",False,0,MEMBER
https://api.github.com/repos/tidyverse/lubridate/issues/comments/454362000,Ceiling date failing,bart1,8,397409578,5,454362000,0,453635266,2019-01-15T11:34:13Z,"That seems to work
```r
> timechange::time_ceiling(lubridate::ymd(""1970-01-01"", tz = ""UTC""), ""day"")
[1] ""1970-01-01 UTC""
> sessionInfo()
R version 3.5.1 (2018-07-02)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: OS X El Capitan 10.11.6
> t<-structure(c(0, 86.4864864864865, 172.972972972973, 259.459459459459, 345.945945945946, 432.432432432432), class = c(""POSIXct"", ""POSIXt""), tzone = ""UTC"") 
> timechange::time_ceiling(t, ""day"")
[1] ""1970-01-01 UTC"" ""1970-01-02 UTC"" ""1970-01-02 UTC"" ""1970-01-02 UTC""
[5] ""1970-01-02 UTC"" ""1970-01-02 UTC""
```",False,0,NONE
https://api.github.com/repos/tidyverse/lubridate/issues/comments/552292078,Ceiling date failing,Blundys,8,397409578,6,552292078,0,454362000,2019-11-11T04:49:52Z,"FYI I also have this problem. Problem doesn't only occur right at 1970, but seems like the first of any month (I've tried about 10 dates) before 1970 encounters this problem. Changing to timechange::time_ceiling also fixes the problem for me.

``` r
library(lubridate)
#> 
#> Attaching package: 'lubridate'
#> The following object is masked from 'package:base':
#> 
#>     date

#works as expected
testdatePost1970 <- as.POSIXct(""1971-09-01 00:00"", format = ""%Y-%m-%d %H:%M"", tz = ""UTC"")

ceiling_date(testdatePost1970, unit = ""day"", change_on_boundary = F)
#> [1] ""1971-09-01 UTC""
ceiling_date(testdatePost1970, unit = ""day"", change_on_boundary = T)
#> [1] ""1971-09-02 UTC""

#gives completely unexpected date if change_on_boundary = F

testdatePre1970 <- as.POSIXct(""1959-09-01 00:00"", format = ""%Y-%m-%d %H:%M"", tz = ""UTC"")

ceiling_date(testdatePre1970, unit = ""day"", change_on_boundary = F)
#> [1] ""1959-08-02 UTC""
ceiling_date(testdatePre1970, unit = ""day"", change_on_boundary = T)
#> [1] ""1959-09-02 UTC""


timechange::time_ceiling(testdatePre1970, ""day"",change_on_boundary = F)
#> [1] ""1959-09-01 UTC""
timechange::time_ceiling(testdatePre1970, ""day"",change_on_boundary = T)
#> [1] ""1959-09-02 UTC""


sessionInfo()
#> R version 3.5.3 (2019-03-11)
#> Platform: x86_64-w64-mingw32/x64 (64-bit)
#> Running under: Windows 10 x64 (build 17763)
#> 
#> Matrix products: default
#> 
#> locale:
#> [1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252   
#> [3] LC_MONETARY=English_Australia.1252 LC_NUMERIC=C                      
#> [5] LC_TIME=English_Australia.1252    
#> 
#> attached base packages:
#> [1] stats     graphics  grDevices utils     datasets  methods   base     
#> 
#> other attached packages:
#> [1] lubridate_1.7.4
#> 
#> loaded via a namespace (and not attached):
#>  [1] compiler_3.5.3   magrittr_1.5     tools_3.5.3      htmltools_0.3.6 
#>  [5] yaml_2.2.0       Rcpp_1.0.1       stringi_1.4.3    rmarkdown_1.13  
#>  [9] highr_0.8        knitr_1.23       stringr_1.4.0    xfun_0.7        
#> [13] digest_0.6.19    timechange_0.0.1 evaluate_0.13
```

<sup>Created on 2019-11-11 by the [reprex package](https://reprex.tidyverse.org) (v0.3.0)</sup>
",False,0,NONE
https://api.github.com/repos/tidyverse/lubridate/issues/comments/555761630,Ceiling date failing,hadley,8,397409578,7,555761630,0,552292078,2019-11-19T23:21:07Z,"Minimal reprex:

``` r
library(lubridate, warn.conflicts = FALSE)

ceiling_date(ymd(""1970-01-01"", tz = ""UTC""), ""day"")
#> [1] ""1969-12-02 UTC""
timechange::time_ceiling(ymd(""1970-01-01"", tz = ""UTC""), ""day"")
#> [1] ""1970-01-01 UTC""
```

<sup>Created on 2019-11-19 by the [reprex package](https://reprex.tidyverse.org) (v0.3.0)</sup>",False,0,MEMBER
https://api.github.com/repos/tidyverse/lubridate/issues/comments/847863588,Ceiling date failing,DavisVaughan,8,397409578,8,847863588,0,555761630,2021-05-25T13:19:27Z,"Also works with clock

``` r
library(clock)

date_ceiling(date_time_build(1970, 1, 1, zone = ""UTC""), precision = ""day"")
#> [1] ""1970-01-01 UTC""
```",False,0,MEMBER
https://api.github.com/repos/tidyverse/lubridate/issues/comments/1304540530,Ceiling date failing,vspinu,8,397409578,9,1304540530,0,847863588,2022-11-05T12:47:34Z,Moved on top of timechange. Issue should be fixed. ,False,0,MEMBER
https://api.github.com/repos/tidyverse/lubridate/issues/746,Changed Duration format to correctly display negative values,hglanz,4,401023874,1,401023874,0,0,2019-01-19T18:52:07Z,Fixes #719 ,True,0,NONE
https://api.github.com/repos/tidyverse/lubridate/issues/comments/555758496,Changed Duration format to correctly display negative values,hadley,4,401023874,2,555758496,0,401023874,2019-11-19T23:09:55Z,"If, you're interested in finishing this off, would you mind add a small unit test?  No worries, if you're not, just let me know and I'll get it over the finish line for you.",False,0,MEMBER
https://api.github.com/repos/tidyverse/lubridate/issues/comments/556961194,Changed Duration format to correctly display negative values,hglanz,4,401023874,3,556961194,0,555758496,2019-11-21T07:43:41Z,"I can definitely put a unit test together for this! Thanks for taking a look. Would you mind if I don't get to it for a couple of days? If you do, then I'm perfectly happy for you to take it over the finish line...I don't want to hold anything up.",False,0,NONE
https://api.github.com/repos/tidyverse/lubridate/issues/comments/557069543,Changed Duration format to correctly display negative values,hadley,4,401023874,4,557069543,0,556961194,2019-11-21T12:47:10Z,No rush!,False,0,MEMBER
https://api.github.com/repos/tidyverse/lubridate/issues/comments/562888049,Changed Duration format to correctly display negative values,vspinu,4,401023874,5,562888049,0,557069543,2019-12-07T21:24:19Z,I have fixed this at the root in `compute_estimate`. Thanks for pushing through!,False,0,MEMBER
https://api.github.com/repos/tidyverse/lubridate/issues/750,ceiling_date returning NA for a specific week,pmhaddad,7,411649591,1,411649591,0,0,2019-02-18T21:25:10Z,"Hello. I think I'm getting unexpected behavior with `ceiling_date()` using `week` as unit, , when the date is formatted as `POSIX.ct`. It is returning `NA` for the week between **2018-10-28** and **2018-11-03** Example:
```
> ceiling_date(x = as.POSIXct('2018-10-21 04:02:00'), unit = 'week')
[1] ""2018-10-28 -03""
> ceiling_date(x = as.POSIXct('2018-10-28 04:02:00'), unit = 'week')
[1] NA
> ceiling_date(x = as.POSIXct('2018-11-03 04:02:00'), unit = 'week')
[1] NA
> ceiling_date(x = as.POSIXct('2018-11-04 04:02:00'), unit = 'week')
[1] ""2018-11-11 -02""
```

<details>

When the format is `as.Date`, it works fine:
```
> ceiling_date(x = as.Date('2018-10-28 04:02:00'), unit = 'week')
[1] ""2018-11-04""
> ceiling_date(x = as.Date('2018-11-03 04:02:00'), unit = 'week')
[1] ""2018-11-04""
```
It also works when the date is in `ymd_hms` format:
```
> ceiling_date(x = ymd_hms('2018-10-28 04:02:00'), unit = 'week')
[1] ""2018-11-04 UTC""
> ceiling_date(x = ymd_hms('2018-11-03 04:02:00'), unit = 'week')
[1] ""2018-11-04 UTC""
```
This is my `SessionInfo()`:
```
R version 3.5.2 (2018-12-20)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows >= 8 x64 (build 9200)

Matrix products: default

locale:
[1] LC_COLLATE=Portuguese_Brazil.1252  LC_CTYPE=Portuguese_Brazil.1252    LC_MONETARY=Portuguese_Brazil.1252 LC_NUMERIC=C                      
[5] LC_TIME=Portuguese_Brazil.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] lubridate_1.7.4

loaded via a namespace (and not attached):
 [1] compiler_3.5.2   magrittr_1.5     rsconnect_0.8.13 htmltools_0.3.6  tools_3.5.2      base64enc_0.1-3  yaml_2.2.0       Rcpp_1.0.0       rmarkdown_1.11  
[10] stringi_1.3.1    knitr_1.21       jsonlite_1.6     digest_0.6.18    stringr_1.4.0    xfun_0.4         evaluate_0.13   
```
Am I doing something wrong, or is this indeed unexpected?
</details>",True,0,NONE
https://api.github.com/repos/tidyverse/lubridate/issues/comments/464895061,ceiling_date returning NA for a specific week,pmhaddad,7,411649591,2,464895061,0,411649591,2019-02-18T21:57:10Z,"_Quick follow up_: despite reviewing previous issues before posting, only after I created this issue I found other users encountering similar results for dates near **daylight saving time** (DST) **beginnings**. This was the case for the date I mentioned: `2018-11-04 00:00:00`, which was the DST start date.

I'm not going to close the issue because I'm not completely sure that `NA` should be returned in those cases, but in case it should, feel free to close the issue.

I'm sorry that I only found this after posting!",False,0,NONE
https://api.github.com/repos/tidyverse/lubridate/issues/comments/465012519,ceiling_date returning NA for a specific week,cderv,7,411649591,3,465012519,0,464895061,2019-02-19T07:10:07Z,"I don't know why but I don't get the NA when I try to reproduce
``` r
library(lubridate)
#> 
#> Attachement du package : 'lubridate'
#> The following object is masked from 'package:base':
#> 
#>     date
packageVersion(""lubridate"")
#> [1] '1.7.4'
ceiling_date(x = as.POSIXct('2018-10-21 04:02:00'), unit = 'week')
#> [1] ""2018-10-28 UTC""
ceiling_date(x = as.POSIXct('2018-10-28 04:02:00'), unit = 'week')
#> [1] ""2018-11-04 UTC""
ceiling_date(x = as.POSIXct('2018-11-03 04:02:00'), unit = 'week')
#> [1] ""2018-11-04 UTC""
ceiling_date(x = as.POSIXct('2018-11-04 04:02:00'), unit = 'week')
#> [1] ""2018-11-11 UTC""
```

<sup>Created on 2019-02-19 by the [reprex package](https://reprex.tidyverse.org) (v0.2.1)</sup>
",False,0,CONTRIBUTOR
https://api.github.com/repos/tidyverse/lubridate/issues/comments/465089159,ceiling_date returning NA for a specific week,pmhaddad,7,411649591,4,465089159,0,465012519,2019-02-19T11:11:41Z,"Hello.
Maybe it is because the beginning of this **daylight saving time** - `2018-10-04 00:00:00` - was specific to my time zone? I'm guessing that since I was not originally defining `tz`, it was using my System's value? See:
```
> ceiling_date(x = as.POSIXct('2018-10-28 04:02:00', tz = 'America/Sao_Paulo'), unit = 'week')
[1] NA
> ceiling_date(x = as.POSIXct('2018-10-28 04:02:00', tz = 'Europe/Paris'), unit = 'week')
[1] ""2018-11-04 CET""
> ceiling_date(x = as.POSIXct('2018-10-28 04:02:00', tz = 'UTC'), unit = 'week')
[1] ""2018-11-04 UTC""
```
It appears that is only affecting `ceiling_date()` on my `tz`.",False,0,NONE
https://api.github.com/repos/tidyverse/lubridate/issues/comments/466337821,ceiling_date returning NA for a specific week,vspinu,7,411649591,5,466337821,0,465089159,2019-02-22T09:45:06Z,"It's a bug. Please use `timechange` package for now:

```R
x <- ymd_hms('2018-10-28 04:02:00', tz = 'America/Sao_Paulo')
timechange::time_ceiling(x, unit = 'week')
## [1] ""2018-10-29 -03""
```
I haven't had time to re-base lubridate on top of `timechange` but it should happen sooner or later. ",False,0,MEMBER
https://api.github.com/repos/tidyverse/lubridate/issues/comments/555762201,ceiling_date returning NA for a specific week,hadley,7,411649591,6,555762201,0,466337821,2019-11-19T23:23:05Z,"Minimal reprex:

``` r
library(lubridate, warn.conflicts = FALSE)

x <- ymd_hms('2018-10-28 04:02:00', tz = 'America/Sao_Paulo')

ceiling_date(x, ""week"")
#> [1] NA
timechange::time_ceiling(x, ""week"")
#> [1] ""2018-10-29 -03""
```

<sup>Created on 2019-11-19 by the [reprex package](https://reprex.tidyverse.org) (v0.3.0)</sup>",False,0,MEMBER
https://api.github.com/repos/tidyverse/lubridate/issues/comments/847869168,ceiling_date returning NA for a specific week,DavisVaughan,7,411649591,7,847869168,0,555762201,2021-05-25T13:26:45Z,"With clock:

``` r
library(clock)
library(magrittr)

x <- date_time_parse(""2018-10-28 04:02:00"", zone = ""America/Sao_Paulo"")

# Uses 1970-01-01 origin, which is a thursday
date_ceiling(x, ""week"")
#> [1] ""2018-11-01 -03""

# Find a monday, which is what timechange uses as an origin
origin <- date_shift(
  date_time_parse(""1970-01-01"", ""America/Sao_Paulo"", format = ""%Y-%m-%d""),
  weekday(clock_weekdays$monday)
)

date_ceiling(x, ""week"", origin = origin)
#> [1] ""2018-10-29 -03""
```

<sup>Created on 2021-05-25 by the [reprex package](https://reprex.tidyverse.org) (v1.0.0)</sup>",False,0,MEMBER
https://api.github.com/repos/tidyverse/lubridate/issues/comments/1304541292,ceiling_date returning NA for a specific week,vspinu,7,411649591,8,1304541292,0,847869168,2022-11-05T12:52:50Z,Fixed after moving on top of timechange. ,False,0,MEMBER
https://api.github.com/repos/tidyverse/lubridate/issues/753,Round date for months is dependant on month length,rlh1994,4,413810536,1,413810536,0,0,2019-02-24T11:17:18Z,"I'm not sure if this is by design, but when rounding dates to the nearest e.g. 2 months (or using bimonth) when the date is the first of the second, longer month, then it has to be past midday for the round to go up, otherwise it goes down. I would have assumed rounding to the nearest n months wouldn't want to depend on the different length of months, only the length of the month that the date is in as otherwise this is a little counter-intuitive to what you might expect (especially if it involved February).

The below demonstrates this for the 1st December, and the more extreme case of the 30th January.

```r
library(lubrdiate)
round_date(as.POSIXct('2018-12-01 07:00:00', format = '%Y-%m-%d %H:%M:%S'), unit= '2 months')
# ""2018-11-01 GMT""
round_date(as.POSIXct('2018-12-01 12:00:01', format = '%Y-%m-%d %H:%M:%S'), unit= '2 months')
# ""2019-01-01 GMT""

round_date(as.POSIXct('2018-01-30 07:00:00', format = '%Y-%m-%d %H:%M:%S'), unit= '2 months')
# ""2018-01-01 GMT""
round_date(as.POSIXct('2018-01-30 12:00:01', format = '%Y-%m-%d %H:%M:%S'), unit= '2 months')
# ""2018-03-01 GMT""
```
I'm using R version 3.5.2 and have tested it on lubrdiate v 1.7.4.9000",True,0,NONE
https://api.github.com/repos/tidyverse/lubridate/issues/comments/466781974,Round date for months is dependant on month length,vspinu,4,413810536,2,466781974,0,413810536,2019-02-24T14:28:25Z,"It depends on the definition of rounding. Currently rounding just chooses the side (ceiling or floor) based on the absolute time difference between the sides and the supplied time. This part is consistent for all units and I think this is what most of the uses of rounding would assume. Making a special case for months and years would complicate the code with little benefit. So I would rather not add this extra option. 

I think `round_date(x, ""m"") %>% round_date(""2m"")` should do what you need, no?",False,0,MEMBER
https://api.github.com/repos/tidyverse/lubridate/issues/comments/466784966,Round date for months is dependant on month length,rlh1994,4,413810536,3,466784966,0,466781974,2019-02-24T15:06:58Z,"That's fair. I guess it is mostly a subjective thing, if you asked me to round 30th Jan to either 1st Jan or 1st March I would probably say 1st Jan for most use cases, same with 1st December, I'd likely round to 1st Jan rather than November, but that might just be me and it probably is better to keep a consistent case for all units.

That solution doesn't quite do it, it provides consistency within a day as the time is removed, but in the examples it leads to the december example being rounded down still, and the January example being rounded up (both of which based on above I don't want).

This solution seems to work but is a bit clumsy, flooring the date to the month then setting the month based on the month value rounded

    x <- as.POSIXct('2018-12-01 07:00:01', format = '%Y-%m-%d %H:%M:%S')
    x <- x %>% floor_date(""m"") %>% `month<-`(floor(month(x)/2)*2 +1)

I will have to keep this in mind in the future, thanks.",False,0,NONE
https://api.github.com/repos/tidyverse/lubridate/issues/comments/467347642,Round date for months is dependant on month length,vspinu,4,413810536,4,467347642,0,466784966,2019-02-26T08:39:33Z,"
Thiis particular logic is valid for `2 months` rounding. You basically want floor for odd months and ceiling for even months. It's not immediately clear what should we do with `3 months` rounding. 

A generic algorithm for this style of rounding would be to transform the date into a decimal month first, round and then get back to the date. 

I will keep this open, but it's low priority. In any case this should be an extra option to the `round_date` function. I think, changing the default is a bit too late. ",False,0,MEMBER
https://api.github.com/repos/tidyverse/lubridate/issues/comments/467608189,Round date for months is dependant on month length,rlh1994,4,413810536,5,467608189,0,467347642,2019-02-26T20:50:47Z,"I agree that makes the most sense, and that would also negate any impact of current scripts. Thanks for understanding :) ",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/8543,new analog option,ghost,13,428860002,1,428860002,0,0,2019-04-03T16:21:43Z,Well this all works well but how do we test if an input is analog the thing with analog it sends a spike now and then so you can easily tell its not digital. If its on a deazone with no spike there is no way to tell if it is analog or digital. I would suggest returning a none zero number enough to pick up its an analog control. Again its up to you guys,True,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/479699244,new analog option,rsn8887,13,428860002,2,479699244,0,428860002,2019-04-03T23:54:28Z,"What you describe is a terrible way to test whether an input is analog or not. I hope it is not being used anywhere. I might be naive, but I would say there should be no need to test whether an input is analog or digital. The API should provide this information to the cores, no testing needed.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/479707581,new analog option,ghost,13,428860002,3,479707581,0,479699244,2019-04-04T00:42:29Z,"Well Im not aware of the api providing this information you mind telling me how the api tells us ? I dont see how reading analog if a value is bigger than 1 or less than zero is terrible it reading the behavior of an anlog device that has voltage spikes 


https://github.com/libretro/RetroArch/blob/1a3ec1c3be85df8262a2aa9b4460c0545491ca5c/libretro-common/include/libretro.h#L183-L210",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/479713025,new analog option,ghost,13,428860002,4,479713025,0,479707581,2019-04-04T01:14:49Z,"looks like beetle is also checking the value 0. Hopefully there is an api function to tell us this information.

https://github.com/libretro/beetle-psx-libretro/blob/53591985319edc34d83a0858ad9a935b934dcf5c/input.cpp#L208-L238
",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/479729551,new analog option,rsn8887,13,428860002,5,479729551,0,479713025,2019-04-04T02:48:55Z,"The api names have ANALOG in them for all analog inputs. So far so good. However I don’t understand why the id is the same for ANALOG_BUTTON_ and JOYPAD_? Clearly one is an analog and one is a digital control. They shouldn’t have the same id in my opinion.

Is this an oversight in the api specification for retropad?",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/479891620,new analog option,orbea,13,428860002,6,479891620,0,479729551,2019-04-04T13:14:16Z,We have an issue template for a reason...,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/479927893,new analog option,ghost,13,428860002,7,479927893,0,479891620,2019-04-04T14:46:25Z,"what info do you need ra version is 

[INFO] RetroArch 1.7.6 (Git 8639018976)
[INFO] === Build =======================================
[INFO] CPU Model Name: Intel(R) Core(TM) i3-5005U CPU @ 2.00GHz
[INFO] Capabilities: MMX MMXEXT SSE1 SSE2 SSE3 SSSE3 SSE4 SSE4.2 AVX AES
[INFO] Built: Mar 31 2019
[INFO] Version: 1.7.6
[INFO] Git: 8639018976


the question is simple how do you find out if a button is analog or not before starting a core so you can set the controls appropriately. IE a snes pad will be all digital and a xbox pad will have two analog buttons ",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/479930095,new analog option,rsn8887,13,428860002,8,479930095,0,479927893,2019-04-04T14:51:34Z,"Looking at the beetle example more closely, I don't see the problem anymore.

If you want to read analog buttons in the core, use 
```
input_state_cb( player_index, RETRO_DEVICE_ANALOG, RETRO_DEVICE_INDEX_ANALOG_BUTTON, id);
```

If you want to read digital buttons in the core, use something like
```
input_state_cb( player_index, RETRO_DEVICE_JOYPAD, 0, id );
```
A return of zero has the same meaning in both cases: not pressed.

Of course, when you read analog buttons, you might not want to treat a returned number 1 as pressed because the user might have set the deadzone to zero, and the values go up to 32k. For digital buttons, I think a 1 should count as pressed.

AFAIK now, the API *does* provide clear different mechanisms to read analog vs digital (see above). So you know what you are reading and what to expect in either case.

It doesn't hurt to check both analog and digital buttons whether they are pressed, but that depends on the core and the mapping.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/479934971,new analog option,ghost,13,428860002,9,479934971,0,479930095,2019-04-04T15:02:43Z,"the thing is this relies on you pressing the button to find out that not ideal for the situation. Here is an example I have a snes pad and a xbox 360 or psx pad. 

I want to setup the controls depending on what pads plugged in. I guess you could do a manual select on options->controls it would be nice to have a way to detect the gamepads capabilities maybe there is i dont know. ",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/479953953,new analog option,andres-asm,13,428860002,10,479953953,0,479934971,2019-04-04T15:48:36Z,"I don't even understand what's going on...
The new analog deadzone option is a FRONTEND feature and has nothing to do with the API.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/480016300,new analog option,ghost,13,428860002,11,480016300,0,479953953,2019-04-04T18:41:56Z,"I just want to know how to find out if a given controller plugged in has analog axis available  without the need to press every button to find out if it has an analog axis.  

So i can either map the controller as digital or analog.
",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/480017688,new analog option,andres-asm,13,428860002,12,480017688,0,480016300,2019-04-04T18:45:52Z,"There is not sure way to tell, and the physical gamepad has no bearing in this discussion.
The cores only know about one gamepad. RETROPAD

There are two variations

- RETRO_DEVICE_JOYPAD which looks like a SNES gamepad
- RETRO_DEVICE_ANALOG which looks like a WiiU Pro gamepad/Dualshock

That's all there is to it. Any other variation is up to the frontend",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/480023692,new analog option,ghost,13,428860002,13,480023692,0,480017688,2019-04-04T19:03:39Z,Well that answers the question you cant tell physical gamepads characteristics to map it to an appropiate retropad. I guess ill just add controller types. That aside there is a bug in the deadzone code when you set it the l2and r2 analog triggers stop working for some reason,False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/480542145,new analog option,ghost,13,428860002,14,480542145,0,480023692,2019-04-06T22:16:52Z,"L2/R2 works fine for me with both analog deadzone/sensitivity set to non-default values, please file a separate bug for this, and make sure you're testing using the latest git master code as well.",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/8545,[Linux] Retroarch should ignore keys that are pressed as system shortcuts.,Blast-City,13,429022932,1,429022932,0,0,2019-04-03T23:53:40Z,"elementary OS Juno (Ubuntu 18.04).
Retroarch from the stable repository. Fully updated.

1- Open Retroarch
2- Press Super+Right Arrow to switch to another workspace

**Result:** The workspace changes, but Retroarch's menu also changes.

Is this the normal behaviour? Shouldn't Retroarch ignore the arrow keys when it's pressed as a system keyboard shortcut?

On Firefox as soon as i press the Super key, keyboard inputs are disabled. The same happens on Steam main window or in the terminal. Steam video player also have a similar problem as Retroarch.",True,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/479891206,[Linux] Retroarch should ignore keys that are pressed as system shortcuts.,orbea,13,429022932,2,479891206,0,429022932,2019-04-04T13:13:00Z,"This is not a good idea, these keys are going to differ from system to system and the only way to ""solve"" it is to ignore all keys which is just not going to happen.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/479970897,[Linux] Retroarch should ignore keys that are pressed as system shortcuts.,Blast-City,13,429022932,3,479970897,0,479891206,2019-04-04T16:32:47Z,"> This is not a good idea, these keys are going to differ from system to system and the only way to ""solve"" it is to ignore all keys which is just not going to happen.

Hi.

Maybe I'm not understanding what you're saying, but I was just talking about when the Super key is pressed.

If i press Super right now on firefox i can't write any more letters on this box. So Firefox seems to be aware of which keys are system shortcuts.

The same happens on terminal. If i press the Super key the cursor becomes an empty box and you can't press any more keys.

Thanks.",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/479976254,[Linux] Retroarch should ignore keys that are pressed as system shortcuts.,orbea,13,429022932,4,479976254,0,479970897,2019-04-04T16:48:01Z,What if the user doesn't use the windows key and uses `alt` instead? What if they are using another arbitrary key like `w`? I guess this might even be a key combination...,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/479986204,[Linux] Retroarch should ignore keys that are pressed as system shortcuts.,orbea,13,429022932,5,479986204,0,479976254,2019-04-04T17:16:12Z,"Also, fwiw I can't reproduce this at all. RetroArch and firefox both correctly recognize that I am pressing `mod+arrow key` instead of `mod` and the `arrow key`.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/479996823,[Linux] Retroarch should ignore keys that are pressed as system shortcuts.,Blast-City,13,429022932,6,479996823,0,479986204,2019-04-04T17:46:48Z,"> Also, fwiw I can't reproduce this at all. RetroArch and firefox both correctly recognize that I am pressing `mod+arrow key` instead of `mod` and the `arrow key`.

Hi.

When you click on the address bar of Firefox and press the Super key what happens? Can you input any letters while pressing the super key?

On my computer as soon you press Super you can't press any key. It's like it is on a lock state.",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/480055456,[Linux] Retroarch should ignore keys that are pressed as system shortcuts.,orbea,13,429022932,7,480055456,0,479996823,2019-04-04T20:41:10Z,"Firefox is not blocking the key, its recognizing its a key combo and not a single key being pressed where firefox doesn't use any such key combos by default and hence does nothing. This should be the same in RetroArch and I can't reproduce otherwise.

What RetroArch version are you using? What input driver are you using in RetroArch? Do you have any conflicting non-default keybinds in your RetroArch configuration?",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/480133914,[Linux] Retroarch should ignore keys that are pressed as system shortcuts.,Blast-City,13,429022932,8,480133914,0,480055456,2019-04-05T03:09:27Z,"> Firefox is not blocking the key, its recognizing its a key combo and not a single key being pressed where firefox doesn't use any such key combos by default and hence does nothing. This should be the same in RetroArch and I can't reproduce otherwise.
> 
> What RetroArch version are you using? What input driver are you using in RetroArch? Do you have any conflicting non-default keybinds in your RetroArch configuration?

Latest version on the stable repo. Default configuration.

If i go to Youtube on Firefox and I play a video, using the arrow keys makes the videos fast-forward or go backward, but if i press Super+Arrow keys (workspace switch shortcut) the video continues to play normally (arrow keys ignored) and the workspace switches to another one.

If i do the same on Retroarch main menu, the arrow keys are accepted, so the menu changes at the same time as the workspace switch. I think this behaviour shouldn't be happening because when you go back to the retroarch workspace what is on the screen is not the same as it was when you switched workspaces.

Maybe ignore key presses if the window looses focus, but the input would probably reach Retroarch before the lost of focus.",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/480162340,[Linux] Retroarch should ignore keys that are pressed as system shortcuts.,orbea,13,429022932,9,480162340,0,480133914,2019-04-05T06:24:38Z,"> Latest version on the stable repo. Default configuration.

Which is what version?",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/480300828,[Linux] Retroarch should ignore keys that are pressed as system shortcuts.,Blast-City,13,429022932,10,480300828,0,480162340,2019-04-05T14:41:01Z,"> > Latest version on the stable repo. Default configuration.
> 
> Which is what version?

https://launchpadlibrarian.net/410056719/retroarch_1.7.6-r201902062228-9750719-83~ubuntu18.04.1_source.changes",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/480305626,[Linux] Retroarch should ignore keys that are pressed as system shortcuts.,orbea,13,429022932,11,480305626,0,480300828,2019-04-05T14:53:27Z,"So `1.7.6`...

> If i do the same on Retroarch main menu, the arrow keys are accepted, so the menu changes at the same time as the workspace switch. I think this behaviour shouldn't be happening because when you go back to the retroarch workspace what is on the screen is not the same as it was when you switched workspaces.

This shouldn't happen, what input driver are you using? Is with with x or wayland?

@hunterk Can you reproduce this?",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/480307552,[Linux] Retroarch should ignore keys that are pressed as system shortcuts.,orbea,13,429022932,12,480307552,0,480305626,2019-04-05T14:58:32Z,"Okay, I can kind of reproduce this...

I am getting stray key input when switching to the workspace with RetroArch, but not when switching away. This also clearly affects a KMS context, but that is not really a problem.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/480319064,[Linux] Retroarch should ignore keys that are pressed as system shortcuts.,orbea,13,429022932,13,480319064,0,480307552,2019-04-05T15:29:22Z,"Given how confusing this issue is and the how the issue template was ignored I made a new issue that is hopefully easier to understand. I hope this works for you?

https://github.com/libretro/RetroArch/issues/8550",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/480336379,[Linux] Retroarch should ignore keys that are pressed as system shortcuts.,Blast-City,13,429022932,14,480336379,0,480319064,2019-04-05T16:20:04Z,"> So `1.7.6`...
> 
> > If i do the same on Retroarch main menu, the arrow keys are accepted, so the menu changes at the same time as the workspace switch. I think this behaviour shouldn't be happening because when you go back to the retroarch workspace what is on the screen is not the same as it was when you switched workspaces.
> 
> This shouldn't happen, what input driver are you using? Is with with x or wayland?
> 
> @hunterk Can you reproduce this?

I'm using X (elementary OS Juno).

Input driver I can't check now, but is the default one (new configuration after deleting config files).",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/8546,[Feature request] basic .sh scripting support at game launch and exit,fzacchi,32,429038270,1,429038270,0,0,2019-04-04T01:10:39Z,"I’ve written a set of scripts for RetroPie on the Raspberry Pi that activate the correct nonstandard refresh rates for each game that needs them on LCD monitors, by parsing a refresh list. LCDs support integer rates only, so for example with R-Type and Mortal Kombat the monitor runs at 55 Hz, with Neo Geo games at 59, with Double Dragon at 57 and so on.

It’s called by runcommand-onstart.sh (when the frontend launches a game) and runcommand-onend.sh (when exiting the emulator back into the frontend), and I’d love to have the same functionality on RetroArch. Running the refresh rate switching commands from the command line via ssh (on Lakka) sort of works, but there’s no hook that I can find to do it when launching and then quitting a lr- core.

The only previous discussion I found is here:
https://forums.libretro.com/t/custom-scripts-system/4776",True,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/479768480,[Feature request] basic .sh scripting support at game launch and exit,i30817,32,429038270,2,479768480,0,429038270,2019-04-04T06:32:19Z,"This btw, will never work on wayland because they explicitly determine that the only one program allowed to run changes is a blessed, 'user-only' (probably suid) program that has no cmdline interface. Probably pointless aside but just something to mention.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/479890400,[Feature request] basic .sh scripting support at game launch and exit,orbea,32,429038270,3,479890400,0,479768480,2019-04-04T13:10:40Z,"This doesn't seem like a very good idea and we have an issue template for a reason, please fill it out because I am not following you desired behavior...",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/479908873,[Feature request] basic .sh scripting support at game launch and exit,fzacchi,32,429038270,4,479908873,0,479890400,2019-04-04T13:59:56Z,"Thanks for the Wayland info. My primary, if not only, use case would be Lakka on the Raspberry Pi, however. The refresh rate switch commands work, I've already tested it, I just have no way to invoke them automatically without dropping to the command line each time.

It's not an issue, it's a feature request for something that RetroArch-the-frontend currently lacks: the ability to call a bash script right before the frontend launches a libretro core, and call another one when the core quits back into the frontend. They're called runcommand-onstart.sh and runcommand-onend.sh in RetroPie, but they can be called anything and be stored anywhere, it doesn't matter. RetroPie had that forever, and I've made Recalbox support it as well. I think there's no way to do it in Lakka by scripting alone, the frontend app itself has to be modified (please correct me if I'm wrong).

Basically as it stands now the frontend just does:

retroarch *libretro.so romname

the sequence should become:

/path/to/script/onstart.sh corename romname
retroarch *libretro.so romname
/path/to/script/onend.sh

Where can I look to try to hack it in myself?",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/479914686,[Feature request] basic .sh scripting support at game launch and exit,orbea,32,429038270,5,479914686,0,479908873,2019-04-04T14:13:54Z,"What would these scripts do?

@bparker06 What do you think of supporting shell scripting inside of RetroArch, is this supportable or worth adding?",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/479984267,[Feature request] basic .sh scripting support at game launch and exit,fzacchi,32,429038270,6,479984267,0,479914686,2019-04-04T17:10:41Z,"Just to be clear, by default they should do nothing, in fact the .sh files shouldn't even be there.

You can check out my repos to get a good idea of what my script does, but in short it's the only way to get smooth scrolling at the right speed on PAL on nonstandard refresh rate games without using Freesync or G-Sync, on the Raspberry Pi (RasPi doesn't support Freesync or G-sync anyway).

Others have fancy arcade setups using LCDs as marquees and programmable LEDs, joysticks and buttons that need per-game initialization, others use them for launch videos.

It's also not about what you can do with it right now, but what possibilities open up once the feature is there, IMO.",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/480007300,[Feature request] basic .sh scripting support at game launch and exit,Ferk,32,429038270,7,480007300,0,479984267,2019-04-04T18:16:05Z,"Wouldn't it make more sense to do that through a core?
You could use lutro/chailove to write scripts in lua/chaiscript or for bash something like https://github.com/SwedishGojira/libretro-bash-launcher",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/480010653,[Feature request] basic .sh scripting support at game launch and exit,fzacchi,32,429038270,8,480010653,0,480007300,2019-04-04T18:25:37Z,"Interesting, but it seems unneedlessly complicated. My script needs to be fed the name of the core and the rom to work properly, so you should pass those to the bash launcher (how?) that would then pass them to my script ... doesn't make much sense.",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/480019936,[Feature request] basic .sh scripting support at game launch and exit,andres-asm,32,429038270,9,480019936,0,480010653,2019-04-04T18:52:39Z,"It could certainly be done... 
But should it? at some point you have to draw a line and start thinking about the big picture.
Big picture being the common denominator.

Scripting is usually a last resort solution to something that can't be done through an API.
The proper solution is to use an API to do modeline switching (which is implemented already even though it may not suit your usecase ideally)",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/480026938,[Feature request] basic .sh scripting support at game launch and exit,fzacchi,32,429038270,10,480026938,0,480019936,2019-04-04T19:13:28Z,"I actually agree with that :)

Yet, fully automatic modeline switching on Lakka on the Raspberry Pi is far, far away from completion. As it is it's best suited to CRTs anyway, while my script is way simpler and meant for standard LCDs.

It's working on RetroPie and Recalbox, so only Lakka is missing now. It just seems like a case of something easy enough to implement that it would be worth the cost (also for other uses than refresh rate change). I would do it myself if I knew where to start ...",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/480103396,[Feature request] basic .sh scripting support at game launch and exit,ghost,32,429038270,11,480103396,0,480026938,2019-04-04T23:54:55Z,you dont have to change the modeline it has been said before the cores can handle this internally if they need to all you to fix your 57 and others bordeline all you have to do is adjust your audio skew setting to 0.01 not sure about pal would need to test 50hz,False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/480108917,[Feature request] basic .sh scripting support at game launch and exit,ghost,32,429038270,12,480108917,0,480103396,2019-04-05T00:26:45Z,">LCDs support integer rates only

This is incorrect.

Most LCD monitors do not support many different refresh rates anyway (especially in the higher resolutions) besides the standard 24/30/50/60 and their 1.001 equivalents.

I think that running a script on startup and exit should be left to, well, scripts. I see no reason to add this functionality directly into RetroArch... especially where ""scripts"" in general or the execution of separate processs does not even work on the majority of platforms we support.",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/480116296,[Feature request] basic .sh scripting support at game launch and exit,ghost,32,429038270,13,480116296,0,480108917,2019-04-05T01:13:20Z,"just to clarify above its maximum  timing scew  not audio skew setting my bad.

Load robocop with fba or any mame youll see it runs 60fps with an increased in pitch with sound as well  with the default settings.  Change it to 0.01 restart youll see it runs the right frame rate hope that clarifies any confusion 

old post but pal is covered here

https://forums.libretro.com/t/perfect-audio-video-synchronization/12072
",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/480416171,[Feature request] basic .sh scripting support at game launch and exit,ghost,32,429038270,14,480416171,0,480116296,2019-04-05T20:44:53Z,"@grant2258 Please don't spread bad advice... it's absolutely required to be able to set modelines for proper operation in all circumstances... timing skew is not a solution to everything and won't fix larger framerate differences.

For example with MAME Mortal Kombat 1, on the scrolling page of all the fighters, the ONLY way to get this to be perfectly 100% smooth is either with a CRT+exact modeline, or a VRR display such as G-Sync/Freesync with the ""sync content to exact framerate"" option plus the frameskip core option disabled in MAME.",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/480418633,[Feature request] basic .sh scripting support at game launch and exit,ghost,32,429038270,15,480418633,0,480416171,2019-04-05T20:53:47Z,your entitled to your opinion 👍 from lcd to crt big jump just bear in mind sound effects timing as well. I know you have to agree with anything I say so ill agree to disagree ,False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/480419417,[Feature request] basic .sh scripting support at game launch and exit,andres-asm,32,429038270,16,480419417,0,480418633,2019-04-05T20:56:32Z,"@grant2258 thing is this **topic** has nothing to do with your advice.
Resolution switching is a valid request, this is why CRT switchres and VRR runloop were implemented.

The only thing you're achieving by lowering timing skew is you're disabling DRC, basically you're disabling vsync and running at the proper speed (with tearing for lower fps content and with tearing + skipping at higher fps content)",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/480419654,[Feature request] basic .sh scripting support at game launch and exit,ghost,32,429038270,17,480419654,0,480419417,2019-04-05T20:57:28Z,it has everything to do with this what this the usual team tag it the sound that takes the timing up on 57 fps games and that's why the timing skew fixes it.  There is no tearing either,False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/480420403,[Feature request] basic .sh scripting support at game launch and exit,andres-asm,32,429038270,18,480420403,0,480419654,2019-04-05T21:00:07Z,"No it doesn't, the request is about basic scripting support for RetroArch so he can switch to the proper resolution + refresh rate combination.

You're claiming you can run 57hz content on a 60hz display with no tearing...
RA is a lot of things but it's not magic.

Doesn't mean it will have horrible tearing, but there is gonna be a tear here and there. VSYNC exists for a reason.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/480420893,[Feature request] basic .sh scripting support at game launch and exit,ghost,32,429038270,19,480420893,0,480420403,2019-04-05T21:01:40Z,lol  there is no tearing set it and check i wont be wasting my breath on you and bparker last time you tagged team I got kicked because disagreed with him you fought his corner not intrested in in a tag team again we can agree do disagree not interested in arguing,False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/480457159,[Feature request] basic .sh scripting support at game launch and exit,fzacchi,32,429038270,20,480457159,0,480420893,2019-04-06T00:15:21Z,">> LCDs support integer rates only
> This is incorrect.

CRU and the NVidia control panel on Windows, ""vcgencmd hdmi_cvt ""on the RasPi ... they let you change the refresh rate in 1hz increments only. Believe me, I've tried. It's not a big deal: it just means that any game is off by no more than 0.5 Hz in the worst case, so speed and music pitch aren't perfect, but very negligibly so. Scrolling however is just as smooth as the arcade was. No more horrid, choppy PAL scrollers. Transparency effects work.

> Most LCD monitors do not support many different refresh rates anyway

Every single LCD monitor I tested is able to sync from 50 to 63 Hz in 1 Hz increments, which is the full range needed for 99.5% of games.

You're obviously right about audio timing skew not fixing the problem at all. Short of writing some kind of next gen, AI-powered, interpolating renderer, there's no way to have a 57 Hz game running on a 60 Hz screen without the speed being wrong or the scrolling being choppy.

> For example with MAME Mortal Kombat 1, on the scrolling page of all the fighters, the ONLY way to get this to be perfectly 100% smooth is either with a CRT+exact modeline, or a VRR display such as G-Sync/Freesync with the ""sync content to exact framerate"" option plus the frameskip core option disabled in MAME.

Guess what: with my script MK is perfectly 100% smooth at the right speed on a lowly Raspberry Pi with any LCD monitor, old or new. In fact it's the main game I used for testing during development. That spinning fighters carousel doesn't lie.

> basic scripting support for RetroArch so he can switch to the proper resolution + refresh rate combination.

Even simpler, the resolution always stays the same, the native LCD monitor one. Only the refresh rate changes. 

> especially where ""scripts"" in general or the execution of separate process does not even work on the majority of platforms we support.

This, sadly, is a strong argument against implementing .sh support.

I'm happy to have it working as well as it does on RetroPie, but it's clear that libretro is taking over, and Lakka is a much more elegant solution.

I can't stand choppy scrolling. The real solution is ubiquitous Freesync, but the Pi doesn't support it and it's not really needed anyhow (no on the fly changes during gameplay needed).

Another workable solution would be to simplify CRT Switchres and create LCD Switchrate: same resolution, per-game (or per-system) adaptive refresh. Groovymame has an LCD specific mode that works amazingly well, and was the main inspiration for me to create something similar for the Pi. Maybe that's what's worth pursuing for Lakka.


",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/480458533,[Feature request] basic .sh scripting support at game launch and exit,ghost,32,429038270,21,480458533,0,480457159,2019-04-06T00:29:11Z,"do me a favour leave your lcd at its default 60hz. Start ra goto setting audio machine timing skew set it to 0.01. Restart retroarch then play robocop on fba alpah.  (dont touch dynamic audio) 

Send me a link to your script ill see if there is any difference from this setting and what your script does.",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/480463871,[Feature request] basic .sh scripting support at game launch and exit,ghost,32,429038270,22,480463871,0,480458533,2019-04-06T01:39:49Z,"i do agree  one thing this shouldnt be such an issue mame has worked fine from the good old days. all you had to do was set your ini like this and t worked properly.
```
waitvsync               0
triplebuffer            1
matchrefresh         1

```",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/480465504,[Feature request] basic .sh scripting support at game launch and exit,andres-asm,32,429038270,23,480465504,0,480463871,2019-04-06T02:05:57Z,"@fzacchi right, changing modes will always work better than what grant proposed here (disabling vsync and running 57hz content at 60hz).

Only ways I know to get proper scrolling and speed is mode switching or VRR.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/480467093,[Feature request] basic .sh scripting support at game launch and exit,ghost,32,429038270,24,480467093,0,480465504,2019-04-06T02:32:46Z,"im talking about stand alone mame you can get it looking good without all this messing about not perfect but has options to make everything presentable easily. 

The biggest  problem with RA is it messes the audio pitch up thats as bad as screen tearing Id love to hear a suggestion that actually works without setting per game that makes odd ball frame rates more presentable. 

also how are you setting your modelines in windows 10 if this solution is better for you",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/480470005,[Feature request] basic .sh scripting support at game launch and exit,andres-asm,32,429038270,25,480470005,0,480467093,2019-04-06T03:19:30Z,"You can't get 57hz content at proper speed and no tearing on a display that is set at 60hz, that's all I have been saying.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/480470101,[Feature request] basic .sh scripting support at game launch and exit,ghost,32,429038270,26,480470101,0,480470005,2019-04-06T03:21:25Z,"I just tested VVR scrolling in robocop is jerky works better with machine timing skew looks smooth to the eye. I know how to set modes in linux but not sure about windows setting per game seems a very odd way to deal with it. I guess there is no real solution but to tinker the machine timing does work well with 57 and up if you change it. I really cant notice any tearing in it with machine timing when you go below that you do notice it

",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/480540583,[Feature request] basic .sh scripting support at game launch and exit,ghost,32,429038270,27,480540583,0,480470101,2019-04-06T21:49:53Z,"@fzacchi Whether a monitor or video encoder can support those rates is still not a universal given... I routinely work with devices that only accept a single specific set of timings for either input or output. But anyway, most of the time you'll be stopped by the OS refusing to use timings outside the device's EDID, which won't have all those 1Hz increments in it... but sure if you force it, there's a chance it might work. Also the MAME dat shows the refresh rate for MK1 is 53.204948Hz.

Anyway, all of this is *way* off-topic for this thread I think. The topic is about running scripts on startup/exit, and that just doesn't belong in RetroArch IMO.

@twinaphex Care to chime in?",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/480541064,[Feature request] basic .sh scripting support at game launch and exit,inactive123,32,429038270,28,480541064,0,480540583,2019-04-06T21:56:57Z,"I really don't think this is the thread to be launching into direct MAME vs. RetroArch comparisons.

Let's try to de-escalate this and let's keep to the subject matter.

The subject should just be about scripting support in RA.

There still remains the issue that scripting pulls in a ton of dependencies and RA is already growing rather big as-is. It's a hard sell IMHO.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/480548868,[Feature request] basic .sh scripting support at game launch and exit,ghost,32,429038270,29,480548868,0,480541064,2019-04-07T00:40:53Z,This isint about mame vs RA its about games 57.x-59.x fps  running at 60mhz with the default timing skew running too fast and how to improve it or at least make it more presentable on a lcd running at the correct speed. Scripting isint available on all platforms like has been said before.,False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/480552638,[Feature request] basic .sh scripting support at game launch and exit,orbea,32,429038270,30,480552638,0,480548868,2019-04-07T02:12:39Z,"> There still remains the issue that scripting pulls in a ton of dependencies and RA is already growing rather big as-is. It's a hard sell IMHO.

I think this is the bottom line, implementing and maintaining it could likely be extra burden with only limited benefit.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/480625812,[Feature request] basic .sh scripting support at game launch and exit,fzacchi,32,429038270,31,480625812,0,480552638,2019-04-07T20:23:18Z,"> Whether a monitor or video encoder can support those rates is still not a universal given...

Well, no one's asking to make LCD refresh rate switching mandatory :)

> But anyway, most of the time you'll be stopped by the OS refusing to use timings outside the device's EDID, which won't have all those 1Hz increments in it... but sure if you force it, there's a chance it might work.

In my real world testing it works 100% of the time on the Pi ... I was pretty surprised myself.

> Also the MAME dat shows the refresh rate for MK1 is 53.204948Hz.

Yes, what do you mean exactly by that? The LCD runs at 53.0 Hz (rounded to the nearest integer), and the RA core makes up the 0.2 Hz difference by slowing the game down by 0.4% or so, just like it does for all those ""60-but-not-quite"" Hz NTSC or arcade systems when running on a 60 Hz LCD. Scrolling is perfectly smooth, the speed difference is negligible, the experience is night and day.

> There still remains the issue that scripting pulls in a ton of dependencies and RA is already growing rather big as-is. It's a hard sell IMHO.

I understand wanting to keep RA feature parity across platforms, and I agree it's not worth pursuing it if the goal is full-fledged scripting support across every system RA runs on. It seemed to me that Lakka on the Pi support would be simple enough - just two hooks before and after launching the core.

Now I have to pester Alphanu for LCD support for CRT Switchres :)



",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/8548,Increase import performance on switch using new hardware crypto,fennectech,6,429558383,1,429558383,0,0,2019-04-05T02:32:51Z,"We have hardware SHA1 and CRC32 in libnx now this could be used to speed up the content importer  
https://github.com/switchbrew/libnx/pull/259

Relevant pull request",True,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/480134097,Increase import performance on switch using new hardware crypto,andres-asm,6,429558383,2,480134097,0,429558383,2019-04-05T03:10:37Z,"The biggest bottleneck is building up the file list though.
Not scanning itself.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/480134768,Increase import performance on switch using new hardware crypto,fennectech,6,429558383,3,480134768,0,480134097,2019-04-05T03:15:10Z,Okay. ,False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/480135215,Increase import performance on switch using new hardware crypto,andres-asm,6,429558383,4,480135215,0,480134768,2019-04-05T03:18:18Z,"No need to close it, it's still an idea worth approaching.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/480135324,Increase import performance on switch using new hardware crypto,fennectech,6,429558383,5,480135324,0,480135215,2019-04-05T03:19:14Z,Okay :)  i figured you ment that the improvement wouldent be worth the effort.,False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/480415035,Increase import performance on switch using new hardware crypto,ghost,6,429558383,6,480415035,0,480135324,2019-04-05T20:40:30Z,"Also worth noting that no checksum generation is even done for compressed files (zip/7z), because it's already provided in the archive metadata for every file.",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/1236131446,Increase import performance on switch using new hardware crypto,LibretroAdmin,6,429558383,7,1236131446,0,480415035,2022-09-03T14:33:27Z,"Similarly on this topic, ARM and SSE 4.x should have hardware implementations of SHA1 and CRC32 too (although not CRC32-C).",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/2597,Fix the make 'make rpm',jpereira,4,428415685,1,428415685,0,0,2019-04-02T20:01:16Z,The 'make rpm' should be friendly and resolve all dependencies first.,True,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/479175386,Fix the make 'make rpm',mattrose,4,428415685,2,479175386,0,428415685,2019-04-02T20:02:47Z,I don't think the Makefile should alter the system it's building.  I left this out on purpose.  ,False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/479175826,Fix the make 'make rpm',arr2036,4,428415685,3,479175826,0,479175386,2019-04-02T20:03:53Z,"I think doing it interactively would be ok, but definitely not implicitly",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/479176041,Fix the make 'make rpm',alandekok,4,428415685,4,479176041,0,479175826,2019-04-02T20:04:20Z,Installing extra packages shouldn't be part of the `make` process.  It's better to check if the packages have been installed.  And maybe tell the admin what to do.,False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/479179710,Fix the make 'make rpm',mcnewton,4,428415685,5,479179710,0,479176041,2019-04-02T20:13:10Z,"No, `fakeroot debian/rules debian/control` makes `debian/control` from `debian/control.in`. `yum-builddep` actually installs dependent packages.
",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/2601,4.0.x - DHCP v4 encoder loops forever if given a string option > 255 octets,nchaigne,10,429800823,1,429800823,0,0,2019-04-05T15:02:32Z,"# Issue type
- Defect - Unexpected behaviour (obvious or verified by project member).

# Defect

Calling DHCP v4 encoder function (fr_dhcpv4_packet_encode) with a value pair containing a value (string or octets) too long for a DHCP option (> 255) makes it loop forever.

Function encode_rfc_hdr calls encode_value, which returns -1 if there is not enough space.
Then it tries again. But there will never be enough space in 255 octets, so it loops forever.

Proposed fix:

Have function fr_dhcpv4_encode_option check the length of the value pair it has to encode to DHCP options. If it exceeds 255, return an error.

```text
if (vp->vp_length > 255) {
        fr_strerror_printf(""Attribute \""%s\"" value is too large for a DHCP option"", vp->da->name);
        return -1;
}
```

",True,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/480315528,4.0.x - DHCP v4 encoder loops forever if given a string option > 255 octets,alandekok,10,429800823,2,480315528,0,429800823,2019-04-05T15:19:54Z,"RFC 2131 says:

>    The values to be passed in an 'option' tag may be too long to fit in
   the 255 octets available to a single option (e.g., a list of routers
   in a 'router' option [21]).  Options may appear only once, unless
   otherwise specified in the options document.  The client concatenates
   the values of multiple instances of the same option into a single
   parameter list for configuration.

We should just chop up the ""too long"" inputs into multiple options.

The RADIUS encoder does the same thing for some attributes.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/480318355,4.0.x - DHCP v4 encoder loops forever if given a string option > 255 octets,nchaigne,10,429800823,3,480318355,0,480315528,2019-04-05T15:27:26Z,"OK, thanks for the RFC pointer.
Not so trivial then... I'll let you figure out how to fix this. :)

No urgency whatsoever of course.
",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/480320359,4.0.x - DHCP v4 encoder loops forever if given a string option > 255 octets,alandekok,10,429800823,4,480320359,0,480318355,2019-04-05T15:33:06Z,"I don't see it looping forever in a test case, so I'm not sure what's wrong there.

I'll push a fix to split the option automatically",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/480325045,4.0.x - DHCP v4 encoder loops forever if given a string option > 255 octets,nchaigne,10,429800823,5,480325045,0,480320359,2019-04-05T15:46:25Z,"You can reproduce it with dhcpclient, e.g. with a 256 octets-long option:

```
echo ""DHCP-Client-Hardware-Address=\""01:02:03:04:05:06\"", DHCP-Merit-Dump-File=\""1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456\"""" | dhcpclient 1.2.3.4 discover
```",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/480350812,4.0.x - DHCP v4 encoder loops forever if given a string option > 255 octets,alandekok,10,429800823,6,480350812,0,480325045,2019-04-05T17:06:20Z,"The issue here I think is ""256"", and not ""300"".  :(  It loops forever if `fr_dhcpv4_encode_option()` returns `0`.  Other values are OK.

I've pushed a fix so it doesn't loop forever.  The larger fix of splitting data across multiple options will take more time.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/480415351,4.0.x - DHCP v4 encoder loops forever if given a string option > 255 octets,alandekok,10,429800823,7,480415351,0,480350812,2019-04-05T20:41:42Z,The fixes above should work.  I've added the example to the test cases,False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/480729256,4.0.x - DHCP v4 encoder loops forever if given a string option > 255 octets,nchaigne,10,429800823,8,480729256,0,480415351,2019-04-08T08:08:25Z,"Thanks for the fixes.

I tried with an option 82 larger than 255 bytes. Encoding seems to work, but Wireshark is not happy (""no room left in option for suboption value""). But maybe it's just too dumb to decode such long options...

My DHCP server returns an option 82 with a length of 0.
(Likely, the server doesn't know how to handle these long options either.)

However, FreeRADIUS cannot decode the reply: fr_dhcpv4_packet_decode fails. Seems it doesn't like an option with a length of 0.
I think this should be allowed.
",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/480738827,4.0.x - DHCP v4 encoder loops forever if given a string option > 255 octets,nchaigne,10,429800823,9,480738827,0,480729256,2019-04-08T08:37:00Z,"A sub-option (82.n) of 253 octets is encoded in two options: one of length 0, and the other of length 255 (containing the sub-option of 253 octets).
While technically not incorrect, this is a bit weird (and unnecessary).",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/480891101,4.0.x - DHCP v4 encoder loops forever if given a string option > 255 octets,nchaigne,10,429800823,10,480891101,0,480738827,2019-04-08T15:54:11Z,"Thanks for these last fixes, it seems ok now.

Wireshark is still unhappy when a long sub-option is split across two options, but RFC 3396 clearly states how long options should be handled and I believe FreeRADIUS is now compliant :) (unless there's another RFC that says something different about sub-options...)

",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/480897402,4.0.x - DHCP v4 encoder loops forever if given a string option > 255 octets,alandekok,10,429800823,11,480897402,0,480891101,2019-04-08T16:10:27Z,Thanks for the review and update.,False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/2608,Fix radclient i option,bmork,5,431675905,1,431675905,0,0,2019-04-10T19:33:12Z,"This is an attempt to fix issue #2194 

Lightly tested with radclient, but not yet with the server.",True,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/492956166,Fix radclient i option,bmork,5,431675905,2,492956166,0,431675905,2019-05-16T07:42:21Z,"ping?  I believe I addressed all the comments on this request.  Please close it, with or wthout merging as you see best - that's your privilege to decide :-)

Unless there was something I missed?
",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/493109935,Fix radclient i option,alandekok,5,431675905,3,493109935,0,492956166,2019-05-16T15:13:53Z,"I think it should be OK.  I'll have to take a deeper look

If this was v3, I'd be worried about changing the server functionality, just to fix radclient.  But the proxying in ""master"" uses an entirely different API to allocate IDs.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/494889312,Fix radclient i option,bmork,5,431675905,4,494889312,0,493109935,2019-05-22T17:06:10Z,"> I think it should be OK. I'll have to take a deeper look
> 
> If this was v3, I'd be worried about changing the server functionality, just to fix radclient. But the proxying in ""master"" uses an entirely different API to allocate IDs.

Fair enough.  I believe it should have no measurale impact on the server, but verifying this would be good.",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/575405614,Fix radclient i option,arr2036,5,431675905,5,575405614,0,494889312,2020-01-17T00:08:27Z,@bmork can you rebase and I'll merge this.,False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/577406315,Fix radclient i option,bmork,5,431675905,6,577406315,0,575405614,2020-01-22T22:00:52Z,Hope I got the rebasing right.  Didn't really remember writing this code ;-),False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/2626,rlm_redis_ippool: break out lua scripts as defacto schema,jimdigriz,22,435809470,1,435809470,0,0,2019-04-22T17:27:47Z,"Summary of changes:
 - extracted lua code into separate files (can be treated as a schema for redis_ippool)
 - documented the namespace usage in Redis
 - removed 'gateway' and 'counter' as both were not plumbed into anything in the years they have existed (conversed with @mcnewton on this)
 - moved `rlm_redis_ippool.c:ippool_script` to `cluster.c:fr_redis_script` so to remove code duplication
 - moved IP range handling into Lua (partially addresses concerns in https://github.com/FreeRADIUS/freeradius-server/issues/1744) (65k item guard for range based operations) all in `preamble.lua:iptool_module`
 - rework ippool tool to just perform a single task (chaining operations should be via script/`xargs`/...)
 - make IP sticky work (`device` keys live for 10x lease time)
 - fix 'list' in the tool as it looks like it never worked (pool 'start' needed to be non-zero)
 - 'modify' removed as you can just re-run 'add' to perform the same task (it will noop already existing bits, and update the 'address' hash key if need be)

Talking points:
 - not 100% convinced this patch set can be broken up, most of it is ""lift and move the lua code into files""; in doing so some opportunities to simplify things were too hard to ignore
 - patch looks large, but most of it is ""move into separate files and load them""
 - JSON as a transport for 'show' and 'stats'.  Though 'stats' could be made an array again, things are a little harder for 'show'.  This is helpful though for other consumers that which to poke/peek Redis directly
 - replace script loading in the config with (as of yet unimplemented) `${READFILE} /path/to/file.lua` (suggested by @arr2036)
 - I have not run the unit tests as it is unclear how (what deps, I seem to have lots missing), but that is why you have CI...lolz, I'll wait 30mins and check back in on the carnage there",True,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/485488531,rlm_redis_ippool: break out lua scripts as defacto schema,jimdigriz,22,435809470,2,485488531,0,435809470,2019-04-22T17:39:10Z,"I effectively reverted 3d075859aab363b0f7ff37eebebe12041b5eab60 in my PR, so we probably should get that resolved properly.",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/485513416,rlm_redis_ippool: break out lua scripts as defacto schema,arr2036,22,435809470,3,485513416,0,485488531,2019-04-22T18:57:21Z,"The gateway ID and counter fields should not be stripped.  They're used in customer deployments.  Can you add that code back in, and I'll add some additional code to dump them into the current FR request to make them available for general consumption.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/485515150,rlm_redis_ippool: break out lua scripts as defacto schema,arr2036,22,435809470,4,485515150,0,485513416,2019-04-22T19:02:31Z,"Can you break out your changes to the content of the lua scripts into a separate commit.  Because they've been moved bodily to external files, it's hard to see what actually changed.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/485516200,rlm_redis_ippool: break out lua scripts as defacto schema,jimdigriz,22,435809470,5,485516200,0,485515150,2019-04-22T19:05:28Z,"> Why is the gateway ID stuff stripped out everywhere?

---
Summary of changes:
  [snipped]
  - removed 'gateway' and 'counter' as both were not plumbed into anything in the years they have existed (conversed with @mcnewton on this)
---

I could not see any active use of the `gateway` parameter in the code base, nothing was plumbed in for processing `Accounting-On` packets.  Maybe I missed it?",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/485516963,rlm_redis_ippool: break out lua scripts as defacto schema,arr2036,22,435809470,6,485516963,0,485516200,2019-04-22T19:07:50Z,"> > Why is the gateway ID stuff stripped out everywhere?
> 
> Summary of changes:
> [snipped]
> 
> * removed 'gateway' and 'counter' as both were not plumbed into anything in the years they have existed (conversed with @mcnewton on this)
> 
> I could not see any active use of the `gateway` parameter in the code base, nothing was plumbed in for processing `Accounting-On` packets. Maybe I missed it?

Yes I read the comment and changed the query to a request :)

They're both used, but not queried directly through rlm_redis_ippool in existing deployments.  It shouldn't be hard to fix that though and dump them into the request list when the ippool module is called.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/485517813,rlm_redis_ippool: break out lua scripts as defacto schema,jimdigriz,22,435809470,7,485517813,0,485516963,2019-04-22T19:10:42Z,"> Can you break out your changes to the content of the lua scripts into a separate commit. Because they've been moved bodily to external files, it's hard to see what actually changed.

Not sure what you mean by this?  As originally most of the Lua was in a large `char` array it is not really readily comparable; I suspect even a git word diff would not help.

Maybe if you describe what you want to see, maybe with an example, it will be clearer to me?",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/485518812,rlm_redis_ippool: break out lua scripts as defacto schema,jimdigriz,22,435809470,8,485518812,0,485517813,2019-04-22T19:14:09Z,"> > > Why is the gateway ID stuff stripped out everywhere?
> [snipped]
> They're both used, but not queried directly through rlm_redis_ippool in existing deployments. It shouldn't be hard to fix that though and dump them into the request list when the ippool module is called.

Are you thinking as just a generic KV store?  Something that would just extend the `address` map object?",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/485519265,rlm_redis_ippool: break out lua scripts as defacto schema,arr2036,22,435809470,9,485519265,0,485518812,2019-04-22T19:15:33Z,"> > Can you break out your changes to the content of the lua scripts into a separate commit. Because they've been moved bodily to external files, it's hard to see what actually changed.
> 
> Not sure what you mean by this? As originally most of the Lua was in a large `char` array it is not really readily comparable; I suspect even a git word diff would not help.
> 
> Maybe if you describe what you want to see, maybe with an example, it will be clearer to me?

In addition to changing the location of the lua code, you changed the functionality of the lua code.  It would have been nice to see the changes in content first, before you moved it over to external files.

The alternative would be to have a commit moving the lua code out to separate files and changing the return codes, then another commit changing the functionality, which I suspect would be easier.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/485519732,rlm_redis_ippool: break out lua scripts as defacto schema,arr2036,22,435809470,10,485519732,0,485519265,2019-04-22T19:17:06Z,"> > > > Why is the gateway ID stuff stripped out everywhere?
> > > > [snipped]
> > > > They're both used, but not queried directly through rlm_redis_ippool in existing deployments. It shouldn't be hard to fix that though and dump them into the request list when the ippool module is called.
> 
> Are you thinking as just a generic KV store? Something that would just extend the `address` map object?

Not currently, I was just going to dump the values into attributes, but yeah eventually it might be nice to offer that functionality.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/487423041,rlm_redis_ippool: break out lua scripts as defacto schema,jimdigriz,22,435809470,11,487423041,0,485519732,2019-04-28T23:04:44Z,"> The alternative would be to have a commit moving the lua code out to separate files and changing the return codes, then another commit changing the functionality, which I suspect would be easier.

Compile tested only, good enough to see the affect, shows conceptually how extracting the Lua code looks: https://github.com/FreeRADIUS/freeradius-server/compare/master...jimdigriz:rlm_redis_ippool_lua_stepped

I am continuing to add the remains of https://github.com/FreeRADIUS/freeradius-server/compare/master...jimdigriz:rlm_redis_ippool_lua as more digestible parts.",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/497857253,rlm_redis_ippool: break out lua scripts as defacto schema,jimdigriz,22,435809470,12,497857253,0,487423041,2019-05-31T20:55:43Z,"This work cycle is now complete, tests have also been fixed up.

TravisCI/clang seems to be upset about HTML entities in a C header file, not really sure how I could have caused this: https://travis-ci.org/FreeRADIUS/freeradius-server/jobs/539870493#L3706

Can someone look over my PR and let me know what the next steps for me are.",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/497909680,rlm_redis_ippool: break out lua scripts as defacto schema,jpereira,22,435809470,13,497909680,0,497857253,2019-06-01T03:54:07Z,"@jimdigriz Try to:

1. Remove the unnused function `ippool_wait_check`
2. Rename `cluster.h` by `redis_ippool.h` in src/modules/rlm_redis_ippool/redis_ippool.h",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/497939134,rlm_redis_ippool: break out lua scripts as defacto schema,jimdigriz,22,435809470,14,497939134,0,497909680,2019-06-01T12:04:16Z,"> @jimdigriz Try to:
> 
>     1. Remove the unnused function `ippool_wait_check`

Done 06bac70380023f48a042c70412faa0991d24466e, thanks!

>     2. Rename `cluster.h` by `redis_ippool.h` in src/modules/rlm_redis_ippool/redis_ippool.h

Not sure what you mean by this.",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/497940872,rlm_redis_ippool: break out lua scripts as defacto schema,jpereira,22,435809470,15,497940872,0,497939134,2019-06-01T12:23:05Z,"I mean, update the documentation in src/modules/rlm_redis_ippool/redis_ippool.h replacing the cluster.h by redis_ippool.h 
",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/497945679,rlm_redis_ippool: break out lua scripts as defacto schema,arr2036,22,435809470,16,497945679,0,497940872,2019-06-01T13:34:07Z,Can you squash the fixes that address errors in new code? I'll push something for the copyright notices.,False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/497956283,rlm_redis_ippool: break out lua scripts as defacto schema,arr2036,22,435809470,17,497956283,0,497945679,2019-06-01T15:59:39Z,Rebase and doxygen should no longer cause issues,False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/498011526,rlm_redis_ippool: break out lua scripts as defacto schema,jimdigriz,22,435809470,18,498011526,0,497956283,2019-06-02T08:42:35Z,"Changes made, tests are now passing.

Can someone look over my PR and let me know what the next steps for me are.",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/498570719,rlm_redis_ippool: break out lua scripts as defacto schema,arr2036,22,435809470,19,498570719,0,498011526,2019-06-04T08:16:31Z,"Can you add the ""modify"" tests back in, and update the list of changes in the description to reflect the changes you've done recently, and the changes that are included in this PR.  As we talked about offline, the utility behaviour must not change as it's already in use at multiple sites.

I really don't like the use of cjson to encode responses to the stats request, as it adds a dependency that wasn't there before.  What was the reason for doing this? The Redis protocol already supports returning the contents of hashes.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/498574221,rlm_redis_ippool: break out lua scripts as defacto schema,jimdigriz,22,435809470,20,498574221,0,498570719,2019-06-04T08:26:45Z,"> Can you add the ""modify"" tests back in, and update the list of changes in the description to reflect the changes you've done recently, and the changes that are included in this PR. As we talked about offline, the utility behaviour must not change as it's already in use at multiple sites.

I will do this.

> I really don't like the use of cjson to encode responses to the stats request, as it adds a dependency that wasn't there before. What was the reason for doing this? The Redis protocol already supports returning the contents of hashes.

I brought this up as a possible problem over six weeks ago.  I cannot work on a cycle of ""make all these changes"" and then something that *I* flagged up before those changes is not a problem that concerns you.

Thank you for wasting time and efforts.",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/498574787,rlm_redis_ippool: break out lua scripts as defacto schema,arr2036,22,435809470,21,498574787,0,498574221,2019-06-04T08:28:21Z,Where was this raised as an issue?,False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/498592007,rlm_redis_ippool: break out lua scripts as defacto schema,arr2036,22,435809470,22,498592007,0,498574787,2019-06-04T09:18:04Z,"Throughout this project there have been communication issues.  Ones that I've tried to go out of my way to address, by outlining an effective way of working jointly on this design.  

Despite this multiple intermediary design decisions were made without requesting my feedback, which as the person who's actually wrote the code originally and who has deployed it at multiple customer sites, It should have been.  If nothing else, to ensure that we don't break existing deployments with changes in behaviour here.

The original PR you created had some major red flags, which is why I didn't give it serious consideration.  Those were:
- Large monolithic commits.  These make it much harder to determine what's been changed, and whether those changes were appropriate, and makes it very easy to miss issues like this. I admit, I didn't make the connection between requiring JSON as a stats transport, and adding a dependency to the ippool tool.  It seems... bizarre to add this when the native transport could handle the encoding just fine.
- Failing tests.  Which honestly, you submitted a PR with failing tests and didn't fix them for several weeks... Come on, how do you think that looks from a reviewer's perspective? 

Passing tests, and clean, broken out commits are the basic requirements to get good feedback. If those aren't there it just screams ""Don't give a shit"" and ""You should be honoured to review my work!"" - don't be surprised if reviews get repeatedly deferred.
",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/498594171,rlm_redis_ippool: break out lua scripts as defacto schema,arr2036,22,435809470,23,498594171,0,498592007,2019-06-04T09:24:33Z,"Anyway, just forget the review, I'll pull your changes across manually.  I don't think continuing to work on this together is going to be constructive or productive.",False,0,MEMBER
https://api.github.com/repos/libretro/RetroArch/issues/8607,"[Bounty $50] [Feature request] ""Most Played"" tab (content sorted based on playtime log)",Ryunam,14,435381203,1,435381203,0,0,2019-04-20T10:14:24Z,"Now that we have per-game playtime logging as per @jdgleaver's contributions (thanks a lot once again!), it would be interesting and akin to what happens on several systems - notably the 3DS and even the Switch to some extent - to have a tab that displays a list of content sorted by overall playtime.

A playtime diary basically, with content listed (and possibly numbered ) according to your playtime logs, but with the ability to also select and run content like with the other playlists.

**$30 bounty on Bountysource:** 
https://www.bountysource.com/issues/73102634-feature-request-most-played-tab-content-sorted-based-on-playtime-log

**$20 bounty on Bountyhub:** 
https://bountyhub.co/bounty/5d5db72c7abe912482bea4a4",True,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485115265,"[Bounty $50] [Feature request] ""Most Played"" tab (content sorted based on playtime log)",ghost,14,435381203,2,485115265,0,435381203,2019-04-20T13:04:25Z,"Would this be needed in addition to the history playlist, or is a sorting function for the history playlist sufficient?",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/485141527,"[Bounty $50] [Feature request] ""Most Played"" tab (content sorted based on playtime log)",hizzlekizzle,14,435381203,3,485141527,0,485115265,2019-04-20T16:38:53Z,"having an option to sort history by playtime seems like a good way to do it. Conversely, I thought having an option to automatically add your top 10 playtimes or whatever to Favorites would be similar.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485150209,"[Bounty $50] [Feature request] ""Most Played"" tab (content sorted based on playtime log)",Ryunam,14,435381203,4,485150209,0,485141527,2019-04-20T18:43:20Z,"I'll say my preference although of course this is open to debate. My idea is to have it a separate tab, because Favourites, History and this new implementation would then serve three different and equally useful  purposes:

- History is for the latest content you have run (a purely chronological list);
- Favorites is the content you particularly liked and manually chose to include;
- Most Played would be a list of titles exclusively sorted by playtime (because of this I was thinking of even having the content numbered, exactly like on the 3DS Diary). 

The way I see it, the ideal scenario would be to have them co-exist as unique tabs because of these separate functionalities.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485155642,"[Bounty $50] [Feature request] ""Most Played"" tab (content sorted based on playtime log)",hizzlekizzle,14,435381203,5,485155642,0,485150209,2019-04-20T19:30:18Z,the problem i see with adding more tabs is that people already complain about the number of tabs.,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485159278,"[Bounty $50] [Feature request] ""Most Played"" tab (content sorted based on playtime log)",Ryunam,14,435381203,6,485159278,0,485155642,2019-04-20T19:51:36Z,"I understand your concern. At the same time, people do complain about virtually everything and this aspect could easily be remedied by making the “Most Played” Tab:
- not visibile by default (manually toggleable);
- and most importantly be displayed only if total per-content playtime logging is enabled (another option that is OFF by default right now).",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485176932,"[Bounty $50] [Feature request] ""Most Played"" tab (content sorted based on playtime log)",orbea,14,435381203,7,485176932,0,485159278,2019-04-20T21:35:49Z,"> the problem i see with adding more tabs is that people already complain about the number of tabs.

I think a `Most Played` tab is the cleanest sounding solution, it should of course include a toggle to enable/disable it.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485244674,"[Bounty $50] [Feature request] ""Most Played"" tab (content sorted based on playtime log)",jdgleaver,14,435381203,8,485244674,0,485176932,2019-04-21T11:36:40Z,"I quite like this idea.

I'm currently away for Easter week and won't be writing any code, but if no one else wants to work on this I don't mind adding it to my TODO list for when I get back.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/523655512,"[Bounty $50] [Feature request] ""Most Played"" tab (content sorted based on playtime log)",harperd3d,14,435381203,9,523655512,0,485244674,2019-08-21T21:25:00Z,I think this would be great. I love how Steam shows me how much time I've wasted per game!,False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/523656379,"[Bounty $50] [Feature request] ""Most Played"" tab (content sorted based on playtime log)",harperd3d,14,435381203,10,523656379,0,523655512,2019-08-21T21:27:53Z,I posted a small bounty on [BountyHub](https://bountyhub.co/bounty/5d5db72c7abe912482bea4a4) for this :),False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/523860811,"[Bounty $50] [Feature request] ""Most Played"" tab (content sorted based on playtime log)",Ryunam,14,435381203,11,523860811,0,523656379,2019-08-22T11:13:36Z,"Perhaps it would be best to post bounties on Bountysource instead, since all libretro bounties are currently being hosted there. Gonna wait for a decision on this and then I'd be more than happy to follow up and add something to @harperd3d's initial contribution.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/616223679,"[Bounty $50] [Feature request] ""Most Played"" tab (content sorted based on playtime log)",Ryunam,14,435381203,12,616223679,0,523860811,2020-04-19T20:54:47Z,"I thought about this a bit more. The likely inconvenience that would stem from having a separate ""Most Played"" tab is that, theoretically, this tab would have to parse and display all content you have ever recorded a playtime log for. 

This would presumably result in a very long list of entries, some of which might display less than a second of actual playtime (for example, content that was just quickly tested and then forgotten about). Also, I'm not sure about the performance hit that parsing all this data would cause.

Considering all of the above and given that after https://github.com/libretro/RetroArch/pull/10434 we now have a ""Sorting Method"" option in the Playlist Manager that allows to decide the sorting approach for each playlist, maybe this request would be better addressed by having the following:

- two new sorting methods, ""per-core playtime"" and ""aggregate / total playtime"", based on the respective type of playtime log available on RA;
- an optional per-playlist toggle inside the Playlist Manager to append numbers to each entry, basically enumerating each piece of content in that playlist from top to bottom.

This would prevent any extra clutter from being added to the Menu, while still providing this functionality in a way that most resembles the Playtime ""diary"" found in other systems (3DS for example)

@jdgleaver - What do you think about it? You had expressed interest in the original idea, but maybe this solution is cleaner / more sustainable?

",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/616522991,"[Bounty $50] [Feature request] ""Most Played"" tab (content sorted based on playtime log)",jdgleaver,14,435381203,13,616522991,0,616223679,2020-04-20T12:32:38Z,"@Ryunam Crikey - I can't believe this issue is a year old... Yes, I know I said I'd look at this (it's still written on my TODO list, in fact) - sorry for neglecting it...

Your suggestions make a lot of sense, but there are issues with sorting a playlist by runtime. Since runtime is stored in separate files (and not in playlists), it means the corresponding file for each entry in a playlist would have to be parsed before any sorting could be done. This is pretty rough - for a large playlist with many items that have been played, the loading time would be horrible.

I think the original idea of having a separate 'most played' playlist is more practical - since this would be a special case, the actual runtime could be written to the playlist itself, making loading/sorting very fast. The number of entries is not really a concern - it would work just like content history (with a user-set limit on the max number), with no performance issues.

I guess I need to give the actual implementation some more consideration...",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/616545302,"[Bounty $50] [Feature request] ""Most Played"" tab (content sorted based on playtime log)",Ryunam,14,435381203,14,616545302,0,616522991,2020-04-20T13:15:21Z,"Thank you for your comment! Indeed I had not considered those issues that you're bringing up...

In general I quite like the fact that runtime logs are completely separate from playlist entries, because that way the actual playtime is calculated based on the filename of the game and is not tied to the name of the entry itself. You can have multiple playlist entries for a certain title (for instance, the same piece of content associated with different cores) and still display one aggregate playtime count for that particular content.

I will be definitely looking forward to any future development on this front. It's no crucial feature by any means, but like @harperd3d I sure love taking a look at how much time was invested (or wasted) on a per-game basis... :)",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/824022336,"[Bounty $50] [Feature request] ""Most Played"" tab (content sorted based on playtime log)",Ryunam,14,435381203,15,824022336,0,616545302,2021-04-21T12:30:35Z,"I decided to try and reignite some interest in this feature request by contributing a small bounty of $30. Hopefully this will give some additional incentive! 

To recap the points that I would consider necessary for the idea to be accomplished:

1) The best prospect to approach this, as per the previous exchanges in this thread, is to have a separate 'most played' playlist that is displayed in its own tab. We now have visibility toggles for each of the menu tabs in RA, so this could be even be made entirely optional and OFF by default so as to assuage concerns of excessive clutter.

2) It would be great to have each of the entries numbered, turning the playlist essentially into a ranking that is sorted based on playtime. This is once again similar to the 3DS Playtime Diary, which was admittedly my source of inspiration when I thought about the feature.

3) Another thing that I believe would be useful:
- either having a Max Entries settings (similar to what we have right now for both Favorites and History) or 
- having an option that allows to set a minimum amount of playtime needed for an entry to be counted in this playlist. 

My main concern is to avoid having to display hundreds of content that may have been merely tested by a user for just a few seconds (with a playtime along the lines of 00:00:01) and then left to rot.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/8610,C89/CXX support for rcheevos,Jamiras,31,435436703,1,435436703,0,0,2019-04-20T20:22:21Z,"## Guidelines

1. Rebase before opening a pull request
2. If you are sending several unrelated fixes or features, use a branch and a separate pull request for each
3. If possible try squashing everything in a single commit. This is particularly beneficial in the case of feature merges since it allows easy bisecting when a problem arises

## Description

Addendum to #8501 - fixes C89_BUILD and CXX_BUILD

## Related Issues

#8501

## Related Pull Requests

#8501

## Reviewers

@meleu @orbea @twinaphex @leiradel 
",True,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485164884,C89/CXX support for rcheevos,Jamiras,31,435436703,2,485164884,0,435436703,2019-04-20T20:24:50Z,"Linux C89_BUILD > success

Linux CXX_BUILD:
```
LD retroarch
obj-unix/release/gfx/drivers_context/wayland_ctx.o: In function `registry_handle_global(void*, wl_registry*, unsigned int, char const*, unsigned int)':
wayland_ctx.c:(.text+0x1f52): undefined reference to `zxdg_decoration_manager_v1_interface'
wayland_ctx.c:(.text+0x20a3): undefined reference to `xdg_wm_base_interface'
wayland_ctx.c:(.text+0x2153): undefined reference to `zwp_idle_inhibit_manager_v1_interface'
collect2: error: ld returned 1 exit status
Makefile:195: recipe for target 'retroarch' failed
make: *** [retroarch] Error 1
```

Linux normal build:
```
gfx/drivers_context/wayland_ctx.c:629:29: error: unknown type name ‘wl_surface’; did you mean ‘EGLSurface’?
 static void wl_nop(void *a, wl_surface *b, wl_output *c)
                             ^~~~~~~~~~
                             EGLSurface
gfx/drivers_context/wayland_ctx.c:629:44: error: unknown type name ‘wl_output’
 static void wl_nop(void *a, wl_surface *b, wl_output *c)
                                            ^~~~~~~~~
CC gfx/common/wayland/xdg-shell.c
gfx/drivers_context/wayland_ctx.c:638:5: error: ‘wl_nop’ undeclared here (not in a function); did you mean ‘wl_api’?
     wl_nop,
     ^~~~~~
     wl_api
CC gfx/common/wayland/xdg-shell-unstable-v6.c
Makefile:199: recipe for target 'obj-unix/release/gfx/drivers_context/wayland_ctx.o' failed
make: *** [obj-unix/release/gfx/drivers_context/wayland_ctx.o] Error 1
```",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485164907,C89/CXX support for rcheevos,inactive123,31,435436703,3,485164907,0,485164884,2019-04-20T20:24:58Z,Thanks @Jamiras ,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485166659,C89/CXX support for rcheevos,inactive123,31,435436703,4,485166659,0,485164907,2019-04-20T20:35:27Z,"Hi @Jamiras, I still get these errors with CXX_BUILD -

CC deps/rcheevos/src/rcheevos/condset.c
In file included from D:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/8.2.0/include/stddef.h:1,
                 from deps/rcheevos/src/rcheevos/internal.h:6,
                 from deps/rcheevos/src/rcheevos/trigger.c:1:
deps/rcheevos/src/rcheevos/trigger.c: In function 'int rc_trigger_size(const char*)':
deps/rcheevos/src/rcheevos/internal.h:10:66: error: types may not be defined within __builtin_offsetof
 #define RC_ALIGNOF(t) offsetof(struct RC_TAG(_unnamed, __LINE__) {char c; t d;}, d)
                                                                  ^
deps/rcheevos/src/rcheevos/internal.h:12:76: note: in expansion of macro 'RC_ALIGNOF'
 #define RC_ALLOC(t, p) ((t*)rc_alloc((p)->buffer, &(p)->offset, sizeof(t), RC_ALIGNOF(t), &(p)->scratch))
                                                                            ^~~~~~~~~~
deps/rcheevos/src/rcheevos/trigger.c:45:10: note: in expansion of macro 'RC_ALLOC'
   self = RC_ALLOC(rc_trigger_t, &parse);
          ^~~~~~~~
deps/rcheevos/src/rcheevos/trigger.c: In function 'rc_trigger_t* rc_parse_trigger(void*, const char*, lua_State*, int)':
deps/rcheevos/src/rcheevos/internal.h:10:66: error: types may not be defined within __builtin_offsetof
 #define RC_ALIGNOF(t) offsetof(struct RC_TAG(_unnamed, __LINE__) {char c; t d;}, d)
                                                                  ^
deps/rcheevos/src/rcheevos/internal.h:12:76: note: in expansion of macro 'RC_ALIGNOF'
 #define RC_ALLOC(t, p) ((t*)rc_alloc((p)->buffer, &(p)->offset, sizeof(t), RC_ALIGNOF(t), &(p)->scratch))
                                                                            ^~~~~~~~~~
deps/rcheevos/src/rcheevos/trigger.c:57:10: note: in expansion of macro 'RC_ALLOC'
   self = RC_ALLOC(rc_trigger_t, &parse);
          ^~~~~~~~
CC deps/rcheevos/src/rcheevos/condition.c
make: *** [Makefile:199: obj-unix/release/deps/rcheevos/src/rcheevos/trigger.o] Error 1
make: *** Waiting for unfinished jobs....
In file included from D:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/8.2.0/include/stddef.h:1,
                 from deps/rcheevos/src/rcheevos/internal.h:6,
                 from deps/rcheevos/src/rcheevos/condset.c:1:
deps/rcheevos/src/rcheevos/condset.c: In function 'rc_condset_t* rc_parse_condset(const char**, rc_parse_state_t*)':
deps/rcheevos/src/rcheevos/internal.h:10:66: error: types may not be defined within __builtin_offsetof
 #define RC_ALIGNOF(t) offsetof(struct RC_TAG(_unnamed, __LINE__) {char c; t d;}, d)
                                                                  ^
deps/rcheevos/src/rcheevos/internal.h:12:76: note: in expansion of macro 'RC_ALIGNOF'
 #define RC_ALLOC(t, p) ((t*)rc_alloc((p)->buffer, &(p)->offset, sizeof(t), RC_ALIGNOF(t), &(p)->scratch))
                                                                            ^~~~~~~~~~
deps/rcheevos/src/rcheevos/condset.c:31:10: note: in expansion of macro 'RC_ALLOC'
   self = RC_ALLOC(rc_condset_t, parse);
          ^~~~~~~~
CC deps/rcheevos/src/rcheevos/operand.c
make: *** [Makefile:201: obj-unix/release/deps/rcheevos/src/rcheevos/condset.o] Error 1
In file included from D:/msys64/mingw64/lib/gcc/x86_64-w64-mingw32/8.2.0/include/stddef.h:1,
                 from deps/rcheevos/src/rcheevos/internal.h:6,
                 from deps/rcheevos/src/rcheevos/condition.c:1:
deps/rcheevos/src/rcheevos/condition.c: In function 'rc_condition_t* rc_parse_condition(const char**, rc_parse_state_t*)':
deps/rcheevos/src/rcheevos/internal.h:10:66: error: types may not be defined within __builtin_offsetof
 #define RC_ALIGNOF(t) offsetof(struct RC_TAG(_unnamed, __LINE__) {char c; t d;}, d)
                                                                  ^
deps/rcheevos/src/rcheevos/internal.h:12:76: note: in expansion of macro 'RC_ALIGNOF'
 #define RC_ALLOC(t, p) ((t*)rc_alloc((p)->buffer, &(p)->offset, sizeof(t), RC_ALIGNOF(t), &(p)->scratch))
                                                                            ^~~~~~~~~~
deps/rcheevos/src/rcheevos/condition.c:11:10: note: in expansion of macro 'RC_ALLOC'
   self = RC_ALLOC(rc_condition_t, parse);
          ^~~~~~~~
make: *** [Makefile:201: obj-unix/release/deps/rcheevos/src/rcheevos/condition.o] Error 1

",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485169611,C89/CXX support for rcheevos,Jamiras,31,435436703,5,485169611,0,485166659,2019-04-20T20:52:43Z,"What command do I need to duplicate that? If I just do a `./configure` and `make CXX_BUILD=1` in my  64bit mingw console on RetroArch master, it runs to completion. 
```
...
CC deps/rcheevos/src/rcheevos/condset.c
CC deps/rcheevos/src/rcheevos/condition.c
...
CC menu/drivers_display/menu_display_gdi.c
CC tasks/task_decompress.c
LD retroarch
```
The only obvious difference I can see is that my `/mingw64/lib/gcc/...` folder is 7.3.0 instead of 8.2.0.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485171008,C89/CXX support for rcheevos,orbea,31,435436703,6,485171008,0,485169611,2019-04-20T21:00:12Z,Fwiw `CXX_BUILD` seems to be working with mingw in my travis test build.,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485172100,C89/CXX support for rcheevos,orbea,31,435436703,7,485172100,0,485171008,2019-04-20T21:07:14Z,"`C89_BUILD` and `CXX_BUILD` still needs to be fixed in rcheevos.

gcc + CXX_BUILD
```
CC deps/rcheevos/src/rcheevos/trigger.c
In file included from deps/rcheevos/src/rcheevos/internal.h:6,
                 from deps/rcheevos/src/rcheevos/trigger.c:1:
deps/rcheevos/src/rcheevos/trigger.c: In function ‘int rc_trigger_size(const char*)’:
deps/rcheevos/src/rcheevos/internal.h:10:66: error: types may not be defined within __builtin_offsetof
 #define RC_ALIGNOF(t) offsetof(struct RC_TAG(_unnamed, __LINE__) {char c; t d;}, d)
                                                                  ^
deps/rcheevos/src/rcheevos/internal.h:12:76: note: in expansion of macro ‘RC_ALIGNOF’
 #define RC_ALLOC(t, p) ((t*)rc_alloc((p)->buffer, &(p)->offset, sizeof(t), RC_ALIGNOF(t), &(p)->scratch))
                                                                            ^~~~~~~~~~
deps/rcheevos/src/rcheevos/trigger.c:45:10: note: in expansion of macro ‘RC_ALLOC’
   self = RC_ALLOC(rc_trigger_t, &parse);
          ^~~~~~~~
deps/rcheevos/src/rcheevos/trigger.c: In function ‘rc_trigger_t* rc_parse_trigger(void*, const char*, lua_State*, int)’:
deps/rcheevos/src/rcheevos/internal.h:10:66: error: types may not be defined within __builtin_offsetof
 #define RC_ALIGNOF(t) offsetof(struct RC_TAG(_unnamed, __LINE__) {char c; t d;}, d)
                                                                  ^
deps/rcheevos/src/rcheevos/internal.h:12:76: note: in expansion of macro ‘RC_ALIGNOF’
 #define RC_ALLOC(t, p) ((t*)rc_alloc((p)->buffer, &(p)->offset, sizeof(t), RC_ALIGNOF(t), &(p)->scratch))
                                                                            ^~~~~~~~~~
deps/rcheevos/src/rcheevos/trigger.c:57:10: note: in expansion of macro ‘RC_ALLOC’
   self = RC_ALLOC(rc_trigger_t, &parse);
          ^~~~~~~~
make: *** [obj-unix/release/deps/rcheevos/src/rcheevos/trigger.o] Error 1
make: *** Waiting for unfinished jobs....
```
clang + C89_BUILD
```
CC deps/rcheevos/src/rcheevos/format.c
deps/rcheevos/src/rcheevos/alloc.c:53:2: error: no newline at end of file [-Werror,-Wnewline-eof]
}
 ^
1 error generated.
```",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485177895,C89/CXX support for rcheevos,Jamiras,31,435436703,8,485177895,0,485172100,2019-04-20T21:41:03Z,"It seems like you're both seeing the same error, but at different times. I don't see it either time. It looks like it wants the struct to be removed from within the `offsetof` macro, which I switched to, replacing the `RC_OFFSETOF` macro @leiradel added [here](https://github.com/RetroAchievements/rcheevos/commit/7a25d015730fb7703c42b06643981829b05da1e6#diff-6c611697043371fc9f330a9ece88dbc2).

Both approaches are listed [here](https://stackoverflow.com/questions/28460987/c-get-type-alignment-portably)

With the RC_OFFSETOF macro, I get this error:
```
deps/rcheevos/src/rcheevos/internal.h:14:43: error: types may not be defined in casts
  #define RC_ALIGNOF(t) RC_OFFSETOF(struct {char c; t d;}, d)
                                           ^
deps/rcheevos/src/rcheevos/internal.h:13:49: note: in definition of macro 'RC_OFFSETOF'
  #define RC_OFFSETOF(s, f) ((int)(long long)(&((s*)0)->f))
                                                 ^
```
If either of you have any ideas how to address this, I would appreciate the help.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485178946,C89/CXX support for rcheevos,meleu,31,435436703,9,485178946,0,485177895,2019-04-20T21:47:04Z,"Guys, sorry for the trouble inserted by my PR. At least I got a lesson learned: **test every commit against `CXX_BUILD` and `C89_BUILD`**.

Integrating rcheevos into RetroArch as a very important step for us, cheevos enthusiasts.

Many thanks for all the effort put here! :heart:",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485179359,C89/CXX support for rcheevos,inactive123,31,435436703,10,485179359,0,485178946,2019-04-20T21:49:24Z,"No problem @meleu, it's all a worthy learning experience.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485179619,C89/CXX support for rcheevos,orbea,31,435436703,11,485179619,0,485179359,2019-04-20T21:50:43Z,"The clang issue is easy to fix, how does contributing to rcheevos work? Should I just make PRs here?",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485180015,C89/CXX support for rcheevos,Jamiras,31,435436703,12,485180015,0,485179619,2019-04-20T21:52:55Z,"rcheevos has its own repository: https://github.com/RetroAchievements/rcheevos
but as RetroArch is using a copy of the code the change has to be made in both places, so a PR for either would suffice.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485180614,C89/CXX support for rcheevos,orbea,31,435436703,13,485180614,0,485180015,2019-04-20T21:56:35Z,"@Jamiras Can you tell us a bit about your build environment? What OS and compilers are you using?

I'm not sure about the CXX_BUILD issue either, but I can reproduce it locally too where the previous error was with travis. For reference here is the error clang makes.
```
CC deps/rcheevos/src/rcheevos/trigger.c
deps/rcheevos/src/rcheevos/trigger.c:45:10: error: '_unnamed45' cannot be defined in a type specifier
  self = RC_ALLOC(rc_trigger_t, &parse);
         ^
deps/rcheevos/src/rcheevos/internal.h:12:76: note: expanded from macro 'RC_ALLOC'
#define RC_ALLOC(t, p) ((t*)rc_alloc((p)->buffer, &(p)->offset, sizeof(t), RC_ALIGNOF(t), &(p)->scratch))
                                                                           ^
deps/rcheevos/src/rcheevos/internal.h:10:39: note: expanded from macro 'RC_ALIGNOF'
#define RC_ALIGNOF(t) offsetof(struct RC_TAG(_unnamed, __LINE__) {char c; t d;}, d)
                                      ^
deps/rcheevos/src/rcheevos/internal.h:9:21: note: expanded from macro 'RC_TAG'
#define RC_TAG(x,y) RC_TAG2(x,y)
                    ^
deps/rcheevos/src/rcheevos/internal.h:8:22: note: expanded from macro 'RC_TAG2'
#define RC_TAG2(x,y) x ## y
                     ^
<scratch space>:9:1: note: expanded from here
_unnamed45
^
deps/rcheevos/src/rcheevos/trigger.c:57:10: error: '_unnamed57' cannot be defined in a type specifier
  self = RC_ALLOC(rc_trigger_t, &parse);
         ^
deps/rcheevos/src/rcheevos/internal.h:12:76: note: expanded from macro 'RC_ALLOC'
#define RC_ALLOC(t, p) ((t*)rc_alloc((p)->buffer, &(p)->offset, sizeof(t), RC_ALIGNOF(t), &(p)->scratch))
                                                                           ^
deps/rcheevos/src/rcheevos/internal.h:10:39: note: expanded from macro 'RC_ALIGNOF'
#define RC_ALIGNOF(t) offsetof(struct RC_TAG(_unnamed, __LINE__) {char c; t d;}, d)
                                      ^
deps/rcheevos/src/rcheevos/internal.h:9:21: note: expanded from macro 'RC_TAG'
#define RC_TAG(x,y) RC_TAG2(x,y)
                    ^
deps/rcheevos/src/rcheevos/internal.h:8:22: note: expanded from macro 'RC_TAG2'
#define RC_TAG2(x,y) x ## y
                     ^
<scratch space>:11:1: note: expanded from here
_unnamed57
^
2 errors generated.
make: *** [Makefile:201: obj-unix/release/deps/rcheevos/src/rcheevos/trigger.o] Error 1
```",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485180620,C89/CXX support for rcheevos,Jamiras,31,435436703,14,485180620,0,485180614,2019-04-20T21:56:37Z,I'd recommend making the fix here as it's an immediate issue here. Then meleu or I can make sure it happens upstream.,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485181070,C89/CXX support for rcheevos,inactive123,31,435436703,15,485181070,0,485180620,2019-04-20T21:59:34Z,"Yeah, I agree.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485181212,C89/CXX support for rcheevos,Jamiras,31,435436703,16,485181212,0,485181070,2019-04-20T22:00:35Z,My primary development environment is Windows 10. I usually use VS2017 (RetroArch-msvc2017.sln) for build/debug. I have an Ubunutu18 VM specifically for doing Linux builds and followed the steps [here](https://docs.libretro.com/development/retroarch/compilation/ubuntu/) to build RetroArch. I also have mingw installed for those times when it is needed.,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485181712,C89/CXX support for rcheevos,orbea,31,435436703,17,485181712,0,485181212,2019-04-20T22:03:56Z,"From what I can tell from travis and my local builds its only with linux and maybe only some compiler versions? Have you tried both gcc and clang? What versions?

You can find out with:
```
g++ -dumpversion
```
and
```
clang++ --version
```

Edit: The clang fix is here. https://github.com/libretro/RetroArch/pull/8612",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485182023,C89/CXX support for rcheevos,Jamiras,31,435436703,18,485182023,0,485181712,2019-04-20T22:06:04Z,"No. How do I make RetroArch target `g++` or `clang++`?

`g++` reports ""7"". `clang++` does not appear to be installed.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485182300,C89/CXX support for rcheevos,orbea,31,435436703,19,485182300,0,485182023,2019-04-20T22:07:38Z,"You can pass `CC` and `CXX` to configure as environment variables to target specific compiler binaries.

For example I build with clang like this.
```
CC=clang CXX=clang++ ./configure
make
```",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485182720,C89/CXX support for rcheevos,Jamiras,31,435436703,20,485182720,0,485182300,2019-04-20T22:09:41Z,"I'll give that a try, but I could still use some insight on how to address the underlying issue: how to implement `alignof` ([C++11 feature](https://en.cppreference.com/w/cpp/language/alignof)) in a way that works for all of the various builds.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485183470,C89/CXX support for rcheevos,orbea,31,435436703,21,485183470,0,485182720,2019-04-20T22:13:43Z,@hhromic This might be the kind of thing you can help with if you would be so kind. :),False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485183894,C89/CXX support for rcheevos,inactive123,31,435436703,22,485183894,0,485183470,2019-04-20T22:16:14Z,"Best not to use these newer constructs please, same with offsetof/alignof. It's not portable enough.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485184464,C89/CXX support for rcheevos,Jamiras,31,435436703,23,485184464,0,485183894,2019-04-20T22:19:18Z,"`offsetof` already occurs 170+ times in the repository, so I thought it was safe to use. I understand that c++11 features are not, so I didn't go all the way to `alignof`. 

Maybe [this](https://github.com/libretro/RetroArch/blob/master/gfx/include/userland/interface/khronos/common/khrn_int_util.h#L432-L438) will work.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485184971,C89/CXX support for rcheevos,inactive123,31,435436703,24,485184971,0,485184464,2019-04-20T22:22:04Z,"You might have a point about offsetof, although I do feel we should not add to the problem at the expense of portability. The files for which they are used generally assume a compiler with a higher supported C / C++ version, but generally we tend to prefer to err on the side of caution and go for the lowest requirements possible per source file. Cheevos should definitely be a feature that should be available from the low end to the high end.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485185061,C89/CXX support for rcheevos,inactive123,31,435436703,25,485185061,0,485184971,2019-04-20T22:22:37Z,"That being said, we can try what you suggested.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485186967,C89/CXX support for rcheevos,orbea,31,435436703,26,485186967,0,485185061,2019-04-20T22:33:37Z,"I tried this.
```
diff --git a/deps/rcheevos/src/rcheevos/internal.h b/deps/rcheevos/src/rcheevos/internal.h
index 18b123e871..a0b0cd8265 100644
--- a/deps/rcheevos/src/rcheevos/internal.h
+++ b/deps/rcheevos/src/rcheevos/internal.h
@@ -7,7 +7,14 @@
 
 #define RC_TAG2(x,y) x ## y
 #define RC_TAG(x,y) RC_TAG2(x,y)
-#define RC_ALIGNOF(t) offsetof(struct RC_TAG(_unnamed, __LINE__) {char c; t d;}, d)
+
+#ifdef _MSC_VER
+   #define RC_ALIGNOF(T) __alignof(T)
+#elif defined(__CC_ARM)
+   #define RC_ALIGNOF(T) __alignof__(T)
+#else
+   #define RC_ALIGNOF(T) (sizeof(struct { T t; char ch; }) - sizeof(T))
+#endif
 
 #define RC_ALLOC(t, p) ((t*)rc_alloc((p)->buffer, &(p)->offset, sizeof(t), RC_ALIGNOF(t), &(p)->scratch))
```
and got this error with `CXX_BUILD=1`.
```
CC deps/rcheevos/src/rcheevos/trigger.c
In file included from deps/rcheevos/src/rcheevos/trigger.c:1:
deps/rcheevos/src/rcheevos/trigger.c: In function ‘int rc_trigger_size(const char*)’:
deps/rcheevos/src/rcheevos/internal.h:16:41: error: types may not be defined in ‘sizeof’ expressions
    #define RC_ALIGNOF(T) (sizeof(struct { T t; char ch; }) - sizeof(T))
                                         ^
deps/rcheevos/src/rcheevos/internal.h:19:76: note: in expansion of macro ‘RC_ALIGNOF’
 #define RC_ALLOC(t, p) ((t*)rc_alloc((p)->buffer, &(p)->offset, sizeof(t), RC_ALIGNOF(t), &(p)->scratch))
                                                                            ^~~~~~~~~~
deps/rcheevos/src/rcheevos/trigger.c:45:10: note: in expansion of macro ‘RC_ALLOC’
   self = RC_ALLOC(rc_trigger_t, &parse);
          ^~~~~~~~
deps/rcheevos/src/rcheevos/trigger.c: In function ‘rc_trigger_t* rc_parse_trigger(void*, const char*, lua_State*, int)’:
deps/rcheevos/src/rcheevos/internal.h:16:41: error: types may not be defined in ‘sizeof’ expressions
    #define RC_ALIGNOF(T) (sizeof(struct { T t; char ch; }) - sizeof(T))
                                         ^
deps/rcheevos/src/rcheevos/internal.h:19:76: note: in expansion of macro ‘RC_ALIGNOF’
 #define RC_ALLOC(t, p) ((t*)rc_alloc((p)->buffer, &(p)->offset, sizeof(t), RC_ALIGNOF(t), &(p)->scratch))
                                                                            ^~~~~~~~~~
deps/rcheevos/src/rcheevos/trigger.c:57:10: note: in expansion of macro ‘RC_ALLOC’
   self = RC_ALLOC(rc_trigger_t, &parse);
          ^~~~~~~~
make: *** [Makefile:201: obj-unix/release/deps/rcheevos/src/rcheevos/trigger.o] Error 1
```",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485187179,C89/CXX support for rcheevos,Jamiras,31,435436703,27,485187179,0,485186967,2019-04-20T22:34:53Z,"Sigh, it worked for the C89 build on both Linux and MinGW, but failed the CXX build on both.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485191160,C89/CXX support for rcheevos,Jamiras,31,435436703,28,485191160,0,485187179,2019-04-20T22:57:39Z,"I dislike having to specify every type exposed to the macro, but this seems to work for all of my builds. @orbea - can you verify?
```
#ifndef INTERNAL_H
#define INTERNAL_H

#include ""rcheevos.h""

#define RC_ALLOW_ALIGN(T) struct __align_ ## T { char ch; T t; };
RC_ALLOW_ALIGN(rc_condition_t)
RC_ALLOW_ALIGN(rc_condset_t)
RC_ALLOW_ALIGN(rc_expression_t)
RC_ALLOW_ALIGN(rc_lboard_t)
RC_ALLOW_ALIGN(rc_memref_value_t)
RC_ALLOW_ALIGN(rc_operand_t)
RC_ALLOW_ALIGN(rc_richpresence_t)
RC_ALLOW_ALIGN(rc_richpresence_display_t)
RC_ALLOW_ALIGN(rc_richpresence_display_part_t)
RC_ALLOW_ALIGN(rc_richpresence_lookup_t)
RC_ALLOW_ALIGN(rc_richpresence_lookup_item_t)
RC_ALLOW_ALIGN(rc_term_t)
RC_ALLOW_ALIGN(rc_trigger_t)
RC_ALLOW_ALIGN(rc_value_t)
RC_ALLOW_ALIGN(char)

#define RC_ALIGNOF(T) (sizeof(struct __align_ ## T) - sizeof(T))

#define RC_ALLOC(t, p) ((t*)rc_alloc((p)->buffer, &(p)->offset, sizeof(t), RC_ALIGNOF(t), &(p)->scratch))
...
```",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485195076,C89/CXX support for rcheevos,orbea,31,435436703,29,485195076,0,485191160,2019-04-20T23:21:27Z,That seems to build fine here too.,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485195599,C89/CXX support for rcheevos,inactive123,31,435436703,30,485195599,0,485195076,2019-04-20T23:24:33Z,"OK, we'll go with that then for now.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485196364,C89/CXX support for rcheevos,inactive123,31,435436703,31,485196364,0,485195599,2019-04-20T23:29:31Z,"Pushed -

https://github.com/libretro/RetroArch/commit/b5ba2ddc7b4c467a2551c65fc079021d89c9ef81",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/8614,Compilation w/ Wayland fails in Ubuntu 19.04,ofry,7,435485026,1,435485026,0,0,2019-04-21T07:46:40Z,"# First and foremost consider this:
- Only RetroArch bugs should be filed here. Not core bugs or game bugs
- This is not a forum or a help section, this is strictly developer oriented

## Description

Compilation with default configuration (so, with Wayland) fails in KUbuntu 19.04

### Expected behavior

Compilation should be fine

### Actual behavior

```
ofryak@ofryak-virtual-machine:~/CLionProjects/RetroArch$ make clean && ./configure --enable-debug && make
rm -rf obj-unix
rm -f retroarch
rm -f *.d
Checking operating system ... Linux (Ubuntu 19.04 19.04)
Checking for suitable working C compiler ... /usr/bin/gcc works
Checking for suitable working C++ compiler ... /usr/bin/g++ works
Checking for pkg-config ... /usr/bin/pkg-config
Checking for availability of switch -std=gnu99 in /usr/bin/gcc ... yes
Checking for availability of switch -Wno-unused-result in /usr/bin/gcc ... yes
Checking for availability of switch -Wno-unused-variable in /usr/bin/gcc ... yes
Checking function sd_get_machine_names in -lsystemd ... no
Checking presence of package bcm_host ... no
Checking function bcm_host_init in -lbcm_host ... no
Checking presence of package egl ... 19.0.2
Checking function ass_library_init in -lass ... no
Checking function pthread_create in -lpthread ... yes
Checking function pthread_key_create in -lpthread ... yes
Checking function dlopen in -ldl ... yes
Checking function socket in -lc ... yes
Checking function getaddrinfo in -lc ... yes
Checking existence of -lminiupnpc ... no
Checking function fcntl in -lc ... yes
Checking function getopt_long in -lc ... yes
Checking presence of package alsa ... 1.1.8
Checking presence of predefined macro AUDIO_SETINFO in sys/audioio.h ... no
Checking presence of header file sys/soundcard.h ... yes
Checking presence of header file soundcard.h ... no
Checking existence of -lossaudio ... no
Checking function alcOpenDevice in -lopenal ... yes
Checking presence of package rsound >= 1.1 ... no
Checking presence of package libroar >= 1.0.12 ... 1.0.12
Checking presence of package jack >= 0.120.1 ... 1.9.12
Checking presence of package libpulse ... 12.2
Checking presence of package sdl >= 1.2.10 ... no
Checking presence of package sdl2 >= 2.0.0 ... 2.0.9
Checking presence of package Qt5Core >= 5.2 ... 5.12.2
Checking presence of package Qt5Gui >= 5.2 ... 5.12.2
Checking presence of package Qt5Widgets >= 5.2 ... 5.12.2
Checking presence of package Qt5Concurrent >= 5.2 ... 5.12.2
Checking presence of package Qt5Network >= 5.2 ... 5.12.2
Checking presence of package openssl >= 1.0.0 ... 1.1.1b
Checking presence of package flac ... no
Checking presence of header file mbedtls/entropy.h ... no
Checking existence of -lmbedx509 ... no
Checking existence of -lmbedcrypto ... no
Checking presence of package libusb-1.0 >= 1.0.13 ... 1.0.22
Checking presence of header file GL/gl.h ... yes
Checking existence of -lGL ... yes
Checking function cgCreateContext in -lCg -lCgGL ... yes
Checking presence of package zlib ... 1.2.11
Checking presence of package libavcodec >= 54 ... 58.35.100
Checking presence of package libavformat >= 54 ... 58.20.100
Checking presence of package libavdevice ... 58.5.100
Checking presence of package libswresample ... 3.3.100
Checking presence of package libavresample ... no
Checking presence of package libavutil >= 51 ... 56.22.100
Checking presence of package libswscale >= 2.1 ... 5.3.100
Checking presence of header file libavutil/channel_layout.h ... yes
Checking function dlopen in -ldl ... yes
Checking presence of package gbm >= 9.0 ... 19.0.2
Checking presence of package libdrm ... 2.4.97
Checking presence of package vg ... no
Checking presence of package libv4l2 ... 1.16.3
Checking presence of package freetype2 ... 22.1.16
Checking presence of package x11 ... 1.6.7
Checking presence of package xcb ... 1.13.1
Checking presence of package wayland-egl >= 10.1.0 ... 18.1.0
Checking presence of package wayland-cursor >= 1.12 ... 1.16.0
Checking presence of package wayland-protocols >= 1.15 ... 1.17
Checking presence of package wayland-scanner >= 1.12 ... 1.16.0
Checking presence of package xkbcommon >= 0.3.2 ... 0.8.2
Checking presence of package xext ... 1.3.3
Checking presence of package xxf86vm ... 1.1.4
Checking existence of -lXrandr ... yes
Checking presence of package xinerama ... 1.1.4
Checking presence of package xv ... 1.0.11
Checking presence of package libudev ... 240
Checking presence of header file linux/parport.h ... yes
Checking presence of header file linux/ppdev.h ... yes
Checking function strcasestr in -lc ... yes
Checking function mmap in -lc ... yes
Checking function vkCreateInstance in -lvulkan ... yes
Checking for moc ... /usr/bin/moc works
Creating make config: config.mk
Creating config header: config.h
CC input/drivers/linuxraw_input.c
CC input/common/linux_common.c
CC input/drivers_joypad/linuxraw_joypad.c
CC frontend/drivers/platform_unix.c
CC version_git.c
CC frontend/frontend.c
CC frontend/frontend_driver.c
CC frontend/drivers/platform_null.c
CC ui/ui_companion_driver.c
CC ui/drivers/ui_null.c
CC ui/drivers/null/ui_null_window.c
CC ui/drivers/null/ui_null_browser_window.c
CC ui/drivers/null/ui_null_msg_window.c
CC ui/drivers/null/ui_null_application.c
CC core_impl.c
CC retroarch.c
CC dirs.c
CC paths.c
CC command.c
CC msg_hash.c
CC intl/msg_hash_us.c
CC libretro-common/queues/task_queue.c
CC tasks/task_content.c
CC tasks/task_save.c
CC tasks/task_file_transfer.c
CC tasks/task_image.c
CC tasks/task_audio_mixer.c
CC libretro-common/encodings/encoding_utf.c
CC libretro-common/encodings/encoding_crc32.c
CC libretro-common/compat/fopen_utf8.c
CC libretro-common/lists/file_list.c
CC libretro-common/lists/dir_list.c
CC libretro-common/file/retro_dirent.c
CC libretro-common/streams/stdin_stream.c
CC libretro-common/streams/file_stream.c
CC libretro-common/streams/file_stream_transforms.c
CC libretro-common/streams/interface_stream.c
CC libretro-common/streams/memory_stream.c
CC libretro-common/vfs/vfs_implementation.c
CC libretro-common/lists/string_list.c
CC libretro-common/string/stdstring.c
CC libretro-common/memmap/memalign.c
CC setting_list.c
CC list_special.c
CC libretro-common/file/nbio/nbio_stdio.c
CC libretro-common/file/nbio/nbio_linux.c
CC libretro-common/file/nbio/nbio_unixmmap.c
CC libretro-common/file/nbio/nbio_windowsmmap.c
CC libretro-common/file/nbio/nbio_orbis.c
CC libretro-common/file/nbio/nbio_intf.c
CC libretro-common/file/file_path.c
CC file_path_special.c
CC file_path_str.c
CC libretro-common/hash/rhash.c
CC audio/audio_driver.c
CC libretro-common/audio/audio_mixer.c
CC input/common/input_common.c
CC input/input_driver.c
CC input/input_mapper.c
CC led/led_driver.c
CC led/drivers/led_null.c
CC gfx/video_coord_array.c
CC gfx/video_display_server.c
CC gfx/video_driver.c
CC gfx/video_crt_switch.c
CC camera/camera_driver.c
CC wifi/wifi_driver.c
CC location/location_driver.c
CC configuration.c
CC libretro-common/dynamic/dylib.c
CC dynamic.c
CC cores/dynamic_dummy.c
CC libretro-common/queues/message_queue.c
CC managers/core_manager.c
CC managers/state_manager.c
CC gfx/drivers_font_renderer/bitmapfont.c
CC tasks/task_autodetect.c
CC input/input_autodetect_builtin.c
CC input/input_keymaps.c
CC input/input_remapping.c
CC libretro-common/queues/fifo_queue.c
CC managers/core_option_manager.c
CC libretro-common/compat/compat_fnmatch.c
CC libretro-common/compat/compat_posix_string.c
CC managers/cheat_manager.c
CC core_info.c
CC libretro-common/file/config_file.c
CC libretro-common/file/config_file_userdata.c
CC runtime_file.c
CC tasks/task_screenshot.c
CC tasks/task_powerstate.c
CC libretro-common/gfx/scaler/scaler.c
CC gfx/video_shader_parse.c
CC libretro-common/gfx/scaler/pixconv.c
CC libretro-common/gfx/scaler/scaler_int.c
CC libretro-common/gfx/scaler/scaler_filter.c
CC gfx/font_driver.c
CC gfx/video_filter.c
CC libretro-common/audio/resampler/audio_resampler.c
CC libretro-common/audio/dsp_filter.c
CC libretro-common/audio/resampler/drivers/sinc_resampler.c
CC libretro-common/audio/resampler/drivers/nearest_resampler.c
CC libretro-common/audio/resampler/drivers/null_resampler.c
CC libretro-common/utils/md5.c
CC location/drivers/nulllocation.c
CC camera/drivers/nullcamera.c
CC wifi/drivers/nullwifi.c
CC gfx/drivers/nullgfx.c
CC gfx/display_servers/dispserv_null.c
CC audio/drivers/nullaudio.c
CC input/drivers/nullinput.c
CC input/drivers_hid/null_hid.c
CC input/drivers_joypad/null_joypad.c
CC playlist.c
CC movie.c
CC record/record_driver.c
CC record/drivers/record_null.c
CC libretro-common/features/features_cpu.c
CC performance_counters.c
CC verbosity.c
CC midi/midi_driver.c
CC midi/drivers/null_midi.c
CC runahead/copy_load_info.c
CC runahead/dirty_input.c
CC runahead/mem_util.c
CC runahead/mylist.c
CC runahead/run_ahead.c
CC runahead/secondary_core.c
CC audio/drivers_resampler/cc_resampler.c
CC intl/msg_hash_de.c
CC intl/msg_hash_eo.c
CC intl/msg_hash_es.c
CC intl/msg_hash_fr.c
CC intl/msg_hash_it.c
CC intl/msg_hash_ja.c
CC intl/msg_hash_ko.c
CC intl/msg_hash_nl.c
CC intl/msg_hash_pl.c
CC intl/msg_hash_pt_br.c
CC intl/msg_hash_pt_pt.c
CC intl/msg_hash_ru.c
CC intl/msg_hash_vn.c
CC intl/msg_hash_chs.c
CC intl/msg_hash_cht.c
CC intl/msg_hash_ar.c
CC intl/msg_hash_el.c
CC intl/msg_hash_tr.c
CC libretro-common/compat/compat_strl.c
CC libretro-common/formats/image_texture.c
CC cores/libretro-imageviewer/image_core.c
CXX ui/drivers/ui_qt.cpp
CXX ui/drivers/qt/ui_qt_application.cpp
CXX ui/drivers/qt/ui_qt_window.cpp
CXX ui/drivers/qt/ui_qt_browser_window.cpp
CXX ui/drivers/qt/ui_qt_load_core_window.cpp
CXX ui/drivers/qt/ui_qt_msg_window.cpp
CXX ui/drivers/qt/gridview.cpp
CXX ui/drivers/qt/shaderparamsdialog.cpp
CXX ui/drivers/qt/coreoptionsdialog.cpp
CXX ui/drivers/qt/filedropwidget.cpp
CXX ui/drivers/qt/coreinfodialog.cpp
CXX ui/drivers/qt/playlistentrydialog.cpp
CXX ui/drivers/qt/viewoptionsdialog.cpp
CXX ui/drivers/qt/qt_playlist.cpp
CXX ui/drivers/qt/updateretroarch.cpp
CXX ui/drivers/qt/thumbnaildownload.cpp
CXX ui/drivers/qt/thumbnailpackdownload.cpp
CXX ui/drivers/qt/playlistthumbnaildownload.cpp
CXX ui/drivers/qt/settingswidgets.cpp
CXX ui/drivers/qt/options/achievements.cpp
CXX ui/drivers/qt/options/audio.cpp
CXX ui/drivers/qt/options/configuration.cpp
CXX ui/drivers/qt/options/core.cpp
CXX ui/drivers/qt/options/directory.cpp
CXX ui/drivers/qt/options/drivers.cpp
CXX ui/drivers/qt/options/input.cpp
CXX ui/drivers/qt/options/latency.cpp
CXX ui/drivers/qt/options/logging.cpp
CXX ui/drivers/qt/options/network.cpp
CXX ui/drivers/qt/options/osd.cpp
CXX ui/drivers/qt/options/playlists.cpp
CXX ui/drivers/qt/options/recording.cpp
CXX ui/drivers/qt/options/saving.cpp
CXX ui/drivers/qt/options/throttle.cpp
CXX ui/drivers/qt/options/ui.cpp
CXX ui/drivers/qt/options/user.cpp
CXX ui/drivers/qt/options/video.cpp
CC libretro-db/bintree.c
CC libretro-db/libretrodb.c
CC libretro-db/query.c
CC libretro-db/rmsgpack.c
CC libretro-db/rmsgpack_dom.c
CC database_info.c
CC tasks/task_database.c
CC tasks/task_database_cue.c
CC deps/mbedtls/aes.c
CC deps/mbedtls/aesni.c
CC deps/mbedtls/arc4.c
CC deps/mbedtls/asn1parse.c
CC deps/mbedtls/asn1write.c
CC deps/mbedtls/base64.c
CC deps/mbedtls/bignum.c
CC deps/mbedtls/blowfish.c
CC deps/mbedtls/camellia.c
CC deps/mbedtls/ccm.c
CC deps/mbedtls/cipher.c
CC deps/mbedtls/cipher_wrap.c
CC deps/mbedtls/cmac.c
CC deps/mbedtls/ctr_drbg.c
CC deps/mbedtls/des.c
CC deps/mbedtls/dhm.c
CC deps/mbedtls/ecdh.c
CC deps/mbedtls/ecdsa.c
CC deps/mbedtls/ecjpake.c
CC deps/mbedtls/ecp.c
CC deps/mbedtls/ecp_curves.c
CC deps/mbedtls/entropy.c
CC deps/mbedtls/entropy_poll.c
CC deps/mbedtls/error.c
CC deps/mbedtls/gcm.c
CC deps/mbedtls/havege.c
CC deps/mbedtls/hmac_drbg.c
CC deps/mbedtls/md.c
CC deps/mbedtls/md2.c
CC deps/mbedtls/md4.c
CC deps/mbedtls/md5.c
CC deps/mbedtls/md_wrap.c
CC deps/mbedtls/memory_buffer_alloc.c
CC deps/mbedtls/oid.c
CC deps/mbedtls/padlock.c
CC deps/mbedtls/pem.c
CC deps/mbedtls/pk.c
CC deps/mbedtls/pk_wrap.c
CC deps/mbedtls/pkcs12.c
CC deps/mbedtls/pkcs5.c
CC deps/mbedtls/pkparse.c
CC deps/mbedtls/pkwrite.c
CC deps/mbedtls/platform.c
CC deps/mbedtls/ripemd160.c
CC deps/mbedtls/rsa.c
CC deps/mbedtls/sha1.c
CC deps/mbedtls/sha256.c
CC deps/mbedtls/sha512.c
CC deps/mbedtls/threading.c
CC deps/mbedtls/timing.c
CC deps/mbedtls/version.c
CC deps/mbedtls/version_features.c
CC deps/mbedtls/xtea.c
CC deps/mbedtls/certs.c
CC deps/mbedtls/pkcs11.c
CC deps/mbedtls/x509.c
CC deps/mbedtls/x509_create.c
CC deps/mbedtls/x509_crl.c
CC deps/mbedtls/x509_crt.c
CC deps/mbedtls/x509_csr.c
CC deps/mbedtls/x509write_crt.c
CC deps/mbedtls/x509write_csr.c
CC deps/mbedtls/debug.c
CC deps/mbedtls/net_sockets.c
CC deps/mbedtls/ssl_cache.c
CC deps/mbedtls/ssl_ciphersuites.c
CC deps/mbedtls/ssl_cli.c
CC deps/mbedtls/ssl_cookie.c
CC deps/mbedtls/ssl_srv.c
CC deps/mbedtls/ssl_ticket.c
CC deps/mbedtls/ssl_tls.c
CC audio/drivers/oss.c
CC audio/drivers/alsa.c
CC midi/drivers/alsa_midi.c
CC audio/drivers/alsathread.c
CC audio/drivers/tinyalsa.c
CC audio/drivers/roar.c
CC audio/drivers/openal.c
CC audio/drivers/jack.c
CC audio/drivers/pulse.c
CC libretro-common/audio/conversion/s16_to_float.c
CC libretro-common/audio/conversion/float_to_s16.c
CC libretro-common/audio/audio_mix.c
CC libretro-common/formats/wav/rwav.c
CC menu/drivers/rgui.c
CC menu/drivers/materialui.c
CC menu/drivers/xmb.c
CC menu/drivers/ozone/ozone.c
CC menu/drivers/ozone/ozone_entries.c
CC menu/drivers/ozone/ozone_display.c
CC menu/drivers/ozone/ozone_texture.c
CC menu/drivers/ozone/ozone_theme.c
CC menu/drivers/ozone/ozone_sidebar.c
CC menu/menu_shader.c
CC menu/menu_driver.c
CC menu/menu_content.c
CC menu/menu_input.c
CC menu/menu_entries.c
CC menu/menu_setting.c
CC menu/menu_networking.c
CC menu/widgets/menu_filebrowser.c
CC menu/widgets/menu_dialog.c
CC menu/widgets/menu_input_dialog.c
CC menu/widgets/menu_input_bind_dialog.c
CC menu/widgets/menu_entry.c
CC menu/widgets/menu_osk.c
CC menu/menu_cbs.c
CC menu/cbs/menu_cbs_ok.c
CC menu/cbs/menu_cbs_cancel.c
CC menu/cbs/menu_cbs_select.c
CC menu/cbs/menu_cbs_start.c
CC menu/cbs/menu_cbs_info.c
CC menu/cbs/menu_cbs_refresh.c
CC menu/cbs/menu_cbs_left.c
CC menu/cbs/menu_cbs_right.c
CC menu/cbs/menu_cbs_deferred_push.c
CC menu/cbs/menu_cbs_scan.c
CC menu/cbs/menu_cbs_get_value.c
CC menu/cbs/menu_cbs_label.c
CC menu/cbs/menu_cbs_sublabel.c
CC menu/cbs/menu_cbs_title.c
CC menu/cbs/menu_cbs_up.c
CC menu/cbs/menu_cbs_down.c
CC menu/cbs/menu_cbs_contentlist_switch.c
CC menu/menu_displaylist.c
CC menu/menu_animation.c
CC menu/drivers/menu_generic.c
CC menu/drivers/null.c
CC menu/menu_thumbnail_path.c
CC menu/drivers_display/menu_display_null.c
CC tasks/task_overlay.c
CC input/input_overlay.c
CC led/drivers/led_overlay.c
CC gfx/drivers_font_renderer/stb.c
CC gfx/drivers_font_renderer/stb_unicode.c
CC gfx/drivers_font_renderer/freetype.c
CC libretro-common/rthreads/rthreads.c
CC libretro-common/rthreads/rsemaphore.c
CC gfx/video_thread_wrapper.c
CC audio/audio_thread_wrapper.c
CC gfx/drivers_context/wayland_ctx.c
gfx/drivers_context/wayland_ctx.c:629:29: error: unknown type name ‘wl_surface’; did you mean ‘EGLSurface’?
 static void wl_nop(void *a, wl_surface *b, wl_output *c)
                             ^~~~~~~~~~
                             EGLSurface
gfx/drivers_context/wayland_ctx.c:629:44: error: unknown type name ‘wl_output’
 static void wl_nop(void *a, wl_surface *b, wl_output *c)
                                            ^~~~~~~~~
gfx/drivers_context/wayland_ctx.c:638:5: error: ‘wl_nop’ undeclared here (not in a function); did you mean ‘wl_api’?
     wl_nop,
     ^~~~~~
     wl_api
make: *** [Makefile:201: obj-unix/debug/gfx/drivers_context/wayland_ctx.o] Ошибка 1
ofryak@ofryak-virtual-machine:~/CLionProjects/RetroArch$ 
```

### Steps to reproduce the bug

1. [First step]
2. [Second step]
3. [and so on...]

### Bisect Results

[Try to bisect and tell us when this started happening]

### Version/Commit
You can find this information under Information/System Information

- RetroArch: f6fec009d2ef53482997c225d2977651a09fc4d0

### Environment information

- OS: KUbuntu 19.04 x64
- Compiler: make, gcc
",True,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/485253665,Compilation w/ Wayland fails in Ubuntu 19.04,orbea,7,435485026,2,485253665,0,435485026,2019-04-21T13:55:46Z,Would you mind finding the first bad commit?,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485256657,Compilation w/ Wayland fails in Ubuntu 19.04,orbea,7,435485026,3,485256657,0,485253665,2019-04-21T14:36:08Z,"Nevermind, I bisected it.
```
7b3be5eddf6c1a1c1a9f30c4c0eb3eaf1f1fa96f is the first bad commit
commit 7b3be5eddf6c1a1c1a9f30c4c0eb3eaf1f1fa96f
Author: twinaphex <libretro@gmail.com>
Date:   Sat Apr 20 18:42:23 2019 +0200

    (wayland) Fix some CXX_BUILD issues; possibly not all

:040000 040000 e7fa4ecbb5429dee04d01f4a1182e2a6c6308278 6c74f701832d22f775e1e249e40280bb012137c6 M	gfx
```
7b3be5eddf6c1a1c1a9f30c4c0eb3eaf1f1fa96f",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485258137,Compilation w/ Wayland fails in Ubuntu 19.04,orbea,7,435485026,4,485258137,0,485256657,2019-04-21T14:55:28Z,"I submitted a PR to fix this. https://github.com/libretro/RetroArch/pull/8616

Can you later check to make sure it still works during runtime?",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485258494,Compilation w/ Wayland fails in Ubuntu 19.04,ofry,7,435485026,5,485258494,0,485258137,2019-04-21T15:00:07Z,"@orbea Sorry, I can't, because this machine configured for X only :(",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/485258686,Compilation w/ Wayland fails in Ubuntu 19.04,orbea,7,435485026,6,485258686,0,485258494,2019-04-21T15:03:03Z,"No worries.

@Sunderland93 Would you mind testing wayland during runtime later to make sure it hasn't regressed? I also have a X only system...",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485259789,Compilation w/ Wayland fails in Ubuntu 19.04,Sunderland93,7,435485026,7,485259789,0,485258686,2019-04-21T15:18:52Z,"@orbea Sorry, I don't have a Wayland setup currently",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485260345,Compilation w/ Wayland fails in Ubuntu 19.04,orbea,7,435485026,8,485260345,0,485259789,2019-04-21T15:26:55Z,"Thanks for replying, I guess we can just wait and see if anyone complains about new issues. :)",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/8615,mGBA core doesn't save in Duel Masters - Kaijudo Showdown,torben656,4,435493821,1,435493821,0,0,2019-04-21T09:52:33Z,"The VBA-M core saves the game, but the mGBA core doesn't. Tested on nightly and stable.",True,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/485253782,mGBA core doesn't save in Duel Masters - Kaijudo Showdown,orbea,4,435493821,2,485253782,0,435493821,2019-04-21T13:57:21Z,"Does it work with the standalone mgba? This sounds like a core issue, please make an issue for the mgba repo.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/485256883,mGBA core doesn't save in Duel Masters - Kaijudo Showdown,torben656,4,435493821,3,485256883,0,485253782,2019-04-21T14:38:52Z,It works on the standalone mGBA.,False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/485257093,mGBA core doesn't save in Duel Masters - Kaijudo Showdown,RobLoach,4,435493821,4,485257093,0,485256883,2019-04-21T14:41:56Z,What platform? How to reproduce? You seem to have removed the issue template that asked these questions.,False,0,MEMBER
https://api.github.com/repos/libretro/RetroArch/issues/comments/485258449,mGBA core doesn't save in Duel Masters - Kaijudo Showdown,orbea,4,435493821,5,485258449,0,485257093,2019-04-21T14:59:34Z,"> It works on the standalone mGBA.

If its broken with the libretro core and works with standalone I think this is the correct issue tracker.

https://github.com/libretro/mgba/issues

I see the repo doesn't appear to be currently up to date, could it be fixed if it was updated?

@endrift Might know more about this specific issue?",False,0,CONTRIBUTOR
https://api.github.com/repos/element-hq/element-web/issues/9533,"Can't use Numpad keys (+, -, 0) to control zoom",dogancelik,11,435425415,1,435425415,0,0,2019-04-20T18:18:56Z,"![Turkish keyboard layout](https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/KB_Turkey.svg/900px-KB_Turkey.svg.png)

This is the keyboard layout used in Turkey.

```
0 * - (without SHIFT key)
= ? _ (with SHIFT key)
```

- Turkish keyboard doesn't have minus and plus like in US keyboard.
- Turkish users can't use Zoom In (no PLUS key), we use Numpad to control zoom on all browsers.
- All browsers (e.g. Chrome, Firefox) support Numpad keys.
- Numpad section on Turkish keyboard has `- + 0` but it doesn't work on Riot Web.

#### Numpad
![Numpad](https://user-images.githubusercontent.com/486818/56461976-1cd56e00-63c4-11e9-83d5-12f9338e0711.jpg)

#### View Menu
![View Menu](https://user-images.githubusercontent.com/486818/56461977-1cd56e00-63c4-11e9-8132-361c6847cb4b.png)

### Version information

- **OS**: Windows 10 (64-bit)
- **Version**: Riot Web Desktop client [1.0.8](https://github.com/vector-im/riot-web/releases/tag/v1.0.8)",True,0,NONE
https://api.github.com/repos/element-hq/element-web/issues/comments/486141072,"Can't use Numpad keys (+, -, 0) to control zoom",lampholder,11,435425415,2,486141072,0,435425415,2019-04-24T09:21:45Z,Would https://github.com/vector-im/riot-web/issues/3160 solve the problem?,False,0,MEMBER
https://api.github.com/repos/element-hq/element-web/issues/comments/487329249,"Can't use Numpad keys (+, -, 0) to control zoom",dogancelik,11,435425415,3,487329249,0,486141072,2019-04-28T00:12:29Z,"@lampholder Yes. Still, fixing keyboard shortcuts would be a plus.",False,0,NONE
https://api.github.com/repos/element-hq/element-web/issues/comments/489236041,"Can't use Numpad keys (+, -, 0) to control zoom",aaronraimist,11,435425415,4,489236041,0,487329249,2019-05-03T20:52:11Z,"Ugh sorry https://github.com/vector-im/riot-web/pull/8381 probably broke this. Good news is Electron did implement my feature request to allow hidden items to keep working but it is only available starting in Electron 6.0.0.beta.1 but Riot is using 4.1.3 so we can't use that yet. @jryans I guess we should put back the other menu item?

https://github.com/electron/electron/pull/16853

--------

>  would be a plus.

😄",False,0,COLLABORATOR
https://api.github.com/repos/element-hq/element-web/issues/comments/490055752,"Can't use Numpad keys (+, -, 0) to control zoom",jryans,11,435425415,5,490055752,0,489236041,2019-05-07T12:19:29Z,"> @jryans I guess we should put back the other menu item?

Bluh, yes I suppose so. 😭 (I am just sad that Electron makes this so hard...)",False,0,COLLABORATOR
https://api.github.com/repos/element-hq/element-web/issues/comments/490704273,"Can't use Numpad keys (+, -, 0) to control zoom",aaronraimist,11,435425415,6,490704273,0,490055752,2019-05-09T01:01:37Z,"> Numpad section on Turkish keyboard has - + 0 but it doesn't work on Riot Web.

First I read this issue as just zoom in (+/=) didn't work but @dogancelik are you saying zoom out (-) and reset zoom (0) don't work either?

I put back the default electron zoom in menu item in #9654 which should fix the zoom in at least but if the other ones don't work then I don't know what the problem is.",False,0,COLLABORATOR
https://api.github.com/repos/element-hq/element-web/issues/comments/491589360,"Can't use Numpad keys (+, -, 0) to control zoom",dogancelik,11,435425415,7,491589360,0,490704273,2019-05-12T12:00:33Z,"@aaronraimist

![works-doesnt-work](https://user-images.githubusercontent.com/486818/57581872-a6a9c000-74c6-11e9-8f79-a7f1a8f4ecd5.png)

For accessibility:

* `0` and `-` keys above QWERTY row works.
* `0`, `-` and `+` keys on Numpad does NOT work.",False,0,NONE
https://api.github.com/repos/element-hq/element-web/issues/comments/491601042,"Can't use Numpad keys (+, -, 0) to control zoom",aaronraimist,11,435425415,8,491601042,0,491589360,2019-05-12T14:34:44Z,"Alright :( I don’t know what the problem is then.

On my US English keyboard the numpad keys do work.",False,0,COLLABORATOR
https://api.github.com/repos/element-hq/element-web/issues/comments/854996256,"Can't use Numpad keys (+, -, 0) to control zoom",aaronraimist,11,435425415,9,854996256,0,491601042,2021-06-04T21:03:14Z,@dogancelik https://github.com/vector-im/element-desktop/pull/202 may have fixed this. You can try Element Nightly and see if it works now. https://packages.riot.im/nightly/install/,False,0,COLLABORATOR
https://api.github.com/repos/element-hq/element-web/issues/comments/854998663,"Can't use Numpad keys (+, -, 0) to control zoom",t3chguy,11,435425415,10,854998663,0,854996256,2021-06-04T21:08:59Z,"It has for me on macos + USB keyboard, shout if still broken for you.",False,0,MEMBER
https://api.github.com/repos/element-hq/element-web/issues/comments/855028205,"Can't use Numpad keys (+, -, 0) to control zoom",dogancelik,11,435425415,11,855028205,0,854998663,2021-06-04T22:03:25Z,"I downloaded the nightly, it has the same key bindings as before. Even though it shows `Ctrl + -, Ctrl + 0`, they don't work in TR keyboard layout. If I switch to US kb. layout then it works (I mean not numpad keys but the normal ones).
![zoom crop](https://user-images.githubusercontent.com/486818/120866114-f7058600-c597-11eb-9c9f-7ddf1511cc9a.png)

Here's what it looks like when I use the numpad keys.
![zoom working](https://user-images.githubusercontent.com/486818/120866419-90349c80-c598-11eb-982e-d8ea166290ad.png)

This is not a problem of Element but of Electron. I found a solution [here](https://github.com/electron/electron/issues/5256) and will submit a PR to `element-desktop` if you agree.",False,0,NONE
https://api.github.com/repos/element-hq/element-web/issues/comments/855049162,"Can't use Numpad keys (+, -, 0) to control zoom",aaronraimist,11,435425415,12,855049162,0,855028205,2021-06-04T22:26:36Z,If that fixes it for you then sure.,False,0,COLLABORATOR
https://api.github.com/repos/element-hq/element-web/issues/9539,password reset form lacks feedback while it is password-resetting,richvdh,3,436070932,1,436070932,0,0,2019-04-23T08:49:56Z,"1. open password reset form
2. enter new password and submit
3. open confirmation link in email
4. go back to ""reset"" tab. Click on ""I have confirmed my email"".
5. Nothing happens. I think it's sending the request, but I have no idea.
6. Hammer on the button a bit more.
7. give up and reset your password via postgres",True,0,MEMBER
https://api.github.com/repos/element-hq/element-web/issues/comments/486135870,password reset form lacks feedback while it is password-resetting,lampholder,3,436070932,2,486135870,0,436070932,2019-04-24T09:06:32Z,"Our password reset mechanics are super weird, so I'd rather we replace them entirely with something more normal. That said, if we _can_ make this a lot better with a simple spinner we should consider doing so.",False,0,MEMBER
https://api.github.com/repos/element-hq/element-web/issues/comments/895374012,password reset form lacks feedback while it is password-resetting,richvdh,3,436070932,3,895374012,0,486135870,2021-08-09T16:42:28Z,I think this is also a dup of #11531 ,False,0,MEMBER
https://api.github.com/repos/element-hq/element-web/issues/comments/901646032,password reset form lacks feedback while it is password-resetting,Palid,3,436070932,4,901646032,0,895374012,2021-08-19T06:28:18Z,"Duplicate, closing in favor of https://github.com/vector-im/element-web/issues/11531",False,0,CONTRIBUTOR
https://api.github.com/repos/element-hq/element-web/issues/9541,SYSTEM ALERTS section in the room list makes the room list wonky,lampholder,3,436114069,1,436114069,0,0,2019-04-23T10:28:23Z,"I accepted an invite to the System Alerts room and then my roomlist looked like this:

![image](https://user-images.githubusercontent.com/1922197/56574340-e3b31e80-65ba-11e9-93d6-176c639a0663.png)
",True,0,MEMBER
https://api.github.com/repos/element-hq/element-web/issues/comments/485750515,SYSTEM ALERTS section in the room list makes the room list wonky,jryans,3,436114069,2,485750515,0,436114069,2019-04-23T10:39:56Z,"I also had such a section, but then visiting the alerts room (plus maybe opening the room's context menu but not changing anything in it) triggered the room to move to the general ""Rooms"" sublist and the ""System Alerts"" section vanished.",False,0,COLLABORATOR
https://api.github.com/repos/element-hq/element-web/issues/comments/1103987116,SYSTEM ALERTS section in the room list makes the room list wonky,andybalaam,3,436114069,3,1103987116,0,485750515,2022-04-20T14:16:34Z,@lampholder can you reproduce this? We think this may have become irrelevant with recent changes.,False,0,CONTRIBUTOR
https://api.github.com/repos/element-hq/element-web/issues/comments/1104023211,SYSTEM ALERTS section in the room list makes the room list wonky,t3chguy,3,436114069,4,1104023211,0,1103987116,2022-04-20T14:48:56Z,The room list has been entirely rewritten since then I believe! Do shout if you see it again though,False,0,MEMBER
https://api.github.com/repos/element-hq/element-web/issues/9551,Settings > Profile is using wrong profile information when using per-room nicks/avatars,Half-Shot,7,436445108,1,436445108,0,0,2019-04-24T00:29:48Z,"My settings window displays:

![image](https://user-images.githubusercontent.com/2072976/56624321-4d214480-6630-11e9-97a5-20e957dda393.png)

which seems to be getting info from #watercooler:half-shot.uk:

![image](https://user-images.githubusercontent.com/2072976/56624359-67f3b900-6630-11e9-8d98-f73e4489f193.png)


wheras my profile is:

```
> curl https://matrix.half-shot.uk/_matrix/client/r0/profile/@Half-Shot:half-shot.uk
{
    ""displayname"": ""Half-Shot"",
    ""avatar_url"": ""mxc://half-shot.uk/6fc3fb176d5246f1e7cf7d89ad4248b8""
}
```
",True,0,MEMBER
https://api.github.com/repos/element-hq/element-web/issues/comments/563990971,Settings > Profile is using wrong profile information when using per-room nicks/avatars,Half-Shot,7,436445108,2,563990971,0,436445108,2019-12-10T11:27:22Z,"Looked into this as it's still happening:

- Riot gets user profile info from `MatrixClient.getUser` (https://github.com/matrix-org/matrix-react-sdk/blob/develop/src/components/views/settings/ProfileSettings.js#L30-L31)
- `getUser` fetches it from the backing store.
- Presumably, `storeUser` is called with the data from the per-room profile data at some point but I've not been able to track it down.",False,0,MEMBER
https://api.github.com/repos/element-hq/element-web/issues/comments/566538281,Settings > Profile is using wrong profile information when using per-room nicks/avatars,t3chguy,7,436445108,3,566538281,0,563990971,2019-12-17T13:20:04Z,"> I've not been able to track it down.

Nor I, which could imply its a Synapse thinko",False,0,MEMBER
https://api.github.com/repos/element-hq/element-web/issues/comments/566541412,Settings > Profile is using wrong profile information when using per-room nicks/avatars,Half-Shot,7,436445108,4,566541412,0,566538281,2019-12-17T13:29:01Z,"Well, it concerns me that we don't call `/profile` when opening the profile page to be honest. We should be doing that anyway to ensure we have the latest data for the user.",False,0,MEMBER
https://api.github.com/repos/element-hq/element-web/issues/comments/566552430,Settings > Profile is using wrong profile information when using per-room nicks/avatars,Half-Shot,7,436445108,5,566552430,0,566541412,2019-12-17T13:59:48Z,"So, Synapse sends member state down `/sync` when I talk in a room occasionally:

![image](https://user-images.githubusercontent.com/2072976/71001536-64d49e00-20d5-11ea-9891-45bff09ff459.png)

You can see here a membership event in `state`, despite setting that state in the room some time ago.

Additionally, we set the global profile cache in MemoryStore to the contents of the last member event we saw for a user which is obviously a wrong assumption to make given room membership changes are not global state. ",False,0,MEMBER
https://api.github.com/repos/element-hq/element-web/issues/comments/566553652,Settings > Profile is using wrong profile information when using per-room nicks/avatars,t3chguy,7,436445108,6,566553652,0,566552430,2019-12-17T14:02:54Z,"The js-sdk Memory Store updates the global `User` displayName on `m.room.member` events, they also get updated on Presence events (correct). `m.room.member` events should only affect RoomMember displayName not the global `User` displayName.",False,0,MEMBER
https://api.github.com/repos/element-hq/element-web/issues/comments/566553925,Settings > Profile is using wrong profile information when using per-room nicks/avatars,Half-Shot,7,436445108,7,566553925,0,566553652,2019-12-17T14:03:32Z,"Turns out, this is because of lazy loading. We will send redundant membership events down sync due to `include_redundant_members` in the sync filter.",False,0,MEMBER
https://api.github.com/repos/element-hq/element-web/issues/comments/612827931,Settings > Profile is using wrong profile information when using per-room nicks/avatars,t3chguy,7,436445108,8,612827931,0,566553925,2020-04-13T09:32:28Z,Related https://github.com/vector-im/riot-web/issues/940,False,0,MEMBER
https://api.github.com/repos/kaminari/kaminari/issues/987,"Add ""entries_info"" option to paginate helper",mokichi,3,424473674,1,424473674,0,0,2019-03-23T07:29:57Z,"I usually use kaminari often. Thank you very much for your maintenance :)

When I use kaminari, I would like to display page entries info with pagination but I cannot call [page_entries_info](https://github.com/kaminari/kaminari/blob/master/kaminari-core/lib/kaminari/helpers/helper_methods.rb#L196) method inner [paginator view](https://github.com/kaminari/kaminari/blob/master/kaminari-core/app/views/kaminari/_paginator.html.erb). So I add `entries_info` option to paginate helper.

For example, following code outputs page entries info with pagination.

```erb
<%= paginate User.page(1), entries_info: true, params: {controller: 'users', action: 'index'} %>
```

output:

```html
<nav class=""pagination"" role=""navigation"" aria-label=""pager"">
  <span class=""page current"">
    1
  </span>
  <span class=""page"">
    <a rel=""next"" href=""/users?page=2"">2</a>
  </span>
  <span class=""next"">
    <a rel=""next"" href=""/users?page=2"">Next &rsaquo;</a>
  </span>
  <span class=""last"">
    <a href=""/users?page=2"">Last &raquo;</a>
  </span>
  <span class=""entries-info"">
    Displaying users <b>1&nbsp;-&nbsp;25</b> of <b>50</b> in total
  </span>
</nav>
```",True,0,NONE
https://api.github.com/repos/kaminari/kaminari/issues/comments/475882059,"Add ""entries_info"" option to paginate helper",yuki24,3,424473674,2,475882059,0,424473674,2019-03-23T16:08:43Z,"> I cannot call page_entries_info method inner paginator view.

I don't think this is true. Have you tried using `rails g kaminari:views default` and customizing your templates?",False,0,MEMBER
https://api.github.com/repos/kaminari/kaminari/issues/comments/475938795,"Add ""entries_info"" option to paginate helper",mokichi,3,424473674,3,475938795,0,475882059,2019-03-24T08:29:06Z,@yuki24 I'm sorry for lack of explanation. I cannot call page_entries_info method inner paginator view bacause `Paginator` doesn't have the `scope`. Helper method `page_entries_info` needs a scope argument.,False,0,NONE
https://api.github.com/repos/kaminari/kaminari/issues/comments/482660071,"Add ""entries_info"" option to paginate helper",yuki24,3,424473674,4,482660071,0,475938795,2019-04-12T17:36:50Z,"> `Paginator` doesn't have the `scope`

Right, the scope isn't available in the view context. I think it may make sense to make it available, but I think adding the entire `page_entries_info` is going way too far because it's not super complicated to do so with the `paginate` method:

```erb
<%= paginate @users, scope: @users %>
```

Then the `scope` will be available in the `_paginator.html.erb`:

```erb
<span class=""entries-info"">
  <%= page_entries_info scope %>
</span>
```

I know, but at least it works and there's nothing complicated in it. Also, in my experience with Kaminari, what worked well was to add a helper method that does both:

```ruby
# Of course this could be a partial template if it requires heavier HTML templating.
def paginate_with_entries_info(scope)
  concat paginate(scope)

  tag.span class: ""entries-info"" do
    page_entries_info(scope)
  end
end
```

```erb
<%= paginate_with_entries_info @users %>
```

The rationale here is that most design systems and style guides have a Pagination component, which is essentially what the `paginate` method renders while `page_entries_info` is out of the scope of it. I feel like the proposed option is optimized for a specific use case rather than Kaminari staying as a generic pagination library. 

I'm closing this PR due to the reasons mentioned above.
",False,0,MEMBER
https://api.github.com/repos/kaminari/kaminari/issues/993,Clarification about the canonical way to show all records,robotex82,4,438923865,1,438923865,0,0,2019-04-30T18:50:03Z,"I have not found a way to show all records when using kaminari.

If found this this on stackoverflow

https://stackoverflow.com/questions/11818158/show-all-results-on-one-page-gem-kaminari

And this commit, that was not accepted.

https://github.com/kaminari/kaminari/commit/38fb04fab3e6c094a2325ce5e9d9d34051095c07#commitcomment-2425121

And then this one, that uses default page size when per is ni:

https://github.com/kaminari/kaminari/commit/03fe8ba9b04c85372e04b4e31e89060caee26ff5

Now I'm confused about how to show all records, when using page.

Assume I have this code:
`
    def load_collection
      @collection = load_collection_scope.page(params[:page]).per(per_page)
    end

    # This code was written under the assumption that nil does not limit.
    def per_page
      if [nil, 'all'].include?(params[:per_page])
        nil
      else
        25
      end
    end
`
What would be the correct way to paginate without breaking paginate helpers in the views? And can we add the canical way to the docs? That'd be nice

Bonus points for not having to issue an additional count. ;)

Many thanks

Roberto",True,0,NONE
https://api.github.com/repos/kaminari/kaminari/issues/comments/501123265,Clarification about the canonical way to show all records,yuki24,4,438923865,2,501123265,0,438923865,2019-06-12T05:12:16Z,"I think the `except` method on the relation object should work without breaking pagination helpers:

```ruby
@collection = load_collection_scope.page(params[:page]).per(per_page)

if no_pagination?
  @collection = @collection.except(:limit, :order)
end
```
",False,0,MEMBER
https://api.github.com/repos/kaminari/kaminari/issues/comments/635015445,Clarification about the canonical way to show all records,yuki24,4,438923865,3,635015445,0,501123265,2020-05-28T00:24:28Z,"I'm closing this issue due to inactivity. If you need to unpaged, please try calling `.except(:limit, :order)` to remove the limit and offset values from the relation object.",False,0,MEMBER
https://api.github.com/repos/kaminari/kaminari/issues/comments/644791048,Clarification about the canonical way to show all records,doesdev,4,438923865,4,644791048,0,635015445,2020-06-16T14:10:44Z,"As a note, using the `.except` approach will cause `nil can't be coerced into Integer` for some of the view helpers such as `current_page`.",False,0,NONE
https://api.github.com/repos/kaminari/kaminari/issues/comments/947271145,Clarification about the canonical way to show all records,LEstradioto,4,438923865,5,947271145,0,644791048,2021-10-20T02:44:01Z,"Only way to helpers work, don't know about performance
```ruby
@collection = @collection.except(:limit, :offset)
@collection = @collection.page(1).per(@collection.size)
```",False,0,NONE
https://api.github.com/repos/kaminari/kaminari/issues/994,Benchmarking against Pagy vs Will_Paginate,joshm1204,3,453085440,1,453085440,0,0,2019-06-06T15:07:37Z,"Pagy has made some claims on memory usage and speed against Kaminari and Will_paginate.

I am wondering if anyone has reviewed the benchmark results and came to the same conclusion?

https://github.com/ddnexus/pagy

I have been using Kaminari for small projects and love it, but I am concerned about memory usage on a much larger project with large datasets.  Thoughts on pros and cons of each?

",True,0,NONE
https://api.github.com/repos/kaminari/kaminari/issues/comments/501497308,Benchmarking against Pagy vs Will_Paginate,yuki24,3,453085440,2,501497308,0,453085440,2019-06-12T23:58:34Z,"The TL;DR is that you don't have to worry about it.

So why? Looking at the benchmarks I think they are actually quite accurate. The setup for the benchmarks is also well-defined, and even we could use the benchmark script to measure how performant Kaminari is.

So let's take a look at numbers. In the Speed Benchmark, you could find that the i/s of Kaminari is 121, meaning that each iteration takes roughly 8ms. let's say Kaminari is a bit slower and adds 10ms of latency to each request. Now open your monitoring tool and find out the average response time of your app. I'm not sure how fast your app is, but I'm guessing it is above 100ms (sorry if it's way below that). **Now think about how much reducing this 10ms would contribute to the entire app performance.** It is probably less than 10%, and assuming that Kaminari is only used in a subset of the app, it'd probably be less than that. Same applies to memory usage since the rest of Rails would allocate way more than a single paginator could ever allocate. We are also aware of the fact that [the slow method is the `paginate` method](https://github.com/kaminari/kaminari#the-paginate-helper-method). Normally it's not used in JSON API apps or GraphQL servers, so you'll almost never see any performance boost that is statistically significant if your app is a JSON-only app.

Yes, 10ms is something. However, practically speaking, **you will almost never get to the point where replacing Kaminari would actually make your app significantly faster**. Even if you did, you could only do this after applying all the performance tips and techniques you could find online, such as creating missing indexes, resolving N+1 problems, configuring Puma right, Russian doll caching, HTTP/2 and persistent connections, faster JSON serializer, and everything you can find out using [rack-mini-profiler](https://github.com/MiniProfiler/rack-mini-profiler).

It's great to see competing implementations like Pagy and WillPaginate (and many other hidden gems in the wild). There are also many things we could learn from it. We are also aware of the fact that Kaminari is not leading the race, and we haven't forgotten about it. However, at least as a user, you really don't have to worry about anything.
",False,0,MEMBER
https://api.github.com/repos/kaminari/kaminari/issues/comments/560155486,Benchmarking against Pagy vs Will_Paginate,oicitrapdraz,3,453085440,3,560155486,0,501497308,2019-12-01T20:32:30Z,"> Yes, 10ms is something. However, practically speaking, you will almost never get to the point where replacing Kaminari would actually make your app significantly faster. Even if you did, you could only do this after applying all the performance tips and techniques you could find online, such as creating missing indexes, resolving N+1 problems, configuring Puma right, Russian doll caching, HTTP/2 and persistent connections, faster JSON serializer, and everything you can find out using rack-mini-profiler.

Yes, you can do a lot of things to improve the performance of web applications, in the case of Rails one of those things is improving gems performance, especially if only one gem is producing a delay of 10 ms or more.",False,0,NONE
https://api.github.com/repos/kaminari/kaminari/issues/comments/635026555,Benchmarking against Pagy vs Will_Paginate,yuki24,3,453085440,4,635026555,0,560155486,2020-05-28T00:57:09Z,Closing this issue as we are aware of the performance characteristics and we are always looking for opportunities to speed up Kaminari.,False,0,MEMBER
https://api.github.com/repos/kaminari/kaminari/issues/996,paginate_array Returns Entire Array,joemasilotti,6,470914914,1,470914914,0,0,2019-07-22T06:25:58Z,"`Kaminari.paginate_array` is returning the entire array for every page if `total_count` is less than `per`. I'm using `kaminari (1.1.1)`.

### Expected Result
```
Kaminari.paginate_array([1,2,3,4,5], total_count: 10).page(1).per(2)
# => [1, 2]
```

### Actual Result
```
Kaminari.paginate_array([1,2,3,4,5], total_count: 10).page(1).per(2)
# => [1, 2, 3, 4, 5]
```

Removing the `total_count` option ""fixes"" the behavior.
```
Kaminari.paginate_array([1,2,3,4,5]).page(1).per(2)
# => [1, 2]
```",True,0,NONE
https://api.github.com/repos/kaminari/kaminari/issues/comments/514267245,paginate_array Returns Entire Array,yuki24,6,470914914,2,514267245,0,470914914,2019-07-23T15:43:10Z,"Thanks for reporting. I believe this is the same report as https://github.com/kaminari/kaminari/issues/516, which I had thought was a bug back then, which turned out to be false: https://github.com/kaminari/kaminari/commit/21ad994d42527fd97c8168b0d0ccdd88cec91251. One use case here is that when you have already paginated results (e.g. from a JSON HTTP API) the array should not be modified at all and instead it should just confirm to Kaminari's interface, so you could pass it in to the `#paginate` method.

Also, I noticed that the length of the array does not match the `per` value and the `total_count` is more than the length of the original array. Are these numbers hard-coded just for the sake of filing an issue, or it is something you have in your app?",False,0,MEMBER
https://api.github.com/repos/kaminari/kaminari/issues/comments/514328717,paginate_array Returns Entire Array,joemasilotti,6,470914914,3,514328717,0,514267245,2019-07-23T18:28:21Z,"My goal is to combine two models into one pagination ""resource"". So I counted them up individually to get `total_count`. A more fleshed out example would have looked more like this.

```
events = Event.where(...)
places = Place.where(...)
total_count = events.size .+ places.size
Kaminari.paginate_array(events.first(10) + places.first(10), total_count: total_count)
  .page(1).per(10)
```",False,0,NONE
https://api.github.com/repos/kaminari/kaminari/issues/comments/514731833,paginate_array Returns Entire Array,yuki24,6,470914914,4,514731833,0,514328717,2019-07-24T17:46:20Z,"In my experience, constructing a paginated array in Ruby is problematic and slow. Have you looked into [SQL UNION](https://stackoverflow.com/a/3267374)? This way the `UNION`-ed results would behave like a single, aggregated table that could be used with other SQL statements like `LIMIT` and `OFFSET`, and it would be a lot easier to paginate using Kaminari (or any SQL-based paginator).",False,0,MEMBER
https://api.github.com/repos/kaminari/kaminari/issues/comments/515315717,paginate_array Returns Entire Array,joemasilotti,6,470914914,5,515315717,0,514731833,2019-07-26T05:35:25Z,Thanks for the help! After some digging I don't think a `UNION` will work as the two tables have completely unrelated data.,False,0,NONE
https://api.github.com/repos/kaminari/kaminari/issues/comments/592161904,paginate_array Returns Entire Array,remzelg,6,470914914,6,592161904,0,515315717,2020-02-27T20:29:45Z,"We are exploring a similar use case and it was confusing that there is no documentation to show that the total_count argument for #paginate_array is not usable when paginating multiple resources in an array.

Digging into the tests, you can see that this case has strange behavior. When total count is larger than the number of objects it completely breaks pagination.
see https://github.com/kaminari/kaminari/blob/master/kaminari-core/test/models/array_test.rb#L174

Why would we expect
```
Kaminari::PaginatableArray.new((1..10).to_a, total_count: 9999).page(5).per(10)
```
to return 10 objects when we are paginating to `page(5).per(10`?",False,0,NONE
https://api.github.com/repos/kaminari/kaminari/issues/comments/592207788,paginate_array Returns Entire Array,yuki24,6,470914914,7,592207788,0,592161904,2020-02-27T22:21:41Z,"Because results from an external JSON API could return e.g. 10 elements with a total count of e.g. 9999 but you still want the array to confirm to Kaminari's interface (so you can pass it to `paginate`). You could find out more by reading through the comments in https://github.com/kaminari/kaminari/issues/516#issuecomment-46291619.

In my experience, pagination with multiple tables is very tricky and I would recommend using SQL UNION, SQL View or [`pg_search`'s multi search](https://github.com/Casecommons/pg_search#multi-search) rather than doing it at the Ruby level.",False,0,MEMBER
https://api.github.com/repos/kaminari/kaminari/issues/1002,Added test current_page for array when page 1 per 0,araslanov-e,8,483433152,1,483433152,0,0,2019-08-21T13:48:40Z,,True,0,NONE
https://api.github.com/repos/kaminari/kaminari/issues/comments/523501136,Added test current_page for array when page 1 per 0,yuki24,8,483433152,2,523501136,0,483433152,2019-08-21T15:11:15Z,Could you elaborate on why you are sending this PR?,False,0,MEMBER
https://api.github.com/repos/kaminari/kaminari/issues/comments/523594130,Added test current_page for array when page 1 per 0,araslanov-e,8,483433152,3,523594130,0,523501136,2019-08-21T18:34:16Z,"@yuki24 sorry, tests didn't run locally. And I have a problem with current_page when use limit(0)",False,0,NONE
https://api.github.com/repos/kaminari/kaminari/issues/comments/523594626,Added test current_page for array when page 1 per 0,araslanov-e,8,483433152,4,523594626,0,523594130,2019-08-21T18:35:34Z,@yuki24 In tests I wanted to reproduce the problem,False,0,NONE
https://api.github.com/repos/kaminari/kaminari/issues/comments/523852913,Added test current_page for array when page 1 per 0,solutus,8,483433152,5,523852913,0,523594626,2019-08-22T10:50:10Z,"@yuki24,   Could you please clarify behaviour of pagination when per = 0. 

1. `model_class.page(1).per(0)` returns 0 items without exception.
2. `model_class.page(VERY_BIG_NUM).per(1).current_page` returns VERY_BIG_NUM even if there no any items on this page. 
3. `model_class.page(1).per(0).current_page` raises ZeroPerPageOperation. 

Why  `model_class.page(1).per(0).current_page` does not return 1 as for VERY_BIG_NUM? 

It seems it is possible to avoid such kind of exceptions, without impact. Client could handle result as no items, i.e total_pages = 0. 
Please, share you opinion. Thanks for advance.  

   
",False,0,NONE
https://api.github.com/repos/kaminari/kaminari/issues/comments/524428473,Added test current_page for array when page 1 per 0,yuki24,8,483433152,6,524428473,0,523852913,2019-08-23T19:05:55Z,"First of all, we may be deprecating the `#current_page` method as its behavior is always unpredictable and not intuitive. See https://github.com/kaminari/kaminari/pull/990. We should not have to re-compute the current page number because the `params[:page]` is already there. As demonstrated in the PR, Kaminari's internal code totally works without it, and I'd imagine that it is also the case in a typical Rails app as well.

To answer your question, `model_class.page(1).per(0).current_page == 1` actually makes more sense than raising an exception. But again, you should not rely on this method to get the current page.

Also, what are the reasons why you have to pass in `0` to the `per` method? I have personally never done that myself before, and I am not sure in what case we actually need it.",False,0,MEMBER
https://api.github.com/repos/kaminari/kaminari/issues/comments/524754513,Added test current_page for array when page 1 per 0,solutus,8,483433152,7,524754513,0,524428473,2019-08-26T07:42:37Z,"> Also, what are the reasons you have to pass in 0 to the per method

I agree, it is unusual case for pure pagination logic. 
But it is convenient for case, I tried describe below. 
 
We have API with aggregations, similar to elasticsearch aggregations https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-terms-aggregation.html 

**Example:** 
`GET /api/items?date_gte=2019-07-08&page=2&per=1&with_aggregations=city`

with result:
```json
{
  ""items"": [
    {""city"": ""Tokyo""}
  ],
  ""aggregations"": {
    ""city"": [""Tokyo"", ""Kyoto""]
  },
  ""metadata"": {
    ""total_pages"": 2, 
    ""current_page"": 1
  }
}
```

Using such API, client is getting items and list of aggregations data per filter  at once. 
Aggregations are using to display possible filters on index page. 

**Use case:**
1. User opens /items page
2. Possible filters (cities, Tokyo and Kyoto) are rendered together with items. 
3. User filter items for Tokyo. 


Sometimes client wants only aggregations, without items. 
We want reuse the same api. But  total_pages & current_page raises Exception. 
",False,0,NONE
https://api.github.com/repos/kaminari/kaminari/issues/comments/563032176,Added test current_page for array when page 1 per 0,yuki24,8,483433152,8,563032176,0,524754513,2019-12-09T02:11:38Z,"I wanted to check in and see how this is going. I think @solutus's use case is legit and I am open to changing the behavior here. However, the failing builds should be fixe and new tests should be added to demonstrate the point of the change.
",False,0,MEMBER
https://api.github.com/repos/kaminari/kaminari/issues/comments/635028177,Added test current_page for array when page 1 per 0,yuki24,8,483433152,9,635028177,0,563032176,2020-05-28T01:01:45Z,"I'd be happy to take another look at this pull request, but there doesn't seem to be a lot of activity here. I'll close this issue in the coming weeks if there are no more updates",False,0,MEMBER
https://api.github.com/repos/kaminari/kaminari/issues/1003,Raise ZeroPerPageOperation with limit 0,araslanov-e,3,483435939,1,483435939,0,0,2019-08-21T13:53:23Z,"```
> User.page(1).per(1).current_page
=> 1
> User.page(1).per(1).limit(0).current_page
Kaminari::ZeroPerPageOperation: Current page was incalculable. Perhaps you called .per(0)?
from /gems/kaminari-core-1.1.1/lib/kaminari/models/page_scope_methods.rb:52:in `rescue in current_page'
```",True,0,NONE
https://api.github.com/repos/kaminari/kaminari/issues/comments/523467818,Raise ZeroPerPageOperation with limit 0,araslanov-e,3,483435939,2,523467818,0,483435939,2019-08-21T13:55:01Z,https://github.com/kaminari/kaminari/pull/1002,False,0,NONE
https://api.github.com/repos/kaminari/kaminari/issues/comments/523788241,Raise ZeroPerPageOperation with limit 0,araslanov-e,3,483435939,3,523788241,0,523467818,2019-08-22T07:38:42Z,Why issue an error at per 0 or limit 0?,False,0,NONE
https://api.github.com/repos/kaminari/kaminari/issues/comments/563029711,Raise ZeroPerPageOperation with limit 0,yuki24,3,483435939,4,563029711,0,523788241,2019-12-09T01:57:51Z,"I'm closing this issue since it's kind of sparse and @solutus's comment https://github.com/kaminari/kaminari/pull/1002#issuecomment-524754513 describes the problem better, and I would like to use that as a pointer for changing the behavior of the `current_page` method.",False,0,MEMBER
https://api.github.com/repos/kaminari/kaminari/issues/1009,fixes without_count last_page? behaviour,montdidier,6,529712158,1,529712158,0,0,2019-11-28T06:07:26Z,"I believe this will fix [this bug](https://github.com/kaminari/kaminari/issues/975).

After some experimentation I noted that `@arel.limit` is not always an `Integer`. In the cases this code fails to perform as expected this type is `Arel::Nodes::BindParam`. After some inspection of the various types it appears to me this additional type can also be cloned and modified to behave as expected.",True,0,CONTRIBUTOR
https://api.github.com/repos/kaminari/kaminari/issues/comments/559832204,fixes without_count last_page? behaviour,yuki24,6,529712158,2,559832204,0,529712158,2019-11-29T16:01:32Z,Thanks for your pull request. It would greatly be appreciated if you could add a test and fix the builds for Rails 4.2 and 4.1. We still do support them and we don't drop support for older versions unless it is extremely difficult.,False,0,MEMBER
https://api.github.com/repos/kaminari/kaminari/issues/comments/563031698,fixes without_count last_page? behaviour,yuki24,6,529712158,3,563031698,0,559832204,2019-12-09T02:08:59Z,"I just wanted to check in and see if you are still interested in updating the pull request.

 * New tests should be added to demonstrate the existing behavior that should be fixed.
 * The builds for Rails 4.2 and 4.1 should be fixed.",False,0,MEMBER
https://api.github.com/repos/kaminari/kaminari/issues/comments/563692866,fixes without_count last_page? behaviour,montdidier,6,529712158,4,563692866,0,563031698,2019-12-10T03:32:19Z,@yuki24 Yes I will fix this. I've just not had a chance to revisit it yet. ,False,0,CONTRIBUTOR
https://api.github.com/repos/kaminari/kaminari/issues/comments/567855892,fixes without_count last_page? behaviour,montdidier,6,529712158,5,567855892,0,563692866,2019-12-20T09:25:23Z,@yuki24 Should be fixed . ,False,0,CONTRIBUTOR
https://api.github.com/repos/kaminari/kaminari/issues/comments/567975012,fixes without_count last_page? behaviour,yuki24,6,529712158,6,567975012,0,567855892,2019-12-20T16:00:57Z,Could you add tests?  Regression tests are extremely important.,False,0,MEMBER
https://api.github.com/repos/kaminari/kaminari/issues/comments/575623319,fixes without_count last_page? behaviour,yuki24,6,529712158,7,575623319,0,567975012,2020-01-17T13:21:41Z,@montdidier Thank you for your contribution! really appreciated.,False,0,MEMBER
https://api.github.com/repos/kaminari/kaminari/issues/1010,Ruby 2.7 deprecation warning,connorshea,10,542697416,1,542697416,0,0,2019-12-27T00:00:23Z,"```
/Users/connorshea/.rbenv/versions/2.7.0/lib/ruby/gems/2.7.0/gems/kaminari-core-1.1.1/lib/kaminari/helpers/helper_methods.rb:25: warning: Using the last argument as keyword parameters is deprecated; maybe ** should be added to the call
/Users/connorshea/.rbenv/versions/2.7.0/lib/ruby/gems/2.7.0/gems/kaminari-core-1.1.1/lib/kaminari/helpers/paginator.rb:9: warning: The called method `initialize' is defined here
```

- [`lib/kaminari/helpers/helper_methods.rb:25`](https://github.com/kaminari/kaminari/blob/v1.1.1/kaminari-core/lib/kaminari/helpers/helper_methods.rb#L25)
- [`lib/kaminari/helpers/paginator.rb:9`](https://github.com/kaminari/kaminari/blob/v1.1.1/kaminari-core/lib/kaminari/helpers/paginator.rb#L9)

I assume this can be fixed by replacing `paginator = paginator_class.new (template || self), options` with `paginator = paginator_class.new (template || self), **options`? The current master has changed that file a lot, but it still has the same line (now at 115).",True,0,NONE
https://api.github.com/repos/kaminari/kaminari/issues/comments/569153037,Ruby 2.7 deprecation warning,connorshea,10,542697416,2,569153037,0,542697416,2019-12-27T00:04:25Z,"It also seems like the ruby-head builds are failing in CI. I think it may require updating RubyGems, or just re-running it since 2.7 should include the latest RubyGems release.",False,0,NONE
https://api.github.com/repos/kaminari/kaminari/issues/comments/569182152,Ruby 2.7 deprecation warning,yuki24,10,542697416,3,569182152,0,569153037,2019-12-27T04:07:13Z,Thanks for reporting. I'm hoping that we will be able to fix this in the coming weeks.,False,0,MEMBER
https://api.github.com/repos/kaminari/kaminari/issues/comments/569183465,Ruby 2.7 deprecation warning,amatsuda,10,542697416,4,569183465,0,569182152,2019-12-27T04:19:05Z,"@connorshea Thank you for letting us know! I just pushed 011d6ac3b866d5e1836c246f9a598c79d1213fe5 that addresses the warnings that I saw while I run the tests locally.
I'm still not 100% confident that we fixed all kwargs related warnings, but we'll cut a new release as soon as we finish checking all suspicious method calls.",False,0,MEMBER
https://api.github.com/repos/kaminari/kaminari/issues/comments/569184136,Ruby 2.7 deprecation warning,connorshea,10,542697416,5,569184136,0,569183465,2019-12-27T04:24:53Z,"@yuki24 @amatsuda great, thank you! :)",False,0,NONE
https://api.github.com/repos/kaminari/kaminari/issues/comments/573276433,Ruby 2.7 deprecation warning,connorshea,10,542697416,6,573276433,0,569184136,2020-01-11T03:33:27Z,Any news on the new release? :),False,0,NONE
https://api.github.com/repos/kaminari/kaminari/issues/comments/580518104,Ruby 2.7 deprecation warning,amatsuda,10,542697416,7,580518104,0,573276433,2020-01-30T23:59:13Z,@connorshea Pushed 1.2.0 gem with a fix for this issue. Thank you for waiting patiently! :),False,0,MEMBER
https://api.github.com/repos/kaminari/kaminari/issues/comments/580527277,Ruby 2.7 deprecation warning,connorshea,10,542697416,8,580527277,0,580518104,2020-01-31T00:34:11Z,Thanks!,False,0,NONE
https://api.github.com/repos/kaminari/kaminari/issues/comments/602109170,Ruby 2.7 deprecation warning,wilpar,10,542697416,9,602109170,0,580527277,2020-03-21T21:46:13Z,"Confirmed I'm at 1.20, but I'm still getting a deprecation warning for line 130:

`/gems/ruby-2.7.0/gems/kaminari-core-1.2.0/lib/generators/kaminari/views_generator.rb:130: warning: calling URI.open via Kernel#open is deprecated, call URI.open directly or use URI#open
`",False,0,NONE
https://api.github.com/repos/kaminari/kaminari/issues/comments/602663238,Ruby 2.7 deprecation warning,yuki24,10,542697416,10,602663238,0,602109170,2020-03-23T15:11:12Z,@wilpar Good catch! we probably missed it since it's in the generator. It would be greatly appreciated if you could send us a pull request.,False,0,MEMBER
https://api.github.com/repos/kaminari/kaminari/issues/comments/603901036,Ruby 2.7 deprecation warning,wilpar,10,542697416,11,603901036,0,602663238,2020-03-25T15:19:23Z,"if i can figure it out, i most certainly will. ",False,0,NONE
https://api.github.com/repos/symfony/symfony/issues/33303,Unable to decorates router services,yellow1912,9,484495607,1,484495607,0,0,2019-08-23T12:06:05Z,"**Symfony version(s) affected**: 4.3

**Description**  
<!-- A clear and concise description of the problem. -->

**How to reproduce**  


I'm trying to decorate the UrlMatcher to do some custom matching. My xml looks like this:
```
<service id=""app.localization.routing.url_matcher"" class=""App\LocalizationBundle\Routing\UrlMatcher"" decorates=""Symfony\Component\Routing\Generator\UrlGeneratorInterface"">
            
</service>
```
I tried a number of variations and could not get it to work at all. Symfony still falls back to the `Symfony\Component\Routing\Matcher\UrlMatcher` class.

I even tried to add the inner argument as instructed on [Stackoverflow](https://stackoverflow.com/questions/55468435/symfony-4-2-how-to-decorate-the-urlgenerator) but that doesn't work as well.",True,0,NONE
https://api.github.com/repos/symfony/symfony/issues/comments/524293394,Unable to decorates router services,maxhelias,9,484495607,2,524293394,0,484495607,2019-08-23T12:16:53Z,"The decorates service `Symfony\Component\Routing\Generator\UrlGeneratorInterface` must be `Symfony\Component\Routing\Matcher\UrlMatcherInterface`.

And you can inject the original service like this :
```
<argument type=""service"" id=""app.localization.routing.url_matcher.inner""/>
```",False,0,CONTRIBUTOR
https://api.github.com/repos/symfony/symfony/issues/comments/524301745,Unable to decorates router services,yellow1912,9,484495607,3,524301745,0,524293394,2019-08-23T12:45:56Z,"Hello @maxhelias,

It was a typo when I posted the question, sorry. I double checked and the configuration in the xml is correct but it still doesn't seem to work. Is there any way I can debug it? ",False,0,NONE
https://api.github.com/repos/symfony/symfony/issues/comments/524334690,Unable to decorates router services,stof,9,484495607,4,524334690,0,524301745,2019-08-23T14:22:54Z,that's because the router service is named `router` in FrameworkBundle. `Symfony\Component\Routing\Generator\UrlGeneratorInterface` is only an autowiring alias. Decorating that one will not impact at all the many places referencing the router by its main name (including all places using the router in the core).,False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/comments/524339150,Unable to decorates router services,xabbuh,9,484495607,5,524339150,0,524334690,2019-08-23T14:35:02Z,closing here as explained by @stof,False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/comments/524356510,Unable to decorates router services,yellow1912,9,484495607,6,524356510,0,524339150,2019-08-23T15:21:57Z,"@stof thank you very much. One thing that gets me really confused is that the router is aliased like this:

```
<service id=""router"" alias=""router.default"" public=""true"" />
<service id=""Symfony\Component\Routing\RouterInterface"" alias=""router"" />
<service id=""Symfony\Component\Routing\Generator\UrlGeneratorInterface"" alias=""router"" />
<service id=""Symfony\Component\Routing\Matcher\UrlMatcherInterface"" alias=""router"" />
<service id=""Symfony\Component\Routing\RequestContextAwareInterface"" alias=""router"" />
```

Does it mean I can only decorate the router and not the generator and matcher separately? I'm always confused about this alias concept.",False,0,NONE
https://api.github.com/repos/symfony/symfony/issues/comments/524367154,Unable to decorates router services,stof,9,484495607,7,524367154,0,524356510,2019-08-23T15:52:36Z,"well, `router.default` is an internal private alias, not something that gets referenced outside (probably a legacy from early days of Symfony without `decorates` support to make manual decoration easier).

But the matcher and generator don't exist separately anyway. We use the same object implementing both interfaces.",False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/comments/524390079,Unable to decorates router services,yellow1912,9,484495607,8,524390079,0,524367154,2019-08-23T17:03:21Z,"@stof thank you for your explanation. So after looking at the code is it right to assume that:

1. To decorate the router when using with the framework bundle I should decorate 'router' service.
2. To use a custom url matcher I should replace/override the 'router' service definition since the url matcher class is passed in the definition as a full class name.",False,0,NONE
https://api.github.com/repos/symfony/symfony/issues/comments/607521041,Unable to decorates router services,multifinger,9,484495607,9,607521041,0,524390079,2020-04-01T22:27:44Z,"@stof In symfony 4.4 I'm trying to extend router functionality by decorating it like this:
```
#config/services.yaml
services:
...
    app.router:
        class: App\Service\Router
        decorates: 'router'
        arguments: ['@app.router.inner']
```
Where App\Service\Router decorates given router interface in constructor and uses it in all implemented methods. But with such configuration I got ""No route found for ..."" none of my previously configured and working routes. So, how can I decorate router? I've spent all day looking for examples and documentation, digging the code, etc. Still nothing worked for my. 
I realy want to add some features from symfony1.4 (object-properties-based url generation)
",False,0,NONE
https://api.github.com/repos/symfony/symfony/issues/comments/857676263,Unable to decorates router services,yellow1912,9,484495607,10,857676263,0,607521041,2021-06-09T13:04:15Z,"@multifinger I didn't see your message till now, but I ended up overriding the route loader:

```
<service id=my_router"" class=""MyApp\LocalizationBundle\Routing\Router"" decorates=""router"">
            <tag name=""monolog.logger"" channel=""router"" />
            <tag name=""container.service_subscriber"" id=""routing.loader"" />
            <argument type=""service"" id=""Psr\Container\ContainerInterface"" />
            <argument>%router.resource%</argument>
            <argument type=""collection"">
                <argument key=""cache_dir"">%kernel.cache_dir%</argument>
                <argument key=""debug"">%kernel.debug%</argument>
                <argument key=""generator_class"">MyApp\LocalizationBundle\Routing\UrlGenerator</argument>
                <argument key=""generator_dumper_class"">Symfony\Component\Routing\Generator\Dumper\CompiledUrlGeneratorDumper</argument>
                <argument key=""generator_cache_class"">null</argument>
                <argument key=""matcher_class"">MyApp\LocalizationBundle\Routing\UrlMatcher</argument>
                <argument key=""matcher_dumper_class"">Symfony\Component\Routing\Matcher\Dumper\CompiledUrlMatcherDumper</argument>
            </argument>
            <argument type=""service"" id=""router.request_context"" on-invalid=""ignore"" />
            <argument type=""service"" id=""parameter_bag"" on-invalid=""ignore"" />
            <argument type=""service"" id=""logger"" on-invalid=""ignore"" />
            <argument>%kernel.default_locale%</argument>
            <call method=""setConfigCacheFactory"">
                <argument type=""service"" id=""config_cache_factory"" />
            </call>
        </service>
```",False,0,NONE
https://api.github.com/repos/symfony/symfony/issues/33304,[Messenger] Dynamically subscribe to message on bus,ruudk,5,484547769,1,484547769,0,0,2019-08-23T14:03:25Z,"It would be great if I could dynamically subscribe to a message that is dispatched on a bus.

In my current project, we use [SimpleBus](https://github.com/SimpleBus). SimpleBus supports a way to dynamically add middlewares on an already constructed MessageBus ([MessageBusSupportingMiddleware](https://github.com/SimpleBus/MessageBus/blob/master/src/Bus/Middleware/MessageBusSupportingMiddleware.php)).

It allows me to subscribe to a specific message in runtime, just before I trigger something.

```php
final class SimpleBusEventBus
{
    /**
     * @var EventBus
     */
    private $eventBus;

    public function __construct(EventBus $eventBus)
    {
        $this->eventBus = $eventBus;
    }

    public function onEvent(string $event, callable $callable) : void
    {
        $this->eventBus->appendMiddleware(new class($event, $callable) implements MessageBusMiddleware {
            private $event;
            private $callable;

            public function __construct(string $event, callable $callable)
            {
                $this->event = $event;
                $this->callable = $callable;
            }

            public function handle($event, callable $next) : void
            {
                if (get_class($event) === $this->event) {
                    call_user_func($this->callable, $event);
                }

                $next($event);
            }
        });
    }
}

$this->eventBus->onEvent(SomethingHappened::class, function (SomethingHappened $event) {
    echo ""Something happened"";
});

$this->commandBus->handle(new DoSomething());
```

Would it be possible to do the same for Symfony Messenger?

Either by allowing to alter the middlewares on a constructed bus, or to provide a way to dynamically listen to certain messages on a bus.
",True,0,CONTRIBUTOR
https://api.github.com/repos/symfony/symfony/issues/comments/524479724,[Messenger] Dynamically subscribe to message on bus,Tobion,5,484547769,2,524479724,0,484547769,2019-08-23T22:18:59Z,Why do you need it to be dynamic? What's the use-case?,False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/comments/524524994,[Messenger] Dynamically subscribe to message on bus,ruudk,5,484547769,3,524524994,0,524479724,2019-08-24T06:23:55Z,"For example in a console command. I want to loop over a list of items, and trigger a command that creates 0 or 1-10 entities for that item. On the top I want to subscribe to the event that is emitted every time that entity is created, so that I can log whenever something is created.",False,0,CONTRIBUTOR
https://api.github.com/repos/symfony/symfony/issues/comments/524541020,[Messenger] Dynamically subscribe to message on bus,ro0NL,5,484547769,4,524541020,0,524524994,2019-08-24T10:52:30Z,why wouldnt you log from a handler? Im not sure coupling with dynamic runtime is a smart move :thinking: ,False,0,CONTRIBUTOR
https://api.github.com/repos/symfony/symfony/issues/comments/524541684,[Messenger] Dynamically subscribe to message on bus,ruudk,5,484547769,5,524541684,0,524541020,2019-08-24T11:05:18Z,"I can add logs to the handler, but when I'm in a Console command, I want to write a custom message with `OutputInterface`.

I will create my own Middleware that deals with this :) Thanks.",False,0,CONTRIBUTOR
https://api.github.com/repos/symfony/symfony/issues/comments/524542275,[Messenger] Dynamically subscribe to message on bus,ro0NL,5,484547769,6,524542275,0,524541684,2019-08-24T11:17:27Z,"you can tag the handler also a console command listener, then you can obtain the current command.",False,0,CONTRIBUTOR
https://api.github.com/repos/symfony/symfony/issues/33305,WebTestCase: a 500 error doesn't make the PHPUnit test to fail,dunglas,7,484553199,1,484553199,0,0,2019-08-23T14:14:22Z,"**Symfony version(s) affected**: 4.3 (at least)

**Description**  

In the context of a functional test, if the tested page throws an exception, it is silenced by Symfony. Instead of having a failing PHPUnit test, the error page (with the ghost) is generated and no exceptions are thrown. This lead to uncaught exceptions, or cryptic errors at the following assertion. 

**How to reproduce**  

```php
<?php

namespace App\Tests;

use Symfony\Bundle\FrameworkBundle\Test\WebTestCase;

class ItemControllerTest extends WebTestCase
{
    public function testCreateItem(): void
    {
        $client = static::createClient();
        $client->request('GET', '/page-throwing-an-exception');
        // This test is green, but shouldn't
}
```

**Possible Solution**  

Throw instead of generating the error page when in the context of a functional test.",True,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/comments/524333877,WebTestCase: a 500 error doesn't make the PHPUnit test to fail,stof,7,484553199,2,524333877,0,484553199,2019-08-23T14:20:39Z,"Well, `$client->request` does not perform any assertion. So what you have here is a test verifying nothing.

the WebTestCase already has a method to assert that the response is successful.",False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/comments/524334430,WebTestCase: a 500 error doesn't make the PHPUnit test to fail,dunglas,7,484553199,3,524334430,0,524333877,2019-08-23T14:22:10Z,"Yes, but it shouldn't return a response at all, that's the issue. The PHP exception thrown by the controller or whatever other part should (and was in previous versions IIRC) not be silenced.",False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/comments/524335551,WebTestCase: a 500 error doesn't make the PHPUnit test to fail,stof,7,484553199,4,524335551,0,524334430,2019-08-23T14:25:11Z,"Why shouldn't it return a response at all ? You ask for an HTTP response, and a 500 response is one such response. some projects may want to perform assertions on non-successful responses too, and throwing would forbid that as they would never get access to the response.

Note that this is not new in 4.3. this was already the case in 3.x (and maybe even in 2.x but I don't remember)",False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/comments/524335777,WebTestCase: a 500 error doesn't make the PHPUnit test to fail,fabpot,7,484553199,5,524335777,0,524335551,2019-08-23T14:25:46Z,"I don't understand the issue. The client simulates a browser, so you get the same thing. You should test for a 500 status code here. I doubt that the behavior changed recently.",False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/comments/524338315,WebTestCase: a 500 error doesn't make the PHPUnit test to fail,dunglas,7,484553199,6,524338315,0,524335777,2019-08-23T14:32:40Z,"Indeed you get the same thing than with a browser, but you're in the context of a functional test: except in the very specific case of testing the generated error page, your server should never return a 500 (or it's a bug).
Also:

* consequently it's very difficult to access to the stack trace to figure out what's the underlying issue
* the analogy with a real environment is not exact in this context because the ghost page is only displayed in debug mode, it will never be displayed in production, so a real browser should never see it

In term of Developer Experience, it's a weird behavior, making debugging less easy.
Hasn't this behavior changed with #27519?",False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/comments/524339861,WebTestCase: a 500 error doesn't make the PHPUnit test to fail,xabbuh,7,484553199,7,524339861,0,524338315,2019-08-23T14:37:00Z,@dunglas This definitely has been the way it is even in 2.x.,False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/comments/533810180,WebTestCase: a 500 error doesn't make the PHPUnit test to fail,javiereguiluz,7,484553199,8,533810180,0,524339861,2019-09-21T16:13:54Z,Let's close this because the current behavior is the expected one and most contributors agree with it. Thanks!,False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/33309,"Fix AuthMode cannot be null, replace by login",TheGarious,3,484607720,1,484607720,0,0,2019-08-23T16:13:09Z,"| Q             | A
| ------------- | ---
| Branch?       |  4.3  <!-- see below -->
| Bug fix?      | yes
| New feature?  | no <!-- please update src/**/CHANGELOG.md files -->
| BC breaks?    | no     <!-- see https://symfony.com/bc -->
| Deprecations? | no <!-- please update UPGRADE-*.md and src/**/CHANGELOG.md files -->
| Tests pass?   | yes    <!-- please add some, will be required by reviewers -->
| Fixed tickets | #...   <!-- #-prefixed issue number(s), if any -->
| License       | MIT
| Doc PR        | https://symfony.com/doc/current/components/mailer.html#transport

I created an article for Mailer component, when i add all information with GmailTransport (username and password (or password app)).
I have got this error :
![image](https://user-images.githubusercontent.com/10236869/63606931-831c0880-c5d1-11e9-8579-83808dfc1ebc.png)

I see in GmailTransport, Authmode is null then cannot be null for Gmail.

But it's not an error, i can pr this docs and add more informations for this.",True,0,CONTRIBUTOR
https://api.github.com/repos/symfony/symfony/issues/comments/524529466,"Fix AuthMode cannot be null, replace by login",OskarStark,3,484607720,2,524529466,0,484607720,2019-08-24T07:45:30Z,"IIRC @fabpot removed „auth_mode“ option from the code base in 4.4, though gmail should work out of the box using login internally.

This fix looks ok for 4.3 to me",False,0,CONTRIBUTOR
https://api.github.com/repos/symfony/symfony/issues/comments/524529984,"Fix AuthMode cannot be null, replace by login",fabpot,3,484607720,3,524529984,0,524529466,2019-08-24T07:54:14Z,"`null` means that we automatically negotiate the best auth mode possible via the SMTP protocol.
Here, the error show `bad credentials`. I find it strange that the patch fixes the issue. Do you confirm that you patch fixes your `bad credentials` issue?
",False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/comments/524736438,"Fix AuthMode cannot be null, replace by login",TheGarious,3,484607720,4,524736438,0,524529984,2019-08-26T06:38:51Z,"I close this PR, i don't know why, now it's worked with authmode = null. 

Sorry",False,0,CONTRIBUTOR
https://api.github.com/repos/saltstack/salt/issues/54500,Add in support for reserved_percentage kwarg and correct documentation.,qcpeter,3,494083506,1,494083506,0,0,2019-09-16T14:23:15Z,"### What does this PR do?

### What issues does this PR fix or reference?
https://github.com/saltstack/salt/issues/54426

### Previous Behavior
Misleading documentation.

### New Behavior
Adds in `reserved_percentage` kwarg and updates documentation.

### Tests written?

No

### Commits signed with GPG?

No

Please review [Salt's Contributing Guide](https://docs.saltstack.com/en/latest/topics/development/contributing.html) for best practices.

See GitHub's [page on GPG signing](https://help.github.com/articles/signing-commits-using-gpg/) for more information about signing commits with GPG.
",True,0,NONE
https://api.github.com/repos/saltstack/salt/issues/comments/533002378,Add in support for reserved_percentage kwarg and correct documentation.,qcpeter,3,494083506,2,533002378,0,494083506,2019-09-19T07:20:55Z,I'm afraid I'm going away for ten days so will be unable to take a look at this immediately. Presumably you're thinking of some sort of test that passes in the kwargs and tests the flags that are passed the `cmd.run` mock? The existing tests are pretty minimal.,False,0,NONE
https://api.github.com/repos/saltstack/salt/issues/comments/537080366,Add in support for reserved_percentage kwarg and correct documentation.,waynew,3,494083506,3,537080366,0,533002378,2019-10-01T15:05:35Z,"@qcpeter yeah, that should be sufficient. This doesn't really have a lot of logic, so it shouldn't be too difficult. There may be a test that already exists that could just be extended, but if not, what you described should be 👍 ",False,0,CONTRIBUTOR
https://api.github.com/repos/saltstack/salt/issues/comments/565763139,Add in support for reserved_percentage kwarg and correct documentation.,dwoz,3,494083506,4,565763139,0,537080366,2019-12-14T23:46:51Z,"@qcpeter This needs to be re-opened against the `master` branch. We are no longer
accepting PRs to `2018.3`. You can link back to this PR to preserve the
discussion. Sorry taking so long to get to this and for any confusion.",False,0,CONTRIBUTOR
https://api.github.com/repos/saltstack/salt/issues/54501,"2019.2.0 - test mode crashes with both ""unless:"" and ""retry:"" declarations in a file.managed state",OrlandoArcapix,5,494087595,1,494087595,0,0,2019-09-16T14:29:47Z,"### Description of Issue

When running a file.managed state in test mode, which is configured to download a file over https, salt-call will crash if the state has both a `retry:` and an `unless:` declaration which evaluates to true.

Command line returns:
```Passed invalid arguments: sequence item 0: expected string or Unicode, list found.```

followed by the `Usage:` statement for `salt-call`:
[crash.log](https://github.com/saltstack/salt/files/3616723/crash.log)

### Setup

Create a state `test.sls`:

```
download sample data:
  file.managed:
    - name: /tmp/saltstack.README.rst
    - retry:
        attempts: 5
        interval: 5
    - unless:
      - test -f /tmp/saltstack.README.rst
    - source:
      - https://raw.githubusercontent.com/saltstack/salt/develop/README.rst
    - source_hash: f2bc8c0aa2ae4f5bb5c2051686016b48
```

### Steps to Reproduce Issue

* `touch /tmp/saltstack.README.rst`
* `salt-call state.apply test -l info test=true 2>&1 | tee /tmp/crash.log`


### Versions Report
```
Salt Version:
           Salt: 2019.2.0

Dependency Versions:
           cffi: 1.12.3
       cherrypy: unknown
       dateutil: 2.7.2
      docker-py: 3.5.0
          gitdb: 2.0.5
      gitpython: 2.1.11
          ioflo: Not Installed
         Jinja2: 2.9.6
        libgit2: Not Installed
        libnacl: Not Installed
       M2Crypto: 0.31.0
           Mako: 1.1.0
   msgpack-pure: Not Installed
 msgpack-python: 0.5.6
   mysql-python: 1.2.5
      pycparser: 2.19
       pycrypto: 2.6.1
   pycryptodome: 3.7.3
         pygit2: Not Installed
         Python: 2.7.5 (default, Apr  9 2019, 14:30:50)
   python-gnupg: Not Installed
         PyYAML: 3.11
          PyZMQ: 15.3.0
           RAET: Not Installed
          smmap: 2.0.5
        timelib: Not Installed
        Tornado: 4.2.1
            ZMQ: 4.1.4

System Versions:
           dist: centos 7.6.1810 Core
         locale: UTF-8
        machine: x86_64
        release: 3.10.0-957.12.2.el7.x86_64
         system: Linux
        version: CentOS Linux 7.6.1810 Core
```
",True,0,CONTRIBUTOR
https://api.github.com/repos/saltstack/salt/issues/comments/531803441,"2019.2.0 - test mode crashes with both ""unless:"" and ""retry:"" declarations in a file.managed state",OrlandoArcapix,5,494087595,2,531803441,0,494087595,2019-09-16T14:30:08Z,"Possibly related to https://github.com/saltstack/salt/issues/52800 ?
",False,0,CONTRIBUTOR
https://api.github.com/repos/saltstack/salt/issues/comments/571541360,"2019.2.0 - test mode crashes with both ""unless:"" and ""retry:"" declarations in a file.managed state",stale[bot],5,494087595,3,571541360,0,531803441,2020-01-07T11:05:30Z,"This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

If this issue is closed prematurely, please leave a comment and we will gladly reopen the issue.
",False,0,NONE
https://api.github.com/repos/saltstack/salt/issues/comments/572055216,"2019.2.0 - test mode crashes with both ""unless:"" and ""retry:"" declarations in a file.managed state",stale[bot],5,494087595,4,572055216,0,571541360,2020-01-08T13:37:19Z,"Thank you for updating this issue. It is no longer marked as stale.
",False,0,NONE
https://api.github.com/repos/saltstack/salt/issues/comments/615562056,"2019.2.0 - test mode crashes with both ""unless:"" and ""retry:"" declarations in a file.managed state",mchugh19,5,494087595,5,615562056,0,572055216,2020-04-18T05:03:05Z,This can likely be closed with the merge of #56381,False,0,CONTRIBUTOR
https://api.github.com/repos/saltstack/salt/issues/comments/631113726,"2019.2.0 - test mode crashes with both ""unless:"" and ""retry:"" declarations in a file.managed state",sagetherage,5,494087595,6,631113726,0,615562056,2020-05-19T22:18:38Z,closing as fixed with PR referenced will be released in Sodium,False,0,CONTRIBUTOR
https://api.github.com/repos/saltstack/salt/issues/54502,"salt-ssh generates error deploying custom grain on first run, works on subsequent runs",nergdron,4,494234752,1,494234752,0,0,2019-09-16T19:31:42Z,"### Description of Issue
I've run into a real weird one that I'm not sure what's going on. Basically, any time I add or change one of my custom modules and then run `salt-ssh`, it errors out with the following:

```yaml
   _error:
        Failed to return clean data
    retcode:
        0
    stderr:
        Shared connection to 10.1.15.93 closed.
    stdout:
        ERROR: Failure deploying ext_mods: /usr/bin/scp
        SALT_ARGV: ['/usr/bin/python3', '/var/tmp/.ubuntu_c08594_salt/salt-call', '--retcode-passthrough', '--local', '--metadata', '--out', 'json', '-l', 'quiet', '-c', '/var/tmp/.ubuntu_c08594_salt', '--', 'test.opts_pkg']
[... cut massive debug output with lots of private info ...]
```

however, future runs against the same host work correctly with the custom grain set. so it seems like the deploy of the custom grain did work, error message aside. still, it means I can't trust any salt-ssh run to work correctly the first time.

### Setup
I can trigger this by adding or modifying any custom grain, using salt installed under python3 via pip. Not sure what out of my environment is useful, this seems to be salt code problem, but I guess that's only the case if y'all can reproduce.

in any case, I'm using salt without a server and primarily with `salt-ssh` as a non-root user, so here's the relevant custom configs.

`~/.salt/Saltfile`:
```yaml
salt-call:
  config_dir: /home/tessa/.salt/conf/
salt-ssh:
  config_dir: /home/tessa/.salt/conf/
  # don't clean up temp python files on remote host when done,
  # will make subsequent ops faster.
  ssh_wipe: False
```

`~/.salt/conf/minion`
```yaml
# set a fixed minion id so we can share a top.sls between salt-call and salt-ssh
id: local

ext_pillar:
  - ec2_pillar:
      tag_list_key:
        - salt_states
      tag_list_sep: ','
      use_grain: True

file_client: local
# all of this 
file_roots:
  base:
    - /home/tessa/.salt
    - /home/tessa/.salt/_states
log_level: error
module_dirs:
  - /home/tessa/.salt
pillar_roots:
  base:
    - /home/tessa/.salt/_pillar
root_dir: /tmp/.salt-root


# salt-ssh options end up here
roster: ec2
roster_defaults:
  # put config for remote hosts here!
  minion_opts:
    grains_cache: False
    metadata_server_grains: True
  priv: agent-forwarding
  sudo: True
  tty: True
  user: ubuntu

# only show changes by default
state_output: changes

# any python libs our custom modules depend on must be included here
# or they won't be bundled to the client.
thin_extra_mods: boto,boto3
```

### Versions Report
```yaml
Salt Version:
           Salt: 2019.2.0
 
Dependency Versions:
           cffi: 1.12.3
       cherrypy: Not Installed
       dateutil: 2.7.3
      docker-py: Not Installed
          gitdb: Not Installed
      gitpython: Not Installed
          ioflo: Not Installed
         Jinja2: 2.10.1
        libgit2: Not Installed
        libnacl: Not Installed
       M2Crypto: Not Installed
           Mako: Not Installed
   msgpack-pure: Not Installed
 msgpack-python: 0.6.1
   mysql-python: Not Installed
      pycparser: 2.19
       pycrypto: 2.6.1
   pycryptodome: Not Installed
         pygit2: Not Installed
         Python: 3.7.3 (default, Aug 20 2019, 17:04:43)
   python-gnupg: Not Installed
         PyYAML: 5.1
          PyZMQ: 18.0.2
           RAET: Not Installed
          smmap: Not Installed
        timelib: Not Installed
        Tornado: 4.5.3
            ZMQ: 4.3.1
 
System Versions:
           dist: Ubuntu 19.04 disco
         locale: UTF-8
        machine: x86_64
        release: 5.0.0-25-generic
         system: Linux
        version: Ubuntu 19.04 disco
```",True,0,NONE
https://api.github.com/repos/saltstack/salt/issues/comments/571541356,"salt-ssh generates error deploying custom grain on first run, works on subsequent runs",stale[bot],4,494234752,2,571541356,0,494234752,2020-01-07T11:05:29Z,"This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

If this issue is closed prematurely, please leave a comment and we will gladly reopen the issue.
",False,0,NONE
https://api.github.com/repos/saltstack/salt/issues/comments/572055219,"salt-ssh generates error deploying custom grain on first run, works on subsequent runs",stale[bot],4,494234752,3,572055219,0,571541356,2020-01-08T13:37:20Z,"Thank you for updating this issue. It is no longer marked as stale.
",False,0,NONE
https://api.github.com/repos/saltstack/salt/issues/comments/902262573,"salt-ssh generates error deploying custom grain on first run, works on subsequent runs",nergdron,4,494234752,4,902262573,0,572055219,2021-08-19T21:32:29Z,"to update this issue: with the salt release `3003.1`, using the `regen_thin` option via `-t`, or any of the config files, doesn't appear to make this issue any better. get the error every time on a new change, regardless of whether the thin tarball has been regenerated or not.

@sagetherage any idea on an ETA for a fix? as we use salt in a more widespread manner, this is becoming a larger issue for us.",False,0,NONE
https://api.github.com/repos/saltstack/salt/issues/comments/936966304,"salt-ssh generates error deploying custom grain on first run, works on subsequent runs",nergdron,4,494234752,5,936966304,0,902262573,2021-10-06T19:28:07Z,"an update on this bug, in the current salt releases (3003.3-1), this error still occurs, but it no longer claims that it happens during module distribution. now it always happens in `test.opts_pkg`, but with a huge amount of json output on stdout. I'm not going to paste it all here, since it contains a confidential grains and other info, but it appears as if salt is printing two json chunks to stdout, and this may be causing it to get confused about what has happened. it appears to print all the grains for the host as a single-line json blob, and then the next line starts a multi-line formatted json output for `test.opts_pkg`.

```
something:
    ----------
    _error:
        Failed to return clean data
    retcode:
        0
    stderr:
    stdout:
        {'id': '2e1d7458-9f15-4268-867c-b79d143778bc', 'hostname': 'something' [...] }
        {
            ""local"": {
                ""jid"": ""20211006191838933310"",
                ""return"": {
                   ""interface"": ""0.0.0.0"",```
                   [...]
               }
                ""retcode"": 0,
                ""id"": ""ap1-purple-1"",
                ""fun"": ""test.opts_pkg"",
                ""fun_args"": []
            }
        }
```

so it seems as if the function run for those tests does succeed, but it's the strange output of the grains ahead of that output which is breaking `salt-ssh`.

could really use some help debugging what is causing this and how to fix it, it's causing us a ton of trouble.",False,0,NONE
https://api.github.com/repos/saltstack/salt/issues/54504,Proxy pillar ID targetting,alan-cugler,3,494281787,1,494281787,0,0,2019-09-16T21:17:16Z,"### Issue
I was adding hundreds of proxy minion pillars for a cluster. During which, I realized that the **proxy pillar** format doesn't follow the regular pillar convention of `descriptor-ID: key: value` seen with regular pillars. This is a feature loss seeing as with regular pillars many can be listed in the same pillar sls file.

Instead, the ""descriptor"" is taken from the hard coded target ID in the `/srv/pillar/top.sls` file, with a  proxy pillar file indent underneath. That pillar file contains a single pillar who's highest key is `proxy:`
This convention has the added loss of not being able to use wildcards * in the top file to break down minion targeting into groupings.
```yaml
/srv/pillar/$ ls
net-device1.sls top.sls

/srv/pillar/$ cat top.sls
base:
  'target':
    - net-device1

/srv/pillar/$ cat net-device1.sls
proxy:
  proxytype: networkswitch
  host: 172.23.23.5
  username: root
  passwd: letmein

/srv/pillar/$ salt-proxy --proxyid=target -d 
```
This is unwieldy at scale, if I am adding hundreds of proxy pillars I'd prefer to segregate proxy pillars into files with a grouping convention rather than each proxy pillar getting its own file, and slot in the `top.sls` file.
***
### Solution
Two part:
1) The `salt-proxy --proxyid=[ID]` targeting logic needs to be rewritten to allow the same minion ID targeting in the `/srv/pillar/top.sls` file as it is with `/srv/salt/top.sls` file for salt states.

2) Further the `--proxyid` should look for a proxy pillar indented `key:value` for its *ID,* or take it from the proxy pillar's descriptor-ID above `proxy:` like normal pillars.

```yaml
/srv/pillar/$ ls
top.sls groupABC.sls group123.sls

/srv/pillar/$ cat top.sls
base:
  'switch*':
    - groupABC
  'router*':
    - group123

/srv/pillar/$ cat groupABC.sls
switch1:
  proxy:
    proxytype: networkswitch
    host: 172.23.23.5
    username: root
    passwd: letmein

switch2:
  proxy:
    proxytype: networkswitch
    host: 172.23.23.6
    username: root
    passwd: letmein

proxy:
  id: switch3
  proxytype: networkswitch
  host: 172.23.23.7
  username: root
  passwd: letmein

/srv/pillar/$ salt-proxy --proxyid=switch3 -d 
/srv/pillar/$ salt-proxy --proxyid=switch2 -d 
```
Please note that both proxy pillar structures would be valid for spinning up proxy `switch2` & `switch3` with this change.",True,0,CONTRIBUTOR
https://api.github.com/repos/saltstack/salt/issues/comments/535977223,Proxy pillar ID targetting,jtraub91,3,494281787,2,535977223,0,494281787,2019-09-27T15:02:00Z,Bump. Having proxy minions configured like such may also provide benefit of having a mechanism for defining a list of proxy minions to be spawned at once via some sort of module,False,0,CONTRIBUTOR
https://api.github.com/repos/saltstack/salt/issues/comments/571541350,Proxy pillar ID targetting,stale[bot],3,494281787,3,571541350,0,535977223,2020-01-07T11:05:28Z,"This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

If this issue is closed prematurely, please leave a comment and we will gladly reopen the issue.
",False,0,NONE
https://api.github.com/repos/saltstack/salt/issues/comments/572055229,Proxy pillar ID targetting,stale[bot],3,494281787,4,572055229,0,571541350,2020-01-08T13:37:20Z,"Thank you for updating this issue. It is no longer marked as stale.
",False,0,NONE
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/3019,Add Magic module,DomAmato,6,501260939,1,501260939,0,0,2019-10-02T03:57:54Z,Magic is a new authentication protocol built around the blockchain. This module is the minimal requirement to authenticate via a local or hosted gateway.,True,0,NONE
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/537325052,Add Magic module,arr2036,6,501260939,2,537325052,0,501260939,2019-10-02T04:01:16Z,What's the advantage in talking over a raw TCP socket instead of just calling out to a REST API?,False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/537730364,Add Magic module,arr2036,6,501260939,3,537730364,0,537325052,2019-10-03T00:05:23Z,"So the major issues I can see:
- This module doesn't use the connection pool API, so you're creating and destroying connections every time a user logs in, which is incredibly inefficient.
- With zero technical documents being published by magic.co, we can't determine if this will be a useful module, and worth the effort to include it in the server core and maintain it.

My recommendation would be to implement this module in Perl or python and distribute it directly from magic.co as part of the alpha package.  If the protocol gets fleshed out beyond submitting small JSON blobs over a raw TCP connection, and ends up being something you couldn't have just implemented easier with a REST API (and existing rlm_rest module) then we'd definitely reconsider.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/537748192,Add Magic module,DomAmato,6,501260939,4,537748192,0,537730364,2019-10-03T01:29:32Z,"I'll shed a bit more light on some of the reasoning it was made into a module instead of using an interpreted language. 

One of the goals was to get our authentication mechanism working on openWRT which the packages for python and perl are not compiled for and take up a ton of space that the routers usually cannot afford to have installed without a swap file and extra storage space added. We had a module written in python but because of the aforementioned reasons and the fact that it doesn't look like freeradius 3 will ever support python 3 we decided not to go down that path.

This is very much an alpha thing and ideally we don't want to add more maintenance on your end but also maintaining our own fork isn't ideal for us either. 

There will be updates and maybe at that time we will submit another PR with more features fleshed out but before we publish more information we have been working with the SEC regarding the legality so obviously things are slow while we finish that work first.

I will take a look at the rlm_rest module in the meantime but can you shed light on why this module needs to use the connection_pool api when so many others don't? I am not opposed to using it but it seems like if that is a bar set for this module that it should be more consistently enforced on other modules that already exist in the code base.",False,0,NONE
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/537755830,Add Magic module,alandekok,6,501260939,5,537755830,0,537748192,2019-10-03T02:12:52Z,"Most modules which do outbound connections use the connection API:

```
$ git grep -l fr_connection_get src/modules/
src/modules/rlm_cache/drivers/rlm_cache_memcached/rlm_cache_memcached.c
src/modules/rlm_couchbase/mod.c
src/modules/rlm_couchbase/rlm_couchbase.c
src/modules/rlm_krb5/rlm_krb5.c
src/modules/rlm_ldap/ldap.c
src/modules/rlm_mschap/auth_wbclient.c
src/modules/rlm_redis/rlm_redis.c
src/modules/rlm_rediswho/rlm_rediswho.c
src/modules/rlm_rest/rlm_rest.c
src/modules/rlm_smsotp/rlm_smsotp.c
src/modules/rlm_sql/rlm_sql.c
src/modules/rlm_sqlhpwippool/rlm_sqlhpwippool.c
src/modules/rlm_sqlippool/rlm_sqlippool.c
src/modules/rlm_yubikey/validate.c
```

There main reason is that opening connections can be expensive, especially for databases.  There may be not just database communication overhead, but also TLS.

The connection API allows a connection to be opened once, and then re-used many times for different requests.  In our experience, this re-use substantially increases the throughput of the server, and also lowers latency.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/537756000,Add Magic module,arr2036,6,501260939,6,537756000,0,537755830,2019-10-03T02:13:47Z,"> I'll shed a bit more light on some of the reasoning it was made into a module instead of using an interpreted language.
> 
> One of the goals was to get our authentication mechanism working on openWRT which the packages for python and perl are not compiled for and take up a ton of space that the routers usually cannot afford to have installed without a swap file and extra storage space added. We had a module written in python but because of the aforementioned reasons and the fact that it doesn't look like freeradius 3 will ever support python 3 we decided not to go down that path.

OK, in that case if you're targeting a specific platform then there's nothing to stop you from building your own packages and making them available.  Your code does not need to be in the main source tree in order for you to do this.

> This is very much an alpha thing and ideally we don't want to add more maintenance on your end but also maintaining our own fork isn't ideal for us either.

You don't have to.  You'd be maintaining only your specific module.

> There will be updates and maybe at that time we will submit another PR with more features fleshed out but before we publish more information we have been working with the SEC regarding the legality so obviously things are slow while we finish that work first.
> 
> I will take a look at the rlm_rest module in the meantime but can you shed light on why this module needs to use the connection_pool api when so many others don't? 

AFAIK every module that ships with FreeRADIUS that manages handles representing connections to an external database, either uses the connection API to manage those connections, has a thread local connection, or has a connection pool managed by another library.

Taking a quick scan through v3.x clients of the connection pool API are rlm_cache, rlm_couchbase, rlm_ippool, rlm_krb5, rlm_ldap, rlm_mschap, rlm_redis, rlm_smsotp, rlm_rest, rlm_sql*, rlm_yubikey.

rlm_unbound uses libunbound which manages its own connections. rlm_securid uses the securid library of connection management.  rlm_opendirectory uses Apple's OpenDirectory framework.

> I am not opposed to using it but it seems like if that is a bar set for this module that it should be more consistently enforced on other modules that already exist in the code base.

That statement is based on a false premise.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/538008808,Add Magic module,DomAmato,6,501260939,7,538008808,0,537756000,2019-10-03T15:58:49Z,I think we as a team need to do a review of the networking architecture for magic and then come back to this. This module was a MVP we needed to prove the technology as viable but given your feedback I think there are some conversations we will have internally about how to move forward. Thanks for all the suggestions and feedback on this module!,False,0,NONE
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/3022,Add tests for radmin/control-socket,jpereira,3,501598458,1,501598458,0,0,2019-10-02T16:32:07Z,New unit tests to validate the radmin commands.,True,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/537575646,Add tests for radmin/control-socket,jpereira,3,501598458,2,537575646,0,501598458,2019-10-02T16:33:33Z,"Sample.

```
[jpereira@sugarloaf freeradius-server.git]$ make clean.test.radmin
[jpereira@sugarloaf freeradius-server.git]$ make test.radmin
RADMIN src/tests/radmin/config/test.conf
Starting RADMIN test server... Executing: /bin/sh -c build/bin/local/radiusd -Pxxxl build/tests/radmin/radius.log -d src/tests/radmin/config -n test -D /Volumes/Users/jpereira/Devel/FreeRADIUS/freeradius-server.git/share/dictionary/
RADMIN-TEST 00-help
RADMIN-TEST 01-show-client-all-proto
RADMIN-TEST 02-show-client-tcp-proto
RADMIN-TEST 03-show-client-udp-proto
RADMIN-TEST 04-show-config-item1
gmake[1]: Entering directory '/Volumes/Users/jpereira/Devel/FreeRADIUS/freeradius-server.git'
gmake[1]: Leaving directory '/Volumes/Users/jpereira/Devel/FreeRADIUS/freeradius-server.git'
[jpereira@sugarloaf freeradius-server.git]$
```",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/537738839,Add tests for radmin/control-socket,arr2036,3,501598458,3,537738839,0,537575646,2019-10-03T00:43:57Z,Be nice to move the all.mk contents to its own file. ,False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/537741358,Add tests for radmin/control-socket,alandekok,3,501598458,4,537741358,0,537738839,2019-10-03T00:57:02Z,"The tests seem good, but there's a lot of new boilerplate makefile rules which are different from everything else in the server.  Is it not possible to use a similar layout to `src/tests/unit/all.mk` or `src/tests/keywords/all.mk` ?

Those files use a common layout, names, and comments for the test rules.  That makes the tests pretty simple to understand.

the final rule to run each test ends up last in the `all.mk` file.  It has the most complexity, but ends up being 10-30 lines of shell scripting.

If we need a separate set of rules to start / stop the server, they could go in a separate makefile.  There's already `src/tests/Makefile` which is a little specific to running the auth tests.  But it could be leveraged for the radmin tests. too.

i.e. there's no need to duplicate all of that code in the radmin tests.  Instead, split the start / stop / kill rules into a separate makefile, and then include that file from multiple places.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/3037,Move eap test to boiler.mk scheme,jpereira,11,504864121,1,504864121,0,0,2019-10-09T20:04:08Z,"Pretty simple, less code and reuse the same mechanism
to start/stop the radiusd service.",True,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/540208306,Move eap test to boiler.mk scheme,arr2036,11,504864121,2,540208306,0,504864121,2019-10-09T21:28:31Z,"If this is merged whilst the EAP tests are non-functional, i'm going to forcefully expunge it from the commit tree",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/540210536,Move eap test to boiler.mk scheme,jpereira,11,504864121,3,540210536,0,540208306,2019-10-09T21:34:09Z,"@arr2036 the `test.eap` is currently disabled as can be seen in https://github.com/FreeRADIUS/freeradius-server/commit/fc015119d90d35b913dbbdc65a05ff5038497e5c and btw, that changes keep the same behavior.

e.g:

1. Removing the broken tests.

```
[jpereira@sugarloaf freeradius-server.git]$ ../bypass-eapol.sh
########## By pass the eapol_test broken tests removing...
src/tests/eapol_test/peap-client-mschapv2.conf
src/tests/eapol_test/peap-eap-gtc.conf
src/tests/eapol_test/peap-mschapv2.conf
src/tests/eapol_test/ttls-chap.conf
src/tests/eapol_test/ttls-client-eap-mschapv2.conf
src/tests/eapol_test/ttls-client-eap-tls.conf
src/tests/eapol_test/ttls-eap-gtc.conf
src/tests/eapol_test/ttls-eap-mschapv2.conf
src/tests/eapol_test/ttls-mschapv2.conf
src/tests/eapol_test/ttls-pap.conf
[jpereira@sugarloaf freeradius-server.git]$
```

2. Running the test.

```
[jpereira@sugarloaf freeradius-server.git]$ make clean.test.eap test.eap
Clean up build/tests/eapol_test/radiusd.pid
rsa/server.pem: OK
ecc/server.pem: OK
rsa/ocsp.pem: OK
ecc/ocsp.pem: OK
Starting RADIUSD test server for (target=test.eap,port=12340,config_dir=src/tests/eapol_test/config,config_name=servers)
Executing: /bin/sh -c build/bin/local/radiusd -Pxxxl build/tests/eapol_test/radiusd.log -d src/tests/eapol_test/config -n servers -D share/dictionary/
ok
EAPOL_TEST aka-prime
EAPOL_TEST aka
EAPOL_TEST gtc
EAPOL_TEST md5
EAPOL_TEST mschapv2
EAPOL_TEST pwd
EAPOL_TEST sim
EAPOL_TEST tls
gmake[1]: Entering directory '/Volumes/Users/jpereira/Devel/FreeRADIUS/freeradius-server.git'
Clean up build/tests/eapol_test/radiusd.pid
gmake[1]: Leaving directory '/Volumes/Users/jpereira/Devel/FreeRADIUS/freeradius-server.git'
[jpereira@sugarloaf freeradius-server.git]$
```",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/540212646,Move eap test to boiler.mk scheme,arr2036,11,504864121,4,540212646,0,540210536,2019-10-09T21:39:58Z,"In addition to using the unified framework this PR needs to:
- Re-enable the EAP tests for Travis.
- Disable EAP virtual servers and modules that are there to support EAP methods which are disabled when we don't have OpenSSL.
- Disable EAP-TTLS and EAP-PEAP tests",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/540220903,Move eap test to boiler.mk scheme,arr2036,11,504864121,5,540220903,0,540212646,2019-10-09T22:00:33Z,"and @jpereira in future, when you're touching areas of the code or tests which are already failing in travis, at a bare minimum there needs to be discussion in the freeradius-devel channel, as it can make issues significantly harder to solve.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/540861604,Move eap test to boiler.mk scheme,jpereira,11,504864121,6,540861604,0,540220903,2019-10-11T01:27:22Z,"@arr2036 @alandekok I added the capability to handle `IGNORED_LIST`

e.g:

```
[root@dev01 freeradius-server.git]# make clean.test.eap test.eap
Clean up build/tests/eapol_test/radiusd.pid
make[1]: Entering directory '/root/FreeRADIUS/freeradius-server.git/raddb/certs'
rsa/server.pem: OK
ecc/server.pem: OK
rsa/ocsp.pem: OK
ecc/ocsp.pem: OK
make[1]: Leaving directory '/root/FreeRADIUS/freeradius-server.git/raddb/certs'
EAPOL_TEST peap (Skipping, reenable by removing <peap> from 'IGNORED_EAP_TYPES' in src/tests/eapol_test/all.mk)
EAPOL_TEST ttls (Skipping, reenable by removing <ttls> from 'IGNORED_EAP_TYPES' in src/tests/eapol_test/all.mk)
EAPOL_TEST aka_prime (Skipping, reenable by removing <aka_prime> from 'IGNORED_EAP_TYPES' in src/tests/eapol_test/all.mk)
EAPOL_TEST aka (Skipping, reenable by removing <aka> from 'IGNORED_EAP_TYPES' in src/tests/eapol_test/all.mk)
Starting RADIUSD test server for (target=test.eap,port=12340,config_dir=src/tests/eapol_test/config,config_name=servers)
Executing: /bin/sh -c build/bin/local/radiusd -Pxxx -d src/tests/eapol_test/config -n servers -D share/dictionary/ -l build/tests/eapol_test/radiusd.log
ok
EAPOL_TEST gtc
EAPOL_TEST sim
EAPOL_TEST tls
EAPOL_TEST mschapv2
EAPOL_TEST pwd
EAPOL_TEST md5
make[1]: Entering directory '/root/FreeRADIUS/freeradius-server.git'
Clean up build/tests/eapol_test/radiusd.pid
make[1]: Leaving directory '/root/FreeRADIUS/freeradius-server.git'
[root@dev01 freeradius-server.git]#
```",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/540878240,Move eap test to boiler.mk scheme,arr2036,11,504864121,7,540878240,0,540861604,2019-10-11T02:52:37Z,"Great. Thanks!

Eap-aka prime and sim should be enabled thougb.

-Arran

",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/541004913,Move eap test to boiler.mk scheme,jpereira,11,504864121,8,541004913,0,540878240,2019-10-11T10:12:17Z,@arr2036 done.,False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/541139912,Move eap test to boiler.mk scheme,arr2036,11,504864121,9,541139912,0,541004913,2019-10-11T16:47:47Z,"@alandekok this wasn't ready for merging, as evidenced by the build failures. @jpereira hasn't done the mods-available and sites-available dependency checks to make it work with the non-openssl build",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/541142366,Move eap test to boiler.mk scheme,alandekok,11,504864121,10,541142366,0,541139912,2019-10-11T16:54:54Z,"  I’ll take a look at that. IIRC those checks were missing before this PR was submitted. 

> On Oct 11, 2019, at 12:47 PM, Arran Cudbard-Bell <notifications@github.com> wrote:
> 
> @alandekok this wasn't ready for merging, as evidenced by the build failures. @jpereira hasn't don't the mods-available and sites-available dependency checks to make it work with the non-openssl build
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/541142603,Move eap test to boiler.mk scheme,arr2036,11,504864121,11,541142603,0,541142366,2019-10-11T16:55:32Z,"> In addition to using the unified framework this PR needs to:
> Re-enable the EAP tests for Travis.
> Disable EAP virtual servers and modules that are there to support EAP methods which are disabled when we don't have OpenSSL.
> Disable EAP-TTLS and EAP-PEAP tests",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/541142812,Move eap test to boiler.mk scheme,arr2036,11,504864121,12,541142812,0,541142603,2019-10-11T16:56:08Z,"I'm aware, which is why i *EXPLICITLY* included them in the list of conditions for merging this PR",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/3045,Example coa-relay site,terryburton,4,506230131,1,506230131,0,0,2019-10-12T19:49:48Z,I'll work this up into a v4 patch once it lands.,True,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/541723790,Example coa-relay site,alandekok,4,506230131,2,541723790,0,506230131,2019-10-14T14:48:41Z,Can you just squash all of the commits together?  I'll pull it in then.,False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/541905538,Example coa-relay site,terryburton,4,506230131,3,541905538,0,541723790,2019-10-14T20:34:01Z,"> Can you just squash all of the commits together? I'll pull it in then.

Done. Thanks.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/541999272,Example coa-relay site,arr2036,4,506230131,4,541999272,0,541905538,2019-10-15T01:47:15Z,What’s the rationale for the custom attributes?,False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/542152452,Example coa-relay site,terryburton,4,506230131,5,542152452,0,541999272,2019-10-15T10:44:31Z,"> What’s the rationale for the custom attributes?

If you put the data into pre-existing attributes, which includes Packet-Type={CoA-Request,Disconnect-Request}, then the detail reader processes the request through the recv-coa section (rather than accounting) which does not act on the coa list.

Since you need to indicate the intended packet type through another attribute it seemed to make sense to keep the remaining looked-up attributes separate from the provided attributes, and apply them when generating the CoA.",False,0,MEMBER
https://api.github.com/repos/composer/windows-setup/issues/104,Install fail,rmd1710714107,4,507670901,1,507670901,0,0,2019-10-13T10:04:15Z,"When I install in WIN10,it sugggests following errors. What should  I do to solve this problem.

The Composer installer script was not successful [exit code 1].

Script Output:
The ""https://getcomposer.org/versions"" file could not be downloaded: SSL: 远程主机强迫关闭了一个现有的连接。
send of 24 bytes failed with errno=10054 远程主机强迫关闭了一个现有的连接。
send of 23 bytes failed with errno=10054 远程主机强迫关闭了一个现有的连接。
send of 72 bytes failed with errno=10054 远程主机强迫关闭了一个现有的连接。
send of 2 bytes failed with errno=10054 远程主机强迫关闭了一个现有的连接。
failed to open stream: HTTP request failed!",True,0,NONE
https://api.github.com/repos/composer/windows-setup/issues/comments/542734275,Install fail,johnstevenson,4,507670901,2,542734275,0,507670901,2019-10-16T14:39:12Z,"@Martin730913 Please provide  log file, as per the new issue instructions:
https://github.com/composer/windows-setup/issues/new",False,0,MEMBER
https://api.github.com/repos/composer/windows-setup/issues/comments/542956482,Install fail,rmd1710714107,4,507670901,3,542956482,0,542734275,2019-10-17T01:26:18Z,"> @Martin730913 Please provide log file, as per the new issue instructions:
> https://github.com/composer/windows-setup/issues/new
This is the log file
[Setup Log 2019-10-13 #001.txt](https://github.com/composer/windows-setup/files/3737019/Setup.Log.2019-10-13.001.txt)

",False,0,NONE
https://api.github.com/repos/composer/windows-setup/issues/comments/543126750,Install fail,johnstevenson,4,507670901,4,543126750,0,542956482,2019-10-17T11:16:08Z,"Thanks for the log. You are using an old version of PHP (5.4.45) that does not support modern TLS protocols for https transport. PHP version 5.5.0 and upwards are fine.

If you are really stuck with using a 5.4 version, then you need to:

- disable the open_ssl extension in your php.ini
- ignore Composer-Setup.exe's request to update your php.ini

When composer is installed, you then need to configure it to run without TLS:

```
composer config -g disable-tls true
```

This is really not recommended. 
",False,0,MEMBER
https://api.github.com/repos/composer/windows-setup/issues/comments/545744985,Install fail,rmd1710714107,4,507670901,5,545744985,0,543126750,2019-10-24T05:00:05Z,"> Thanks for the log. You are using an old version of PHP (5.4.45) that does not support modern TLS protocols for https transport. PHP version 5.5.0 and upwards are fine.
> 
> If you are really stuck with using a 5.4 version, then you need to:
> 
> * disable the open_ssl extension in your php.ini
> * ignore Composer-Setup.exe's request to update your php.ini
> 
> When composer is installed, you then need to configure it to run without TLS:
> 
> ```
> composer config -g disable-tls true
> ```
> 
> This is really not recommended.

Thank you!",False,0,NONE
https://api.github.com/repos/composer/composer/issues/8381,Question: How to semver patch a patch? e.g. use a specific tag,josephdpurcell,7,509439044,1,509439044,0,0,2019-10-19T11:47:07Z,"## Problem / Motivation

This issues is to help everyone understand what to do when you need to ""patch a patch,"" i.e. insert a tag between two PATCH versions.

Imagine you have a project that has the following versions as tags in the repository:

* `1.0.59` - Includes Features A and B
* `1.0.60` - Includes Features A, B, C, D, E, and F

The `1.0.59` version is deployed to production. The `1.0.60` version is not schedule to go to production for another 5 days and you need a hotfix deployed today. You can't release `1.0.60` because there are features that haven't been QA'd yet, some of them may have bugs. We need to move more quickly.

**How do I tag a release in such a way that composer will accept it and it complies with [semver](https://semver.org/)?**

## Options to Consider

It sounds like there are a few paths that could be taken in theory, let's make the assumption they all require *telling* anyone using the `1.0.59` version to use a specific other version, i.e. no one can just do a composer update to pull in the hotfix in the scenario outlined above. Also, we'll assume you can't simply re-create the tags.

### Option 1: Claim it's a release management issue.

You could argue that the issue is with the release management process or correct use of version numbers. If `1.0.59` and `1.0.60` are releases of features, why  didn't the *MINOR* version increase? Why are you not tagging a release candidate or pre-release version instead of an actual patch since QA hasn't been completed? This is a long term solution, it doesn't solve the immediate problem of needing to patch a patch.

### Option 2: Use a 4 digit version. [violates Semver]

Semver supports only 3 digits, `X.y.z`, but composer supports 4 digits. This is a viable option as long as you have nothing preventing you from creating a 4 digit version and you're OK with violating semver. For example, use `1.0.59.1` as the hotfix version.

### Option 3: Use composer patches.

Release a patch file to the `1.0.59` version. Have everyone using the `1.0.59` version  to add this patch to their composer.json file using [composer patches](https://github.com/cweagans/composer-patches).

### Option 4: Composer to support specifying a tag name. [theoretical]

Composer supports pinning to a specific commit hash or a branch name. It does not support pinning to a tag name. This scenario would require composer changing to support specifying a specific tag name. Perhaps this could be achieved by composer mapping an arbitrary tag to a commit hash and pinning against that commit hash. In turn, this would allow support for semver build metadata, e.g. `1.0.59+hotfix`.

### Option 5: Use a branch instead of a tag.

Create a branch off `1.0.59` like so:

```
git checkout -b  hotfix/foo 1.0.59
```

Add changes to this branch. Have everyone using the `1.0.59` version to use the `hotfix/foo` branch with `composer require vendor/package:dev-hotfix/foo`. Never delete the branch.

### Option 6: Use a pre-release tag. [violates Semver]

Use a tag like `1.0.59-patch1`. While this does work with composer it violates Semver, which states that a tag with a hyphen `-` is a pre-release and has ""a lower precedence than the associated normal version."" So, `1.0.59-patch1` should come *before* `1.0.59` in your version history, which would not be the case here.

### Option 7: Reference the commit of a build tag. [requires disclaimer]

While composer doesn't support referencing a tag name such as a build tag (i.e. a tag that has build information), you can reference the commit hash a tag points to. This solution would involve creating a branch from the tag:

```
git checkout -b  hotfix/foo 1.0.59
```

Add changes to this branch. Tag the branch with `1.0.59+patch1`. Have everyone using the `1.0.59` version to use the `1.0.59+patch1` tag by referencing the commit the tag points to like so: `composer require vendor/package:dev-master#d3f9f1b`. You can now delete the `hotfix/foo` branch, but you must keep the `master` branch.

Please read the [disclaimer](https://getcomposer.org/doc/articles/troubleshooting.md#i-have-locked-a-dependency-to-a-specific-commit-but-get-unexpected-results-) if using this. The composer.json metadata will be read from the `master` branch, so for example if a additional dependency gets added to the `master` composer.json anyone using the `1.0.59+patch1` will also read that additional dependency.

## Proposed Resolution

The long term resolution would be `Option 1: Claim it's a release management issue`.

In the short term, these options are all viable:

* Option 2: Use a 4 digit version. [violates Semver]
* Option 3: Use composer patches.
* Option 5: Use a branch instead of a tag.
* Option 6: Use a pre-release tag. [violates Semver]
* Option 7: Reference the commit of a build tag. [requires disclaimer]

Composer has made it clear that `Option 4: Composer to support specifying a tag name` is not going to happen.

### Commentary / Opinion

Option 1 is clearly the ""right"" answer, but given what I've seen in my research there is a need for a short term solution. Here's my opinion about those:

Option 3 requires too much effort and coordination compared to the alternatives. I would throw this out. Option 4 is a non starter. So, we are left with 2, 5, 6, and 7.

Options 2 and 6 are the best fit if you do not need to comply with Semver. Option 2 is logical: the 4th digit is a sequence of changes to the 3rd digit. Option 6 at least is formatted like Semver but those familiar with Semver might be confused why a pre-release happened after a release.

Options 5 and 7 are the best fit for complying with Semver and also have composer support. Option 5 has the downside of needing to keep a branch. Option 7 has the serious downside of the [disclaimer](https://getcomposer.org/doc/articles/troubleshooting.md#i-have-locked-a-dependency-to-a-specific-commit-but-get-unexpected-results-) that composer will read the metdata from the specified branch.

**Which option is the best choice is contextual. If I had to pick one, I would go with `Option 2: Use a 4 digit version`. While it violates Semver it has the least risk, least effort, and least confusion.**

## Related Information

* [Support letters in version strings #4330](https://github.com/composer/composer/issues/4330) - Makes the point `Build metadata SHOULD be ignored when determining version precedence.` from semver docs, and that build metadata shouldn't be *silently* ignored.
* [Refactoring #13](https://github.com/composer/semver/pull/13#discussion-diff-36172250) - Point that build metadata should be ignored
* [Validate schema name, type and version #8262 ](https://github.com/composer/composer/pull/8262) - Discussion about how 4 digit version numbers are allowed
* [SemverTest.php#L100](https://github.com/composer/semver/blob/master/tests/SemverTest.php#L100) - Shows there are tests for build meta, but no tests for 4 digit version numbers
* [VersionParserTest.php#L56](https://github.com/composer/semver/blob/master/tests/VersionParserTest.php#L56) - Shows normalized versions are parsed to 4 digit versions
* [Allow arbitrary tag names #8071](https://github.com/composer/composer/issues/8071#issuecomment-480192641) - Talks about composer supporting arbitrary patch names, but how determining priority would be unpredictable
* [Possible to reference branch#tag in github? #6206](https://github.com/composer/composer/issues/6206) - You cannot reference a specific tag; and the fact you can reference a specific commit hash is a legacy hack, see [this issue](https://getcomposer.org/doc/articles/troubleshooting.md#i-have-locked-a-dependency-to-a-specific-commit-but-get-unexpected-results-)
* [Handling hotfix versions #241](https://github.com/semver/semver/issues/241) - Discussion about using version suffixes to handle the ""patch to a patch"" case
* [Supporting multiple versions and backporting fixes that introduce features or break things #532](https://github.com/semver/semver/issues/532) - A conversation about the difficulties of managing multiple versions you need to patch while complying with semver.
* [Discussion: pre-release versioning and PEP440 cross-compatibility #483](https://github.com/semver/semver/issues/483) - A discussion comparing semver with PEP440 which brings up some interesting challenges with versioning to consider",True,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/544141764,Question: How to semver patch a patch? e.g. use a specific tag,phansys,7,509439044,2,544141764,0,509439044,2019-10-19T13:05:47Z,"How introducing features C, D, E, and F in a *PATCH* version is intended to be compatible with the semantic versioning spec?",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/544185889,Question: How to semver patch a patch? e.g. use a specific tag,josephdpurcell,7,509439044,3,544185889,0,544141764,2019-10-19T18:38:46Z,"I am interested in what the PHP/composer/semver community thinks about which option is most reasonable.

@phansys your comment sounds like a vote for ""Option 1: Claim it's a release management issue."" For the sake of argument though, what if these are all fixes instead of features? i.e. `1.0.59` is a PATCH and `1.0.60` is a PATCH, but there is a need for a patch to `1.0.59` that needs released *before* `1.0.60`? Option 1 may still be valid, but doesn't offer a short term solution. Say we're in this situation, how would you solve it?",False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/544191263,Question: How to semver patch a patch? e.g. use a specific tag,josephdpurcell,7,509439044,4,544191263,0,544185889,2019-10-19T19:42:23Z,Edited description to clarify Option 1 is long term with no short term solution. Added 2 more reference materials.,False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/545900321,Question: How to semver patch a patch? e.g. use a specific tag,Seldaek,7,509439044,5,545900321,0,544191263,2019-10-24T12:44:45Z,"Strictly per semver you would have to release 1.0.60 and then your upcoming 1.0.60 would be pushed to 1.0.61.

With Composer though you may use 1.0.60.1 which is supported, or 1.0.59-patch1 which is also supported. Using build metadata (`1.0.59+patch1`) IMO is not a good idea as this should resolve to the same version as 1.0.59 and thus users won't necessarily update to it.
",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/545945414,Question: How to semver patch a patch? e.g. use a specific tag,josephdpurcell,7,509439044,6,545945414,0,545900321,2019-10-24T14:29:54Z,"Thanks for the input, @Seldaek!

I apparently did not properly test using a pre-release. This does work! I'm updating the description to show this as Option 6: Use a pre-release tag. This violates Semver since anything `X.y.z-*` precedes `X.y.z`, but it does work.

I'll also clarify the assumption that it is not possible to re-tag; that certainly would be a fine option if its available.",False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/545947959,Question: How to semver patch a patch? e.g. use a specific tag,Seldaek,7,509439044,7,545947959,0,545945414,2019-10-24T14:34:53Z,"It is possible to retag but it is generally speaking poor practice as people having updated before the retag can't easily be sure they are on the right tag, and it can cause other issues with git. ",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/546044186,Question: How to semver patch a patch? e.g. use a specific tag,josephdpurcell,7,509439044,8,546044186,0,545947959,2019-10-24T18:27:05Z,"I've added `Option 7: Reference the commit of a build tag. [requires disclaimer]`.

Also, I updated the ""Proposed Resolution"" section with some opinions.

What I've concluded is: Which option is the best choice is contextual. If I had to pick one, I would go with `Option 2: Use a 4 digit version`. While it violates Semver it has the least risk, least effort, and least confusion.",False,0,NONE
https://api.github.com/repos/composer/composer/issues/8383,Probably dead code in src/Composer/DependencyResolver/Decisions.php,Drupal-Infrastructure,3,509528709,1,509528709,0,0,2019-10-20T00:58:57Z,"I was running the debugger trying to sort out why a packagist.org package is being favored over a path repository, and I accidentally made a dumb assignment on a breakpoint inspection, which triggered this code:

https://github.com/composer/composer/blob/fdcae616b0bdf57b1460491badb4501906a83044/src/Composer/DependencyResolver/Decisions.php#L185-L191

Now, Im going to assume that whole code block is unnecessary, because 

1. `literalToString` is an undefined function. 
2. Its been there for 7 years.  
3. Nobody has reported it or noticed it.


",True,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/544210110,Probably dead code in src/Composer/DependencyResolver/Decisions.php,ryanaslett,3,509528709,2,544210110,0,509528709,2019-10-20T01:01:21Z,Oops. Meant to open this as myself.,False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/544886976,Probably dead code in src/Composer/DependencyResolver/Decisions.php,alcohol,3,509528709,3,544886976,0,544210110,2019-10-22T09:52:41Z,@naderman is this a remnant of some debug stuff you use from time to time?,False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/545912279,Probably dead code in src/Composer/DependencyResolver/Decisions.php,naderman,3,509528709,4,545912279,0,544886976,2019-10-24T13:15:28Z,"@alcohol indeed this is just a piece of debug code which triggers if one makes changes in the wrong place, I guess much like what @ryanaslett did as well ;-) If this actually happened to a user there'd be a bug in the solver, so it makes sense this doesn't usually happen. So I guess the function was never updated, but I'd prefer to keep this section there to catch any potential bugs in this code. The function is simply called ""literalToPrettyString"" today. It takes an installedmap as an additional argument, but if this isn't available in Decisions you can just pass an empty array and the function will work fine.",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/8389,Updating a package provided by a path repository can delete the source,greg-1-anderson,10,512687570,1,512687570,0,0,2019-10-25T19:42:47Z,"## Problem Statement:

When a package is provided by a path repository, and the Composer Installers plugin is used to install the same package to its source location, then the source directory can be deleted by Composer.

Usually, Composer will detect that the path repository is being installed to its source location and do the right thing (new feature in Composer 1.9.0). The behavior is problematic, though, if the path repository no longer matches the version constraints stipulated in the composer.json file.

In the case of Drupal, drupal/core is provided as a path repository to the ""core"" directory. It is also subtree-split out to Packagist, so that sites that are *running* Drupal install drupal/core in a conventional way (i.e. from Packagist) -- the path repository is only used when doing core development. This is an interim situation (lasting years prbly) moving us towards actual native Composer use (e.g. perhaps restructuring like Symfony, with all ""replace"" directives in the root -- but we can't do that yet).

The problem arises if a core developer decides to update a dependency in the core/composer.json file, and then makes a mistake updating the composer.lock file and vendor directory.

## Steps to reproduce (n.b. output truncated for readability):

```
$ git clone https://git.drupalcode.org/project/drupal.git --branch=8.8.x
$ cd drupal
$ composer install
$ composer --working-dir=core require twig/twig:^2 --no-update
$ composer update drupal/core
Loading composer repositories with package information
Updating dependencies (including require-dev)
Package operations: 0 installs, 1 update, 0 removals
  - Removing drupal/core (8.8.x-dev), source is still present in core
  - Installing drupal/core (8.8.x-dev 8117454): Loading from cache
```

In the example above, `composer update drupal/core` could not be upgraded, because twig/twig is still locked to ^1. If the user had instead run `composer update drupal/core twig/twig` or `composer update drupal/core --with-dependencies`, it would have worked.

## Expected behavior:

Composer should give an error, ""your project could not be updated"".

## Actual behavior:

Composer notices that drupal/core can not be updated, but it finds an older version of drupal/core in Packagist that is still installable. It therefore ""uninstalls"" the current path repository and overwrites the source location with the older copy installed from Packagist.",True,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/546690439,Updating a package provided by a path repository can delete the source,greg-1-anderson,10,512687570,2,546690439,0,512687570,2019-10-27T12:35:08Z,"I tried changing the warning to an error in `PathDownloader::remove` (throw an exception instead of printing a message); however, this was not effective, as Composer will innocuously remove and re-add path repositories during normal operation of `composer update` where this problem is not evidenced.

I have also [tried some workarounds in Drupal to detect and prevent this error](https://www.drupal.org/project/drupal/issues/3088935); however, it seems difficult to detect all of the scenarios where this error might occur, and Composer scripts do not have ready access to the whitelist in any event.

It seems that the best fix would be in Composer somewhere in the 'install' step.",False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/547306905,Updating a package provided by a path repository can delete the source,alcohol,10,512687570,3,547306905,0,546690439,2019-10-29T08:19:59Z,Can you confirm this happens with `--no-plugins` ?,False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/547310129,Updating a package provided by a path repository can delete the source,alcohol,10,512687570,4,547310129,0,547306905,2019-10-29T08:29:29Z,"I'm confused about what the issue is here though. Composer does not actually delete the source. So I find the issue title quite misleading. Then there is a wall of text describing a workflow, which from what I can gather, mostly just works.",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/547310617,Updating a package provided by a path repository can delete the source,alcohol,10,512687570,5,547310617,0,547310129,2019-10-29T08:30:51Z,"> It therefore ""uninstalls"" the current path repository and overwrites the source location with the older copy installed from Packagist.

No, it simply removes the symlink in `vendor/` (pointing to `./core`), and installs the older version inside your `vendor/` directory.",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/548171518,Updating a package provided by a path repository can delete the source,greg-1-anderson,10,512687570,6,548171518,0,547310617,2019-10-31T00:49:26Z,"@alcohol You are correct that the source directory will not be deleted if `--no-plugins` is used. The source is only deleted if Composer Installers is used to install a path repository to its source location.

Even in instances when the source is not deleted, this behavior is undesirable, because the information in the composer.lock file changes when a project is converted from being installed from its path repository to being installed from Packagist. For projects that commit the composer.lock file, this is something for users to get wrong if their pull request accidentally downgrades a path repository.

I will build a minimal reproducible case that demonstrates the downgrading behavior with `--no-plugins` / without the Composer Installers plugin, and will rewrite the issue summary to match.",False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/548258068,Updating a package provided by a path repository can delete the source,alcohol,10,512687570,7,548258068,0,548171518,2019-10-31T08:09:56Z,"> I will build a minimal reproducible case that demonstrates the downgrading behavior with --no-plugins / without the Composer Installers plugin, and will rewrite the issue summary to match.

That would greatly help in explaining the exact use-case or problem, and whether or not this is a snowflake or an issue that hits our entire userbase.",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/566661017,Updating a package provided by a path repository can delete the source,cs278,10,512687570,8,566661017,0,548258068,2019-12-17T17:18:14Z,"I've just been bitten by this (or something similar) in a Symfony project using `1.9.0`. Unfortunately I have not been able to reproduce the problem after a bunch of experimenting, with and without `--no-plugins`.

In my case the symlink was maintained but the directory referenced was cleaned out.

I'll have another go at recreating this once I've recovered my lost work. :cry: 

```
Loading composer repositories with package information
Updating dependencies (including require-dev)
Restricting packages listed in ""symfony/symfony"" to ""~4.4.0""
Package operations: 0 installs, 1 update, 0 removals
  - Removing some/package (0.11.x-dev), source is still present in /.../vendor/some/package
  - Installing some/package (0.11.x-dev): Source already present
Package phpstan/phpstan-shim is abandoned, you should avoid using it. Use phpstan/phpstan instead.
Writing lock file
Generating autoload files
ocramius/package-versions: Generating version class...
ocramius/package-versions: ...done generating version class

What about running composer global require symfony/thanks && composer thanks now?
This will spread some 💖  by sending a ★  to the GitHub repositories of your fellow package maintainers.

Executing script cache:clear [OK]
Executing script assets:install public [OK]
```",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/633114903,Updating a package provided by a path repository can delete the source,doekenorg,10,512687570,9,633114903,0,566661017,2020-05-23T18:42:31Z,"> I've just been bitten by this (or something similar) in a Symfony project using `1.9.0`. Unfortunately I have not been able to reproduce the problem after a bunch of experimenting, with and without `--no-plugins`.
> 
> In my case the symlink was maintained but the directory referenced was cleaned out.
> 
> I'll have another go at recreating this once I've recovered my lost work. 😢
> 
> ```
> Loading composer repositories with package information
> Updating dependencies (including require-dev)
> Restricting packages listed in ""symfony/symfony"" to ""~4.4.0""
> Package operations: 0 installs, 1 update, 0 removals
>   - Removing some/package (0.11.x-dev), source is still present in /.../vendor/some/package
>   - Installing some/package (0.11.x-dev): Source already present
> Package phpstan/phpstan-shim is abandoned, you should avoid using it. Use phpstan/phpstan instead.
> Writing lock file
> Generating autoload files
> ocramius/package-versions: Generating version class...
> ocramius/package-versions: ...done generating version class
> 
> What about running composer global require symfony/thanks && composer thanks now?
> This will spread some 💖  by sending a ★  to the GitHub repositories of your fellow package maintainers.
> 
> Executing script cache:clear [OK]
> Executing script assets:install public [OK]
> ```

Had the same thing happen to me today. Fortunately I used PHPStorm and was able to retrieve everything from `Local History`. But otherwise I would have lost weeks of work, because the branch I was working on was not on my remote. 

Seems like when you have a local repository setup, composer will ""remove"" the folder, but the symlink stays intact. It will then download whatever version it can find, and install it in that (symlinked) folder. Removing EVERYTHING inside, including the original `.git`.

I've learned my lesson, but I was baffled by this behavior.",False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/1134699281,Updating a package provided by a path repository can delete the source,Seldaek,10,512687570,10,1134699281,0,633114903,2022-05-23T13:44:44Z,Not sure what to do here. If this is still an issue it'd be great to get an updated idiot-proof repro script.,False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1134886341,Updating a package provided by a path repository can delete the source,doekenorg,10,512687570,11,1134886341,0,1134699281,2022-05-23T16:25:54Z,I haven't had this happen in two years now. Probably a fluke in the filesystem or something. For my sake you can close this issue.,False,0,NONE
https://api.github.com/repos/mrdoob/three.js/issues/17868,(Re-)added AnimationAction import to Three.js,RazorDE,13,517388807,1,517388807,0,0,2019-11-04T20:40:37Z,"The AnimationAction-module is listed in the TypeScript-definition file of Three.js, but actually missing in Three.js itself. As I actually would expect it be imported there I (re-)added it.",True,0,CONTRIBUTOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/549650929,(Re-)added AnimationAction import to Three.js,mrdoob,13,517388807,2,549650929,0,517388807,2019-11-05T03:46:20Z,Is `AnimationAction` supposed to be public? I have not used the animation part of the API much yet...,False,0,OWNER
https://api.github.com/repos/mrdoob/three.js/issues/comments/549662811,(Re-)added AnimationAction import to Three.js,RazorDE,13,517388807,3,549662811,0,549650929,2019-11-05T04:56:55Z,"There are several reasons why this should be public in my opinion:

1. It's referenced in the Animation-section of the documentation which creates the impression of being public (https://threejs.org/docs/index.html#api/en/animation/AnimationAction).
2. It's referenced as a public module in AnimationAction.d.ts (if this merge will be rejected this reference should be removed from the TypeScript definition to avoid faulty imports).
3. When creating an instance of AnimationAction you gain more control on the AnimationClip. For example, if you want to preserve the last frame for a specific animation when it's done playing you can use the `clampWhenFinished` property like this:
```
[...]
const action = new AnimationAction(mixer, clip)
action.clampWhenFinished = true
[...]
```
This is a useful feature which I'm actually using in my project.",False,0,CONTRIBUTOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/549689575,(Re-)added AnimationAction import to Three.js,donmccurdy,13,517388807,4,549689575,0,549662811,2019-11-05T06:59:08Z,"The AnimationAction _constructor_ can be thought of as private; I don't know of any reason to create one directly, as you can use `action = mixer.clipAction( clip )` instead. From the docs:

> Instead of calling this constructor directly you should instantiate an AnimationAction with AnimationMixer.clipAction since this method provides caching for better performance.

But each instance has public properties and methods, like `.play()`, and those certainly are part of the public API. For that reason, `AnimationAction.d.ts` is important.

> (if this merge will be rejected this reference should be removed from the TypeScript definition to avoid faulty imports)

@RazorDE Could you explain what you mean here? That IDEs using TypeScript would let you import the AnimationAction class because the typings are there, but that the code would fail to compile?",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/549997122,(Re-)added AnimationAction import to Three.js,RazorDE,13,517388807,5,549997122,0,549689575,2019-11-05T20:06:58Z,"@donmccurdy For some reason I didn't notice that `clipAction` returns an AnimationAction. Thanks for explaining this.

That was one reason why I created one directly. The other was that `Three.d.ts` includes the reference to AnimationAction such that it's possible to do this when using TypeScript which leads to an error:
`import { AnimationAction } from 'three'`

I've created another pull request for this issue (https://github.com/mrdoob/three.js/pull/17877) and close this one.",False,0,CONTRIBUTOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/576952316,(Re-)added AnimationAction import to Three.js,elalish,13,517388807,6,576952316,0,549997122,2020-01-22T00:31:50Z,"@donmccurdy I agree with your concern, but it seems this got merged anyway in #17877. @RazorDE That change broke my project as now I don't have access to all the public APIs documented here: https://threejs.org/docs/index.html#api/en/animation/AnimationAction",False,0,CONTRIBUTOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/577013573,(Re-)added AnimationAction import to Three.js,donmccurdy,13,517388807,7,577013573,0,576952316,2020-01-22T05:24:41Z,"Hm I missed that... https://github.com/mrdoob/three.js/pull/17877 should be reverted, then, but I understand how the previous state would confuse TS users. Should the constructor just be marked private in the typings? Or is there a better TypeScript-friendly way to expose the type information without giving the impression that it can be instantiated?",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/577463891,(Re-)added AnimationAction import to Three.js,cdata,13,517388807,8,577463891,0,577013573,2020-01-23T01:27:55Z,"Even if the constructor is private for practical purposes, the instance is still exposed via public API, so it is appropriate to export the TypeScript type.

When a TypeScript user invokes `clipAction`, `tsc` will complain about the return type being ""private"" unless you export the type.

I would go so far as to argue that even if the constructor is not intended to be directly invoked by users, it is helpful to export it in JavaScript because it allows users to perform `instanceof` checks. They can access the constructor indirectly anyway (via `instance.constructor`), so you aren't truly hiding it by not exporting it.

Just my two cents, I hope it is helpful.
",False,0,CONTRIBUTOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/577478713,(Re-)added AnimationAction import to Three.js,donmccurdy,13,517388807,9,577478713,0,577463891,2020-01-23T02:38:38Z,"Referring to the current JS API for the moment (and ignoring that `instance.constructor` exists)... the JS API exposes the instance, but not the constructor. Is there a TypeScript equivalent of exactly that? I certainly agree we should export the AnimationAction type, but what's the right way to indicate to TS users that the constructor isn't available? Adjust the typings to make the constructor private, while exporting the class typings?

```typescript
export class AnimationAction {

	private constructor( mixer: AnimationMixer, clip: AnimationClip, localRoot?: Object3D );

        // ...

}
```",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/577520980,(Re-)added AnimationAction import to Three.js,cdata,13,517388807,10,577520980,0,577478713,2020-01-23T06:10:18Z,"The likely TypeScript equivalent is something close to what you already had.

In TypeScript land you quickly get into trouble if you try to use a type that isn't formally exported from a module. I whipped up a small example to demonstrate the problem:


```typescript
// foo.ts
class InternalClass {}

export const createInternalClass = () => new InternalClass();
```

```typescript
// bar.ts
import {createInternalClass} from './foo.js';

const internalInstance = createInternalClass();

// You can get the type with `typeof`, but...
type InternalClassType = typeof internalInstance;

export class Bar {
    // ...it causes an error if it is re-exported:
    constructor(public inst: InternalClassType) {}
}
```

This trivial example will yield the somewhat unclear error:

```
bar.ts:4:7 - error TS4023: Exported variable 'internalInstance' has or is using name 'InternalClass' from external module "".../foo"" but cannot be named
```

One way you might work around this is to define an interface that can be formally exported, and specify that the function returns an object with that interface type (rather than the internal-only class type). The advantage of this is that you can be explicit about the shape of the returned object without exporting its constructor.

For example, if I change `foo.ts` to the following:

```typescript
class InternalClass {
  baz: boolean = true;
}

// Formally exported interface:
export interface InternalClassInterface {
  baz: boolean;
}

export const createInternalClass =
    (): InternalClassInterface => new InternalClass();
```

The error disappears. As a consumer of `foo.ts`, I cannot directly import the `InternalClass` constructor, but TypeScript still knows the return type of `createInternalClass` and doesn't complain if I re-export it somehow.

For your reference, the declaration file that gets generated for `foo.ts` in the above example looks like this:

```typescript
// foo.d.ts
export interface InternalClassInterface {
    baz: boolean;
}
export declare const createInternalClass: () => InternalClassInterface;
```

So, based on my reading of the issue, what you were doing before (exporting the type in the declaration file, but not in the actual JS module) is pretty close to what TypeScript would actually lead you to do.",False,0,CONTRIBUTOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/577741544,(Re-)added AnimationAction import to Three.js,donmccurdy,13,517388807,11,577741544,0,577520980,2020-01-23T15:50:22Z,"I understand we need to export the type. Can we also mark the constructor as private or protected? I don't understand why separate internal/external classes would be needed, as [protected constructors do seem to be a thing](https://visualstudiomagazine.com/articles/2016/12/01/defining-classes.aspx).

If someone would like to open a PR reverting https://github.com/mrdoob/three.js/pull/17877 and is able to test it, ideally protecting the constructor as well, please do. :)",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/577747178,(Re-)added AnimationAction import to Three.js,cdata,13,517388807,12,577747178,0,577741544,2020-01-23T16:02:31Z,"@donmccurdy yes, you can do that, but it means the declaration file will imply the class is exported from the JS module when it isn't. This will work fine, but will lead to confusion (for an example of such confusion, see this very issue).",False,0,CONTRIBUTOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/577949029,(Re-)added AnimationAction import to Three.js,donmccurdy,13,517388807,13,577949029,0,577747178,2020-01-24T01:02:36Z,"@mrdoob would you be OK with exporting `AnimationAction` from the JS package, not just the type definitions? Making the type information available without that seems to be difficult.",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/577962929,(Re-)added AnimationAction import to Three.js,mrdoob,13,517388807,14,577962929,0,577949029,2020-01-24T02:11:13Z,@donmccurdy Sounds good. We can look for alternatives if that causes issues.,False,0,OWNER
https://api.github.com/repos/mrdoob/three.js/issues/17872,Examples: Add raycast support for LineSegments2,gkjohnson,4,517496715,1,517496715,0,0,2019-11-05T01:26:44Z,"This PR adds pixel-perfect raycast functionality to the LineSegments2 class and updates the `webgl_lines_fat` example to demonstrate the capability (and to test) with a red dot on hover.

The intersection point result includes both `point` Vector3 and a `pointOnLine` Vector3. `point` is the line that lies on the ray being cast while `pointOnLine` is the closest point on the line segment itself.

[Live Example Link](http://raw.githack.com/gkjohnson/three.js/linesegments2-raycast/examples/webgl_lines_fat.html)

Here's a gif showing the raycast behavior. The red dot represents the resultant `point` value while the green shows the `pointOnLine` value:

![line-raycast](https://user-images.githubusercontent.com/734200/68170803-04730e00-ff26-11e9-8987-83202bc6980d.gif)

A few open questions I'd like some input on if anyone has any thoughts:

- Should `Raycaster.linePrecision` be used here? It's not exactly clear how it should be used considering this value is in world units for THREE.Line, which doesn't make sense with these screen space lines.
- Should the return value of `point` be the point on the line [as it with THREE.Line](https://github.com/mrdoob/three.js/blob/dev/src/objects/Line.js#L156-L158)? It makes most sense to me to return the point along the ray being cast but this is an inconsistency at the moment. Maybe it makes more sense to use a point on the ray here because the lines actually have thickness that notionally defines a surface.

And this is maybe a separate discussion but as you can see in the example the raycast result when using `THREE.Line` is not smooth -- the point jumps from line segment to line segment as you move the mouse around. I'm not sure if this is already known but it's leading me to believe that the THREE.Line raycast function isn't correct?

@WestLangley

Fixes #15006",True,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/551959153,Examples: Add raycast support for LineSegments2,gkjohnson,4,517496715,2,551959153,0,517496715,2019-11-08T19:27:21Z,"Regarding the questions I listed I think the current behavior of this PR is reasonable and we can update the raycast code in the future to respect the `linePrecision` field and or include the relevant resolution on the raycaster object.

@mrdoob I know there has been some discussion about limiting the number of example pages in the repo -- would you prefer that a new fat lines raycasting example be created or include that code in the current fat lines example (as it is here)?",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/566287714,Examples: Add raycast support for LineSegments2,gkjohnson,4,517496715,3,566287714,0,551959153,2019-12-16T23:04:01Z,@WestLangley I've gone ahead removed the example changes in this PR so it now just adds raycasting to `Line2`. I think we can look into adding a standalone raycast example for fat lines in another PR.,False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/566294359,Examples: Add raycast support for LineSegments2,WestLangley,4,517496715,4,566294359,0,566287714,2019-12-16T23:22:48Z,">I think we can look into adding a standalone raycast example for fat lines in another PR.

My preference is to keep the examples focused, so I definitely agree with that.",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/566783556,Examples: Add raycast support for LineSegments2,mrdoob,4,517496715,5,566783556,0,566294359,2019-12-17T22:46:21Z,Thanks!,False,0,OWNER
https://api.github.com/repos/mrdoob/three.js/issues/17873,Feature request : toFixed() for vectors value,felixmariotto,19,517522813,1,517522813,0,0,2019-11-05T03:07:58Z,"##### Feature request

It would be nice to add a parameter to `Vector3.round()` and `Vector3.roundToZero()`, to ask for a number of decimal like `Number.toFixed()` in JS. If undefined, it would assume that an integer is needed, so it would not break anything.

##### Use case

I had to do my own function to do that, because the objects in my scene are user-transformed, then the transforms are exported as JSON. There is a big tolerance, so in order to reduce file size, I round the vector3 values. But rounding to integer is too much, that's why I did my own function.
I guess that it would also be useful in things like voxel-painter or Minecraft-likes.

I thought it might not be a big deal to add it to three.js, and it's useful, hence my feature request. If you think it's useless code, please close the issue.
",True,0,CONTRIBUTOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/549818912,Feature request : toFixed() for vectors value,Mugen87,19,517522813,2,549818912,0,517522813,2019-11-05T13:18:28Z,"We should not use `Number.toFixed()` since it returns a string. It seems that number-to-string conversion just for rounding is no good approach. 

https://stackoverflow.com/questions/2283566/how-can-i-round-a-number-in-javascript-tofixed-returns-a-string#comment47147413_14978830

Can you please test if this would work for you:

```js
THREE.Vector3.prototype.round = function( digits ) {

    var e = Math.pow( 10, digits || 0 );

    this.x = Math.round( this.x * e ) / e;
    this.y = Math.round( this.y * e ) / e;
    this.z = Math.round( this.z * e ) / e;
        
    return this;

}
```
Live example (check browser console): https://glitch.com/~meowing-bougon

However, I don't think this logic makes sense for `Vector3.roundToZero()`.",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/549842241,Feature request : toFixed() for vectors value,felixmariotto,19,517522813,3,549842241,0,549818912,2019-11-05T14:18:26Z,"I tested your proposal for `Vector3.round(),` it's perfect.

Why does it make no sense for `Vector3.roundToZero()` ?

With your modified `round()` : 

```javascript
var v = new THREE.Vector3( -1.38943, 3.48843, -0.7685353535 );

console.log( v.round(2) );
// Vector3 {x: -1.39, y: 3.49, z: -0.77}
```

With a hypothetical modified `roundToZero()` : 

```javascript
var v = new THREE.Vector3( -1.38943, 3.48843, -0.7685353535 );

console.log( v.roundToZero(2) );
// Vector3 {x: -1.38, y: 3.48, z: -0.76}
```",False,0,CONTRIBUTOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/549862642,Feature request : toFixed() for vectors value,Mugen87,19,517522813,4,549862642,0,549842241,2019-11-05T15:04:40Z,"> Why does it make no sense for Vector3.roundToZero() ?

Sry, I've misunderstood the semantics of this method (I've never used it before). Since it internally works with `Math.ceil()` and `Math.floor()`, I'm not sure how to develop this accordingly. Open for suggestions here...",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/550017551,Feature request : toFixed() for vectors value,Mugen87,19,517522813,5,550017551,0,549862642,2019-11-05T20:59:54Z,"BTW: If `Vector3.round()` and `Vector3.roundToZero()` are enhanced, it's also necessary to do this for `Vector2` and `Vector4` for consistency reasons.",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/550137238,Feature request : toFixed() for vectors value,felixmariotto,19,517522813,6,550137238,0,550017551,2019-11-06T04:24:16Z,"
What about this ? 

```javascript
THREE.Vector3.prototype.roundToZero = function( digits ) {

    var e = Math.pow( 10, digits || 0 );

    this.x = ( ( this.x * e ) < 0 ) ? Math.ceil( ( this.x * e ) ) / e : Math.floor( ( this.x * e ) ) / e ;
    this.y = ( ( this.y * e ) < 0 ) ? Math.ceil( ( this.y * e ) ) / e : Math.floor( ( this.y * e ) ) / e ;
    this.z = ( ( this.z * e ) < 0 ) ? Math.ceil( ( this.z * e ) ) / e : Math.floor( ( this.z * e ) ) / e ;

    return this;

};


var v = new THREE.Vector3( -1.38943, 3.48843, -0.7685353535 );

console.log( v.roundToZero(2) );
// Vector3 {x: -1.38, y: 3.48, z: -0.76}
```",False,0,CONTRIBUTOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/550241739,Feature request : toFixed() for vectors value,Mugen87,19,517522813,7,550241739,0,550137238,2019-11-06T10:13:35Z,"Um, why is `( ( this.x * e ) < 0 )` necessary? I thought this statement is only relevant to detect negative numbers.",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/550294447,Feature request : toFixed() for vectors value,felixmariotto,19,517522813,8,550294447,0,550241739,2019-11-06T12:47:57Z,"You are right, it's not necessary, this is better : 

```javascript
THREE.Vector3.prototype.roundToZero = function( digits ) {

    var e = Math.pow( 10, digits || 0 );

    this.x = this.x < 0 ? Math.ceil( this.x * e ) / e : Math.floor( this.x * e ) / e ;
    this.y = this.y < 0 ? Math.ceil( this.y * e ) / e : Math.floor( this.y * e ) / e ;
    this.z = this.z < 0 ? Math.ceil( this.z * e ) / e : Math.floor( this.z * e ) / e ;

    return this;

};
```",False,0,CONTRIBUTOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/550298038,Feature request : toFixed() for vectors value,Mugen87,19,517522813,9,550298038,0,550294447,2019-11-06T12:58:41Z,"Well, if @mrdoob approves I think it's okay to enhance `round()` and `roundToZero()` like presented here. 

A PR should change `Vector2`, `Vector3` and `Vector4`, the docs, TS files and the unit tests. `Vector2.tests.js` already has some [rounding tests](https://github.com/mrdoob/three.js/blob/dev/test/unit/src/math/Vector2.tests.js#L566-L587) but I think it's better to remove them and implement the [methods](https://github.com/mrdoob/three.js/blob/aea0b4bc96a340cc0bc420971efe71ed5194062b/test/unit/src/math/Vector2.tests.js#L274-L284) instead.",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/550360220,Feature request : toFixed() for vectors value,sciecode,19,517522813,10,550360220,0,550298038,2019-11-06T15:25:52Z,"Careful, these functions might not have the expected behavior when the input precision digits are bigger than the original precision.

https://glitch.com/~hallowed-city (check console)",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/550363598,Feature request : toFixed() for vectors value,Mugen87,19,517522813,11,550363598,0,550360220,2019-11-06T15:33:03Z,"@sciecode Can you please explain in more detail? After a quick glance, it's not obvious to me what's going wrong.",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/550364774,Feature request : toFixed() for vectors value,sciecode,19,517522813,12,550364774,0,550363598,2019-11-06T15:35:34Z,"In some cases it may lead to floating point imprecision. For example:

`-1.38` rounded to 4-digits goes to `-1.3799`, instead of the expected `-1.38`.

![image](https://user-images.githubusercontent.com/3927951/68312487-e3c7c700-0091-11ea-9711-684e6ff46456.png)

**edit:** I think this only happens on the `roundToZero` method, and I'm unsure about what specifically causes this.",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/551021411,Feature request : toFixed() for vectors value,Mugen87,19,517522813,13,551021411,0,550364774,2019-11-07T10:34:19Z,"The semantics of  `Number.toFixed()` and `Vector3.toFixed()` would be different since the native function returns a string. Hence, it's confusing to reuse the same name.

I think enhancing the methods is okay. If we can solve the issue @sciecode mentioned.",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/551425018,Feature request : toFixed() for vectors value,felixmariotto,19,517522813,14,551425018,0,551021411,2019-11-08T07:57:49Z,"
I know this is not very elegant, but it fixes the issue with `roundToZero`, and it's still better than converting to string : 

```javascript
THREE.Vector3.prototype.roundToZero = function( digits ) {

	var e = Math.pow( 10, digits || 0 );

        // return number of decimal places of a
	function precision( v ) {

		var e = 1, p = 0 ;

		while ( Math.round( v * e ) / e !== v ) {
			e *= 10 ;
			p ++ ;
		};

		return p ;
	};

	function roundToZero( v, e ) {

		var vDigits = precision( v );

		e = vDigits < digits ? Math.pow( 10, vDigits || 0 ) : e ;

		return v < 0 ? Math.ceil( v * e ) / e : Math.floor( v * e ) / e ;

	};

	this.x = roundToZero( this.x, e );
	this.y = roundToZero( this.y, e );
	this.z = roundToZero( this.z, e );

	return this;

};
```",False,0,CONTRIBUTOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/551616627,Feature request : toFixed() for vectors value,Mugen87,19,517522813,15,551616627,0,551425018,2019-11-08T11:23:25Z,"That looks indeed a bit strange. Especially since creating `precision()` and `roundToZero()` each invocation of `Vector3.roundToZero()` is no good practice. It would be better to define these functions once in module scope.

@felixmariotto Anyway, would it be okay for you to just enhance `Vector*.round()` for now? I don't think we are going to enhance `Vector*.roundToZero()` if we need to introduce this complexity.

",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/551643572,Feature request : toFixed() for vectors value,felixmariotto,19,517522813,16,551643572,0,551616627,2019-11-08T11:42:19Z,"@Mugen87 It's totally fine for me, my use case was with `round`, it just seemed right to consider enhancing `roundToZero` as well. But I agree that it shouldn't introduce too much completexity.",False,0,CONTRIBUTOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/551673107,Feature request : toFixed() for vectors value,Mugen87,19,517522813,17,551673107,0,551643572,2019-11-08T12:03:19Z,Feel free to file a PR then 😊.,False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/552506083,Feature request : toFixed() for vectors value,WestLangley,19,517522813,18,552506083,0,551673107,2019-11-11T16:07:13Z,">the objects in my scene are user-transformed, then the transforms are exported as JSON. There is a big tolerance, so in order to reduce file size, I round the vector3 values.

It doesn't make sense to ""round"" a number in binary to a certain number of decimal digits in base-10.

You can format the number when represented as a string, however.

Also, the term ""round"" is used to round to integers only.

>If you think it's useless code, please close the issue.

If you are happy with the results you are getting, it is fine for your app -- just not three.js.
",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/552704488,Feature request : toFixed() for vectors value,felixmariotto,19,517522813,19,552704488,0,552506083,2019-11-12T02:23:00Z,"`You can format the number when represented as a string, however.`

You mean clamping to a given number of decimal character ? This is not like rounding, since 1.19 clamped to one decimal would give 1.1, whereas rounding gives 1.2.

`It doesn't make sense to ""round"" a number in binary to a certain number of decimal digits in base-10.`

If it's a matter of semantic, maybe you could elaborate on a alternative ?",False,0,CONTRIBUTOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/569412172,Feature request : toFixed() for vectors value,Mugen87,19,517522813,20,569412172,0,552704488,2019-12-28T12:18:47Z,see https://github.com/mrdoob/three.js/pull/17908#issuecomment-569412157,False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/17874,Feature Request: Clear Coat tint and thickness,raMaa026,5,517636820,1,517636820,0,0,2019-11-05T09:04:17Z,"Hello,

The Clear coat shader is a great addition to three.js and big thanks whoever worked on it.
While exploring SketchFab settings, I have noticed that they have thickness and tint added as well, which ads more to the visual impact overall.

It would be a great help if these features could be implemented in three.js.

Thank you very much

",True,0,NONE
https://api.github.com/repos/mrdoob/three.js/issues/comments/549911095,Feature Request: Clear Coat tint and thickness,donmccurdy,5,517636820,2,549911095,0,517636820,2019-11-05T16:55:44Z,"Related: The proposed glTF clearcoat extension (draft) is here: [KHR_materials_clearcoat](https://github.com/KhronosGroup/glTF/pull/1677). This is based on [Autodesk Standard Surface](https://github.com/Autodesk/standard-surface) and [Dassault Systemes Enterprise PBR](https://github.com/DassaultSystemes-Technology/EnterprisePBRShadingModel).

That proposal does not include the features suggested here (coat thickness and tint). But it does include a few things not yet in three.js: `clearcoatMap` and `clearcoatRoughnessMap`.",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/549926845,Feature Request: Clear Coat tint and thickness,raMaa026,5,517636820,3,549926845,0,549911095,2019-11-05T17:29:28Z,"Would you be able to tell me if these two features are available for 1.0 version.

Thank you",False,0,NONE
https://api.github.com/repos/mrdoob/three.js/issues/comments/549954267,Feature Request: Clear Coat tint and thickness,donmccurdy,5,517636820,4,549954267,0,549926845,2019-11-05T18:25:17Z,"I'm not sure what you mean by ""1.0 version""... glTF, or three.js?

In either case – there are no plans to add clearcoat thickness or tint in either one right now. If you are using glTF and would like to see these supported, I would recommend commenting on https://github.com/KhronosGroup/glTF/pull/1677 and sharing examples and use cases if you can do so.",False,0,COLLABORATOR
https://api.github.com/repos/mrdoob/three.js/issues/comments/551181430,Feature Request: Clear Coat tint and thickness,raMaa026,5,517636820,5,551181430,0,549954267,2019-11-07T17:27:51Z,Thank you. I will try to do what you have suggested.,False,0,NONE
https://api.github.com/repos/mrdoob/three.js/issues/comments/555023615,Feature Request: Clear Coat tint and thickness,Mugen87,5,517636820,6,555023615,0,551181430,2019-11-18T13:51:54Z,Closing for now. I'm adding #16977 here since it is the leading issue for enterprise PBR improvements. I recommend to proceed the discussion there.,False,0,COLLABORATOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/1205,Doom 1.2 demo support,SmileTheory,5,506373137,1,506373137,0,0,2019-10-13T19:53:14Z,"So @fabiangreffrath asked me to make a pull request here for this patch (previously https://github.com/fabiangreffrath/crispy-doom/pull/478 ), so here it is.

I noticed some easy changes I could grab from Prboom-plus, so I did, and made a patch.

I've tested the three demos in Doom 1.2 shareware and they seem to work. I've also tried recording a quick demo in crispy-doom with the Doom 1.2 shareware wad and it played ok in the original exe under dosbox.

Also included are a few minor changes that get the Doom 0.99 shareware WAD running without immediately crashing, though the demos desynch within seconds and there's an invisible nightmare difficulty setting.",True,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/543833828,Doom 1.2 demo support,fragglet,5,506373137,2,543833828,0,506373137,2019-10-18T16:53:09Z,"Bit outside of the scope of this pull request but I wonder: are there demos in the Compet-N repository recorded with v1.2 that we can use to test this? I have an automated build that runs every Friday building the latest version of Chocolate Doom and running through the entire Compet-N archive, so it would be neat to expand the test coverage.

https://github.com/chocolate-doom/statcheck",False,0,MEMBER
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/543848862,Doom 1.2 demo support,fragglet,5,506373137,3,543848862,0,543833828,2019-10-18T17:27:13Z,"Ah never mind - it turns out that Doom v1.2 doesn't have the `-statcopy` command line argument, so it won't be possible to use statcheck.",False,0,MEMBER
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/544138824,Doom 1.2 demo support,fabiangreffrath,5,506373137,4,544138824,0,543848862,2019-10-19T12:31:03Z,"> I have an automated build that runs every Friday building the latest version of Chocolate Doom and running through the entire Compet-N archive

I know I have asked this before and I don't want to be a nuisance, but could you probably extend this to cover Crispy Doom as well, please?

Are the results reported anywhere publicly? ",False,0,MEMBER
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/546421059,Doom 1.2 demo support,fragglet,5,506373137,5,546421059,0,544138824,2019-10-25T16:26:11Z,"Could do, yes. The machine I use is quite slow so it takes the best part of a day to run through the whole set of demos. An email gets sent to the dev list if some demo failures occur.

I'd probably have to set up the Crispy run to run on a different day.",False,0,MEMBER
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/546731611,Doom 1.2 demo support,fabiangreffrath,5,506373137,6,546731611,0,546421059,2019-10-27T20:33:53Z,"> I'd probably have to set up the Crispy run to run on a different day.

That would be absolutely great! It would be even fine for me if the cron job an only once per month or something like this.",False,0,MEMBER
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/1207,Doom v0.99 demo support.,SmileTheory,27,509442570,1,509442570,0,0,2019-10-19T12:18:57Z,"This one is like https://github.com/chocolate-doom/chocolate-doom/pull/1205 , but for v0.99.

Note that v1.1 demos very much don't work.

Yet.",True,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/544204644,Doom v0.99 demo support.,SmileTheory,27,509442570,2,544204644,0,509442570,2019-10-19T23:09:25Z,"A decompiler (http://derevenets.com/ ), a hex editor, a memory dump from dosbox, and a whole lot of reading and comparing code. :)",False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/544236289,Doom v0.99 demo support.,SmileTheory,27,509442570,3,544236289,0,544204644,2019-10-20T09:36:32Z,"Without the 900 denominator they're the exact values, pulled straight out of my memory dump from dosbox, no floats involved.

If you used them directly, they'd be encoded inaccurately when recording a demo.  The original 1.0/1.1 divided movement values by 900 when writing a demo and multiplied by 900 when reading them.

To be honest I haven't actually tested recording demos, though.",False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/544404995,Doom v0.99 demo support.,SmileTheory,27,509442570,4,544404995,0,544236289,2019-10-21T08:23:27Z,"Bleh, I managed to record a v1.0 video that plays out differently in the original exe and in chocolate doom.

Attached, also still trying to figure out why that imp at the end moves differently.


[1.zip](https://github.com/chocolate-doom/chocolate-doom/files/3749710/1.zip)
",False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/544446657,Doom v0.99 demo support.,SmileTheory,27,509442570,5,544446657,0,544404995,2019-10-21T10:10:05Z,https://github.com/chocolate-doom/chocolate-doom/pull/1207/commits/fa7bcca820f8519eaa288c1262d0a0dd9fcf31d7 appears to fix the demo.,False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/547820055,Doom v0.99 demo support.,SmileTheory,27,509442570,6,547820055,0,544446657,2019-10-30T09:49:58Z,"As an aside, I figured out how the various trig tables are calculated for Doom v1.0 and versions after, and put code for them into https://gist.github.com/SmileTheory/02e6a13bc615efa3b6c31decc0ea049a .",False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/549313395,Doom v0.99 demo support.,drfrag666,27,509442570,7,549313395,0,547820055,2019-11-04T11:27:06Z,"""In versions of Doom 1.2 and earlier, armor percentage was not limited to 200.""
https://doomwiki.org/wiki/Armor_percentage_rollover",False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/549379143,Doom v0.99 demo support.,SmileTheory,27,509442570,8,549379143,0,549313395,2019-11-04T14:29:42Z,"> 
> 
> ""In versions of Doom 1.2 and earlier, armor percentage was not limited to 200.""
> https://doomwiki.org/wiki/Armor_percentage_rollover

This was in the old pull request:

https://github.com/chocolate-doom/chocolate-doom/pull/1205/commits/9eae89d3eb668df2ea218f3944d12996e3364000#diff-79f9cf84b40c123971d3775511e0a3e3R385

If that's too hard to read, here's a comment:

https://github.com/chocolate-doom/chocolate-doom/pull/1207/commits/0e72254209cf7dc21f16ec245d0bcf9a58533aec#diff-79f9cf84b40c123971d3775511e0a3e3R385",False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/549411031,Doom v0.99 demo support.,drfrag666,27,509442570,9,549411031,0,549379143,2019-11-04T15:38:38Z, Someone commented it at doomworld and i was not aware it was already in.,False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/550596554,Doom v0.99 demo support.,SmileTheory,27,509442570,10,550596554,0,549411031,2019-11-07T02:49:21Z,"I had the idea of making a struct with all the various constants and flags enabling old version behavior, but the existence of such would imply that they can be turned on and off at will, and doing that outside of emulating specific versions isn't something I wish to enable.",False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/557890137,Doom v0.99 demo support.,drfrag666,27,509442570,11,557890137,0,550596554,2019-11-24T13:47:48Z,Are 1.1 demos supported already?,False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/558048318,Doom v0.99 demo support.,SmileTheory,27,509442570,12,558048318,0,557890137,2019-11-25T08:36:18Z,"> Are 1.1 demos supported already?

The demos in the Doom 1.1 shareware wad work, but beyond that I haven't tested too much.",False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/558647525,Doom v0.99 demo support.,SmileTheory,27,509442570,13,558647525,0,558048318,2019-11-26T14:14:25Z,"> > >
> > > Are 1.1 demos supported already?
> >
> > The demos in the Doom 1.1 shareware wad work, but beyond that I haven't tested too much.
>
> Only in Shareware? They don't work in the registered/full version?

In 1.1 registered, DEMO1 and DEMO2 work, but DEMO3 desynchs a bit after getting the chainsaw.

It doesn't seem chainsaw related though, comparing with the original 1.1 exe shows that the cacos on the left are in slightly different positions, and the lost soul that actually causes the desynch takes a few tics longer to attack on the 1.1 exe than with this patch.

I've been investigating this for a while but I haven't been able to figure it out yet.",False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/559074334,Doom v0.99 demo support.,drfrag666,27,509442570,14,559074334,0,558647525,2019-11-27T12:49:59Z,You rule! :),False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/559098469,Doom v0.99 demo support.,SmileTheory,27,509442570,15,559098469,0,559074334,2019-11-27T13:58:49Z,"> 
> > ""Wallrunning doesn't work in Doom v1.1 (North-South and East-West walls), except for some diagonal walls for which it's the same as Doom v1.9.""

I'd guess that this is a consequence of the half step movement code not being implemented until Doom v1.2. (https://github.com/chocolate-doom/chocolate-doom/pull/1207/files#diff-9b3d1e95726cd7eaef62f94a3d6caf92R158 )

More info at https://doomwiki.org/wiki/Wallrunning#Technical .",False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/560427599,Doom v0.99 demo support.,drfrag666,27,509442570,16,560427599,0,559098469,2019-12-02T14:47:30Z," Okay i've merged this and done some testing. For me it's broken after ""Requested changes"". You can't start a new game until the first demo plays, the game quits inmediately or after the wipe hence you can't play demo2 or demo3 with playdemo. Besides after the demo ends the wipe is shown twice.
 That is with the 1.1 iwad. Does it work for you?",False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/560570371,Doom v0.99 demo support.,SmileTheory,27,509442570,17,560570371,0,560427599,2019-12-02T20:37:54Z,"> 
> 
> Okay i've merged this and done some testing. For me it's broken after ""Requested changes"". You can't start a new game until the first demo plays, the game quits inmediately or after the wipe hence you can't play demo2 or demo3 with playdemo. Besides after the demo ends the wipe is shown twice.
> That is with the 1.1 iwad. Does it work for you?

It works fine with 1.1 registered and 1.1 shareware for me.  Leaving it to run moves on to demo2 as normal instead of quitting, and I can start a game at any point.

Are you using cmake to build?  I haven't tested cmake since I can never get the thing to work properly. :)

Otherwise, did the branch merge cleanly?  The only other thing I can think of is some conflict, unless you're using a clean version of chocolate doom.",False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/560808048,Doom v0.99 demo support.,drfrag666,27,509442570,18,560808048,0,560570371,2019-12-02T22:50:16Z," Sorry, it was a bad merge of ""Fix inaccurate v1.0/v1.1/v1.2 sight calculations"". Now it works, BTW i've lost my internet connection.",False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/561651091,Doom v0.99 demo support.,drfrag666,27,509442570,19,561651091,0,560808048,2019-12-04T13:43:04Z," I've released a test build with this PR in order to help with old demos here:
https://github.com/drfrag666/chocolate-doom/releases/tag/2.5.0a",False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/562838440,Doom v0.99 demo support.,drfrag666,27,509442570,20,562838440,0,561651091,2019-12-07T10:34:39Z," Uploaded another test build with the latest changes:
https://github.com/drfrag666/chocolate-doom/releases/download/2.5.0b/RUDE-2.5.0b-win32.zip",False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/565741612,Doom v0.99 demo support.,tpoppins,27,509442570,21,565741612,0,562838440,2019-12-14T18:39:18Z,"Thank you for the test build, Dr. Frag666!

Here is a set of demos recorded on E2 and E3 of the registered v1.1 in February-March '94: [VDOOM2_3.ZIP](http://cd.textfiles.com/ccbcurrsh2/DOOM/VDOOM2_3.ZIP). It doesn't include a demo for E3M9, and the E3M6 one terminates prematurely due to reaching the default demo size. Of the other 16 demos all but three play to the end with RUDE v2.5.0b.

The desyncing demos are those for **E3M1**, **E3M5** and **E3M7**. Vanilla v1.1 plays these successfully (i.e. the player reaches the exit and exits the level).

This set should provide some extra testing material. ",False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/565747359,Doom v0.99 demo support.,drfrag666,27,509442570,22,565747359,0,565741612,2019-12-14T19:49:19Z,Thanks. These are useful. E3M1 desyncs becouse the door-lift closes too early. E3M5 becouse the bfg doesn't kill a demon near the end. E3M7 becouse the bridge is missing apparently. We'll know more when SmileTheory tries them with his build.,False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/566508177,Doom v0.99 demo support.,drfrag666,27,509442570,23,566508177,0,565747359,2019-12-17T11:48:02Z,"I've released a new test build with the latest changes.
https://github.com/drfrag666/chocolate-doom/releases/tag/2.5.0c",False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/566729165,Doom v0.99 demo support.,tpoppins,27,509442570,24,566729165,0,566508177,2019-12-17T20:10:30Z,"Good job, SmileTheory: all three demos mentioned above complete successfully now in RUDE Doom 2.5.0c!

@drfrag666: thank you for the bins. Would you email me (tpoppins at juno dot com) please, I can't compile your fork in either CodeBlocks or MSYS2.",False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/567019720,Doom v0.99 demo support.,drfrag666,27,509442570,25,567019720,0,566729165,2019-12-18T12:55:12Z," I've enabled issues, post your problem there and i'll reply ASAP.",False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/581602746,Doom v0.99 demo support.,drfrag666,27,509442570,26,581602746,0,567019720,2020-02-03T20:27:47Z, Any issue left here?,False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/1317638361,Doom v0.99 demo support.,tpoppins,27,509442570,27,1317638361,0,581602746,2022-11-16T20:37:30Z,"Yes, there are still a few issues.

1) ""-fast"" should be disabled for v1.2 and older because ""-fast"" was first introduced in v1.4 beta leak (Apr 8 1994). I just submitted a PR that corrects this. Note to self: Prboom-plus incorrectly allows fast monsters with v1.2 compat as well, subject to another PR.

2) Additionally, there are no ""-respawn"" and ""-nomonsters"" in versions 0.99/1.0 and 1.1.

3) Support for forcing ""-respawn"" and ""-nomonsters"" on command line for playback of v1.2 demos is missing. That should be fixed by another PR I just submitted.

4) The biggest issue for last: **not all** plats stayed active in v1.2 and older. Apparently it's wrong to lump together _raiseAndChange_ and _raiseToNearestAndChange_ as commit [3fe7123](https://github.com/chocolate-doom/chocolate-doom/commit/3fe712316d947353a1576dd0bb91d3a395d8513b) does. 

The following demo on [ANTHELL4](https://www.doomworld.com/idgames/levels/doom/a-c/anthell4), recorded with vanilla v1.2, desyncs in the latest RUDE (which incorporates the changes from that commit) because of that.
[ANTHELL4-v12-test.zip](https://github.com/chocolate-doom/chocolate-doom/files/10025386/ANTHELL4-v12-test.zip)

Linedef 898 has action special 67 (SR Floor Raise by 32 and Change), which is _raiseAndChange_. In vanilla v1.2 (and v1.1 and v1.9u) you can activate this switch multiple times; with that commit applied - only once. Separating the _raiseAndChange_ case like this:

```
		  case raiseAndChange:
	        P_RemoveActivePlat(plat);
		    break;
```
allows the demo to play back correctly to the end. Latest Choco autobuild plays back the demo properly since it doesn't incorporate that commit's changes. 

And then there's that issue with CHURCH.WAD mentioned above.",False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/1363840711,Doom v0.99 demo support.,tpoppins,27,509442570,28,1363840711,0,1317638361,2022-12-23T10:46:37Z,"The CHURCH.WAD internal demo desync's cause has been identified: sector special 17 (random flicker) was not a valid special until the official v1.4 beta.

Meanwhile, a v0.99/1.0 demo that desyncs with this PR has been found: LEVEL7.LMP in [DOOMLVL7.ZIP](https://archive.org/download/Gaminator_201308/Gaminator.iso/D_TOOLS%2FDOOMLVL7.ZIP).

It's a 11:49 UV demo of the IWAD E1M7 that plays back properly to the exit in vanilla. The desync becomes evident around 3:20-3:25. In case it could be relevant, there's a three-second pause at 2:35; removing it doesn't make a difference.

**edit**: removing the pause (manually, or with LMPCm) makes vanilla desync the same way at the same spot. Some more experimenting followed:
- recorded a UV Max in vanilla without using pause and it played back fine in my Choco
- did same thing, this time pausing briefly after taking the yellow key, and the demo desyncs in Choco before you get to the red key
- same issue with v1.1
- unable to reproduce in v1.2

So using pause during recording is definitely a factor. ",False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/1208,Leverage SDL_Mixer for seamless OGG looping?,mikeday0,14,509537881,1,509537881,0,0,2019-10-20T03:03:07Z,"### Background

Version of Chocolate Doom: ee9fc21f

Operating System and version: Ubuntu 18.04, Windows 10

Game: All

### Bug description

When using musicpack files, looping is not seamless even with well-chosen loop points. There is always a hiccup or drop-out. (See #1178) After some experimentation with the i_musicpack.c code, I am convinced the only way this can be properly fixed is to petition for (or contribute?) native loop point support to SDL_Mixer. Poking through the SDL_Mixer source (music_ogg.c), I was surprised to see that such support is already present for OGG files. (But unfortunately not FLAC or MP3)

If your OGG file contains LOOPSTART and LOOPEND comments which specify the loop points in sample position, SDL_Mixer will use those loop points whenever it plays the files with looping requested. (I guess it is an unfortunate coincidence that this differs just slightly from the zdoom LOOP_START and LOOP_END tags that Chocolate uses.) 

For illustration, I have attached a zip file containing two ogg files with an identical tone. It is five seconds of a 441 Hz sine followed by 1 second of silence.
[441Hz-Sinewaves.zip](https://github.com/chocolate-doom/chocolate-doom/files/3747411/441Hz-Sinewaves.zip)

The only difference between the two files is that one uses LOOPSTART/LOOPEND, and the other uses LOOP_START/LOOP_END. The loop points are selected so it should loop about every 3 seconds. If you have Chocolate Doom use these as substitute music tracks you can do a direct comparison of the SDL_Mixer and Chocolate looping. In my testing, I find that the SDL_Mixer looping is completely seamless.

My suggestion is to give the user the option to have Chocolate add LOOPSTART and LOOPEND tags to OGG files when it encounters the zdoom standard LOOP_START and LOOP_END tags. Maybe name it something like ""Modify OGG tags to enable seamless looping"" to clearly communicate that Chocolate is touching their music files.

If folks think something like this is worthwhile I'd be more than happy to take a crack at it!",True,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/544620571,Leverage SDL_Mixer for seamless OGG looping?,fragglet,14,509537881,2,544620571,0,509537881,2019-10-21T17:27:00Z,I wasn't even aware that SDL_mixer had native loop tag support. It seems like it ought to be trivial to make it also recognize the `LOOP_START`/`LOOP_END` tags as well?,False,0,MEMBER
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/544662235,Leverage SDL_Mixer for seamless OGG looping?,mikeday0,14,509537881,3,544662235,0,544620571,2019-10-21T19:09:21Z,"Yes, provided that building your own SDL_Mixer wasn't out of the question. You'd need to edit the following in music_ogg.c:

![image](https://user-images.githubusercontent.com/43701387/67233276-e62eed80-f410-11e9-853d-604299b65c4b.png)

Unfortunately SDL_Mixer does not provide an external interface to directly manipulate the loop points. Also, it doesn't appear to support loop points for FLAC and MP3... yet.

If using a custom SDL_Mixer is a no-go, the only way I see to utilize the SDL_Mixer loop point stuff is to have Chocolate add the LOOPSTART and LOOPEND comments to ogg files. I'd imagine you'd also want to turn off the Chocolate looping code whenever LOOPSTART and LOOPEND are present so Chocolate and SDL_Mixer aren't both trying to loop.",False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/545537855,Leverage SDL_Mixer for seamless OGG looping?,fragglet,14,509537881,4,545537855,0,544662235,2019-10-23T16:54:53Z,"Just a brief comment: with this talk about ""building our own SDL_mixer"" - while it's possible, I'd encourage you not to think of SDL_mixer as some kind of immutable thing handed down to us that's entirely outside our control or influence. From everything you're saying it sounds like the best approach here would be to just contribute some code to SDL_mixer itself. I don't see why they wouldn't accept it. In other words, when you said:

> I am convinced the only way this can be properly fixed is to petition for (or contribute?) native loop point support to SDL_Mixer. 

This sounds exactly correct.

There's an added advantage as well that doing so implicitly gives looping support to any and all other source ports using SDL_mixer for music playback.",False,0,MEMBER
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/545569877,Leverage SDL_Mixer for seamless OGG looping?,mikeday0,14,509537881,5,545569877,0,545537855,2019-10-23T18:12:36Z,"Duly noted! I mistakenly assumed they didn't accept contributions due to the lack of any explicit language stating as such on the SDL_Mixer website. Digging a bit, it turns out that you can submit patches via their Bugzilla.

What would you like to see added to SDL_Mixer? The simple route would be to OR in matching the LOOP_* key names to the code above. However I have to wonder if it would be better implemented as an external-facing function where the user specifies to SDL_Mixer the comment/tag key name to look for. Something like:

`Mix_SetLoopKeyNames(char* loop_start_name, char* loop_end_name, char* loop_length_name)`

Or maybe it's better to set the loop points explicitly:

`Mix_SetLoopPoints(uint loop_start_position, uint loop_end_position)`

Or something else entirely?",False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/546418357,Leverage SDL_Mixer for seamless OGG looping?,fragglet,14,509537881,6,546418357,0,545569877,2019-10-25T16:18:13Z,"The ideal solution would be if SDL_mixer could take care of handling loop points entirely, and we can entirely get out of the business of having to deal with that in the Chocolate Doom codebase. I'd suggest you start with your proposed patch to `music_ogg.c` from a couple of comments back. Assuming that goes well, take a look at the FLAC integration and see if you can implement the same there as well.

Good luck and let me know if I can do anything to help.",False,0,MEMBER
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/547722680,Leverage SDL_Mixer for seamless OGG looping?,mikeday0,14,509537881,7,547722680,0,546418357,2019-10-30T03:22:51Z,"Patch file for OGG looping submitted to SDL:
https://bugzilla.libsdl.org/show_bug.cgi?id=4849

FLAC support in progress...",False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/547766154,Leverage SDL_Mixer for seamless OGG looping?,fabiangreffrath,14,509537881,8,547766154,0,547722680,2019-10-30T07:08:25Z,"Great patch, thanks for that!",False,0,MEMBER
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/549094337,Leverage SDL_Mixer for seamless OGG looping?,mikeday0,14,509537881,9,549094337,0,547766154,2019-11-03T00:46:12Z,"The OGG looping patch has been accepted!
http://hg.libsdl.org/SDL_mixer/rev/493a943d944a",False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/552471264,Leverage SDL_Mixer for seamless OGG looping?,mikeday0,14,509537881,10,552471264,0,549094337,2019-11-11T14:38:59Z,"Patch file for FLAC looping submitted to SDL:
https://bugzilla.libsdl.org/show_bug.cgi?id=4855

I also have a bug fix for the initial stutter when first playing FLAC files that I'll submit separately. (Also mentioned in #1178)

If anyone else wants to try it out, feel free to clone [my SDL_mixer fork](https://github.com/mikeday0/SDL_mixer).",False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/563000326,Leverage SDL_Mixer for seamless OGG looping?,mikeday0,14,509537881,11,563000326,0,552471264,2019-12-08T22:02:06Z,"All of my changes to SDL_Mixer are in and should be part of the official 2.0.5 release. Not sure when this will happen, but my baseless speculation is that they are trying to get something out before the end of the year. I have submitted #1225 which disables the Chocolate looping code.

Earlier you mentioned that there were other source ports which used SDL_Mixer. Do you happen to know which ones? I'd like to give them a heads up that this change is coming in case the developers might want to take advantage of it.",False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/563114863,Leverage SDL_Mixer for seamless OGG looping?,fabiangreffrath,14,509537881,12,563114863,0,563000326,2019-12-09T08:09:16Z,"> Earlier you mentioned that there were other source ports which used SDL_Mixer. Do you happen to know which ones? 

PrBoom+ and Eternity for sure.",False,0,MEMBER
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/1295305128,Leverage SDL_Mixer for seamless OGG looping?,richterdeveloper,14,509537881,13,1295305128,0,563114863,2022-10-28T18:06:55Z,Hello!! The inaccurate loop point bug is still present in the latest build. Tested with flac and ogg music packs...,False,0,NONE
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/1295307635,Leverage SDL_Mixer for seamless OGG looping?,mikeday0,14,509537881,14,1295307635,0,1295305128,2022-10-28T18:10:00Z,Chocolate Doom has not migrated yet to SDL Mixer 2.6. That needs to be done in order for the issue to be resolved.,False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/1308167478,Leverage SDL_Mixer for seamless OGG looping?,mikeday0,14,509537881,15,1308167478,0,1295307635,2022-11-09T03:47:19Z,"Thanks to #1531, I think we can close this.",False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/1209,Wrong par time for MAP33,fabiangreffrath,17,513570691,1,513570691,0,0,2019-10-28T21:34:43Z,"Reportedly, the par time shown when finishing MAP33 (Betray) is shown as ""SUCKS"" on real hardware [0], whereas it is initialized to zero [1] in Chocolate Doom.

I'd like to change this initialization value to e.g. `INT_MAX` to make sure it is always a huge number that exceeds `59*61` which is the limit after which the ""SUCKS"" patch is shown. 

One question remains: In a follow-up post, a user suggests to change the condition to `>= 33` to account for PWADs which provide more than 33 maps. However, I am not sure what par time DOOM2.EXE would show for such maps or if it would probably even crash. Does anyone have any experience here or do you consider it safe to change this line of code as suggested?

[0] https://www.doomworld.com/forum/topic/67168-crispy-doom-563-update-oct-04-2019/?page=47&tab=comments#comment-2038332
[1] https://github.com/chocolate-doom/chocolate-doom/blob/master/src/doom/g_game.c#L1463
[2] https://www.doomworld.com/forum/topic/67168-crispy-doom-563-update-oct-04-2019/?page=47&tab=comments#comment-2038392",True,0,MEMBER
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/547841606,Wrong par time for MAP33,fabiangreffrath,17,513570691,2,547841606,0,513570691,2019-10-30T10:47:50Z,"Alright, so I have taken a HEX editor and inspected DOOM.EXE v1.9 to see what int values we would find when reading past the `cpars[]` array. Here are my results for maps up to MAP40:

`cpars[32]` (MAP33): 1835884871 (""Gamm"")
`cpars[33]` (MAP34): 1868767329 (""a co"")
`cpars[34]` (MAP35): 1667592818 (""rrec"")
`cpars[35]` (MAP36): 1852795252 (""tion"")
`cpars[36]` (MAP37): 1179012896 ("" OFF"")
`cpars[37]` (MAP38): 0
`cpars[38]` (MAP39): 1632043008 (""  Ga"")
`cpars[39]` (MAP40): 543255917 (""mma "")

So, I guess we are safe to say that the par time for maps > 32 is well approximated by `INT_MAX` with the single exception of MAP38.",False,0,MEMBER
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/548359281,Wrong par time for MAP33,fabiangreffrath,17,513570691,3,548359281,0,547841606,2019-10-31T12:52:57Z,"NB: We retrieve par time values > 3600 for each level up to MAP76, with the execption of MAP38.",False,0,MEMBER
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/551682931,Wrong par time for MAP33,fabiangreffrath,17,513570691,4,551682931,0,548359281,2019-11-08T12:10:25Z,"Hm, so I have just finished MAP33 with DOOM.EXE in DosBox using the BFG-Edition DOOM2.WAD file and interestingly, *no* par time is printed on the intermission screen. This is a significantly different result than what is presented here: https://www.youtube.com/watch?v=mYRtNFjrZrY

Is there probably any guard in DOOM.EXE that prevents printing par times for maps >32 that didn't make it into the source code?",False,0,MEMBER
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/551687490,Wrong par time for MAP33,fabiangreffrath,17,513570691,5,551687490,0,551682931,2019-11-08T12:13:42Z,"Oh, wait. DOOM.EXE does realize this isn't the original IWAD and prompts me to press Enter during start-up. May this be the reason why the par time isn't printed?",False,0,MEMBER
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/551721944,Wrong par time for MAP33,nukeykt,17,513570691,6,551721944,0,551687490,2019-11-08T12:38:12Z,"Which version of DOOM.EXE do you use? IIRC Ultimate Doom and Final Doom EXEs had some quirks with par times in 'commercial' mode
EDIT: https://doomwiki.org/wiki/Par_times_hidden_in_Final_Doom_after_idclev_or_reload",False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/551727021,Wrong par time for MAP33,fabiangreffrath,17,513570691,7,551727021,0,551721944,2019-11-08T12:41:50Z,I am using the regular 1.9 EXE which came with the shareware IWAD.,False,0,MEMBER
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/551729900,Wrong par time for MAP33,nukeykt,17,513570691,8,551729900,0,551727021,2019-11-08T12:43:51Z,I think regular 1.9 Doom uses exactly the same EXE as Doom 2,False,0,CONTRIBUTOR
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/551780061,Wrong par time for MAP33,fabiangreffrath,17,513570691,9,551780061,0,551729900,2019-11-08T13:19:15Z,"> I think regular 1.9 Doom uses exactly the same EXE as Doom 2

Yes. ",False,0,MEMBER
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/552365892,Wrong par time for MAP33,fabiangreffrath,17,513570691,10,552365892,0,551780061,2019-11-11T09:37:31Z,"> Oh, wait. DOOM.EXE does realize this isn't the original IWAD and prompts me to press Enter during start-up. May this be the reason why the par time isn't printed?

Turns out this is because the BFG Edition DOOM2.WAD has the PWAD header instead of IWAD. This and I'll have to rename the DMENUPIC lump to TITLEPIC. Further tests will follow...",False,0,MEMBER
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/555881475,Wrong par time for MAP33,fabiangreffrath,17,513570691,11,555881475,0,552365892,2019-11-20T07:48:16Z,"So, I have finished MAP33 with any of the three regular DOOM.EXEs (i.e. 1.9, Ultimate, Final) and recorded the map stats with `statdump`. The par time is always reported as `-521:-10`:

```
===========================================
MAP33
===========================================

Time: 0:13 (par: -521:-10)

Player 1 (Green):
	Kills: 0 / 92 (0%)
	Items: 0 / 8 (0%)
	Secrets: 0 / 3 (0%)

```

Yes, I did IDCLIP myself to the exit switch. :wink: ",False,0,MEMBER
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/555923423,Wrong par time for MAP33,fabiangreffrath,17,513570691,12,555923423,0,555881475,2019-11-20T09:41:15Z,"Riddle solved!
```
diff --git a/src/doom/g_game.c b/src/doom/g_game.c
index 9cabfaf8..9bb82cca 100644
--- a/src/doom/g_game.c
+++ b/src/doom/g_game.c
@@ -1460,10 +1460,11 @@ void G_DoCompleted (void)
     // statcheck regression testing.
     if (gamemode == commercial)
     {
-        // map33 has no official time: initialize to zero
+        // map33 reads its par time from beyond the cpars[] array
         if (gamemap == 33)
         {
-            wminfo.partime = 0;
+            const int cpars32 = *(int *)GAMMALVL0;
+            wminfo.partime = TICRATE*cpars32;
         }
         else
         {
diff --git a/src/doom/statdump.c b/src/doom/statdump.c
index 5bacad67..59f935a4 100644
--- a/src/doom/statdump.c
+++ b/src/doom/statdump.c
@@ -268,7 +268,7 @@ static void PrintLevelName(FILE *stream, int episode, int level)
 
 static void PrintStats(FILE *stream, wbstartstruct_t *stats)
 {
-    int leveltime, partime;
+    short leveltime, partime;
     int i;
 
     PrintLevelName(stream, stats->epsd, stats->last);
```",False,0,MEMBER
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/555931871,Wrong par time for MAP33,fabiangreffrath,17,513570691,13,555931871,0,555923423,2019-11-20T10:02:55Z,"Well, strictly speaking this should probably be:
```
const int cpars32 = LONG(*(int *)DEH_String(GAMMALVL0));
```",False,0,MEMBER
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/555935197,Wrong par time for MAP33,turol,17,513570691,14,555935197,0,555931871,2019-11-20T10:11:58Z,"Casting a pointer like that is bad since the string is not guaranteed to be correctly aligned. Try this instead:
```
memcpy(&cpars32, DEH_String(GAMMALVL0), sizeof(int));
```
",False,0,MEMBER
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/555990099,Wrong par time for MAP33,fabiangreffrath,17,513570691,15,555990099,0,555935197,2019-11-20T12:50:45Z,"Good point, thanks. Is this approach endian-safe?",False,0,MEMBER
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/555991979,Wrong par time for MAP33,turol,17,513570691,16,555991979,0,555990099,2019-11-20T12:56:06Z,"> Is this approach endian-safe?

No, but who still has big-endian hardware to test on? If you want it to work you could add an endianness swap after the copy.
",False,0,MEMBER
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/556028909,Wrong par time for MAP33,fabiangreffrath,17,513570691,17,556028909,0,555991979,2019-11-20T14:33:33Z,"I know of at least one Wii fork, so I'd like to keep the code endianess clean. 

https://github.com/derek57/wii-doom",False,0,MEMBER
https://api.github.com/repos/chocolate-doom/chocolate-doom/issues/comments/557745628,Wrong par time for MAP33,fragglet,17,513570691,18,557745628,0,556028909,2019-11-23T00:44:22Z,"> No, but who still has big-endian hardware to test on?

FWIW, the weekly Choco/Crispy regression tests are running on a big endian machine, deliberately for testing this kind of portability.",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/7922,Deprecate EntityRepository#clear(),lcobucci,7,528209647,1,528209647,0,0,2019-11-25T16:49:17Z,"That method calls `EntityManager#clear()` with an argument, which won't be allowed anymore on v3.0. 

We must add a `@deprecated` annotation (without a `trigger_error()` since it's already handled by `EntityManager#clear()`).

--- 

Context on the **why**: https://github.com/doctrine/orm/issues/7925#issuecomment-558997382",True,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/563247209,Deprecate EntityRepository#clear(),danielspk,7,528209647,2,563247209,0,528209647,2019-12-09T13:50:56Z,"Help please!

What is the current solution? The documentation is not up to date: https://www.doctrine-project.org/projects/doctrine-orm/en/2.7/reference/batch-processing.html

Example:

```php
$demoA = new DemoA();
$demoA->setName('Demo');

$entityManager->persist($demoA);
$entityManager->flush();

while (/* many entities .. */) {
  $demoB = new DemoB();
  $demoB->setDemoA($demoA);

  $entityManager->persist($demoB);
  $entityManager->flush();
  $entityManager->detach($demoB); // ERROR: Method Doctrine\\ORM\\EntityManager::detach() is deprecated and will be removed in Doctrine ORM 3.0
}
```",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/563394800,Deprecate EntityRepository#clear(),Ocramius,7,528209647,3,563394800,0,563247209,2019-12-09T19:27:36Z,"Yes, the docs will require updating there 👍

@danielspk check `ocramius/doctrine-batch-utils` for a more (simplistic) self-contained batch processing library",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/563431733,Deprecate EntityRepository#clear(),lcobucci,7,528209647,4,563431733,0,563394800,2019-12-09T20:49:17Z,"Handled by #7928

Documentation will be sorted out by another PR.",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/563993977,Deprecate EntityRepository#clear(),danielspk,7,528209647,5,563993977,0,563431733,2019-12-10T11:36:37Z,"@Ocramius I think `ocramius/doctrine-batch-utils` doesn't solve this BC:

- support Doctrine ORM 2.7 version?
- in my example `$demoA` should never be cleaned/detached. Only instances of `$demoB` that can be thousands should be cleared/detached. How would it be possible to perform this selective cleaning with `doctrine-batch-utils`?",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/564007913,Deprecate EntityRepository#clear(),lcobucci,7,528209647,6,564007913,0,563993977,2019-12-10T12:20:10Z,"@danielspk if your code is your simple as your example, then it should be converted to this:

```php
$demoA = new DemoA();
$demoA->setName('Demo');

$entityManager->persist($demoA);
$entityManager->flush();
$entityManager->clear(); // we don't need anything in the UoW

while (/* many entities .. */) {
  $demoB = new DemoB();
  $demoB->setDemoA($entityManager->getReference(DemoA::class, $demoA->getId()); // assuming that `getId()` is how you get the identifier

  $entityManager->persist($demoB);
  $entityManager->flush();
  $entityManager->clear();
}
```

>  How would it be possible to perform this selective cleaning?

Ideally, nobody would need that.

Managing the UoW is an internal operation that might affect the behaviour of the ORM, hence our move to try to regain control over it.
We're still having some discussions about it, since some people are fine with messing up with the UoW while understanding that their on their own.

In the meantime, (if you really really really really really want to detach stuff and you're aware that you may have to deal with dragons) you can do `$entityManager->getUnitOfWork()->detach($blah)` without triggering and `E_USER_DEPRECATED` - it only has a `@deprecated` annotation which may be converted to `@internal` depending how our discussion goes.

Nevertheless your comment isn't related to this issue, since you're talking about `EntityManager#clear()` and not `EntityRepository#clear()`.",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/564018528,Deprecate EntityRepository#clear(),danielspk,7,528209647,7,564018528,0,564007913,2019-12-10T12:51:16Z,"Thank you very much @lcobucci 

His example is enlightening.

In my case, after the loop, I need to use $ demoA again, but once again accessing the database is not expensive, it simply requires a refactor.

Under these discussions, do you think it is worthwhile to make a refactor to migrate to version 2.7 or will it simply be better to wait for 2.8 when you are more certain?

Cheers",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/564022146,Deprecate EntityRepository#clear(),lcobucci,7,528209647,8,564022146,0,564018528,2019-12-10T13:01:31Z,"> In my case, after the loop, I need to use $ demoA again, but once again accessing the database is not expensive, it simply requires a refactor.

Using [the L2C](https://www.doctrine-project.org/projects/doctrine-orm/en/2.7/reference/second-level-cache.html#the-second-level-cache) would also make this even less expensive - but you'd have to check if it's applicable to your use cases.

> Under these discussions, do you think it is worthwhile to make a refactor to migrate to version 2.7 or will it simply be better to wait for 2.8 when you are more certain?

Triggering `E_USER_DEPRECATED` will remain in 2.8 and it's not an error perse, it's a warning to help you be ready for when Doctrine ORM 3.0 comes.

I'd suggest you to always try to migrate to the latest versions to reduce your maintenance burden but I can't tell how much effort is involved in your app. I'd also say for you to be as away from the UoW as possible but I understand that it's sometimes inevitable.",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/7923,Setting to disable DQL parsing errors,oojacoboo,3,528284117,1,528284117,0,0,2019-11-25T19:16:29Z,"### Feature Request

<!-- Fill in the relevant information below to help triage your issue. -->

|    Q        |   A
|------------ | ------
| New Feature | yes
| RFC         | yes
| BC Break    | no

#### Summary

Currently the DQL parser, via the Lexer, is checking to ensure that all syntax is compatible with all database platforms.  The result of this is very limiting and requires that developers implement work arounds to enable custom database functions, or functions not supported by all.

This feature only has value for developers that are trying to write apps that need to be compatible with multiple database engines.  That's a small fraction of the developers using Doctrine.

I'm suggesting that Doctrine should not throw exceptions when a function, in particular, isn't found in the Lexer and instead should just let PDO blow up, even possibly catching the PDO exception, should some cleanup being required.  So, basically adding a setting that removes these checks to allow developers to write their queries as they wish.",True,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/558397123,Setting to disable DQL parsing errors,lcobucci,3,528284117,2,558397123,0,528284117,2019-11-26T00:02:37Z,"DQL isn't SQL and has its own syntax. The ORM is a generic abstraction layer and as such imposes its constraints. People are completely free to use SQL via the native query API if/when they need or extend the DQL with custom functions for their app-specific needs.

Dropping the DQL syntax validation is a no-go for me. ",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/558404416,Setting to disable DQL parsing errors,oojacoboo,3,528284117,3,558404416,0,558397123,2019-11-26T00:31:57Z,"@lcobucci I guess you'd just choose to leave it enabled then, via the setting.  ",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/558514896,Setting to disable DQL parsing errors,Ocramius,3,528284117,4,558514896,0,558404416,2019-11-26T08:19:21Z,"DQL has its own semantics that are required to be validated, since it is logically different from SQL.

It has to be parsed, interpreted, transformed into a resultsetmapping, and it has to be comprehensible by DQL/SQL walkers in all of its AST in-memory representation.

It is fundamentally its own language, and if SQL is what is needed to get something specific to a certain DB to run (for example via recursive queries, stored functions), then SQL should be used, instead of hoping to make DQL more SQL-ish.",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/7925,Calling Doctrine\ORM\EntityManager::clear() with any arguments to clear specific entities is deprecated,ruudk,5,528708178,1,528708178,0,0,2019-11-26T12:58:03Z,"### Bug Report

|    Q        |   A
|------------ | ------
| BC Break    |no
| Version     | 2.7.0

#### Summary

Calling `Doctrine\ORM\EntityRepository::clear` triggers deprecation message:
```
User Deprecated: Calling Doctrine\ORM\EntityManager::clear() with any arguments to clear specific entities is deprecated and will not be supported in Doctrine ORM 3.0. {""exception"":""[object] (ErrorException(code: 0): User Deprecated: Calling Doctrine\\ORM\\EntityManager::clear() with any arguments to clear specific entities is deprecated and will not be supported in Doctrine ORM 3.0. at /var/www/app/vendor/doctrine/orm/lib/Doctrine/ORM/EntityManager.php:562)""} []
```

#### Current behavior

`Doctrine\ORM\EntityRepository::clear` does not any input and passes the call to `$this->_em->clear($this->_class->rootEntityName);`. 

I think we can just remove the `$this->_class->rootEntityName` argument here:
https://github.com/doctrine/orm/blob/a416a9a8b2cd2ea0f7b7b5638986e8b398f34df8/lib/Doctrine/ORM/EntityRepository.php#L133-L136

",True,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/558671218,Calling Doctrine\ORM\EntityManager::clear() with any arguments to clear specific entities is deprecated,lcobucci,5,528708178,2,558671218,0,528708178,2019-11-26T15:05:33Z,Related to #7922. I think this method should just be removed instead of removing the argument. ,False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/558964223,Calling Doctrine\ORM\EntityManager::clear() with any arguments to clear specific entities is deprecated,ruudk,5,528708178,3,558964223,0,558671218,2019-11-27T07:23:11Z,"Instead of doing that, shouldn't we just remove the argument for now to fix the deprecation? People that upgrade will get this deprecation now with no way to fix it. 

Also, why should that method be removed? To me, it's handy to call clear on repository without having to do repo->getEntityManager->clear.",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/558996336,Calling Doctrine\ORM\EntityManager::clear() with any arguments to clear specific entities is deprecated,Ocramius,5,528708178,4,558996336,0,558964223,2019-11-27T09:06:28Z,Mostly needs to go because it is not up to a repository to control the `UnitOfWork` state.,False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/558997382,Calling Doctrine\ORM\EntityManager::clear() with any arguments to clear specific entities is deprecated,lcobucci,5,528708178,5,558997382,0,558996336,2019-11-27T09:09:31Z,"> Instead of doing that, shouldn't we just remove the argument for now to fix the deprecation? People that upgrade will get this deprecation now with no way to fix it.

That would be a behavioural bc break, which is not really good (as we've seen in v2.6.5).

> Also, why should that method be removed? To me, it's handy to call clear on repository without having to do repo->getEntityManager->clear.

To me, we twisted the [repository pattern](https://martinfowler.com/eaaCatalog/repository.HTML) with methods like that in this class. 

The general idea of acting as an in-memory domain object collection is broken when my collection is still full of objects after I call `clear()`.

Apart from that, it gives control over the identity map to components that should be completely unaware of it - harming encapsulation and leaking persistence details. ",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/563431346,Calling Doctrine\ORM\EntityManager::clear() with any arguments to clear specific entities is deprecated,lcobucci,5,528708178,6,563431346,0,558997382,2019-12-09T20:48:22Z,Handled by #7928 ,False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/7926,Add docs note that FQCN is needed for an Embeddable configured via annotations,Pictor13,8,529442373,1,529442373,0,0,2019-11-27T16:08:37Z,"By default PHP users will try to omit the namespace, importing it with `use`.
But that is not supported, at the moment.

Is possible to spare developers the time for figuring this out.",True,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/559217260,Add docs note that FQCN is needed for an Embeddable configured via annotations,lcobucci,8,529442373,2,559217260,0,529442373,2019-11-27T19:12:48Z,"> But that is not supported, at the moment.

@Pictor13 that should work when using `::class` syntax, have you tried that?",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/559258266,Add docs note that FQCN is needed for an Embeddable configured via annotations,Pictor13,8,529442373,3,559258266,0,559217260,2019-11-27T21:33:26Z,"Inside the annotation/comment? 😳
Had no idea it would work",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/559287615,Add docs note that FQCN is needed for an Embeddable configured via annotations,Pictor13,8,529442373,4,559287615,0,559258266,2019-11-27T23:44:44Z,"It does.
I discovered something new and unexpected. 🙂

Thanks, and sorry for taking your time.
Closing here.",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/559471137,Add docs note that FQCN is needed for an Embeddable configured via annotations,Pictor13,8,529442373,5,559471137,0,559287615,2019-11-28T12:13:59Z,"Ehmm... pardon me for reopening again @lcobucci , I found out to have some caching issue
(since I recently updated the *doctrine-migration-bundle*, that removed the deprecated *doctrine-cache-bundle*).

I reported it as working, but it was because of my previous attempt with the full namespace, that was running correctly and got cached.

```
// WORKING
namespace My\Entity;

// ...
/**
 * @ORM\Embedded(class=""My\ValueObject\Address"")
 **/
private $address;
```

when I tried with `::class` as suggested it _appeared_ to be working

```
// NOT WORKING
namespace My\Entity;

use My\ValueObject\Address;
// ...

/**
 * @ORM\Embedded(class=""Address::class"")
 **/
private $address;
```

but _reality_ is that it was running over the cache (supposedly `memcache`?) from the previous correct case.
When I cleared the cache this morning,
with `bin/console doctrine:cache:clear-metadata`,
it blew up 😣.
> Unknown Entity namespace alias 'My\Entity\Address'.

**Note:**
Also, the other attempt that I tried was _without_ `::class` (as mentioned in the pull request)

```
// NOT WORKING
namespace My\Entity;

use My\ValueObject\Address;
// ...

/**
 * @ORM\Embedded(class=""Address"")
 **/
private $address;
```
> Class 'My\Entity\Address' does not exist

is not working.

---

So, if I am not **still** doing something wrong, I think the addendum to the documentation might be useful and more explicit about how the FQCN **must** be specified.

Consider that I am pretty n00b with Symfony & Doctrine, and I passed the night coding with not much sleep (😴 my brain is in zombie mode); so please, let me know if there is something else that I might be missing; or if the documentation can actually be updated.",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/559484570,Add docs note that FQCN is needed for an Embeddable configured via annotations,Pictor13,8,529442373,6,559484570,0,559471137,2019-11-28T12:56:49Z,"Also, I am not sure how documentation versioning is handled for this repo, but probably (if accepted) the note should be added also for versions < doctrine:2.7 ?",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/559512270,Add docs note that FQCN is needed for an Embeddable configured via annotations,lcobucci,8,529442373,7,559512270,0,559484570,2019-11-28T14:21:54Z,"The `::class` syntax should be used without quotes, like:

```php
namespace My\Entity;

use My\ValueObject\Address;

class Blah
{
    /**
     * @ORM\Embedded(class=Address::class)
     **/
    private $address;
```

Have you tried this?",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/559512542,Add docs note that FQCN is needed for an Embeddable configured via annotations,lcobucci,8,529442373,8,559512542,0,559512270,2019-11-28T14:22:41Z,We don't maintain < v2.7 so don't worry about them.,False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/559524046,Add docs note that FQCN is needed for an Embeddable configured via annotations,Pictor13,8,529442373,9,559524046,0,559512542,2019-11-28T14:56:42Z,"> Have you tried this?

Nope... 😬
And it works!

Closing again 😅

---
> The ::class syntax should be used without quotes

I wasn't aware of that, and am clearly missing some knowledge about annotations... (cause I usually avoid them).

Is it, using quotes or not, defined in some kind of PHP annotations standard/spec?
Or is it some specific Doctrine way of reading annotations?",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/dbal/issues/3756,Dropped SQL Server 2008 support,morozov,3,529654242,1,529654242,0,0,2019-11-28T02:11:04Z,"|      Q       |   A
|------------- | -----------
| Type         | improvement
| BC Break     | yes

Fixes #3755.

Additionally, some changes in `.appveyor.yml` were needed in order to work around the build failure. The reason is:
1. Due to https://github.com/chocolatey/choco/issues/1843, `choco search` only returns PHP 7.4.0 as of today:
   ```
   PS C:\Users\Sergei Morozov> choco search php --exact --all-versions
   Chocolatey v0.10.15
   php 7.4.0 [Approved]
   1 packages found.
   ```
2. Combined with `| select-string -pattern 7.3`, it yields an empty list and [fails the build](https://ci.appveyor.com/project/doctrine/dbal/builds/29173708/job/7ci3uidwp28ri59p).
3. Prior to this change, the builds would pass because all runtime dependencies are cached based on the content of `.appveyor.yml`.
4. We cannot switch to PHP 7.4 on AppVeyor because the corresponding `sqlsrv` and `pdo_sqlsrv` binaries are not yet available.",True,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/comments/562358046,Dropped SQL Server 2008 support,SenseException,3,529654242,2,562358046,0,529654242,2019-12-05T23:04:52Z,Are we going to create a new PR for having `sqlsrv` and `pdo_sqlsrv` with PHP 7.4 when it is available? Or do you want to try to find another solution?,False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/comments/562367024,Dropped SQL Server 2008 support,morozov,3,529654242,3,562367024,0,562358046,2019-12-05T23:38:17Z,"> Are we going to create a new PR for having `sqlsrv` and `pdo_sqlsrv` with PHP 7.4 when it is available? Or do you want to try to find another solution?

Apparently, the [`5.7.1preview` builds](https://windows.php.net/downloads/pecl/releases/pdo_sqlsrv/5.7.1preview/) are compiled for PHP 7.4 but I'd rather solve one problem at a time.",False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/comments/562857398,Dropped SQL Server 2008 support,beberlei,3,529654242,4,562857398,0,562367024,2019-12-07T14:49:52Z,@morozov this needs to get into 2.10 as well as appveyor is mass failing there as well,False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/3758,[POSTGRESQL 12] schema problem with IDENTITY,EnergieZ,3,529786514,1,529786514,0,0,2019-11-25T16:06:18Z,"Hello,

I'm in trouble with doctrine and postgreSQL.
Doctrine bundle : 1.11.2
doctrine/orm : 2.7.0
PHP : 7.1.31
SF : 3.4.26
Postgresql : 12.1

i'm having an existing PostgreSQL server with schema and datas.

Each ""id"" is using identity, and has been created with this SQL : 
```
CREATE TABLE public.my_table(
    id int GENERETAD BY DEFAULT AS IDENTITY NOT NULL,
    ...
)
```
(I can't change this, because it's a migration from an existing symfony MySQL, using fullconvert)

Doctrine Entity is : 
```
/**
 * MyTable
 *
 * @ORM\Table()
 * @ORM\Entity(repositoryClass=""..../myTableRepository"")
 */
class MyTable
{
    /**
     * @var integer
     *
     * @ORM\Column(name=""id"", type=""integer"")
     * @ORM\Id
     * @ORM\GeneratedValue(strategy=""IDENTITY"")
     */
    private $id;
```

Then, when i try a `doctrine:schema:update`, doctrine bundle tries to create new sequence, wich create an error, because IDENTITY create the same non visible seuqence : 

```
An exception occurred while executing 'CREATE SEQUENCE my_table_id_seq' : 
 SQLSTATE[42P07]: Duplicate table: 7 ERROR: relation ""my_table_id_seq"" already exists """"""
```

I can see the public.my_table_id_seq in ""Dependents"" of the public schema (with pgadmin).
But i can't see it in the ""Sequences"" under public schema.

When using identity, no sequence should be created by doctrine ? ",True,0,NONE
https://api.github.com/repos/doctrine/dbal/issues/comments/559398495,[POSTGRESQL 12] schema problem with IDENTITY,stof,3,529786514,2,559398495,0,529786514,2019-11-28T08:50:03Z,"This should be reported to DBAL, as that's where these features are implemented (and the main DBAL maintainers are not following the DoctrineBundle issue tracker AFAIK).",False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/comments/559401145,[POSTGRESQL 12] schema problem with IDENTITY,EnergieZ,3,529786514,3,559401145,0,559398495,2019-11-28T08:57:49Z,"Thank you, will repost on dbal soon :)",False,0,NONE
https://api.github.com/repos/doctrine/dbal/issues/comments/559408751,[POSTGRESQL 12] schema problem with IDENTITY,alcaeus,3,529786514,4,559408751,0,559401145,2019-11-28T09:19:03Z,"> Thank you, will repost on dbal soon :)

No need: we can transfer issues so you don't have to do twice the work.",False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/3759,Extract getSequenceNumber() from lastInsertId(),BenMorel,7,530658675,1,530658675,0,0,2019-12-01T02:28:47Z,"<!-- Fill in the relevant information below to help triage your pull request. -->

|      Q       |   A
|------------- | -----------
| Type         | improvement
| BC Break     | yes
| Fixed issues | N/A

#### Summary

This PR supersedes #3368. From the original issue:

> **Proposed changes**
> 
>This PR splits the existing `lastInsertId(?string $name = null) : string` method into 2 methods:
> 
> - `lastInsertId() : string`
> - `getSequenceNumber(string $name) : string`
> 
> Naming is a first draft, suggestions welcome (`getLastInsertId()` for consistency?)
> 
> Tests have been extended to cover the following scenarios:
> 
> - `lastInsertId()` on supported platforms
> - `lastInsertId()` on unsupported platforms (exception)
> - `lastInsertId()` on all platforms, on a fresh connection, i.e. with no ID available (exception)
> - `getSequenceNumber()` with a known sequence name on supported platforms
> - `getSequenceNumber()` with an unknown sequence name on all platforms (exception)

This PR has been rebased onto `master`, and only covers the split of `lastInsertId()` into `lastInsertId()` and `getSequenceNumber()`, without the originally proposed changes to the driver interfaces & exceptions.",True,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/dbal/issues/comments/560088336,Extract getSequenceNumber() from lastInsertId(),greg0ire,7,530658675,2,560088336,0,530658675,2019-12-01T10:24:35Z,"IMO this should be contributed to the stable branch, without a BC-break. Calling the method with an argument should be deprecated in favor of calling the new method. But that's just my opinion, I think it better fits the merge up workflow, maybe let another contributor chime in before actually following this piece of advice.",False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/comments/560127709,Extract getSequenceNumber() from lastInsertId(),BenMorel,7,530658675,3,560127709,0,560088336,2019-12-01T16:27:05Z,"@morozov All tests now pass. Waiting for your review, in particular whether we should consider renaming `lastInsertId()` to `getLastInsertId()` for consistency with `getSequenceNumber()`.

@greg0ire I can understand the motivation behind making this feature available to the `2.x` series, however I cannot myself spend more time to make it happen. If this PR is merged, if should be pretty trivial for someone else to take over and port it to `2.x`.",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/dbal/issues/comments/566409805,Extract getSequenceNumber() from lastInsertId(),BenMorel,7,530658675,4,566409805,0,560127709,2019-12-17T07:00:44Z,"@morozov Is there anything specific you want to be changed to finish this PR, or do you just need more time for review? Should I work on removing the driver-specific exceptions in another PR?",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/dbal/issues/comments/566593632,Extract getSequenceNumber() from lastInsertId(),morozov,7,530658675,5,566593632,0,566409805,2019-12-17T15:34:35Z,"> Should I work on removing the driver-specific exceptions in another PR?

Yes. See https://github.com/doctrine/dbal/pull/3759#discussion_r354589710.",False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/comments/654961955,Extract getSequenceNumber() from lastInsertId(),morozov,7,530658675,6,654961955,0,566593632,2020-07-07T16:00:10Z,The development of this change should be now unblocked by the recent changes in exception handling in `3.0.x` (see https://github.com/doctrine/dbal/pull/3367#issuecomment-654960605).,False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/comments/703300128,Extract getSequenceNumber() from lastInsertId(),morozov,7,530658675,7,703300128,0,654961955,2020-10-04T18:59:17Z,"Since #3367 is addressed, @BenMorel, could you try to rebase this so we could reassess where we are? From the static analysis standpoint, this is one of the most annoying APIs in the library (not counting the ones that have been already deprecated and removed).",False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/comments/703330784,Extract getSequenceNumber() from lastInsertId(),BenMorel,7,530658675,8,703330784,0,703300128,2020-10-04T23:22:45Z,"@morozov I opened a new PR #4324, please stand by while I refine it, I'll let you know when it's ready for review!
Closing this one in the meantime.",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/dbal/issues/3760,Develop branch is gone,BenMorel,3,530660267,1,530660267,0,0,2019-12-01T02:49:21Z,"<!-- Fill in the relevant information below to help triage your pull request. -->

|      Q       |   A
|------------- | -----------
| Type         | improvement
| BC Break     | no
| Fixed issues | N/A

#### Summary

The `develop` branch does not exist anymore.",True,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/dbal/issues/comments/562340387,Develop branch is gone,morozov,3,530660267,2,562340387,0,530660267,2019-12-05T22:07:22Z,@BenMorel could you also replace 2.9 with 2.10?,False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/comments/562354305,Develop branch is gone,BenMorel,3,530660267,3,562354305,0,562340387,2019-12-05T22:51:48Z,@morozov Done!,False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/dbal/issues/comments/562372316,Develop branch is gone,morozov,3,530660267,4,562372316,0,562354305,2019-12-06T00:00:23Z,"Thank you, @BenMorel.",False,0,MEMBER
https://api.github.com/repos/compat-table/compat-table/issues/1556,Improve historical Node data,zloirock,35,534536830,1,534536830,0,0,2019-12-08T12:46:53Z,,True,0,COLLABORATOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/562964960,Improve historical Node data,ljharb,35,534536830,2,562964960,0,534536830,2019-12-08T16:15:15Z,How are all these verified? node older than 0.6 won’t compile on any hardware i have access to.,False,0,MEMBER
https://api.github.com/repos/compat-table/compat-table/issues/comments/562966264,Improve historical Node data,zloirock,35,534536830,3,562966264,0,562964960,2019-12-08T16:26:50Z,@ljharb by V8 versions.,False,0,COLLABORATOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/562967075,Improve historical Node data,zloirock,35,534536830,4,562967075,0,562966264,2019-12-08T16:35:07Z,"Feel free to check it. I haven't required hardware, you - too, but the version from the current PR definitely better than we have now (difference in 10 Chrome / V8 versions with the real result in 0.10, 0.12, iojs1, etc).",False,0,COLLABORATOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/562967230,Improve historical Node data,zloirock,35,534536830,5,562967230,0,562967075,2019-12-08T16:36:50Z,"But if you wanna check it, please, do it out of the scope of this PR which will not wait for it.",False,0,COLLABORATOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/562967964,Improve historical Node data,ljharb,35,534536830,6,562967964,0,562967230,2019-12-08T16:44:52Z,"Yes, it will wait for it; this table is for manually verified data, and things don’t land on this repo when a collaborator blocks it, as you well know.

Please feel free to remove changes you can’t manually verify (anything below node 0.8 is likely to be tricky, but the rest is trivial with nvm) and I’ll be on board.",False,0,MEMBER
https://api.github.com/repos/compat-table/compat-table/issues/comments/562968135,Improve historical Node data,zloirock,35,534536830,7,562968135,0,562967964,2019-12-08T16:46:39Z,"If you wanna do it - do in a separate PR, please. This PR will be merged anyway, even without your destructive ""review"". If you want to set any rule for this repository, please do at least something useful for the project. For example, the first PR for the 2 years with validation of this result.",False,0,COLLABORATOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/562970310,Improve historical Node data,ljharb,35,534536830,8,562970310,0,562968135,2019-12-08T17:08:38Z,"Validating PRs alone is useful. If this PR is merged anyways, I’ll just revert it, and then we’ll have to get the repo owner involved - which won’t likely be good for anybody.

Nothing lands in any github repo unless collaborators don’t object. This isn’t my rule, it’s just how it’s always worked - especially here, but also anywhere. If you’ll recall I’ve had some changes that you’ve blocked, and I’ve never done you the discourtesy of merging through your block, conceptual or concrete. Please treat me with the same respect.",False,0,MEMBER
https://api.github.com/repos/compat-table/compat-table/issues/comments/562970719,Improve historical Node data,zloirock,35,534536830,9,562970719,0,562970310,2019-12-08T17:12:49Z,"If you will revert it - I'll revert it back. If you will show where I can read this ""rule"" about verification critically obsolete engines on hardware - I'll think about it, otherwise - it's your work. Please do not engage in destructive activities, interfering with improving the project.",False,0,COLLABORATOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/562970813,Improve historical Node data,ljharb,35,534536830,10,562970813,0,562970719,2019-12-08T17:13:51Z,Landing data unverified by a human is destructive.,False,0,MEMBER
https://api.github.com/repos/compat-table/compat-table/issues/comments/562971327,Improve historical Node data,zloirock,35,534536830,11,562971327,0,562970813,2019-12-08T17:19:19Z,"...and now we store data with

> difference in 10 Chrome / V8 versions with the real result in 0.10, 0.12, iojs1, etc

One more time - if you wanna verify it on the real hardware - do it, I can't do it, no rule forces me to do this and it's not my or users problem.",False,0,COLLABORATOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/562974222,Improve historical Node data,chicoxyzzy,35,534536830,12,562974222,0,562971327,2019-12-08T17:51:53Z,I agree with @ljharb that adding unverified results is not what we were doing historically. +1 for removing unverifiable data.,False,0,MEMBER
https://api.github.com/repos/compat-table/compat-table/issues/comments/562975412,Improve historical Node data,zloirock,35,534536830,13,562975412,0,562974222,2019-12-08T18:03:51Z,Ok.,False,0,COLLABORATOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/562975986,Improve historical Node data,ljharb,35,534536830,14,562975986,0,562975412,2019-12-08T18:09:01Z,"To be clear, verification of everything prior to merge is what i asked for, not just removing the unverifiable ones. Did you try out every node version covered by this PR yourself?",False,0,MEMBER
https://api.github.com/repos/compat-table/compat-table/issues/comments/562976535,Improve historical Node data,zloirock,35,534536830,15,562976535,0,562975986,2019-12-08T18:13:56Z,"Feel free to check them all if you need it, it's not my problem. You wrote that you can't check 0.6-, so now it's work for you. I checked some of them selectively.",False,0,COLLABORATOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/562977382,Improve historical Node data,ljharb,35,534536830,16,562977382,0,562976535,2019-12-08T18:22:21Z,"The burden of verifying a change is on whoever wants to land it; you don’t land things without tests and say “not my problem, write the tests yourself”.",False,0,MEMBER
https://api.github.com/repos/compat-table/compat-table/issues/comments/562977914,Improve historical Node data,zloirock,35,534536830,17,562977914,0,562977382,2019-12-08T18:27:49Z,"If you don't wanna improve this project - please, don't cause problems for those who want to do this.",False,0,COLLABORATOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/562978183,Improve historical Node data,ljharb,35,534536830,18,562978183,0,562977914,2019-12-08T18:30:10Z,You haven’t improved it - reducing the data quality makes it worse. Leaving it frozen in time forever is more of an improvement than ruining the data quality.,False,0,MEMBER
https://api.github.com/repos/compat-table/compat-table/issues/comments/562978691,Improve historical Node data,zloirock,35,534536830,19,562978691,0,562978183,2019-12-08T18:35:22Z,"Apparently you can't read.

> difference in 10 Chrome / V8 versions with the real result in 0.10, 0.12, iojs1, etc

Perfect data quality -)",False,0,COLLABORATOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/563495653,Improve historical Node data,kangax,35,534536830,20,563495653,0,562978691,2019-12-09T23:59:27Z,"@zloirock @ljharb folks, you both reached out to me personally to resolve or comment on this. It's sad to see this come to this. Clearly, you both have strong opinions and I'm sure you both have reasons for doing things certain way. It's not my place to ""chose"" one of you or ban someone. It's not my personal project (anymore), I haven't been contributing to it in ages, and you've both done incredible work over the years — either with direct commits or reviewing and commenting on things.

So, how do we resolve this?

In most of the places I've worked at, the rule for merging is simple — a PR needs at least one thumb from another person. This usually avoids situations like this and shifts responsibility onto the majority of votes. A single person should not be able to make (potentially controversial) decisions.

I think this would be the most democratic and reasonable solution BUT I don't know if we have enough contributors (@chicoxyzzy seems to be the only other person) for this to work effectively? In absence of 3+ contributors, this could just lead to a painful drag where no one stamps and merges things (or blocks the other).

Let me know what you think.",False,0,COLLABORATOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/563496376,Improve historical Node data,ljharb,35,534536830,21,563496376,0,563495653,2019-12-10T00:01:44Z,"@kangax the unspoken rule we've tended to follow over the years is that two collaborators' approvals (counting the PR author's implicit one) is sufficient to merge, but that a block from any collab may never be overridden. This mirrors many other open source projects where 100% approval is not required, but 0% rejection is. (Many projects also make sure that a PR that is potentially controversial ""sits"" for awhile, to give the most people the best opportunity to review - iow, it wouldn't be acting in good faith to have two collaborators ""team up"" to rush and get PRs in before another has a chance to voice an objection)

I doubt we will have any issues with 2 of the 3 of us gaining approvals, and if we do, we can certainly come to an agreement on some kind of ""waiting period"" - but I don't think it's ever going to be a good idea to override objections of other collaborators.",False,0,MEMBER
https://api.github.com/repos/compat-table/compat-table/issues/comments/563500239,Improve historical Node data,zloirock,35,534536830,22,563500239,0,563496376,2019-12-10T00:16:20Z,"@kangax that makes sense. But...

Requirements of approvement that no one wanna check for some days (like #1518) is a bad idea.

Unreasonable block like in this case - it's bull shit. Actions of @ljharb are sabotage since it's adding fixes for Node 0.12 / 0.10 compat data mapping which currently is completely broken, still shown in the table and used by Babel. If he don't wanna improve `compat-table`, he should not interfere with those who do this. 2 approvements should beat a block.",False,0,COLLABORATOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/563505376,Improve historical Node data,ljharb,35,534536830,23,563505376,0,563500239,2019-12-10T00:37:04Z,"Who decides what's ""unreasonable"" though? If specific data for node 0.10 and 0.12 is broken, then a PR that fixes that - including manually verifying the new results - is a great PR to add!

However, just like bugfixes without regression tests are often not landed until those tests are written (whether that takes hours, days, or months), data that's allegedly an improvement but lacks manual verification can wait too until the proper checking is done.",False,0,MEMBER
https://api.github.com/repos/compat-table/compat-table/issues/comments/563506456,Improve historical Node data,zloirock,35,534536830,24,563506456,0,563505376,2019-12-10T00:41:14Z,"@ljharb feel free to check it. Current `node` script does not work in ancient versions, I have no access to some ancient Node versions - but I'm sure in the results. If you are not sure - you can rewrite the script, check it and update the result. Forcing me to do this as part of this PR is stupid.",False,0,COLLABORATOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/563506894,Improve historical Node data,ljharb,35,534536830,25,563506894,0,563506456,2019-12-10T00:42:56Z,"The attitude of ""feel free to do the extra work yourself"" is the one I'm taking issue with. The burden of doing the work is on the PR author (the person making the change), not anyone else. If you're interested in your change landing, it's *on you* to satisfy the other decisionmakers on the project.

I'm not aware of any multiple-contributor project - open source or corporate - that works differently.",False,0,MEMBER
https://api.github.com/repos/compat-table/compat-table/issues/comments/563507991,Improve historical Node data,zloirock,35,534536830,26,563507991,0,563506894,2019-12-10T00:47:19Z,"Sorry, but you have not been adding anything to this project for many years - only periodically review PRs. It’s not for you to force me to rewrite this script and manually test hundreds of Node versions and spend dozen of hours for that.

Maybe also I should buy hardware where I should test them?

Maybe also I should manually test all Opera Mobile or Samsung Internet version and buy hardware for that? -) The same Chromium / V8 mapping like here. About built-ins related differences in Node with Chromium I know from the changelogs.",False,0,COLLABORATOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/563509282,Improve historical Node data,ljharb,35,534536830,27,563509282,0,563507991,2019-12-10T00:52:44Z,"Reviewing PRs *is* adding value to projects; code is not the only (or even the most important) kind of contribution.

I'm not sure what your development environment is that means you can't test various node versions - but yes, if you're incapable of testing an environment and also can't find someone willing to volunteer, then you are not able to reliably make changes to that environment's data. I""m not asking you to rewrite any script (nor do I see any such script; perhaps adding that to the PR would encourage volunteers to help) - but you are asking the rest of us to accept untested data.",False,0,MEMBER
https://api.github.com/repos/compat-table/compat-table/issues/comments/563510150,Improve historical Node data,zloirock,35,534536830,28,563510150,0,563509282,2019-12-10T00:56:25Z,"You wrote that you can test Node >=0.6 - I asked you about it - but it seems you can only ""review"" PRs and enforce others to do something -) Yes, reviewing has a value - but, in this case, without adding something new - very small value.",False,0,COLLABORATOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/563512230,Improve historical Node data,ljharb,35,534536830,29,563512230,0,563510150,2019-12-10T01:04:43Z,"That i have the capability doesn’t mean i have the time.

Maintaining invariants is a much larger value than adding something new.",False,0,MEMBER
https://api.github.com/repos/compat-table/compat-table/issues/comments/563514616,Improve historical Node data,zloirock,35,534536830,30,563514616,0,563512230,2019-12-10T01:14:43Z,"Maintaining invariants is a much larger value than just reviewing PRs without deep knowledge of the project. You are ""maintain"" too many projects - but how many of them you know enough good?

At this moment for this project adding new content required much more than reviewing PRs.

If you don't have the time - it does not mean that I have time for that. Even in the scope of this project, I can spend time much more productive. However, this fix required and ASAP.",False,0,COLLABORATOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/563524925,Improve historical Node data,ljharb,35,534536830,31,563524925,0,563514616,2019-12-10T01:25:14Z,"I don’t see why - nothing in the PR indicates a concrete bug or problem being fixed. Note the “no description given” in the part of the PR where you’re supposed to explain why the change is needed and important? https://chris.beams.io/posts/git-commit/ may be helpful.

@kangax I’m afraid that it’s unlikely either of us will change our stance; i think the real question you will need to dictate is whether a PR can be merged through a block, or not. The rest is something that we can hopefully figure out with ourselves with the hope that we’re all operating in good faith.",False,0,MEMBER
https://api.github.com/repos/compat-table/compat-table/issues/1559,String.prototype.matchAll fixed on Firefox 73,afmenez,5,534586266,1,534586266,0,0,2019-12-08T19:13:01Z,String.prototype.matchAll now throws on non-global regEx.,True,0,CONTRIBUTOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/562982978,String.prototype.matchAll fixed on Firefox 73,chicoxyzzy,5,534586266,2,562982978,0,534586266,2019-12-08T19:20:33Z,The first two commits in this PR are not related to `String.prototype.matchAll`,False,0,MEMBER
https://api.github.com/repos/compat-table/compat-table/issues/comments/562983117,String.prototype.matchAll fixed on Firefox 73,afmenez,5,534586266,3,562983117,0,562982978,2019-12-08T19:22:00Z,"Yep, and they are not even mine.  Don't know how they appeared here.",False,0,CONTRIBUTOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/562983217,String.prototype.matchAll fixed on Firefox 73,zloirock,5,534586266,4,562983217,0,562983117,2019-12-08T19:23:12Z,Seems @ljharb forced pushed to `gh-pages` :-D,False,0,COLLABORATOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/562983585,String.prototype.matchAll fixed on Firefox 73,ljharb,5,534586266,5,562983585,0,562983217,2019-12-08T19:27:05Z,indeed; those commits shouldn't be on master.,False,0,MEMBER
https://api.github.com/repos/compat-table/compat-table/issues/comments/562983633,String.prototype.matchAll fixed on Firefox 73,zloirock,5,534586266,6,562983633,0,562983585,2019-12-08T19:27:27Z,They should be.,False,0,COLLABORATOR
https://api.github.com/repos/compat-table/compat-table/issues/1560,Mark Chrome 79 as stable,zloirock,4,535402886,1,535402886,0,0,2019-12-09T23:40:30Z,,True,0,COLLABORATOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/563530706,Mark Chrome 79 as stable,chicoxyzzy,4,535402886,2,563530706,0,535402886,2019-12-10T01:29:38Z,Chrome 79 stable is not released yet https://omahaproxy.appspot.com,False,0,MEMBER
https://api.github.com/repos/compat-table/compat-table/issues/comments/563533629,Mark Chrome 79 as stable,ljharb,4,535402886,3,563533629,0,563530706,2019-12-10T01:31:50Z,"lol, guess this should be reverted then",False,0,MEMBER
https://api.github.com/repos/compat-table/compat-table/issues/comments/563534585,Mark Chrome 79 as stable,zloirock,4,535402886,4,563534585,0,563533629,2019-12-10T01:32:34Z,"Yep, I don't know why @ljharb merged it too early. Anyway, it's not a problem since it will be released today. I don't think that any actions required.",False,0,COLLABORATOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/563535843,Mark Chrome 79 as stable,ljharb,4,535402886,5,563535843,0,563534585,2019-12-10T01:33:29Z,"Fair, i assumed i could trust the PR title, and that a stable PR wouldn’t go up until it was actually stable. I’ll be more careful in the future",False,0,MEMBER
https://api.github.com/repos/compat-table/compat-table/issues/1561,Feature/sticky header improvement,everdimension,8,535630068,1,535630068,0,0,2019-12-10T10:19:12Z,"Use CSS for sticky header.
Remove jquery plugin.

I made screen recordings to compare before and after, but files are too large for github ¯\_(ツ)_/¯ ",True,0,CONTRIBUTOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/564022406,Feature/sticky header improvement,zloirock,8,535630068,2,564022406,0,535630068,2019-12-10T13:02:12Z,(http://raw.githack.com/everdimension/compat-table/feature/sticky-header-improvement/es6/index.html),False,0,COLLABORATOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/564024969,Feature/sticky header improvement,zloirock,8,535630068,3,564024969,0,564022406,2019-12-10T13:09:53Z,"IE11:
![image](https://user-images.githubusercontent.com/2213682/70532096-e03fc800-1b88-11ea-9b22-a1e2e94d4c9b.png)

The header is not sticky and overlaps the top rows of the table.",False,0,COLLABORATOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/564043292,Feature/sticky header improvement,everdimension,8,535630068,4,564043292,0,564024969,2019-12-10T13:56:09Z,"@zloirock Right, thanks for noticing.
Fixed the overlapping.

I believe it's alright to lose the sticky behavior in ie11 at this time.",False,0,CONTRIBUTOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/564050994,Feature/sticky header improvement,zloirock,8,535630068,5,564050994,0,564043292,2019-12-10T14:13:47Z,"Seems not fixed, I don't see any changes in IE11 -/",False,0,COLLABORATOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/564071367,Feature/sticky header improvement,everdimension,8,535630068,6,564071367,0,564050994,2019-12-10T14:57:36Z,"@zloirock Perhaps you're seeing cached results

Here's what I see in IE11 after the update:
![image](https://user-images.githubusercontent.com/5347023/70540537-7e766280-1b76-11ea-8a8b-6d0578fbce58.png)
",False,0,CONTRIBUTOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/564072509,Feature/sticky header improvement,zloirock,8,535630068,7,564072509,0,564071367,2019-12-10T15:00:06Z,"I checked it on another VM. Ok, let's check it again...",False,0,COLLABORATOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/564074501,Feature/sticky header improvement,zloirock,8,535630068,8,564074501,0,564072509,2019-12-10T15:04:06Z,"Ok, fixed, it seems it was cached on github / githack side.",False,0,COLLABORATOR
https://api.github.com/repos/compat-table/compat-table/issues/comments/1488984391,Feature/sticky header improvement,sedghi,8,535630068,9,1488984391,0,564074501,2023-03-29T17:07:12Z,should the `feature name` row be sticky? since it is not right now,False,0,NONE
https://api.github.com/repos/nim-lang/Nim/issues/12849,Incompatible type runtime error with table assignment,zqqw,4,534555312,1,534555312,0,0,2019-12-08T15:11:50Z,"Incompatible type runtime error with table assignment
(https://forum.nim-lang.org/t/5654)

### Example
```
let satisfied = toTable[package.PackageReference, syncinstall.SatisfyResult] (pkgInfos.map(p => ((p.name, none(string), none(VersionConstraint)),

    (false, p.name, some(p)))))

    testtable2 = initTable[package.PackageReference, syncinstall.SatisfyResult](1024)

    testtable2 = satisfied
```
### Current Output
```
resolving dependencies...
testnewseq1 =
@[(packref: subtitleripper, satres: (installed: false, name: ""subtitleripper"", buildPkgInfo: Some((baseIndex: 0, baseCount: 1, archs: @[""x86_64""], url: Some(""http://subtitleripper.sourceforge.net/""), licenses: @[""GPL""], groups: @[], pgpKeys: @[], depends: @[netpbm], makeDepends: @[make, gcc], checkDepends: @[], optional: @[], provides: @[], conflicts: @[], replaces: @[], repo: ""aur"", base: ""subtitleripper"", name: ""subtitleripper"", version: ""0.5.2-2"", description: Some(""DVD subtitle to text converter""), maintainer: Some(""init""), firstSubmitted: Some(1484683508), lastModified: Some(1574810177), outOfDate: None[int64], votes: 3, popularity: 0.376722, gitUrl: ""https://aur.archlinux.org/subtitleripper.git"", gitSubdir: None[TaintedString]))))]
satisfied =
{subtitleripper: (installed: false, name: ""subtitleripper"", buildPkgInfo: Some((baseIndex: 0, baseCount: 1, archs: @[""x86_64""], url: Some(""http://subtitleripper.sourceforge.net/""), licenses: @[""GPL""], groups: @[], pgpKeys: @[], depends: @[netpbm], makeDepends: @[make, gcc], checkDepends: @[], optional: @[], provides: @[], conflicts: @[], replaces: @[], repo: ""aur"", base: ""subtitleripper"", name: ""subtitleripper"", version: ""0.5.2-2"", description: Some(""DVD subtitle to text converter""), maintainer: Some(""init""), firstSubmitted: Some(1484683508), lastModified: Some(1574810177), outOfDate: None[int64], votes: 3, popularity: 0.376722, gitUrl: ""https://aur.archlinux.org/subtitleripper.git"", gitSubdir: None[TaintedString])))}
testtable2 assignment
/home/name/projects/pakku/zqqw-pakku-git/makepkg/src/pakku/src/main.nim(263) main
/home/name/projects/pakku/zqqw-pakku-git/makepkg/src/pakku/src/main.nim(254) run
/home/name/projects/pakku/zqqw-pakku-git/makepkg/src/pakku/src/main.nim(132) handleSync
/home/name/projects/pakku/zqqw-pakku-git/makepkg/src/pakku/src/feature/syncinstall.nim(1442) handleSyncInstall
/home/name/projects/pakku/zqqw-pakku-git/makepkg/src/pakku/src/feature/syncinstall.nim(1212) handleInstall
/home/name/projects/pakku/zqqw-pakku-git/makepkg/src/pakku/src/feature/syncinstall.nim(735) resolveDependencies
/home/name/projects/pakku/zqqw-pakku-git/makepkg/src/pakku/src/feature/syncinstall.nim(307) findDependencies
/usr/lib/nim/system/assign.nim(147) genericSeqAssign
/usr/lib/nim/system/assign.nim(111) genericAssign
/usr/lib/nim/system/assign.nim(76) genericAssignAux
/usr/lib/nim/system/assign.nim(100) genericAssignAux
/usr/lib/nim/system/assign.nim(24) genericAssignAux
/usr/lib/nim/system/assign.nim(20) genericAssignAux
/usr/lib/nim/system/assign.nim(100) genericAssignAux
/usr/lib/nim/system/assign.nim(24) genericAssignAux
/usr/lib/nim/system/assign.nim(20) genericAssignAux
/usr/lib/nim/system/assign.nim(100) genericAssignAux
/usr/lib/nim/system/assign.nim(24) genericAssignAux
/usr/lib/nim/system/assign.nim(20) genericAssignAux
/usr/lib/nim/system/assign.nim(97) genericAssignAux
/usr/lib/nim/system/fatal.nim(39) sysFatal
Error: unhandled exception: invalid object assignment [ObjectAssignmentError]

```

### Expected Output
With older versions of nim the assignment did not cause the runtime exception.

### Possible Solution
?

### Additional Information
I pushed my updates and testing code which simplifies / highlights the problem to here:
https://github.com/zqqw/pakku
So if anyone was using an Arch based distro you could modify the AUR pakku-git PKGBUILD to point there and easily make it with makepkg. Also the makefile is edited to not make a release build for better error messages.
The same failure happens with an unmodified syncinstall.nim so I am pretty sure it's the pre-existing code that no longer works.  
* It was working a while back but not the last couple of versions of Nim in Artix I think. 
* Pakku does not work with the latest Nim versions even when the deprecation errors are fixed so it builds. Pakku is a popular AUR helper used in Arch derived distros and users would like it working again.

```
$ nim -v
Nim Compiler Version 1.0.4 [Linux: amd64]
Compiled at 2019-11-27
Copyright (c) 2006-2019 by Andreas Rumpf

active boot switches: -d:release -d:nativeStackTrace

```
",True,0,NONE
https://api.github.com/repos/nim-lang/Nim/issues/comments/568588341,Incompatible type runtime error with table assignment,zqqw,4,534555312,2,568588341,0,534555312,2019-12-23T21:40:59Z,"kitsunyan has now released an updated version of Pakku that avoids this issue. To make a fork of that because I had a fork of a fork I deleted my original mentioned above, but could probably push that point in another branch if you wanted. kitsunyan's changes were made in previously unpublished commits on 22 October 2018 so they are dated to then but come after ""fixed bash.patch"" in the git log history which was my start point, although are not shown like that in the git hub commit history page which shows commits in date order.
So the issue has been resolved in respect of pakku not working although whether you think it still demonstrates a problem with Nim is up to you to decide.
```
$ git log

commit 8c75dc9df518579cab48a6ded803bf8d493a3cab (HEAD -> lc-for, tag: v0.14, origin/master, origin/HEAD, master)
Author: kitsunyan <kitsunyan@airmail.cc>
Date:   Fri Dec 20 08:01:42 2019 +0300

    Release 0.14

commit cb433c355d168a0a0c0de2538b372f1fab18b868
Author: kitsunyan <kitsunyan@airmail.cc>
Date:   Fri Dec 20 07:52:44 2019 +0300

    Fix some deprecations

commit 90d4c4be3bc15b2f594a0046c07b6f8654659ad5
Author: kitsunyan <kitsunyan@airmail.cc>
Date:   Fri Dec 20 07:35:07 2019 +0300

    Add Nim 1.0 support

commit a25e544b717edab821779b4e7d978e8bf24debcb
Author: kitsunyan <kitsunyan@airmail.cc>
Date:   Mon Oct 22 16:26:13 2018 +0300

    Replace package target object tree with tuples

commit d125243edc87a4bc961c7976f73fb2248050effb
Author: kitsunyan <kitsunyan@airmail.cc>
Date:   Mon Oct 22 16:07:40 2018 +0300

    Replace package info object tree with tuples

commit 55507df52ba95c2d97f02f2c4d0cdd2355cadaa2
Author: kitsunyan <kitsunyan@airmail.cc>
Date:   Mon Oct 22 14:22:24 2018 +0300

    Replace config object tree with tuples

commit a953c4c49cff505b16d08d87a58962a878bc5127
Author: Bruno Miguel <brunoalexandremiguel@gmail.com>
Date:   Wed Oct 23 13:36:58 2019 +0100

    fixed bash.patch
```",False,0,NONE
https://api.github.com/repos/nim-lang/Nim/issues/comments/791950921,Incompatible type runtime error with table assignment,ringabout,4,534555312,3,791950921,0,568588341,2021-03-06T14:03:07Z,Please provide a reproducible example,False,0,MEMBER
https://api.github.com/repos/nim-lang/Nim/issues/comments/791975695,Incompatible type runtime error with table assignment,zqqw,4,534555312,4,791975695,0,791950921,2021-03-06T15:51:24Z,"This was so long ago I can't really remember what the problem was, it was some build error after a Nim version update, it was fixed in Pakku ages ago.",False,0,NONE
https://api.github.com/repos/nim-lang/Nim/issues/comments/791978245,Incompatible type runtime error with table assignment,ringabout,4,534555312,5,791978245,0,791975695,2021-03-06T16:03:55Z,"thanks, feel free to reopen if someone can find more concrete examples.",False,0,MEMBER
https://api.github.com/repos/nim-lang/Nim/issues/12850,os.GetAppFileName  return error bug?,wiremoons,3,534560490,1,534560490,0,0,2019-12-08T15:49:38Z,"### Test Code
Running the following test code file 'getapptest.nim':
```
import os

echo ""With empty brackets : "", getAppFileName() # <-- compiles ok
echo ""With NO brackets : "", getAppFileName # <-- compile fails
echo ""done""
```
Generates the following error on compile:
```
$ nim c -r ./getapptest.nim 
Hint: used config file '/opt/nim/config/nim.cfg' [Conf]
Hint: system [Processing]
Hint: widestrs [Processing]
Hint: io [Processing]
Hint: getapptest [Processing]
Hint: os [Processing]
Hint: strutils [Processing]
Hint: parseutils [Processing]
Hint: math [Processing]
Hint: bitops [Processing]
Hint: macros [Processing]
Hint: algorithm [Processing]
Hint: unicode [Processing]
Hint: pathnorm [Processing]
Hint: osseps [Processing]
Hint: posix [Processing]
Hint: times [Processing]
Hint: options [Processing]
Hint: typetraits [Processing]
/home/simon/projects/code/nim/system/getapptest.nim(4, 29) Error: type mismatch: got <proc (): string{.gcsafe, locks: <unknown>.}>
but expected one of: 
proc `$`(x: bool): string
  first type mismatch at position: 1
  required type for x: bool
  but expression 'getAppFilename' is of type: proc (): string{.gcsafe, locks: <unknown>.}
proc `$`(x: int64): string
  first type mismatch at position: 1
  required type for x: int64
  but expression 'getAppFilename' is of type: proc (): string{.gcsafe, locks: <unknown>.}
proc `$`(x: cstring): string
  first type mismatch at position: 1
  required type for x: cstring
  but expression 'getAppFilename' is of type: proc (): string{.gcsafe, locks: <unknown>.}
proc `$`(x: char): string
  first type mismatch at position: 1
  required type for x: char
  but expression 'getAppFilename' is of type: proc (): string{.gcsafe, locks: <unknown>.}
proc `$`(t: typedesc): string
  first type mismatch at position: 1
  required type for t: typedesc
  but expression 'getAppFilename' is of type: proc (): string{.gcsafe, locks: <unknown>.}
proc `$`[T](x: openArray[T]): string
  first type mismatch at position: 1
  required type for x: openArray[T]
  but expression 'getAppFilename' is of type: proc (): string{.gcsafe, locks: <unknown>.}
proc `$`[T, IDX](x: array[IDX, T]): string
  first type mismatch at position: 1
  required type for x: array[IDX, T]
  but expression 'getAppFilename' is of type: proc (): string{.gcsafe, locks: <unknown>.}
proc `$`(s: WideCString): string
  first type mismatch at position: 1
  required type for s: WideCString
  but expression 'getAppFilename' is of type: proc (): string{.gcsafe, locks: <unknown>.}
proc `$`(x: int): string
  first type mismatch at position: 1
  required type for x: int
  but expression 'getAppFilename' is of type: proc (): string{.gcsafe, locks: <unknown>.}
proc `$`[T: tuple |
    object](x: T): string
  first type mismatch at position: 1
  required type for x: T: tuple or object
  but expression 'getAppFilename' is of type: proc (): string{.gcsafe, locks: <unknown>.}
proc `$`(x: float): string
  first type mismatch at position: 1
  required type for x: float
  but expression 'getAppFilename' is of type: proc (): string{.gcsafe, locks: <unknown>.}
proc `$`(x: uint64): string
  first type mismatch at position: 1
  required type for x: uint64
  but expression 'getAppFilename' is of type: proc (): string{.gcsafe, locks: <unknown>.}
proc `$`(w: WideCString; estimate: int; replacement: int = 0x0000FFFD): string
  first type mismatch at position: 1
  required type for w: WideCString
  but expression 'getAppFilename' is of type: proc (): string{.gcsafe, locks: <unknown>.}
proc `$`[T](x: set[T]): string
  first type mismatch at position: 1
  required type for x: set[T]
  but expression 'getAppFilename' is of type: proc (): string{.gcsafe, locks: <unknown>.}
proc `$`[Enum: enum](x: Enum): string
  first type mismatch at position: 1
  required type for x: Enum: enum
  but expression 'getAppFilename' is of type: proc (): string{.gcsafe, locks: <unknown>.}
proc `$`[T, U](x: HSlice[T, U]): string
  first type mismatch at position: 1
  required type for x: HSlice[$.T, $.U]
  but expression 'getAppFilename' is of type: proc (): string{.gcsafe, locks: <unknown>.}
proc `$`[T](x: seq[T]): string
  first type mismatch at position: 1
  required type for x: seq[T]
  but expression 'getAppFilename' is of type: proc (): string{.gcsafe, locks: <unknown>.}
proc `$`(x: string): string
  first type mismatch at position: 1
  required type for x: string
  but expression 'getAppFilename' is of type: proc (): string{.gcsafe, locks: <unknown>.}
proc `$`(err: OSErrorCode): string
  first type mismatch at position: 1
  required type for err: OSErrorCode
  but expression 'getAppFilename' is of type: proc (): string{.gcsafe, locks: <unknown>.}

expression: `$`(getAppFilename)
```

### Expected Output
I expect both calls to the same function `getAppFileName` to return successfully with the path and name of the application. Adding brackets to both calls (ie alter the code above so both calls are made as: `getAppFileName()` ) produces this output:
```
nim c -r ./getapptest.nim 
Hint: used config file '/opt/nim/config/nim.cfg' [Conf]
Hint: operation successful (300 lines compiled; 0.087 sec total; 5.754MiB peakmem; Debug Build) [SuccessX]
Hint: /home/simon/projects/code/nim/system/getapptest  [Exec]
With empty brackets : /home/simon/projects/code/nim/system/getapptest
With NO brackets : /home/simon/projects/code/nim/system/getapptest
done
```
 
### Possible Solution
Not sure if it is a bug - as I am new to Nim. However my understanding is that the brackets are optional when calling a proceedure with no required parameters? Mybe there are exceptions, or I am missunderstanding something. Reporting it just in case though!

### Additional Information
Code tested on two different computers (Raspberry Pi 4B Raspbian Buster and Alienware laptop Ubuntu 19.10)

```
$ nim -v

Nim Compiler Version 1.0.4 [Linux: amd64]
Compiled at 2019-11-27
Copyright (c) 2006-2019 by Andreas Rumpf

git hash: c8998c498f5e2a0874846eb31309e1d1630faca6
active boot switches: -d:release
```
and
```
Nim Compiler Version 1.0.4 [Linux: arm]
Compiled at 2019-11-27
Copyright (c) 2006-2019 by Andreas Rumpf

git hash: c8998c498f5e2a0874846eb31309e1d1630faca6
active boot switches: -d:release
```
",True,0,NONE
https://api.github.com/repos/nim-lang/Nim/issues/comments/562964084,os.GetAppFileName  return error bug?,SolitudeSF,3,534560490,2,562964084,0,534560490,2019-12-08T16:07:26Z,"its not a bug, `getAppFileName` is procedure as value, not the call of that procedure. you need to add brackets if you want to call a procedure with no arguments.

```nim
echo typeof getAppFileName    # proc (): string{.gcsafe, locks: <unknown>.}
echo typeof getAppFileName()  # string
```",False,0,CONTRIBUTOR
https://api.github.com/repos/nim-lang/Nim/issues/comments/562977241,os.GetAppFileName  return error bug?,wiremoons,3,534560490,3,562977241,0,562964084,2019-12-08T18:20:55Z,"Thank you for checking, and for providing the explaination @SolitudeSF - glad it is not a bug, just user error! 

Not sure I understand the diffeence betwen calling with or without the `()` yet, as I thought any call to the proceedure should return a string. The first call in your code below (without `()`) is returning the actual proceedure? Perhaps so it can be used in a functional programming way maybe... 

Guess I have some more reading and learing to do :) Part of the fun learning a new language!

> its not a bug, `getAppFileName` is procedure as value, not the call of that procedure. you need to add brackets if you want to call a procedure with no arguments.
> 
> ```nim
> echo typeof getAppFileName    # proc (): string{.gcsafe, locks: <unknown>.}
> echo typeof getAppFileName()  # string
> ```
",False,0,NONE
https://api.github.com/repos/nim-lang/Nim/issues/comments/562977873,os.GetAppFileName  return error bug?,nc-x,3,534560490,4,562977873,0,562977241,2019-12-08T18:27:30Z,"@wiremoons 
https://nim-lang.org/docs/manual.html#procedures-command-invocation-syntax
> Routines can be invoked without the () if the call is syntactically a statement. This command invocation syntax also works for expressions, but then only a single argument may follow. 
.....
Function calls with no arguments still needs () to distinguish between a call and the function itself as a first class value.
",False,0,CONTRIBUTOR
https://api.github.com/repos/nim-lang/Nim/issues/12860,Undefine `paramCount` & `paramStr` in nimscript.nim for *.nims,nc-x,7,534711332,1,534711332,0,0,2019-12-09T06:05:27Z,"(and fix error message on js target)
Closes https://github.com/nim-lang/Nim/issues/12835",True,0,CONTRIBUTOR
https://api.github.com/repos/nim-lang/Nim/issues/comments/563159360,Undefine `paramCount` & `paramStr` in nimscript.nim for *.nims,Araq,7,534711332,2,563159360,0,534711332,2019-12-09T10:10:35Z,It's better to remove them from ``nimscript.nim`` IMO.,False,0,MEMBER
https://api.github.com/repos/nim-lang/Nim/issues/comments/563219386,Undefine `paramCount` & `paramStr` in nimscript.nim for *.nims,Araq,7,534711332,3,563219386,0,563159360,2019-12-09T12:38:28Z,"Excellent work, now the only missing part is a changelog entry and backwards compat.",False,0,MEMBER
https://api.github.com/repos/nim-lang/Nim/issues/comments/619967733,Undefine `paramCount` & `paramStr` in nimscript.nim for *.nims,nc-x,7,534711332,4,619967733,0,563219386,2020-04-27T12:55:16Z,"This is now blocked on https://github.com/nim-lang/nimble/pull/797
After that PR is merged, need to update https://github.com/nim-lang/Nim/blob/664cb2c0be4e31d40cd3a5a2b9013f1afe47df97/koch.nim#L13
and this PR should (hopefully) be green.",False,0,CONTRIBUTOR
https://api.github.com/repos/nim-lang/Nim/issues/comments/620055670,Undefine `paramCount` & `paramStr` in nimscript.nim for *.nims,nc-x,7,534711332,5,620055670,0,619967733,2020-04-27T15:24:37Z,Ready to be merged.,False,0,CONTRIBUTOR
https://api.github.com/repos/nim-lang/Nim/issues/comments/620617819,Undefine `paramCount` & `paramStr` in nimscript.nim for *.nims,genotrance,7,534711332,6,620617819,0,620055670,2020-04-28T13:45:26Z,Isn't this a breaking change?,False,0,CONTRIBUTOR
https://api.github.com/repos/nim-lang/Nim/issues/comments/620939964,Undefine `paramCount` & `paramStr` in nimscript.nim for *.nims,Yardanico,7,534711332,7,620939964,0,620617819,2020-04-29T01:28:39Z,"Yeah, it is, I noticed when installing `golden` - https://github.com/xmonader/nim-terminaltables/blob/master/terminaltables.nimble uses paramCount and it **doesn't** work after this PR",False,0,COLLABORATOR
https://api.github.com/repos/nim-lang/Nim/issues/comments/621019276,Undefine `paramCount` & `paramStr` in nimscript.nim for *.nims,nc-x,7,534711332,8,621019276,0,620939964,2020-04-29T06:43:31Z,"@Yardanico 
Terminaltables was not in the tested packages list so it went unnoticed.
It would require a patch similar to https://github.com/Araq/ormin/pull/49/files to make it work with Nim version pre-1.3 as well as 1.3 and beyond.",False,0,CONTRIBUTOR
https://api.github.com/repos/nim-lang/Nim/issues/12862,The Defect exceptions are not consistently tracked,zah,17,534827216,1,534827216,0,0,2019-12-09T10:19:29Z,"In [RFC 77](https://github.com/nim-lang/RFCs/issues/77), it was proposed that `Defect` exception types should not be tracked. Since this proposal was not accepted, we should assume that the currently specified behaviour is that the compiler should be tracking them.

This can be confirmed with the following simple program:

```nim
proc foo(x: seq[int], i: int): int {.raises: [].} =
  if i >= x.len:
    #  Error: can raise an unlisted exception: ref IndexError
    raise newException(IndexError, ""index out of bounds"") 
  x[i]
```

Unfortunately, there are many alternative situations where the compiler is failing to enforce a similar empty `raises: []` list.

#### Indexing a sequence or array

```nim
proc foo(x: seq[int], i: int): int {.raises: [].} =
  x[i]

proc bar(x: array[10, int], i: int): int {.raises: [].} =
  x[i]
```

This program compiles without errors, even though it can raise `IndexError`.

#### Doing integer arithmetic

```nim
proc foo(x: int, y: int): int {.raises: [].} =
  x + y # This can fail with OverflowError
```

#### Assertions

```nim
proc foo(x: int, y: int): int {.raises: [].} =
  assert x < y
``` 

Please note that this example fails only because there is a deliberate hack in [lib/system/assertions.nim](https://github.com/nim-lang/Nim/blob/93461aee34244a6c004a5572f31a50ff4fad280d/lib/system/assertions.nim#L22-L27) trying to hide the `AssertionError` effect. It was introduced many years ago before we had the clear distinction between recoverable errors and defects.

### Expected behaviour

My expectation is that all of the above programs should fail to compile until the user has specified `raises: [Defect]` in the signature. Alternatively, if the RFC is accepted, the very first program that raises `IndexError` manually should start compiling.

```
$ nim -v
Nim Compiler Version 1.0.4
```
",True,0,MEMBER
https://api.github.com/repos/nim-lang/Nim/issues/comments/594464348,The Defect exceptions are not consistently tracked,arnetheduck,17,534827216,2,594464348,0,534827216,2020-03-04T11:19:22Z,"One thing I've wondered about is why more of the exception-raising behaviour isn't defined in the std lib - ie it seems that one should be able to have a `+` operator that checks for overflow and calls `sysFatal` instead of generating that code in the backend - what are issues with this approach?

@Araq ?

this is something I've considered for `wasm` as well as `nlvm`, both of which would be more simple if some of these things were moved to the library instead - I imagine getting consistency would be helped as well because the ""normal"" tracking that the compiler already does would apply.
",False,0,CONTRIBUTOR
https://api.github.com/repos/nim-lang/Nim/issues/comments/594478066,The Defect exceptions are not consistently tracked,Araq,17,534827216,3,594478066,0,594464348,2020-03-04T11:54:58Z,"> what are issues with this approach?

We're doing that slowly but it wasn't all that obvious how to write a ``+`` purely in the library that works at compile-time and at runtime and respects the ``--overflowChecks`` switch. 
",False,0,MEMBER
https://api.github.com/repos/nim-lang/Nim/issues/comments/594483454,The Defect exceptions are not consistently tracked,Araq,17,534827216,4,594483454,0,594478066,2020-03-04T12:07:39Z,"Let's analyse this snippet more closely, because I think the actual current implementation is better than the solutions the manual dreams about.

```nim

proc foo(x: seq[int], i: int): int {.raises: [].} =
  if i >= x.len:
    #  Error: can raise an unlisted exception: ref IndexError
    raise newException(IndexError, ""index out of bounds"") 
  x[i]
```

Imagine you read this as a new Nim programmer and that the compiler compiles this snippet. This is ""obviously"" a compiler bug! You do raise IndexError, claim you don't and the compiler swallows it. Yet, this is one proposed solution to the exception tracking problem. It doesn't feel right anymore. If the code raises an IndexError which is a bug indicator, it shouldn't have used ``raise``, but instead ``sysFatal`` (though preferable under a better name). And ``sysFatal`` can either cause a stack unwind or a direct process termination, depending on the compilation model. (This is also what Rust/Go do btw.)

So instead of making the distinction between ""uncatchable"" exceptions and ""catchable"" exceptions we should have a distinction between ``raise`` and ``sysFatal``. These are two separate things but encoding the difference in the exception hiearchy is the wrong design: It obfuscates what really happens, it never was implemented properly, and arguably it's harder to teach. All we really need to do is to expose ``sysFatal`` to libraries and document it properly. The implementation always had the right idea and there is little left to patch.
",False,0,MEMBER
https://api.github.com/repos/nim-lang/Nim/issues/comments/595071706,The Defect exceptions are not consistently tracked,arnetheduck,17,534827216,5,595071706,0,594483454,2020-03-05T07:34:18Z,"@zah had a hack/workaround in mind for that: `{.errors: [XXX].}` - basically something that would expand to `{.raises: [Defect, XXX].}`, and that users would use when they don't want to track defects (sometimes? often? most of the time? depends on the use case) - of course, this adds to the teaching burden because now you also have to remember the difference between the two.


With `sysFatal`:
* :+1:  the mechanisms are separate making a stronger distinction between the two modes - this is good because it's a lot easier to explain, and a lot harder to accidentally abuse - no longer do you run the risk of catching more than you intended with a naked `catch` - `rust` does a similar thing: normal errors go as return values, panics go as exceptions and require a special mechanism to contain
* :+1:  we can rethink what should happen for certain other tricky conditions, such as out-of-memory: when you have no more memory you cannot allocate a Defect either - C++ tends to reserve some memory for an exception instance for this reason - this is made easier if `Defect` cannot be inherited from because you can more easily bound the memory usage
* :-1: we lose the ability to have the compiler guarantee Defect-free code - this is easier / more common than one would think - ie overflow addition is well-defined for all inputs, and I'd like to have  a way to express / guarantee that there are no defects or exceptions at all - imagine writing a device driver, a real time or embedded system. This can perhaps be worked around by adding some other effect to track it? 

In rust, panic-free libraries are generally considered higher-quality because it's easier to reason about them and the generated code can be made more efficient - no stack unwinding, no alternate code paths that mess up the logic or crash the application.

Simply put, a `Defect`-free library can be used everywhere a `Defect`ive one can be used, but also in some other situations - they're more powerful - but the only way to be sure is if the compiler checks it.

The other way to deal with `sysFatal` would indeed be to follow rust and add a cumbersome way to ""catch"" them - but as the `rust` manual notes, there are some fatal defects that can't be caught (I imagine certain hardware exceptions or platform-specific things, stack overflow etc) - key here is that the internal delivery mechanism / implementation could be the same, but the ""keywords"" that developers use to deal with them would have to be separate and water-tight.
",False,0,CONTRIBUTOR
https://api.github.com/repos/nim-lang/Nim/issues/comments/595073490,The Defect exceptions are not consistently tracked,arnetheduck,17,534827216,6,595073490,0,595071706,2020-03-05T07:39:57Z,"one more issue with tracking raises as pragmas is that it's hard to express relations:

```
proc x(callback: proc () {.raises: [A])) {.raises: [...].}
```

how do I express x raises the same exceptions that the callback and nothing else? If raises were part of the ""ordinary"" type signature it seems like generics could be expanded to cover this scenario - it often happens in generic code in C++ for example, which is why they have a way to reason about it using `nothrow(true)` and `nothrow(false)` world - in particular, it allows them to write generic code that behaves differently if the callback can be guaranteed to not raise - there are many simplicity and efficiency gains to be had, specially when RAII is involved.


",False,0,CONTRIBUTOR
https://api.github.com/repos/nim-lang/Nim/issues/comments/595118483,The Defect exceptions are not consistently tracked,Araq,17,534827216,7,595118483,0,595073490,2020-03-05T09:21:09Z,">  we lose the ability to have the compiler guarantee Defect-free code - this is easier / more common than one would think - ie overflow addition is well-defined for all inputs, and I'd like to have a way to express / guarantee that there are no defects or exceptions at all - 

I think what people really want is **total** functions, they don't realize it though and it comes out as ""I want to be able to catch programming bugs in my server"". My ""quirky exceptions"" idea is a cheap way of enabling this -- instead of dying due to the error you set a global error flag and continue. If you break out after too many loop iterations/recursion levels automatically then also termination is guaranteed. So this is a way to make a function ``.total`` at runtime, it doesn't ""guarantee"" defect-free code, it uses brute force runtime mechanisms to ensure it. For example ``+`` would be mapped to a wrap around integer that can set the error flag. 

Crazy idea ahead: On out of memory the allocator sets the error flag and returns a pointer to a **single**, preallocated fixed size block of memory (that is big enough, if not, we terminate the process), then we have hundred of spurious writes before the upper layers detect the OOM condition and reject the result of a computation. But it could work.",False,0,MEMBER
https://api.github.com/repos/nim-lang/Nim/issues/comments/595134202,The Defect exceptions are not consistently tracked,arnetheduck,17,534827216,8,595134202,0,595118483,2020-03-05T09:52:22Z,"consider writing a bigint library (who would have thought, but we're up to about 6-7 now, turns out each cryptography library must have its own) - we really want to have defect-free addition for each limb and not quirky exceptions, because we a) want to pass the carry to the next limb and b) we want the compiler to tell us that we're not missing some weird edge condition as far as possible.

yes, ""terminating"" would be another nice guarantee, but since that's hard, ""loop-free"" could also be interesting since these tend to terminate as well. all these properties are orthogonal.

quirky, like float NaN is nice for side-effect-free stuff where you only care about some composite result being there or not, and you keep going as if nothing happened in the meantime - it doesn't always work/help though.

your OOM area would have to be per-thread I suspect. that's one of the things I remember as tricky from when I tried adding support for it in `nlvm` - the other being that the nim std lib api is broken/impossible to implement correctly when nested exceptions happen ;)",False,0,CONTRIBUTOR
https://api.github.com/repos/nim-lang/Nim/issues/comments/595182498,The Defect exceptions are not consistently tracked,Araq,17,534827216,9,595182498,0,595134202,2020-03-05T11:30:43Z,"> consider writing a bigint library (who would have thought, but we're up to about 6-7 now, turns out each cryptography library must have its own) - we really want to have defect-free addition for each limb and not quirky exceptions, because we a) want to pass the carry to the next limb and b) we want the compiler to tell us that we're not missing some weird edge condition as far as possible.

Ok, thanks, that clears things up. So when you say ""Defect"" you think about overflows and not so much about invalid array accesses.

> quirky, like float NaN is nice for side-effect-free stuff where you only care about some composite result being there or not, and you keep going as if nothing happened in the meantime - it doesn't always work/help though.

Certainly.",False,0,MEMBER
https://api.github.com/repos/nim-lang/Nim/issues/comments/595209991,The Defect exceptions are not consistently tracked,arnetheduck,17,534827216,10,595209991,0,595182498,2020-03-05T12:44:30Z,"> not so much about invalid array accesses.

Well, I just highlighted an example of where I've wanted not to have a Defect, recently :) I'm not even sure I'd see out-of-bounds array accesses as defects always - I mean one way to view an array is a dense table indexed by integers - at that point, accessing out of bounds is just another KeyError or whatever it's called. That's what I find tricky with Defects - there's no logic behind the distinction that clearly picks a winner - it's all context. @zah likes to explain that you should document an intended API and make a defect out of anything that doesn't conform (pre-conditions etc) but that's when I'm usually thinking that I'd rather it was part of the API instead so the compiler would tell me and not the documentation. 

The other reason is when you give up correctness for performance - this is usually the case for Defects - overflow is a good example - you kind of just hope that nobody will use big numbers and most of the time it works, enough that you as a programmer think that the user won't be too bothered by a crash, because although it's documented that integers have overflow checks sometimes, it's not like devs go off and actually write the code to avoid them. The eth2 specification had a bug like this - had it gone live, it would have been.. costly.

The last reason would be things that are outside of your control because by their nature, they're shared outside the scope of your application - memory, failing hardware etc etc - these are more clear cut, but then you wouldn't want to catch them, to begin with.

Nim has the advantage that it's a source-code-first language - that means that you can almost always fix the underlying defect if you want to. I guess that's also a reason to  make defects more strict and crash.",False,0,CONTRIBUTOR
https://api.github.com/repos/nim-lang/Nim/issues/comments/616640218,The Defect exceptions are not consistently tracked,arnetheduck,17,534827216,11,616640218,0,595209991,2020-04-20T15:48:51Z,"actually, `sysFatal` and the panic mode is somewhat orthogonal to `Defect` tracking - the defects can be tracked as an effect regardless if they are raised or panicked. 

In particular, even when the `panic` mode is on, the effect should not change, because if I type `raises: []` I don't want that to change behaviour depending on the panic flag - I want the compiler to guarantee  that there are no overflows or invalid array accesses or whatever else it might be in that particular piece of code.
",False,0,CONTRIBUTOR
https://api.github.com/repos/nim-lang/Nim/issues/comments/626865564,The Defect exceptions are not consistently tracked,Araq,17,534827216,12,626865564,0,616640218,2020-05-11T18:09:28Z,Exceptions inheriting from `Defect` are not tracked anymore. For even more control DrNim will prove your array indexing correct and eventually also that no overflows can happen.,False,0,MEMBER
https://api.github.com/repos/nim-lang/Nim/issues/comments/626882705,The Defect exceptions are not consistently tracked,arnetheduck,17,534827216,13,626882705,0,626865564,2020-05-11T18:40:05Z,"that's a bit unsatisfactory in that there's no feature available today then, that allows me to track not only things that drnim in a rosy future maybe will understand, but also things I develop in libraries of my own - with my own defects. ie I might consider out-of-diskspace a defect because it's such a bother to code for - likewise for a number of other defects that that would be easy to manage with a tracking feature here. tracking defects allow me to know when the author of a library I depend on changes their mind.

in summary, this is a bit the opposite of what would be useful for delineating code that doesn't have failure modes (say.. a hash function) from stuff that does. in particular, drnim will remain fundamentally limited in what it can analyse - for example, with exception tracking I can say that I want a callback to not raise anything, not even defects, and get a useful best-effort attempt (yes, minus stack overflow, maybe - but I can avoid memory allocations, integer operations, indexing errors etc by simply improving the structure of my code, for all total problems) that gives me some security.

we want to write Defect-free code, but to do that at scale, we need tools that lets us see  where the defects are coming from, generally - not prove that in some particular code path, defects don't happen and that there's a small optimization to be had..
",False,0,CONTRIBUTOR
https://api.github.com/repos/nim-lang/Nim/issues/comments/626907659,The Defect exceptions are not consistently tracked,Araq,17,534827216,14,626907659,0,626882705,2020-05-11T19:24:40Z,"I thought about adding ``.nodefects`` but there is not really an RFC for it. Please write one and then we can implement it. I cannot write it because I don't really understand what you need.
",False,0,MEMBER
https://api.github.com/repos/nim-lang/Nim/issues/comments/1030206467,The Defect exceptions are not consistently tracked,iacore,17,534827216,15,1030206467,0,626907659,2022-02-04T17:39:22Z,`array.pop()` is marked as `.nosideeffect.`... when the array is emtpy the program terminates. This feels wrong.,False,0,CONTRIBUTOR
https://api.github.com/repos/nim-lang/Nim/issues/comments/1030534676,The Defect exceptions are not consistently tracked,Araq,17,534827216,16,1030534676,0,1030206467,2022-02-05T06:02:09Z,"Read the manual, there is a definition for `.noSideEffect` and ""can raise due to a Defect"" is not part of the definition.",False,0,MEMBER
https://api.github.com/repos/nim-lang/Nim/issues/comments/1030571834,The Defect exceptions are not consistently tracked,iacore,17,534827216,17,1030571834,0,1030534676,2022-02-05T07:53:11Z,"Coming from a functional programming background, the name is confusing. Divergent from regular execution path is considered ""side effect"" in academic or nonacademic literature (like blog posts about programming). I think it's confusing enough to change it, since most people don't read the whole manual before they use Nim.",False,0,CONTRIBUTOR
https://api.github.com/repos/nim-lang/Nim/issues/comments/1032573326,The Defect exceptions are not consistently tracked,Araq,17,534827216,18,1032573326,0,1030571834,2022-02-08T12:49:51Z,"Haskell doesn't consider defects to be ""effects"" either:

```haskell

mydiv:: Integer -> Integer
mydiv b = (7 :: Integer) `div` b
-- can raise an exception but no monad required

main = putStrLn (show (mydiv 0))
```

> I think it's confusing enough to change it, since most people don't read the whole manual before they use Nim. 

Yet we don't punish the people who did read it by constantly renaming things.",False,0,MEMBER
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/3278,"Support more Sport Types, ie: map VirtualRun to Run",ph4r,5,544353320,1,544353320,0,0,2020-01-01T12:45:43Z,"I do over half of my training on Zwift currently, and Strava pulls in those events with Sport type set to VirtualRide or VirtualRun.  I just noticed that when that happens since the Sport is unknown the data is not included in trends and perhaps other areas (such as auto-finding appropriate intervals).  Some people like to keep indoor and outdoor metrics separate (as if they were separate sports); however, I am happy to consider them the same.  Option to suit me is to provide an Import Task to remap sports to a user list, or add these types as aliases automatically.  For the others a much more complicated solution may include an ability to create a new sport and choose how it is treated in total.",True,0,NONE
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/570057814,"Support more Sport Types, ie: map VirtualRun to Run",amtriathlon,5,544353320,2,570057814,0,544353320,2020-01-01T14:31:38Z,"On Strava download VirtualRun and VirtualRide should be mapped to Run and Bike respectively for the Sport field, and SubSport used to differentiate them, like in FIT file import.",False,0,MEMBER
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/570247811,"Support more Sport Types, ie: map VirtualRun to Run",ph4r,5,544353320,3,570247811,0,570057814,2020-01-02T15:48:49Z,"Elegant Code Change, I assume this this only works on newly synced activities?  Is there a non-manual method to update my existing database to match?",False,0,NONE
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/570250022,"Support more Sport Types, ie: map VirtualRun to Run",amtriathlon,5,544353320,4,570250022,0,570247811,2020-01-02T15:55:52Z,"Yes, the change is in download code. You can use set in the filter box to change existing activities:
`set(SubSport, Sport, Sport=""VirtualRun"")`
and then
`set(Sport, ""Run"", Sport=""VirtualRun"")`",False,0,MEMBER
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/570555503,"Support more Sport Types, ie: map VirtualRun to Run",ph4r,5,544353320,5,570555503,0,570250022,2020-01-03T12:09:06Z,"Thanks, I'm currently on V3.5-RC2X and SubSport isn't a field, so I used keywords for now and stored filters to update my Zwift Runs and Rides until this is released.

set(Keywords, Sport, Sport=""VirtualRun"")
set(Sport, ""Run"", Sport=""VirtualRun"")
set(Keywords, Sport, Sport=""VirtualRide"")
set(Sport, ""Bike"", Sport=""VirtualRide"")
",False,0,NONE
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/570556165,"Support more Sport Types, ie: map VirtualRun to Run",amtriathlon,5,544353320,6,570556165,0,570555503,2020-01-03T12:12:12Z,"Likely because your Athlete was created with a previous version, for new athletes it is create automatically, for existing ones you can add it, see the wiki for how to add metadata fields.",False,0,MEMBER
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/3279,HR Zones ,Fluxator,6,544384443,1,544384443,0,0,2020-01-01T18:18:33Z,"Workouts with sports other than Bike/Run/Swim are sometimes recorded for stress tracking via HR (TRIMP/Triscore). 
GC uses Bike HR zones  for TRIMP calculations even if other zones are defined for running. 
Most of the time the running zones would be more accurate. Dedicated zones for everything other than Bike/Run would be even better. ",True,0,NONE
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/570094121,HR Zones ,amtriathlon,6,544384443,2,570094121,0,544384443,2020-01-01T23:56:40Z,"If you prefer to use Run Zones for others sports you could set Sport=""Run"" and to use the SubSport field to differentiate them in filters.
The real solution is to make any sport first class generalizing Hr/Power/Pace zones for any sport, not just swim, bike and run. May be in the next release if there demand for it, I will open a feature request for this.",False,0,MEMBER
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/570095818,HR Zones ,Fluxator,6,544384443,3,570095818,0,570094121,2020-01-02T00:17:33Z,"> you could set Sport=""Run""

I thought about that, but it is has its disadvantages: 
- requires manual editing of workouts
- it messes up strava sync 
- it messes with filters

Feels like GC is quite close to supporting this but not quite there. 
I agree with the real solution, but that sounds like work. 
",False,0,NONE
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/570098492,HR Zones ,amtriathlon,6,544384443,4,570098492,0,570095818,2020-01-02T01:00:30Z,"Manual edit can be avoided using set in the filter box, for example if the Run-like sport is Row:
`set(SubSport, Sport, Sport=""Row"")` and then `set(Sport, ""Run"", Sport=""Row"")`
filters are easily changed in GC and wrt to Strava sync it could be a problem if you use upload, not for download only.
Yes, the generalization requires some design, coding and testing. Looking retrospectively would have been better to go that way from start, but we were adding sports incrementally and here we are.",False,0,MEMBER
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/570158638,HR Zones ,Fluxator,6,544384443,5,570158638,0,570098492,2020-01-02T09:44:58Z,"Thanks, it's not pretty, but it works. 

Alternatively, a simple change in GC would be to offer a checkbox ""use as default zone model"" in the bike/run zones and then use that for all sports other than bike/run. 
",False,0,NONE
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/570184426,HR Zones ,amtriathlon,6,544384443,6,570184426,0,570158638,2020-01-02T11:40:40Z,"> Alternatively, a simple change in GC would be to offer a checkbox ""use as default zone model"" in the bike/run zones and then use that for all sports other than bike/run.

IMHO that’s far from a simple change and, considering all the places in code involved, I would prefer to directly go to zones generalization.",False,0,MEMBER
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/570268355,HR Zones ,amtriathlon,6,544384443,7,570268355,0,570184426,2020-01-02T16:54:45Z,I'm closing this since it is subsumed in the more general https://github.com/GoldenCheetah/GoldenCheetah/issues/3280,False,0,MEMBER
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/3280,Generalize Power and HR zones for any sport,amtriathlon,13,544658428,1,544658428,0,0,2020-01-02T16:52:53Z,"Currently we have:
- Power Zones for Bike and Run, default Bike.
- HR Zones for Bike and Run, default Bike.
- Pace Zones for Run (min/km or min/mi) and Swim (min/100m or min/100yd), default Run.

Some users are using GC for sports other than S/B/R and they have requested to have zones specific for these.",True,0,MEMBER
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/610045518,Generalize Power and HR zones for any sport,amtriathlon,13,544658428,2,610045518,0,544658428,2020-04-06T21:26:01Z,"I plan to implement this in 3 parts:

1. Add normalized sport field to RideItem/RideDB as primary field deriving isRun/isSwim from it for compatibility plus isRide/isXtrain for consistency, use them in DataFilter and RideSummary.
Finished: https://github.com/GoldenCheetah/GoldenCheetah/commit/42fa49c50f91de3649469b705444061e4f4180d5
2. HR Zones for any sport, based on default for Bike
Finished: https://github.com/GoldenCheetah/GoldenCheetah/commit/380dc47ac772df6fdac5feb98c67f64941dee572
3. Power Zones for any sport, based on default for Bike
Finished: https://github.com/GoldenCheetah/GoldenCheetah/commit/3a07cc52d7cbecd5901acfccfc11be204683192a
4. Not sure about Pace Zones are useful for other sports than Run/Swim.
I will not implement this for now since Pace Zones doesn't seem to be common for other than Run/Swim.",False,0,MEMBER
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/624744137,Generalize Power and HR zones for any sport,srwareham,13,544658428,3,624744137,0,610045518,2020-05-06T16:13:53Z,"Just echoing that a min/500m pace for rowing would be amazing.

Are there plans for GC to be able to import/store other rowing data? I wouldn't anticipate the data would really be integrated for trends etc., at least for a good while. 

If helpful, I've attached a CSV of a Concept2 rowing workout recorded using the BoatCoach Android app. This is the only cloud-free way of capturing second-by-second workout data from an Erg that I've come across and might at least be a good starting point for a data model.
[boatcoach_2020-05-06__11-20-26.txt](https://github.com/GoldenCheetah/GoldenCheetah/files/4587946/boatcoach_2020-05-06__11-20-26.txt)

",False,0,NONE
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/624860364,Generalize Power and HR zones for any sport,liversedge,13,544658428,4,624860364,0,624744137,2020-05-06T20:02:48Z,"we support rowperfect3 files, with much of the stroke data going into xdata series, so could extend to include other formats too. will have a look at the file.

I don't row any more (have a C2 in the attic) so don't know if boatcoach is popular or just one that you use? Would like to support the most popular formats first ...",False,0,MEMBER
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/624972260,Generalize Power and HR zones for any sport,srwareham,13,544658428,5,624972260,0,624860364,2020-05-07T01:12:46Z,"The official app developed by Concept2 is called ErgRace, however, it does not record any session-level data. It was written by Dan Eiref. He then went on to write BoatCoach, which at least seems to be from the same code base. From my research it is the *only* non-cloud Android option that actually records on a second-by-second basis, however I'd be quite excited if anyone else had experience to the contrary.

I believe one of the most popular desktop solutions is [RowPro](http://www.digitalrowing.com/) however it's $99 and requires having a laptop connected to the Erg when rowing. Certainly not a great option for people who row at gyms.",False,0,NONE
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/625036199,Generalize Power and HR zones for any sport,liversedge,13,544658428,6,625036199,0,624972260,2020-05-07T05:25:02Z,"Have added a new issue #3434 for boatcoach support, can continue the dsicussion there.",False,0,MEMBER
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/625382455,Generalize Power and HR zones for any sport,amtriathlon,13,544658428,7,625382455,0,625036199,2020-05-07T17:08:56Z,"If you want a Row Pace metric, similar to Pace or Swim Pace but in min/500m units, you can add it as a custom metric like this:

![Row_Pace](https://user-images.githubusercontent.com/1444784/81323742-33e90b80-906c-11ea-8965-4e4dc96291b6.png)

I will upload it to CloudDB for v3.6",False,0,MEMBER
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/646775914,Generalize Power and HR zones for any sport,Mickyduck55,13,544658428,8,646775914,0,625382455,2020-06-19T17:30:45Z,"First time I have commented on here but I think a lot of people who row (on C2) will by now be using ErgData which Im sure you know is C2s App. and C2s online logbook I also have RowPro which seamlessly links to the C2 logbook.  From the C2 logbook I can export data as FIT... which I do and import to GC.  The data is displayed in the ride window and looks just like a ""ride"" with laps being logged as every 5 mins.  Happy to supply any files that are required from C2 logbook as CSV, TCX or FIT.... these are the export formats available, as I said FIT imports to GC without errors.",False,0,NONE
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/646805679,Generalize Power and HR zones for any sport,amtriathlon,13,544658428,9,646805679,0,646775914,2020-06-19T18:25:17Z,"Hi, if FIT is working I think we should use it as a richer and more compact format, if you want to add a sample it can be attached after zip compression.",False,0,MEMBER
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/646873108,Generalize Power and HR zones for any sport,amtriathlon,13,544658428,10,646873108,0,646805679,2020-06-19T21:51:55Z,"Thanks, but attachments by mail don't work, you need to drag&drop the zipped file on github site.",False,0,MEMBER
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/646878073,Generalize Power and HR zones for any sport,amtriathlon,13,544658428,11,646878073,0,646873108,2020-06-19T22:13:03Z,Where you wrote your first comment: https://github.com/GoldenCheetah/GoldenCheetah/issues/3280,False,0,MEMBER
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/646878156,Generalize Power and HR zones for any sport,Mickyduck55,13,544658428,12,646878156,0,646878073,2020-06-19T22:13:24Z,"Found it...

[Downloads.zip](https://github.com/GoldenCheetah/GoldenCheetah/files/4806870/Downloads.zip)
",False,0,NONE
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/646879932,Generalize Power and HR zones for any sport,amtriathlon,13,544658428,13,646879932,0,646878156,2020-06-19T22:20:41Z,"It looks good when imported, only problem is variable recording interval each 2-3 secs, but this is easy to solve using Edit > Fix Gaps, after that all GC metrics should be Ok.",False,0,MEMBER
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/646883233,Generalize Power and HR zones for any sport,amtriathlon,13,544658428,14,646883233,0,646879932,2020-06-19T22:33:09Z,"Likely because you have Smart Recording enabled in Options/Preferences so gaps are automatically interpolated on import, I would suggest to switch to users forum (https://groups.google.com/forum/#!forum/golden-cheetah-users) for any other question.",False,0,MEMBER
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/3284,Issue 3283: Use tangent vector to compute interpolated grade.,ericchristoffersen,6,545354521,1,545354521,0,0,2020-01-05T01:34:04Z,"This change has interpolated slope come from instant interpolated tangent vector instead of averaging slope across nearby samples. Along with correcting slope when riding ergfiles this massively improves the mergefile behavior in some cases.

Rename location interpolation method ""Interpolate"" to be ""Location"".

Change ErgFile::LocationAt and GradientAt to accept location as double instead of int. Location reporting was jumping all around when multiple gpx files were in a small area (interpolation now interpolates instead of snapping to nearest meter.)

This change helps refine training mode behavior. Should go in along with bicycle sim KE change.",True,0,CONTRIBUTOR
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/573234634,Issue 3283: Use tangent vector to compute interpolated grade.,ericchristoffersen,6,545354521,2,573234634,0,545354521,2020-01-10T22:43:06Z,Well... change is cool and correct but it extremely sensitive to having good gps points. I'm finding most gps data have stepwise altitude so route slope has too much variation. I am going to write a parameterized gps route smoothing filter (maybe based on NURBS.) This change should be considered only after there's a good way to smooth gps routes.,False,0,CONTRIBUTOR
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/573265219,Issue 3283: Use tangent vector to compute interpolated grade.,amtriathlon,6,545354521,3,573265219,0,573234634,2020-01-11T01:27:15Z,"No problem, I tagged this for 3.6 but I will not merge it until is ready!",False,0,MEMBER
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/575837994,Issue 3283: Use tangent vector to compute interpolated grade.,ericchristoffersen,6,545354521,4,575837994,0,573265219,2020-01-17T23:50:58Z,"Gpx is set of locaiton points of route. When gpx is loaded the average slope is computed between the points. When gps data is noisy the averaging will make very extreme slopes, sometimes oscillating quickly and always discontinuously.

These extreme slopes are much higher than a trainer can honor, and occur much faster than a trainer can respond, so these slopes are mostly not felt by the rider. The new KE based trainer code does honor the extreme slopes so the rider has their speed penalized but they don't get to appreciate the true horror of the climb because they won't experience correct pedal resistance.

This altitude noise is the root cause of a lot of pain when riding gpx files so I think we should offer a way to nicely smooth gpx route data - especially the altitude data where a few vertical meters in a short span can make a big difference. I have something working nicely using b-splines but haven't integrated into gc.

Current GC only allows to query slope from known points on the route.

This change introduces the ability to query gradient for all locations on the interpolated route spline, and trainer mode then uses that data to update slope more frequently. The current interpolation is cubic splines which have continuous derivatives so the slope changes will be smooth and correctly integrate over distance to the correct altitude. In practice with a nicely smoothed gpx this works really well.

The downside of this change is that when gps points oscillate wildly the cubic spline can make the extreme slopes even worse.
",False,0,CONTRIBUTOR
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/581047033,Issue 3283: Use tangent vector to compute interpolated grade.,ericchristoffersen,6,545354521,5,581047033,0,575837994,2020-02-01T16:42:50Z,"I found the root cause of the slope fluctuations... the cubic interpolator is only correct when samples are uniformly spaced. Most of the time it doesn't matter but causes significant artifacts when computing slope with non-uniform samples. A bunch of my ride files work great but a few have intereresting artifacts.

I've implemented an update to the cubic interpolator so it will be correct with non-uniform sample spacing. It cleans up all the artifacts. Good news is that all users of cubic splines will only benefit.

Anyway... please wait for another commit to fix the non-uniform sample spacing issue.",False,0,CONTRIBUTOR
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/581052705,Issue 3283: Use tangent vector to compute interpolated grade.,ericchristoffersen,6,545354521,6,581052705,0,581047033,2020-02-01T17:44:44Z,Just wrote above. I am working on another commit for this.,False,0,CONTRIBUTOR
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/581092113,Issue 3283: Use tangent vector to compute interpolated grade.,ericchristoffersen,6,545354521,7,581092113,0,581052705,2020-02-02T02:57:20Z,"Ok, this is good to go.",False,0,CONTRIBUTOR
https://api.github.com/repos/tpope/vim-fugitive/issues/1418,The mapping 'p' to jump to patch in preview window fails when previewpopup is not empty,jmdevin,18,540444697,1,540444697,0,0,2019-12-19T17:12:22Z,"### Vim Version
8.2
Included patches 1-19
`v:version` 802
### Issue
When the option 'previewpopup' is not empty, the default-mapped `p` (jump to patch or blob in preview window) throws E994 and then opens an empty preview-popup window.
### Steps to Reproduce
1. With vim-fugitive installed, open a git-tracked file in vim.
2. Do `:Gblame` on a line of the file.
3. Press `p` with cursor on any line.
4. See the following message:
```vimscript
Error detected while processing function fugitive#BufReadCmd[71]..<SNR>16_ReplaceCmd:
line 21:
E994: Not allowed in a popup window
```
**(Note: for the original reporter this always showed line 21)**
5. An empty preview-popup window opens.
### Expected Behavior/Suggested Fix
Either a regular preview window should be opened instead of a preview-popup window regardless of the value of `previewpopup` (if that is possible) or the preview-popup window should be supported.",True,0,NONE
https://api.github.com/repos/tpope/vim-fugitive/issues/comments/567593968,The mapping 'p' to jump to patch in preview window fails when previewpopup is not empty,tpope,18,540444697,2,567593968,0,540444697,2019-12-19T17:50:42Z,"`line X`?? What is X????? I think temporarily disabling `'previewpopup'` is the way to go, but I'd like to do a cursory inspection of what's going wrong (without needing to compile Vim 8.2).",False,0,OWNER
https://api.github.com/repos/tpope/vim-fugitive/issues/comments/567596352,The mapping 'p' to jump to patch in preview window fails when previewpopup is not empty,jmdevin,18,540444697,3,567596352,0,567593968,2019-12-19T17:57:45Z,"Well, X was meant to be whatever line you happened to be on when you hit `p`, but I'm redoing this now and it actually says `line 21` in the error message regardless of what line I'm on. I didn't realize that at first.",False,0,NONE
https://api.github.com/repos/tpope/vim-fugitive/issues/comments/567597366,The mapping 'p' to jump to patch in preview window fails when previewpopup is not empty,tpope,18,540444697,4,567597366,0,567596352,2019-12-19T18:00:40Z,https://github.com/tpope/vim-fugitive/blob/6d4564a05e6d974ae05623338a4579ae63ba4243/autoload/fugitive.vim#L1562 is line 21. Try changing `silent` to `silent!` and see if anything else fails.,False,0,OWNER
https://api.github.com/repos/tpope/vim-fugitive/issues/comments/567600654,The mapping 'p' to jump to patch in preview window fails when previewpopup is not empty,jmdevin,18,540444697,5,567600654,0,567597366,2019-12-19T18:10:28Z,"No difference. Same message and behavior.

And to be sure, I edited the file, saved it, closed and reopened vim and tried again. No difference.",False,0,NONE
https://api.github.com/repos/tpope/vim-fugitive/issues/comments/567601778,The mapping 'p' to jump to patch in preview window fails when previewpopup is not empty,tpope,18,540444697,6,567601778,0,567600654,2019-12-19T18:13:53Z,It still says line 21? Try deleting the line entirely.,False,0,OWNER
https://api.github.com/repos/tpope/vim-fugitive/issues/comments/567602340,The mapping 'p' to jump to patch in preview window fails when previewpopup is not empty,tpope,18,540444697,7,567602340,0,567601778,2019-12-19T18:15:29Z,"Just to make sure, you're on the latest version of Fugitive?",False,0,OWNER
https://api.github.com/repos/tpope/vim-fugitive/issues/comments/567604932,The mapping 'p' to jump to patch in preview window fails when previewpopup is not empty,jmdevin,18,540444697,8,567604932,0,567602340,2019-12-19T18:22:23Z,"Whoops, it changed to say line 12, not 21. I'll learn to read. Latest version of fugitive.

Now changing line 12's `silent` to `silent!` did get rid of the error message entirely. The preview-popup now just opens empty without complaint.",False,0,NONE
https://api.github.com/repos/tpope/vim-fugitive/issues/comments/567606294,The mapping 'p' to jump to patch in preview window fails when previewpopup is not empty,tpope,18,540444697,9,567606294,0,567604932,2019-12-19T18:25:44Z,"Try calling `:pedit somefile.gz`, where `somefile.gz` is a valid `.gz` file. Does that work?",False,0,OWNER
https://api.github.com/repos/tpope/vim-fugitive/issues/comments/567608370,The mapping 'p' to jump to patch in preview window fails when previewpopup is not empty,tpope,18,540444697,10,567608370,0,567606294,2019-12-19T18:31:37Z,Try `:pedit https://www.google.com/`too.,False,0,OWNER
https://api.github.com/repos/tpope/vim-fugitive/issues/comments/567609337,The mapping 'p' to jump to patch in preview window fails when previewpopup is not empty,jmdevin,18,540444697,11,567609337,0,567608370,2019-12-19T18:34:25Z,"`:pedit somefile.gz` works for me. It opens in a preview-popup window fine.

`:pedit https://www.google.com/` does not work; it gives E994 with a reference to some netrw functions.",False,0,NONE
https://api.github.com/repos/tpope/vim-fugitive/issues/comments/567612132,The mapping 'p' to jump to patch in preview window fails when previewpopup is not empty,tpope,18,540444697,12,567612132,0,567609337,2019-12-19T18:42:39Z,"Please file a Vim bug for the latter, and follow up when a solution is decided upon.

As an interim solution, you're also welcome to explore changing `ReplaceCmd()` to use `silent execute '$read' temp` when `&buftype =~# 'popup'`.",False,0,OWNER
https://api.github.com/repos/tpope/vim-fugitive/issues/comments/567618803,The mapping 'p' to jump to patch in preview window fails when previewpopup is not empty,jmdevin,18,540444697,13,567618803,0,567612132,2019-12-19T19:00:02Z,"Something weird to add, although it's still a vim bug so it won't reopen this. `:pedit https://www.google.com/` works if you first open it with `previewpopup` empty, then close it, set previewpopup to something, and open it again.",False,0,NONE
https://api.github.com/repos/tpope/vim-fugitive/issues/comments/567621470,The mapping 'p' to jump to patch in preview window fails when previewpopup is not empty,tpope,18,540444697,14,567621470,0,567618803,2019-12-19T19:07:22Z,"Presumably because the buffer is already in memory, so `BufReadCmd` doesn't get invoked again. Might be affected by `:set hidden?`.",False,0,OWNER
https://api.github.com/repos/tpope/vim-fugitive/issues/comments/567623719,The mapping 'p' to jump to patch in preview window fails when previewpopup is not empty,tpope,18,540444697,15,567623719,0,567621470,2019-12-19T19:13:38Z,"I was worried about file encoding issues with the `read` solution but it looks like `read ++edit` addresses this, so we can probably ditch the conditional and use that for everything. (`gzip.vim` uses `$read ++edit` and `netrw.vim` uses `file`/`edit!` just like Fugitive, which explains why one works and one breaks.)",False,0,OWNER
https://api.github.com/repos/tpope/vim-fugitive/issues/comments/567627950,The mapping 'p' to jump to patch in preview window fails when previewpopup is not empty,jmdevin,18,540444697,16,567627950,0,567623719,2019-12-19T19:24:37Z,"You were right, `https://www.google.com/` remained as an unlisted buffer in the buffer list. Not with `set hidden` though, that was off.",False,0,NONE
https://api.github.com/repos/tpope/vim-fugitive/issues/comments/567632091,The mapping 'p' to jump to patch in preview window fails when previewpopup is not empty,tpope,18,540444697,17,567632091,0,567627950,2019-12-19T19:35:55Z,`'bufhidden'` then.,False,0,OWNER
https://api.github.com/repos/tpope/vim-fugitive/issues/comments/567754472,The mapping 'p' to jump to patch in preview window fails when previewpopup is not empty,jmdevin,18,540444697,18,567754472,0,567632091,2019-12-20T01:57:18Z,"Ah, `'bufhidden'` was it. ",False,0,NONE
https://api.github.com/repos/tpope/vim-fugitive/issues/comments/574526174,The mapping 'p' to jump to patch in preview window fails when previewpopup is not empty,tpope,18,540444697,19,574526174,0,567754472,2020-01-15T07:07:23Z,"Too easy, I hope it didn't break anything.",False,0,OWNER
https://api.github.com/repos/tpope/vim-fugitive/issues/1420,Glog hide whitespaces,dihak,3,541727440,1,541727440,0,0,2019-12-23T12:09:45Z,How to hide the whitespaces diff after entered a commit in Glog command?,True,0,NONE
https://api.github.com/repos/tpope/vim-fugitive/issues/comments/568524717,Glog hide whitespaces,tpope,3,541727440,2,568524717,0,541727440,2019-12-23T16:52:56Z,What is a whitespaces diff?,False,0,OWNER
https://api.github.com/repos/tpope/vim-fugitive/issues/comments/568590253,Glog hide whitespaces,dihak,3,541727440,3,568590253,0,568524717,2019-12-23T21:52:13Z,"![image](https://user-images.githubusercontent.com/10445482/71382127-1e1d0180-2609-11ea-8e54-3fb070174faa.png)
",False,0,NONE
https://api.github.com/repos/tpope/vim-fugitive/issues/comments/568969967,Glog hide whitespaces,tpope,3,541727440,4,568969967,0,568590253,2019-12-26T04:58:08Z,"Not supported, but see #1109.",False,0,OWNER
https://api.github.com/repos/tpope/vim-fugitive/issues/1422,Gblame navigation,tkhai,5,542900715,1,542900715,0,0,2019-12-27T14:57:15Z,"This feature request is about possibility to navigate blame commits using a single key instead of keys combination. Say, we have:

commit1 (Author1              Date1)
commit2 (Author2              Date2)

and we want to see the both of commits sequentially.
Currently, this is possible only via opening in a new tab:
1)Press 'O' on commit1 (i.e., 'Shift + o' -- 2 keys)
2)Press "":q<CR> to return back (3 keys).
3)Goto commit2, etc
In case of there are a lot commits to see, this excess keys become a tiredness.
The problem is that there is no a way to remap 'Shift + o' to a single key, and the same is with ':q<CR>'. Another problem is that opening occurs in a new tab, that is not always comfortable for a user (tab is only possibility to open commit in full screen and return back later).

It would be great to have both of:
1)possibility to open commit in the same buffer (not in a new tab) via single key (configurable);
2)possibility to return back to blame lines list via a single key (configurable).

Thanks!",True,0,NONE
https://api.github.com/repos/tpope/vim-fugitive/issues/comments/569336498,Gblame navigation,odnoletkov,5,542900715,2,569336498,0,542900715,2019-12-27T20:03:06Z,"<kbd>p</kbd> might be a shortcut you are looking for:
```
                                                *fugitive_p*
p                       Open the file or |fugitive-object| under the cursor in
                        a preview window.  …
```",False,0,CONTRIBUTOR
https://api.github.com/repos/tpope/vim-fugitive/issues/comments/569381430,Gblame navigation,tpope,5,542900715,3,569381430,0,569336498,2019-12-28T03:38:57Z,"> 1)possibility to open commit in the same buffer (not in a new tab) via single key (configurable);

You mean open it in the blame window? That window has a really awkward width; I don't think this is a good idea.

> 2)possibility to return back to blame lines list via a single key (configurable).

I don't provide configuration options for things like this. You can `nmap <whatever> :q<CR>` without my help. (If I did your first idea, it would be `nmap <whatever> :e #<CR>`, but I don't think I'll be doing that.)",False,0,OWNER
https://api.github.com/repos/tpope/vim-fugitive/issues/comments/569607545,Gblame navigation,tkhai,5,542900715,4,569607545,0,569381430,2019-12-30T07:49:19Z,"> You mean open it in the blame window? That window has a really awkward width; I don't think this is a good idea.

Yes, I mean that. It should be possible to resize blame window on commit opening.

>You can nmap

This is only possible in case of opening a commit in a new tab. But my suggestion in general is to open a commit in the blame window.",False,0,NONE
https://api.github.com/repos/tpope/vim-fugitive/issues/comments/570086732,Gblame navigation,tpope,5,542900715,5,570086732,0,569607545,2020-01-01T21:57:06Z,Resize to what width? I don't think there's a one size fits all solution here.,False,0,OWNER
https://api.github.com/repos/tpope/vim-fugitive/issues/comments/570646487,Gblame navigation,tkhai,5,542900715,6,570646487,0,570086732,2020-01-03T17:50:57Z,"1)It does not matter . Something like 95% of screen or (screen_width - 1).

let c = float2nr(&columns * 100 / 95)
execute ""vertical resize"" . c

2)I just clarify my use case. I want to have a possibility to iterate blame commits on 5-10 neighbor strings. It's needed to return from commit back to blame window. Currently, the only possibility is to open a commit in a new tab with Shift+o, which is not comfortable. I always map frequently-used  combinations in a single key, but for Gblame it's not possible.

3)Also, it's not very intuitive, that CR in blame window destroys the window without any possibility to return back. Because Enter is common key for many utils. E.g., mc never deprives you a possibility to return to parent directory after you entered a child directory. The same is vim's netrw navigation.

Sadly, but Gblame behaves in another way. I use Gblame once a week, but every time I forget, that Enter kills blame window, and I have to wait second Gblame call after I pressed Enter and jumper to wrong commit.

I even have such the comment in vimrc, just to stop press Enter and to save my time on Gblame second call:
nnoremap \<S-F6\> :Gblame\<CR\>:echo ""O -- open commit in new tab, :q -- close commit""\<CR\>

So, maybe I had to write all of this in the initial description, but it's better later than never.

My experience is a user: jumping to wrong commit is a common case. Necessity to check commits of neighbour lines is also necessity. But historical-intuitive key (Enter) is not intuitive in Gblame. This is a big problem for me.

Possibility to return back after Enter would be solved the problem for me.",False,0,NONE
https://api.github.com/repos/tpope/vim-rhubarb/issues/52,[ Feature Request ] Comments Editing,ldelossa,10,543041563,1,543041563,0,0,2019-12-28T01:45:30Z,"It would be pretty useful to be able to view, edit, and create comments on a given pull request. 
I began looking into this feature and the `hub` command line allows for listing open PRs and listing comments within those PRs. The command returns JSON.

I'm curious if vim-fugitive maybe interested in this feature and if so work to get it moving. I am pretty novice in vim-script but, with a plan, I'm willing to do the necessary work as it would be pretty awesome to do code reviews right from Vim.

The major difference I see with this feature is API requirement and taking the hub command on as a dependency. A assume a polling mechanism would need to exist as well to get the latest comments at some interval. 

Let me know what you guys think. ",True,0,NONE
https://api.github.com/repos/tpope/vim-rhubarb/issues/comments/569375123,[ Feature Request ] Comments Editing,tpope,10,543041563,2,569375123,0,543041563,2019-12-28T01:54:23Z,"Fugitive is absolutely not interested in this issue, but Rhubarb could be. I imagine the JSON API already in place can largely do the same job that Hub can without the dependency.",False,0,OWNER
https://api.github.com/repos/tpope/vim-rhubarb/issues/comments/569375433,[ Feature Request ] Comments Editing,ldelossa,10,543041563,3,569375433,0,569375123,2019-12-28T01:59:13Z,"@tpope sorry, didn't realize the issue was transferred. 

Does vim-rhubarb already have a method for polling the api for updates? ",False,0,NONE
https://api.github.com/repos/tpope/vim-rhubarb/issues/comments/569376170,[ Feature Request ] Comments Editing,tpope,10,543041563,4,569376170,0,569375433,2019-12-28T02:09:50Z,"The way to do this is to make a special URL buffer, presumably similar to a `fugitive://...` buffer but with `rhurbab://`, that loads the issue and a list of comments, and perhaps further URLs for each individual comment. Calling `:edit` in the buffer reloads, which could optionally be accompanied by a map like `nnoremap <buffer> r :edit<CR>`.

I'm not sure polling is a good idea (you really plan to leave an issue open in a window and watch for updates?), but even if it's the best idea in the universe, I won't entertain further discussion of it until the basics are in place.",False,0,OWNER
https://api.github.com/repos/tpope/vim-rhubarb/issues/comments/569376666,[ Feature Request ] Comments Editing,ldelossa,10,543041563,5,569376666,0,569376170,2019-12-28T02:17:31Z,"@tpope 
In this feature request I'm focusing more on comments during a pull-request not comments in issues.
The Github API requires you to provide a pull request number and responds with all comments in that pull request. JSON objects have both file name details and hunk details. 

If the feature is to support code reviews within Vim - then I had originally imaged some interactivity in the process, when new PR comments are created, they should show up in Vim. That being said - I'll defer to you for the ""best way"" to go about that - I am new to Vim scripting. 

With the focus being on pull request would you comments on the URL buffer still stand? 
I will also need to discover ""remotes"" and call the GitHub API with the appropriate remote to list the correct pull requests in flight. ",False,0,NONE
https://api.github.com/repos/tpope/vim-rhubarb/issues/comments/569377269,[ Feature Request ] Comments Editing,tpope,10,543041563,6,569377269,0,569376666,2019-12-28T02:27:33Z,I was thinking of plain comments - the same kind that appear on issues - and hadn't really taken diff comments into account. This sounds way more useful but it's also way less obvious to me how it should work. How should it work?,False,0,OWNER
https://api.github.com/repos/tpope/vim-rhubarb/issues/comments/569378133,[ Feature Request ] Comments Editing,ldelossa,10,543041563,7,569378133,0,569377269,2019-12-28T02:41:44Z,"I'll dump my initial brain storming - there will definitely be gaps to fill. 

A high level vim command is registered, lets call it 'GitCommentsToggle' for sake of example.

When triggered we can parse the output of `git remote show origin` (lets ignore other remotes for now) and grab the owner/repo combination for API usage. 

We can make an API call to list ""in flight"" pull requests and then introduce some form of user input to ""select"" the PR we want to load comments for. 

API call is made to grab all the comments for this PR. Comment objects have some key fields (from an example pr comment on one of my projects):
```
""diff_hunk"": ""@@ -47,25 +45,19 @@ func Test_Matcher_Integration(t *testing.T) {\n \tctx, cancel := context.WithTimeout(ctx, 2*time.Minute)\n \tdefer cancel()\n \tup.Update(ctx)\n-\n \tpath := filepath.Join(\""testdata\"", \""indexreport-buster-jackson-databind.json\"")\n \tf, err := os.Open(path)\n \tif err != nil {\n \t\tt.Fatalf(\""%v\"", err)\n \t}\n \n-\tvar sr claircore.IndexReport\n-\terr = json.NewDecoder(f).Decode(&sr)\n+\tvar ir claircore.IndexReport"",
""path"": ""debian/matcher_integration_test.go"",
""position"": 42,
""original_position"": 42,
""body"": ""renamed to ir"",
""created_at"": ""2019-12-28T02:35:24Z"",
""updated_at"": ""2019-12-28T02:35:25Z"",
```

With this path information and line number we can then find if the buffer for that file is open and create some character either in the gutter or some indicator like a linter would to indicate a comment is at that line. Then, in my head, a floating window could display the comment but that's a vim version/implementation detail. 

That would get us displaying the comments. Posting comments would entail placing your cursor in a buffer at a particular line number, opening a buffer where your comment body can go, and then making a POST api call with details similar to the response posted above. 



",False,0,NONE
https://api.github.com/repos/tpope/vim-rhubarb/issues/comments/569379911,[ Feature Request ] Comments Editing,tpope,10,543041563,8,569379911,0,569378133,2019-12-28T03:12:44Z,"Step 3 implies we're on the branch for a particular PR. Step 1 makes me pick a PR from a list of all open PRs. There is one correct PR and if we pick any other PR we get invalid results. Please ... think this through a bit more.

Even past that easily rectifiable oversight I don't understand your workflow. If you're reviewing a PR, you're not looking at random files, you're looking at a diff and maybe diving into a file to get additional context. If you're resolving a reviewed PR, you're presumably starting with the comments and want to jump to the files they reference. Neither of these would be particularly helped by splattering a bunch of signs and floating windows over the files you already have open.",False,0,OWNER
https://api.github.com/repos/tpope/vim-rhubarb/issues/comments/569417348,[ Feature Request ] Comments Editing,ldelossa,10,543041563,9,569417348,0,569379911,2019-12-28T13:27:58Z,"Good catch on the PR mismatch. I can work out a better flow for that which removes the ambiguity.
As far as workflow however...

I would argue the opposite. That is how you perform a code review in the GitHub UI, you are scoped to particular set of chunks, and have to dig further to get the full file view... and if you for some reason want to browse a file outside of the diffs... well you go open VIM.

One of the reasons to approach code review in Vim is to have a Vim native experience. Opening non-related files should be supported, and viewing comments should be out of the way until you desire them. I'd like to avoid a scenario with Vim is adapted heavily for the purpose (like the diff UI in vim-fugitive). 

For example, I have a PR that changes some interface. This interface changes may affect files which are not diff'd in the PR. If code review was happening solely in Vim, I could still use git diff to find what changed, go to that block, see any comments for that hunk, and now also jump to any other files outside the PR to confirm the changes I'm looking at are correct. ",False,0,NONE
https://api.github.com/repos/tpope/vim-rhubarb/issues/comments/569448565,[ Feature Request ] Comments Editing,tpope,10,543041563,10,569448565,0,569417348,2019-12-28T20:25:43Z,"> I would argue the opposite. That is how you perform a code review in the GitHub UI, you are scoped to particular set of chunks, and have to dig further to get the full file view... and if you for some reason want to browse a file outside of the diffs... well you go open VIM.

If you ""dig in further to get the full file view"", you don't see comments. Your proposed addition, as I understand it, is to show comments on the full file view. So it's as far from ""how you perform a code review in the GitHub UI"" as you can get. There's literally zero overlap.

> I'd like to avoid a scenario with Vim is adapted heavily for the purpose (like the diff UI in vim-fugitive).

You're proposing polling and floating windows, you don't think that screams ""adapted heavily""?

> If code review was happening solely in Vim, I could still use git diff to find what changed,

What does this mean? Call `git diff common-ancestor` in the console? This is the first and most important step and you're brushing it off like it's a solved problem.

> go to that block,

How? I guess you mean jump from `:Git diff common-ancestor` but that isn't currently supported.

> see any comments for that hunk,

Why does this happen now? Why not when viewing the diff? You're so obsessed with the idea of showing comments on the full file that you're blinded to how contrived it is.",False,0,OWNER
https://api.github.com/repos/tpope/vim-rhubarb/issues/comments/569462568,[ Feature Request ] Comments Editing,ldelossa,10,543041563,11,569462568,0,569448565,2019-12-29T00:26:24Z,Okay let me reconsider design given some of your points. I maybe pushing an idea too quick. Ill take another look and circle back if anything comes of it. ,False,0,NONE
https://api.github.com/repos/rails/rails/issues/38330,rake db clears previously-set ActiveRecord::Base.configurations,wtn,7,555894522,1,555894522,0,0,2020-01-27T23:25:28Z,"I am using the rails 6 ""multiple databases"" API to run a multi-tenant setup. Each tenant has its own database. Instead of enumerating each tenant in my `database.yml`, that file references a single ""template"" tenant database. At application launch, an initializer appends a hash config object for each tenant database to the `ActiveRecord::DatabaseConfigurations` object.

The issue is that `rake db` tasks reload database configurations set at rails boot. This happens in `db:load_config` [here](https://github.com/rails/rails/blob/1d1991430dc5174a54abe5c2f6ecb3fd180a829e/activerecord/lib/active_record/railties/databases.rake#L19) which calls into [here](https://github.com/rails/rails/blob/1d1991430dc5174a54abe5c2f6ecb3fd180a829e/activerecord/lib/active_record/railtie.rb#L41) and results in re-reading the application's `database.yml`.

**Configuration:** rails 6.0.2.1

**Steps to reproduce**
1. Modify `ActiveRecord::Base.configurations` from an initializer
2. Run `rake db:drop` or similar

**Expected behavior**
* `ActiveRecord::Base.configurations` is unchanged (same as after step 1)

**Actual behavior**
* `ActiveRecord::Base.configurations` gets reinitialized from `database.yml`",True,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/579298140,rake db clears previously-set ActiveRecord::Base.configurations,eileencodes,7,555894522,2,579298140,0,555894522,2020-01-28T15:23:29Z,"This behavior is intentional. Otherwise how else will we create the rake tasks for multi-db?

What is the issue you're experiencing from this behavior? If you have a specific bug you're hitting please create a sample application that demonstrates the issue.",False,0,MEMBER
https://api.github.com/repos/rails/rails/issues/comments/580829163,rake db clears previously-set ActiveRecord::Base.configurations,eileencodes,7,555894522,3,580829163,0,579298140,2020-01-31T17:26:35Z,"I'm gonna close this since there hasn't been a response. If there''s a bug caused by reinitializing please let me know and I'll reopen. However, simply re-initializing isn't a bug. ",False,0,MEMBER
https://api.github.com/repos/rails/rails/issues/comments/580913171,rake db clears previously-set ActiveRecord::Base.configurations,wtn,7,555894522,4,580913171,0,580829163,2020-01-31T21:11:24Z,"I've posted an app with [tests](https://github.com/wtn/db_config_injection_app/blob/master/test/db_setup_test.rb) that demonstrate the behavior. If you can please reopen this issue, I would appreciate it.

To clarify, running a rake database task for a rails app from the command line results in the database config file being read at three points:
1. rake calls `ActiveRecord::Tasks::DatabaseTasks.setup_initial_database_yaml` [here](https://github.com/rails/rails/blob/6a6e3f6efe9d621543da77dd3e9f1e875778d4e6/activerecord/lib/active_record/railties/databases.rake#L5)
2. ActiveRecord configures its databases [here](https://github.com/rails/rails/blob/6a6e3f6efe9d621543da77dd3e9f1e875778d4e6/activerecord/lib/active_record/railtie.rb#L210)
3. rake re-configures ActiveRecord [here](https://github.com/rails/rails/blob/6a6e3f6efe9d621543da77dd3e9f1e875778d4e6/activerecord/lib/active_record/railtie.rb#L41) → [here](https://github.com/rails/rails/blob/6a6e3f6efe9d621543da77dd3e9f1e875778d4e6/activerecord/lib/active_record/railties/databases.rake#L19)

My issue is with point 3. Rake does not need to force a change when ActiveRecord is already configured, and reinitializing is the less-expected choice.

> This behavior is intentional. Otherwise how else will we create the rake tasks for multi-db?

Under rails, the rake tasks work as long as ActiveRecord is configured (point 2).

I acknowledge that my approach looks unconventional at first, but is simple and works with the current public API. I hope that you will give some consideration to customized (but valid) database configurations as the API evolves.

Thanks for your work on multiple databases support, and I appreciate your continuing leadership regarding this interface.",False,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/622123521,rake db clears previously-set ActiveRecord::Base.configurations,rails-bot[bot],7,555894522,5,622123521,0,580913171,2020-04-30T21:27:25Z,"This issue has been automatically marked as stale because it has not been commented on for at least three months.
The resources of the Rails team are limited, and so we are asking for your help.
If you can still reproduce this error on the `6-0-stable` branch or on `master`, please reply with all of the information you have about it in order to keep the issue open.
Thank you for all your contributions.
",False,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/666339425,rake db clears previously-set ActiveRecord::Base.configurations,rails-bot[bot],7,555894522,6,666339425,0,622123521,2020-07-30T12:39:17Z,"This issue has been automatically marked as stale because it has not been commented on for at least three months.
The resources of the Rails team are limited, and so we are asking for your help.
If you can still reproduce this error on the `6-0-stable` branch or on `master`, please reply with all of the information you have about it in order to keep the issue open.
Thank you for all your contributions.
",False,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/686954771,rake db clears previously-set ActiveRecord::Base.configurations,tgxworld,7,555894522,7,686954771,0,666339425,2020-09-04T06:57:40Z,"@wtn I took a look at this and it turns out the reassignment of `ActiveRecord::Base.configurations` in `db:load_config` is actually not necessary in the context of Rails because loading `ActiveRecord` itself would already have loaded the configurations.

Can you try out https://github.com/rails/rails/pull/40175 to see if that fixes it for you? 

If you want to work around the issue, you can alter `Rails.application.config.database_configuration` in your initializer instead of `ActiveRecord::Base.configurations`",False,0,CONTRIBUTOR
https://api.github.com/repos/rails/rails/issues/comments/687253165,rake db clears previously-set ActiveRecord::Base.configurations,wtn,7,555894522,8,687253165,0,686954771,2020-09-04T16:28:03Z,Thank you very much!,False,0,NONE
https://api.github.com/repos/rails/rails/issues/38332,where clause inside 'connected_to' block is not fetching data from replica database,mdaftab88,6,556060860,1,556060860,0,0,2020-01-28T08:43:47Z,"### Steps to reproduce
<!-- (Guidelines for creating a bug report are [available
here](https://edgeguides.rubyonrails.org/contributing_to_ruby_on_rails.html#creating-a-bug-report)) -->

1. Create a new rails app using postgresql database
```
rails new replica-test-app database=postgresql
```
2. database.yml config

```
development:
  primary:
    database: my_primary_database
    user: mdaftab88
    adapter: postgresql
  primary_replica:
    database: my_replica_database
    user: mdaftab88
    adapter: postgresql
    replica: true
```
3. Update `application_record.rb`
```
class ApplicationRecord < ActiveRecord::Base
  self.abstract_class = true
  connects_to database: { writing: :primary, reading: :primary_replica }
end
```
4. `rails generate scaffold User name:string role:string`
5. I have updated my `my_replica_database`  to identify the diff.  See the attached image.
<img width=""393"" alt=""Screenshot 2020-01-28 at 12 51 55 PM"" src=""https://user-images.githubusercontent.com/25167441/73243310-429e6780-41cd-11ea-88a7-70454786b951.png"">

### Actual behavior (On Rails Console)

When i fire
```
User.connected_to(role: :reading) { User.find_by(id: 1) }
```
it retrieves record from `my_replica_database`
But when I fire
```
User.connected_to(role: :reading) { User.where(id: 1) }
```
it retrieves record from `my_primary_database`.


Look at the attached console image.
<img width=""1048"" alt=""Screenshot 2020-01-28 at 2 08 37 PM"" src=""https://user-images.githubusercontent.com/25167441/73247834-c9584200-41d7-11ea-9125-a43705bb81ec.png"">

### Expected behavior
On firing
```
User.connected_to(role: :reading) { User.where(id: 1) }
```
it should retrieve record from `my_replica_database`

### System configuration
**Rails version**: 6.0.2.1

**Ruby version**: 2.6.3
",True,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/579313165,where clause inside 'connected_to' block is not fetching data from replica database,eileencodes,6,556060860,2,579313165,0,556060860,2020-01-28T15:47:30Z,"I was able to reproduce this, and this bug is not good. I will work on figuring out why it's happening and a fix for it.",False,0,MEMBER
https://api.github.com/repos/rails/rails/issues/comments/579341592,where clause inside 'connected_to' block is not fetching data from replica database,eileencodes,6,556060860,3,579341592,0,579313165,2020-01-28T16:40:39Z,Hey @mdaftab88 are you seeing this just in the console or elsewhere? I can reproduce in the console but my test environment and web requests are showing the correct data. I want to verify you're having the same experience. ,False,0,MEMBER
https://api.github.com/repos/rails/rails/issues/comments/579361596,where clause inside 'connected_to' block is not fetching data from replica database,eileencodes,6,556060860,4,579361596,0,579341592,2020-01-28T17:22:50Z,"Ok so this isn't strictly reproducible in tests because tests share a connection pool. But I could see that the handler wasn't correctly getting chosen. This is a bug but not as scary as I originally thought.

Rails is querying the database _after_ we exit the block, unless we ask the relation for something. Here's an example of wheres that work:

```
>> ActiveRecord::Base.connected_to(role: :replica) { Post.where(id: 1).to_a }
  Post Load (0.2ms)  SELECT `posts`.* FROM `posts` WHERE `posts`.`id` = 1
=> [#<Post id: 1, title: ""read"", created_at: ""2020-01-28 15:39:50"", updated_at: ""2020-01-28 15:39:50"">]
```

```
>> ActiveRecord::Base.connected_to(role: :replica) { Post.where(id: 1).first.title }
  Post Load (0.3ms)  SELECT `posts`.* FROM `posts` WHERE `posts`.`id` = 1 ORDER BY `posts`.`id` ASC LIMIT 1
=> ""read""
```

But this doesn't work:

```
>> ActiveRecord::Base.connected_to(role: :replica) { Post.where(id: 1) }
  Post Load (0.2ms)  SELECT `posts`.* FROM `posts` WHERE `posts`.`id` = 1 LIMIT 11
=> #<ActiveRecord::Relation [#<Post id: 1, title: ""write"", created_at: ""2020-01-28 15:38:39"", updated_at: ""2020-01-28 15:38:39"">]>
```

Because the query is happening after we exit the connected_to block 😬 

Working on figuring out what to do about this. Stay tuned.",False,0,MEMBER
https://api.github.com/repos/rails/rails/issues/comments/579385914,where clause inside 'connected_to' block is not fetching data from replica database,eileencodes,6,556060860,5,579385914,0,579361596,2020-01-28T18:20:15Z,PR https://github.com/rails/rails/pull/38339,False,0,MEMBER
https://api.github.com/repos/rails/rails/issues/comments/579604234,where clause inside 'connected_to' block is not fetching data from replica database,mdaftab88,6,556060860,6,579604234,0,579385914,2020-01-29T05:46:05Z,"@eileencodes Now its working properly.

Thanks.",False,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/581104378,where clause inside 'connected_to' block is not fetching data from replica database,alexander-alyoshin,6,556060860,7,581104378,0,579604234,2020-02-02T06:40:38Z,"@eileencodes Hi! Tell me, when will the release with these changes be?",False,0,NONE
https://api.github.com/repos/rails/rails/issues/38336,undefined method `get_schema_cache' for nil:NilClass,richardrails,6,556204963,1,556204963,0,0,2020-01-28T13:20:13Z,"Puma can't start in production after I upgraded rails from 5.2 to 6.0.2.1, getting error undefined method `get_schema_cache' for nil:NilClass

### System configuration
**Rails version**: 6.0.2.1

**Ruby version**: 2.6.1

```
/var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/activerecord-6.0.2.1/lib/active_record/connection_adapters/abstract_adapter.rb:227:in `schema_cache': undefined method `get_schema_cache' for nil:NilClass (NoMethodError)
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/activerecord-6.0.2.1/lib/active_record/railtie.rb:158:in `block (4 levels) in <class:Railtie>'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/activerecord-6.0.2.1/lib/active_record/railtie.rb:151:in `each'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/activerecord-6.0.2.1/lib/active_record/railtie.rb:151:in `block (3 levels) in <class:Railtie>'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.2.1/lib/active_support/lazy_load_hooks.rb:72:in `class_eval'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.2.1/lib/active_support/lazy_load_hooks.rb:72:in `block in execute_hook'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.2.1/lib/active_support/lazy_load_hooks.rb:62:in `with_execution_control'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.2.1/lib/active_support/lazy_load_hooks.rb:67:in `execute_hook'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.2.1/lib/active_support/lazy_load_hooks.rb:43:in `block in on_load'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.2.1/lib/active_support/lazy_load_hooks.rb:42:in `each'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.2.1/lib/active_support/lazy_load_hooks.rb:42:in `on_load'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/activerecord-6.0.2.1/lib/active_record/railtie.rb:149:in `block (2 levels) in <class:Railtie>'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.2.1/lib/active_support/lazy_load_hooks.rb:69:in `block in execute_hook'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.2.1/lib/active_support/lazy_load_hooks.rb:62:in `with_execution_control'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.2.1/lib/active_support/lazy_load_hooks.rb:67:in `execute_hook'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.2.1/lib/active_support/lazy_load_hooks.rb:52:in `block in run_load_hooks'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.2.1/lib/active_support/lazy_load_hooks.rb:51:in `each'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/activesupport-6.0.2.1/lib/active_support/lazy_load_hooks.rb:51:in `run_load_hooks'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/railties-6.0.2.1/lib/rails/application/finisher.rb:129:in `block in <module:Finisher>'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/railties-6.0.2.1/lib/rails/initializable.rb:32:in `instance_exec'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/railties-6.0.2.1/lib/rails/initializable.rb:32:in `run'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/railties-6.0.2.1/lib/rails/initializable.rb:61:in `block in run_initializers'
	from /home/deployer/.rbenv/versions/2.6.1/lib/ruby/2.6.0/tsort.rb:228:in `block in tsort_each'
	from /home/deployer/.rbenv/versions/2.6.1/lib/ruby/2.6.0/tsort.rb:350:in `block (2 levels) in each_strongly_connected_component'
	from /home/deployer/.rbenv/versions/2.6.1/lib/ruby/2.6.0/tsort.rb:431:in `each_strongly_connected_component_from'
	from /home/deployer/.rbenv/versions/2.6.1/lib/ruby/2.6.0/tsort.rb:349:in `block in each_strongly_connected_component'
	from /home/deployer/.rbenv/versions/2.6.1/lib/ruby/2.6.0/tsort.rb:347:in `each'
	from /home/deployer/.rbenv/versions/2.6.1/lib/ruby/2.6.0/tsort.rb:347:in `call'
	from /home/deployer/.rbenv/versions/2.6.1/lib/ruby/2.6.0/tsort.rb:347:in `each_strongly_connected_component'
	from /home/deployer/.rbenv/versions/2.6.1/lib/ruby/2.6.0/tsort.rb:226:in `tsort_each'
	from /home/deployer/.rbenv/versions/2.6.1/lib/ruby/2.6.0/tsort.rb:205:in `tsort_each'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/railties-6.0.2.1/lib/rails/initializable.rb:60:in `run_initializers'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/railties-6.0.2.1/lib/rails/application.rb:363:in `initialize!'
	from /var/www/deployer/app_staging/releases/1361/config/environment.rb:5:in `<top (required)>'
	from config.ru:3:in `require'
	from config.ru:3:in `block in <main>'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/rack-2.0.8/lib/rack/builder.rb:55:in `instance_eval'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/rack-2.0.8/lib/rack/builder.rb:55:in `initialize'
	from config.ru:in `new'
	from config.ru:in `<main>'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/rack-2.0.8/lib/rack/builder.rb:49:in `eval'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/rack-2.0.8/lib/rack/builder.rb:49:in `new_from_string'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/rack-2.0.8/lib/rack/builder.rb:40:in `parse_file'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/puma-3.12.0/lib/puma/configuration.rb:318:in `load_rackup'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/puma-3.12.0/lib/puma/configuration.rb:243:in `app'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/puma-3.12.0/lib/puma/runner.rb:155:in `app'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/puma-3.12.0/lib/puma/runner.rb:162:in `start_server'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/puma-3.12.0/lib/puma/cluster.rb:273:in `worker'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/puma-3.12.0/lib/puma/cluster.rb:137:in `block (2 levels) in spawn_workers'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/puma-3.12.0/lib/puma/cluster.rb:137:in `fork'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/puma-3.12.0/lib/puma/cluster.rb:137:in `block in spawn_workers'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/puma-3.12.0/lib/puma/cluster.rb:133:in `times'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/puma-3.12.0/lib/puma/cluster.rb:133:in `spawn_workers'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/puma-3.12.0/lib/puma/cluster.rb:211:in `check_workers'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/puma-3.12.0/lib/puma/cluster.rb:484:in `run'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/puma-3.12.0/lib/puma/launcher.rb:184:in `run'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/puma-3.12.0/lib/puma/cli.rb:78:in `run'
	from /var/www/deployer/app_staging/shared/bundle/ruby/2.6.0/gems/puma-3.12.0/bin/puma-wild:31:in `<main>'
```

GEMFILE:
```
source 'https://rubygems.org'
ruby '2.6.1'

git_source(:github) do |repo_name|
  repo_name = ""#{repo_name}/#{repo_name}"" unless repo_name.include?(""/"")
  ""https://github.com/#{repo_name}.git""
end
# gem 'bundler', '1.17.3'
gem 'rails', '6.0.2.1'
gem 'mysql2', '0.5.2'
gem 'sass-rails', '~> 6.0'
gem 'uglifier', '>= 1.3.0'
gem 'coffee-rails', '~> 5'

gem 'jquery-rails'
gem 'countries'
gem 'json_vat', github: 'benoist/json-vat'

gem ""i18n-js""#, "">= 3.0.0.rc11""
gem 'jquery-ui-rails', '5.0.0'
gem 'therubyracer',  platforms: :ruby
gem 'apitome'
gem 'net-http-persistent'
gem 'ruby-ares'
gem 'sprockets-rails', '3.2.1'
gem 'sprockets', '4.0.0'
gem 'activerecord-import'
gem ""activerecord-tablefree"", github: 'railsformers/activerecord-tablefree'
gem 'file_validators'
gem 'valvat'
gem 'sqlite3', '1.4.2'
gem 'prawn-rails'
gem 'two_factor_authentication'
gem 'gibbon'

group :development do
  gem 'meta_request'
  gem 'web-console', '~> 2.0'
end

group :development, :test do
  gem 'byebug'
  gem 'better_errors'
  gem 'binding_of_caller'
  gem 'letter_opener'
  gem 'rspec-rails', '4.0.0.beta4'
  gem 'factory_bot', '4.11.1'
  gem 'shoulda-matchers'
  gem ""shoulda-callback-matchers""
  gem 'database_cleaner'
  gem 'mina', '0.3.8'
  gem 'mina-sidekiq', '0.4.1'
  gem 'rails-controller-testing'
  gem 'rspec_api_documentation'
  gem 'capybara'
  gem 'selenium-webdriver'
  gem 'sunspot-rails-tester'
  gem 'write_xlsx'
end
# gem 'rake', '< 11.0'
gem 'gelf'
group :production do
  gem 'puma', '3.12.0'
  gem 'whenever'
end

gem 'rack', '~> 2.0.8' # remove after rspec-api-documentation issue is solved https://github.com/zipmark/rspec_api_documentation/issues/456

gem 'braintree', '~> 2.100.00'
gem 'braintree-rails', github: ""twalpole/braintree-rails"", branch: 'rails_6'
gem 'paypal-sdk-rest'
gem 'mime-types'#, require: 'mime/types/full'
gem 'rack-utf8_sanitizer'
gem 'rest-client'
gem 'xml-sitemap'
gem 'handlebars_assets'
gem 'faker'
gem 'roadie'
gem 'open_uri_redirections'
gem 'roadie-rails'
gem 'wicked_pdf'
gem 'less-rails', github: 'fujun/less-rails'
gem 'sunspot_rails'
gem 'sunspot_solr', '2.2.0'
gem 'jbuilder', :github => 'rails/jbuilder'
gem 'geocoder'
gem 'rails-i18n'
gem 'sinatra', '>= 1.3.0', require: nil
gem 'globalize-validations'
gem 'haml'
gem 'simple_form'
gem 'ransack', '2.3.2'
gem 'devise'
gem 'devise_header_token', github: 'stvp/devise_header_token'
gem 'devise-token_authenticatable'
gem 'cancancan'
gem 'kaminari'
gem 'sentry-raven'
gem 'responders', '~> 3.0'
gem 'font-awesome-rails'
gem 'draper'
gem 'metamagic'
gem 'carrierwave', '0.11.2'
gem 'carrierwave-i18n'
gem 'mini_magick'
gem 'rolify'
gem 'momentjs-rails', '2.10.3'
gem 'simple-spreadsheet'
gem 'liquid', '~> 3.0'
gem 'browser'
gem 'rqrcode'
gem 'video_info'

gem 'carmen-rails'
gem 'redis-session-store'
gem 'redis-namespace'

# IOS notifications
gem 'houston'
# Android notifications
gem 'fcm'

gem 'bootstrap3-datetimepicker-rails'#, '~> 4.14.30'
gem 'rails-assets-growl', '1.3.1', source: 'https://rails-assets.org'
gem 'rails-assets-jquery', '2.2.3', source: 'https://rails-assets.org'

gem 'route_translator', '7.1.1'
gem 'nprogress-rails'
gem 'premailer-rails'
gem 'omniauth-facebook'
gem 'omniauth-twitter'
gem 'omniauth-google-oauth2', '>= 0.6.0'
gem 'omniauth-mojeid', github: 'mbendik/omniauth-mojeid'
gem 'request_store'
gem 'email_validator'
gem 'validates_timeliness'
gem 'globalize', '~> 5.3.0'
gem 'sidekiq', '5.2.5'

gem 'nested_form', github: 'BenZhang/nested_form'
gem 'awesome_nested_set'
gem 'cookies_eu'
gem 'select2-rails' #, '3.5.9.3'
gem 'ckeditor', github: 'galetahub/ckeditor', ref: '32bc0c6702388549cb4b3f00f82afbc3798d6891'
gem 'ratyrate'
gem 'friendly_id'
gem 'friendly_id-globalize'
gem 'globalize-accessors'
gem 'icalendar'
gem 'spreadsheet'
gem 'x-real-ip'
gem 'wicked'
gem 'wkhtmltopdf-binary'
```

LOCK:
```
GIT
  remote: https://github.com/BenZhang/nested_form.git
  revision: 16ba467a0dc20e5ad5119e3e222079619324d893
  specs:
    nested_form (0.3.2)

GIT
  remote: https://github.com/benoist/json-vat.git
  revision: 9e4ee83af86df978c5eaf414d4da87bcf458625a
  specs:
    json_vat (1.1.0)

GIT
  remote: https://github.com/fujun/less-rails.git
  revision: f769e45cb4fe62da969859932d0696c1afc29d5e
  specs:
    less-rails (4.0.0)
      actionpack (>= 4)
      less (~> 2.6.0)
      sprockets (>= 2)

GIT
  remote: https://github.com/galetahub/ckeditor.git
  revision: 32bc0c6702388549cb4b3f00f82afbc3798d6891
  ref: 32bc0c6702388549cb4b3f00f82afbc3798d6891
  specs:
    ckeditor (4.2.4)
      cocaine
      orm_adapter (~> 0.5.0)

GIT
  remote: https://github.com/mbendik/omniauth-mojeid.git
  revision: 8db94739f78c82ebdb5af9ba1dd5f9a4cd8625a3
  specs:
    omniauth-mojeid (0.0.2)
      json
      omniauth
      omniauth-openid
      rack-openid
      ruby-openid

GIT
  remote: https://github.com/rails/jbuilder.git
  revision: bec0d6c840c3486ee589d5de0ba9c348ccbc27ee
  specs:
    jbuilder (2.9.1)
      activesupport (>= 5.0.0)

GIT
  remote: https://github.com/railsformers/activerecord-tablefree.git
  revision: 6adb04b12da128523edbc9527c647e4fa6869aee
  specs:
    activerecord-tablefree (3.1.7)
      activerecord (>= 6.0.0)

GIT
  remote: https://github.com/stvp/devise_header_token.git
  revision: 2deb5a5871c74836681e766912d02c305e8d1ec4
  specs:
    devise_header_token (1.0.0)
      devise

GIT
  remote: https://github.com/twalpole/braintree-rails.git
  revision: a0808607488356799de9f12bb9da0c4994b47066
  branch: rails_6
  specs:
    braintree-rails (1.4.1)
      activemodel (>= 3.0, < 6.1)
      activesupport (>= 3.0, < 6.1)
      braintree (>= 2.28.0, < 3)

GEM
  remote: https://rubygems.org/
  remote: https://rails-assets.org/
  specs:
    actioncable (6.0.2.1)
      actionpack (= 6.0.2.1)
      nio4r (~> 2.0)
      websocket-driver (>= 0.6.1)
    actionmailbox (6.0.2.1)
      actionpack (= 6.0.2.1)
      activejob (= 6.0.2.1)
      activerecord (= 6.0.2.1)
      activestorage (= 6.0.2.1)
      activesupport (= 6.0.2.1)
      mail (>= 2.7.1)
    actionmailer (6.0.2.1)
      actionpack (= 6.0.2.1)
      actionview (= 6.0.2.1)
      activejob (= 6.0.2.1)
      mail (~> 2.5, >= 2.5.4)
      rails-dom-testing (~> 2.0)
    actionpack (6.0.2.1)
      actionview (= 6.0.2.1)
      activesupport (= 6.0.2.1)
      rack (~> 2.0, >= 2.0.8)
      rack-test (>= 0.6.3)
      rails-dom-testing (~> 2.0)
      rails-html-sanitizer (~> 1.0, >= 1.2.0)
    actiontext (6.0.2.1)
      actionpack (= 6.0.2.1)
      activerecord (= 6.0.2.1)
      activestorage (= 6.0.2.1)
      activesupport (= 6.0.2.1)
      nokogiri (>= 1.8.5)
    actionview (6.0.2.1)
      activesupport (= 6.0.2.1)
      builder (~> 3.1)
      erubi (~> 1.4)
      rails-dom-testing (~> 2.0)
      rails-html-sanitizer (~> 1.1, >= 1.2.0)
    activejob (6.0.2.1)
      activesupport (= 6.0.2.1)
      globalid (>= 0.3.6)
    activemodel (6.0.2.1)
      activesupport (= 6.0.2.1)
    activemodel-serializers-xml (1.0.2)
      activemodel (> 5.x)
      activesupport (> 5.x)
      builder (~> 3.1)
    activerecord (6.0.2.1)
      activemodel (= 6.0.2.1)
      activesupport (= 6.0.2.1)
    activerecord-import (1.0.4)
      activerecord (>= 3.2)
    activestorage (6.0.2.1)
      actionpack (= 6.0.2.1)
      activejob (= 6.0.2.1)
      activerecord (= 6.0.2.1)
      marcel (~> 0.3.1)
    activesupport (6.0.2.1)
      concurrent-ruby (~> 1.0, >= 1.0.2)
      i18n (>= 0.7, < 2)
      minitest (~> 5.1)
      tzinfo (~> 1.1)
      zeitwerk (~> 2.2)
    addressable (2.7.0)
      public_suffix (>= 2.0.2, < 5.0)
    akami (1.3.1)
      gyoku (>= 0.4.0)
      nokogiri
    ansi (1.5.0)
    apitome (0.3.0)
      kramdown
      railties
    ast (2.4.0)
    awesome_nested_set (3.2.0)
      activerecord (>= 4.0.0, < 7.0)
    bcrypt (3.1.13)
    better_errors (2.5.1)
      coderay (>= 1.0.0)
      erubi (>= 1.0.0)
      rack (>= 0.9.0)
    binding_of_caller (0.8.0)
      debug_inspector (>= 0.0.1)
    bootstrap3-datetimepicker-rails (4.17.47)
      momentjs-rails (>= 2.8.1)
    braintree (2.100.0)
      builder (>= 2.0.0)
    browser (3.0.3)
    builder (3.2.4)
    byebug (11.1.1)
    cancancan (3.0.2)
    capybara (3.31.0)
      addressable
      mini_mime (>= 0.1.3)
      nokogiri (~> 1.8)
      rack (>= 1.6.0)
      rack-test (>= 0.6.3)
      regexp_parser (~> 1.5)
      xpath (~> 3.2)
    carmen (1.0.2)
      activesupport (>= 3.0.0)
    carmen-rails (1.0.1)
      carmen (~> 1.0.0)
      rails
    carrierwave (0.11.2)
      activemodel (>= 3.2.0)
      activesupport (>= 3.2.0)
      json (>= 1.7)
      mime-types (>= 1.16)
      mimemagic (>= 0.3.0)
    carrierwave-i18n (0.2.0)
    childprocess (3.0.0)
    chronic (0.10.2)
    chunky_png (1.3.11)
    climate_control (0.2.0)
    cocaine (0.6.0)
      terrapin (= 0.6.0)
    coderay (1.1.2)
    coffee-rails (5.0.0)
      coffee-script (>= 2.2.0)
      railties (>= 5.2.0)
    coffee-script (2.4.1)
      coffee-script-source
      execjs
    coffee-script-source (1.12.2)
    commander (4.5.0)
      highline (~> 2.0.0)
    commonjs (0.2.7)
    concurrent-ruby (1.1.5)
    connection_pool (2.2.2)
    cookies_eu (1.7.6)
      js_cookie_rails (~> 2.2.0)
    countries (3.0.0)
      i18n_data (~> 0.8.0)
      sixarm_ruby_unaccent (~> 1.1)
      unicode_utils (~> 1.4)
    crass (1.0.6)
    css_parser (1.7.1)
      addressable
    database_cleaner (1.7.0)
    debug_inspector (0.0.3)
    devise (4.7.1)
      bcrypt (~> 3.0)
      orm_adapter (~> 0.1)
      railties (>= 4.1.0)
      responders
      warden (~> 1.2.3)
    devise-token_authenticatable (1.1.0)
      devise (>= 4.0.0, < 5.0.0)
    diff-lcs (1.3)
    domain_name (0.5.20190701)
      unf (>= 0.0.5, < 1.0.0)
    draper (3.1.0)
      actionpack (>= 5.0)
      activemodel (>= 5.0)
      activemodel-serializers-xml (>= 1.0)
      activesupport (>= 5.0)
      request_store (>= 1.0)
    email_validator (2.0.1)
      activemodel
    encryptor (3.0.0)
    erubi (1.9.0)
    execjs (2.7.0)
    factory_bot (4.11.1)
      activesupport (>= 3.0.0)
    faker (2.10.1)
      i18n (>= 1.6, < 2)
    faraday (0.17.3)
      multipart-post (>= 1.2, < 3)
    fcm (0.0.6)
      httparty (~> 0.10, >= 0.10.0)
    ffi (1.12.1)
    file_validators (2.3.0)
      activemodel (>= 3.2)
      mime-types (>= 1.0)
    font-awesome-rails (4.7.0.5)
      railties (>= 3.2, < 6.1)
    friendly_id (5.3.0)
      activerecord (>= 4.0.0)
    friendly_id-globalize (1.0.0.alpha3)
      friendly_id (>= 5.2.0, < 6.0)
    gelf (3.1.0)
      json
    geocoder (1.6.1)
    gibbon (3.3.2)
      faraday (>= 0.16.0)
      multi_json (>= 1.11.0)
    globalid (0.4.2)
      activesupport (>= 4.2.0)
    globalize (5.3.0)
      activemodel (>= 4.2, < 6.1)
      activerecord (>= 4.2, < 6.1)
      request_store (~> 1.0)
    globalize-accessors (0.2.1)
      globalize (~> 5.0, >= 5.0.0)
    globalize-validations (0.0.4)
      globalize (>= 3)
      globalize-accessors (~> 0.1)
    gyoku (1.3.1)
      builder (>= 2.1.2)
    haml (5.1.2)
      temple (>= 0.8.0)
      tilt
    handlebars_assets (0.23.7)
      execjs (~> 2.0)
      sprockets (>= 2.0.0)
      tilt (>= 1.2)
    hashie (3.6.0)
    highline (2.0.3)
    houston (2.4.0)
      commander (~> 4.4)
      json
    htmlentities (4.3.4)
    http-accept (1.7.0)
    http-cookie (1.0.3)
      domain_name (~> 0.5)
    httparty (0.17.3)
      mime-types (~> 3.0)
      multi_xml (>= 0.5.2)
    httpi (2.4.4)
      rack
      socksify
    i18n (1.8.2)
      concurrent-ruby (~> 1.0)
    i18n-js (3.5.1)
      i18n (>= 0.6.6)
    i18n_data (0.8.0)
    icalendar (2.6.1)
      ice_cube (~> 0.16)
    ice_cube (0.16.3)
    iso8601 (0.9.1)
    jquery-rails (4.3.5)
      rails-dom-testing (>= 1, < 3)
      railties (>= 4.2.0)
      thor (>= 0.14, < 2.0)
    jquery-ui-rails (5.0.0)
      railties (>= 3.2.16)
    js_cookie_rails (2.2.0)
      railties (>= 3.1)
    json (2.3.0)
    jwt (2.2.1)
    kaminari (1.1.1)
      activesupport (>= 4.1.0)
      kaminari-actionview (= 1.1.1)
      kaminari-activerecord (= 1.1.1)
      kaminari-core (= 1.1.1)
    kaminari-actionview (1.1.1)
      actionview
      kaminari-core (= 1.1.1)
    kaminari-activerecord (1.1.1)
      activerecord
      kaminari-core (= 1.1.1)
    kaminari-core (1.1.1)
    kramdown (2.1.0)
    launchy (2.4.3)
      addressable (~> 2.3)
    less (2.6.0)
      commonjs (~> 0.2.7)
    letter_opener (1.7.0)
      launchy (~> 2.2)
    libv8 (3.16.14.19)
    libxml-ruby (3.1.0)
    liquid (3.0.6)
    loofah (2.4.0)
      crass (~> 1.0.2)
      nokogiri (>= 1.5.9)
    mail (2.7.1)
      mini_mime (>= 0.1.1)
    marcel (0.3.3)
      mimemagic (~> 0.3.2)
    meta_request (0.7.2)
      rack-contrib (>= 1.1, < 3)
      railties (>= 3.0.0, < 7)
    metamagic (3.1.7)
      rails (>= 3.0.0)
    method_source (0.9.2)
    mime-types (3.3.1)
      mime-types-data (~> 3.2015)
    mime-types-data (3.2019.1009)
    mimemagic (0.3.4)
    mina (0.3.8)
      open4 (~> 1.3.4)
      rake
    mina-sidekiq (0.4.1)
      mina
    mini_magick (4.10.1)
    mini_mime (1.0.2)
    mini_portile2 (2.4.0)
    minitest (5.14.0)
    momentjs-rails (2.10.3)
      railties (>= 3.1)
    multi_json (1.14.1)
    multi_xml (0.6.0)
    multipart-post (2.1.1)
    mustache (1.1.1)
    mustermann (1.1.1)
      ruby2_keywords (~> 0.0.1)
    mysql2 (0.5.2)
    net-http-persistent (3.1.0)
      connection_pool (~> 2.2)
    net_http_timeout_errors (0.3.5)
    netrc (0.11.0)
    nio4r (2.5.2)
    nokogiri (1.10.7)
      mini_portile2 (~> 2.4.0)
    nori (2.6.0)
    nprogress-rails (0.2.0.2)
    oauth (0.5.4)
    oauth2 (1.4.2)
      faraday (>= 0.8, < 2.0)
      jwt (>= 1.0, < 3.0)
      multi_json (~> 1.3)
      multi_xml (~> 0.5)
      rack (>= 1.2, < 3)
    oga (3.2)
      ast
      ruby-ll (~> 2.1)
    omniauth (1.9.0)
      hashie (>= 3.4.6, < 3.7.0)
      rack (>= 1.6.2, < 3)
    omniauth-facebook (6.0.0)
      omniauth-oauth2 (~> 1.2)
    omniauth-google-oauth2 (0.8.0)
      jwt (>= 2.0)
      omniauth (>= 1.1.1)
      omniauth-oauth2 (>= 1.6)
    omniauth-oauth (1.1.0)
      oauth
      omniauth (~> 1.0)
    omniauth-oauth2 (1.6.0)
      oauth2 (~> 1.1)
      omniauth (~> 1.9)
    omniauth-openid (1.0.1)
      omniauth (~> 1.0)
      rack-openid (~> 1.3.1)
    omniauth-twitter (1.4.0)
      omniauth-oauth (~> 1.1)
      rack
    open4 (1.3.4)
    open_uri_redirections (0.2.1)
    orm_adapter (0.5.0)
    paypal-sdk-rest (1.7.4)
      multi_json (~> 1.0)
      xml-simple
    pdf-core (0.7.0)
    polyamorous (2.3.2)
      activerecord (>= 5.2.1)
    pr_geohash (1.0.0)
    prawn (2.2.2)
      pdf-core (~> 0.7.0)
      ttfunk (~> 1.5)
    prawn-rails (1.3.0)
      prawn
      prawn-table
      rails (>= 3.1.0)
    prawn-table (0.2.2)
      prawn (>= 1.3.0, < 3.0.0)
    premailer (1.11.1)
      addressable
      css_parser (>= 1.6.0)
      htmlentities (>= 4.0.0)
    premailer-rails (1.10.3)
      actionmailer (>= 3)
      premailer (~> 1.7, >= 1.7.9)
    public_suffix (4.0.3)
    puma (3.12.0)
    rack (2.0.8)
    rack-contrib (2.1.0)
      rack (~> 2.0)
    rack-openid (1.3.1)
      rack (>= 1.1.0)
      ruby-openid (>= 2.1.8)
    rack-protection (2.0.8.1)
      rack
    rack-test (1.1.0)
      rack (>= 1.0, < 3)
    rack-utf8_sanitizer (1.6.0)
      rack (>= 1.0, < 3.0)
    rails (6.0.2.1)
      actioncable (= 6.0.2.1)
      actionmailbox (= 6.0.2.1)
      actionmailer (= 6.0.2.1)
      actionpack (= 6.0.2.1)
      actiontext (= 6.0.2.1)
      actionview (= 6.0.2.1)
      activejob (= 6.0.2.1)
      activemodel (= 6.0.2.1)
      activerecord (= 6.0.2.1)
      activestorage (= 6.0.2.1)
      activesupport (= 6.0.2.1)
      bundler (>= 1.3.0)
      railties (= 6.0.2.1)
      sprockets-rails (>= 2.0.0)
    rails-assets-growl (1.3.1)
      rails-assets-jquery
    rails-assets-jquery (2.2.3)
    rails-controller-testing (1.0.4)
      actionpack (>= 5.0.1.x)
      actionview (>= 5.0.1.x)
      activesupport (>= 5.0.1.x)
    rails-dom-testing (2.0.3)
      activesupport (>= 4.2.0)
      nokogiri (>= 1.6)
    rails-html-sanitizer (1.3.0)
      loofah (~> 2.3)
    rails-i18n (6.0.0)
      i18n (>= 0.7, < 2)
      railties (>= 6.0.0, < 7)
    railties (6.0.2.1)
      actionpack (= 6.0.2.1)
      activesupport (= 6.0.2.1)
      method_source
      rake (>= 0.8.7)
      thor (>= 0.20.3, < 2.0)
    rake (13.0.1)
    randexp (0.1.7)
    ransack (2.3.2)
      activerecord (>= 5.2.1)
      activesupport (>= 5.2.1)
      i18n
      polyamorous (= 2.3.2)
    ratyrate (1.2.2.alpha)
    redis (4.1.3)
    redis-namespace (1.7.0)
      redis (>= 3.0.4)
    redis-session-store (0.11.1)
      actionpack (>= 3)
      redis (>= 3, < 5)
    ref (2.0.0)
    regexp_parser (1.6.0)
    request_store (1.5.0)
      rack (>= 1.4)
    responders (3.0.0)
      actionpack (>= 5.0)
      railties (>= 5.0)
    rest-client (2.1.0)
      http-accept (>= 1.7.0, < 2.0)
      http-cookie (>= 1.0.2, < 2.0)
      mime-types (>= 1.16, < 4.0)
      netrc (~> 0.8)
    roadie (4.0.0)
      css_parser (~> 1.4)
      nokogiri (~> 1.8)
    roadie-rails (2.1.1)
      railties (>= 5.1, < 6.1)
      roadie (>= 3.1, < 5.0)
    rolify (5.2.0)
    roo (2.8.2)
      nokogiri (~> 1)
      rubyzip (>= 1.2.1, < 2.0.0)
    roo-xls (1.2.0)
      nokogiri
      roo (>= 2.0.0, < 3)
      spreadsheet (> 0.9.0)
    rotp (5.1.0)
      addressable (~> 2.5)
    route_translator (7.1.1)
      actionpack (>= 5.0.0.1, < 6.1)
      activesupport (>= 5.0.0.1, < 6.1)
      addressable (~> 2.7)
    rqrcode (1.1.2)
      chunky_png (~> 1.0)
      rqrcode_core (~> 0.1)
    rqrcode_core (0.1.1)
    rsolr (2.3.0)
      builder (>= 2.1.2)
      faraday (>= 0.9.0)
    rspec (3.9.0)
      rspec-core (~> 3.9.0)
      rspec-expectations (~> 3.9.0)
      rspec-mocks (~> 3.9.0)
    rspec-core (3.9.1)
      rspec-support (~> 3.9.1)
    rspec-expectations (3.9.0)
      diff-lcs (>= 1.2.0, < 2.0)
      rspec-support (~> 3.9.0)
    rspec-mocks (3.9.1)
      diff-lcs (>= 1.2.0, < 2.0)
      rspec-support (~> 3.9.0)
    rspec-rails (4.0.0.beta4)
      actionpack (>= 4.2)
      activesupport (>= 4.2)
      railties (>= 4.2)
      rspec-core (~> 3.9)
      rspec-expectations (~> 3.9)
      rspec-mocks (~> 3.9)
      rspec-support (~> 3.9)
    rspec-support (3.9.2)
    rspec_api_documentation (6.1.0)
      activesupport (>= 3.0.0)
      mustache (~> 1.0, >= 0.99.4)
      rspec (~> 3.0)
    ruby-ares (0.0.3)
      libxml-ruby
    ruby-ll (2.1.2)
      ansi
      ast
    ruby-ole (1.2.12.2)
    ruby-openid (2.9.2)
    ruby2_keywords (0.0.2)
    rubyzip (1.3.0)
    sass-rails (6.0.0)
      sassc-rails (~> 2.1, >= 2.1.1)
    sassc (2.2.1)
      ffi (~> 1.9)
    sassc-rails (2.1.2)
      railties (>= 4.0.0)
      sassc (>= 2.0)
      sprockets (> 3.0)
      sprockets-rails
      tilt
    savon (2.12.0)
      akami (~> 1.2)
      builder (>= 2.1.2)
      gyoku (~> 1.2)
      httpi (~> 2.3)
      nokogiri (>= 1.8.1)
      nori (~> 2.4)
      wasabi (~> 3.4)
    select2-rails (4.0.3)
      thor (~> 0.14)
    selenium-webdriver (3.142.7)
      childprocess (>= 0.5, < 4.0)
      rubyzip (>= 1.2.2)
    sentry-raven (2.13.0)
      faraday (>= 0.7.6, < 1.0)
    shoulda-callback-matchers (1.1.4)
      activesupport (>= 3)
    shoulda-matchers (4.2.0)
      activesupport (>= 4.2.0)
    sidekiq (5.2.5)
      connection_pool (~> 2.2, >= 2.2.2)
      rack (>= 1.5.0)
      rack-protection (>= 1.5.0)
      redis (>= 3.3.5, < 5)
    simple-spreadsheet (0.5.0)
      roo (~> 2.4)
      roo-xls (~> 1.0)
    simple_form (5.0.1)
      actionpack (>= 5.0)
      activemodel (>= 5.0)
    sinatra (2.0.8.1)
      mustermann (~> 1.0)
      rack (~> 2.0)
      rack-protection (= 2.0.8.1)
      tilt (~> 2.0)
    sixarm_ruby_unaccent (1.2.0)
    socksify (1.7.1)
    spreadsheet (1.2.6)
      ruby-ole (>= 1.0)
    sprockets (4.0.0)
      concurrent-ruby (~> 1.0)
      rack (> 1, < 3)
    sprockets-rails (3.2.1)
      actionpack (>= 4.0)
      activesupport (>= 4.0)
      sprockets (>= 3.0.0)
    sqlite3 (1.4.2)
    sunspot (2.5.0)
      pr_geohash (~> 1.0)
      rsolr (>= 1.1.1, < 3)
    sunspot-rails-tester (1.0.0)
      sunspot_rails (>= 1.2)
      sunspot_solr (>= 1.2)
    sunspot_rails (2.5.0)
      rails (>= 3)
      sunspot (= 2.5.0)
    sunspot_solr (2.2.0)
    temple (0.8.2)
    terrapin (0.6.0)
      climate_control (>= 0.0.3, < 1.0)
    therubyracer (0.12.3)
      libv8 (~> 3.16.14.15)
      ref
    thor (0.20.3)
    thread_safe (0.3.6)
    tilt (2.0.10)
    timeliness (0.4.4)
    ttfunk (1.6.1)
    two_factor_authentication (2.2.0)
      devise
      encryptor
      rails (>= 3.1.1)
      randexp
      rotp (>= 4.0.0)
    tzinfo (1.2.6)
      thread_safe (~> 0.1)
    uglifier (4.2.0)
      execjs (>= 0.3.0, < 3)
    unf (0.1.4)
      unf_ext
    unf_ext (0.0.7.6)
    unicode_utils (1.4.0)
    validates_timeliness (4.1.1)
      timeliness (>= 0.3.10, < 1)
    valvat (0.8.2)
      savon (>= 2.3.0)
    video_info (2.7.1)
      iso8601 (~> 0.9.1)
      net_http_timeout_errors (~> 0.3.0)
      oga (~> 3.0)
    warden (1.2.8)
      rack (>= 2.0.6)
    wasabi (3.5.0)
      httpi (~> 2.0)
      nokogiri (>= 1.4.2)
    web-console (2.3.0)
      activemodel (>= 4.0)
      binding_of_caller (>= 0.7.2)
      railties (>= 4.0)
      sprockets-rails (>= 2.0, < 4.0)
    websocket-driver (0.7.1)
      websocket-extensions (>= 0.1.0)
    websocket-extensions (0.1.4)
    whenever (1.0.0)
      chronic (>= 0.6.3)
    wicked (1.3.4)
      railties (>= 3.0.7)
    wicked_pdf (1.4.0)
      activesupport
    wkhtmltopdf-binary (0.12.5.1)
    write_xlsx (0.85.7)
      rubyzip (>= 1.0.0)
      zip-zip
    x-real-ip (0.2.1)
      activesupport
      rack
    xml-simple (1.1.5)
    xml-sitemap (1.3.3)
      builder (>= 2.0)
    xpath (3.2.0)
      nokogiri (~> 1.8)
    zeitwerk (2.2.2)
    zip-zip (0.3)
      rubyzip (>= 1.0.0)

PLATFORMS
  ruby

DEPENDENCIES
  activerecord-import
  activerecord-tablefree!
  apitome
  awesome_nested_set
  better_errors
  binding_of_caller
  bootstrap3-datetimepicker-rails
  braintree (~> 2.100.00)
  braintree-rails!
  browser
  byebug
  cancancan
  capybara
  carmen-rails
  carrierwave (= 0.11.2)
  carrierwave-i18n
  ckeditor!
  coffee-rails (~> 5)
  cookies_eu
  countries
  database_cleaner
  devise
  devise-token_authenticatable
  devise_header_token!
  draper
  email_validator
  factory_bot (= 4.11.1)
  faker
  fcm
  file_validators
  font-awesome-rails
  friendly_id
  friendly_id-globalize
  gelf
  geocoder
  gibbon
  globalize (~> 5.3.0)
  globalize-accessors
  globalize-validations
  haml
  handlebars_assets
  houston
  i18n-js
  icalendar
  jbuilder!
  jquery-rails
  jquery-ui-rails (= 5.0.0)
  json_vat!
  kaminari
  less-rails!
  letter_opener
  liquid (~> 3.0)
  meta_request
  metamagic
  mime-types
  mina (= 0.3.8)
  mina-sidekiq (= 0.4.1)
  mini_magick
  momentjs-rails (= 2.10.3)
  mysql2 (= 0.5.2)
  nested_form!
  net-http-persistent
  nprogress-rails
  omniauth-facebook
  omniauth-google-oauth2 (>= 0.6.0)
  omniauth-mojeid!
  omniauth-twitter
  open_uri_redirections
  paypal-sdk-rest
  prawn-rails
  premailer-rails
  puma (= 3.12.0)
  rack (~> 2.0.8)
  rack-utf8_sanitizer
  rails (= 6.0.2.1)
  rails-assets-growl (= 1.3.1)!
  rails-assets-jquery (= 2.2.3)!
  rails-controller-testing
  rails-i18n
  ransack (= 2.3.2)
  ratyrate
  redis-namespace
  redis-session-store
  request_store
  responders (~> 3.0)
  rest-client
  roadie
  roadie-rails
  rolify
  route_translator (= 7.1.1)
  rqrcode
  rspec-rails (= 4.0.0.beta4)
  rspec_api_documentation
  ruby-ares
  sass-rails (~> 6.0)
  select2-rails
  selenium-webdriver
  sentry-raven
  shoulda-callback-matchers
  shoulda-matchers
  sidekiq (= 5.2.5)
  simple-spreadsheet
  simple_form
  sinatra (>= 1.3.0)
  spreadsheet
  sprockets (= 4.0.0)
  sprockets-rails (= 3.2.1)
  sqlite3 (= 1.4.2)
  sunspot-rails-tester
  sunspot_rails
  sunspot_solr (= 2.2.0)
  therubyracer
  two_factor_authentication
  uglifier (>= 1.3.0)
  validates_timeliness
  valvat
  video_info
  web-console (~> 2.0)
  whenever
  wicked
  wicked_pdf
  wkhtmltopdf-binary
  write_xlsx
  x-real-ip
  xml-sitemap

RUBY VERSION
   ruby 2.6.1p33

BUNDLED WITH
   1.17.3
```


application.rb:
```
require File.expand_path('../boot', __FILE__)
require_relative 'boot'
ENV['RANSACK_FORM_BUILDER'] = '::SimpleForm::FormBuilder'
require 'rails/all'


# Require the gems listed in Gemfile, including any gems
# you've limited to :test, :development, or :production.
Bundler.require(*Rails.groups)

module App
  class Application < Rails::Application
    # Use the responders controller from the responders gem
    config.app_generators.scaffold_controller :responders_controller
    config.load_defaults 6.0
    config.autoloader = :classic

    config.exceptions_app = self.routes
    config.middleware.insert 0, Rack::UTF8Sanitizer

    config.generators do |g|
      g.stylesheets false
      # don't generate RSpec tests for views and helpers
      g.controller_specs false
      g.helper_specs false
      g.route_specs false
      g.routing_specs false
      g.view_specs false
    end

    config.active_job.queue_adapter = :sidekiq

    # Set Time.zone default to the specified zone and make Active Record auto-convert to this zone.
    # Run ""rake -D time"" for a list of tasks for finding time zone names. Default is UTC.
    config.time_zone = 'Prague'
    # config.time_zone = 'UTC'
    # Settings in config/environments/* take precedence over those specified here.
    # Application configuration should go into files in config/initializers

    config.to_prepare do
      Devise::Mailer.layout ""mailer""
      Devise::SessionsController.layout ""devise""
      Devise::RegistrationsController.layout ""devise""
      Devise::ConfirmationsController.layout ""devise""
      Devise::UnlocksController.layout ""devise""
      Devise::PasswordsController.layout ""devise""
    end

    config.i18n.enforce_available_locales = true
    config.i18n.available_locales = %w(cs en hr sk)
    config.i18n.default_locale = :en
    config.i18n.fallbacks = true
    # I18n.enforce_available_locales = false
    # config.i18n.enforce_available_locales = true
    # config.active_record.raise_in_transactional_callbacks = true

    config.active_record.belongs_to_required_by_default = false

    config.autoload_paths += %W(#{config.root}/lib)
    config.autoload_paths += %W(#{config.root}/app/models/ckeditor)
    config.i18n.load_path += Dir[Rails.root.join('config', 'locales', '**/*.{rb,yml}').to_s]
  end
end
```

",True,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/579252081,undefined method `get_schema_cache' for nil:NilClass,richardrails,6,556204963,2,579252081,0,556204963,2020-01-28T13:44:46Z,"also getting this on localhost after running
```
rails s -e staging
```

```
Traceback (most recent call last):
        61: from bin/rails:4:in `<main>'
        60: from bin/rails:4:in `require'
        59: from /home/rf/.rvm/gems/ruby-2.6.1/gems/railties-6.0.2.1/lib/rails/commands.rb:18:in `<top (required)>'
        58: from /home/rf/.rvm/gems/ruby-2.6.1/gems/railties-6.0.2.1/lib/rails/command.rb:46:in `invoke'
        57: from /home/rf/.rvm/gems/ruby-2.6.1/gems/railties-6.0.2.1/lib/rails/command/base.rb:69:in `perform'
        56: from /home/rf/.rvm/gems/ruby-2.6.1/gems/thor-0.20.3/lib/thor.rb:387:in `dispatch'
        55: from /home/rf/.rvm/gems/ruby-2.6.1/gems/thor-0.20.3/lib/thor/invocation.rb:126:in `invoke_command'
        54: from /home/rf/.rvm/gems/ruby-2.6.1/gems/thor-0.20.3/lib/thor/command.rb:27:in `run'
        53: from /home/rf/.rvm/gems/ruby-2.6.1/gems/railties-6.0.2.1/lib/rails/commands/server/server_command.rb:138:in `perform'
        52: from /home/rf/.rvm/gems/ruby-2.6.1/gems/railties-6.0.2.1/lib/rails/commands/server/server_command.rb:138:in `tap'
        51: from /home/rf/.rvm/gems/ruby-2.6.1/gems/railties-6.0.2.1/lib/rails/commands/server/server_command.rb:147:in `block in perform'
        50: from /home/rf/.rvm/gems/ruby-2.6.1/gems/railties-6.0.2.1/lib/rails/commands/server/server_command.rb:39:in `start'
        49: from /home/rf/.rvm/gems/ruby-2.6.1/gems/rack-2.0.8/lib/rack/server.rb:283:in `start'
        48: from /home/rf/.rvm/gems/ruby-2.6.1/gems/rack-2.0.8/lib/rack/server.rb:354:in `wrapped_app'
        47: from /home/rf/.rvm/gems/ruby-2.6.1/gems/rack-2.0.8/lib/rack/server.rb:219:in `app'
        46: from /home/rf/.rvm/gems/ruby-2.6.1/gems/rack-2.0.8/lib/rack/server.rb:319:in `build_app_and_options_from_config'
        45: from /home/rf/.rvm/gems/ruby-2.6.1/gems/rack-2.0.8/lib/rack/builder.rb:40:in `parse_file'
        44: from /home/rf/.rvm/gems/ruby-2.6.1/gems/rack-2.0.8/lib/rack/builder.rb:49:in `new_from_string'
        43: from /home/rf/.rvm/gems/ruby-2.6.1/gems/rack-2.0.8/lib/rack/builder.rb:49:in `eval'
        42: from config.ru:in `<main>'
        41: from config.ru:in `new'
        40: from /home/rf/.rvm/gems/ruby-2.6.1/gems/rack-2.0.8/lib/rack/builder.rb:55:in `initialize'
        39: from /home/rf/.rvm/gems/ruby-2.6.1/gems/rack-2.0.8/lib/rack/builder.rb:55:in `instance_eval'
        38: from config.ru:3:in `block in <main>'
        37: from /home/rf/.rvm/gems/ruby-2.6.1/gems/activesupport-6.0.2.1/lib/active_support/dependencies.rb:325:in `require'
        36: from /home/rf/.rvm/gems/ruby-2.6.1/gems/activesupport-6.0.2.1/lib/active_support/dependencies.rb:291:in `load_dependency'
        35: from /home/rf/.rvm/gems/ruby-2.6.1/gems/activesupport-6.0.2.1/lib/active_support/dependencies.rb:325:in `block in require'
        34: from /home/rf/.rvm/gems/ruby-2.6.1/gems/activesupport-6.0.2.1/lib/active_support/dependencies.rb:325:in `require'
        33: from /home/rf/projects/reservatic/config/environment.rb:5:in `<top (required)>'
        32: from /home/rf/.rvm/gems/ruby-2.6.1/gems/railties-6.0.2.1/lib/rails/application.rb:363:in `initialize!'
        31: from /home/rf/.rvm/gems/ruby-2.6.1/gems/railties-6.0.2.1/lib/rails/initializable.rb:60:in `run_initializers'
        30: from /home/rf/.rvm/rubies/ruby-2.6.1/lib/ruby/2.6.0/tsort.rb:205:in `tsort_each'
        29: from /home/rf/.rvm/rubies/ruby-2.6.1/lib/ruby/2.6.0/tsort.rb:226:in `tsort_each'
        28: from /home/rf/.rvm/rubies/ruby-2.6.1/lib/ruby/2.6.0/tsort.rb:347:in `each_strongly_connected_component'
        27: from /home/rf/.rvm/rubies/ruby-2.6.1/lib/ruby/2.6.0/tsort.rb:347:in `call'
        26: from /home/rf/.rvm/rubies/ruby-2.6.1/lib/ruby/2.6.0/tsort.rb:347:in `each'
        25: from /home/rf/.rvm/rubies/ruby-2.6.1/lib/ruby/2.6.0/tsort.rb:349:in `block in each_strongly_connected_component'
        24: from /home/rf/.rvm/rubies/ruby-2.6.1/lib/ruby/2.6.0/tsort.rb:431:in `each_strongly_connected_component_from'
        23: from /home/rf/.rvm/rubies/ruby-2.6.1/lib/ruby/2.6.0/tsort.rb:350:in `block (2 levels) in each_strongly_connected_component'
        22: from /home/rf/.rvm/rubies/ruby-2.6.1/lib/ruby/2.6.0/tsort.rb:228:in `block in tsort_each'
        21: from /home/rf/.rvm/gems/ruby-2.6.1/gems/railties-6.0.2.1/lib/rails/initializable.rb:61:in `block in run_initializers'
        20: from /home/rf/.rvm/gems/ruby-2.6.1/gems/railties-6.0.2.1/lib/rails/initializable.rb:32:in `run'
        19: from /home/rf/.rvm/gems/ruby-2.6.1/gems/railties-6.0.2.1/lib/rails/initializable.rb:32:in `instance_exec'
        18: from /home/rf/.rvm/gems/ruby-2.6.1/gems/railties-6.0.2.1/lib/rails/application/finisher.rb:129:in `block in <module:Finisher>'
        17: from /home/rf/.rvm/gems/ruby-2.6.1/gems/activesupport-6.0.2.1/lib/active_support/lazy_load_hooks.rb:51:in `run_load_hooks'
        16: from /home/rf/.rvm/gems/ruby-2.6.1/gems/activesupport-6.0.2.1/lib/active_support/lazy_load_hooks.rb:51:in `each'
        15: from /home/rf/.rvm/gems/ruby-2.6.1/gems/activesupport-6.0.2.1/lib/active_support/lazy_load_hooks.rb:52:in `block in run_load_hooks'
        14: from /home/rf/.rvm/gems/ruby-2.6.1/gems/activesupport-6.0.2.1/lib/active_support/lazy_load_hooks.rb:67:in `execute_hook'
        13: from /home/rf/.rvm/gems/ruby-2.6.1/gems/activesupport-6.0.2.1/lib/active_support/lazy_load_hooks.rb:62:in `with_execution_control'
        12: from /home/rf/.rvm/gems/ruby-2.6.1/gems/activesupport-6.0.2.1/lib/active_support/lazy_load_hooks.rb:69:in `block in execute_hook'
        11: from /home/rf/.rvm/gems/ruby-2.6.1/gems/activerecord-6.0.2.1/lib/active_record/railtie.rb:149:in `block (2 levels) in <class:Railtie>'
        10: from /home/rf/.rvm/gems/ruby-2.6.1/gems/activesupport-6.0.2.1/lib/active_support/lazy_load_hooks.rb:42:in `on_load'
         9: from /home/rf/.rvm/gems/ruby-2.6.1/gems/activesupport-6.0.2.1/lib/active_support/lazy_load_hooks.rb:42:in `each'
         8: from /home/rf/.rvm/gems/ruby-2.6.1/gems/activesupport-6.0.2.1/lib/active_support/lazy_load_hooks.rb:43:in `block in on_load'
         7: from /home/rf/.rvm/gems/ruby-2.6.1/gems/activesupport-6.0.2.1/lib/active_support/lazy_load_hooks.rb:67:in `execute_hook'
         6: from /home/rf/.rvm/gems/ruby-2.6.1/gems/activesupport-6.0.2.1/lib/active_support/lazy_load_hooks.rb:62:in `with_execution_control'
         5: from /home/rf/.rvm/gems/ruby-2.6.1/gems/activesupport-6.0.2.1/lib/active_support/lazy_load_hooks.rb:72:in `block in execute_hook'
         4: from /home/rf/.rvm/gems/ruby-2.6.1/gems/activesupport-6.0.2.1/lib/active_support/lazy_load_hooks.rb:72:in `class_eval'
         3: from /home/rf/.rvm/gems/ruby-2.6.1/gems/activerecord-6.0.2.1/lib/active_record/railtie.rb:151:in `block (3 levels) in <class:Railtie>'
         2: from /home/rf/.rvm/gems/ruby-2.6.1/gems/activerecord-6.0.2.1/lib/active_record/railtie.rb:151:in `each'
         1: from /home/rf/.rvm/gems/ruby-2.6.1/gems/activerecord-6.0.2.1/lib/active_record/railtie.rb:158:in `block (4 levels) in <class:Railtie>'
/home/rf/.rvm/gems/ruby-2.6.1/gems/activerecord-6.0.2.1/lib/active_record/connection_adapters/abstract_adapter.rb:227:in `schema_cache': undefined method `get_schema_cache' for nil:NilClass (NoMethodError)
```",False,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/579272523,undefined method `get_schema_cache' for nil:NilClass,richardrails,6,556204963,3,579272523,0,579252081,2020-01-28T14:30:44Z,"something with Zeitwerk? If I set 
```
config.eager_load = false
```
it works. But I need eager loading in production",False,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/579295704,undefined method `get_schema_cache' for nil:NilClass,eileencodes,6,556204963,4,579295704,0,579272523,2020-01-28T15:18:53Z,"@richardrails can you make a new Rails app that reproduces the issue? Your gemfile isn't much use for debugging this particular problem, I need to know how your models are setup.",False,0,MEMBER
https://api.github.com/repos/rails/rails/issues/comments/579624641,undefined method `get_schema_cache' for nil:NilClass,richardrails,6,556204963,5,579624641,0,579295704,2020-01-29T07:12:44Z,"I solved this issue.
It is incompatibility with gem ```activerecord-tableless```
When I remove this gem and includes in model, it works. ",False,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/579745678,undefined method `get_schema_cache' for nil:NilClass,eileencodes,6,556204963,6,579745678,0,579624641,2020-01-29T13:03:04Z,Thanks for following up @richardrails! ,False,0,MEMBER
https://api.github.com/repos/rails/rails/issues/comments/1002409960,undefined method `get_schema_cache' for nil:NilClass,Louis-7,6,556204963,7,1002409960,0,579745678,2021-12-29T05:58:32Z,@richardrails You removed `activerecord-tableless` but how to create tableless model in your application?,False,0,NONE
https://api.github.com/repos/rails/rails/issues/38340,has_many :through no longer works with UUID primary keys or custom type PKs,travisp,12,556417710,1,556417710,0,0,2020-01-28T19:26:58Z,"### Steps to reproduce
Create an application using ActiveStorage and UUIDs

Sample application modeled off guide:

https://github.com/travisp/sample-activestorage-app

Run a server, and then visit /users/new and try to create a user with an avatar attached.

### Expected behavior
Everything works correctly. The official Ruby on Rails guide for Active Storage suggests that UUIDs can be used.

### Actual behavior
Error is received while trying to create attachment:
```
In order to correctly type cast User.id, ActiveStorage::Blob needs to define a :avatar_attachment association.
```

Trace:
```
rails (f207e00eb25b) activerecord/lib/active_record/reflection.rb:772:in `block in klass'
rails (f207e00eb25b) activerecord/lib/active_record/reflection.rb:767:in `tap'
rails (f207e00eb25b) activerecord/lib/active_record/reflection.rb:767:in `klass'
rails (f207e00eb25b) activerecord/lib/active_record/associations/association.rb:139:in `klass'
rails (f207e00eb25b) activerecord/lib/active_record/associations/association.rb:246:in `find_target?'
rails (f207e00eb25b) activerecord/lib/active_record/associations/association.rb:163:in `load_target'
rails (f207e00eb25b) activerecord/lib/active_record/associations/association.rb:68:in `reload'
rails (f207e00eb25b) activerecord/lib/active_record/associations/singular_association.rb:9:in `reader'
rails (f207e00eb25b) activerecord/lib/active_record/associations/builder/association.rb:102:in `avatar_blob'
rails (f207e00eb25b) activestorage/lib/active_storage/attached/changes/create_one.rb:42:in `public_send'
rails (f207e00eb25b) activestorage/lib/active_storage/attached/changes/create_one.rb:42:in `find_attachment'
rails (f207e00eb25b) activestorage/lib/active_storage/attached/changes/create_one.rb:38:in `find_or_build_attachment'
rails (f207e00eb25b) activestorage/lib/active_storage/attached/changes/create_one.rb:15:in `attachment'
rails (f207e00eb25b) activestorage/lib/active_storage/attached/changes/create_one.rb:32:in `save'
```

If ActiveStorage::Blob is monkey patched to have an avatar_attachment association, a new error appears between variant and blob:

NotImplementedError (In order to correctly type cast ActiveStorage::VariantRecord.id, ActiveStorage::Blob needs to define a :image_attachment association.):


### System configuration
**Rails version**: 6.1.0.alpha, ref: ""f207e00""
In rails 6.0.2, this error did not occur

**Ruby version**: 2.7.0

### Other notes:
This is related to this bug report https://github.com/rails/rails/issues/36984 and was reported in a comment https://github.com/rails/rails/pull/36847#issuecomment-521897696
There was a fix https://github.com/rails/rails/pull/37120 but it did not fix activestorage",True,0,CONTRIBUTOR
https://api.github.com/repos/rails/rails/issues/comments/582524436,has_many :through no longer works with UUID primary keys or custom type PKs,travisp,12,556417710,2,582524436,0,556417710,2020-02-05T17:37:53Z,"BTW, I'm unsure if this should be 1) considered an ActiveStorage issue, 2) considered an issue with the changes for rails 6.1 in #36847 that were not very UUID friendly, or 3) if UUIDs are not to be considered supported for ActiveStorage primary keys. If someone can help by pointing me to what might be the best resolution of this, I'd be happy to take a stab at creating a PR to fix it.",False,0,CONTRIBUTOR
https://api.github.com/repos/rails/rails/issues/comments/598761573,has_many :through no longer works with UUID primary keys or custom type PKs,ryenski,12,556417710,3,598761573,0,582524436,2020-03-13T14:58:48Z,"I think this must be related to #36847, which raises an exception on all has_many :through associations when the pk is a uuid.",False,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/598916099,has_many :through no longer works with UUID primary keys or custom type PKs,jeremy,12,556417710,4,598916099,0,598761573,2020-03-13T21:19:49Z,/cc @gmcgibbon,False,0,MEMBER
https://api.github.com/repos/rails/rails/issues/comments/598952864,has_many :through no longer works with UUID primary keys or custom type PKs,ryenski,12,556417710,5,598952864,0,598916099,2020-03-13T22:16:57Z,"Here's a test script to reproduce the error: 

```rb
# frozen_string_literal: true

require 'bundler/inline'

gemfile(true) do
  source 'https://rubygems.org'

  git_source(:github) { |repo| ""https://github.com/#{repo}.git"" }

  # Activate the gem you are reporting the issue against.
  gem 'rails', github: 'rails/rails'
  gem 'pg'
end

require 'active_record'
require 'minitest/autorun'
require 'logger'

`dropdb active_record_gem_template`
`createdb -E UTF8 -T template0 active_record_gem_template`

# This connection will do for database-independent bug reports.
ActiveRecord::Base.establish_connection(adapter: 'postgresql', database: 'active_record_gem_template')
ActiveRecord::Base.logger = Logger.new(STDOUT)

ActiveRecord::Schema.define do
  enable_extension 'pgcrypto'

  create_table :documents, id: :uuid, force: true do |t|
  end

  create_table :sections, id: :uuid, force: true do |t|
    t.references :document, null: false, foreign_key: true, type: :uuid
  end

  create_table :paragraphs, id: :uuid, force: true do |t|
    t.references :section, null: false, foreign_key: true, type: :uuid
  end
end

class Document < ActiveRecord::Base
  has_many :sections
  has_many :paragraphs, through: :sections
end

class Section < ActiveRecord::Base
  belongs_to :document
  has_many :paragraphs
end

class Paragraph < ActiveRecord::Base
  belongs_to :section
end

class BugTest < Minitest::Test
  def test_document_has_many_paragraphs_through_sections
    document = Document.create!
    section =  Section.create!(document: document)
    paragraph =  Paragraph.create!(section: section)

    assert_equal 1, document.sections.count
    assert_equal 1, document.paragraphs.count
  end
end
```",False,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/598953255,has_many :through no longer works with UUID primary keys or custom type PKs,ryenski,12,556417710,6,598953255,0,598952864,2020-03-13T22:18:10Z,"Here's a link to the block that's causing the error: 

https://github.com/rails/rails/blob/99b607e6ad681b17de40d6cc55aa3af7989305db/activerecord/lib/active_record/reflection.rb#L772-L780",False,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/598953746,has_many :through no longer works with UUID primary keys or custom type PKs,ryenski,12,556417710,7,598953746,0,598953255,2020-03-13T22:19:55Z,"@travisp I think this is an ActiveRecord issue related to that PR you mentioned, unrelated to ActiveStorage.",False,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/599025405,has_many :through no longer works with UUID primary keys or custom type PKs,ekampp,12,556417710,8,599025405,0,598953746,2020-03-14T08:02:54Z,"I raised [my concerns](https://github.com/rails/rails/pull/36847#issuecomment-522696484) about that specific if-statement that @crispinheneise [mentions here](https://github.com/rails/rails/issues/38340#issuecomment-598953255) before because it seems disproportionately complex and the tests surrounding the code are sparse, so any changes here will almost inevitably have unforeseen consequences.",False,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/599869051,has_many :through no longer works with UUID primary keys or custom type PKs,jeremy,12,556417710,9,599869051,0,599025405,2020-03-17T04:15:53Z,Anyone familiar with the issue feeling motivated to work up a PR that expand support for non-integer PKs?,False,0,MEMBER
https://api.github.com/repos/rails/rails/issues/comments/601381737,has_many :through no longer works with UUID primary keys or custom type PKs,gmcgibbon,12,556417710,10,601381737,0,599869051,2020-03-19T19:44:31Z,"For historical context, this is all rooted in this problem: https://github.com/rails/rails/issues/35839#issuecomment-480064841

While you can subclass or monkey patch `ActiveStorage::Blob` and add the association to fix this problem, it is inconvenient to do so. Regarding the test case in https://github.com/rails/rails/issues/38340#issuecomment-598952864, that appears to be a case where we need to singularize the name to inflect properly. I'll take a closer look at this 🤔 

The problem with non-integer types is we don't know if they need to be quoted or not. We can flip the logic on its head and permit everything _except_ cases where we know quoting is needed (eg. binary PKs), but that doesn't seem quite right to me. We should be raising if we can't resolve the type information for the through relation.",False,0,MEMBER
https://api.github.com/repos/rails/rails/issues/comments/601388507,has_many :through no longer works with UUID primary keys or custom type PKs,ryenski,12,556417710,11,601388507,0,601381737,2020-03-19T20:00:18Z,"@gmcgibbon I think you are right. When the relationship is a `has_many through` shortcut, the value of the key in `klass.reflections` is singular (in this case ""section""). 

I did an experiment by adding a condition to singularize `options[:through]`, and it worked as expected. However, I'm not sure if this is the best way because it adds another line of complexity to an already complex statement: 

```rb
    @klass ||= delegate_reflection.compute_class(class_name).tap do |klass|
      if !parent_reflection.is_a?(HasAndBelongsToManyReflection) &&
         !(klass.reflections.key?(options[:through].to_s) ||
           (klass.reflections.key?(options[:through].to_s.pluralize) ||
            klass.reflections.key?(options[:through].to_s.singularize))) && # << Singularize
         active_record.type_for_attribute(active_record.primary_key).type != :integer
        raise NotImplementedError, <<~MSG.squish
          In order to correctly type cast #{active_record}.#{active_record.primary_key},
          #{klass} needs to define a :#{options[:through]} association.
        MSG
      end
    end
```",False,0,NONE
https://api.github.com/repos/rails/rails/issues/comments/627024961,has_many :through no longer works with UUID primary keys or custom type PKs,gmcgibbon,12,556417710,12,627024961,0,601388507,2020-05-11T23:47:58Z,"I made a test case to capture the issue a little more precisely:

```ruby
# frozen_string_literal: true

require 'bundler/inline'

gemfile(true) do
  source 'https://rubygems.org'

  git_source(:github) { |repo| ""https://github.com/#{repo}.git"" }

  # Activate the gem you are reporting the issue against.
  gem 'rails', path: '../rails'
  gem 'sqlite3'
  gem 'byebug'
end

require ""active_record""
require ""active_storage/engine""
require ""minitest/autorun""
require ""logger""

ROOT = Pathname.new(__dir__)

class Dummy < Rails::Application; end

Rails.configuration.tap do |config|
  config.eager_load = false
  config.logger = Logger.new(STDOUT)

  config.class_eval do
    def database_configuration
      { development: { adapter: ""sqlite3"", database: "":memory:"" } }
    end
  end

  config.active_storage.service_configurations = {
    development: { service: ""Disk"", root: ROOT.join(""tmp/storage"") }
  }
  config.active_storage.service = :development
end

Rails.application.initialize!

ActiveRecord::Schema.define do
  def binary_id
    ActiveRecord::Base.connection.quote(SecureRandom.uuid)
  end

  create_table :users, id: :binary, default: -> { binary_id } do |t|
    t.timestamps
  end

  create_table :active_storage_blobs do |t|
    t.string   :key,          null: false
    t.string   :filename,     null: false
    t.string   :content_type
    t.text     :metadata
    t.string   :service_name, null: false
    t.bigint   :byte_size,    null: false
    t.string   :checksum,     null: false
    t.datetime :created_at,   null: false

    t.index [ :key ], unique: true
  end

  create_table :active_storage_attachments do |t|
    t.string     :name,     null: false
    t.references :record,   null: false, polymorphic: true, index: false, type: :binary
    t.references :blob,     null: false

    t.datetime :created_at, null: false

    t.index [ :record_type, :record_id, :name, :blob_id ], name: ""index_active_storage_attachments_uniqueness"", unique: true
    t.foreign_key :active_storage_blobs, column: :blob_id
  end

  create_table :active_storage_variant_records do |t|
    t.belongs_to :blob, null: false, index: false
    t.string :variation_digest, null: false

    t.index %i[ blob_id variation_digest ], name: ""index_active_storage_variant_records_uniqueness"", unique: true
    t.foreign_key :active_storage_blobs, column: :blob_id
  end
end

class User < ActiveRecord::Base
  has_one_attached :avatar
end

class BugTest < Minitest::Test
  def test_through_cast
    avatar = ROOT.join(""tmp"", ""image.png"")
    user = User.create!
    user.avatar.attach(io: avatar.open, filename: ""image.png"")
    blob = user.avatar.blob

    assert_equal blob, user.reload.avatar_blob
  end
end
```
This revealed two interesting this:

1. From the reflection point in the predicate builder mentioned in https://github.com/rails/rails/issues/35839#issuecomment-480064841, we are trying to inflect on the table name, which is `active_storage_attachments`. Because the table name is prefixed and the associations aren't, there's no way this can work AFAICT.

2. Later down the line, the column type is inferred [here](https://github.com/rails/rails/blob/dd2acd5ec6d747ee4be00d9125e93c1a1a6dd8a7/activerecord/lib/active_record/relation/predicate_builder.rb#L60), which makes casting work in my test case (and probably 99% of usages of Active Storage using non-int IDs). The case  I'm concerned about [here](https://github.com/rails/rails/blob/99b607e6ad681b17de40d6cc55aa3af7989305db/activerecord/lib/active_record/reflection.rb#L772-L780) is when the type cannot be inferred by the table's column type. The logic is wrong, we only need to raise this error when the PK attribute type has been overridden. That should significantly cut down on false positives.",False,0,MEMBER
https://api.github.com/repos/rails/rails/issues/comments/643646901,has_many :through no longer works with UUID primary keys or custom type PKs,josh-m-sharpe,12,556417710,13,643646901,0,627024961,2020-06-13T16:34:48Z,"I was just trying out the new proxy helpers for ActiveStorage using 6.1.0-alpha (00c2d3e1e61093451a00b1b70548cfd9ae549c53) and ran into this issue.

Should this issue be added to the 6.1 milestone? https://github.com/rails/rails/issues?q=is%3Aopen+is%3Aissue+milestone%3A6.1.0",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/10103,gpSP for GBA roms not working with BIOS ,ghost,3,561117822,1,561117822,0,0,2020-02-06T16:15:43Z,"# First and foremost consider this:
- Only RetroArch bugs should be filed here. Not core bugs or game bugs
- This is not a forum or a help section, this is strictly developer oriented

## Description

[I just don't know why I can not use gpSP in Lakka on raspberry pi zero. They said I need bios in system folder, but I tried and its not work. After I put the bios in sytem folder, I open one GBA rom with gpSP core, then black screen and then back to menu. It's just can not run rom with gpSP. mGBA is working but laggy on raspberry pi zero.]

### Expected behavior

[gpSP should work when we have gba_bios.bin in system folder]

### Actual behavior

[load the rom then black screen then quit to menu.]

### Steps to reproduce the bug

1. [Install brand new lakka]
2. [put bios file into storage/system folder]
3. [open the GBA rom with gpSP emulator]

### Bisect Results

[Try to bisect and tell us when this started happening]

### Version/Commit
You can find this information under Information/System Information

- RetroArch: [version/commit]

### Environment information

- OS: [Lakka 2.3.2]
- Compiler: [In case you are running local builds]
",True,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/582983588,gpSP for GBA roms not working with BIOS ,ghost,3,561117822,2,582983588,0,561117822,2020-02-06T16:18:42Z,"I tried many times and now just flash SD to retropie, I can use gpSP with bios file. But I really like lakka, retroarch interface is very easy to use, I hope you can fix the bug, really thank you!",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/594049723,gpSP for GBA roms not working with BIOS ,ghost,3,561117822,3,594049723,0,582983588,2020-03-03T16:46:26Z,"I found the answer, you need to replace the gpsp_libretro.so file because the original file seems to been broken in Lakka 2.3.2 on raspberry pi zero version.",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/886271142,gpSP for GBA roms not working with BIOS ,bailey293,3,561117822,4,886271142,0,594049723,2021-07-25T23:07:10Z,"> I found the answer, you need to replace the gpsp_libretro.so file because the original file seems to been broken in Lakka 2.3.2 on raspberry pi zero version.

What did you replace the file with? I am currently experiencing this issue.",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/10105,Retroarch Crashes on Startup,jeflinus,6,561351372,1,561351372,0,0,2020-02-07T00:32:12Z,"Retroarch crashes in Debug mode on startup, regular retroarch hangs for about 3 minutes on a white non responding screen then boots, 

Windows 10 64 bit, Ryzen 7 1700 Eight-Core 3.00 GHz, Nvidia GTX 1080 

Graphics drivers fully updated, tried nightly and stable builds, switched from opengl to multiple other video drivers, the issue still persisted.
-------------------

> Error occurred on Thursday, February 6, 2020 at 16:22:54.
> 
> retroarch_debug.exe caused an Access Violation at location 00000000007D5B5E in module retroarch_debug.exe Reading from location 0000000000000000.
> 
> AddrPC           Params
> 00000000007D5B5E 0000000000000000 0000000000000000 0000000000000000  retroarch_debug.exe!D3D12EnableDebugLayer  [C:/msys64/home/buildbot/buildbot/windows_x64/retroarch/gfx/common/d3d12_common.h @ 942]
> 00000000007D6056 00000000109AD630 0000000010973629 0000000001226620  retroarch_debug.exe!d3d12_init_base  [C:/msys64/home/buildbot/buildbot/windows_x64/retroarch/gfx/common/d3d12_common.c @ 167]
> 00000000007D1EC7 000000000A11F550 0000000001226620 0000000001226628  retroarch_debug.exe!d3d12_gfx_init  [C:/msys64/home/buildbot/buildbot/windows_x64/retroarch/gfx/drivers/d3d12.c @ 940]
> 0000000000427CDE 000000000A11F5EF 0000000000000000 000000000000000B  retroarch_debug.exe!video_driver_init_internal  [C:/msys64/home/buildbot/buildbot/windows_x64/retroarch/retroarch.c @ 20774]
> 000000000042D3E1 00000000000003FF 00000000011FF348 0000000000CDDA61  retroarch_debug.exe!drivers_init  [C:/msys64/home/buildbot/buildbot/windows_x64/retroarch/retroarch.c @ 23427]
> 0000000000432612 0000000000000001 000000000EEA0000 0000000000000000  retroarch_debug.exe!retroarch_main_init  [C:/msys64/home/buildbot/buildbot/windows_x64/retroarch/retroarch.c @ 25578]
> 000000000044E64B 000000000A11FD40 0000000000000000 0000000000000000  retroarch_debug.exe!content_load  [C:/msys64/home/buildbot/buildbot/windows_x64/retroarch/tasks/task_content.c @ 618]
> 000000000045102E 000000000A11FD40 0000000000000001 0000000000000001  retroarch_debug.exe!task_load_content_callback  [C:/msys64/home/buildbot/buildbot/windows_x64/retroarch/tasks/task_content.c @ 2041]
> 0000000000451243 0000000000000000 0000000000000000 000000000A11FD40  retroarch_debug.exe!task_push_load_content_from_cli  [C:/msys64/home/buildbot/buildbot/windows_x64/retroarch/tasks/task_content.c @ 2122]
> 000000000040D70B 0000000000000001 000000000EEA0000 0000000000000000  retroarch_debug.exe!rarch_main  [C:/msys64/home/buildbot/buildbot/windows_x64/retroarch/retroarch.c @ 8186]
> 000000000057BF97 0000000000000001 000000000EEA0000 000000000A2A2A66  retroarch_debug.exe!SDL_main  [C:/msys64/home/buildbot/buildbot/windows_x64/retroarch/ui/drivers/qt/ui_qt_application.cpp @ 150]
> 0000000000AAED4E 0000000000000000 0000000000000027 0000000001A14038  retroarch_debug.exe!main_getcmdline
> 00000000004013B4 0000000000000000 0000000000000000 0000000000000000  retroarch_debug.exe!__tmainCRTStartup  [E:/mingwbuild/mingw-w64-crt-git/src/mingw-w64/mingw-w64-crt/crt/crtexe.c @ 339]
> 00000000004014DB 0000000000000000 0000000000000000 0000000000000000  retroarch_debug.exe!WinMainCRTStartup  [E:/mingwbuild/mingw-w64-crt-git/src/mingw-w64/mingw-w64-crt/crt/crtexe.c @ 195]
> 00007FFF7B3D7BD4 0000000000000000 0000000000000000 0000000000000000  KERNEL32.DLL!BaseThreadInitThunk
> 00007FFF7C44CED1 0000000000000000 0000000000000000 0000000000000000  ntdll.dll!RtlUserThreadStart
> 
> retroarch_debug.exe
> ntdll.dll   	10.0.18362.418
> KERNEL32.DLL	10.0.18362.329
> KERNELBASE.dll	10.0.18362.535
> apphelp.dll 	10.0.18362.1
> ADVAPI32.dll	10.0.18362.329
> msvcrt.dll  	7.0.18362.1
> sechost.dll 	10.0.18362.267
> RPCRT4.dll  	10.0.18362.476
> comdlg32.dll	10.0.18362.418
> combase.dll 	10.0.18362.449
> ucrtbase.dll	10.0.18362.387
> bcryptPrimitives.dll	10.0.18362.295
> shcore.dll  	10.0.18362.1
> USER32.dll  	10.0.18362.592
> win32u.dll  	10.0.18362.592
> GDI32.dll   	10.0.18362.1
> gdi32full.dll	10.0.18362.535
> msvcp_win.dll	10.0.18362.387
> SHLWAPI.dll 	10.0.18362.1
> SHELL32.dll 	10.0.18362.535
> COMCTL32.dll	5.82.18362.592
> cfgmgr32.dll	10.0.18362.387
> windows.storage.dll	10.0.18362.535
> profapi.dll 	10.0.18362.1
> powrprof.dll	10.0.18362.1
> UMPDC.dll
> kernel.appcore.dll	10.0.18362.1
> cryptsp.dll 	10.0.18362.1
> ole32.dll   	10.0.18362.113
> SETUPAPI.dll	10.0.18362.1
> HID.DLL     	10.0.18362.1
> DINPUT8.dll 	10.0.18362.1
> DSOUND.dll  	10.0.18362.1
> bcrypt.dll  	10.0.18362.267
> WS2_32.dll  	10.0.18362.387
> IPHLPAPI.DLL	10.0.18362.1
> MSIMG32.dll 	10.0.18362.175
> libwinpthread-1.dll	1.0.0.0
> OPENGL32.dll	10.0.18362.387
> WINMM.dll   	10.0.18362.1
> libstdc++-6.dll
> libass-9.dll
> avformat-58.dll	58.29.100.0
> avutil-56.dll	56.31.100.0
> libcaca-0.dll
> avcodec-58.dll	58.54.100.0
> cgGL.dll    	3.1.0.13
> cgD3D9.dll  	3.1.0.13
> cg.dll      	3.1.0.13
> libfreetype-6.dll	2.10.1.0
> libopenal-1.dll
> Qt5Core.dll 	5.13.2.0
> Qt5Network.dll	5.13.2.0
> CRYPT32.dll 	10.0.18362.592
> SDL2.dll    	2.0.10.0
> MSASN1.dll  	10.0.18362.1
> IMM32.dll   	10.0.18362.387
> libssl-1_1-x64.dll	1.1.1.4
> OLEAUT32.dll	10.0.18362.535
> swresample-3.dll	3.5.100.0
> swscale-5.dll	5.5.100.0
> libusb-1.0.dll	1.0.23.11397
> winmmbase.dll	10.0.18362.1
> GLU32.dll   	10.0.18362.387
> libfontconfig-1.dll
> libfribidi-0.dll
> libgcc_s_seh-1.dll
> libharfbuzz-0.dll
> libbluray-2.dll
> libbz2-1.dll
> libmfx-1.dll
> librtmp-1.dll
> libmodplug-1.dll
> libsrt.dll
> zlib1.dll
> libcelt0-2.dll
> libgsm.dll
> liblzma-5.dll	5.2.4.0
> libmp3lame-0.dll
> libopencore-amrnb-0.dll
> libopus-0.dll
> libspeex-1.dll
> libtheoradec-1.dll
> libtheoraenc-1.dll
> libvorbis-0.dll
> libvorbisenc-2.dll
> libwavpack-1.dll
> libvpx-1.dll
> libwebp-7.dll
> libwebpmux-3.dll
> libx264-157.dll	0.157.2970.0
> libpng16-16.dll
> MPR.dll     	10.0.18362.1
> NETAPI32.dll	10.0.18362.1
> USERENV.dll 	10.0.18362.387
> VERSION.dll 	10.0.18362.1
> libicuuc65.dll
> libpcre2-16-0.dll
> libzstd.dll
> libcrypto-1_1-x64.dll	1.1.1.4
> DNSAPI.dll  	10.0.18362.267
> NSI.dll     	10.0.18362.449
> libintl-8.dll	0.19.8.0
> libexpat-1.dll
> USP10.dll   	10.0.18362.476
> libgraphite2.dll
> libxml2-2.dll
> libgmp-10.dll
> libhogweed-5.dll
> WSOCK32.dll 	10.0.18362.1
> libogg-0.dll
> dxcore.dll  	10.0.18362.1
> exchndl.dll 	0.9.2.0
> PSAPI.DLL   	10.0.18362.1
> mgwhelp.dll 	0.9.2.0
> dbghelp.dll 	10.0.18362.1
> dbgcore.DLL 	10.0.18362.1
> Qt5Gui.dll  	5.13.2.0
> Qt5Widgets.dll	5.13.2.0
> libiconv-2.dll	1.16.0.0
> libgnutls-30.dll
> libopencore-amrwb-0.dll
> libopenjp2-7.dll
> libx265.dll 	3.2.0.1
> xvidcore.dll
> libdouble-conversion.dll
> libicuin65.dll
> libglib-2.0-0.dll	2.62.2.0
> libnettle-7.dll
> libicudt65.dll
> libidn2-0.dll
> libtasn1-6.dll
> dwmapi.dll  	10.0.18362.267
> UxTheme.dll 	10.0.18362.449
> CRYPTBASE.DLL	10.0.18362.1
> NETUTILS.DLL	10.0.18362.1
> SRVCLI.DLL  	10.0.18362.1
> libp11-kit-0.dll
> libunistring-2.dll	0.9.10.0
> libpcre-1.dll
> libffi-6.dll
> ncrypt.dll  	10.0.18362.1
> NTASN1.dll  	10.0.18362.1
> rsaenh.dll  	10.0.18362.1
> inputhost.dll	10.0.18362.387
> CoreUIComponents.dll	10.0.18362.207
> PROPSYS.dll 	7.0.18362.267
> wintypes.dll	10.0.18362.449
> CoreMessaging.dll	10.0.18362.1
> ntmarta.dll 	10.0.18362.1
> Start10_64.dll	1.8.0.1
> FencesMenu64.dll	3.0.9.11
> WTSAPI32.dll	10.0.18362.1
> gdiplus.dll 	10.0.18362.592
> MSCTF.dll   	10.0.18362.535
> TextInputFramework.dll	10.0.18362.267
> iertutil.dll	11.0.18362.449
> AppHook64_9C68FAD7-EB58-4A5D-AA05-FCBE25FC6E28.dll	9.6.0.6
> DEVOBJ.dll  	10.0.18362.387
> WINTRUST.dll	10.0.18362.387
> xinput1_4.dll	10.0.18362.329
> d3d12.dll   	10.0.18362.267
> 
> Windows 10.0.18362
> DrMingw 0.9.2
> 

",True,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/583907182,Retroarch Crashes on Startup,RobLoach,6,561351372,2,583907182,0,561351372,2020-02-09T23:26:49Z,Delete your retroarch.cfg and try again?,False,0,MEMBER
https://api.github.com/repos/libretro/RetroArch/issues/comments/584513256,Retroarch Crashes on Startup,jeflinus,6,561351372,3,584513256,0,583907182,2020-02-11T07:50:31Z,"I deleted it, uninstalled and reinstalled and I'm still having the same issue, I searched around and found some people posting about corsair keyboards maybe having to do with this kind of issue",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/584519192,Retroarch Crashes on Startup,inactive123,6,561351372,4,584519192,0,584513256,2020-02-11T08:12:37Z,List the exact keyboard you have.,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/584520692,Retroarch Crashes on Startup,jeflinus,6,561351372,5,584520692,0,584519192,2020-02-11T08:17:48Z,Corsair Strafe RGB Mk1,False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/584522364,Retroarch Crashes on Startup,inactive123,6,561351372,6,584522364,0,584520692,2020-02-11T08:23:48Z,Yeah that's a bit too expensive for us to purchase for the purposes of debugging it. Perhaps if somebody gifts it we could consider looking at it ourselves.,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/584542450,Retroarch Crashes on Startup,inactive123,6,561351372,7,584542450,0,584522364,2020-02-11T09:23:59Z,"See above, any dev that owns this hardware can fix it and send a PR.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/10109,snes9x stuttering on nintendo switch portable mode with gl api,asp0909,12,562545072,1,562545072,0,0,2020-02-10T13:00:12Z,"as the title says ... of course, in tv mode this does not happen, if you change the api to software mode the stutering does not appear ... this problem has enough time already ... I do not know if someone else has already reported it but don't lease it",True,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/584602274,snes9x stuttering on nintendo switch portable mode with gl api,RobLoach,12,562545072,2,584602274,0,562545072,2020-02-11T12:00:02Z,Could you provide a bit more information? Driver information? Shader info?,False,0,MEMBER
https://api.github.com/repos/libretro/RetroArch/issues/comments/584780088,snes9x stuttering on nintendo switch portable mode with gl api,asp0909,12,562545072,3,584780088,0,584602274,2020-02-11T18:23:42Z,Where is that info? ?,False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/585272265,snes9x stuttering on nintendo switch portable mode with gl api,RobLoach,12,562545072,4,585272265,0,584780088,2020-02-12T15:52:14Z,https://docs.libretro.com/guides/generating-retroarch-logs/,False,0,MEMBER
https://api.github.com/repos/libretro/RetroArch/issues/comments/585335881,snes9x stuttering on nintendo switch portable mode with gl api,m4xw,12,562545072,5,585335881,0,585272265,2020-02-12T17:59:31Z,"This is actually a old one, snes9x runs so fast it actually causes sync issues with gl.
it works fine on my sw gfx driver that I wrote, never figured why. ",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/585337535,snes9x stuttering on nintendo switch portable mode with gl api,m4xw,12,562545072,6,585337535,0,585335881,2020-02-12T18:03:18Z,"Fwiw this happens with the gl driver and that core since I wrote the implementation.
this might be related to nouveau or a obscure gl driver bug, but seems to be frontend related. ",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/586505594,snes9x stuttering on nintendo switch portable mode with gl api,asp0909,12,562545072,7,586505594,0,585337535,2020-02-14T22:38:01Z,m4xw   You could tell those who fix these things ... it would be great!,False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/586509813,snes9x stuttering on nintendo switch portable mode with gl api,m4xw,12,562545072,8,586509813,0,586505594,2020-02-14T22:52:55Z,@asp0909 That would be me,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/586516592,snes9x stuttering on nintendo switch portable mode with gl api,asp0909,12,562545072,9,586516592,0,586509813,2020-02-14T23:21:58Z,"do you fix it? I have that console just for that core, my friend...ja ja",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/586535775,snes9x stuttering on nintendo switch portable mode with gl api,m4xw,12,562545072,10,586535775,0,586516592,2020-02-15T01:01:11Z,"@asp0909 Why do u want GL tho?
Honestly, for that core, the switch video driver is exactly why its still there.
You can even have *real 1:1 pixel output* if u set ""1:1 par"" in the video settings as aspect ratio.
Guess u want shaders?

> do you fix it? 

Its so low prio that I didn't fix it for over a year (I wrote all of the switch stuff thats relevant)",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/586540069,snes9x stuttering on nintendo switch portable mode with gl api,asp0909,12,562545072,11,586540069,0,586535775,2020-02-15T01:36:34Z,"snes9x should work fine in gl, like the other cores ... and not have to switch to the Switch driver ... no core does that! and I use core provided, never 1.1, I think nobody uses that aspect ratio, and using the shaders sounds great ...",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/586540448,snes9x stuttering on nintendo switch portable mode with gl api,asp0909,12,562545072,12,586540448,0,586540069,2020-02-15T01:40:29Z,Doesn't it seem relevant to you that the core works with stuttering on the console's main video driver?,False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/586614671,snes9x stuttering on nintendo switch portable mode with gl api,m4xw,12,562545072,13,586614671,0,586540448,2020-02-15T16:16:01Z,"@asp0909 Blame nouveau, as far as I am concerned it's neither a RA bug or core bug, but a issue with the GL driver itself.
Also I dont use the core so I dont care.
You can start a bounty if you want.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/10111,(Ozone) Add DPI-based scaling,jdgleaver,3,563353855,1,563353855,0,0,2020-02-11T17:13:37Z,"## Description

This PR adds DPI-based scaling to the Ozone menu driver. The menu should now scale appropriately regardless of display size/resolution. The scale may also be adjusted manually via the `Menu Scale Factor` setting under `User Interface > Appearance`.

**Important note:** Due to the manner in which Ozone is laid out, the menu scale is capped such that the width of the left sidebar cannot be larger than 1/3 of the total window width. This prevents the menu from becoming unusable when increasing the scale. This should not affect normal operation!

## Reviewers

@natinusala 
",True,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/584753675,(Ozone) Add DPI-based scaling,inactive123,3,563353855,2,584753675,0,563353855,2020-02-11T17:25:49Z,Works great here and scales fine even at 8K (!).,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/585302239,(Ozone) Add DPI-based scaling,natinusala,3,563353855,3,585302239,0,584753675,2020-02-12T16:50:20Z,"For the record here is a small poll of Switch users concerning the current ozone scale when docked : https://twitter.com/natinusala/status/1227308205967052801?s=19

""It looks just fine"" means that the menu doesn't need scaling according to them
""It's too small"" means that the menu need scaling to them
""It's too big"" means they are using binoculars to play docked I don't know what's wrong with them",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/585321101,(Ozone) Add DPI-based scaling,jdgleaver,3,563353855,4,585321101,0,585302239,2020-02-12T17:29:23Z,"Hi @natinusala,

With the fix I just pushed, this PR should produce (virtually) identical behaviour to the current master on Switch - the only difference will be the ability to manually adjust the scale. We're waiting on some testing, but it should be fine!",False,0,CONTRIBUTOR
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/632,Upgrades Even If --No-Upgrade Specified,Blackjacx,5,555723232,1,555723232,0,0,2020-01-27T17:29:18Z,"Upgrades are performed even if no-upgrade is performed. This behavior siverges from similar, existing package managers like Bundler, Cocoapods, Carthage. There if you only execute an ""install"" you can be sure nothing is updated. This is especially good when the project is shared using git with multiple team mates.",True,0,NONE
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/578925106,Upgrades Even If --No-Upgrade Specified,MikeMcQuaid,5,555723232,2,578925106,0,555723232,2020-01-27T19:59:11Z,`--no-upgrade` is not a documented or supported flag. Homebrew does not support workflows where packages are installed and not updated.,False,0,MEMBER
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/579162310,Upgrades Even If --No-Upgrade Specified,Blackjacx,5,555723232,3,579162310,0,578925106,2020-01-28T09:46:02Z,"Hmm but `brew bundle --help` gives me 🤔:

```
Install or upgrade all dependencies in a Brewfile.

    -v, --verbose         Print the output from commands as they are
                                     run.
    --no-upgrade        Don't run brew upgrade on outdated
                                     dependencies. Note they may still be
                                     upgraded by brew install if needed.
```
But ok good to know.",False,0,NONE
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/579205566,Upgrades Even If --No-Upgrade Specified,MikeMcQuaid,5,555723232,4,579205566,0,579162310,2020-01-28T11:39:45Z,"Apologies, I just checked the README (that's out of date and I'll fix it).

> Note they may still be upgraded by brew install if needed.

Does this not cover the behaviour your describe? Is `brew upgrade` being run when it shouldn't be?",False,0,MEMBER
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/579234825,Upgrades Even If --No-Upgrade Specified,Blackjacx,5,555723232,5,579234825,0,579205566,2020-01-28T13:02:17Z,"Well, when I run e.g. `bundle update` it updates and when I run `bundle install` it installs the versions from the lock file. All the major dependency managers behave this way. With `brew bundle` it is currently not possible to retain certain version on a git branch and other version on a different one.

But it's not a drama for me ;-)",False,0,NONE
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/579241038,Upgrades Even If --No-Upgrade Specified,MikeMcQuaid,5,555723232,6,579241038,0,579234825,2020-01-28T13:18:12Z,This is not a normal language dependency manager and the lock file does not pin versions.,False,0,MEMBER
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/641,Add trailing newline to lock file,ghost,3,562432173,1,562432173,0,0,2020-02-10T09:31:03Z,"Adds a trailing newline to the lock file to make its last line conform to the [POSIX standard for lines](https://pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap03.html#tag_03_206):

> 3.206 Line
>
> A sequence of zero or more non- \<newline\> characters plus a terminating \<newline\> character.

I'm not that fluent in rspec so I wasn't sure how to add a test that mocks `Pathname` to actually  check what is written to the lock file in the locker spec. Let me know if I should have a deeper look into that!",True,0,NONE
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/584095503,Add trailing newline to lock file,MikeMcQuaid,3,562432173,2,584095503,0,562432173,2020-02-10T12:17:23Z,"Makes sense to me! 
Thanks so much for your first contribution! Without people like you submitting PRs we couldn't run this project. You rock, @daniel-mohemian",False,0,MEMBER
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/584116706,Add trailing newline to lock file,ghost,3,562432173,3,584116706,0,584095503,2020-02-10T13:15:19Z,"Thanks @MikeMcQuaid!

Out of curiosity: How do releases work for external commands like `bundler`? Will they be included in one of the next `brew` releases?",False,0,NONE
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/584311535,Add trailing newline to lock file,MikeMcQuaid,3,562432173,4,584311535,0,584116706,2020-02-10T19:35:41Z,"There are no releases, you `brew update` always to the latest version/`master`.",False,0,MEMBER
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/646,Unknown command: bundle,brandon-leapyear,16,568504032,1,568504032,0,0,2020-02-20T18:59:22Z,"Seeing this in our CI right now:
```
+ export HOMEBREW_BUNDLE_NO_LOCK=1
+ HOMEBREW_BUNDLE_NO_LOCK=1
+ brew bundle check --no-upgrade
==> Tapping homebrew/bundle
Cloning into '/usr/local/Homebrew/Library/Taps/homebrew/homebrew-bundle'...
remote: Enumerating objects: 93, done.
remote: Counting objects: 100% (93/93), done.
remote: Compressing objects: 100% (84/84), done.
remote: Total 93 (delta 4), reused 34 (delta 2), pack-reused 0
UnpacUnpacking objects: 100% (93/93), done.
Tapped (192 files, 262.8KB).
Error: Unknown command: bundle
+ brew bundle --no-upgrade
Error: Unknown command: bundle
```

I suspect it has something to do with the PR that was just merged #643 ?",True,0,NONE
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/589264265,Unknown command: bundle,MikeMcQuaid,16,568504032,2,589264265,0,568504032,2020-02-20T19:23:09Z,You likely need to `brew update`. If that's not fixing it: run `brew config` and paste your output here.,False,0,MEMBER
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/589266023,Unknown command: bundle,brandon-leapyear,16,568504032,3,589266023,0,589264265,2020-02-20T19:27:00Z,"I'll try that, thanks. I thought `brew` automatically updates, though?

> it is a rolling release package manager

https://github.com/Homebrew/homebrew-bundle/pull/552#issuecomment-553178488",False,0,NONE
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/589366157,Unknown command: bundle,jablko,16,568504032,4,589366157,0,589266023,2020-02-20T22:07:00Z,I'm investigating the [same error message](https://travis-ci.org/junegunn/fzf/jobs/653161626#L126). I'm using the Travis CI [Homebrew addon](https://docs.travis-ci.com/user/installing-dependencies#installing-packages-on-macos).,False,0,NONE
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/589384838,Unknown command: bundle,jablko,16,568504032,5,589384838,0,589366157,2020-02-20T22:32:06Z,Adding `update: true` to my `.travis.yml` (documented [here](https://docs.travis-ci.com/user/installing-dependencies#installing-packages-on-macos)) did solve the problem. It sounds like Homebrew Bundle now depends on a newer version of Homebrew than the one included on the Travis CI VM?,False,0,NONE
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/589391621,Unknown command: bundle,casconed,16,568504032,6,589391621,0,589384838,2020-02-20T22:49:15Z,"> I'll try that, thanks. I thought `brew` automatically updates, though?
> 
> > it is a rolling release package manager
> 
> [#552 (comment)](https://github.com/Homebrew/homebrew-bundle/pull/552#issuecomment-553178488)

Travis (and maybe other CI systems) doesn't run `brew update`. From the Travis docs:

>By default, the Homebrew addon will not run brew update before installing packages. brew update can take a long time and slow down your builds.
",False,0,NONE
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/589393926,Unknown command: bundle,jablko,16,568504032,7,589393926,0,589391621,2020-02-20T22:54:18Z,"Yes, I think Homebrew Bundle now depends on `external_ruby_v2_cmd_path`, introduced in Homebrew/brew@8a9dcad2c708ce945695029c5af79b4b3965a4de and distributed in [version 2.2.5](https://github.com/Homebrew/brew/commits/2.2.5).",False,0,NONE
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/589398680,Unknown command: bundle,jablko,16,568504032,8,589398680,0,589393926,2020-02-20T23:05:09Z,Linking to the Travis CI community forum [thread](https://travis-ci.community/t/macos-build-fails-because-of-homebrew-bundle-unknown-command/7296).,False,0,NONE
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/589670816,Unknown command: bundle,MikeMcQuaid,16,568504032,9,589670816,0,589398680,2020-02-21T14:15:48Z,"> Travis (and maybe other CI systems) doesn't run `brew update`. From the Travis docs:
> > By default, the Homebrew addon will not run brew update before installing packages. brew update can take a long time and slow down your builds.

Travis should stop doing this. Running `brew update` can take some time (although it's been steadily improving) but not running `brew update` will break your builds (case in point here).
",False,0,MEMBER
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/589743195,Unknown command: bundle,casconed,16,568504032,10,589743195,0,589670816,2020-02-21T17:03:22Z,"> Travis should stop doing this. 

No doubt, or at least stay more on top of making sure tools like homebrew are updated more than every six weeks or so. Would be nice also to get a deprecation notice from the software tools before functionality gets removed and things start breaking. 

Thanks for all your work on this project!",False,0,NONE
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/589748945,Unknown command: bundle,MikeMcQuaid,16,568504032,11,589748945,0,589743195,2020-02-21T17:17:40Z,"> Would be nice also to get a deprecation notice from the software tools before functionality gets removed and things start breaking.

No, sorry, you've misunderstood how this works:

- Homebrew (except for the package manager itself in Homebrew/brew) is a rolling release package manager which auto-updates by default so everyone is on the latest `master` branch of all repositories
- Travis CI have disabled this functionality for all taps and Homebrew itself
- They do not include e.g. `brew bundle` in their image at a supported version
- When you `brew tap` in their unsupported configuration (it normally auto-updates) you end up on the latest version of a tap which will likely fail

I'm not sure how we can really address this beyond ""don't allow people with auto-update disabled to tap new taps"" which will break things even further for Travis CI users (but perhaps is warranted).

> Thanks for all your work on this project!

Thanks for your kind words: they are genuinely appreciated.",False,0,MEMBER
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/589756670,Unknown command: bundle,jablko,16,568504032,12,589756670,0,589748945,2020-02-21T17:37:52Z,"It sounds like some Travis CI users [notice the performance](https://github.com/cyberbotics/webots/pull/1393) of `brew update`? Maybe when Travis updates macOS virtual machines, if they include the current version of Homebrew, they should also include the current version of Homebrew Bundle? You could still set `update: true` to get the latest version of both, but you wouldn't end up with this mismatch between the latest version of one and stale version of the other?",False,0,NONE
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/589770552,Unknown command: bundle,casconed,16,568504032,13,589770552,0,589756670,2020-02-21T18:14:27Z,"@jablko the issue was the other way around - the Travis image includes an older version of Homebrew, and was tapping the latest version of Bundle. @MikeMcQuaid is right - the answer is to just always run the auto-update.",False,0,NONE
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/589771090,Unknown command: bundle,MikeMcQuaid,16,568504032,14,589771090,0,589770552,2020-02-21T18:15:58Z,"Ultimately this is all down to Travis. I (and Homebrew) stopped using them years ago personally due to the host of problems with their macOS workers (performance, reliability, stuff mentioned here).",False,0,MEMBER
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/589802943,Unknown command: bundle,jablko,16,568504032,15,589802943,0,589771090,2020-02-21T19:36:11Z,"I opened a [macOS Packer Templates PR](https://github.com/travis-ci/packer-templates-mac/pull/13) to add Homebrew Bundle to the macOS images. Does that look right? Aside from the fact that disabling auto-update will continue to cause mismatches with other taps ...

Incidentally I tried adding `env: HOMEBREW_NO_AUTO_UPDATE=` to my `.travis.yml` (unset HOMEBREW_NO_AUTO_UPDATE) but this didn't provoke Homebrew to auto-update and resolve the current error, unlike `update: true` does. I'm not sure how Travis is disabling auto-update, but haven't investigated further.",False,0,NONE
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/589947004,Unknown command: bundle,MikeMcQuaid,16,568504032,16,589947004,0,589802943,2020-02-22T11:26:37Z,"> I opened a [macOS Packer Templates PR](https://github.com/travis-ci/packer-templates-mac/pull/13) to add Homebrew Bundle to the macOS images. Does that look right?

Have commented, thanks! Beyond that I'm not sure I know enough about Travis to help further.",False,0,MEMBER
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/589969895,Unknown command: bundle,jablko,16,568504032,17,589969895,0,589947004,2020-02-22T16:03:29Z,Thank you for the feedback!,False,0,NONE
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/655,Support for whalebrew,jacobbednarz,6,576648052,1,576648052,0,0,2020-03-06T02:03:51Z,"I've been using Docker (alot) lately using an approach similar to [Jess Frazelle's `dockerfunc` setup](https://github.com/jessfraz/dotfiles/blob/master/.dockerfunc). More recently, I've started using [Whalebrew](https://github.com/whalebrew/whalebrew) which elegantly shims in Docker images inplace of a full binary. For example, take a look at the contents of [`/usr/local/bin/wget`](https://github.com/whalebrew/whalebrew-packages/blob/master/wget/Dockerfile).

This is working pretty-ok at the moment but I have hit a couple of times where I've used a Homebrew package instead of the intended Whalebrew wrapped-package due to to managing the packages via a Brewfile. This got me thinking, would it make sense to add Whalebrew as an addon for Homebrew Bundle? I don't know how used Whalebrew is at the moment so if this is just me, it's probably not worth it but if there is interest from others, it may be worth enabling something.

If this was to go ahead, the Brewfile would look a little something like this:

```rb
brew ""wget""
brew ""whalebrew""
whalebrew ""httpie"" 
``` 

Or perhaps more like `mas` where you don't need to explicitly mention the source brew package.

```rb
brew ""wget""
whalebrew ""httpie""
```

Thoughts? I'm happy to POC something together if there is any interest outside of myself.",True,0,MEMBER
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/595579441,Support for whalebrew,colindean,6,576648052,2,595579441,0,576648052,2020-03-06T03:18:27Z,I'm not super hot about it but I'm not opposed. Can you come up with some statistics that could help understand how many people are using `whalebrew` and bundle and would benefit from this integration?,False,0,MEMBER
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/595580883,Support for whalebrew,jacobbednarz,6,576648052,3,595580883,0,595579441,2020-03-06T03:23:43Z,"I can reach out to the `whalebrew` maintainers but I can't quite see how we could map that overlap seeing how it's not an existing integration and I would assume most people are currently using Docker + Homebrew separately or in a duct tape bash solution I mentioned in the initial description. Do you have any ideas on measuring it?

There is another alternative here whereby we look at pulling non-brew integrations out from the core repository and define a integrations hook system where can load/unload as needed (think taps but for bundle).",False,0,MEMBER
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/595780236,Support for whalebrew,MikeMcQuaid,6,576648052,4,595780236,0,595580883,2020-03-06T14:00:56Z,I don't think we need statistics for this but I'm not opposed if the code is pretty easy/simple (i.e. no more complex than `mas` integration).,False,0,MEMBER
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/595939667,Support for whalebrew,jacobbednarz,6,576648052,5,595939667,0,595780236,2020-03-06T19:54:35Z,Sure thing. I’d imagine it being the same size (most likely smaller) than `mas` as the interface is pretty simple. How about I put up the PR with the integration and we can make a call on it then?,False,0,MEMBER
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/596087953,Support for whalebrew,MikeMcQuaid,6,576648052,6,596087953,0,595939667,2020-03-07T13:22:46Z,Sounds good! No hard feelings if we don't merge it.,False,0,MEMBER
https://api.github.com/repos/Homebrew/homebrew-bundle/issues/comments/598091145,Support for whalebrew,MikeMcQuaid,6,576648052,7,598091145,0,596087953,2020-03-12T09:33:25Z,Closing in favour of PR in https://github.com/Homebrew/homebrew-bundle/pull/656,False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/16621,Error in Agg backend's PNG renderer when `markeredgewidth > markersize`,brunobeltran,6,573609761,1,573609761,0,0,2020-03-01T20:29:19Z,"<!--To help us understand and resolve your issue, please fill out the form to the best of your ability.-->
<!--You can feel free to delete the sections that do not apply.-->

### Bug report

**Bug summary**

Whenever the edge width of a marker is increased beyond the size of the marker, you would want the marker to 

**Code for reproduction**

<!--A minimum code snippet required to reproduce the bug.
Please make sure to minimize the number of dependencies required, and provide
any necessary plotted data.
Avoid using threads, as Matplotlib is (explicitly) not thread-safe.-->

```python
import matplotlib.pyplot as plt
for i in range(0, 150, 20):
    fig, ax = plt.subplots()
    lines = ax.plot(0, 0, marker='p', markersize=60, markeredgewidth=i, 
                    markeredgecolor='k', clip_on=False)
    plt.xlim([-0.04, 0.04])
    plt.ylim([-0.04, 0.04])
    plt.savefig(f'/home/bbeltr1/Downloads/test_{i}.png')
fig._cachedRenderer
```

**Actual outcome**

<!--The output produced by the above code, which may be a screenshot, console output, etc.-->

While the outer extents of the pentagon's edge appear correct, you can see that the inner extents begin to recede away from the center as the edge width is set larger and larger, until eventually the original marker is fully visible again, along with some of the background.

Console output:
`<matplotlib.backends.backend_agg.RendererAgg at 0x7f5277bf0e80>`

Saved images:
![test_0](https://user-images.githubusercontent.com/1475390/75633133-397f2c80-5bb7-11ea-870c-72d336625caa.png)
![test_20](https://user-images.githubusercontent.com/1475390/75633134-3b48f000-5bb7-11ea-93f7-d6e1ff4b4523.png)
![test_40](https://user-images.githubusercontent.com/1475390/75633135-3d12b380-5bb7-11ea-8ae6-8e96145ac49d.png)
![test_60](https://user-images.githubusercontent.com/1475390/75633136-3edc7700-5bb7-11ea-8d9f-e544f7919c3f.png)
![test_80](https://user-images.githubusercontent.com/1475390/75633138-41d76780-5bb7-11ea-912f-67d4cda2c0ac.png)
![test_100](https://user-images.githubusercontent.com/1475390/75633140-43a12b00-5bb7-11ea-9b51-7a78eb2e2dc1.png)
![test_120](https://user-images.githubusercontent.com/1475390/75633143-4734b200-5bb7-11ea-9379-952432ecaf89.png)
![test_140](https://user-images.githubusercontent.com/1475390/75633144-4865df00-5bb7-11ea-9f81-ae6e1aa4a1d9.png)


**Expected outcome**

The expected outcome is a fully-shaded pentagon (due to the edge being huge). My PDF backend does this correctly, as seen below in a screenshot  of what `test_140.pdf` looks like if I save as `'test_{i}.pdf'` instead:

![test_140 pdf](https://user-images.githubusercontent.com/1475390/75633195-b5797480-5bb7-11ea-9c32-7eeb07e16a3d.png)


**Matplotlib version**
<!--Please specify your platform and versions of the relevant libraries you are using:-->
  * Operating system: Debian 9
  * Matplotlib version: 3.1.3
  * Matplotlib backend (`print(matplotlib.get_backend())`): `module://ipykernel.pylab.backend_inline` is what gets printed, and inline plots also show this error, but I can take Jupyter out of the loop by saving directly to file. Both cases are apparently using `RendererAgg` to make the PNG, as seen above.
  * Python version: 3.7.3
  * Jupyter version (if applicable):
  * Other libraries: 

Matplotlib was installed and updated via the default conda channel.
<!--Please tell us how you installed matplotlib and python e.g., from source, pip, conda-->
<!--If you installed from conda, please specify which channel you used if not the default-->

",True,0,CONTRIBUTOR
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/595979167,Error in Agg backend's PNG renderer when `markeredgewidth > markersize`,brunobeltran,6,573609761,2,595979167,0,573609761,2020-03-06T21:47:42Z,"I'm sure whoever (if anyone) eventually tackles this will notice, but this looks like a typical ""even/odd"" vs ""non-zero"" fill style mix up (see e.g. https://www.slideshare.net/Mark_Kilgard/22pathrender, slide 21). ",False,0,CONTRIBUTOR
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/596040609,Error in Agg backend's PNG renderer when `markeredgewidth > markersize`,tacaswell,6,573609761,3,596040609,0,595979167,2020-03-07T03:22:17Z,"I wonder if mplcairo has this problem...

That is wild how did you find this?",False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/596393934,Error in Agg backend's PNG renderer when `markeredgewidth > markersize`,QuLogic,6,573609761,4,596393934,0,596040609,2020-03-09T08:29:42Z,"This does not affect mplcairo:
![image](https://user-images.githubusercontent.com/302469/76195361-8027e480-61be-11ea-8a2a-6717a705f967.png)
",False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/596430035,Error in Agg backend's PNG renderer when `markeredgewidth > markersize`,anntzer,6,573609761,5,596430035,0,596393934,2020-03-09T09:49:38Z,This also doesn't seem to affect mplcairo even if setting the fill rule (with cairo_set_fill_rule) to even-odd (the default is nonzero).,False,0,CONTRIBUTOR
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/596975899,Error in Agg backend's PNG renderer when `markeredgewidth > markersize`,brunobeltran,6,573609761,6,596975899,0,596430035,2020-03-10T09:03:51Z,"> I wonder if mplcairo has this problem...
> 
> That is wild how did you find this?

Writing tests for #16607, of course wanted to make sure formulas work in fat/thin marker edge cases.",False,0,CONTRIBUTOR
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/1627969200,Error in Agg backend's PNG renderer when `markeredgewidth > markersize`,github-actions[bot],6,573609761,7,1627969200,0,596975899,2023-07-10T02:10:47Z,"This issue has been marked ""inactive"" because it has been 365 days since the last comment. If this issue is still present in recent Matplotlib releases, or the feature request is still wanted, please leave a comment and this label will be removed. If there are no updates in another 30 days, this issue will be automatically closed, but you are free to re-open or create a new issue if needed. We value issue reports, and this procedure is meant to help us resurface and prioritize issues that have not been addressed yet, not make them disappear.  Thanks for your help!",False,0,NONE
https://api.github.com/repos/matplotlib/matplotlib/issues/16624,Azure pipelines are broken on v3.2.x,QuLogic,5,573652768,1,573652768,0,0,2020-03-02T00:37:25Z,"As noted in #16612, Azure doesn't seem to post on non-`master` PRs.

If you go to Azure, and check the Runs (not Recent for some reason), then you can find the `v3.2.x` builds, and the latest one fails
https://dev.azure.com/matplotlib/matplotlib/_build/results?buildId=8691&view=results

In fact, it's been failing for a _long_ time.",True,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/593174034,Azure pipelines are broken on v3.2.x,QuLogic,5,573652768,2,593174034,0,573652768,2020-03-02T00:49:26Z,"Build log says we're building with FreeType 2.10.1, which explains the small image failures.",False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/593264462,Azure pipelines are broken on v3.2.x,QuLogic,5,573652768,3,593264462,0,593174034,2020-03-02T07:43:53Z,"The linked PR fixed macOS, but not Windows: https://dev.azure.com/matplotlib/matplotlib/_build/results?buildId=9280&view=logs&j=7fb64067-7f42-5414-94b1-b7d4c3501c77&t=350b785d-724e-5d38-bb09-cca4c8ab57f2&l=410",False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/593605954,Azure pipelines are broken on v3.2.x,QuLogic,5,573652768,4,593605954,0,593264462,2020-03-02T20:30:11Z,"Sigh, still not fixed https://dev.azure.com/matplotlib/matplotlib/_build/results?buildId=9283&view=results

I'll see if I can set this up on my fork to iterate quicker.",False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/593720401,Azure pipelines are broken on v3.2.x,QuLogic,5,573652768,5,593720401,0,593605954,2020-03-03T01:34:48Z,"Setting up a fork is a bit of a pain, but I realized I can just push it here.",False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/598886730,Azure pipelines are broken on v3.2.x,tacaswell,5,573652768,6,598886730,0,593720401,2020-03-13T19:52:03Z,Closed by #16640,False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/16626,Updated Readme + Setup.py for PyPa,story645,6,573722956,1,573722956,0,0,2020-03-02T05:16:17Z,"## PR Summary
PyPI will  render readmes written in [plaintext, markdown or rst](https://packaging.python.org/guides/making-a-pypi-friendly-readme/) , so wanted to take advantage of that since the current mpl page is kind of sparse: https://pypi.org/project/matplotlib/

While updating the readme & setup.py for pictures (logo and a grainy version of the frontpage quartet - would love some help here to improve it), I also added the discourse and funding links in setup.py ([project urls are fluid](https://packaging.python.org/guides/distributing-packages-using-setuptools/#project-urls) & updated some of the readme links 'cause the old references had been moved. Also shortened and moved around some content to try and make the readme a bit concise. 

This is also sort of a model for what packages should do if #16592 goes in.",True,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/593416314,Updated Readme + Setup.py for PyPa,tacaswell,6,573722956,2,593416314,0,573722956,2020-03-02T14:01:36Z,Is there anyway to check how pypi is going to interpret the updated strings (short of releasing as seeing what it does)?,False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/593560540,Updated Readme + Setup.py for PyPa,story645,6,573722956,3,593560540,0,593416314,2020-03-02T18:56:22Z,"@tacaswell apparently yes: https://packaging.python.org/guides/making-a-pypi-friendly-readme/#validating-restructuredtext-markup
```
twine check dist/*
```
ETA1 I think I'm accidentally gonna learn about packaging 😅 
ETA2: 
```
Checking dist\matplotlib-3.2.0rc2+1618.g1f13cc811.tar.gz: PASSED
```
Now to figure out how to automate that 😓 ",False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/593947626,Updated Readme + Setup.py for PyPa,tacaswell,6,573722956,4,593947626,0,593560540,2020-03-03T13:23:36Z,I'm going to merge this and then manually do the backport so I can (finally) get the 3.2.0 tag done.,False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/593948262,Updated Readme + Setup.py for PyPa,lumberbot-app[bot],6,573722956,5,593948262,0,593947626,2020-03-03T13:25:06Z,"Owee, I'm MrMeeseeks, Look at me.

There seem to be a conflict, please backport manually. Here are approximate instructions:

1. Checkout backport branch and update it.

```
$ git checkout v3.2.x
$ git pull
```

2. Cherry pick the first parent branch of the this PR on top of the older branch:
```
$ git cherry-pick -m1 64ae32323f9d997c00bf36326dc1d4196618c7b1
```

3. You will likely have some merge/cherry-pick conflict here, fix them and commit:

```
$ git commit -am 'Backport PR #16626: Updated Readme + Setup.py for PyPa'
```

4. Push to a named branch :

```
git push YOURFORK v3.2.x:auto-backport-of-pr-16626-on-v3.2.x
```

5. Create a PR against branch v3.2.x, I would have named this PR:

> ""Backport PR #16626 on branch v3.2.x""

And apply the correct labels and milestones.

Congratulation you did some good work ! Hopefully your backport PR will be tested by the continuous integration and merged soon!

If these instruction are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).
                ",False,0,NONE
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/593957024,Updated Readme + Setup.py for PyPa,tacaswell,6,573722956,6,593957024,0,593948262,2020-03-03T13:44:42Z,"I have done the backport locally, will push soon.",False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/593981502,Updated Readme + Setup.py for PyPa,tacaswell,6,573722956,7,593981502,0,593957024,2020-03-03T14:34:19Z,Manually backported via 65a35ef,False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/16628,Different rendring between show() and savefig(),student-sx,12,573961068,1,573961068,0,0,2020-03-02T13:05:40Z,"Savefig() gives me a different output than show() in the following example

```python
import matplotlib
import matplotlib.pyplot as plt
import numpy as np



# matplotlib.rc('font', family='serif')
# matplotlib.rc('font', size=16)
# matplotlib.rc('legend', fontsize=16)
# matplotlib.rc('legend', numpoints=1)
# matplotlib.rc('legend', handlelength=1.5)
# matplotlib.rc('legend', frameon=False)
# matplotlib.rc('xtick.major', pad=7)
# matplotlib.rc('xtick.minor', pad=7)
# matplotlib.rc('text', usetex=True)
# matplotlib.rc('text.latex', 
#               preamble=[r'\usepackage[T1]{fontenc}',
#                         r'\usepackage{amsmath}',
#                         r'\usepackage{txfonts}',
#                         r'\usepackage{textcomp}'])
 



X = np.arange(-10, 10, 1)
Y = np.arange(-10, 10, 1)
U, V = np.meshgrid(X, Y)

R = np.sqrt(U**2 + V**2)

fig, ax = plt.subplots()
q = ax.quiver(X, Y, U/R, V/R,color='gray',scale_units='inches',scale=4)

ax.set_title('Math test: $\int_a^b f(x) \,\mathrm{d}x$')

plt.savefig('quiver_test.pdf',dpi=fig.dpi)
plt.show()

```

Result of show():

![Selection_029](https://user-images.githubusercontent.com/18629143/75678767-a31e3a00-5c8e-11ea-875b-b9d4906dd6a7.png)


Resulting pdf:

![Selection_028](https://user-images.githubusercontent.com/18629143/75678708-85e96b80-5c8e-11ea-837a-3f881864d711.png)



**Matplotlib version**
<!--Please specify your platform and versions of the relevant libraries you are using:-->
  * Operating system: Linux (ubuntu 19.04)
  * Matplotlib version: 3.0.2
  * Matplotlib backend (`print(matplotlib.get_backend())`): TkAgg
  * Python version: 3.7.3

How can I force savefig to produce exactly the same output as show() (even with the font and latex settings added, which I commented out in my code above)
",True,0,NONE
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/593403062,Different rendring between show() and savefig(),ImportanceOfBeingErnest,12,573961068,2,593403062,0,573961068,2020-03-02T13:31:43Z,"It looks like you changed the figure size of the shown figure, e.g. by maximizing the figure window to screen size or similar. If you don't do that, both figures will be the same.
",False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/593904753,Different rendring between show() and savefig(),student-sx,12,573961068,3,593904753,0,593403062,2020-03-03T11:29:25Z,No I didn't rescale it.,False,0,NONE
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/593909431,Different rendring between show() and savefig(),ImportanceOfBeingErnest,12,573961068,4,593909431,0,593904753,2020-03-03T11:42:53Z,"If the figure wasn't changed, it would have dimensions 640 by 480 pixels. Given that it has 1604 by 899 pixels *something* needs to cause it to change. That could be a system setting to maximize the GUI window, or a doubleclick, which wasn't on purpose or anything similar. ",False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/594059326,Different rendring between show() and savefig(),jklymak,12,573961068,5,594059326,0,593909431,2020-03-03T17:04:43Z,Also please make sure that your rcparameters are all cleared (i.e. move `~/.matplotlib/matplotlibrc` to `~/.matplotlib/matplotlibrc.Old`) and try again.  This seems unlikely to be a matplotlib bug. ,False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/594067934,Different rendring between show() and savefig(),timhoffm,12,573961068,6,594067934,0,594059326,2020-03-03T17:22:13Z,"By default the first plot including the window should look similar to this.

![grafik](https://user-images.githubusercontent.com/2836374/75801708-ddb1d080-5d7b-11ea-9839-99e9545def8a.png)

",False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/594138752,Different rendring between show() and savefig(),student-sx,12,573961068,7,594138752,0,594067934,2020-03-03T19:56:24Z,"Hm. I have saved the figure from the show command using a screenshot. If I do it via the save button below, it looks like
![Figure_1](https://user-images.githubusercontent.com/18629143/75813986-435c8780-5d91-11ea-9e2f-27a435acf48b.png)

Exactly like my screenshot. I also don't have any `.matplotlib` directory.
",False,0,NONE
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/594147157,Different rendring between show() and savefig(),ImportanceOfBeingErnest,12,573961068,8,594147157,0,594138752,2020-03-03T20:16:05Z,"Could you show a screenshot of your complete screen? What's your screen's resolution? Do you have a special window manager installed in ubuntu? Do you use some ""high-dpi"" setting?",False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/594158346,Different rendring between show() and savefig(),student-sx,12,573961068,9,594158346,0,594147157,2020-03-03T20:42:25Z,"I am using xmonad. Screen resolution depends if I use the laptop screen or an external monitor, but both times the same. Yes I think I have some high dpi settings for qt and gtk.",False,0,NONE
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/594162826,Different rendring between show() and savefig(),timhoffm,12,573961068,10,594162826,0,594158346,2020-03-03T20:53:07Z,"HiDPI may influence the rendering, but it should not affect the aspect ratio of the figure.",False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/594196337,Different rendring between show() and savefig(),jklymak,12,573961068,11,594196337,0,594162826,2020-03-03T22:09:18Z,Try installing qt and setting the backend to qt5Agg?  Just to see if this is backend dependent?  ,False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/594209008,Different rendring between show() and savefig(),tacaswell,12,573961068,12,594209008,0,594196337,2020-03-03T22:41:49Z,"Can you put in a `print(fig.get_size_inches())` before and after `plt.show()`?  My guess is that when it is getting tiled by xmonad the size is getting changed (to make it much bigger).  The fonts are sized in absolute units so if you make the figure bigger and then scale the two to be the same size the font will look way smaller in the bigger image.

",False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/731320821,Different rendring between show() and savefig(),jklymak,12,573961068,13,731320821,0,594209008,2020-11-20T17:56:56Z,I'll close for lack of response but feel free to get back to us if we can help....,False,0,MEMBER
https://api.github.com/repos/mitmproxy/mitmproxy/issues/3895,Graceful shutdown,Prinzhorn,3,593786227,1,593786227,0,0,2020-04-04T09:45:57Z,"**Is your feature request related to a problem? Please describe.**
I'm spawning `mitmdump` from a parent process and communicate bidirectionally using gRPC. When I exit the parent process I'd like to ask mitmdump to gracefully shutdown. What I mean by graceful is something like:

1. Stop accepting new client connections and do not open new server connections
2. Let existing HTTP requests finish
3. Close WebSocket connections

A configurable timeout as a new option would also be useful. In the best case all connections can be closed gracefully and we get all `clientdisconnet`, `serverdisconnect`, `tcp_end` and `websocket_end` events. One exception might be long running TCP connections not associated with HTTP or WebSockets, because we lack the semantics for a graceful shutdown.
 
#### Describe the solution you'd like
Mitmproxy should explicitly handle SIGTERM. I could also imagine having an API that can be called from within an addon (on `ctx`), but signals would suffice. Not sure how these things work on Windows but of course it should also work on Windows. A new `shutdown` event might also be useful to give addons a chance to react in the scope of the timeout.

It might also currently a bug that `mitmdump` doesn't trigger the `done` event at all, neither via SIGINT nor SIGTERM.

#### Describe alternatives you've considered
Not sure if there is an alternative right now. All I can do is kill the thing.

#### Additional context

```
Mitmproxy: 5.0.1
Python:    3.7.5
OpenSSL:   OpenSSL 1.1.0j  20 Nov 2018
Platform:  Linux-5.3.0-45-generic-x86_64-with-Ubuntu-19.10-eoan
```
",True,0,MEMBER
https://api.github.com/repos/mitmproxy/mitmproxy/issues/comments/609017411,Graceful shutdown,mhils,3,593786227,2,609017411,0,593786227,2020-04-04T11:55:10Z,"That's a sensible feature request, albeit a bit tricky to implement due to the TCP connections you pointed out. We can probably do much better here with sans-io, where the core proxy server is managed in an addon.

> It might also currently a bug that mitmdump doesn't trigger the done event at all, neither via SIGINT nor SIGTERM.

Yes, see #3572.",False,0,MEMBER
https://api.github.com/repos/mitmproxy/mitmproxy/issues/comments/609648003,Graceful shutdown,Prinzhorn,3,593786227,3,609648003,0,609017411,2020-04-06T08:21:56Z,"> That's a sensible feature request, albeit a bit tricky to implement due to the TCP connections you pointed out. We can probably do much better here with sans-io, where the core proxy server is managed in an addon.

I see. Maybe we'll come up with a better solution in the future. Once `done` is fixed in `mitmdump` that makes it usable at least. What if instead of just exiting we could explicitly close all connections (without any special treatment for HTTP/WebSockets) to at least get the full event lifecycle? Maybe we can get new events like `clientdrop` and `serverdrop`? They would also be useful when `flow.kill()` is explicitly used.",False,0,MEMBER
https://api.github.com/repos/mitmproxy/mitmproxy/issues/comments/1659462686,Graceful shutdown,nshuba,3,593786227,4,1659462686,0,609648003,2023-08-01T02:18:29Z,"Hello, is there any update on this?

I am running into a similar problem. I am on Windows, using Python to start `mitmdump` and then sending a `CTRL_C_EVENT` to stop the proxy. This triggers the `done` event and works ok for the most part, but sometimes, after sending a `CTRL_C_EVENT`, the `mitmdump` process does not finish for a long time (over 30mins). I thought it may have been remaining CLOSE_WAIT connections, but even after closing them via TcpViewer, the process kept running. 

Sending `SIGTERM` kills `mitmdump` , but then the `done` event isn't triggered. Any advice? Based on [this SO answer](https://stackoverflow.com/questions/68654077/is-there-a-way-to-start-mitmproxy-v-7-0-2-programmatically-in-the-background/68661172#68661172), using Python to directly start/stop `mitmdump` is not supported either.",False,0,NONE
https://api.github.com/repos/mitmproxy/mitmproxy/issues/3896,"ServerConnection.source_address has a default value of ('', 0)",Prinzhorn,4,593788893,1,593788893,0,0,2020-04-04T10:03:39Z,"#### Problem Description
`source_address` should be `None` until it is known. Currently it is `('', 0)` which is an odd value.

**Note**:  #3881 ""fixes"" the issue, inside `serverconnect` the value is now also properly populated. However, the default value still does not align with others and I'm not sure where else it might pop up. It should be `None` for consistency. Currently you cannot check if the value is set, because it is always set to a tuple.

#### Steps to reproduce the behavior:
`mitmdump --quiet --scripts conn.py`

```python
def serverconnect(conn):
  print('-------connect--------------')
  print(conn.id)
  print(conn.address)
  print(conn.ip_address)
  print(conn.source_address)
  print(conn.connected())
  print('-------/connect--------------')

def serverdisconnect(conn):
  print('----------disconnect-----------')
  print(conn.id)
  print(conn.address)
  print(conn.ip_address)
  print(conn.source_address)
  print(conn.connected())
  print('----------/disconnect-----------')
```

```
-------connect--------------
026f902f-001b-4e0e-a17d-8ee16a027dca
('www.google.com', 80)
None
('', 0)
False
-------/connect--------------
----------disconnect-----------
026f902f-001b-4e0e-a17d-8ee16a027dca
('www.google.com', 80)
('2a00:1450:4001:81f::2004', 80, 0, 0)
('2a02:810b:1040:8398:61a2:13f8:be5f:9eff', 41361, 0, 0)
False
----------/disconnect-----------
```

**Output with master branch**

```
-------connect--------------
6e73001d-cbc2-45db-9e68-e2809efe51f6
('www.google.com', 80)
('2a00:1450:4001:81f::2004', 80, 0, 0)
('2a02:810b:1040:8398:61a2:13f8:be5f:9eff', 47873, 0, 0)
True
-------/connect--------------
----------disconnect-----------
6e73001d-cbc2-45db-9e68-e2809efe51f6
('www.google.com', 80)
('2a00:1450:4001:81f::2004', 80, 0, 0)
('2a02:810b:1040:8398:61a2:13f8:be5f:9eff', 47873, 0, 0)
False
----------/disconnect-----------
```

#### System Information

```
Mitmproxy: 5.0.1
Python:    3.7.5
OpenSSL:   OpenSSL 1.1.0j  20 Nov 2018
Platform:  Linux-5.3.0-45-generic-x86_64-with-Ubuntu-19.10-eoan
```",True,0,MEMBER
https://api.github.com/repos/mitmproxy/mitmproxy/issues/comments/609006394,"ServerConnection.source_address has a default value of ('', 0)",Prinzhorn,4,593788893,2,609006394,0,593788893,2020-04-04T10:06:49Z,"I just noticed the additional `0, 0`. What's up with them? I thought it'd be tuples of length 2 with ip+port. Is that some ipv6 stuff I don't know about?

Edit: wow, I can read. Totally forgot

> For AF_INET6 address family, a four-tuple (host, port, flowinfo, scopeid) is used, where flowinfo and scopeid represent the sin6_flowinfo and sin6_scope_id members in struct sockaddr_in6 in C. For socket module methods, flowinfo and scopeid can be omitted just for backward compatibility. Note, however, omission of scopeid can cause problems in manipulating scoped IPv6 addresses.

https://docs.python.org/3/library/socket.html

Are these two relevant for mitmproxy at all? Maybe we should slice them away for consistency?",False,0,MEMBER
https://api.github.com/repos/mitmproxy/mitmproxy/issues/comments/609007452,"ServerConnection.source_address has a default value of ('', 0)",Prinzhorn,4,593788893,3,609007452,0,609006394,2020-04-04T10:18:08Z,"On a related note: can we rename `address` vs `ip_address`? They're misleading. `ip_address` does not contain the ip address, but a tuple. Maybe rename to `resolved_address` instead? Because it's basically `address` but it is guaranteed that the host has been resolved if it wasn't an IP already?

Here are the misleading code comments

https://github.com/mitmproxy/mitmproxy/blob/3cd37652709292cffa1bc733134cef5483489341/mitmproxy/connections.py#L168-L169",False,0,MEMBER
https://api.github.com/repos/mitmproxy/mitmproxy/issues/comments/609018940,"ServerConnection.source_address has a default value of ('', 0)",mhils,4,593788893,4,609018940,0,609007452,2020-04-04T12:07:52Z,"> source_address should be None until it is known. Currently it is ('', 0) which is an odd value.

Yes, I fixed this on the mystical sans-io branch already. 🙊 https://github.com/mitmproxy/mitmproxy/blob/744f7e5720eb3cb01958f6342b64d1eea9bf42b0/mitmproxy/proxy2/context.py#L20-L21

> On a related note: can we rename `address` vs `ip_address`? 

This sounds sensible. How about we go with `peername` and `sockname` for all connections, and additionally `address` for server connections? This would align with the Berkeley socket API.


> [flowinfo and scopeid in the IPv6 four-tuple] Are these two relevant for mitmproxy at all? Maybe we should slice them away for consistency?

Tricky question. I _think_ we shouldn't discard them unless it causes us major pain. For example, if someone were to use link-local IPv6 addresses with mitmproxy, sin6_scope_id is very relevant. I'm not saying that anyone ever does this for practical purposes, but we may want to have support for it to just allow security researchers to fiddle with it.",False,0,MEMBER
https://api.github.com/repos/mitmproxy/mitmproxy/issues/comments/609650308,"ServerConnection.source_address has a default value of ('', 0)",Prinzhorn,4,593788893,5,609650308,0,609018940,2020-04-06T08:26:42Z,"> Yes, I fixed this on the mystical sans-io branch already. speak_no_evil

sans-io seems to be a cool dude



> This sounds sensible. How about we go with `peername` and `sockname` for all connections, and additionally `address` for server connections? This would align with the Berkeley socket API.

Never heard either term. But I'm all for consistency. I assume the new code will have comments such as

https://github.com/mitmproxy/mitmproxy/blob/3cd37652709292cffa1bc733134cef5483489341/mitmproxy/connections.py#L16-L32

because they've helped me a lot.

> Tricky question. I _think_ we shouldn't discard them unless it causes us major pain. For example, if someone were to use link-local IPv6 addresses with mitmproxy, sin6_scope_id is very relevant. I'm not saying that anyone ever does this for practical purposes, but we may want to have support for it to just allow security researchers to fiddle with it.

Ok, it doesn't hurt to keep them. I just don't know what they're for (yet) and might find them useful myself.",False,0,MEMBER
https://api.github.com/repos/mitmproxy/mitmproxy/issues/3899,Don't force host header on outgoing requests,mhils,4,593886121,1,593886121,0,0,2020-04-04T14:17:57Z,"It is not really clear why we did this, so we stop doing this and see who complains.",True,0,MEMBER
https://api.github.com/repos/mitmproxy/mitmproxy/issues/comments/609035842,Don't force host header on outgoing requests,Kriechi,4,593886121,2,609035842,0,593886121,2020-04-04T14:21:52Z,"If I get asked in 5 years from now, why I approved this PR, I will deny everything!",False,0,MEMBER
https://api.github.com/repos/mitmproxy/mitmproxy/issues/comments/679370289,Don't force host header on outgoing requests,ghost,4,593886121,3,679370289,0,609035842,2020-08-24T21:15:05Z,"Should i still be seeing the `Host:` header in flow views if it doesn't get output by `_assemble_request_headers`? I noticed that even if the `Host:` header is displayed in mitmproxy ui, it still doesn't show up in the raw export for a request and presumably the actual request as well.

Also it might be a good idea to always add the host header? From https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Host
```text
    A Host header field must be sent in all HTTP/1.1 request messages. A 400 (Bad
    Request) status code may be sent to any HTTP/1.1 request message that lacks a
    Host header field or that contains more than one.
```",False,0,NONE
https://api.github.com/repos/mitmproxy/mitmproxy/issues/comments/679379371,Don't force host header on outgoing requests,mhils,4,593886121,4,679379371,0,679370289,2020-08-24T21:36:41Z,"> Also it might be a good idea to always add the host header? From https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Host

Generally yes, but our use case for mitmproxy is a bit different: We want to pass-through requests _as-is_. It would be not very helpful if your requests work with your debugger (mitmproxy) on the line, but not without.",False,0,MEMBER
https://api.github.com/repos/mitmproxy/mitmproxy/issues/comments/679379677,Don't force host header on outgoing requests,mhils,4,593886121,5,679379677,0,679379371,2020-08-24T21:37:31Z,"Regarding your first question, we have a bunch of related changes on master. If you have inconsistencies there, please open a new issue :)",False,0,MEMBER
https://api.github.com/repos/mitmproxy/mitmproxy/issues/3901,(request/feature) Transparent TLSv1.2 websocket analysis not working,tsujp,6,594259528,1,594259528,0,0,2020-04-05T05:01:40Z,"**Is your feature request related to a problem? Please describe.**

Yes it is. I am trying to DE TLSv1.2 packets of a game so that I can make those API calls outside of the game itself, for statistical analysis. I've used Wireshark and mitmproxy to determine that the game is requesting a websocket upgrade, receives an HTTP 101 upgrade from the server after which all traffic is over said websocket. Mitmproxy doesn't display this, and I cannot get certificates working with mitmdump despite even with this issue: https://github.com/mitmproxy/mitmproxy/issues/899#issuecomment-608996389

The result is always `Client Handshake failed. The client may not trust the proxy's certificate`. Note, the certificates are fine when using `mitmproxy` for the initial websocket upgrade so I don't understand.

#### Describe the solution you'd like

Viewing websocket data transparently within `mitmproxy` or instructions on how to dump decrypted websocket data with `mitmdump`, as I cannot get certificates to work.

#### Describe alternatives you've considered

I've tried every single library I can find for MiTM proxy self-attacks and none work, almost all are designed for browsers which this application is not and uses no part of. I've also tried `MITMPROXY_SSLKEYLOGFILE` but of course this doesn't do anything since it refuses the certificate to start the handshake, as well as `SSLKEYLOGFILE` and `LD_PRELOAD` which as far as I know are also browser specific.

#### Additional context

My `mitmdump` command is as follows (foobar.py is from the issue aforementioned)

```
mitmdump -s ./foobar.py -p 8081 --cert *=~/.mitmproxy/mitmproxy-ca-cert.pem --set block_global=false --set keep_host_header=true
```",True,0,NONE
https://api.github.com/repos/mitmproxy/mitmproxy/issues/comments/609370481,(request/feature) Transparent TLSv1.2 websocket analysis not working,Kriechi,6,594259528,2,609370481,0,594259528,2020-04-05T07:15:05Z,"You do not need to specify the mitmproxy certs from the default directory.
You do not need to generate your own CA and certs - mitmproxy takes care of it on the first start.

Does the game still work with mitmproxy/mitmdump active, or do all requests fail?
Which mitmproxy version?
Which OS?
How do you configure your game to use mitmproxy?
Did you try mitmproxy/mitmdump with `-vvv`?",False,0,MEMBER
https://api.github.com/repos/mitmproxy/mitmproxy/issues/comments/609394149,(request/feature) Transparent TLSv1.2 websocket analysis not working,tsujp,6,594259528,3,609394149,0,609370481,2020-04-05T10:29:08Z,"@Kriechi  ah whoops, maybe I had borked something earlier but I took the certificate defintion off and am getting this error now, as with `-vvv`.

```
192.168.1.139:48892: clientconnect
::ffff:192.168.1.139:48892: Establish TLS with client
 << Invalid HTTP request form (expected: authority or absolute, got: relative)
::ffff:192.168.1.139:48892: request
  -> HTTP protocol error in client request: Invalid HTTP request form (expected: authority or absolute, got: relative)
192.168.1.139:48892: clientdisconnect
```

> Does the game still work with mitmproxy/mitmdump active, or do all requests fail?

All online requests fail with the error described at the top of this comment.

> Which mitmproxy version?
> Which OS?

Mitmproxy: 5.0.1
Python:    3.8.2
OpenSSL:   OpenSSL 1.1.1e  17 Mar 2020
Platform:  Linux-5.5.10-arch1-1-x86_64-with-glibc2.2.5


> How do you configure your game to use mitmproxy?

```bash
sudo sysctl -w net.ipv4.ip_forward=1
sudo sysctl -w net.ipv6.conf.all.forwarding=1
sudo sysctl -w net.ipv4.conf.all.send_redirects=0
sudo iptables -t nat -A OUTPUT -p tcp -m owner ! --uid-owner mitmproxyuser --dport 80 -j REDIRECT --to-port 8080
sudo iptables -t nat -A OUTPUT -p tcp -m owner ! --uid-owner mitmproxyuser --dport 443 -j REDIRECT --to-port 8080
sudo iptables -t nat -A OUTPUT -p tcp -m owner ! --uid-owner mitmproxyuser --dport 60442 -j REDIRECT --to-port 8081
```

The last line redirects the games specific 60442 to 8081 instead of 8080 so that I can use mitmdump for that. Then:

```bash
sudo -u mitmproxyuser bash -c 'mitmproxy --mode transparent --showhost --set block_global=false --set keep_host_header=true'

mitmdump -s ./foobar.py -p 8081
```

> Did you try mitmproxy/mitmdump with -vvv?

I have done now and have posted the error at the top of this comment.",False,0,NONE
https://api.github.com/repos/mitmproxy/mitmproxy/issues/comments/609394340,(request/feature) Transparent TLSv1.2 websocket analysis not working,tsujp,6,594259528,4,609394340,0,609394149,2020-04-05T10:30:41Z,"If I add `--mode transparent` (I forgot) I instead get:

```
192.168.1.139:49052: clientconnect
::ffff:192.168.1.139:49052: Establish TLS with client
::ffff:192.168.1.139:49052: request
  -> Request(GET /)
::ffff:192.168.1.139:49052: serverconnect
  -> ('37.187.27.57', 60442)
::ffff:192.168.1.139:49052: Establish TLS with server
192.168.1.139:40521: clientconnect
::ffff:192.168.1.139:40521: Establish TLS with client
192.168.1.139:40521: Client Handshake failed. The client may not trust the proxy's certificate for master.shirogames.com.
192.168.1.139:40521: ClientHandshakeException('Cannot establish TLS with client (sni: master.shirogames.com): TlsException(""SSL handshake error: Error([(\'SSL routines\', \'ssl3_read_bytes\', \'tlsv1 alert decrypt error\')])"")')
192.168.1.139:40521: clientdisconnect
192.168.1.139:49052: GET https://37.187.27.57:60442/
    Host: master.shirogames.com
    Upgrade: websocket
    Connection: Upgrade
    Sec-WebSocket-Key: SjNN5gbKf+FHXSzpc/3GUQ==
    Sec-WebSocket-Version: 13
    X-Ident: northgard
    X-Pass: 5b69ae0b2864a49d753b27fe974c36a485d605ca
 << Certificate verification error for master.shirogames.com: certificate signature failure (errno: 7, depth: 0)
::ffff:192.168.1.139:49052: serverdisconnect
  -> ('37.187.27.57', 60442)
192.168.1.139:49052: clientdisconnect
```",False,0,NONE
https://api.github.com/repos/mitmproxy/mitmproxy/issues/comments/609394849,(request/feature) Transparent TLSv1.2 websocket analysis not working,Kriechi,6,594259528,5,609394849,0,609394340,2020-04-05T10:34:49Z,@mhils could this be a case of client cert pinning?,False,0,MEMBER
https://api.github.com/repos/mitmproxy/mitmproxy/issues/comments/609408095,(request/feature) Transparent TLSv1.2 websocket analysis not working,mhils,6,594259528,6,609408095,0,609394849,2020-04-05T12:24:14Z,"We have two separate issues here:

**First,** there is a connection from :49052 which is intercepted just fine. However, the upstream server's certificate is not trusted, which is why mitmproxy does not continue: 
```
192.168.1.139:49052: GET https://37.187.27.57:60442/
    Host: master.shirogames.com
    Upgrade: websocket
    Connection: Upgrade
    Sec-WebSocket-Key: SjNN5gbKf+FHXSzpc/3GUQ==
    Sec-WebSocket-Version: 13
    X-Ident: northgard
    X-Pass: 5b69ae0b2864a49d753b27fe974c36a485d605ca
 << Certificate verification error for master.shirogames.com: certificate signature failure (errno: 7, depth: 0)
```
The fix here is to set mitmproxy's ssl_insecure option to true.


**Second,** there is a connection from :40521 which we can't intercept:
```
192.168.1.139:40521: Client Handshake failed. The client may not trust the proxy's certificate for master.shirogames.com.
192.168.1.139:40521: ClientHandshakeException('Cannot establish TLS with client (sni: master.shirogames.com): TlsException(""SSL handshake error: Error([(\'SSL routines\', \'ssl3_read_bytes\', \'tlsv1 alert decrypt error\')])"")')
```
This likely is certificate pinning.",False,0,MEMBER
https://api.github.com/repos/mitmproxy/mitmproxy/issues/comments/652803264,(request/feature) Transparent TLSv1.2 websocket analysis not working,danghuong18,6,594259528,7,652803264,0,609408095,2020-07-02T06:05:55Z,"> We have two separate issues here:
> 
> **First,** there is a connection from :49052 which is intercepted just fine. However, the upstream server's certificate is not trusted, which is why mitmproxy does not continue:
> 
> ```
> 192.168.1.139:49052: GET https://37.187.27.57:60442/
>     Host: master.shirogames.com
>     Upgrade: websocket
>     Connection: Upgrade
>     Sec-WebSocket-Key: SjNN5gbKf+FHXSzpc/3GUQ==
>     Sec-WebSocket-Version: 13
>     X-Ident: northgard
>     X-Pass: 5b69ae0b2864a49d753b27fe974c36a485d605ca
>  << Certificate verification error for master.shirogames.com: certificate signature failure (errno: 7, depth: 0)
> ```
> 
> The fix here is to set mitmproxy's ssl_insecure option to true.
> 
> **Second,** there is a connection from :40521 which we can't intercept:
> 
> ```
> 192.168.1.139:40521: Client Handshake failed. The client may not trust the proxy's certificate for master.shirogames.com.
> 192.168.1.139:40521: ClientHandshakeException('Cannot establish TLS with client (sni: master.shirogames.com): TlsException(""SSL handshake error: Error([(\'SSL routines\', \'ssl3_read_bytes\', \'tlsv1 alert decrypt error\')])"")')
> ```
> 
> This likely is certificate pinning.

I cant capture websockets, could you help me?
I tried everything but it still didn't work.

**My version mitmproxy:**
Mitmproxy: 5.1.1
Python:    3.8.2
OpenSSL:   OpenSSL 1.1.1g  21 Apr 2020
Platform:  Windows-10-10.0.18362-SP0

Thanks.
",False,0,NONE
https://api.github.com/repos/openscad/openscad/issues/3264,parent_module() wrong return,RonaldoCMP,17,589872230,1,589872230,0,0,2020-03-29T20:03:08Z,"That is what I get with just the test code loaded to the editor:

![parent_module_1](https://user-images.githubusercontent.com/19966253/77859262-313eff00-7200-11ea-8bbf-213201203462.PNG)

But when other codes are loaded a different result comes out:

![parent_module_2](https://user-images.githubusercontent.com/19966253/77859281-59c6f900-7200-11ea-934e-54730978e083.PNG)

show_quad_mesh() is a function defined in new_CP.scad
",True,0,NONE
https://api.github.com/repos/openscad/openscad/issues/comments/605692480,parent_module() wrong return,t-paul,17,589872230,2,605692480,0,589872230,2020-03-29T20:06:28Z,Please add the text of the scripts in addition.,False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/605707749,parent_module() wrong return,RonaldoCMP,17,589872230,3,605707749,0,605692480,2020-03-29T21:54:14Z,">
> Please add the text of the scripts in addition.
>
>
Do you mean the code of newCP.scad? That is a somewhat big code I am
working on. But even after I close it the the parent_module code still
returns the same string ""show_quad_mesh"".

>
>
",False,0,NONE
https://api.github.com/repos/openscad/openscad/issues/comments/605708686,parent_module() wrong return,t-paul,17,589872230,4,605708686,0,605707749,2020-03-29T22:02:37Z,"Everything related, specifically including the code from the images. It seems like reasonably small test case. That might increase the chances someone tries to fix the issue.",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/605715148,parent_module() wrong return,nophead,17,589872230,5,605715148,0,605708686,2020-03-29T22:57:23Z,"Isn't parent_module(2) out of bounds when there is just one parent?

On Sun, 29 Mar 2020 at 23:02, Torsten Paul <notifications@github.com> wrote:

> Everything related, specifically including the code from the images. It
> seems like reasonably small test case. That might increase the chances
> someone tries to fix the issue.
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/openscad/openscad/issues/3264#issuecomment-605708686>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAEKHBMMIWR7TYOUBGD5MC3RJ7AQVANCNFSM4LWDHTJA>
> .
>
",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/605715493,parent_module() wrong return,t-paul,17,589872230,6,605715493,0,605715148,2020-03-29T23:00:32Z,"Yes, I'm wondering about that too. The code seems to have a valid bounds check, but maybe there's some wrong data in that stack of module names.",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/605718583,parent_module() wrong return,RonaldoCMP,17,589872230,7,605718583,0,605715493,2020-03-29T23:28:59Z,"It should and do it ... sometimes.

In a fresh window, run:
module top() {
   children();
 }

x = 0;
top() echo(parent_module(x)); 

It should corretly echo ""top"". Now, initialize x with 3. It will warn that x is greater than the number of modules on the stack. Then reset x to 1. then 2, then 3. It will echo ""top"" in the first two cases and issue a warn to the  last one.  Set x to 4 then reset to 3 again. It  will echo ""top"" once more.

It seems that it retains some memory from previous runs.

I am unable to reproduce the first case a have reported before.

I using version 2019.10.25.ci3851 (git feee8f02) 
",False,0,NONE
https://api.github.com/repos/openscad/openscad/issues/comments/605722025,parent_module() wrong return,t-paul,17,589872230,8,605722025,0,605718583,2020-03-29T23:58:29Z,"Oh, thanks, that's a good hint. So it probably does not clean out the module name stack at all. This would only be visible when trying to access out of bounds index values.",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/612459694,parent_module() wrong return,t-paul,17,589872230,9,612459694,0,605722025,2020-04-11T16:34:35Z,"I can' reproduce that, tested
- Fresh debug build from master (Debian/Testing)
- Fresh release build from master (Debian/Testing)
- 2019.10.25.ci3851 downloaded from file server via `wine`
",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/619473509,parent_module() wrong return,vcfxb,17,589872230,10,619473509,0,612459694,2020-04-26T03:08:55Z,"I am also having this issue. OpenSCAD 2019.05 for Windows. 
```
/*
Nia Calia-Bogan
April 25th, 2020
OpenSCAD 2019.05

Utilities for tracing through parents of a given.
*/

// Module that immediately calls children, without any operation.
module Nop() {children();echo(_list_parents());}

// Returns list of parent modules. 
// Currently not working.
function _list_parents() = 
    [for (i = [0:$parent_modules-1]) parent_module(i)];

module ListChildren() {
    children();
}

ListChildren() Nop();
```
output:
`ECHO: [""Nop"", ""ListChildren"", ""AssertIsList""]`",False,0,NONE
https://api.github.com/repos/openscad/openscad/issues/comments/619473722,parent_module() wrong return,vcfxb,17,589872230,11,619473722,0,619473509,2020-04-26T03:11:42Z,"For context, there are several other files in the same directory (none are referenced by this file). One of those files contains a module called AssertIsList. That file happens to be open in another window, but this still happens when that window is closed.",False,0,NONE
https://api.github.com/repos/openscad/openscad/issues/comments/619473867,parent_module() wrong return,vcfxb,17,589872230,12,619473867,0,619473722,2020-04-26T03:13:24Z,"If all the windows are closed though, and then this file is reopened, the bug disappears.",False,0,NONE
https://api.github.com/repos/openscad/openscad/issues/comments/619473946,parent_module() wrong return,vcfxb,17,589872230,13,619473946,0,619473867,2020-04-26T03:14:29Z,I think somewhere stuff just needs to get flushed or reloaded or something?,False,0,NONE
https://api.github.com/repos/openscad/openscad/issues/comments/619474093,parent_module() wrong return,t-paul,17,589872230,14,619474093,0,619473946,2020-04-26T03:16:07Z,"Yes, see my suspicion above, it's just hard to do a fix if it's not reproducible on the dev machine. I'll try again with some combinations of multiple windows and tabs.",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/624904379,parent_module() wrong return,t-paul,17,589872230,15,624904379,0,619474093,2020-05-06T21:37:23Z,"The [forum post](http://forum.openscad.org/parent-modules-increases-each-time-the-recursion-limit-is-broken-in-2019-5-0-td29050.html) seems to have given the important hint that it's happening on compile errors. @RonaldoCMP do you have ""Stop on first Warning"" active?",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/624923701,parent_module() wrong return,RonaldoCMP,17,589872230,16,624923701,0,624904379,2020-05-06T22:26:58Z,Usually yes but in my reported case there was no warning.,False,0,NONE
https://api.github.com/repos/openscad/openscad/issues/comments/624933243,parent_module() wrong return,t-paul,17,589872230,17,624933243,0,624923701,2020-05-06T22:56:56Z,"So far I could only reproduce after an assert or compile error happened (potentially in a different tab) and that should be fixed in:

[Windows 32bit](https://4978-1049088-gh.circle-artifacts.com/0/32-bit/OpenSCAD-2020.05.06.ci4978-x86-32_fix-parent-module-stack.zip)
[Windows 64bit](https://4979-1049088-gh.circle-artifacts.com/0/64-bit/OpenSCAD-2020.05.06.ci4979-x86-64_fix-parent-module-stack.zip)
[Linux AppImage](https://4977-1049088-gh.circle-artifacts.com/0/64-bit/OpenSCAD-2020.05.06.ai4977-_fix-parent-module-stackd7da70a-x86_64.AppImage)
",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/626217357,parent_module() wrong return,RonaldoCMP,17,589872230,18,626217357,0,624933243,2020-05-09T18:29:39Z,Yes! It worked nice on my Windows 64 system.,False,0,NONE
https://api.github.com/repos/openscad/openscad/issues/3265,Add Export STL option to Viewer-Toolbar when Editor Pane is hidden ,Sharma-Hrishabh,8,592108544,1,592108544,0,0,2020-04-01T18:12:51Z,Fixes #1900,True,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/607503841,Add Export STL option to Viewer-Toolbar when Editor Pane is hidden ,t-paul,8,592108544,2,607503841,0,592108544,2020-04-01T21:40:41Z,It should be possible to use the same action in multiple places. That would also prevent 2 showing up when editing keyboard shortcuts.,False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/607568118,Add Export STL option to Viewer-Toolbar when Editor Pane is hidden ,MichaelAtOz,8,592108544,3,607568118,0,607503841,2020-04-02T01:21:23Z,"@Sharma-Hrishabh  Looks good, thanks.
Once @t-paul is happy, you can claim the bounty.
IIRC you need to 'Solve Issue', [here](https://www.bountysource.com/issues/40462106-feature-request-when-editor-pane-hidden-add-export-stl-icon-to-preview-icon-list), then I close the issue and you can claim it.
",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/607707890,Add Export STL option to Viewer-Toolbar when Editor Pane is hidden ,Sharma-Hrishabh,8,592108544,4,607707890,0,607568118,2020-04-02T08:43:33Z,"Surely it is possible @t-paul . I tried this at first, but keeping the same action in both the toolbar, will not allow to show the option in one condition and hide it in another condition. Consider-

`viewerToolBar->actions().at(2)->setVisible(true);`
`editortoolbar->actions().at(12)->setVisible(false);`

If we have used the same action, then both the above lines would have returned reference to the same action, and the line which will be executed recently will have the final effect, so by the above snippet, export STL will be hidden at both the places- editor as well as viewer toolbar.

To avoid that condition, I made a different instance of the action.

",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/607727061,Add Export STL option to Viewer-Toolbar when Editor Pane is hidden ,t-paul,8,592108544,5,607727061,0,607707890,2020-04-02T09:21:39Z,"If we want to hide the action, we'd need to remove if I suspect. Is the hiding used currently?",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/607763639,Add Export STL option to Viewer-Toolbar when Editor Pane is hidden ,Sharma-Hrishabh,8,592108544,6,607763639,0,607727061,2020-04-02T10:34:27Z,"Yes, I used hiding currently. But your point, that it won't be a good idea for keyboard shortcuts lead me to these two methods in the documentation. 
[https://doc.qt.io/qt-5.12/qwidget.html#insertAction](https://doc.qt.io/qt-5.12/qwidget.html#insertAction)
[https://doc.qt.io/qt-5.12/qwidget.html#removeAction](https://doc.qt.io/qt-5.12/qwidget.html#removeAction)
I think they will help, ",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/609057591,Add Export STL option to Viewer-Toolbar when Editor Pane is hidden ,t-paul,8,592108544,7,609057591,0,607763639,2020-04-04T16:55:14Z,"I think it's trying to catch the event of hiding the editor in the wrong place. It seems to work when using the ""Hide Editor"" menu entry, but not when just closing the editor pane via the GUI close button.

Maybe `MainWindow::on_editorDock_visibilityChanged()`?
",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/609373760,Add Export STL option to Viewer-Toolbar when Editor Pane is hidden ,Sharma-Hrishabh,8,592108544,8,609373760,0,609057591,2020-04-05T07:38:44Z,"@t-paul , It was because I should have checked for visibility rather than isChecked(). I will fix that.
I tried the same approach in 'on_editorDock_visibilityChanged()' method, but it also has a problem. if we leave the editor dock hidden and then relaunch the software, the option is not there until you tweak with the visibility of editor again.
So, I think we can also add one line in the constructor of MainWindow, to handle that. It will cover all the cases then.",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/609418571,Add Export STL option to Viewer-Toolbar when Editor Pane is hidden ,t-paul,8,592108544,9,609418571,0,609373760,2020-04-05T13:40:44Z,"Yes, good point. That's the same issue which makes the preferences dialog code so annoyingly verbose. I don't think there's much way around having both the init and the update case handled.",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/3266,PDF export of 2D Outlines,tbharathchandra,55,592653288,1,592653288,0,0,2020-04-02T13:56:50Z,"This adds Export of 2D model to PDF as requested in #3188 using [Cairo](https://www.cairographics.org/) 

- [x] Add Cairo to the project
- [x] Add 'Export as PDF' to the export menu. 
- [x] Add Export 2D model to PDF single page portrait, no scaling, origin bottom left
- [x] Add Header: Title, Filename.
- [x] Add X/Y scale
- [x] Follow suggestion regarding border and scales from https://github.com/openscad/openscad/pull/3266#issuecomment-612693457
- Set meta data (may need to be conditional as it's only availabe with cairo 1.16)
  - [x] ""Title"" = just source file name (no path)
  - [x] ""Creator"" = ""OpenSCAD (https://www.openscad.org/)"" (no version number for now)
  - ~~""Producer"" = ""cairo (https://www.cairographics.org)"" (removing default version number, adding https instead of http)~~ not possible with cairo 1.16
  - [x] Remove create & modification date (or set to empty string?)
- [x] Add test case

",True,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/608999326,PDF export of 2D Outlines,tbharathchandra,55,592653288,2,608999326,0,592653288,2020-04-04T09:03:58Z,Travis build passed https://travis-ci.org/github/openscad/openscad/builds/670874847 ,False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/609049012,PDF export of 2D Outlines,t-paul,55,592653288,3,609049012,0,608999326,2020-04-04T15:55:30Z,"Trying the current state, that looks nice already. One (hopefully simple) additional idea would be to fill out some of the meta data (screenshot of the file properties in evince pdf viewer):

![grafik](https://user-images.githubusercontent.com/1330241/78455066-7483ec80-769c-11ea-81b6-78b0560357db.png)

Maybe we could at least set `Creator` to OpenSCAD (`openscad_shortversionnumber` from `version.h`). I'm not sure if it's easy enough to pass the source file name through to the export function for use as `Title`.",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/609052016,PDF export of 2D Outlines,t-paul,55,592653288,4,609052016,0,609049012,2020-04-04T16:16:50Z,"The coordinate transformation needs some changes though, e.g. script
```
n = 20;

p = [
    for (i = [0 : n - 1])
        let(a = 360 / n * i)
            (50 * (i%2) + 30) * [ -sin(a), cos(a) ]
    ];
    
translate([100, 150]) difference() { polygon(p); circle(20); }
translate([1, 1]) text(""Hello World!"", 26);
```
produces:
![grafik](https://user-images.githubusercontent.com/1330241/78455748-68019300-76a0-11ea-93e5-f8309503eadc.png) ![grafik](https://user-images.githubusercontent.com/1330241/78455668-093c1980-76a0-11ea-8661-f433f9d50104.png)
",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/609460854,PDF export of 2D Outlines,tbharathchandra,55,592653288,5,609460854,0,609052016,2020-04-05T18:28:33Z,Travis build passed https://travis-ci.org/github/openscad/openscad/builds/671328177,False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/609461497,PDF export of 2D Outlines,t-paul,55,592653288,6,609461497,0,609460854,2020-04-05T18:32:39Z,"I've added cairo to the MXE docker image, so the windows builds on CircleCI are fine too now. I will leave the AppVeyor with cairo disabled to verify this will build too. Right now it's probably still ignoring the ENABLE_CAIRO flag, so it fails with
```
src/export_pdf.cc:1:10: fatal error: cairo.h: No such file or directory
```
The `export_3mf.cc` file could serve as example for handling this case I think.",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/609675858,PDF export of 2D Outlines,t-paul,55,592653288,7,609675858,0,609461497,2020-04-06T09:18:10Z,Nice! All green. I'll have a look to get it enabled for the AppImage too.,False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/609926826,PDF export of 2D Outlines,tbharathchandra,55,592653288,8,609926826,0,609675858,2020-04-06T17:20:35Z,"```
n = 20;

p = [
    for (i = [0 : n - 1])
        let(a = 360 / n * i)
            (50 * (i%2) + 30) * [ -sin(a), cos(a) ]
    ];
    
translate([100, 150]) difference() { polygon(p); circle(20); }
translate([1, 1]) text(""Hello World!"", 26);
```
Now this script will generate pdf like 
[testbottom.pdf](https://github.com/openscad/openscad/files/4439839/testbottom.pdf)

Translating the entire geometry above to [-100,-40] will generate pdf like
[testcenter.pdf](https://github.com/openscad/openscad/files/4439845/testcenter.pdf)


",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/610417184,PDF export of 2D Outlines,t-paul,55,592653288,9,610417184,0,609926826,2020-04-07T14:24:11Z,"This looks great already. Some things I'd list for discussion (lets not just change the code yet, maybe we decide it's fine as it is :smile:)

- Not sure about the red color. Maybe we want to stick to gray scales until we can give the user a choice?
- Maybe add minor ticks to the scale? Only for the first couple of cm?
- Align the scales text either centered or on one side?
- For the centered view, maybe still put the scales at top&left, but don't let them overlap, so they stand separately. Maybe some extra thick tick mark for the center points?",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/610801367,PDF export of 2D Outlines,tbharathchandra,55,592653288,10,610801367,0,610417184,2020-04-08T07:35:56Z,"- I added red color in an only intention to make geometry differ from the axis lines. Well, we can do that by using the alpha parameter. 
- Smaller ticks would make it look clean but why for only a couple of cm?
- Text aligning on one side would be better.
- Yeah, that would be great, I was also thinking to remove those lines over which scales are drawn and draw them at the end of the paper. Top X and Left Y.",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/610879287,PDF export of 2D Outlines,t-paul,55,592653288,11,610879287,0,610801367,2020-04-08T10:27:27Z,"I'm not sure if it looks too ""full"" when having the minor ticks everywhere. I guess we can just try and see if it's ok to just add them for the whole ruler. Due to the alpha settings, it's probably fine.

Hi @sbridger, maybe you want to have a look too :-).",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/611227168,PDF export of 2D Outlines,sbridger,55,592653288,12,611227168,0,610879287,2020-04-08T22:29:02Z,"> Hi @sbridger, maybe you want to have a look too :-).

Thanks I will, great (and unexpected) to see this happen. 
How do I get an exe?

My default choice would be edge scales as they are out of the object area.
Don't get obsessive about the scales. They are there so that print accuracy (x and Y) can be checked, they don't have another actual function. (Printers tend be be accurate in X, but a bit random in the friction feed direction Y)

Filename in header is the name of the openscad file, not the pdf file.

My intial use case for this was to make a cutting and drilling template on the laser printer. The default line colour should be solid black for that.",False,0,NONE
https://api.github.com/repos/openscad/openscad/issues/comments/611231335,PDF export of 2D Outlines,t-paul,55,592653288,13,611231335,0,611227168,2020-04-08T22:41:48Z,"For now only the windows builds are enabled, AppImage for Linux is not ready yet (but I can build one if needed).

So for Windows find the last change like that:
![grafik](https://user-images.githubusercontent.com/1330241/78839990-f3a95580-79f9-11ea-8fee-d98759d07160.png)
and click the green check mark.

![grafik](https://user-images.githubusercontent.com/1330241/78840105-33703d00-79fa-11ea-9281-46f16ab5c104.png)

`openscad-mxe-64bit` would be the Windows 64bit version, follow the `Details` link.

For some strange reason, this link does not directly show the download tab, so you have to modify from
`https://circleci.com/gh/openscad/openscad/4758?...some...sufff...`
to
`https://circleci.com/gh/openscad/openscad/4758#artifacts`
",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/611288245,PDF export of 2D Outlines,sbridger,55,592653288,14,611288245,0,611231335,2020-04-09T02:11:56Z,"Tested, works OK, prints OK on my laser. Meets my need with these changes:

- Should be black
- default to scales at edge.
- filename should be source (openscad) file, not pdf filename

I suggest that 2D only export menu strings should be a bit more explicit so people don't expect to get a picture
eg
export->""as PDF 2D Outline""
or put some labelled dividers in the export menu
export  --3D--
   as XXX etc
   --Outline 2D--
   as DXF
   as PDF
  --Image--
  as PNG
  as SVG

------------------
How much further do y'all want to go with PDF export?",False,0,NONE
https://api.github.com/repos/openscad/openscad/issues/comments/611376914,PDF export of 2D Outlines,tbharathchandra,55,592653288,15,611376914,0,611288245,2020-04-09T07:30:07Z,"Hi @sbridger, Thanks for testing it. 

There is no problem with making the color black and taking the scales to edges. I think the problem may arise with the third modification you suggested. Though it is a useful feature in the case of PDF export, source filename is not used in any other export feature. The code is also designed accordingly. Even then, we can add this feature but this may bring some inconsistency in the code. 

I think it's a tradeoff here, @t-paul should make a call for it.",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/611405579,PDF export of 2D Outlines,tbharathchandra,55,592653288,16,611405579,0,611376914,2020-04-09T08:35:10Z,"About the testing, converting the PDF into an image and then running the check on that would be a better option. We can use Ghostscripts for converting PDFs into PNG. ",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/611570605,PDF export of 2D Outlines,t-paul,55,592653288,17,611570605,0,611405579,2020-04-09T14:50:58Z,"I think it sounds sensible to have the source file in the PDF. Currently there's not much info passed into the export functions, but I think it may make sense to add an ExportInfo or ExportContext object that could later be extended to pass even more data like the options gathered by a future export options GUI.

For the menu entries, I would like to see first how things look in various combinations, we can leave that for later maybe. I think at this point it's still strictly 2D or 3D for each of the export types, but there already was some code to export a 3D view as SVG.",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/611571238,PDF export of 2D Outlines,t-paul,55,592653288,18,611571238,0,611570605,2020-04-09T14:52:05Z,"Oh, about converter, I guess we have to check what's available best on all platforms without too much installation going on.

So far I've seen:
- Ghostscript
- pdftocairo (from poppler utilities)
- imagemagick/graphicsmagick
",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/611831609,PDF export of 2D Outlines,MichaelAtOz,55,592653288,19,611831609,0,611571238,2020-04-10T01:32:00Z,"> Currently there's not much info passed into the export functions, but I think it may make sense to add an ExportInfo or ExportContext object that could later be extended to pass even more data like the options gathered by a future export options GUI.

There is space in STL for more info, I think we should include filename, date/time & 'OpenSCAD=\<version\>'. And similar where feasible in other formats.",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/612044353,PDF export of 2D Outlines,tbharathchandra,55,592653288,20,612044353,0,611831609,2020-04-10T14:08:55Z,"samples:
[Untitled.pdf](https://github.com/openscad/openscad/files/4461842/Untitled.pdf)
[starcenter.pdf](https://github.com/openscad/openscad/files/4461844/starcenter.pdf)
",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/612105527,PDF export of 2D Outlines,t-paul,55,592653288,21,612105527,0,612044353,2020-04-10T16:22:12Z,"The examples look great. May need some real world printing, if the scales show up, but I guess todays printers should be able to handle that fine.
Is the centered one a bit too high? It somehow looks if it's offset maybe twice as much as it should?",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/612162533,PDF export of 2D Outlines,nophead,55,592653288,22,612162533,0,612105527,2020-04-10T18:39:14Z,"No don't put date/time inside STL files. They have a date and time on the file system. Making files change when their contents haven't is not good for automatic build systems and source control. Similarly with OpenSCAD version. I would just have to strip it all out.
",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/612163706,PDF export of 2D Outlines,t-paul,55,592653288,23,612163706,0,612162533,2020-04-10T18:42:15Z,"Yeah, I'm seeing the ""Reproducible Build"" topic too. I guess lets have that as default and maybe give an option later to add more info if people want to. I do see some cases where at least having the version number of the creating application could be useful.",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/612233943,PDF export of 2D Outlines,sbridger,55,592653288,24,612233943,0,612163706,2020-04-10T21:51:59Z,"[nb. My actual requested requirement is 2D outlines and is essentially met. The below are things that might be needed long term if you kept developing pdf export...]

For ExportContext object the following should be considered:

It should also have the echo output available to it.
For example the part I used this to make, also requires some wire, and I calculate how much in the openscad, and show that with echo statements. In the perfect world, this information would be able to print in the pdf. The PDF export might simply print everything from echo, or just strings that begin with a keyword (e.g ""PDF:"" or ""PRINT:"")

I also see that if you export the rendered 3D view to PDF, then multipage PDF is very desirable. I normally have a min of 2 or different views (normal, cross-section/cutaway, assembled) in the openscad file, as well as many designs having multiple separate components. For documentation it would be desireable to print these to one file. (the current animation mechanism seems a fairly workable way to do this)

It is desirable to be able to pass Title string/s to the PDF, and this should ideally be done in a way that they can be set from the commandline for batch builds.",False,0,NONE
https://api.github.com/repos/openscad/openscad/issues/comments/612239843,PDF export of 2D Outlines,sbridger,55,592653288,25,612239843,0,612233943,2020-04-10T22:08:16Z,"@tbharathchandra tbharathchandra
> [Untitled.pdf](https://github.com/openscad/openscad/files/4461842/Untitled.pdf)

Black is good. Linewidth is good .
Printers can't print at the very edge of the paper - only the  ""0"" of left hand scale is on the printable area of my printer. 
If your tickmarks reach 10mm in from the edge, I think you are pretty safe that they will print on all lasers I have used. My printer has a 5mm side gutter.
As I said, the purpose is to check calibration of physical printers, so as long as the tick marks are legible that can be done. (i.e. it doesn't matter so much if the numbers don't print on some printers, so numbers should probably be above tick marks)
",False,0,NONE
https://api.github.com/repos/openscad/openscad/issues/comments/612555705,PDF export of 2D Outlines,MichaelAtOz,55,592653288,26,612555705,0,612239843,2020-04-12T03:01:39Z,"> 
> No don't put date/time inside STL files. They have a date and time on the file system. 

Once the file is moved the FS datetime no longer reflects the actual creation, for example posting the file on Thingiverse/Shapeways. Knowing when that export was created, plus the filename & OpenSCAD version used, spells the environment that generated the geometry , thus allowing it to be replicated, to tie a flaw to a specific version (of source or OpenSCAD version) etc. (yes it doesn't include libraries etc)

I have SpiderOak which saves versions of files as they change, I can recover a source back to any version since it was created, but I'd need to know which one, hence filename & datetime. 

> Making files change when their contents haven't is not good for automatic build systems and source control. Similarly with OpenSCAD version. 

How am I proposing to modify it, I'm talking exported files not source, these are added at export time and not meant to change.

> I would just have to strip it all out.

Why? It doesn't affect geometry. It's like Exif metadata in photo files, the equivalent 'properties' is stored in Office documents and plenty of other applications.
",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/612577336,PDF export of 2D Outlines,nophead,55,592653288,27,612577336,0,612555705,2020-04-12T07:43:21Z,"Why, because I want to know if my STL files have actually changed or not to know if they need to re-rendered for the build instructions and re-sliced and reprinted.

With a fully parametric design it is often difficult to know the knock on effects of changing something.",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/612577998,PDF export of 2D Outlines,nophead,55,592653288,28,612577998,0,612577336,2020-04-12T07:49:44Z,Also when OpenSCAD changes I want to know if it changes my STLs.,False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/612597186,PDF export of 2D Outlines,sbridger,55,592653288,29,612597186,0,612577998,2020-04-12T10:58:57Z,@nophead @MichaelAtOz   I suggest a make new issue to discuss this. It's a great topic for an argument and I'd love to weigh in too. In a new thread.,False,0,NONE
https://api.github.com/repos/openscad/openscad/issues/comments/612602225,PDF export of 2D Outlines,t-paul,55,592653288,30,612602225,0,612597186,2020-04-12T11:46:23Z,"I don't see much need for discussion actually. Both use cases are totally valid. Base line target for this PR will be to add no special changeable attributes. I'll add the suggestions to #649 which would allow the user to opt-in for extra information.

I wonder if we should try making the PDF export actually reproducable - that way we could just add a reference PDF to the test framework instead of converting things to image for comparison.",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/612650789,PDF export of 2D Outlines,tbharathchandra,55,592653288,31,612650789,0,612602225,2020-04-12T17:38:31Z,"@sbridger 

> If your tickmarks reach 10mm in from the edge, I think you are pretty safe that they will print on all lasers I have used.

So are you suggesting to increase the size of the tick marks? 
I have also gone through your suggestions to further improve PDF export, I am not sure about the first one. The thing export means about geometry export. If that is really required, I think should be in other PR.

> It should also have the echo output available to it.

And the second one sounds really interesting but I think the views should be selected by the user before rotating and projecting them. If we set some default views, that may not fulfill the user requirement because we may loose some hidden details of the part which are represented by the dashed lines in the drafting sheets.

> I also see that if you export the rendered 3D view to PDF, then multipage PDF is very desirable.



 


",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/3271,`--autocenter --viewall` command line arguments not seeming to work,timmit99,7,594743650,1,594743650,0,0,2020-04-06T01:19:11Z,"I have 30+ STL's that i need to generate images for however that are not centered on 00 as they were exported relative to their assembly's origin and are all over the XYZ space. If i MANUALLY load them up i can hit ""View All"" and it centers but running ""openscad file.stl --viewall -o out.png"" yields a blank yellow image.

Directory is:
Images (folder)
STLs (folder)
model.scad
Image_Generation.py

```python
# Image_Generation.py
import os

directory = r'STLs'
accent = ""[a]""
for entry in os.scandir(directory):
    if (entry.path.lower().endswith("".stl"") and entry.is_file()):
        print(entry.path)
        fileName = entry.path[len(directory)+1:]
        justName = fileName[0:len(fileName)-4]
        if (fileName.startswith(accent)):
            color = ""accent""
        else:
            color = ""main""
        print(fileName,""   "",justName)

        command = ""openscad model.scad -D model=\"""" +justName+ ""\"" -D type=\"""" +color+ ""\"" -o Images/"" + justName + "".png --viewall  --colorscheme DeepOcean ""
        print(command)
        os.system(command)
```
and

```openSCAD
model=""temp"";
type = ""main"";
filename=str(""\STLs\\"",model,"".STL"");
import(filename, center=true);
color(""red"")
import(filename, center=false);
```
If anyone can help me out... I've tried just:
`openscad test.stl -o Images/test.png --viewall  --colorscheme DeepOcean` in command line but still no success",True,0,NONE
https://api.github.com/repos/openscad/openscad/issues/comments/609549604,`--autocenter --viewall` command line arguments not seeming to work,MichaelAtOz,7,594743650,2,609549604,0,594743650,2020-04-06T03:42:20Z,"With 2019.05 on Windows &
```
translate([-95,0]) cube(3);
translate([-90,0]) cube(3);
```
and 
```
openscad viewall.scad -o viewall-va.png

```
I get an image with the two cubes really close up, centred in the png.
Adding `--viewall` produced identical output.
A changing one of the minus translates to positive, give a similar full image showing both cubes further zoomed out.

I exported the two minus cubes as .STL, then changed the .SAD to `import(""viewall.stl);`, then
`openscad viewall.scad -o viewall-cs-va.png --colorscheme DeepOcean --viewall`
got the same close up cubes, and the same without `--viewall`

So I don't know what you are doing to not get centred output...",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/609549894,`--autocenter --viewall` command line arguments not seeming to work,MichaelAtOz,7,594743650,3,609549894,0,609549604,2020-04-06T03:43:47Z,and `--autocenter' without `--viewall` similarly same output.,False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/609641487,`--autocenter --viewall` command line arguments not seeming to work,nophead,7,594743650,4,609641487,0,609549894,2020-04-06T08:08:36Z,"```--viewall``` and ```--autocenter``` are both needed.

```autocenter``` points the camera at the centre of the object's bounding sphere. ```viewall``` sets the camera distance to ensure the bounding sphere fits in the height of the image. That is a bit pessimistic in most cases so I make the image oversized and then use Imakemagick to trim the excess border and resample it to a lower resolution. That gives me anti-aliasing. For example I start with a 4096 x 4096 image to make a 280x280 one of each STL for my build instructions.

![image](https://user-images.githubusercontent.com/566149/78536595-051a1400-77e6-11ea-9640-44f75d550f59.png)
",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/609645728,`--autocenter --viewall` command line arguments not seeming to work,nophead,7,594743650,5,609645728,0,609641487,2020-04-06T08:17:26Z,"This is what my framework generates for the two cubes.

![image](https://user-images.githubusercontent.com/566149/78537418-5ecf0e00-77e7-11ea-8fe8-8f70fe5892a6.png)
",False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/609674534,`--autocenter --viewall` command line arguments not seeming to work,t-paul,7,594743650,6,609674534,0,609645728,2020-04-06T09:15:28Z,@timmit99 please post a specific example STL + full command line that is not working.,False,0,MEMBER
https://api.github.com/repos/openscad/openscad/issues/comments/1001224045,`--autocenter --viewall` command line arguments not seeming to work,spuder,7,594743650,7,1001224045,0,609674534,2021-12-26T18:16:58Z,"I also am seeing that `--viewall` and `--autocenter` appear to not work (Running 2021.01)

```
find ~+ -type f -name ""*.stl"" -print0 | while read -d '' -r file; do 
    echo ""Reading $file""
    /Applications/OpenSCAD.app/Contents/MacOS/OpenSCAD /dev/null -D ""import(\""$file\"");"" -o ""$file.png"" --imgsize=600,600 --colorscheme ""Tomorrow Night"" --viewall --autocenter
done
```

The md5sum of files with and without `--viewall --autocenter` is identical. 

I've also tried using the options when generating a gif, and openscad also produces the same result regardless if `--viewall --autocenter` is defined or not

```
find ~+ -type f -name ""*.stl"" -print0 | while read -d '' -r file; do 
    echo ""Reading $file""
    MYTMPDIR=""$(mktemp -d)""
    trap 'rm -rf -- ""$MYTMPDIR""' EXIT
    echo ""Creating temp directory ${MYTMPDIR}""
    /Applications/OpenSCAD.app/Contents/MacOS/OpenSCAD /dev/null -D '$vpd = 100;' -D '$vpr = [60, 0, 360 * $t];' -o ""${MYTMPDIR}/foo.png""  -D ""import(\""$file\"");"" --imgsize=300,300 --animate 60 --colorscheme ""Tomorrow Night"" --viewall --autocenter
    yes | ffmpeg \
        -framerate 12 \
        -pattern_type glob \
        -i ""$MYTMPDIR/*.png"" \
        -r 24 \
        -vf scale=512:-1 \
        ""${file}.gif"" \
        ;
    rm -rf -- ""$MYTMPDIR""
done
```",False,0,NONE
https://api.github.com/repos/openscad/openscad/issues/comments/1001252410,`--autocenter --viewall` command line arguments not seeming to work,rcolyer,7,594743650,8,1001252410,0,1001224045,2021-12-26T23:02:05Z,"Since @nophead's 2018 commit d57e6e990aad15a646ba9961bebdfda2e3937214 the --viewall and --autocenter options are defaulted to on whenever the --camera parameter is not specified.  Actually displaying what was generated seems to me to have been a reasonable change in default behavior.  Their only remaining role is to override values passed for camera, and autocenter is only processed if viewall is also enabled.  So it's not that they don't work, it's that there is a very limited case where they are not working.  I suspect this is NotABug.

Three different cases:
```openscad /dev/null -D ""translate([20,0,0]) cube(10);"" -o test_None.png```
![test_None](https://user-images.githubusercontent.com/1266642/147421938-966a145c-7ac1-44bb-a9d1-3f614ae01d58.png)
```openscad /dev/null --camera 30,0,0,70,0,20,50 -D ""translate([20,0,0]) cube(10);"" -o test_C.png```
![test_C](https://user-images.githubusercontent.com/1266642/147421940-13c5d30d-2ba1-477f-b6ac-84c3d95ff2a2.png)
```openscad /dev/null --camera 30,0,0,70,0,20,50 --viewall --autocenter -D ""translate([20,0,0]) cube(10);"" -o test_CVA.png```
![test_CVA](https://user-images.githubusercontent.com/1266642/147421945-9314ba7c-268d-4ee8-a277-89fd32c2b755.png)

",False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/36836,Debug toolbar is gone,derrabus,7,619470086,1,619470086,0,0,2020-05-16T13:05:45Z,"**Symfony version(s) affected**: 4.4.9-dev, 5.0.9-dev, 5.1.0-RC1

**Description**  
I'm testing my pet projects with Symfony 5.1 since the BETA1 release. I've upgraded them to RC1 today and the first thing I've noticed in each of them is that the debug toolbar is not displayed anymore. I can still access the `/_profiler/` route, though. Rolling back to BETA1 solves the issue for me.

Update: The issue also happens on 4.4/5.0 if I switch to the latest dev packages.

**How to reproduce**  
```sh
symfony new --full --version=next my_project
cd my_project
symfony serve
```

**Possible Solution**  
Display the toolbar again. 😃 ",True,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/comments/629648934,Debug toolbar is gone,derrabus,7,619470086,2,629648934,0,619470086,2020-05-16T13:50:39Z,"The issue seems to go away if I revert #36789.

cc @marcw 
",False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/comments/629681921,Debug toolbar is gone,COil,7,619470086,3,629681921,0,629648934,2020-05-16T17:42:20Z,"I confirm, it's in 5.1 RC1 too.",False,0,CONTRIBUTOR
https://api.github.com/repos/symfony/symfony/issues/comments/629685917,Debug toolbar is gone,ovrflo,7,619470086,4,629685917,0,629681921,2020-05-16T18:11:26Z,"Yep. I was just debugging this as well. The debug led me here.
I fixed it locally by changing the WebDebugToolbar priority to Profiler+1.

While I didn't quite have the issue fixed in #36789, I did know that because of the priorities we had in the past, some things might escape the profiler. That is a legitimate bug and should be fixed.

A better solution than reverting would be to update the Profiler listener priority, though right now I'm wondering if anything else would be broken by changing the toolbar's priority.",False,0,CONTRIBUTOR
https://api.github.com/repos/symfony/symfony/issues/comments/629688561,Debug toolbar is gone,derrabus,7,619470086,5,629688561,0,629685917,2020-05-16T18:33:06Z,Status: Reviewed,False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/comments/629688687,Debug toolbar is gone,derrabus,7,619470086,6,629688687,0,629688561,2020-05-16T18:34:07Z,"I guess, @carsonbot won't let me update my own review status. ;-)",False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/comments/629689138,Debug toolbar is gone,derrabus,7,619470086,7,629689138,0,629688687,2020-05-16T18:38:05Z,"> A better solution than reverting would be to update the Profiler listener priority,

I was searching for a quick fix, so I proposed a revert. If you've found a combination of priorities that works, feel free to submit a PR. I'd be happy to close mine then. 😃 

> though right now I'm wondering if anything else would be broken by changing the toolbar's priority.

Yeah, that's what I thought as well. Fiddling with listener priorities is always a dangerous thing to do.",False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/comments/629788238,Debug toolbar is gone,marcw,7,619470086,8,629788238,0,629689138,2020-05-17T12:19:54Z,Sorry for introducing this regression! I created an issue for my original problem. ,False,0,CONTRIBUTOR
https://api.github.com/repos/symfony/symfony/issues/36838,[HttpKernel] Bring back the debug toolbar,derrabus,3,619483018,1,619483018,0,0,2020-05-16T14:04:44Z,"| Q             | A
| ------------- | ---
| Branch?       | 4.4
| Bug fix?      | yes
| New feature?  | no
| Deprecations? | no
| Tickets       | Fix #36836
| License       | MIT
| Doc PR        | N/A

This PR effectively reverts #36789 in order to fix a regression caused by that PR.",True,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/comments/629706895,[HttpKernel] Bring back the debug toolbar,noniagriconomie,3,619483018,2,629706895,0,619483018,2020-05-16T21:18:08Z,"Can it be usefull to create a simple test where the priority of events are set and garanty that the order does not change when runing the test?
Because changing the priority should be something to do very carefuly imo, moreover core events
",False,0,CONTRIBUTOR
https://api.github.com/repos/symfony/symfony/issues/comments/629749828,[HttpKernel] Bring back the debug toolbar,derrabus,3,619483018,3,629749828,0,629706895,2020-05-17T06:19:35Z,"This PR reverts the priorities to the state of 4.4.8, which should be a safe change.

Apart from that, yes: Some kind of integration test that prevents future regressions would make sense here.",False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/comments/630008504,[HttpKernel] Bring back the debug toolbar,fabpot,3,619483018,4,630008504,0,629749828,2020-05-18T07:50:45Z,Thank you @derrabus.,False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/36839,[BrowserKit] Raw body with custom Content-Type header,azhurb,4,619493887,1,619493887,0,0,2020-05-16T15:02:21Z,"| Q             | A
| ------------- | ---
| Branch?       | 4.4
| Bug fix?      | yes
| New feature?  | no
| Deprecations? | no
| License       | MIT

Currently, if you try to send POST/PUT request with custom `Content-Type` header and specified body, the real request will contain `text/plain` content type.

Following code
```php
$client->request(
    'POST',
    '/url',
    [],
    [],
    [
        'CONTENT_TYPE' => 'application/json'
    ],
    '{""foo"":""bar""}'
);
```
produces next request
```
POST /
Content-Type: text/plain; charset=utf-8

{""foo"":""bar""}
```

With this fix, the request will be
```
POST /
Content-Type: application/json

{""foo"":""bar""}
```",True,0,CONTRIBUTOR
https://api.github.com/repos/symfony/symfony/issues/comments/629675582,[BrowserKit] Raw body with custom Content-Type header,ro0NL,4,619493887,2,629675582,0,619493887,2020-05-16T16:56:25Z,"Hi @azhurb, looks like it fixes #36640 :) cool.

WDYT of my patch suggestion in the issue? I believe there are some other cases where we need to preserve the given content-type as well.",False,0,CONTRIBUTOR
https://api.github.com/repos/symfony/symfony/issues/comments/629679368,[BrowserKit] Raw body with custom Content-Type header,azhurb,4,619493887,3,629679368,0,629675582,2020-05-16T17:21:39Z,"> Hi @azhurb, looks like it fixes #36640 :) cool.
> 
> WDYT of my patch suggestion in the issue? I believe there are some other cases where we need to preserve the given content-type as well.

Hi @ro0NL. Actually I believe we need to preserve content-type only if the raw body data is not empty. It looks like other cases are already covered. Anyway, your patch should work as well :)",False,0,CONTRIBUTOR
https://api.github.com/repos/symfony/symfony/issues/comments/629681099,[BrowserKit] Raw body with custom Content-Type header,azhurb,4,619493887,4,629681099,0,629679368,2020-05-16T17:35:31Z,There is also discussion from 2016 about this issue https://github.com/symfony/symfony/issues/20042,False,0,CONTRIBUTOR
https://api.github.com/repos/symfony/symfony/issues/comments/632819191,[BrowserKit] Raw body with custom Content-Type header,fabpot,4,619493887,5,632819191,0,629681099,2020-05-22T17:28:10Z,Thank you @azhurb.,False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/36840,[EventDispatcher] Register listener for security.interactive_login omitting the event name,reanim8ed,10,619505946,1,619505946,0,0,2020-05-16T16:08:16Z,"**Symfony version(s) affected**: 4.4.5

**Description**  
If the kernel.event_listener tag doesn't define event, the method whose name is on + CamelCased event name should be executed. Tried it with `security.interactive_login` but it doesnt work.

**How to reproduce**  
1. Register all event listeners at once with:
```
services:
    App\EventListener\:
        resource: ../src/EventListener/*
        tags: [kernel.event_listener]
```
2. Create new listener class
3. If method `__invoke` is used - listener is executed correctly:
```
public function __invoke(InteractiveLoginEvent $event): void
{
   // code to execute
}
```
4. Should be working the same with `onSecurityInteractiveLogin` method name too.

**Additional context**  
Related to pull request: [33851](https://github.com/symfony/symfony/pull/33851)
",True,0,NONE
https://api.github.com/repos/symfony/symfony/issues/comments/629669556,[EventDispatcher] Register listener for security.interactive_login omitting the event name,derrabus,10,619505946,2,629669556,0,619505946,2020-05-16T16:15:14Z,"Not a bug. If you don't specify the event, only `__invoke()` will work. It has always been that way. If you want to name the method differently, specify the event on the DI tag or use a subscriber.",False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/comments/629669802,[EventDispatcher] Register listener for security.interactive_login omitting the event name,reanim8ed,10,619505946,3,629669802,0,629669556,2020-05-16T16:17:00Z,"@derrabus Oh, but I found about it in Symfony blog [post](https://symfony.com/blog/new-in-symfony-4-4-simpler-event-listeners) about 4.4 simpler event listeners",False,0,NONE
https://api.github.com/repos/symfony/symfony/issues/comments/629670540,[EventDispatcher] Register listener for security.interactive_login omitting the event name,derrabus,10,619505946,4,629670540,0,629669802,2020-05-16T16:22:51Z,"Yes, the text of the blog post is a bit misleading. Good catch. Can we change it, @javiereguiluz?",False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/comments/629671373,[EventDispatcher] Register listener for security.interactive_login omitting the event name,reanim8ed,10,619505946,5,629671373,0,629670540,2020-05-16T16:30:10Z,"I see, yeah it is misleading. I found another [post ](https://symfony.com/blog/new-in-symfony-4-1-invokable-event-listeners) here too.",False,0,NONE
https://api.github.com/repos/symfony/symfony/issues/comments/630084555,[EventDispatcher] Register listener for security.interactive_login omitting the event name,javiereguiluz,10,619505946,6,630084555,0,629671373,2020-05-18T10:10:02Z,"In this article -> https://symfony.com/doc/current/event_dispatcher.html

we say this:

```rst
Symfony follows this logic to decide which method to execute inside the event
listener class:

#. If the ``kernel.event_listener`` tag defines the ``method`` attribute, that's
   the name of the method to be executed;
#. If no ``method`` attribute is defined, try to execute the method whose name
   is ``on`` + ""camel-cased event name"" (e.g. ``onKernelException()`` method for
   the ``kernel.exception`` event);
#. If that method is not defined either, try to execute the ``__invoke()`` magic
   method (which makes event listeners invokable);
#. If the ``_invoke()`` method is not defined either, throw an exception.
```

We've always said that ... so has this article been wrong since day one? Ping @xabbuh and @wouterj  Thanks!",False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/comments/630094166,[EventDispatcher] Register listener for security.interactive_login omitting the event name,wouterj,10,619505946,7,630094166,0,630084555,2020-05-18T10:29:49Z,"No, there are two separate situations here. The full tag definition is:

```yaml
{ name: kernel.event_listener, event: security.interactive_login, method: onLogin }
``` 

You **can** omit the `method` BUT NOT the `event` attribute if:
* The listener has an `__invoke()` method
* The listener has a camel-cased event name method: `onSecurityInteractiveLogin()`

You **can** omit the `method` and `event` attribute if:
* The listener has an `__invoke()` method with a correct typehint (`InteractiveLoginEvent $event`)",False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/comments/630103835,[EventDispatcher] Register listener for security.interactive_login omitting the event name,reanim8ed,10,619505946,8,630103835,0,630094166,2020-05-18T10:52:16Z,"Blog posts should probably be a lil bit more clear abour this.

@wouterj Is there any speed differences using full tag vs `__invoke` with a typehint?",False,0,NONE
https://api.github.com/repos/symfony/symfony/issues/comments/630112009,[EventDispatcher] Register listener for security.interactive_login omitting the event name,wouterj,10,619505946,9,630112009,0,630103835,2020-05-18T11:10:29Z,"> @wouterj Is there any speed differences using full tag vs __invoke with a typehint?

No, everything is resolved on compile time. So performance of any alternative is equal.",False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/comments/630277395,[EventDispatcher] Register listener for security.interactive_login omitting the event name,derrabus,10,619505946,10,630277395,0,630112009,2020-05-18T15:58:34Z,"@wouterj There's actually a third case:

> You **can** omit the `method` BUT NOT the `event` attribute if:
> * The listener has an `__invoke()` method
> * The listener has a camel-cased event name method: `onSecurityInteractiveLogin()`

You **can** omit the `event` BUT NOT the `method` attribute if:
* The method uses a correct parameter type declaration (`InteractiveLoginEvent $event`)

> You **can** omit the `method` and `event` attribute if:
> * The listener has an `__invoke()` method with a correct typehint (`InteractiveLoginEvent $event`)

",False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/comments/638198929,[EventDispatcher] Register listener for security.interactive_login omitting the event name,wouterj,10,619505946,11,638198929,0,630277395,2020-06-03T13:31:50Z,"I think the conclusion is that this is not a bug, but expected behavior. So I think this issue can be closed.

I've summarized the behavior in the table below, maybe we can clarify this better in the documentation.

| | `method` | `event` |
| --- | --- | --- |
| `someMethod($event)` | **required** | **required** |
| `someMethod(InteractiveLoginEvent $event)` | **required** | _optional_ |
| `onSecurityInteractiveLogin($event)` | _optional_ | **required** |
| `__invoke($event)` | _optional_ | **required** |
| `__invoke(InteractiveLoginEvent $event)` | _optional_ | _optional_ |",False,0,MEMBER
https://api.github.com/repos/libretro/RetroArch/issues/10717,French: French translation update,WeedyWeedSmoker,11,625850461,1,625850461,0,0,2020-05-27T16:36:29Z,"## Description

French translation update:

- (Ozone) Add option to sort playlists after name truncation
- Enable configuration of date separator in clock and runtime 'last played' displays
- Core updater improvements
- Update Downloader/Updater confusion
- Update MENU_ENUM_SUBLABEL_DOWNLOAD_CORE

## Related Pull Requests

https://github.com/libretro/RetroArch/pull/10498

## Reviewers

@twinaphex 
",True,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/636502558,French: French translation update,inactive123,11,625850461,2,636502558,0,625850461,2020-05-31T17:32:10Z,Do these changes come from Crowdin?,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/636504819,French: French translation update,WeedyWeedSmoker,11,625850461,3,636504819,0,636502558,2020-05-31T17:51:39Z,"@twinaphex I will add them to Crowdin as soon as @guoyunhe syncs the latest US file with Crowdin, but none of the changes here have been available there yet…",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/636512553,French: French translation update,guoyunhe,11,625850461,4,636512553,0,636504819,2020-05-31T18:52:52Z,"@WeedyWeedSmoker I think the following strings should be disabled for translation:

![Screenshot_2020-05-31 All Strings - RetroArch - Crowdin translation](https://user-images.githubusercontent.com/5836790/83360325-0c464400-a389-11ea-9389-5a8ce2cec9e4.png)
",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/636516955,French: French translation update,WeedyWeedSmoker,11,625850461,5,636516955,0,636512553,2020-05-31T19:28:28Z,@guoyunhe I think you should hide ALL the strings containing `_LANG_` in them…,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/636519023,French: French translation update,im4potato,11,625850461,6,636519023,0,636516955,2020-05-31T19:43:55Z,"Hey guys, if you've been following any of my comments/issues lately you might have seen that I'm in the process of overhauling the US translation and I'm just about done with it. As far as I understand, the US translation is the only one still manually updated with a PR? Also, I'm trying to standardize the language across everything and make it more descriptive, and one of the changes I've made is changing anything that requires a restart to say `(Restart Required)`, not just `(Restart)`.

I'm not sure if anything I've done will interfere/conflict with what you're doing, just thought I'd make you aware that a big change should be coming (assuming it gets merged).",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/636528093,French: French translation update,WeedyWeedSmoker,11,625850461,7,636528093,0,636519023,2020-05-31T20:51:32Z,"@im4potato Yeah, I was very tempted to put ""(Restart Required)"" instead of just ""(Restart)"" in my PR https://github.com/libretro/RetroArch/pull/10727

I'm all for unification, so yeah, ""(Restart Required)"" would indeed be more self-explanatory, and not so much harder to understand for non-english speakers anyway…",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/637168597,French: French translation update,im4potato,11,625850461,8,637168597,0,636528093,2020-06-01T22:57:29Z,I've been thinking more about this and a better solution might be to just put a note about some languages requiring a restart in the sub-label instead of putting them on each individual language. That would make some of the formatting more consistent.,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/637174336,French: French translation update,WeedyWeedSmoker,11,625850461,9,637174336,0,637168597,2020-06-01T23:14:08Z,"@im4potato I have to disagree on that point, the sub-label might be hidden in some cases… This is kinda crucial information…",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/637175525,French: French translation update,im4potato,11,625850461,10,637175525,0,637174336,2020-06-01T23:17:54Z,"That is true, however, sub-labels are turned on by default in all menu drivers, and there are already plenty of settings that rely on them to convey important information, including settings requiring a restart. So this would be no different than many other settings that already exist.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/638153939,French: French translation update,inactive123,11,625850461,11,638153939,0,637175525,2020-06-03T12:06:24Z,@WeedyWeedSmoker @guoyunhe is this ready to go now?,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/638225864,French: French translation update,WeedyWeedSmoker,11,625850461,12,638225864,0,638153939,2020-06-03T14:14:00Z,"@twinaphex This PR is ready…

Those strings have been added to Crowdin too!",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/10718,Playlist relative paths,francescotintori,48,625973988,1,625973988,0,0,2020-05-27T19:33:23Z,"## Description

Addes support for optional relative paths in playlists, with path conversion between windows and posix syntax.
Useful for sharing playlists between installations, on different OSes.

The modification implements new config parameter 'playlist_save_relative_paths': when enabled, and 
'rgui_browser_directory' is also set, retroarch merges the relative path name from the playlist with 'rgui_browser_directory', and then converts the final path in windows/posix syntax, depending on the local OS.

## Notes
With relative paths enabled, playlist entries are saved in this format:
```json   
{
      ""relative_path"": ""roms/Genesis/Sonic The Hedgehog (W) (REV01) [!].zip"",
      ""label"": ""Sonic The Hedgehog (W) (REV01) [!]"",
      ""core_path"": ""DETECT"",
      ""core_name"": ""DETECT"",
      ""crc32"": ""00000000|crc"",
      ""db_name"": ""Genesis.lpl"",
      ""subsystem_roms_relative_paths"": [ ""roms/Genesis/subsystem.zip"" ]
},
```

## Examples:

On Windows, with 'rgui_browser_directory' = ""D:\RetroArch\"", the previous example is resolved to ""D:\RetroArch\roms\Genesis\Sonic The Hedgehog (W) (REV01) [!].zip""

On Linux, with 'rgui_browser_directory' = ""/mnt/hdd2/RetroArch"" the previous example is resolved to ""/mnt/hdd2/RetroArch/roms/Genesis/Sonic The Hedgehog (W) (REV01) [!].zip""

On a NvidiaShield, with 'rgui_browser_directory' = ""/storage/jarvis/roms"" the previous example is resolved to ""/storage/jarvis/roms/roms/Genesis/Sonic The Hedgehog (W) (REV01) [!].zip""

## Related Issues

Relies on logic in https://github.com/libretro/RetroArch/pull/10615 for core detection in different OSes.
Replaces https://github.com/libretro/RetroArch/pull/10642",True,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/634895018,Playlist relative paths,francescotintori,48,625973988,2,634895018,0,625973988,2020-05-27T19:34:20Z,"This pull request replaces https://github.com/libretro/RetroArch/pull/10642, also adds relative paths support in subsystem roms.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/634980924,Playlist relative paths,RobLoach,48,625973988,3,634980924,0,634895018,2020-05-27T22:39:36Z,"This is a great idea! Haven't tested it, but seems super handy.",False,0,MEMBER
https://api.github.com/repos/libretro/RetroArch/issues/comments/635242157,Playlist relative paths,jdgleaver,48,625973988,4,635242157,0,634980924,2020-05-28T09:56:17Z,"@francescotintori Many apologies for neglecting your PRs... For the past few months I've been working regular 18 hour days, often 7 days a week, and both real life and RetroArch demands are pulling me in all directions. I seem to be the only one available to review PRs of this nature, and I'm so very tired. Please bear with me... :(

I need to read your code more carefully, but I think it's pretty solid. There are some optimisation issues - maybe I can fix these later myself - and we might need to change how core paths are recorded in 'relative' playlists. Certainly in `playlist_core_path_equal()`, we're going to need to retain the old matching behaviour if relative paths are disabled - we really do need to match the full path in most cases, since developers and testers may have multiple different builds of the same core in different locations, and these different files should be recognised (obviously, people who use relative paths won't care about this - so you can just check a bool to decide the matching behaviour).

One thing that stands out is the `config_get_base_content_directory_if_enabled()` function. I'm afraid this is going to suck for you, but you can't use that - you'll have to pass the directory longhand each time. This may seem like pedantry, but it's not: you see all the places where `config_get_base_content_directory_if_enabled()` is called in the various `task`* functions? *These all happen on a different thread*. This means we cannot access the settings pointer here (we get thread race conditions). That's why we have these sorts of constructs: https://github.com/libretro/RetroArch/blob/fad57c9a50485dccc8c5275040404370f8b52741/tasks/task_playlist_manager.c#L879-L881 - i.e. you need to add a new member to the relevant task handles, and cache the path in the 'push' function (which happens on the main thread). Also, we want to handle all the settings pointer stuff better in the future, so you'll see that needed parameters are often cached at the start of functions, or passed as arguments - this is so we can more easily find and move/refactor them later, when we have more robust multithreading support. If you bury settings pointer access inside a function, that's much harder to disentangle...",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/635386682,Playlist relative paths,francescotintori,48,625973988,5,635386682,0,635242157,2020-05-28T14:32:27Z,"Hello @jdgleaver, don't worry if you are busy, I understand :)
Meanwhile I'll work some more on the code to apply your changes.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/635397290,Playlist relative paths,jdgleaver,48,625973988,6,635397290,0,635386682,2020-05-28T14:47:31Z,"Thanks for understanding, and for continuing to work on this :)

I do think it will be a valuable feature once we get the last details ironed out. I'm sure many users will appreciate it!",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/636298033,Playlist relative paths,francescotintori,48,625973988,7,636298033,0,635397290,2020-05-30T08:21:28Z,"Ok, I removed usage of the `config_get_base_content_directory_if_enabled()`, now using the settings values, and making copies of them when running tasks.
To be honest, this was a pain :)
Also, tons of copy/pasted code.. 

I don't know if it would just be simpler to make a complete copy of the settings_t struct when starting a task, for example in `task_queue_push()`: I understand it would be slower, but we are just copying some data already in memory, and only when starting a task. 
Maybe we could define an alternate `task_queue_push_with_settings()`, which make a copy of `settings_t` in `retro_task_t`.

Anyway, I still need to modify `playlist_core_path_equal()` to disable the new matching logic when relative paths are disabled.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/636318954,Playlist relative paths,jdgleaver,48,625973988,8,636318954,0,636298033,2020-05-30T11:39:43Z,"> To be honest, this was a pain :)
> Also, tons of copy/pasted code..

Yeah, I know exactly what you mean - I've had to deal with this multiple times :)

> I don't know if it would just be simpler to make a complete copy of the settings_t struct when starting a task, for example in task_queue_push(): I understand it would be slower, but we are just copying some data already in memory, and only when starting a task.

Sadly, this isn't really practical. We push tasks all the time (literally *all the time*), and copying the whole settings struct is too much of a performance overhead.

It's often easy to forget that we don't just target the desktop. RetroArch has to run on pretty much everything, all the way down to PSP, PS2 and o3DS. Performance is a *huge* issue on many, many platforms (this is one of the reasons why it will take me a while to properly review your PR - need to profile every little thing!)

Regardless, thank you for your continued efforts - we'll get there in the end :)",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/636330026,Playlist relative paths,francescotintori,48,625973988,9,636330026,0,636318954,2020-05-30T13:19:26Z,"Ok no problem I understand, if Doom can run on a printer RetroArch will too!",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/636704011,Playlist relative paths,Ryunam,48,625973988,10,636704011,0,636330026,2020-06-01T08:42:39Z,"Just chiming in quickly to say that I am highly looking forward to this feature being implemented. Using RA with several devices and being able to share playlists with relative paths would be terrific!

@francescotintori Sempre bello vedere contributi da parte di altri appassionati italiani. :)",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/636784568,Playlist relative paths,francescotintori,48,625973988,11,636784568,0,636704011,2020-06-01T10:57:34Z,"Ok changed `playlist_core_path_equal()` and added a new parameter to enable/disable the new logic.
I was thinking that maybe I should revert some of the changes, for example it doesn't make sense to handle relative paths when saving screenshots, or updating the history playlists..

Ciao @Ryunam, allora non sono l'unico italiano qui 👍 ",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/636836428,Playlist relative paths,jdgleaver,48,625973988,12,636836428,0,636784568,2020-06-01T12:37:26Z,"> I was thinking that maybe I should revert some of the changes, for example it doesn't make sense to handle relative paths when saving screenshots, or updating the history playlists..

Hmm... I think you have a point there...

I was also thinking some more about the code duplication and annoyances of having to pass so many config parameters to the playlist functions. I reckon I should make a new `playlist_config_t` struct to handle all this - so we just pass a single argument to `playlist_init()` and cache it internally, then all the other playlist functions will be 'clean'. We can then have a method for copying the struct, so we'd only need to add one duplicated config object to the various task handlers. This should be much tidier, and would make it easier to add new stuff in the future. The downside that you'd need to deal with some merge conflicts...  :)

I'm bogged down in adding the interface for core backups at the moment, but shall I look into this config refactor later? It would probably mean you wouldn't have to modify the existing task code at all...",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/636909306,Playlist relative paths,RobLoach,48,625973988,13,636909306,0,636836428,2020-06-01T15:01:39Z,"Quick question... Is this relative to which of the following?
- Executable directory
- Current working directory
- Playlist file directory

Would likely make the most sense to be relative to the playlist directory.",False,0,MEMBER
https://api.github.com/repos/libretro/RetroArch/issues/comments/636920278,Playlist relative paths,francescotintori,48,625973988,14,636920278,0,636909306,2020-06-01T15:22:11Z,"Hello, current implementation uses the rgui_browser_directory parameter, the one used to set the initial directory for rom scanning.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/636942122,Playlist relative paths,francescotintori,48,625973988,15,636942122,0,636920278,2020-06-01T16:00:36Z,"> I was also thinking some more about the code duplication and annoyances of having to pass so many config parameters to the playlist functions. I reckon I should make a new `playlist_config_t` struct to handle all this - so we just pass a single argument to `playlist_init()` and cache it internally, then all the other playlist functions will be 'clean'. We can then have a method for copying the struct, so we'd only need to add one duplicated config object to the various task handlers. This should be much tidier, and would make it easier to add new stuff in the future. The downside that you'd need to deal with some merge conflicts... :)
> 
> I'm bogged down in adding the interface for core backups at the moment, but shall I look into this config refactor later? It would probably mean you wouldn't have to modify the existing task code at all...

I agree with any change that reduces code duplication :)
It's ok if I have to refactor something to adapt to your changes, don't worry 👍 ",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/641420055,Playlist relative paths,francescotintori,48,625973988,16,641420055,0,636942122,2020-06-09T16:35:49Z,"Noticed some conflicts today, after latest changes to master.
Rebased, hope I did not break anything",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/641455180,Playlist relative paths,jdgleaver,48,625973988,17,641455180,0,641420055,2020-06-09T17:13:06Z,"@francescotintori Thanks!

I'm still snowed under at the moment, but don't worry, I haven't forgotten about this PR. I want to get the playlist config refactor done before I check over your work in detail. I appreciate your patience :)",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/641521104,Playlist relative paths,francescotintori,48,625973988,18,641521104,0,641455180,2020-06-09T19:23:18Z,"Hello @jdgleaver , don't worry and take your time :)",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/646657388,Playlist relative paths,jdgleaver,48,625973988,19,646657388,0,641521104,2020-06-19T14:10:00Z,"@francescotintori Hi! Apologies again for the delay in dealing with this - we've got another stable release planned very soon, and I've been tied up with prep work...

Anyway, I'm going to tackle the playlist config refactor first thing next week. Hopefully this will only need a couple of days. I'll let you know as soon as it's done, then we should be able start moving forward with this PR. :)",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/647086944,Playlist relative paths,francescotintori,48,625973988,20,647086944,0,646657388,2020-06-21T06:50:16Z,"Hello @jdgleaver, again don't worry, in the meanwhile I spent some time on actually playing with retroarch instead of working on it :)
I noticed some more conflicts popped up, I'll wait for you to complete the playlist config refactor and then I'll resume work on my PR.
",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/650260008,Playlist relative paths,jdgleaver,48,625973988,21,650260008,0,647086944,2020-06-26T16:04:53Z,"@francescotintori Hi! I've finally managed to get the playlist refactor done: https://github.com/libretro/RetroArch/pull/10922

Sorry for taking so long, and sorry for all the merge conflicts - but I hope it will end up being helpful :)

The main part is that there is a new `playlist_config_t` struct which is passed only on playlist initialisation, and which contains all relevant settings parameters. So you should be able to add your 'use relative paths' and 'relative base path' parameters to this - and then you can access them inside any playlist function, and it should minimise the number of places where you have to track/insert these values externally (some of the tasks will need 2 lines adding, some won't need to be touched at all). I think it should be pretty straight-forward, but let me know if there are any issues.
",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/650709521,Playlist relative paths,francescotintori,48,625973988,22,650709521,0,650260008,2020-06-28T07:16:48Z,"Hello @jdgleaver, really nice update!! 👍 
As you said there are tons of conflicts, I'll start by rebasing and fixing them.
After that I'll start refactoring all my changes.
Unfortunately I'm also a little busy lately, I'll may take some days to finish.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/650768746,Playlist relative paths,jdgleaver,48,625973988,23,650768746,0,650709521,2020-06-28T14:27:05Z,"That's great - I'm pleased you like the changes!

> Unfortunately I'm also a little busy lately, I'll may take some days to finish.

Ah, that's no problem at all - please take all the time you need. I know what it's like being busy with other things ;)

I'm pretty certain that no-one is planning any other changes to the playlist stuff for the foreseeable future, so you should be able to code at your leisure without worrying about any more significant merge conflicts :)",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/651938739,Playlist relative paths,francescotintori,48,625973988,24,651938739,0,650768746,2020-06-30T17:33:02Z,"I found some free time and made an initial refactor :)
For some reason I lost  the travis build, I'll check if I broke something..",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/652923804,Playlist relative paths,jdgleaver,48,625973988,25,652923804,0,651938739,2020-07-02T10:24:23Z,"Nice :)

That is much cleaner - good stuff!

I'll start going through this carefully over the next day or so.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/653091138,Playlist relative paths,francescotintori,48,625973988,26,653091138,0,652923804,2020-07-02T15:57:21Z,"Glad you like it!
I still have some things to fix, including travis.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/654263436,Playlist relative paths,jdgleaver,48,625973988,27,654263436,0,653091138,2020-07-06T14:11:01Z,"@francescotintori Okay, sorry again for the delay! I ran out of time last week, and then I've been ill since Saturday...

Anyway, I've been through the code, and it's in good shape. I think there's mostly just small stuff that needs a little extra work.

I'll leave a bunch of comments in the code itself, and you can review them at your leisure :)

Once the code is final, I'll do some profiling, and make sure there are no significant performance regressions (it should be fine, I think - those extra conditionals shouldn't be too heavy when relative paths are disabled)",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/655654538,Playlist relative paths,francescotintori,48,625973988,28,655654538,0,654263436,2020-07-08T17:28:26Z,"Hello, sorry for the delay, I was a little busy :)
I see tons of little fixes here and there, nothing major, I'll review them in the next days",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/656167440,Playlist relative paths,jdgleaver,48,625973988,29,656167440,0,655654538,2020-07-09T14:39:03Z,"@francescotintori Hey, you never need to apologise for any delay! Please take as much time as you need - no-one will ever rush you :)

Thank you for the fixes so far - we're getting there!",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/656319317,Playlist relative paths,lgtm-com[bot],48,625973988,30,656319317,0,656167440,2020-07-09T19:51:57Z,"This pull request **introduces 1 alert** when merging 26b231b8b265a2470c2c5a25d817a8b2bd7491c4 into dc01bf8d467f7bb4a9d08455d2723ae5a9ac707f - [view on LGTM.com](https://lgtm.com/projects/g/libretro/RetroArch/rev/pr-5af61ad81a2e9a2686d70bd8d5ad5591efa129ab)

**new alerts:**

* 1 for Implicit function declaration",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/657016920,Playlist relative paths,francescotintori,48,625973988,31,657016920,0,656319317,2020-07-11T08:43:03Z,"Hello @jdgleaver,
I think I fixed all your comments, it should be ok now :)

I still want to play with his a little though, I noticed some problems when updating playlists: if a old playlist with absolute paths is rescanned, the new relative paths do not replace the absolute paths, I want to check why..

Also, any idea why Travis is gone from my PR? :)",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/10720,ekeeke's solution to force loading of content into RAM if soft-patchi…,hizzlekizzle,15,626160130,1,626160130,0,0,2020-05-28T02:15:40Z,"…ng is required by the user and still provide a valid *data pointer in this case that the core can use, even if need_fullpath is set to True

## Description

This patch comes from ekeeke's suggestion from here https://github.com/libretro/Genesis-Plus-GX/issues/54 to solve https://github.com/libretro/Genesis-Plus-GX/issues/211. In short, this should allow needs_fullpath cores that also support files that shouldn't need fullpath to apply softpatches to valid files.

## Related Issues

already linked above

## Related Pull Requests

none AFAIK

## Reviewers

@twinaphex @m4xw @jdgleaver 
",True,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/635054350,ekeeke's solution to force loading of content into RAM if soft-patchi…,i30817,15,626160130,2,635054350,0,626160130,2020-05-28T02:21:14Z,"Are there other cores in this situation, where the core supposedly supports softpatching but because one of the romtypes is too large it was disabled that this solution can be applied to?",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/635055309,ekeeke's solution to force loading of content into RAM if soft-patchi…,hizzlekizzle,15,626160130,3,635055309,0,635054350,2020-05-28T02:24:07Z,"@i30817 beetle-pce/supergrafx, maybe? And if we ever get a combined mednafen core, probably that, too. Dunno if there's any others.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/635066193,ekeeke's solution to force loading of content into RAM if soft-patchi…,Sanaki,15,626160130,4,635066193,0,635055309,2020-05-28T03:00:24Z,"Beetle PCE, Beetle PCE FAST, Beetle SuperGrafx, Genesis Plus GX, and Picodrive should be the only current ones that fit that criteria (other than PC cores that may have additional rationales). I grepped through the full set of cores and made a list of all fullpath entries, in case it's of value.
[ra_fullpath.txt](https://github.com/libretro/RetroArch/files/4692989/ra_fullpath.txt)",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/635066460,ekeeke's solution to force loading of content into RAM if soft-patchi…,i30817,15,626160130,5,635066460,0,635066193,2020-05-28T03:01:13Z,"What about the n64 cores, they don't have softpatching support? I'd expected that with 256 mb max they would but maybe it's unrealistic now that i think about it (bps is soooo slow patching a cd vs xdelta it's comical). And it's almost completely because it wants to put the entire cd in memory.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/635068592,ekeeke's solution to force loading of content into RAM if soft-patchi…,Sanaki,15,626160130,6,635068592,0,635066460,2020-05-28T03:08:33Z,"N64 cores softpatch fine. The main contentious ones are DS cores, since they should be able to softpatch but have rather large files.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/635069192,ekeeke's solution to force loading of content into RAM if soft-patchi…,i30817,15,626160130,7,635069192,0,635068592,2020-05-28T03:10:37Z,"There is also the 'other' unrelated problem that the softpatching experience in retroarch (or just the 'hack' experience after serial scanning) is unsatisfactory but i'll stay quiet on that, everyone already knows my rants about it and we have the manual scanner to workaround it (but get no images).

> N64 cores softpatch fine

uh. Last time i tried it in RA it didn't work, so i just started hardpatching them. If it does work with mupen or parallel it's news to me.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/635070747,ekeeke's solution to force loading of content into RAM if soft-patchi…,Sanaki,15,626160130,8,635070747,0,635069192,2020-05-28T03:15:55Z,"Then I suppose it's news to you. I softpatch N64 all the time. Would be rather odd to restrict it, since without hacks the files don't ever exceed 64MiB. But regardless, DS and N64 are both outside the scope of the question posed here.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/635154286,ekeeke's solution to force loading of content into RAM if soft-patchi…,negativeExponent,15,626160130,9,635154286,0,635070747,2020-05-28T07:12:23Z,"whats the difference just making need_fullpath=false here? isnt this doint the same thing, patching roms in memory? this means it will also try to patch iso images then as well if there is an existing patch file.

i think my original suggestion still works, just make ->path valid whichever need_fullpath is set to, since cd images needs the path to be valid since they are manually loaded.

imho.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/635227993,ekeeke's solution to force loading of content into RAM if soft-patchi…,jdgleaver,15,626160130,10,635227993,0,635154286,2020-05-28T09:27:15Z,"I don't think this is right...

It's going to load content into ram (and patch it) regardless of whether the core can do anything with the data. If a core ignores the data buffer, then it's wasted effort - and to use the data buffer at all would require core-side hacks (well, complete disregard for the API...).

It would be better to add an API extension which would allow a core to specify a list of supported file types for which `need_fullpath` is true (rather than having `need_fullpath` as a blanket on/off switch)",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/635560233,ekeeke's solution to force loading of content into RAM if soft-patchi…,ekeeke,15,626160130,11,635560233,0,635227993,2020-05-28T19:50:56Z,"@negativeExponent : as explained in linked issue, it is not possible to dynamically change need_fullpath value reported by the core and setting need_fullpath to false will force retroarch to always load any content into RAM, which will fail on many platforms when loading CD game (and it is not really a good idea anyway to use 600 MB of RAM with an application without the user consent). With this change, it will only happen if softpatching is enabled AND a patch file is found for the loaded content, so it will likely only happen when the user really needs it and with content that is patchable.

@jdgleaver : I agree this would be a cleaner solution (although there will still be a problem with some file extensions that can be used by both ROM and CD image files, like .bin). My solution was just a quick workaround to avoid modifying libretro API while not breaking compatibility with existing cores.",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/635616215,ekeeke's solution to force loading of content into RAM if soft-patchi…,i30817,15,626160130,12,635616215,0,635560233,2020-05-28T21:24:32Z,"No one should be using .bin either for cds or for genesis, modulo bugs. All the bins in no-intro were renamed to .md iirc. 

And as for cds, well, a bin without a cue is begging for music bugs or worse, though i seem to remember retroarch having problems with that when trying to unzip cds for emulators.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/635888281,ekeeke's solution to force loading of content into RAM if soft-patchi…,jdgleaver,15,626160130,13,635888281,0,635616215,2020-05-29T10:02:01Z,"@ekeeke Oh, certainly - I fully understand the appeal of a convenient workaround :)

My concern is that it breaks the specification - i.e. if a core relies on this then it won't work with any other frontend. So then we start having hacks and undefined behaviour:

Core sets `need_fullpath`, so the data buffer will be invalid, but we know that frontend `x` breaks spec, so let's check the buffer anyway, and let's assume the buffer will be `NULL` if the frontend doesn't break spec, so if it's not `NULL` we ignore the path and read the buffer instead - but oops, frontend `y` sends a buffer that's not `NULL` but which contains garbage data - that will crash the core, so we better try and do some integrity checks, but uh oh, the buffer size sent by the frontend is also invalid, so we don't know how much data to read without going out of bounds...

See what I mean? It quickly gets rather sticky...

I'll try to think about an API extension...",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/635935616,ekeeke's solution to force loading of content into RAM if soft-patchi…,ekeeke,15,626160130,14,635935616,0,635888281,2020-05-29T12:04:10Z,"@jdgleaver : Yes, I see. My initial thought was that since the specification is basically just one line in libretro.h (https://github.com/libretro/RetroArch/blob/master/libretro-common/include/libretro.h#L2680 ), it would be simple enough to replace ""are invalid"" by ""are only valid and not null when automatic soft-patching is possible for loaded content"" but I indeed didn't think about other existing libretro frontends which would need to be modified to conform to the new spec.

So it indeed seems that an API extension (optional) is the most correct solution. Maybe instead of adding an extension so the core could force need_fullpath=true only for some of the supported file extensions, you could rather add an extension so the core could allow   automatic soft-patching for some of the supported file extensions even when need_fullpath=true, then retrieve the data/size via that API extension ? Indeed, GPGX core is particular that it requires the full path even when loading ROM because it supports Mega CD Mode 1 (and 'soon' will support MegaSD MD+ mode) where it needs to detect and load also any CD image file in the same directory as the ROM file. This is not problematic with Retroarch since the path is always returned even when need_fullpath=false but could be with other frontends since it's not strictly required by the spec.",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/636034078,ekeeke's solution to force loading of content into RAM if soft-patchi…,hizzlekizzle,15,626160130,15,636034078,0,635935616,2020-05-29T15:24:36Z,"Good discussion! I'll go ahead and close this PR so it doesn't get merged accidentally, but feel free to keep talking if needed :)",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/636067787,ekeeke's solution to force loading of content into RAM if soft-patchi…,jdgleaver,15,626160130,16,636067787,0,636034078,2020-05-29T16:33:21Z,"@ekeeke Ah, thanks for explaining the full needs of your core! Yes, that is a tricky situation. I'm sure we can work around it, though.

I have quite a full TODO list at the moment, but I can see the importance of this issue. Let me have a think about possible implementations...",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/10721,Add new language to CrowdIn,duduke,4,626316926,1,626316926,0,0,2020-05-28T08:24:05Z,"The new CrowdIn service is great for contributing language translations.
Can you create a new translation language for Hebrew?

Thanks.",True,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/637169363,Add new language to CrowdIn,WeedyWeedSmoker,4,626316926,2,637169363,0,626316926,2020-06-01T22:59:28Z,@guoyunhe Could you handle this?,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/637307218,Add new language to CrowdIn,guoyunhe,4,626316926,3,637307218,0,637169363,2020-06-02T06:28:11Z,The Hebrew language has been added to crowdin,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/637583657,Add new language to CrowdIn,WeedyWeedSmoker,4,626316926,4,637583657,0,637307218,2020-06-02T14:35:29Z,@duduke You can now close this issue!,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/638034919,Add new language to CrowdIn,duduke,4,626316926,5,638034919,0,637583657,2020-06-03T08:07:51Z,Thanks.,False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/34499,REF/PERF: PeriodDtype decouple from DateOffset,jbrockmendel,6,627989539,1,627989539,0,0,2020-05-31T15:49:01Z,"ATM we define PeriodDtype in terms of DateOffsets, but this is a misnomer.  In fact, virtually every Period/PeriodArray method has to start off by taking its `.freq` and finding the corresponding integer code.  This makes the integer code itself into a dtype.  We lose a little bit of ground on the constructor, then make it back up in subsequent calls.

```
In [2]: per = pd.Period(""2016Q1"")                                                                                                                                                                   

In [3]: %timeit per.year
556 ns ± 13.3 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)    # <-- master
94.5 ns ± 1.36 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)  # <-- PR

In [4]: %timeit pd.Period(""2016Q1"")                   
21.2 µs ± 176 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)  # <-- master
25.8 µs ± 457 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)  # <-- PR
```

The constructor perf I think we can improve by eventually cutting the DateOffset out of the process altogether.

We'll also be able to de-duplicate a _bunch_ of other stuff: FreqGroup can be defined in terms of PeriodDypeCode, Resolution can be defined in terms of FreqGroup (xref #34462), we can avoid redundant definitions of the dtype codes in period.pyx, and a lot of the rest of libfrequencies becomes unnecessary.

In a follow-up I plan to mix the cython-space PeriodDtype into the core.dtypes PeriodDtype and we can get the same perf improvements in the PeriodArray methods.",True,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/636972601,REF/PERF: PeriodDtype decouple from DateOffset,jbrockmendel,6,627989539,2,636972601,0,627989539,2020-06-01T16:32:01Z,"> The other methods of the PeriodDtype class don't seem used and/or tested?

yah not yet.  i can remove them until they are actually used i guess",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/636972809,REF/PERF: PeriodDtype decouple from DateOffset,jbrockmendel,6,627989539,3,636972809,0,636972601,2020-06-01T16:32:26Z,"> It needs another name IMO, since we already have another PeriodDtype class that is something else

Any suggestions?  (I plan to mix it into the core.dtypes PeriodDtype before long)",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/637240245,REF/PERF: PeriodDtype decouple from DateOffset,jbrockmendel,6,627989539,4,637240245,0,636972809,2020-06-02T02:58:46Z,updated with a placeholder name PeriodPseudoDtype,False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/637761305,REF/PERF: PeriodDtype decouple from DateOffset,jorisvandenbossche,6,627989539,5,637761305,0,637240245,2020-06-02T19:33:05Z,"Alternative could also be `PeriodCode` 
(but if you are still going to change it, might also not matter too much)",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/637864026,REF/PERF: PeriodDtype decouple from DateOffset,jbrockmendel,6,627989539,6,637864026,0,637761305,2020-06-02T23:43:09Z,"updated with docstring.  im increasingly confident this will (eventually, soon-ish) let us de-duplicate Resolution, FreqGroup, and some cdef constants we define in libperiod.  Maybe even NPY_DATETIMEUNIT depending on what numpy does",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/638518053,REF/PERF: PeriodDtype decouple from DateOffset,jbrockmendel,6,627989539,7,638518053,0,637864026,2020-06-03T23:45:36Z,ping,False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/34500,REG: Fix read_parquet from file-like objects,alimcmaster1,14,628001759,1,628001759,0,0,2020-05-31T16:58:23Z,"- [x] xref #34467
- [x] tests added / passed
- [x] passes `black pandas`
- [x] passes `git diff upstream/master -u -- ""*.py"" | flake8 --diff`
- [x] whatsnew entry - waiting on https://github.com/pandas-dev/pandas/pull/34481

Use arrow parquet.read_table opposed to ParquetDataset
",True,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/636506458,REG: Fix read_parquet from file-like objects,jorisvandenbossche,14,628001759,2,636506458,0,628001759,2020-05-31T18:05:04Z,"> whatsnew entry - waiting on #34481

I merged that PR",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/636506870,REG: Fix read_parquet from file-like objects,jorisvandenbossche,14,628001759,3,636506870,0,636506458,2020-05-31T18:08:43Z,"The original version (before https://github.com/pandas-dev/pandas/pull/33632) used `get_filepath_or_buffer`, which eg also enables to read from urls. Do you know if that is tested? ",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/636994279,REG: Fix read_parquet from file-like objects,alimcmaster1,14,628001759,4,636994279,0,636506870,2020-06-01T17:13:50Z,"> The original version (before #33632) used `get_filepath_or_buffer`, which eg also enables to read from urls. Do you know if that is tested?

Agree - previously untested and I missed this in #33632 - apologies for that. I've added a test case for this. @jorisvandenbossche ",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/637402348,REG: Fix read_parquet from file-like objects,pep8speaks,14,628001759,5,637402348,0,636994279,2020-06-02T09:05:43Z,"Hello @alimcmaster1! Thanks for updating this PR. We checked the lines you've touched for [PEP 8](https://www.python.org/dev/peps/pep-0008) issues, and found:





There are currently no PEP 8 issues detected in this Pull Request. Cheers! :beers: 

##### Comment last updated at 2020-06-12 18:15:00 UTC",False,0,NONE
https://api.github.com/repos/pandas-dev/pandas/issues/comments/639160580,REG: Fix read_parquet from file-like objects,alimcmaster1,14,628001759,6,639160580,0,637402348,2020-06-04T22:59:46Z,"> Looks good to me.
> The url still needs to be changed before merging?
> 
> Do you think this should be safe to use for 1.0.5? (as the other option is to revert the original PR for 1.0.5, and keep this for master only)
> 
> cc @simonjayhawkins

I was planning on updating the URL post merge. Other option is I can open a separate PR with just .parquet file so it exists on master. I think should be fine for 1.0.5 - any additional test cases you can think of would be helpful. 
",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/641761568,REG: Fix read_parquet from file-like objects,jorisvandenbossche,14,628001759,7,641761568,0,639160580,2020-06-10T06:39:40Z,"I would propose to keep this for 1.1 (and we reverted to original patch in the 1.0.x branch for 1.0.5). @alimcmaster1 you can remove the whatsnew note then? (we still need to add a similar line to the v1.0.5.txt, but that should be done in a separate PR)",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/642964123,REG: Fix read_parquet from file-like objects,alimcmaster1,14,628001759,8,642964123,0,641761568,2020-06-11T22:32:14Z,"> I would propose to keep this for 1.1 (and we reverted to original patch in the 1.0.x branch for 1.0.5). @alimcmaster1 you can remove the whatsnew note then? (we still need to add a similar line to the v1.0.5.txt, but that should be done in a separate PR)

Yes makes sense - I’ll do this tomorrow.",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/643390947,REG: Fix read_parquet from file-like objects,jreback,14,628001759,9,643390947,0,642964123,2020-06-12T17:14:50Z,"this now doesn't close the issue as that's actually marked for 1.0.5? 

The plan is to patch that separately right?",False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/643396837,REG: Fix read_parquet from file-like objects,TomAugspurger,14,628001759,10,643396837,0,643390947,2020-06-12T17:29:36Z,"IIUC, all that needs to be done is move the release note to 1.1.0.rst. I'll do that now.",False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/643398834,REG: Fix read_parquet from file-like objects,TomAugspurger,14,628001759,11,643398834,0,643396837,2020-06-12T17:33:35Z,"Actually, I'm sufficintly confused about what the appropriate whatsnew to describe the changes from 1.0.5 to 1.1 is, so I'll leave that to you @alimcmaster1.",False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/643415530,REG: Fix read_parquet from file-like objects,jorisvandenbossche,14,628001759,12,643415530,0,643398834,2020-06-12T18:08:58Z,"In this PR, the whatsnew only needs to be simply removed (this is fixing a regression compared to master, so doesn't need a whatsnew). Describing what's changed in 1.0.5, that's for a separate PR that gets backported.

Will do that now",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/643418649,REG: Fix read_parquet from file-like objects,jorisvandenbossche,14,628001759,13,643418649,0,643415530,2020-06-12T18:16:56Z,"I also updated the URL to point to the master branch, so this is going to fail anyway here, thus merging directly",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/643418810,REG: Fix read_parquet from file-like objects,jorisvandenbossche,14,628001759,14,643418810,0,643418649,2020-06-12T18:17:19Z,Thanks @alimcmaster1 !,False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/643508772,REG: Fix read_parquet from file-like objects,alimcmaster1,14,628001759,15,643508772,0,643418810,2020-06-12T22:33:50Z,Thanks for fixing up @jorisvandenbossche - apologies I didn’t get to this. I’ll add the 1.0.5 whatsnew note you mentioned ,False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/34501,ENH: add logfmt support,link2xt,10,628008797,1,628008797,0,0,2020-05-31T17:40:06Z,"[logfmt](https://www.brandur.org/logfmt) is a structured log format similar to JSON lines, but much simpler. Each line has a format `column1=value1 column2=value2 ...`. Pandas already has support for JSON lines, which can be read with `pd.read_json(path, lines=True)`, but to read logfmt logs a conversion is needed.

I have been using [agrind](https://github.com/rcoh/angle-grinder) to convert logs to JSON lines, but it is an additional step that I would like to eliminate from my workflow. You can see an example at https://gitlab.com/nsnam/ns-3-dev/-/merge_requests/303

Besides, I would like to use logfmt as an output format for simple computational experiments (think C/Fortran without dependencies), because it is easier to maintain one line of code that outputs keys and values interleaved, in contrast to maintaining the code to output headers and code to output values separately. And logfmt becomes easier to read than CSV as the number of columns grows. Compare
```
node=1 throughput=63.0 delay=52.0 x=0.0 y=5.0
node=2 throughput=100.0 delay=35.0 x=5.0 y=5.0
```
to
```
node,throughput,delay,x,y
1,63.0,52.0,0.0,5.0
2,100.0,35.0,5.0,5.0
```

To read logfmt directly with pandas, I want a function `pd.read_logfmt()` that can be used in place of `pd.read_csv()` and `pd.read_json()` in described above cases.
",True,0,NONE
https://api.github.com/repos/pandas-dev/pandas/issues/comments/636503700,ENH: add logfmt support,link2xt,10,628008797,2,636503700,0,628008797,2020-05-31T17:41:58Z,take,False,0,NONE
https://api.github.com/repos/pandas-dev/pandas/issues/comments/636504277,ENH: add logfmt support,jreback,10,628008797,3,636504277,0,636503700,2020-05-31T17:46:46Z,"can u provide justification on how this is a popular format?

why would we not just document using this? why bake this into pandas itself?",False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/636508465,ENH: add logfmt support,link2xt,10,628008797,4,636508465,0,636504277,2020-05-31T18:22:06Z,"> can u provide justification on how this is a popular format?

[Official nodejs package](https://www.npmjs.com/package/logfmt) has 28k weekly downloads now. This is an official log format of Heroku and it is supported in [Elastic stack](https://www.elastic.co/), [Splunk](https://www.splunk.com/), [InfluxDB](https://docs.influxdata.com/telegraf/v1.14/data_formats/input/logfmt/), [Fluentd (with plugin)](https://www.fluentd.org/plugins/all).

It is sure not a popular *data* format (it is log format first of all), but it is the only standard for simple `key=value` output with a [grammar](https://godoc.org/github.com/kr/logfmt), which rules out other formats like `[key=value]`, `key=value, ` etc. And for plain C/C++/Fortran programs such format is needed, because the only alternative for schemaless output is formatting JSON lines with `printf`.

> why would we not just document using this? why bake this into pandas itself?

I don't get what do you propose to document.

Using plain python logfmt package does not create `DataFrame` and infer dtypes, it parses the file into generator of dictionaries, parsing every field as string or boolean flags.

Angle-grinder, `logfmt` tool from npm and [hutils](https://blog.heroku.com/hutils-explore-your-structured-data-logs) require additional binary, NPM or Ruby. It is much easier to eliminate additional dependency and only install `logfmt` package from pypi or [conda-forge](https://github.com/conda-forge/staged-recipes/pull/11779).",False,0,NONE
https://api.github.com/repos/pandas-dev/pandas/issues/comments/636510850,ENH: add logfmt support,jorisvandenbossche,10,628008797,5,636510850,0,636508465,2020-05-31T18:39:11Z,"> Using plain python logfmt package does not create DataFrame and infer dtypes, it parses the file into generator of dictionaries, parsing every field as string or boolean flags.

Have you proposed in that package to add pandas support?

In general we are rather converative in adding new formats in IO support in pandas, as there are *many* formats people would like to see added, and it is not scalable to add support for all possible formats directly into pandas. 
So therefore, I think we would rather encourage making external packages that give a nice pandas-like interface for people using pandas and want to read/write the specific format. 

And if such a package exists (whether it is in `logfmt` itself or in a new ""pandas-logfmt"" package), we can refer to that in our documentation. 
(we have an ecosystem page in the docs, but we should actually also do a better job of listing specifically third-party packages for file formats that are not natively supported in pandas on the IO doc page).



",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/636511064,ENH: add logfmt support,jreback,10,628008797,6,636511064,0,636510850,2020-05-31T18:41:08Z,"@link2xt using the conversion as code

if a user wanted to write this it’s just several lines of code right? (meaning import logfmt then take that output and put in a dataframe)

can u show an example here
",False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/636512108,ENH: add logfmt support,link2xt,10,628008797,7,636512108,0,636511064,2020-05-31T18:49:02Z,"> if a user wanted to write this it’s just several lines of code right?

The problem is that there is no type inference, which is needed for pandas.

```python
#!/usr/bin/env python3

from io import StringIO

import logfmt
import pandas as pd

data = StringIO(""x=1 y=2\nx=10 y=15"")
df = pd.DataFrame(logfmt.parse(data))
print(type(df['x'][0]))
```

This code outputs `<class 'str'>`.",False,0,NONE
https://api.github.com/repos/pandas-dev/pandas/issues/comments/636513495,ENH: add logfmt support,jreback,10,628008797,8,636513495,0,636512108,2020-05-31T19:00:28Z,"it would be better to make a package that has a to_pandas method

-1 on adding this directly to pandas at this time",False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/636520930,ENH: add logfmt support,link2xt,10,628008797,9,636520930,0,636513495,2020-05-31T19:59:25Z,"If I move this into a separate package, how do I use compression support from `get_filepath_or_buffer`? Is there any API exposed for that? PR #34494 tests for `.gz` support.",False,0,NONE
https://api.github.com/repos/pandas-dev/pandas/issues/comments/636529377,ENH: add logfmt support,jreback,10,628008797,10,636529377,0,636520930,2020-05-31T21:01:35Z,"> If I move this into a separate package, how do I use compression support from `get_filepath_or_buffer`? Is there any API exposed for that? PR #34494 tests for `.gz` support.

nope but it’s pretty easy to implement ",False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/636534056,ENH: add logfmt support,link2xt,10,628008797,11,636534056,0,636529377,2020-05-31T21:39:56Z,I have moved the code to https://gitlab.com/link2xt/logfmt-pandas,False,0,NONE
https://api.github.com/repos/pandas-dev/pandas/issues/34502,CLN: GH29547 format with f-strings,DanBasson,8,628010894,1,628010894,0,0,2020-05-31T17:52:39Z,"replace .format() for f-strings in the following:

1. pandas/tests/series/indexing/test_numeric.py
2. pandas/tests/series/indexing/test_take.py
3. pandas/tests/series/indexing/test_where.py

",True,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/636504938,CLN: GH29547 format with f-strings,pep8speaks,8,628010894,2,636504938,0,628010894,2020-05-31T17:52:42Z,"Hello @DanBasson! Thanks for updating this PR. We checked the lines you've touched for [PEP 8](https://www.python.org/dev/peps/pep-0008) issues, and found:





There are currently no PEP 8 issues detected in this Pull Request. Cheers! :beers: 

##### Comment last updated at 2020-06-20 16:23:55 UTC",False,0,NONE
https://api.github.com/repos/pandas-dev/pandas/issues/comments/646990016,CLN: GH29547 format with f-strings,jreback,8,628010894,3,646990016,0,636504938,2020-06-20T12:44:53Z,lgtm. ping on green (the 3.9 biuld is failing but x that),False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/646992052,CLN: GH29547 format with f-strings,DanBasson,8,628010894,4,646992052,0,646990016,2020-06-20T13:04:03Z,"i don't understand what you are saying (i'm new...).
what is ""ping on green""?",False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/646992373,CLN: GH29547 format with f-strings,jreback,8,628010894,5,646992373,0,646992052,2020-06-20T13:06:51Z,"> i don't understand what you are saying (i'm new...).
> what is ""ping on green""?

it means when the CI are all green, comment. note that the CI is currently having various issues.",False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/647011392,CLN: GH29547 format with f-strings,DanBasson,8,628010894,6,647011392,0,646992373,2020-06-20T15:42:19Z,"@jreback 

the CI are all green.
i got some errors which i couldn't understand",False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/647011665,CLN: GH29547 format with f-strings,jreback,8,628010894,7,647011665,0,647011392,2020-06-20T15:44:43Z,"just to make sure (this error should be patched), can you merge upstream master and then ping on green.",False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/647035648,CLN: GH29547 format with f-strings,DanBasson,8,628010894,8,647035648,0,647011665,2020-06-20T19:19:34Z,"Turns out that was the problem.
thank you very much @jreback ",False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/647039416,CLN: GH29547 format with f-strings,jreback,8,628010894,9,647039416,0,647035648,2020-06-20T19:59:26Z,thanks @DanBasson ,False,0,CONTRIBUTOR
https://api.github.com/repos/OpenRA/OpenRA/issues/18221,Laggy rendering performance,christoph110,3,628734075,1,628734075,0,0,2020-06-01T21:21:04Z,"SYSTEM INFORMATION
- Operating System: Windows 10 Professional
- Prozessor: Intel i5 CPU
- Graphic card: NVIDIA GeForce GT 540M (1GB)
- OpenRA release: 20200503 (issue appeared first in playtest 20200301)

DESCRIPTION
The rendering starts to lag periodically after some time of running (see performance graph in screenshot below):
- the lags appear only after some time (~1min) of running the game
- no lags appearant with release 20200202 and appeared with playtest 20200301
- ""render"" and ""render_flip"" cycle time rises from 13ms to >60ms
- lags appear periodically (every ~3secs)
- lags appear only for the ""render_flip"" cycle when setting ""DisableWindowsRenderThread: True"". When  ""DisableWindowsRenderThread: False"" only the ""render"" cycle lags. 
- using ""CapFramerate: True"" (with e.g. 50 Hz) delays the start of the first lag but then the lags appear with the same periodicity as without ""CapFramerate""
- switching Vsync on or off (either in-game or in the graphic driver GUI) does not seem to influence this behavior.

![OpenRA-Performance](https://user-images.githubusercontent.com/59751309/83444152-3c561b80-a44b-11ea-83c4-633367624121.jpg)",True,0,NONE
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/637114871,Laggy rendering performance,pchote,3,628734075,2,637114871,0,628734075,2020-06-01T21:29:04Z,Does this test build help at all? https://github.com/pchote/OpenRA/releases/tag/release-20200503-graphicstest1,False,0,MEMBER
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/637134254,Laggy rendering performance,christoph110,3,628734075,3,637134254,0,637114871,2020-06-01T21:53:06Z,"@pchote : The ""graphictest1"" works like a charm for the screen resolution/scale issue (https://github.com/OpenRA/OpenRA/issues/18206).
However, the performance issue seems to be unrelated to the screen resolution/scale (although both appeared with the changes for the playtest release 20200301).

",False,0,NONE
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/1793498100,Laggy rendering performance,abcdefg30,3,628734075,4,1793498100,0,637134254,2023-11-04T17:09:00Z,"Closing as stale, there have been several changes to the rendering code since this was opened.",False,0,MEMBER
https://api.github.com/repos/OpenRA/OpenRA/issues/18228,Convert IFacing.Facing and TurnSpeed to WAngle.,pchote,7,629443698,1,629443698,0,0,2020-06-02T19:06:01Z,"This PR takes the next big step towards #15196 and voxel orientations.
Related to #18058, #18067, #18211, #18213.

Fixes #18249.

Note that `TurnSpeed` is in WAngle *units* but remains as an int to avoid unexpected behaviour if somebody decides to define values < 0 or > 1023 (which are wrapped by `WAngle`).",True,0,MEMBER
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/638228714,Convert IFacing.Facing and TurnSpeed to WAngle.,tovl,7,629443698,2,638228714,0,629443698,2020-06-03T14:18:11Z,"> Note that TurnSpeed is in WAngle units but remains as an int to avoid unexpected behaviour if somebody decides to define values < 0 or > 1023 (which are wrapped by WAngle).

I'm not sure if this is an actual problem. Turnspeeds must not exceed 180 degrees per tick anyway, since anything higher will result in aliasing. This leads to unwanted behaviour regardless of whether it is wrapped in `WAngle` or not.

(We do use a default of 360 degrees per tick in several places in the code to mean 'can turn any direction instantly'. This should technically be 180 degrees per tick, but since this is only used as an upper bound, and we always take the smallest possible angle, the actual turnspeeds will still always be <= 180.)

In cases where a turnspeed is supposed to represent a directional angular velocity component and thus can be between -180 and 0 degrees, there is still no problem. The aliasing effect will actually ensure that the effective angular velocity is the same as if the negative value was maintained internally.",False,0,CONTRIBUTOR
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/638234065,Convert IFacing.Facing and TurnSpeed to WAngle.,pchote,7,629443698,3,638234065,0,638228714,2020-06-03T14:26:27Z,"I have no strong objection to changing this if there is a consensus that it would be the better approach. We'll just need to bear in mind that we may lose the ability to round-trip certain values without modification, and be careful about any magic values (e.g. -1 to mean ""take a value from somewhere else"").",False,0,MEMBER
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/638269614,Convert IFacing.Facing and TurnSpeed to WAngle.,tovl,7,629443698,4,638269614,0,638234065,2020-06-03T15:24:21Z,"Well, I'm not really arguing one way or the other. Just pointing out that this is actually more feasible than your OP seems to presume. Also, I don't know what the rest of your roadmap looks like exactly, but I'd think that if you go through all the trouble of converting all these to `WAngle` that you ideally would want everything that conceptually represents an angle to be a `WAngle` and leave as few stragglers behind as you can.

As far as I can see:
- Cons: Might still break some exotic use case that probably should be doing things differently anyway, but would be a pain to fix. (I mean, who _really_ knows what `Missile` is doing anyway?)
- Pros: Consistency with everything else; Will likely make things easier in the long run, if we want to support 3D angular velocities.

Additionally: It would probably a good idea to add some more yaml checks eventually to ensure that turnspeeds defined in TraitInfos are within a valid range (regardless of if they are `int` or `WAngle`)",False,0,CONTRIBUTOR
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/638274336,Convert IFacing.Facing and TurnSpeed to WAngle.,pchote,7,629443698,5,638274336,0,638269614,2020-06-03T15:32:09Z,"> Additionally: It would probably a good idea to add some more yaml checks eventually to ensure that turnspeeds defined in TraitInfos are within a valid range (regardless of if they are int or WAngle)

This becomes trivial if turn speeds are defined as WAngle, so is a good argument for doing so.",False,0,MEMBER
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/638328064,Convert IFacing.Facing and TurnSpeed to WAngle.,pchote,7,629443698,6,638328064,0,638274336,2020-06-03T17:02:34Z,Added a commit to convert TurnSpeed to WAngle.,False,0,MEMBER
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/638336421,Convert IFacing.Facing and TurnSpeed to WAngle.,tovl,7,629443698,7,638336421,0,638328064,2020-06-03T17:17:42Z,"Of course, if you ever wanted to add physics into the engine, the whole thing will collapse like a house of cards. But that seems pretty far-fetched at this point. :smile: As long as we stick to kinematics we should be fine. If a need for that somehow does arise, adding a new W* struct that relates to `WAngle` in the same way as `WVec` relates to `WPos` and that doesn't wrap internally might be appropriate.",False,0,CONTRIBUTOR
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/643374887,Convert IFacing.Facing and TurnSpeed to WAngle.,teinarss,7,629443698,8,643374887,0,638336421,2020-06-12T16:38:27Z,https://github.com/OpenRA/OpenRA/wiki/Changelog-(bleed)/_compare/ae066a420e26db5bb877ebb8a06f74fa2b72a1d4...fc3e4e4cdf179f0e5f2fe5d39ac23b6be152f50a,False,0,CONTRIBUTOR
https://api.github.com/repos/OpenRA/OpenRA/issues/18230,Add Aftermath mission Production Disruption,Smittytron,5,630474484,1,630474484,0,0,2020-06-04T03:05:23Z,"This is one of a handful of Aftermath missions that were easy to speedrun and seemed to be designed for the sole purpose of highlighting one of the new units.

I left things as they were in the original for easy difficulty and for normal I create a few actors to prevent the chronotanks from just  jumping past the base onto the island.",True,0,MEMBER
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/646854792,Add Aftermath mission Production Disruption,Smittytron,5,630474484,2,646854792,0,630474484,2020-06-19T20:47:15Z,Rebased and Updated for #18271,False,0,MEMBER
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/649667780,Add Aftermath mission Production Disruption,Smittytron,5,630474484,3,649667780,0,646854792,2020-06-25T16:14:52Z,Updated,False,0,MEMBER
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/653838293,Add Aftermath mission Production Disruption,Smittytron,5,630474484,4,653838293,0,649667780,2020-07-05T03:43:41Z,"Updated. Added a camera on the radar dome after the two flametowers are destroyed. This is due to feedback from @Orb370, who pointed out that because bridges are repairable in OpenRA, the natural assumption of a player is to repair the bridge and advance north.",False,0,MEMBER
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/653892156,Add Aftermath mission Production Disruption,abcdefg30,5,630474484,5,653892156,0,653838293,2020-07-05T13:58:02Z,Merging with @Orb370's second +1.,False,0,MEMBER
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/653892280,Add Aftermath mission Production Disruption,abcdefg30,5,630474484,6,653892280,0,653892156,2020-07-05T13:59:06Z,[Changelog](https://github.com/OpenRA/OpenRA/wiki/Changelog-(bleed)/_compare/7ea10fef4cc4b970b62472fe96d4e2dbc2fac383...d7b640ff9ea19918a97c3afa6ed16950fb03e835),False,0,MEMBER
https://api.github.com/repos/OpenRA/OpenRA/issues/18231,Add pitch and roll to TS helicopters,pchote,40,631073809,1,631073809,0,0,2020-06-04T18:58:57Z,"Aircraft in TS would pitch forward by 30 degrees while flying, and roll to an angle of 20 degrees while turning.
This was effectively purely visual effect, and we have converted enough of the facing code to enable this for everything except the carryall.

https://i.imgur.com/Er7j4Bp.mp4

~Depends on #18228~

~I have taken the liberty of adjusting the pitch and roll values to look better with the current speed configuration on the different aircraft. I have also taken the approach from #17796 to define the roll as a factor of the turn amount, which looks more natural for aircraft that have different turn vs idle turn speeds.~
",True,0,MEMBER
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/639467199,Add pitch and roll to TS helicopters,Inq8,40,631073809,2,639467199,0,631073809,2020-06-05T13:04:17Z,"The Banshee does a strange-looking bob about 75% of the way around the turn in that mp4 example.

Is that just a recording blip?",False,0,CONTRIBUTOR
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/639485099,Add pitch and roll to TS helicopters,pchote,40,631073809,3,639485099,0,639467199,2020-06-05T13:37:37Z,I think it may be passing off corner of a cliff briefly. There is another minor issue visible where it waggles its wings a bit - i may want to add a check to not roll if the delta-facing is less than one step.,False,0,MEMBER
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/639549138,Add pitch and roll to TS helicopters,tovl,40,631073809,4,639549138,0,639485099,2020-06-05T14:59:38Z,It might be nice to replace `FlyPitch` with a `PitchMultiplier` as well. Letting it depend on the aircraft speed. That would make sure we already have a hook for when we implement aircraft acceleration.,False,0,CONTRIBUTOR
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/639551530,Add pitch and roll to TS helicopters,pchote,40,631073809,5,639551530,0,639549138,2020-06-05T15:03:43Z,"I was actually planning on going the other way, removing `RollMultiplier` and adding back `TurnRoll` and `IdleTurnRoll`. Multipliers have the same limited resolution issues that we are going to so much effort to remove in the facing rework.",False,0,MEMBER
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/639562640,Add pitch and roll to TS helicopters,tovl,40,631073809,6,639562640,0,639551530,2020-06-05T15:23:40Z,"Hmm, I see what you mean, but I think the issue there is that the multiplier should just be defined as a percentage instead. (actually it would make sense to have fractions defined as per 1024 instead of per 100, since that is our standard resolution for every other measure, but I think there is no precedent for that)",False,0,CONTRIBUTOR
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/639567596,Add pitch and roll to TS helicopters,abcdefg30,40,631073809,7,639567596,0,639562640,2020-06-05T15:32:25Z,"> (actually it would make sense to have fractions defined as per 1024 instead of per 100, since that is our standard resolution for every other measure, but I think there is no precedent for that)

Won't that get a problem with all of our other modifiers? I.e. why should a health or damage modifier have a base of 1024, or why should different modifiers behave so differently? (It can be done, but sounds quite unintuitive to me.)",False,0,MEMBER
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/639571748,Add pitch and roll to TS helicopters,tovl,40,631073809,8,639571748,0,639567596,2020-06-05T15:38:38Z,"That is exactly what I meant by ""there is no precedent for that""...",False,0,CONTRIBUTOR
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/639811633,Add pitch and roll to TS helicopters,pchote,40,631073809,9,639811633,0,639571748,2020-06-05T20:54:05Z,Updated.,False,0,MEMBER
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/643393222,Add pitch and roll to TS helicopters,pchote,40,631073809,10,643393222,0,639811633,2020-06-12T17:20:27Z,Rebased.,False,0,MEMBER
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/643416394,Add pitch and roll to TS helicopters,pchote,40,631073809,11,643416394,0,643393222,2020-06-12T18:11:07Z,"Updated: made some additional tweaks to improve the behaviour of TS aircraft:
* Removed Sliding - TS's actual behaviour was somewhere between our CanSlide: true and CanSlide: false, having it disabled feels better until we can implement it properly.
* Allow Banshee and Orca Bomber to hover - this is a better fit to the original game, and provides a testcase for our AttackType: Strafe.
* Increased movement speed to match the relative speed of ground vehicles (~14.2 x the rules.ini value) - TS is in desperate need of something like #18051 to fix the speed inconsistencies, but until that happens the newer values feel much better especially on the orca bomber.",False,0,MEMBER
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/643441151,Add pitch and roll to TS helicopters,Smittytron,40,631073809,12,643441151,0,643416394,2020-06-12T19:13:37Z,"Roll looks good. Is it possible to slow down the pitch rate? The rate of pitching forward and backward looks a bit abrupt imo, especially on the orca transport.",False,0,MEMBER
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/643444356,Add pitch and roll to TS helicopters,pchote,40,631073809,13,643444356,0,643441151,2020-06-12T19:21:23Z,The fast pitch rate was intentional because IMO it looks wrong to have the pitch slowly adjusting while the unit is otherwise stationary. I could perhaps split out two separate pitch rates for active vs stationary changes so it pitches forward slower than it returns after stopping?,False,0,MEMBER
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/643450538,Add pitch and roll to TS helicopters,tovl,40,631073809,14,643450538,0,643444356,2020-06-12T19:36:38Z,"> Removed Sliding - TS's actual behaviour was somewhere between our CanSlide: true and CanSlide: false, having it disabled feels better until we can implement it properly.

The sliding behaviour in TS was actually exactly the same as the sliding behaviour in earlier games, so it  doesn't seem justified to change this in TS only. If we want to fix this, we should just rework the sliding behaviour itself. The original games achieved this halfway behaviour by giving aircraft two facings: one for the sprite/voxel orientation and one for the flight direction. By giving these two different turnspeeds the original behaviour can be exactly recreated. Our current sliding behaviour is then equivalent to having the turnspeed for the flight direction maximized.

> Allow Banshee and Orca Bomber to hover - this is a better fit to the original game, and provides a testcase for our AttackType: Strafe.

In the original game, Banshees and Orca bombers never hovered in place, unless they were landing. We already split out the VTOL behaviour so this change makes no sense.

",False,0,CONTRIBUTOR
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/643451956,Add pitch and roll to TS helicopters,pchote,40,631073809,15,643451956,0,643450538,2020-06-12T19:40:09Z,"The same was true for Orca and Harpy - the only difference is that those two could hover while attacking, whereas the other two used a strafing/bombing run style attack. The fact that the orcab/scrin can hover is demonstrated by their ability to land, so IMO it makes no sense for them to circle when idle.",False,0,MEMBER
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/643456028,Add pitch and roll to TS helicopters,tovl,40,631073809,16,643456028,0,643451956,2020-06-12T19:51:27Z,"In that case it makes just as little sense for D2K carryalls to circle when idle, but they do.",False,0,CONTRIBUTOR
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/643459614,Add pitch and roll to TS helicopters,pchote,40,631073809,17,643459614,0,643456028,2020-06-12T20:00:51Z,"In D2k's case it is for consistency with the original game, and the same applies to an extent here:
* The orcab artwork is clearly helicopter/non-bomber-orca-like, so there is no reason for it to circle if the regular orca doesn't
* The circling interacts badly with the no-move-into-shroud logic, either allowing you to slowly walk them across the map (with the current reveal behaviour) or lose them under the shroud (if we properly remove the revealing).

I didn't think this change would be controversial, but if it is then my preference would be to reintroduce the full OG behaviour when they land while idle - as frustrating as that logic is - and defer the arguments until we have a properly playable mod where balancing of everything can be properly considered together. This would need to apply to the carryall too for consistency, which is an even bigger shame considering how well that is working now.",False,0,MEMBER
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/643477793,Add pitch and roll to TS helicopters,Smittytron,40,631073809,18,643477793,0,643459614,2020-06-12T20:50:14Z,"> The fast pitch rate was intentional because IMO it looks wrong to have the pitch slowly adjusting while the unit is otherwise stationary.

I can't think of a happy middle ground without making things overly complicated, so I'm fine with keeping pitch as you have it now.",False,0,MEMBER
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/643496395,Add pitch and roll to TS helicopters,tovl,40,631073809,19,643496395,0,643477793,2020-06-12T21:47:54Z,"For what it's worth, I do not object to reconsidering the behaviour of these craft on principle. Indeed, there is an argument to be made for the orca bomber (but the same argument can be made for the D2K carryall, so...). I do object to you claiming this is somehow more consistent with the original game than what we have now, when it is quite clear that the original game provides no precedent whatsoever on this, one way or the other, since in the original they just land on idle (which is awful). In fact, if we consider the later games, there is plenty of precedent against it (Firehawks, Vertigo bombers, Storm Riders all circle when idle while being VTOLs). As it stands, this is an unmotivated change, that is not an objective improvement and is a scope creep from what the PR claims to be. I would advise to just open a new issue to gather opinions about such a change, and leave it out of this PR.

> The circling interacts badly with the no-move-into-shroud logic, either allowing you to slowly walk them across the map (with the current reveal behaviour) or lose them under the shroud (if we properly remove the revealing).

This will be an issue with any mod that combines fixed-wing aircraft with no-move-into-shroud logic, which seems not far-fetched at all. This is a problem that we need to deal with head-on, not sidestep, provided we want to support no-move-into-shroud logic at all. (But this is not something that needs to be addressed in this PR).

> I didn't think this change would be controversial, but if it is then my preference would be to reintroduce the full OG behaviour when they land while idle - as frustrating as that logic is - and defer the arguments until we have a properly playable mod where balancing of everything can be properly considered together. This would need to apply to the carryall too for consistency, which is an even bigger shame considering how well that is working now.

This is just childish. Please don't stoop to threatening to flip the table.

Regarding the pitch rate: Ideally, the aircraft would adjust its pitch before stopping, not after. I don't know how simple it would be to incorporate that here, otherwise I would be happy to take a look at this myself in a follow up. It would tie in nicely with acceleration/deceleration.",False,0,CONTRIBUTOR
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/643497924,Add pitch and roll to TS helicopters,pchote,40,631073809,20,643497924,0,643496395,2020-06-12T21:53:19Z,"I didn't intend for that comment as a hammer to force my way... i really do think that when we put ourselves into a corner with no clear escape that the sensible option is to fall back to the original logic (which is just a yaml tweak here) - we have time to consider this again before we release anything to the public.

How about a compromise where we put the orcab back to VTOL, keep the banshee circling, but then fix the vision revealing so that it disappears under the shroud (maybe this isn't as bad as I feared)?
",False,0,MEMBER
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/643524774,Add pitch and roll to TS helicopters,tovl,40,631073809,21,643524774,0,643497924,2020-06-12T23:50:47Z,"If you insist on doing this here, then making just the orca bomber hovering on idle but keeping the banshee circling seems like a reasonable compromise, considering the visuals. 

As for the vision changes: I just checked and in the old game aircraft did reveal shroud and not just when landing either. It was totally possible to slowly walk across the map this way as well (or quickly if you already have a spot revealed on the other side of the map). That the aircraft didn't circle on idle didn't really matter here, as the vision was more than one cell anyway. The same applied to subterranean units. So if you want consistency with the original games, the current behaviour is already there.",False,0,CONTRIBUTOR
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/643534659,Add pitch and roll to TS helicopters,pchote,40,631073809,22,643534659,0,643524774,2020-06-13T00:40:36Z,"Ok. Restored circling on the banshee and left the vision alone - we still make it a lot easier even for non-banshees, but i suspect this may end up falling under the banner of QOL improvements...",False,0,MEMBER
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/643808043,Add pitch and roll to TS helicopters,penev92,40,631073809,23,643808043,0,643534659,2020-06-14T19:02:47Z,"A PR that is supposed to be about a basic engine feature should really not get bogged down over gameplay politics! (aircraft pitching/tilting/rolling vs whether a specific unit should hover, circle, land or return to base and how each of those is good or bad for gameplay)",False,0,MEMBER
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/644833477,Add pitch and roll to TS helicopters,pchote,40,631073809,24,644833477,0,643808043,2020-06-16T15:21:20Z,"> I don't see the need to make it worse than it could already be tbh.

Sliding breaks the banshee and orca bomber - see #17935.",False,0,MEMBER
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/644847641,Add pitch and roll to TS helicopters,deleted-user-1,40,631073809,25,644847641,0,644833477,2020-06-16T15:45:19Z,"> Sliding breaks the banshee and orca bomber - see #17935.

I might be missing something but I thought to only add it for orca and harpy. In the original banshees can't slide to the sides (orca and harpy can, don't know about orca bomber). My idea was that all aircraft become hovering vtols and banshee and orca bomber keep their non-sliding-plane-alike behavior (however as penev noted this should not block progress).",False,0,CONTRIBUTOR
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/646939871,Add pitch and roll to TS helicopters,dnqbob,40,631073809,26,646939871,0,644847641,2020-06-20T04:34:12Z,"> > Sliding breaks the banshee and orca bomber - see #17935.
> 
> I might be missing something but I thought to only add it for orca and harpy. In the original banshees can't slide to the sides (orca and harpy can, don't know about orca bomber). My idea was that all aircraft become hovering vtols and banshee and orca bomber keep their non-sliding-plane-alike behavior (however as penev noted this should not block progress).

I think it is the engine limit make aircrafts not slide/cycling in original TS.  because in CG Banshee slides well. ",False,0,CONTRIBUTOR
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/646942883,Add pitch and roll to TS helicopters,dnqbob,40,631073809,27,646942883,0,646939871,2020-06-20T05:14:58Z,"And I support circling for Banshee and bomber. 

However, if we really apply ion storm in map,  the needs of immediately landing will be necessary,  which means we need a good circling landing for those aircrafts. ",False,0,CONTRIBUTOR
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/646964429,Add pitch and roll to TS helicopters,deleted-user-1,40,631073809,28,646964429,0,646942883,2020-06-20T08:47:09Z,@dnqbob have you tested this pull request?,False,0,CONTRIBUTOR
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/647010458,Add pitch and roll to TS helicopters,dnqbob,40,631073809,29,647010458,0,646964429,2020-06-20T15:34:01Z,"I feel sorry about it,  but IMO I think a circling Banshee is the way better,  probably because I like Cnc3 aircraft movements.  As well as in CG when Banshee destroy MKII they are just behaving like the normal fixed wings aircrafts. 

Update: 
In other CG when Banshee land on a helipad,  they are not landing verticaly like normal hover aircraft/helicopter. 

But I agree ""IdleTurnSpeed"" should be applied to all aircrafts that cycling. Making they cycle slowly will help players select them easier and more close to modern CNC. 

Besides,  I am the one like the art and environment of TS but disagree with its balance and some of the game mechanics.  Aircrafts' behavior in idle is one of them. 

In addition,  if I am really that nitpicking I think solve the high pitch of VXLs that will lag the entire game is a more urgent issue compared to current conversation. ",False,0,CONTRIBUTOR
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/647089941,Add pitch and roll to TS helicopters,deleted-user-1,40,631073809,30,647089941,0,647010458,2020-06-21T07:20:10Z,"> As well as in CG when Banshee destroy MKII they are just behaving like the normal fixed wings aircrafts.

> Update:
> In other CG when Banshee land on a helipad, they are not landing verticaly like normal hover aircraft/helicopter.

Link source or anything? So far you have not provided anything substantial besides your opinion that you like aircraft in c&c3 and don't like ts gameplay. I highly doubt that you actually looked at the changes from this PR or tried the different setups.

You have not brought up a single argument why circling is the better behavior and I find it super frustrating that nevertheless you have had already big influence on key design aspects of the game. Banhees landing during ion storms like you propose will obviously be a horrible hack. :(",False,0,CONTRIBUTOR
https://api.github.com/repos/OpenRA/OpenRA/issues/comments/647090794,Add pitch and roll to TS helicopters,deleted-user-1,40,631073809,31,647090794,0,647089941,2020-06-21T07:28:42Z,"@dnqbob 

> I think it is the engine limit make aircrafts not slide/cycling in original TS. because in CG Banshee slides well.

No, that's not what I said. There is a distinction between harpy and banshee, the one can slide and the other can not. Please provide anything to back your implied claim that circling was intended design in ts othwise it's just yet another random opinion. Also no idea what 'CG' is or what you're referring to.
",False,0,CONTRIBUTOR
https://api.github.com/repos/nodejs/node/issues/33850,src: add public APIs to manage v8::TracingController,addaleax,3,637337636,1,637337636,0,0,2020-06-11T21:38:37Z,"We added a hack for this a while ago for Electron, so let’s remove
that hack and make this an official API.

Refs: https://github.com/nodejs/node/pull/28724
Refs: https://github.com/nodejs/node/issues/33800

<!--
Thank you for your pull request. Please provide a description above and review
the requirements below.

Bug fixes and new features should include tests and possibly benchmarks.

Contributors guide: https://github.com/nodejs/node/blob/master/CONTRIBUTING.md
-->

##### Checklist
<!-- Remove items that do not apply. For completed items, change [ ] to [x]. -->

- [x] `make -j4 test` (UNIX), or `vcbuild test` (Windows) passes
- [x] tests and/or benchmarks are included
- [x] documentation is changed or added
- [x] commit message follows [commit guidelines](https://github.com/nodejs/node/blob/master/doc/guides/contributing/pull-requests.md#commit-message-guidelines)

<!--
Developer's Certificate of Origin 1.1

By making a contribution to this project, I certify that:

(a) The contribution was created in whole or in part by me and I
    have the right to submit it under the open source license
    indicated in the file; or

(b) The contribution is based upon previous work that, to the best
    of my knowledge, is covered under an appropriate open source
    license and I have the right under that license to submit that
    work with modifications, whether created in whole or in part
    by me, under the same open source license (unless I am
    permitted to submit under a different license), as indicated
    in the file; or

(c) The contribution was provided directly to me by some other
    person who certified (a), (b) or (c) and I have not modified
    it.

(d) I understand and agree that this project and the contribution
    are public and that a record of the contribution (including all
    personal information I submit with it, including my sign-off) is
    maintained indefinitely and may be redistributed consistent with
    this project or the open source license(s) involved.
-->
",True,0,MEMBER
https://api.github.com/repos/nodejs/node/issues/comments/642940825,src: add public APIs to manage v8::TracingController,nodejs-github-bot,3,637337636,2,642940825,0,637337636,2020-06-11T21:39:22Z,CI: https://ci.nodejs.org/job/node-test-pull-request/31843/ (:yellow_heart:),False,0,COLLABORATOR
https://api.github.com/repos/nodejs/node/issues/comments/643764642,src: add public APIs to manage v8::TracingController,addaleax,3,637337636,3,643764642,0,642940825,2020-06-14T13:10:15Z,@nodejs/embedders ,False,0,MEMBER
https://api.github.com/repos/nodejs/node/issues/comments/644434537,src: add public APIs to manage v8::TracingController,addaleax,3,637337636,4,644434537,0,643764642,2020-06-15T23:04:44Z,Landed in b371213d3d2b499f0392af2103cf45262e1042d3,False,0,MEMBER
https://api.github.com/repos/nodejs/node/issues/33851,src: minor updates to FastHrtime,addaleax,4,637359414,1,637359414,0,0,2020-06-11T22:29:14Z,"- Don’t use 12 as a magic number for the buffer size
- Mark the object as weak (which is conceptually the right thing to do,
  even if there is little practical impact)
- Keep a reference to the `ArrayBuffer` in question for memory tracking

<!--
Thank you for your pull request. Please provide a description above and review
the requirements below.

Bug fixes and new features should include tests and possibly benchmarks.

Contributors guide: https://github.com/nodejs/node/blob/master/CONTRIBUTING.md
-->

##### Checklist
<!-- Remove items that do not apply. For completed items, change [ ] to [x]. -->

- [x] `make -j4 test` (UNIX), or `vcbuild test` (Windows) passes
- [x] commit message follows [commit guidelines](https://github.com/nodejs/node/blob/master/doc/guides/contributing/pull-requests.md#commit-message-guidelines)

<!--
Developer's Certificate of Origin 1.1

By making a contribution to this project, I certify that:

(a) The contribution was created in whole or in part by me and I
    have the right to submit it under the open source license
    indicated in the file; or

(b) The contribution is based upon previous work that, to the best
    of my knowledge, is covered under an appropriate open source
    license and I have the right under that license to submit that
    work with modifications, whether created in whole or in part
    by me, under the same open source license (unless I am
    permitted to submit under a different license), as indicated
    in the file; or

(c) The contribution was provided directly to me by some other
    person who certified (a), (b) or (c) and I have not modified
    it.

(d) I understand and agree that this project and the contribution
    are public and that a record of the contribution (including all
    personal information I submit with it, including my sign-off) is
    maintained indefinitely and may be redistributed consistent with
    this project or the open source license(s) involved.
-->
",True,0,MEMBER
https://api.github.com/repos/nodejs/node/issues/comments/643764651,src: minor updates to FastHrtime,nodejs-github-bot,4,637359414,2,643764651,0,637359414,2020-06-14T13:10:18Z,CI: https://ci.nodejs.org/job/node-test-pull-request/31861/,False,0,COLLABORATOR
https://api.github.com/repos/nodejs/node/issues/comments/646419937,src: minor updates to FastHrtime,nodejs-github-bot,4,637359414,3,646419937,0,643764651,2020-06-19T03:50:05Z,CI: https://ci.nodejs.org/job/node-test-pull-request/31935/,False,0,COLLABORATOR
https://api.github.com/repos/nodejs/node/issues/comments/646701411,src: minor updates to FastHrtime,addaleax,4,637359414,4,646701411,0,646419937,2020-06-19T15:35:53Z,Landed in 52de4cb107a6fc1a06f7c98f4fd36c7f7fd539d5,False,0,MEMBER
https://api.github.com/repos/nodejs/node/issues/comments/658249737,src: minor updates to FastHrtime,MylesBorins,4,637359414,5,658249737,0,646701411,2020-07-14T15:33:43Z,This does not land cleanly on v14.x. @addaleax would it make sense to backport?,False,0,MEMBER
https://api.github.com/repos/nodejs/node/issues/33852,tools: update remark-preset-lint-node@1.15.1 to 1.16.0,Trott,5,637387491,1,637387491,0,0,2020-06-11T23:46:15Z,"This adds linting for code fence language/grammar strings. This is so,
for example, we have only one of ```text and ```txt and not both.

<!--
Thank you for your pull request. Please provide a description above and review
the requirements below.

Bug fixes and new features should include tests and possibly benchmarks.

Contributors guide: https://github.com/nodejs/node/blob/master/CONTRIBUTING.md
-->

##### Checklist
<!-- Remove items that do not apply. For completed items, change [ ] to [x]. -->

- [x] `make -j4 test` (UNIX), or `vcbuild test` (Windows) passes
- [x] commit message follows [commit guidelines](https://github.com/nodejs/node/blob/master/doc/guides/contributing/pull-requests.md#commit-message-guidelines)

<!--
Developer's Certificate of Origin 1.1

By making a contribution to this project, I certify that:

(a) The contribution was created in whole or in part by me and I
    have the right to submit it under the open source license
    indicated in the file; or

(b) The contribution is based upon previous work that, to the best
    of my knowledge, is covered under an appropriate open source
    license and I have the right under that license to submit that
    work with modifications, whether created in whole or in part
    by me, under the same open source license (unless I am
    permitted to submit under a different license), as indicated
    in the file; or

(c) The contribution was provided directly to me by some other
    person who certified (a), (b) or (c) and I have not modified
    it.

(d) I understand and agree that this project and the contribution
    are public and that a record of the contribution (including all
    personal information I submit with it, including my sign-off) is
    maintained indefinitely and may be redistributed consistent with
    this project or the open source license(s) involved.
-->
",True,0,MEMBER
https://api.github.com/repos/nodejs/node/issues/comments/645147784,tools: update remark-preset-lint-node@1.15.1 to 1.16.0,Trott,5,637387491,2,645147784,0,637387491,2020-06-17T04:49:01Z,@nodejs/linting ,False,0,MEMBER
https://api.github.com/repos/nodejs/node/issues/comments/645373589,tools: update remark-preset-lint-node@1.15.1 to 1.16.0,Trott,5,637387491,3,645373589,0,645147784,2020-06-17T13:28:16Z,"Oh, look at that: A `shell` code fence flag landed in the interim. Added a commit to change it to `bash`. Your work is paying off already, @DerekNonGeneric.",False,0,MEMBER
https://api.github.com/repos/nodejs/node/issues/comments/645384144,tools: update remark-preset-lint-node@1.15.1 to 1.16.0,DerekNonGeneric,5,637387491,4,645384144,0,645373589,2020-06-17T13:47:10Z,"> A `shell` code fence flag landed in the interim.

That was a big fear of mine — should've fast-tracked in hindsight. Hopefully there's no issue w/ landing this puppy!",False,0,CONTRIBUTOR
https://api.github.com/repos/nodejs/node/issues/comments/646004982,tools: update remark-preset-lint-node@1.15.1 to 1.16.0,Trott,5,637387491,5,646004982,0,645384144,2020-06-18T13:07:16Z,Landed in a4f3206b767b...0ef6956225bb,False,0,MEMBER
https://api.github.com/repos/nodejs/node/issues/comments/658249139,tools: update remark-preset-lint-node@1.15.1 to 1.16.0,MylesBorins,5,637387491,6,658249139,0,646004982,2020-07-14T15:32:35Z,Added the backported-to-v14.x label. Manually skipped landing 7407fc2 to v14.x as the file it changes doesn't exist on that branch,False,0,MEMBER
https://api.github.com/repos/nodejs/node/issues/33853,Why the http client does not support the keep alive feature?,masx200,4,637472836,1,637472836,0,0,2020-06-12T04:21:31Z,"Why the http client does not support the keep alive feature?

TCP socket should be reused in multiple requests.

But the result is that the request and response are sent only once per connection.

<!--
Thank you for reporting an issue.

This issue tracker is for bugs and issues found within Node.js core.
If you require more general support please file an issue on our help
repo. https://github.com/nodejs/help


Please fill in as much of the template below as you're able.

Version: output of `node -v`
Platform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)
Subsystem: if known, please specify affected core module name
-->

* **Version**:

nodejs  v14.2.0
* **Platform**:

Linux localhost 4.9.148 #1 SMP PREEMPT Tue Mar 10 02:27:59 CST 2020 aarch64 Android
* **Subsystem**:

### What steps will reproduce the bug?

client.js
```js

 const http = require('http');
const agent = new http.Agent({
    keepAlive: true,
    keepAliveMsecs: 10000
});
function request() {
    count++;
    
    const req = http.request({
        host: 'localhost',
        port: 9000,
        method: 'GET',
        agent: agent
    }, res => {
        const socket = res.socket;
        console.log(socket.localAddress, socket.localPort);
        console.log(res.headers);
    });
    req.end();
    if (count > 20) {
        process.exit();
    }
}
let count = 0;
setInterval(() => {
    request();
    request();
}, 500 * (1 + Math.random()));
setInterval(() => {
    request();
}, 500 * (1 + Math.random()));
setInterval(() => {
    request();
}, 500 * (1 + Math.random()));
```
<!--
Enter details about your bug, preferably a simple code snippet that can be
run using `node` directly without installing third-party dependencies.
-->

server.js
```js
 const http = require('http');
http.createServer((req, res) => {
    const socket = req.socket;
    const info = socket.remoteAddress + ',' + req.socket.remotePort;
    console.log(info);
    console.log(req.headers);
    res.write(JSON.stringify(req.headers));
    res.end(info);
}).listen(9000, () => {
    console.log('listening');
});
```

```shell
node server.js
```
```shell
node client.js
```

### How often does it reproduce? Is there a required condition?
100%
### What is the expected behavior?
TCP socket should be reused in multiple requests.
<!--
If possible please provide textual output instead of screenshots.
-->

### What do you see instead?
```txt
$ node /storage/emulated/0/test/server.js
listening
::ffff:127.0.0.1,44284
{ host: 'localhost:9000', connection: 'keep-alive' }
::ffff:127.0.0.1,44286                                  
{ host: 'localhost:9000', connection: 'keep-alive' }    
::ffff:127.0.0.1,44288
{ host: 'localhost:9000', connection: 'keep-alive' }
::ffff:127.0.0.1,44290
{ host: 'localhost:9000', connection: 'keep-alive' }
::ffff:127.0.0.1,44294
{ host: 'localhost:9000', connection: 'keep-alive' }
::ffff:127.0.0.1,44296
{ host: 'localhost:9000', connection: 'keep-alive' }
::ffff:127.0.0.1,44300
{ host: 'localhost:9000', connection: 'keep-alive' }
::ffff:127.0.0.1,44302
{ host: 'localhost:9000', connection: 'keep-alive' }
::ffff:127.0.0.1,44304
{ host: 'localhost:9000', connection: 'keep-alive' }
::ffff:127.0.0.1,44308
{ host: 'localhost:9000', connection: 'keep-alive' }
::ffff:127.0.0.1,44310
{ host: 'localhost:9000', connection: 'keep-alive' }
::ffff:127.0.0.1,44312
{ host: 'localhost:9000', connection: 'keep-alive' }
::ffff:127.0.0.1,44314
{ host: 'localhost:9000', connection: 'keep-alive' }
::ffff:127.0.0.1,44318
{ host: 'localhost:9000', connection: 'keep-alive' }
::ffff:127.0.0.1,44320
{ host: 'localhost:9000', connection: 'keep-alive' }
::ffff:127.0.0.1,44322
{ host: 'localhost:9000', connection: 'keep-alive' }
::ffff:127.0.0.1,44324
{ host: 'localhost:9000', connection: 'keep-alive' }
::ffff:127.0.0.1,44328
{ host: 'localhost:9000', connection: 'keep-alive' }
::ffff:127.0.0.1,44330
{ host: 'localhost:9000', connection: 'keep-alive' }
^C
$
```
<!--
If possible please provide textual output instead of screenshots.
-->
```txt
$ node /storage/emulated/0/test/client.js


127.0.0.1 44284
{
  date: 'Fri, 12 Jun 2020 04:22:52 GMT',
  connection: 'keep-alive',
  'transfer-encoding': 'chunked'
}


127.0.0.1 44286
{
  date: 'Fri, 12 Jun 2020 04:22:52 GMT',
  connection: 'keep-alive',
  'transfer-encoding': 'chunked'
}
127.0.0.1 44288
{
  date: 'Fri, 12 Jun 2020 04:22:52 GMT',                
  connection: 'keep-alive',
  'transfer-encoding': 'chunked'
}
127.0.0.1 44290
{
  date: 'Fri, 12 Jun 2020 04:22:52 GMT',
  connection: 'keep-alive',
  'transfer-encoding': 'chunked'
}

127.0.0.1 44294
{
  date: 'Fri, 12 Jun 2020 04:22:52 GMT',
  connection: 'keep-alive',
  'transfer-encoding': 'chunked'
}

127.0.0.1 44296
{
  date: 'Fri, 12 Jun 2020 04:22:53 GMT',
  connection: 'keep-alive',
  'transfer-encoding': 'chunked'
}


127.0.0.1 44300
{
  date: 'Fri, 12 Jun 2020 04:22:53 GMT',
  connection: 'keep-alive',
  'transfer-encoding': 'chunked'
}
127.0.0.1 44302
{
  date: 'Fri, 12 Jun 2020 04:22:53 GMT',
  connection: 'keep-alive',
  'transfer-encoding': 'chunked'
}

127.0.0.1 44304
{
  date: 'Fri, 12 Jun 2020 04:22:53 GMT',
  connection: 'keep-alive',
  'transfer-encoding': 'chunked'
}

127.0.0.1 44308
{
  date: 'Fri, 12 Jun 2020 04:22:53 GMT',
  connection: 'keep-alive',
  'transfer-encoding': 'chunked'
}

127.0.0.1 44310
{
  date: 'Fri, 12 Jun 2020 04:22:53 GMT',
  connection: 'keep-alive',
  'transfer-encoding': 'chunked'
}


127.0.0.1 44312
{
  date: 'Fri, 12 Jun 2020 04:22:54 GMT',
  connection: 'keep-alive',
  'transfer-encoding': 'chunked'
}
127.0.0.1 44314
{
  date: 'Fri, 12 Jun 2020 04:22:54 GMT',
  connection: 'keep-alive',
  'transfer-encoding': 'chunked'
}

127.0.0.1 44318
{
  date: 'Fri, 12 Jun 2020 04:22:54 GMT',
  connection: 'keep-alive',
  'transfer-encoding': 'chunked'
}

127.0.0.1 44320
{
  date: 'Fri, 12 Jun 2020 04:22:54 GMT',
  connection: 'keep-alive',
  'transfer-encoding': 'chunked'
}


127.0.0.1 44322
{
  date: 'Fri, 12 Jun 2020 04:22:54 GMT',
  connection: 'keep-alive',
  'transfer-encoding': 'chunked'
}
127.0.0.1 44324
{
  date: 'Fri, 12 Jun 2020 04:22:54 GMT',
  connection: 'keep-alive',
  'transfer-encoding': 'chunked'
}

127.0.0.1 44328
{
  date: 'Fri, 12 Jun 2020 04:22:54 GMT',
  connection: 'keep-alive',
  'transfer-encoding': 'chunked'
}

127.0.0.1 44330
{
  date: 'Fri, 12 Jun 2020 04:22:55 GMT',
  connection: 'keep-alive',
  'transfer-encoding': 'chunked'
}


$
```
### Additional information

<!--
Tell us anything else you think we should know.
-->
",True,0,CONTRIBUTOR
https://api.github.com/repos/nodejs/node/issues/comments/643065108,Why the http client does not support the keep alive feature?,DerekNonGeneric,4,637472836,2,643065108,0,637472836,2020-06-12T04:57:52Z,"I think this is traditionally solved as is described on the following page.

https://www.jstips.co/en/javascript/working-with-websocket-timeout/

At least that's how I've solved it for myself, anyone else please feel free to add 2¢.",False,0,CONTRIBUTOR
https://api.github.com/repos/nodejs/node/issues/comments/643083418,Why the http client does not support the keep alive feature?,masx200,4,637472836,3,643083418,0,643065108,2020-06-12T06:04:08Z,"@Flarna 

Thanks, you found the correct answer to the question.
",False,0,CONTRIBUTOR
https://api.github.com/repos/nodejs/node/issues/comments/643225361,Why the http client does not support the keep alive feature?,Flarna,4,637472836,4,643225361,0,643083418,2020-06-12T11:39:08Z,"I think you have to consume the response data received on client side. Try adding `res.resume()` if you are not interested in the response data in your sample.
Please note that this is done automatically if no response callback is set at all (see https://nodejs.org/dist/latest-v14.x/docs/api/http.html#http_class_http_clientrequest)",False,0,MEMBER
https://api.github.com/repos/nodejs/node/issues/comments/643596985,Why the http client does not support the keep alive feature?,bnoordhuis,4,637472836,5,643596985,0,643225361,2020-06-13T09:23:28Z,Closing as answered.,False,0,MEMBER
https://api.github.com/repos/openzfs/zfs/issues/10441,Invalid backup stream during zfs receive,Flyffies,6,637176289,1,637176289,0,0,2020-06-11T16:53:42Z,"<!-- Please fill out the following template, which will help other contributors address your issue. -->

<!--
Thank you for reporting an issue.

*IMPORTANT* - Please check our issue tracker before opening a new issue.
Additional valuable information can be found in the OpenZFS documentation
and mailing list archives.

Please fill in as much of the template as possible.
-->

### System information
<!--  add version after ""|"" character -->
Type | Version/Name
 --- | ---
Distribution Name	| Debian
Distribution Version	| Buster (10.4)
Linux Kernel	| 4.19.0-9
Architecture	| amd64
ZFS Version	| 0.8.4-1~bpo10+1
SPL Version	| 0.8.4-1~bpo10+1
<!--
Commands to find ZFS/SPL versions:
modinfo zfs | grep -iw version
modinfo spl | grep -iw version
-->

### Describe the problem you're observing

I had to restore my System and decided to do so by exporting my ZFS Filesystems via ZFS send to a network share my hoster could provide.

I had to mount my pool in read only in the recovery environment and send the filesystems into a file on the share. 

After reinstalling my server I received the filesystems back into the new pool. on 5 of the 7 this worked no problem. But my nextcloud files (of course the most important one...) has en error while importing.

After running a while it fails with the following error:
`cannot receive new filesystem stream: invalid backup stream`

When I run the snapshotfile through zstreamsdump it fails with this message:
```
<many many records>
BEGIN record
        hdrtype = 0
        features = 0
        magic = 0
        creation_time = 0
        type = 0
        flags = 0x0
        toguid = 0
        fromguid = 0
        toname =
invalid checksum
Incorrect checksum in record header.
Expected checksum = 4935c8a66e56e85c/e1f01e74dc163f48/bcc20562df6ae0c/ec815b9d684b028d
SUMMARY:
        Total DRR_BEGIN records = 26662 (0 bytes)
        Total DRR_END records = 0 (0 bytes)
        Total DRR_OBJECT records = 52078 (8748264 bytes)
        Total DRR_FREEOBJECTS records = 912 (0 bytes)
        Total DRR_WRITE records = 912181 (117219152896 bytes)
        Total DRR_WRITE_BYREF records = 0 (0 bytes)
        Total DRR_WRITE_EMBEDDED records = 0 (0 bytes)
        Total DRR_FREE records = 79454 (0 bytes)
        Total DRR_SPILL records = 0 (0 bytes)
        Total records = 1071287
        Total payload size = 117227901160 (0x1b4b53d0e8)
        Total header overhead = 334241544 (0x13ec1f08)
        Total stream length = 117562143016 (0x1b5f3ff128)
```

On my old server there were some error with a Bad RIP value.
I was able to find similar messages in my kernel as well...

Is there any way I can try to recover the files?
Is there a Tool? Something?

",True,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/642810367,Invalid backup stream during zfs receive,ahrens,6,637176289,2,642810367,0,637176289,2020-06-11T17:00:35Z,"It looks like maybe part of your send file has been zeroed out, because the BEGIN record it type #0, and all its fields are zero.  (It's also strange that the summary has so many BEGIN records.)

Off the top of my head, I'm not sure how you'd recover from that...",False,0,MEMBER
https://api.github.com/repos/openzfs/zfs/issues/comments/642816871,Invalid backup stream during zfs receive,Flyffies,6,637176289,3,642816871,0,642810367,2020-06-11T17:10:19Z,"I just ran zstreamdump again an redirected the output into a file... It looks like all of the output except the first record is zeroes...

Might it be possible to recover the old pool? could that be a possiblility? Sadly I already created the new pool...",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/642819723,Invalid backup stream during zfs receive,Flyffies,6,637176289,4,642819723,0,642816871,2020-06-11T17:16:12Z,Would It be possible to ignore the zeroed records during a receive? Maybe something could be recovered instead of nothing?,False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/642844647,Invalid backup stream during zfs receive,ahrens,6,637176289,5,642844647,0,642819723,2020-06-11T18:04:07Z,I don't know how you would do that.,False,0,MEMBER
https://api.github.com/repos/openzfs/zfs/issues/comments/643095035,Invalid backup stream during zfs receive,Flyffies,6,637176289,6,643095035,0,642844647,2020-06-12T06:38:24Z,"Today I might have a bit more information.

It seems the snaphot somehow contains multiple BEGIN recors at the end of the file...
I could also ""grep"" through the snapshot and find data that was contained in my files.

I would want to try and remove these tailing zero begin recors (and probably add a matching end record?). Where could I find more information about the binary format itself?
",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/647398275,Invalid backup stream during zfs receive,Flyffies,6,637176289,7,647398275,0,643095035,2020-06-22T09:26:25Z,"Ok, I made progress. 
I am able to import 106 Gb of the 117 Gb ZFS. Sadly I am not just able to mount it when using `receive -s`.

Could that somehow be achieved? Not aborting an incomplete transfer, but just take it ""as is"" and mount it?

Or fake the END DMU record and that way let ZFS think it would be finished? That I could mount it read only and copy the files?",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/10443,FreeBSD: Kernel module should depend on xdr not krpc after 1300092,ghost,3,637443017,1,637443017,0,0,2020-06-12T02:41:30Z,"<!--- Please fill out the following template, which will help other contributors review your Pull Request. -->

<!--- Provide a general summary of your changes in the Title above -->

<!---
Documentation on ZFS Buildbot options can be found at
https://openzfs.github.io/openzfs-docs/Developer%20Resources/Buildbot%20Options.html
-->

### Motivation and Context
<!--- Why is this change required? What problem does it solve? -->
<!--- If it fixes an open issue, please link to the issue here. -->
Closes #10442

Since https://reviews.freebsd.org/D24408 FreeBSD provides XDR functions
in the xdr module instead of krpc.

### Description
<!--- Describe your changes in detail -->
For FreeBSD 13, the MODULE_DEPEND should be changed to xdr

### How Has This Been Tested?
<!--- Please describe in detail how you tested your changes. -->
<!--- Include details of your testing environment, and the tests you ran to -->
<!--- see how your change affects other areas of the code, etc. -->
<!--- If your change is a performance enhancement, please provide benchmarks here. -->
<!--- Please think about using the draft PR feature if appropriate -->
Built and loaded correctly on recent 13-current.

### Types of changes
<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->
- [x] Bug fix (non-breaking change which fixes an issue)
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Performance enhancement (non-breaking change which improves efficiency)
- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)
- [ ] Breaking change (fix or feature that would cause existing functionality to change)
- [ ] Documentation (a change to man pages or other documentation)

### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [x] My code follows the ZFS on Linux [code style requirements](https://github.com/zfsonlinux/zfs/blob/master/.github/CONTRIBUTING.md#coding-conventions).
- [x] I have updated the documentation accordingly.
- [x] I have read the [**contributing** document](https://github.com/zfsonlinux/zfs/blob/master/.github/CONTRIBUTING.md).
- [ ] I have added [tests](https://github.com/zfsonlinux/zfs/tree/master/tests) to cover my changes.
- [ ] I have run the ZFS Test Suite with this change applied.
- [x] All commit messages are properly formatted and contain [`Signed-off-by`](https://github.com/zfsonlinux/zfs/blob/master/.github/CONTRIBUTING.md#signed-off-by).
",True,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/643046683,FreeBSD: Kernel module should depend on xdr not krpc after 1300092,ghost,3,637443017,2,643046683,0,637443017,2020-06-12T03:36:15Z,Well that's not good 🤔 ,False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/643681238,FreeBSD: Kernel module should depend on xdr not krpc after 1300092,ghost,3,637443017,3,643681238,0,643046683,2020-06-13T21:33:45Z,Manually confirmed this works on head for now.,False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/643691383,FreeBSD: Kernel module should depend on xdr not krpc after 1300092,codecov[bot],3,637443017,4,643691383,0,643681238,2020-06-13T23:21:35Z,"# [Codecov](https://codecov.io/gh/openzfs/zfs/pull/10443?src=pr&el=h1) Report
> Merging [#10443](https://codecov.io/gh/openzfs/zfs/pull/10443?src=pr&el=desc) into [master](https://codecov.io/gh/openzfs/zfs/commit/e08b993396692c227f576dd789280663103d3332&el=desc) will **decrease** coverage by `0.06%`.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/openzfs/zfs/pull/10443/graphs/tree.svg?width=650&height=150&src=pr&token=NGfxvvG2io)](https://codecov.io/gh/openzfs/zfs/pull/10443?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master   #10443      +/-   ##
==========================================
- Coverage   79.58%   79.51%   -0.07%     
==========================================
  Files         391      391              
  Lines      123872   123872              
==========================================
- Hits        98586    98503      -83     
- Misses      25286    25369      +83     
```

| Flag | Coverage Δ | |
|---|---|---|
| #kernel | `79.97% <ø> (-0.06%)` | :arrow_down: |
| #user | `65.75% <ø> (-0.37%)` | :arrow_down: |

| [Impacted Files](https://codecov.io/gh/openzfs/zfs/pull/10443?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [module/os/linux/spl/spl-kmem-cache.c](https://codecov.io/gh/openzfs/zfs/pull/10443/diff?src=pr&el=tree#diff-bW9kdWxlL29zL2xpbnV4L3NwbC9zcGwta21lbS1jYWNoZS5j) | `75.58% <0.00%> (-8.50%)` | :arrow_down: |
| [module/zfs/vdev\_indirect.c](https://codecov.io/gh/openzfs/zfs/pull/10443/diff?src=pr&el=tree#diff-bW9kdWxlL3pmcy92ZGV2X2luZGlyZWN0LmM=) | `73.66% <0.00%> (-7.00%)` | :arrow_down: |
| [module/zfs/bpobj.c](https://codecov.io/gh/openzfs/zfs/pull/10443/diff?src=pr&el=tree#diff-bW9kdWxlL3pmcy9icG9iai5j) | `86.86% <0.00%> (-4.29%)` | :arrow_down: |
| [module/os/linux/zfs/zio\_crypt.c](https://codecov.io/gh/openzfs/zfs/pull/10443/diff?src=pr&el=tree#diff-bW9kdWxlL29zL2xpbnV4L3pmcy96aW9fY3J5cHQuYw==) | `79.97% <0.00%> (-1.23%)` | :arrow_down: |
| [module/zfs/vdev\_removal.c](https://codecov.io/gh/openzfs/zfs/pull/10443/diff?src=pr&el=tree#diff-bW9kdWxlL3pmcy92ZGV2X3JlbW92YWwuYw==) | `96.45% <0.00%> (-1.03%)` | :arrow_down: |
| [cmd/ztest/ztest.c](https://codecov.io/gh/openzfs/zfs/pull/10443/diff?src=pr&el=tree#diff-Y21kL3p0ZXN0L3p0ZXN0LmM=) | `79.11% <0.00%> (-1.03%)` | :arrow_down: |
| [module/zfs/vdev\_initialize.c](https://codecov.io/gh/openzfs/zfs/pull/10443/diff?src=pr&el=tree#diff-bW9kdWxlL3pmcy92ZGV2X2luaXRpYWxpemUuYw==) | `96.83% <0.00%> (-0.95%)` | :arrow_down: |
| [cmd/zed/agents/zfs\_mod.c](https://codecov.io/gh/openzfs/zfs/pull/10443/diff?src=pr&el=tree#diff-Y21kL3plZC9hZ2VudHMvemZzX21vZC5j) | `77.55% <0.00%> (-0.67%)` | :arrow_down: |
| [module/zfs/arc.c](https://codecov.io/gh/openzfs/zfs/pull/10443/diff?src=pr&el=tree#diff-bW9kdWxlL3pmcy9hcmMuYw==) | `89.08% <0.00%> (-0.63%)` | :arrow_down: |
| [module/zfs/vdev.c](https://codecov.io/gh/openzfs/zfs/pull/10443/diff?src=pr&el=tree#diff-bW9kdWxlL3pmcy92ZGV2LmM=) | `89.95% <0.00%> (-0.61%)` | :arrow_down: |
| ... and [45 more](https://codecov.io/gh/openzfs/zfs/pull/10443/diff?src=pr&el=tree-more) | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/openzfs/zfs/pull/10443?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/openzfs/zfs/pull/10443?src=pr&el=footer). Last update [e08b993...22858c3](https://codecov.io/gh/openzfs/zfs/pull/10443?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/10444,Zero out uninitialized lock locals,ghost,5,637469461,1,637469461,0,0,2020-06-12T04:10:37Z,"Signed-off-by: Ryan Moeller <ryan@iXsystems.com>

<!--- Please fill out the following template, which will help other contributors review your Pull Request. -->

<!--- Provide a general summary of your changes in the Title above -->

<!---
Documentation on ZFS Buildbot options can be found at
https://openzfs.github.io/openzfs-docs/Developer%20Resources/Buildbot%20Options.html
-->

### Motivation and Context
<!--- Why is this change required? What problem does it solve? -->
<!--- If it fixes an open issue, please link to the issue here. -->
Trash in the uninitialized local causes a panic on FreeBSD with INVARIANTS.

### Description
<!--- Describe your changes in detail -->
Zero out the lock before initialization.

### How Has This Been Tested?
<!--- Please describe in detail how you tested your changes. -->
<!--- Include details of your testing environment, and the tests you ran to -->
<!--- see how your change affects other areas of the code, etc. -->
<!--- If your change is a performance enhancement, please provide benchmarks here. -->
<!--- Please think about using the draft PR feature if appropriate -->

### Types of changes
<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->
- [x] Bug fix (non-breaking change which fixes an issue)
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Performance enhancement (non-breaking change which improves efficiency)
- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)
- [ ] Breaking change (fix or feature that would cause existing functionality to change)
- [ ] Documentation (a change to man pages or other documentation)

### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [x] My code follows the ZFS on Linux [code style requirements](https://github.com/zfsonlinux/zfs/blob/master/.github/CONTRIBUTING.md#coding-conventions).
- [x] I have updated the documentation accordingly.
- [x] I have read the [**contributing** document](https://github.com/zfsonlinux/zfs/blob/master/.github/CONTRIBUTING.md).
- [ ] I have added [tests](https://github.com/zfsonlinux/zfs/tree/master/tests) to cover my changes.
- [ ] I have run the ZFS Test Suite with this change applied.
- [x] All commit messages are properly formatted and contain [`Signed-off-by`](https://github.com/zfsonlinux/zfs/blob/master/.github/CONTRIBUTING.md#signed-off-by).
",True,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/643057046,Zero out uninitialized lock locals,adamdmoss,5,637469461,2,643057046,0,637469461,2020-06-12T04:23:32Z,"If this is a platform requirement should the zero'ing be moved up into the freebsd spl's mutex_init()?
",False,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/643062167,Zero out uninitialized lock locals,ghost,5,637469461,3,643062167,0,643057046,2020-06-12T04:46:28Z,* same in spa_activity_check,False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/643063108,Zero out uninitialized lock locals,ghost,5,637469461,4,643063108,0,643062167,2020-06-12T04:49:51Z,"> If this is a platform requirement should the zero'ing be moved up into the freebsd spl's mutex_init()?

Ok, we can add a flag to mutex_init for this.",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/643212347,Zero out uninitialized lock locals,codecov[bot],5,637469461,5,643212347,0,643063108,2020-06-12T11:03:25Z,"# [Codecov](https://codecov.io/gh/openzfs/zfs/pull/10444?src=pr&el=h1) Report
> Merging [#10444](https://codecov.io/gh/openzfs/zfs/pull/10444?src=pr&el=desc) into [master](https://codecov.io/gh/openzfs/zfs/commit/e08b993396692c227f576dd789280663103d3332&el=desc) will **decrease** coverage by `0.11%`.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/openzfs/zfs/pull/10444/graphs/tree.svg?width=650&height=150&src=pr&token=NGfxvvG2io)](https://codecov.io/gh/openzfs/zfs/pull/10444?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master   #10444      +/-   ##
==========================================
- Coverage   79.58%   79.47%   -0.12%     
==========================================
  Files         391      391              
  Lines      123872   123874       +2     
==========================================
- Hits        98586    98446     -140     
- Misses      25286    25428     +142     
```

| Flag | Coverage Δ | |
|---|---|---|
| #kernel | `79.94% <100.00%> (-0.09%)` | :arrow_down: |
| #user | `65.52% <50.00%> (-0.60%)` | :arrow_down: |

| [Impacted Files](https://codecov.io/gh/openzfs/zfs/pull/10444?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [module/zfs/dmu\_objset.c](https://codecov.io/gh/openzfs/zfs/pull/10444/diff?src=pr&el=tree#diff-bW9kdWxlL3pmcy9kbXVfb2Jqc2V0LmM=) | `91.63% <100.00%> (+<0.01%)` | :arrow_up: |
| [module/zfs/spa.c](https://codecov.io/gh/openzfs/zfs/pull/10444/diff?src=pr&el=tree#diff-bW9kdWxlL3pmcy9zcGEuYw==) | `87.08% <100.00%> (+<0.01%)` | :arrow_up: |
| [module/os/linux/spl/spl-zlib.c](https://codecov.io/gh/openzfs/zfs/pull/10444/diff?src=pr&el=tree#diff-bW9kdWxlL29zL2xpbnV4L3NwbC9zcGwtemxpYi5j) | `55.35% <0.00%> (-28.58%)` | :arrow_down: |
| [module/os/linux/spl/spl-kmem-cache.c](https://codecov.io/gh/openzfs/zfs/pull/10444/diff?src=pr&el=tree#diff-bW9kdWxlL29zL2xpbnV4L3NwbC9zcGwta21lbS1jYWNoZS5j) | `75.22% <0.00%> (-8.87%)` | :arrow_down: |
| [module/zfs/vdev\_indirect.c](https://codecov.io/gh/openzfs/zfs/pull/10444/diff?src=pr&el=tree#diff-bW9kdWxlL3pmcy92ZGV2X2luZGlyZWN0LmM=) | `74.50% <0.00%> (-6.17%)` | :arrow_down: |
| [module/zfs/zio.c](https://codecov.io/gh/openzfs/zfs/pull/10444/diff?src=pr&el=tree#diff-bW9kdWxlL3pmcy96aW8uYw==) | `87.58% <0.00%> (-0.87%)` | :arrow_down: |
| [module/zfs/vdev\_trim.c](https://codecov.io/gh/openzfs/zfs/pull/10444/diff?src=pr&el=tree#diff-bW9kdWxlL3pmcy92ZGV2X3RyaW0uYw==) | `95.34% <0.00%> (-0.76%)` | :arrow_down: |
| [module/zfs/vdev\_removal.c](https://codecov.io/gh/openzfs/zfs/pull/10444/diff?src=pr&el=tree#diff-bW9kdWxlL3pmcy92ZGV2X3JlbW92YWwuYw==) | `96.80% <0.00%> (-0.69%)` | :arrow_down: |
| [cmd/zed/agents/zfs\_mod.c](https://codecov.io/gh/openzfs/zfs/pull/10444/diff?src=pr&el=tree#diff-Y21kL3plZC9hZ2VudHMvemZzX21vZC5j) | `77.55% <0.00%> (-0.67%)` | :arrow_down: |
| [module/icp/api/kcf\_mac.c](https://codecov.io/gh/openzfs/zfs/pull/10444/diff?src=pr&el=tree#diff-bW9kdWxlL2ljcC9hcGkva2NmX21hYy5j) | `38.28% <0.00%> (-0.58%)` | :arrow_down: |
| ... and [44 more](https://codecov.io/gh/openzfs/zfs/pull/10444/diff?src=pr&el=tree-more) | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/openzfs/zfs/pull/10444?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/openzfs/zfs/pull/10444?src=pr&el=footer). Last update [e08b993...67ca79c](https://codecov.io/gh/openzfs/zfs/pull/10444?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/643334065,Zero out uninitialized lock locals,ghost,5,637469461,6,643334065,0,643212347,2020-06-12T15:26:04Z,The assert can be removed instead.,False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/10445,Upstream: zil_commit_waiter() can stall forever,lundman,3,637496788,1,637496788,0,0,2020-06-12T05:34:47Z,"On macOS clock_t is unsigned, so when cv_timedwait_hires() returns -1
we loop forever. The conditional was tweaked to ignore signedness.

<!--- Please fill out the following template, which will help other contributors review your Pull Request. -->

<!--- Provide a general summary of your changes in the Title above -->

<!---
Documentation on ZFS Buildbot options can be found at
https://openzfs.github.io/openzfs-docs/Developer%20Resources/Buildbot%20Options.html
-->

### Motivation and Context
<!--- Why is this change required? What problem does it solve? -->
<!--- If it fixes an open issue, please link to the issue here. -->

Stall forever from fsync.

### Description
<!--- Describe your changes in detail -->

By testing directly against -1, it does not matter if it is interpreted as signed or unsigned. Ie, no greater-than usage. Unfortunately `clock_t` is defined by OS.

### How Has This Been Tested?
<!--- Please describe in detail how you tested your changes. -->
<!--- Include details of your testing environment, and the tests you ran to -->
<!--- see how your change affects other areas of the code, etc. -->
<!--- If your change is a performance enhancement, please provide benchmarks here. -->
<!--- Please think about using the draft PR feature if appropriate -->

### Types of changes
<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->
- [x] Bug fix (non-breaking change which fixes an issue)
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Performance enhancement (non-breaking change which improves efficiency)
- [ ] Code cleanup (non-breaking change which makes code smaller or more readable)
- [ ] Breaking change (fix or feature that would cause existing functionality to change)
- [ ] Documentation (a change to man pages or other documentation)

### Checklist:
<!--- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [x] My code follows the ZFS on Linux [code style requirements](https://github.com/zfsonlinux/zfs/blob/master/.github/CONTRIBUTING.md#coding-conventions).
- [ ] I have updated the documentation accordingly.
- [x] I have read the [**contributing** document](https://github.com/zfsonlinux/zfs/blob/master/.github/CONTRIBUTING.md).
- [ ] I have added [tests](https://github.com/zfsonlinux/zfs/tree/master/tests) to cover my changes.
- [x] I have run the ZFS Test Suite with this change applied.
- [x] All commit messages are properly formatted and contain [`Signed-off-by`](https://github.com/zfsonlinux/zfs/blob/master/.github/CONTRIBUTING.md#signed-off-by).
",True,0,CONTRIBUTOR
https://api.github.com/repos/openzfs/zfs/issues/comments/643238322,Upstream: zil_commit_waiter() can stall forever,codecov[bot],3,637496788,2,643238322,0,637496788,2020-06-12T12:13:18Z,"# [Codecov](https://codecov.io/gh/openzfs/zfs/pull/10445?src=pr&el=h1) Report
> Merging [#10445](https://codecov.io/gh/openzfs/zfs/pull/10445?src=pr&el=desc) into [master](https://codecov.io/gh/openzfs/zfs/commit/e08b993396692c227f576dd789280663103d3332&el=desc) will **decrease** coverage by `0.18%`.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/openzfs/zfs/pull/10445/graphs/tree.svg?width=650&height=150&src=pr&token=NGfxvvG2io)](https://codecov.io/gh/openzfs/zfs/pull/10445?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master   #10445      +/-   ##
==========================================
- Coverage   79.58%   79.39%   -0.19%     
==========================================
  Files         391      391              
  Lines      123872   123872              
==========================================
- Hits        98586    98354     -232     
- Misses      25286    25518     +232     
```

| Flag | Coverage Δ | |
|---|---|---|
| #kernel | `79.97% <100.00%> (-0.06%)` | :arrow_down: |
| #user | `64.57% <100.00%> (-1.55%)` | :arrow_down: |

| [Impacted Files](https://codecov.io/gh/openzfs/zfs/pull/10445?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [module/zfs/zil.c](https://codecov.io/gh/openzfs/zfs/pull/10445/diff?src=pr&el=tree#diff-bW9kdWxlL3pmcy96aWwuYw==) | `93.03% <100.00%> (+1.78%)` | :arrow_up: |
| [module/os/linux/spl/spl-kmem-cache.c](https://codecov.io/gh/openzfs/zfs/pull/10445/diff?src=pr&el=tree#diff-bW9kdWxlL29zL2xpbnV4L3NwbC9zcGwta21lbS1jYWNoZS5j) | `75.58% <0.00%> (-8.50%)` | :arrow_down: |
| [module/zfs/vdev\_indirect.c](https://codecov.io/gh/openzfs/zfs/pull/10445/diff?src=pr&el=tree#diff-bW9kdWxlL3pmcy92ZGV2X2luZGlyZWN0LmM=) | `73.33% <0.00%> (-7.34%)` | :arrow_down: |
| [module/zfs/vdev\_removal.c](https://codecov.io/gh/openzfs/zfs/pull/10445/diff?src=pr&el=tree#diff-bW9kdWxlL3pmcy92ZGV2X3JlbW92YWwuYw==) | `94.05% <0.00%> (-3.43%)` | :arrow_down: |
| [module/zfs/dsl\_scan.c](https://codecov.io/gh/openzfs/zfs/pull/10445/diff?src=pr&el=tree#diff-bW9kdWxlL3pmcy9kc2xfc2Nhbi5j) | `83.10% <0.00%> (-2.83%)` | :arrow_down: |
| [module/zfs/zio\_compress.c](https://codecov.io/gh/openzfs/zfs/pull/10445/diff?src=pr&el=tree#diff-bW9kdWxlL3pmcy96aW9fY29tcHJlc3MuYw==) | `89.74% <0.00%> (-2.57%)` | :arrow_down: |
| [module/zfs/dsl\_synctask.c](https://codecov.io/gh/openzfs/zfs/pull/10445/diff?src=pr&el=tree#diff-bW9kdWxlL3pmcy9kc2xfc3luY3Rhc2suYw==) | `92.40% <0.00%> (-2.54%)` | :arrow_down: |
| [cmd/ztest/ztest.c](https://codecov.io/gh/openzfs/zfs/pull/10445/diff?src=pr&el=tree#diff-Y21kL3p0ZXN0L3p0ZXN0LmM=) | `78.05% <0.00%> (-2.08%)` | :arrow_down: |
| [module/zfs/vdev\_indirect\_mapping.c](https://codecov.io/gh/openzfs/zfs/pull/10445/diff?src=pr&el=tree#diff-bW9kdWxlL3pmcy92ZGV2X2luZGlyZWN0X21hcHBpbmcuYw==) | `97.10% <0.00%> (-1.45%)` | :arrow_down: |
| [module/zcommon/zfs\_uio.c](https://codecov.io/gh/openzfs/zfs/pull/10445/diff?src=pr&el=tree#diff-bW9kdWxlL3pjb21tb24vemZzX3Vpby5j) | `87.75% <0.00%> (-1.03%)` | :arrow_down: |
| ... and [45 more](https://codecov.io/gh/openzfs/zfs/pull/10445/diff?src=pr&el=tree-more) | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/openzfs/zfs/pull/10445?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/openzfs/zfs/pull/10445?src=pr&el=footer). Last update [e08b993...761aeb6](https://codecov.io/gh/openzfs/zfs/pull/10445?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/644329109,Upstream: zil_commit_waiter() can stall forever,ghost,3,637496788,3,644329109,0,643238322,2020-06-15T19:21:14Z,"We don't return -1 we return the delta, so this doesn't work for FreeBSD. That would be why stable/12 failed miserably. Looks like we have a few other mistakes to fix in our condvars too, so thanks :)",False,0,NONE
https://api.github.com/repos/openzfs/zfs/issues/comments/644343530,Upstream: zil_commit_waiter() can stall forever,behlendorf,3,637496788,4,644343530,0,644329109,2020-06-15T19:51:42Z,@freqlabs thanks for commenting.  After talking with @mattmacy the plan is to get the FreeBSD condvars aligned with the other implementations as quickly as possible.  ,False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/73372,Re-order correctly the sections in the sidebar,GuillaumeGomez,4,638853262,1,638853262,0,0,2020-06-15T13:26:54Z,"Before that, ""trait implementations"" and ""implementors"" titles in the sidebar were before ""methods"" for example. Which wasn't logical considering that the two sections come after in the ""content"".

r? @kinnison ",True,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/644151865,Re-order correctly the sections in the sidebar,kinnison,4,638853262,2,644151865,0,638853262,2020-06-15T13:58:28Z,"Keeping the sidebar ordering in sync with the main content makes sense to me.  I don't see any reason why this change would fail to build unless there are ordering sensitive tests out there, so.

@bors r+",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/644151880,Re-order correctly the sections in the sidebar,bors,4,638853262,3,644151880,0,644151865,2020-06-15T13:58:29Z,":pushpin: Commit b67bdb5082b097585b1ad052598a5b0f77623285 has been approved by `kinnison`

<!-- @bors r=kinnison b67bdb5082b097585b1ad052598a5b0f77623285 -->
<!-- homu: {""type"":""Approved"",""sha"":""b67bdb5082b097585b1ad052598a5b0f77623285"",""approver"":""kinnison""} -->",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/644208707,Re-order correctly the sections in the sidebar,RalfJung,4,638853262,4,644208707,0,644151880,2020-06-15T15:35:15Z,"@bors rollup
(please mark tiny PRs that are unlikely to fail CI for rollup, thanks :)",False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/644212224,Re-order correctly the sections in the sidebar,kinnison,4,638853262,5,644212224,0,644208707,2020-06-15T15:41:36Z,"@RalfJung Okay, I'll try and remember that, thanks for the pointer.",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/73373,Use track caller for bug! macro,tesuji,4,638866639,1,638866639,0,0,2020-06-15T13:44:42Z,,True,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/644168409,Use track caller for bug! macro,tesuji,4,638866639,2,644168409,0,638866639,2020-06-15T14:26:43Z,r? @Amanieu ,False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/644227198,Use track caller for bug! macro,Amanieu,4,638866639,3,644227198,0,644168409,2020-06-15T16:07:57Z,@bors r+,False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/644227213,Use track caller for bug! macro,bors,4,638866639,4,644227213,0,644227198,2020-06-15T16:07:59Z,":pushpin: Commit fe7456ce94b8edd549176d004a4435e1132c9c36 has been approved by `Amanieu`

<!-- @bors r=Amanieu fe7456ce94b8edd549176d004a4435e1132c9c36 -->
<!-- homu: {""type"":""Approved"",""sha"":""fe7456ce94b8edd549176d004a4435e1132c9c36"",""approver"":""Amanieu""} -->",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/644425830,Use track caller for bug! macro,RalfJung,4,638866639,5,644425830,0,644227213,2020-06-15T22:39:45Z,@bors rollup,False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/73374,rustbuild: Move compiler-builtins build logic to manifest,alexcrichton,12,638920235,1,638920235,0,0,2020-06-15T14:56:32Z,"This commit moves the compiler-builtins-specific build logic from
`src/bootstrap/bin/rustc.rs` into the workspace `Cargo.toml`'s
`[profile]` configuration. Now that rust-lang/cargo#7253 is fixed we can
ensure that Cargo knows about debug assertions settings, and it can also
be configured to specifically disable debug assertions unconditionally
for compiler-builtins. This should improve rebuild logic when
debug-assertions settings change and also improve build-std integration
where Cargo externally now has an avenue to learn how to build
compiler-builtins as well.",True,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/644186027,rustbuild: Move compiler-builtins build logic to manifest,rust-highfive,12,638920235,2,644186027,0,638920235,2020-06-15T14:56:36Z,"r? @Mark-Simulacrum

(rust_highfive has picked a reviewer for you, use r? to override)",False,0,COLLABORATOR
https://api.github.com/repos/rust-lang/rust/issues/comments/644209299,rustbuild: Move compiler-builtins build logic to manifest,ehuss,12,638920235,3,644209299,0,644186027,2020-06-15T15:36:15Z,"There will be a few more steps before this can help build-std.  The root manifest is not included in the src distribution (https://github.com/rust-lang/wg-cargo-std-aware/issues/27).  Even if it was, Cargo would need to merge the profiles somehow (possibly just the overrides?) (cc https://github.com/rust-lang/wg-cargo-std-aware/issues/28).
",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/644228272,rustbuild: Move compiler-builtins build logic to manifest,alexcrichton,12,638920235,4,644228272,0,644209299,2020-06-15T16:09:57Z,"Oh it's true yeah I don't expect this to ""simply by default"" help build-std, but at least in this form the information is encoded in a way that build-std has any hope of reading one day!",False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/649805858,rustbuild: Move compiler-builtins build logic to manifest,Mark-Simulacrum,12,638920235,5,649805858,0,644228272,2020-06-25T20:39:31Z,"@bors r+

One thing I've been thinking about is that more broadly, removing support for configuring these values in config.toml may make some sense. On the other hand, it does seem true that it's nice to have the .gitignore'd nature of config.toml which you can't readily get with Cargo.toml today (due to lack of cargo.toml inheritance) as far as I know.",False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/649805869,rustbuild: Move compiler-builtins build logic to manifest,bors,12,638920235,6,649805869,0,649805858,2020-06-25T20:39:32Z,":pushpin: Commit 260d5cf1e8fe6f6c36a742de2e22e5ac954b7445 has been approved by `Mark-Simulacrum`

<!-- @bors r=Mark-Simulacrum 260d5cf1e8fe6f6c36a742de2e22e5ac954b7445 -->
<!-- homu: {""type"":""Approved"",""sha"":""260d5cf1e8fe6f6c36a742de2e22e5ac954b7445"",""approver"":""Mark-Simulacrum""} -->",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/650254933,rustbuild: Move compiler-builtins build logic to manifest,Manishearth,12,638920235,7,650254933,0,649805869,2020-06-26T15:54:39Z,"Seeing a failure in https://github.com/rust-lang/rust/pull/73768#issuecomment-650253965 , might be y'all, but it might also be a bad interaction with a different PR

```
Caused by:
  could not parse input as TOML

Caused by:
  redefinition of table `profile.release.package.compiler_builtins` for key `profile.release.package.compiler_builtins` at line 46 column 1
```",False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/650744658,rustbuild: Move compiler-builtins build logic to manifest,bors,12,638920235,8,650744658,0,650254933,2020-06-28T12:20:09Z,":hourglass: Testing commit 260d5cf1e8fe6f6c36a742de2e22e5ac954b7445 with merge 3e6c31fa36e8bdd5333aa341f8205bfb3f47ce06...
<!-- homu: {""type"":""BuildStarted"",""head_sha"":""260d5cf1e8fe6f6c36a742de2e22e5ac954b7445"",""merge_sha"":""3e6c31fa36e8bdd5333aa341f8205bfb3f47ce06""} -->",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/650745444,rustbuild: Move compiler-builtins build logic to manifest,bors,12,638920235,9,650745444,0,650744658,2020-06-28T12:24:56Z,":broken_heart: Test failed - [checks-azure](https://dev.azure.com/rust-lang/e71b0ddf-dd27-435a-873c-e30f86eea377/_build/results?buildId=33153)
<!-- homu: {""type"":""BuildFailed"",""builder_url"":""https://dev.azure.com/rust-lang/e71b0ddf-dd27-435a-873c-e30f86eea377/_build/results?buildId=33153"",""builder_name"":""checks-azure""} -->",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/651137395,rustbuild: Move compiler-builtins build logic to manifest,alexcrichton,12,638920235,10,651137395,0,650745444,2020-06-29T13:54:16Z,@bors: r=Mark-Simulacrum,False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/651137407,rustbuild: Move compiler-builtins build logic to manifest,bors,12,638920235,11,651137407,0,651137395,2020-06-29T13:54:17Z,":pushpin: Commit 3dfbf0bc738d1ba4ee0f084ce3f32074fceee3bb has been approved by `Mark-Simulacrum`

<!-- @bors r=Mark-Simulacrum 3dfbf0bc738d1ba4ee0f084ce3f32074fceee3bb -->
<!-- homu: {""type"":""Approved"",""sha"":""3dfbf0bc738d1ba4ee0f084ce3f32074fceee3bb"",""approver"":""Mark-Simulacrum""} -->",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/651384702,rustbuild: Move compiler-builtins build logic to manifest,bors,12,638920235,12,651384702,0,651137407,2020-06-29T21:42:49Z,":hourglass: Testing commit 3dfbf0bc738d1ba4ee0f084ce3f32074fceee3bb with merge a1528c432e45339d9b5602a19ac3571e2900d37b...
<!-- homu: {""type"":""BuildStarted"",""head_sha"":""3dfbf0bc738d1ba4ee0f084ce3f32074fceee3bb"",""merge_sha"":""a1528c432e45339d9b5602a19ac3571e2900d37b""} -->",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/651468132,rustbuild: Move compiler-builtins build logic to manifest,bors,12,638920235,13,651468132,0,651384702,2020-06-30T01:44:20Z,":sunny: Test successful - [checks-azure](https://dev.azure.com/rust-lang/e71b0ddf-dd27-435a-873c-e30f86eea377/_build/results?buildId=33253)
Approved by: Mark-Simulacrum
Pushing a1528c432e45339d9b5602a19ac3571e2900d37b to master...
<!-- homu: {""type"":""BuildCompleted"",""approved_by"":""Mark-Simulacrum"",""base_ref"":""master"",""builders"":{""checks-azure"":""https://dev.azure.com/rust-lang/e71b0ddf-dd27-435a-873c-e30f86eea377/_build/results?buildId=33253""},""merge_sha"":""a1528c432e45339d9b5602a19ac3571e2900d37b""} -->",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/73376,Rollup of 5 pull requests,Dylan-DPC-zz,4,638942333,1,638942333,0,0,2020-06-15T15:26:24Z,"Successful merges:

 - #72628 (Add tests for 'impl Default for [T; N]')
 - #72836 (Complete the std::time documentation to warn about the inconsistencies between OS)
 - #73065 (Fix link error with #[thread_local] introduced by #71192)
 - #73142 (Ensure std benchmarks get tested.)
 - #73287 (lint: normalize projections using opaque types)

Failed merges:


r? @ghost",True,0,NONE
https://api.github.com/repos/rust-lang/rust/issues/comments/644207405,Rollup of 5 pull requests,Dylan-DPC-zz,4,638942333,2,644207405,0,638942333,2020-06-15T15:33:03Z,@bors r+ rollup=never p=5,False,0,NONE
https://api.github.com/repos/rust-lang/rust/issues/comments/644207415,Rollup of 5 pull requests,bors,4,638942333,3,644207415,0,644207405,2020-06-15T15:33:04Z,":pushpin: Commit b2a98b26c0b88e9cac033626f717c6d459927e62 has been approved by `Dylan-DPC`

<!-- @bors r=Dylan-DPC b2a98b26c0b88e9cac033626f717c6d459927e62 -->
<!-- homu: {""type"":""Approved"",""sha"":""b2a98b26c0b88e9cac033626f717c6d459927e62"",""approver"":""Dylan-DPC""} -->",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/644265894,Rollup of 5 pull requests,Dylan-DPC-zz,4,638942333,4,644265894,0,644207415,2020-06-15T17:24:28Z,CI failed spuriously..,False,0,NONE
https://api.github.com/repos/rust-lang/rust/issues/comments/644427718,Rollup of 5 pull requests,Dylan-DPC-zz,4,638942333,5,644427718,0,644265894,2020-06-15T22:46:00Z,"superseeded  by bigger rollup

@bors r-",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/10884,Can't use keyboard keys for analog inputs anymore.,bslenul,3,642604919,1,642604919,0,0,2020-06-21T17:21:43Z,"## Description

Binding left or right analog in Settings > Input to keyboard keys doesn't work anymore. You can bind them but they don't respond ingame.

### Expected behavior

Keys working as left/right analog inputs if bound as such.

### Actual behavior

Doesn't do anything ingame.

### Steps to reproduce the bug

1. Go to Settings > Input > Port 1 Binds.
2. Bind some numpad keys for example for left analog inputs.
3. Start Super Mario 64 and try to move with the numpad keys.

### Bisect Results

Started with this commit: c7cd327b5bb5da6295fa7c93e478b3f3a1dfc8b2

### Version/Commit

- RetroArch: 1.8.9 / 857b0da555

### Environment information

- OS: Windows 10",True,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/647157592,Can't use keyboard keys for analog inputs anymore.,bslenul,3,642604919,2,647157592,0,642604919,2020-06-21T17:29:27Z,"Ah, seems to only happen when a controller is plugged, with no controller the keys respond properly.

**edit:** Tested on my Linux Mint VM too, same behavior.

**edit2:** Results seem to vary depending on the controller and/or the mode set for it:
* DS4 with DS4Windows I get no inputs at all for analog with kb keys.
* DS4 without DS4Windows I get only up/down axis.
* 8bitdo NES30 Pro depending on the mode (dinput/xinput/etc.) I get it to work fine (both axis I mean) or sometimes only left/right axis.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/647702186,Can't use keyboard keys for analog inputs anymore.,inactive123,3,642604919,3,647702186,0,647157592,2020-06-22T18:36:42Z,"Try to see if this solves the issue -

https://github.com/libretro/RetroArch/commit/35c55c4b50105a6107f4754585a2c68995d9174d",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/647710738,Can't use keyboard keys for analog inputs anymore.,bslenul,3,642604919,4,647710738,0,647702186,2020-06-22T18:54:21Z,"Yup, tested with both my DS4 (with and without DS4Windows) and my 8bitdo, no issue anymore, thanks for the fix!",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/10890,[Windows/Bug]Guide/Home button on Xinput controller bug with explorer.exe terminated,Immersion95,5,642902435,1,642902435,0,0,2020-06-22T09:19:48Z,"Hi,

I have this exact same issue which is bothering me : https://www.reddit.com/r/RetroArch/comments/ensw3o/i_think_i_discovered_a_bug_with_retroarch_anyone/

Pressing the Guide button when explorer.exe is off make Retroarch start a server, it then becomes extremely slow and I have to restart it",True,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/647450889,[Windows/Bug]Guide/Home button on Xinput controller bug with explorer.exe terminated,bslenul,5,642902435,2,647450889,0,642902435,2020-06-22T11:13:04Z,"Just tried out of curiosity and can confirm this oO 

> [ERROR] [dispserv]: HrInit of ITaskbarList3 failed.
...
[INFO] [netplay] Waiting for client ...
[INFO] [CONTENT LOAD]: CRC32: 0x3337ec46 .
[INFO] [netplay] You have joined as player 1
[INFO] [netplay] Port Mapping Successful: xx.xx.xx.xx:55435
[INFO] [DISCORD]: Netplay room details: ID=78806, Nick=bslenul IP=xx.xx.xx.xx Port=55435
[INFO] [DISCORD]: Join secret: 78806|xxxxxxxxxx
[INFO] [DISCORD]: Party ID: 78806

Not sure what the ""Join secret"" is, so I preferred to hide the 2nd part of that line.

If no content is loaded you get that notification: `Netplay will start when content is loaded`. Steam completely closed, I even closed DS4Windows just in case... It's like it's pressing the ""Netplay Hosting"" hotkey, except it's not bound to anything for me 😅 ",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/744728217,[Windows/Bug]Guide/Home button on Xinput controller bug with explorer.exe terminated,corgana,5,642902435,3,744728217,0,647450889,2020-12-14T21:41:15Z,"I have had this issue for a long time. A developer on Reddit once told me it was Steam, not Retroarch causing the problem (however I didn't have Steam at the time). I actually just tried the new Retroarch for Steam beta assuming it would be fixed (because Steam uses the guide button to access it's menu) and it STILL brings up the netplay stuff and slows down the game.

EDIT: I have tried unbinding the guide button from everything in Retroarch configs and it does not fix it.",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/745015306,[Windows/Bug]Guide/Home button on Xinput controller bug with explorer.exe terminated,hizzlekizzle,5,642902435,4,745015306,0,744728217,2020-12-15T02:43:32Z,This is a related issue: https://github.com/libretro/RetroArch/issues/10855,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/795251849,[Windows/Bug]Guide/Home button on Xinput controller bug with explorer.exe terminated,bslenul,5,642902435,5,795251849,0,745015306,2021-03-10T11:02:02Z,"Any news on this? Looks like it happened to other users with different setups:

* This user had the issue but with a normal button, he apparently had to unbind volume hotkeys (I guess? He never replied): https://www.reddit.com/r/RetroArch/comments/ho10t8/when_i_press_this_specific_button_on_my_arcade/
* This user has the issue when pressing L2+R1: https://www.reddit.com/r/RetroArch/comments/k0jbl2/l2r1_hotkey_exit/
* This one with a P2 button: https://www.reddit.com/r/RetroArch/comments/m1nuo9/weird_behavior_with_p2_arcade_side/
* Someone on Discord had the same issue but WITH explorer.exe running few months ago:

![image](https://user-images.githubusercontent.com/33353403/110619539-3c343a80-8198-11eb-9066-bd1c93114c9d.png)
",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/1008325474,[Windows/Bug]Guide/Home button on Xinput controller bug with explorer.exe terminated,Immersion95,5,642902435,6,1008325474,0,795251849,2022-01-09T16:02:24Z,Any news on that ? This still happens on latest Win 11 x64.,False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/10891,Retroarch deleted saves after update,XKCorp,3,642933508,1,642933508,0,0,2020-06-22T10:03:27Z,"Hello

I have lost my saves and states after updating Retroarch :(

RetroArch: updated from 1.8.8 to 1.8.9

OS: Ubuntu 20.04 64bit

Updated using apt-get update && apt-get upgrade
PPA repo: deb http://ppa.launchpad.net/libretro/stable/ubuntu focal main

Retroarch and Cores configurations are still here.",True,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/647483312,Retroarch deleted saves after update,bslenul,3,642933508,2,647483312,0,642933508,2020-06-22T12:23:37Z,Are you sure it's not just using a different path for your saves folder (and maybe states)? `Settings > Directory > Savefile` to double check.,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/647749524,Retroarch deleted saves after update,cmitu,3,642933508,3,647749524,0,647483312,2020-06-22T20:21:12Z,"The defaults for Linux save paths (states/game) have been changed in 1.8.9 (with [this PR](https://github.com/libretro/RetroArch/pull/10723)). 
As @bslenul said, check if your saves are loaded/saves from/to the right location.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/647856242,Retroarch deleted saves after update,XKCorp,3,642933508,4,647856242,0,647749524,2020-06-23T01:43:33Z,"You are right, before version 1.8.9 Retroarch saved saves/states in the ROM directory by default, they were not deleted when upgrading.
Thank you!",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/10894,Some missing core banners for 3DS,fpscan,5,643211766,1,643211766,0,0,2020-06-22T16:33:26Z,"Let there be something to start with, so that users don't confuse between the same icons or banners. I will make the rest in future. 
![image](https://user-images.githubusercontent.com/4651944/85315279-6e472480-b4c3-11ea-8155-1305d0c9a7d4.png)
",True,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/648008688,Some missing core banners for 3DS,jdgleaver,5,643211766,2,648008688,0,643211766,2020-06-23T08:58:44Z,"@fpscan Thanks for this!  :)

But why did you change the RACE icon...? I feel the old one was more appropriate...",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/648078706,Some missing core banners for 3DS,fpscan,5,643211766,3,648078706,0,648008688,2020-06-23T11:13:51Z,"> @fpscan Thanks for this! :)
> 
> But why did you change the RACE icon...? I feel the old one was more appropriate...

Hey there :) actually I was working on it and I had few more variations but I didn't realized that was in this branch, RACE have it's own logo and banner. Okay I see it now, it was in first commit which I wasn't aimed the `RACE` would you like me to change it back? 

![race](https://user-images.githubusercontent.com/4651944/85397165-c16cb600-b55b-11ea-9872-eee86261fd56.png)
",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/648082978,Some missing core banners for 3DS,jdgleaver,5,643211766,4,648082978,0,648078706,2020-06-23T11:22:06Z,"It's a tough call... On the one hand, I can see the appeal of using official logo images for all the app icons, but on the other hand we already standardised on using controller (or handheld console) images where possible...

I think if we want to use logos, they should all be changed at the same time :)
(and we should maybe ask for feedback on this - a twitter poll or something)

Until then, it might best to use the old RACE icon. Is that okay?",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/648095349,Some missing core banners for 3DS,fpscan,5,643211766,5,648095349,0,648082978,2020-06-23T11:48:55Z,"> It's a tough call... On the one hand, I can see the appeal of using official logo images for all the app icons, but on the other hand we already standardised on using controller (or handheld console) images where possible...
> 
> I think if we want to use logos, they should all be changed at the same time :)
> (and we should maybe ask for feedback on this - a twitter poll or something)
> 
> Until then, it might best to use the old RACE icon. Is that okay?

It's all good, I was just aiming to make quick icons/banners so people won't confuse the cores with no banners/icons :)
https://github.com/libretro/RetroArch/pull/10903",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/648096801,Some missing core banners for 3DS,jdgleaver,5,643211766,6,648096801,0,648095349,2020-06-23T11:52:31Z,"Thanks!

>  I was just aiming to make quick icons/banners so people won't confuse the cores with no banners/icons :)

Yes, absolutely - cores are pretty much unusable on 3DS without proper banners, so your work is very much appreciated :)",False,0,CONTRIBUTOR
https://api.github.com/repos/angular/angular/issues/37949,ci: decrease the minBodyLength commit message limit to 20 chars,IgorMinar,5,651892225,1,651892225,0,0,2020-07-07T00:08:43Z,"The motivation behind this change is to improve the productivity in the angular/angular repo
without sacrificing the original goal of having better understanding of changes within
the repo.

When the minBodyLength limit was originally introduced the goal was simple: force
committers to provide more contextual information for each change coming into the
repo. Too often we found ourselves in a situation where nobody understood what
motivated some of the changes and we needed more contextual info to know if the
change was correct, desirable, and still relevant (at a later point in time).

When the limit was introduced, we needed to pick a minimum body length - given no
data, and frustration with even big changes being committed with just a words in
the subject (along the lines of ""fix(core): fixing a bug""), we overcompensated
and started off with a really high bar of minBodyLength set to 100 chars.

This turned out to be impractical and created a big friction point in making valid
changes in the angular/angular repo, and in fact caused some of the refactorings
and smaller changes to be either skipped or combined into other commits which
increased the burden for code reviewers.

The evidence in the friction points can be seen in the number of PRs that fail to pass
the current lint check on the first try, but more importantly also in the ""creative""
writing that some of the committers are forced to resort to in order to satisfy the
current checks. Examples:

- https://github.com/angular/angular/commit/286fbf42c65a02e6da7420cd19a2c5baff3f2656
- https://github.com/angular/angular/commit/b2816a1536075397d876ba27ce2b7dcd785d4a39

Given that we primarily care to document the motivation behind each change
(the answer to the ultimate question: WHY?), I've collected several *common* &
*valid* commit messages that are minimalistic and capture the WHY sufficiently:

```
Refactoring for readability.  => 28 chars
Improving variable naming.    => 26 chars
Additional test coverage.     => 25 chars
Cleaning up the code.         => 21 chars
Simplifies the code.          => 20 chars
```

These commit message bodies in addition to the commit message subject should
sufficiently satisfy the need to capture the context and motivation behind each
change without creating an undue burden on committers.

Example minimalistic commit message:

```
------

refactor(core): cleanup the expression parser

Simplifies the code.

----
```

Given this research, I'm decreasing the minBodyLenth in angular/angular to 20 chars.

The commit message quality can be additionally improved by implementing a commit message
template via `.gitmessage` that will guide the committers in following our commit message
guidelines via instructions provided in the form of in-the-flow help rather than as an after
the fact lint check.

More info: https://thoughtbot.com/blog/better-commit-messages-with-a-gitmessage-template

I'm intentionally deferring such change for a separate PR as not to complicate or delay the
minBodyLength limit decrease.
",True,0,CONTRIBUTOR
https://api.github.com/repos/angular/angular/issues/comments/655022071,ci: decrease the minBodyLength commit message limit to 20 chars,IgorMinar,5,651892225,2,655022071,0,651892225,2020-07-07T17:47:12Z,@gkalpak you are right as always. 😄 ,False,0,CONTRIBUTOR
https://api.github.com/repos/angular/angular/issues/comments/655187234,ci: decrease the minBodyLength commit message limit to 20 chars,sonukapoor,5,651892225,3,655187234,0,655022071,2020-07-07T23:16:21Z,"@IgorMinar Thank you. I always had trouble coming up with 100 chars for the commit message when making minor fixes. 

@gkalpak I can make the change in the commit guidelines. ",False,0,CONTRIBUTOR
https://api.github.com/repos/angular/angular/issues/comments/655340359,ci: decrease the minBodyLength commit message limit to 20 chars,gkalpak,5,651892225,4,655340359,0,655187234,2020-07-08T07:26:54Z,"Thx for offering, @sonukapoor. @IgorMinar has already taken care of it :wink:

_EDIT: I now realize the guidelines update is on a different PR, so putting it here for reference: #37951_",False,0,MEMBER
https://api.github.com/repos/angular/angular/issues/comments/655735978,ci: decrease the minBodyLength commit message limit to 20 chars,IgorMinar,5,651892225,5,655735978,0,655340359,2020-07-08T20:21:19Z,"@sonukapoor thanks for offering, but as @gkalpak I updated the guidelines in #37951 - it's not ideal that the change is in a different PR but I didn't want to deal with merge conflicts between the two PRs.",False,0,CONTRIBUTOR
https://api.github.com/repos/angular/angular/issues/comments/670946436,ci: decrease the minBodyLength commit message limit to 20 chars,angular-automatic-lock-bot[bot],5,651892225,6,670946436,0,655735978,2020-08-08T16:15:48Z,"This issue has been automatically locked due to inactivity.
Please file a new issue if you are encountering a similar or related problem.

Read more about our [automatic conversation locking policy](https://github.com/angular/angular/blob/67d80f/docs/GITHUB_PROCESS.md#conversation-locking).

<sub>_This action has been performed automatically by a bot._</sub>",False,0,NONE
https://api.github.com/repos/angular/angular/issues/37950,docs: Generalize the data transformation of pipes,KingMario,4,651917272,1,651917272,0,0,2020-07-07T01:19:54Z,"## PR Checklist
Please check if your PR fulfills the following requirements:

- [x] The commit message follows our guidelines: https://github.com/angular/angular/blob/master/CONTRIBUTING.md#commit
- [ ] Tests for the changes have been added (for bug fixes / features)
- [x] Docs have been added / updated (for bug fixes / features)


## PR Type
What kind of change does this PR introduce?

<!-- Please check the one that applies to this PR using ""x"". -->

- [ ] Bugfix
- [ ] Feature
- [ ] Code style update (formatting, local variables)
- [ ] Refactoring (no functional changes, no api changes)
- [ ] Build related changes
- [ ] CI related changes
- [x] Documentation content changes
- [ ] angular.io application / infrastructure changes
- [ ] Other... Please describe:


## What is the current behavior?
<!-- Please describe the current behavior that you are modifying, or link to a relevant issue. -->

The current description of pipes is too specific about data formating which may cause some misunderstanding of the purpose and usage of pipes.

Issue Number: N/A


## What is the new behavior?

Make it more generalized about the transformation that the pipes do. Give another example of transformation.

## Does this PR introduce a breaking change?

- [ ] Yes
- [x] No


<!-- If this PR contains a breaking change, please describe the impact and migration path for existing applications below. -->


## Other information
",True,0,CONTRIBUTOR
https://api.github.com/repos/angular/angular/issues/comments/654545613,docs: Generalize the data transformation of pipes,KingMario,4,651917272,2,654545613,0,651917272,2020-07-07T01:28:29Z,"PS: in a code review for a pipe of a form control checking, my peer argued that a pipe should only format the data as described in this doc.

```
@Pipe({
  name: 'touchedAndInvalid',
  pure: false,
})
export class TouchedAndInvalidPipe implements PipeTransform {
  transform(control: FormControl): boolean {
    return !!control && control.touched && control.invalid;
  }
}
```

You may notice how crazy it is if you have to put `controlA.touched && controlA.invalid`, `controlB.touched && controlB.invalid` in every template expression. Declaring a method in every component is still nasty. Even worse, the controls might be in form of `myFormGroup.get('controlA')`.

I think, as described in the doc of Version 8, the essential of a pipe is `You may notice that you desire many of the same transformations repeatedly, both within and across many applications.` https://github.com/angular/angular.io/blob/master/public/docs/ts/latest/guide/pipes.jade#L14

That's why I make this PR and want it to be merged.

Correct me if I am wrong.

Thanks.",False,0,CONTRIBUTOR
https://api.github.com/repos/angular/angular/issues/comments/664072836,docs: Generalize the data transformation of pipes,KingMario,4,651917272,3,664072836,0,654545613,2020-07-27T01:27:45Z,"Thanks @kapunahelewong 

The commit is rebased and squashed. And thanks for the commit message. I'm using it.

Thanks.
",False,0,CONTRIBUTOR
https://api.github.com/repos/angular/angular/issues/comments/664558719,docs: Generalize the data transformation of pipes,AndrewKushnir,4,651917272,4,664558719,0,664072836,2020-07-27T18:18:36Z,"Hi @KingMario, thanks for contributing to Angular! Your PR is now merged and the changes are propagated to angular.io website. You can see the updated page at https://angular.io/guide/pipes (if you don't see the change, please clear the cache of the browser). Thank you.",False,0,CONTRIBUTOR
https://api.github.com/repos/angular/angular/issues/comments/682049913,docs: Generalize the data transformation of pipes,angular-automatic-lock-bot[bot],4,651917272,5,682049913,0,664558719,2020-08-27T16:18:18Z,"This issue has been automatically locked due to inactivity.
Please file a new issue if you are encountering a similar or related problem.

Read more about our [automatic conversation locking policy](https://github.com/angular/angular/blob/67d80f/docs/GITHUB_PROCESS.md#conversation-locking).

<sub>_This action has been performed automatically by a bot._</sub>",False,0,NONE
https://api.github.com/repos/angular/angular/issues/37951,Create shared .gitconfig and .gitmessage with commit message template,IgorMinar,7,651934683,1,651934683,0,0,2020-07-07T02:08:11Z,See individual commits for info.,True,0,CONTRIBUTOR
https://api.github.com/repos/angular/angular/issues/comments/654912449,Create shared .gitconfig and .gitmessage with commit message template,IgorMinar,7,651934683,2,654912449,0,651934683,2020-07-07T14:42:33Z,"@gkalpak which part didn't work on windows? The shared gitconfig or the template?

Both should work on windows as far as I know.",False,0,CONTRIBUTOR
https://api.github.com/repos/angular/angular/issues/comments/654928226,Create shared .gitconfig and .gitmessage with commit message template,gkalpak,7,651934683,3,654928226,0,654912449,2020-07-07T15:06:08Z,I couldn't get the message template to work 😞,False,0,MEMBER
https://api.github.com/repos/angular/angular/issues/comments/654941112,Create shared .gitconfig and .gitmessage with commit message template,gkalpak,7,651934683,4,654941112,0,654928226,2020-07-07T15:26:20Z,"NVM, I tried it again and now it worked fine. Not sure what I did wrong before. Sorry for the noise 😇 ",False,0,MEMBER
https://api.github.com/repos/angular/angular/issues/comments/655106942,Create shared .gitconfig and .gitmessage with commit message template,IgorMinar,7,651934683,5,655106942,0,654941112,2020-07-07T20:18:46Z,I pushed a bunch more changes. I linked the template to the commit message docs on github and updated them so that the github version is a strict superset of the version in the template that is a bit more succinct. ,False,0,CONTRIBUTOR
https://api.github.com/repos/angular/angular/issues/comments/655154817,Create shared .gitconfig and .gitmessage with commit message template,jelbourn,7,651934683,6,655154817,0,655106942,2020-07-07T21:51:03Z,Adding @aikidave for contributing guide changes,False,0,MEMBER
https://api.github.com/repos/angular/angular/issues/comments/656339955,Create shared .gitconfig and .gitmessage with commit message template,IgorMinar,7,651934683,7,656339955,0,655154817,2020-07-09T20:39:27Z,@aikidave I incorporated all of your changes in the last fixup commit. thanks for the review. PTAL.,False,0,CONTRIBUTOR
https://api.github.com/repos/angular/angular/issues/comments/673571568,Create shared .gitconfig and .gitmessage with commit message template,angular-automatic-lock-bot[bot],7,651934683,8,673571568,0,656339955,2020-08-13T16:16:29Z,"This issue has been automatically locked due to inactivity.
Please file a new issue if you are encountering a similar or related problem.

Read more about our [automatic conversation locking policy](https://github.com/angular/angular/blob/67d80f/docs/GITHUB_PROCESS.md#conversation-locking).

<sub>_This action has been performed automatically by a bot._</sub>",False,0,NONE
https://api.github.com/repos/angular/angular/issues/37952,Components with non-empty HTML input field not released in memory,capc0,11,652067429,1,652067429,0,0,2020-07-07T07:17:41Z,"<!--🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅

Oh hi there! 😄

To expedite issue processing please search open and closed issues before submitting a new one.
Existing issues often contain information about workarounds, resolution, or progress updates.

🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅🔅-->


# 🐞 bug report

### Affected Package
<!-- Can you pin-point one or more @angular/* packages as the source of the bug? -->
<!-- ✍️edit: --> The issue is caused by package @angular/core or forms?


### Is this a regression?

<!-- Did this behavior use to work in the previous version? -->
<!-- ✍️--> unsure


### Description

<!-- ✍️--> If I have an app with 2 pages and routing between them, the components on each page would normally be destroyed when routing between the pages. If a page has an input with [(ngModel)] binding however, the page/component will still call ngOnDestroy but will not be released from memory (see chrome dev tools)


## 🔬 Minimal Reproduction
<!--
Please create and share minimal reproduction of the issue starting with this template: https://stackblitz.com/fork/angular-ivy
-->

https://stackblitz.com/edit/angular-b5sb94

Enter something in the input field -> route to page 2 -> route back -> Page1Component will be 2x in the memory

![image](https://user-images.githubusercontent.com/27284008/86734721-80cc6c80-c032-11ea-8dcd-ebb1ccf0d02a.png)


<!--
If StackBlitz is not suitable for reproduction of your issue, please create a minimal GitHub repository with the reproduction of the issue.
A good way to make a minimal reproduction is to create a new app via `ng new repro-app` and add the minimum possible code to show the problem.
Share the link to the repo below along with step-by-step instructions to reproduce the problem, as well as expected and actual behavior.

Issues that don't have enough info and can't be reproduced will be closed.

You can read more about issue submission guidelines here: https://github.com/angular/angular/blob/master/CONTRIBUTING.md#-submitting-an-issue
-->

## 🔥 Exception or Error

n/a

## 🌍  Your Environment

**Angular Version:**
<pre><code>
10
</code></pre>

**Anything else relevant?**
n/a",True,0,NONE
https://api.github.com/repos/angular/angular/issues/comments/654844630,Components with non-empty HTML input field not released in memory,pkozlowski-opensource,11,652067429,2,654844630,0,652067429,2020-07-07T13:07:53Z,"@capc0 thnx for reporting, this is a valid issue! In fact, there are 2 separate issues here:
* dev mode only, already tracked in #35164 
* the issue you've mentioned, specific to the interaction with an input field.

What is interesting here is that `ShadowRoot` shows up as one of the retainers - since none of the components in your app is using shadow DOM encapsulation I would expect that this is the native input's implementation that acts funky here. Still, it is not clear to me if this is a bug in a browser or something specific that we do in the framework.

In any case this is a valid bug report and it needs more investigation to diagnose the root cause.",False,0,MEMBER
https://api.github.com/repos/angular/angular/issues/comments/657374523,Components with non-empty HTML input field not released in memory,capc0,11,652067429,3,657374523,0,654844630,2020-07-13T05:55:04Z,"Actually the model binding is not the cause.

Any HTML input field with a value is enough for the memory leak.

New minimal reproduction: https://stackblitz.com/edit/angular-y7wbvv
",False,0,NONE
https://api.github.com/repos/angular/angular/issues/comments/660061866,Components with non-empty HTML input field not released in memory,capc0,11,652067429,4,660061866,0,657374523,2020-07-17T11:42:54Z,"this should be high prio IMO, since all angular apps will leak large amounts of memory and perform very poorly after some hours of usage. Almost all components have this problem.
",False,0,NONE
https://api.github.com/repos/angular/angular/issues/comments/661840756,Components with non-empty HTML input field not released in memory,beniaminp,11,652067429,5,661840756,0,660061866,2020-07-21T12:51:29Z,"Hi! we also have this problem. We noticed the same problem also with HtmlTextArea. It is a huge problem for us because after about an hour our application almost freeze and we cannot deliver to our clients a new release.
What we noticed is that if any HTML input field is completed, the angular component that holds the input is never destroyed resulting a big junk. We did our tests with production mode on. It is reproducing also on angular 9.x.
I also think that this should be a very high priority issue.

Thanks!",False,0,NONE
https://api.github.com/repos/angular/angular/issues/comments/668571450,Components with non-empty HTML input field not released in memory,capc0,11,652067429,6,668571450,0,661840756,2020-08-04T12:38:47Z,seems to be related to ivy. with ```enableIvy``` set to ```false``` the components are destroyed normally,False,0,NONE
https://api.github.com/repos/angular/angular/issues/comments/675924027,Components with non-empty HTML input field not released in memory,rekna1,11,652067429,7,675924027,0,668571450,2020-08-19T08:13:02Z,"For me it's not related to input elements : I encountered the problem when I was testing the behaviour of providers property of a component decorator to provide service only to component and its children. When I navigate away from this component, and take a memory snapshot, the component and service are still in memory. (even though I see ngDestroy is called on both service and component).

When navigating several times to and away from this component, only one instance of the component and one instance of the service remains in memory (the last activated component and its service). But still if this services would hold large amounts of data it would be a huge memory leak. 

In my test the component and service don't contain anything (e.g. no observables or other references)",False,0,NONE
https://api.github.com/repos/angular/angular/issues/comments/695322998,Components with non-empty HTML input field not released in memory,nartc,11,652067429,8,695322998,0,675924027,2020-09-19T16:16:16Z,"I believe I just ran into this same issue. Here's the sample repro: https://github.com/nartc/demo-angular-memory-profile

There are two cases (screenshots) that demonstrate this memory issue:

![image](https://user-images.githubusercontent.com/25516557/93671531-6585d080-fa69-11ea-92be-2b32a79f2e8d.png)
![image](https://user-images.githubusercontent.com/25516557/93671533-69b1ee00-fa69-11ea-84d2-b597c68b4154.png)

- The currentPage input was initially a `[(ngModel)]` then I changed to `[value]` and `(input)` just to see if there's any difference. No difference at all. 
- `ngOnDestroy` in ListItemComponent is being called correctly for each item.

Not sure if this is entirely related because the memory issue does not exist if the input isn't used at all. 

PS: I also forgot to mention that the leaked seems to be garbage collected after doing another round of Navigation without changing `currentPage`",False,0,CONTRIBUTOR
https://api.github.com/repos/angular/angular/issues/comments/707372037,Components with non-empty HTML input field not released in memory,jelbourn,11,652067429,9,707372037,0,695322998,2020-10-12T22:14:37Z,Duplicate of #20007,False,0,MEMBER
https://api.github.com/repos/angular/angular/issues/comments/707497695,Components with non-empty HTML input field not released in memory,beniaminp,11,652067429,10,707497695,0,707372037,2020-10-13T05:28:23Z,"@jelbourn, it does not look like a duplicate for me. I do not need to use a FormControlName to reproduce the memory leak.
There is no resolution for this bug yet?
Thanks!",False,0,NONE
https://api.github.com/repos/angular/angular/issues/comments/718099777,Components with non-empty HTML input field not released in memory,jelbourn,11,652067429,11,718099777,0,707497695,2020-10-28T17:42:46Z,I marked as a duplicate because we believe it's the same underlying cause,False,0,MEMBER
https://api.github.com/repos/angular/angular/issues/comments/735252443,Components with non-empty HTML input field not released in memory,angular-automatic-lock-bot[bot],11,652067429,12,735252443,0,718099777,2020-11-28T16:28:41Z,"This issue has been automatically locked due to inactivity.
Please file a new issue if you are encountering a similar or related problem.

Read more about our [automatic conversation locking policy](https://github.com/angular/angular/blob/8f24bc9443b3872fe095d9f7f77b308a361a13b4/docs/GITHUB_PROCESS.md#conversation-locking).

<sub>_This action has been performed automatically by a bot._</sub>",False,0,NONE
https://api.github.com/repos/sinonjs/sinon/issues/2260,docs(fake-timers): rename lolex to FakeTimers,munierujp,3,624330459,1,624330459,0,0,2020-05-25T14:21:17Z,"#### Purpose (TL;DR) - mandatory
rename `lolex` to `FakeTimers` on Fake timers' ducument

#### Background (Problem in detail)  - optional
- `lolex` package has renamed to `@sinonjs/fake-timers` after v6.0.0. [^1]
- sinon is using [@sinonjs/fake-timers](https://www.npmjs.com/package/@sinonjs/fake-timers) after v9.0.0. [^2]

#### How to verify - mandatory
1. Check out this branch
2. `npm install`
3. `npm run serve-docs`
4. Open Fake timers' ducument on http://localhost:4000/
    - http://localhost:4000/releases/v9.0.0/fake-timers/
    - http://localhost:4000/releases/v9.0.1/fake-timers/
    - http://localhost:4000/releases/v9.0.2/fake-timers/
    - http://localhost:4000/releases/latest/fake-timers/

#### Checklist for author
- [x] `npm run lint` passes
- [x] References to standard library functions are [cached](https://github.com/sinonjs/sinon/pull/1523).

[^1]: https://github.com/sinonjs/fake-timers/blob/master/CHANGELOG.md#600--2020-02-04
[^2]: https://github.com/sinonjs/sinon/commit/10a9182bfe27b357460e80089f0539091ab1c16e",True,0,CONTRIBUTOR
https://api.github.com/repos/sinonjs/sinon/issues/comments/663808664,docs(fake-timers): rename lolex to FakeTimers,stale[bot],3,624330459,2,663808664,0,624330459,2020-07-25T04:46:24Z,"This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.
",False,0,NONE
https://api.github.com/repos/sinonjs/sinon/issues/comments/663815795,docs(fake-timers): rename lolex to FakeTimers,munierujp,3,624330459,3,663815795,0,663808664,2020-07-25T06:10:29Z,Would anyone please review?,False,0,CONTRIBUTOR
https://api.github.com/repos/sinonjs/sinon/issues/comments/664486668,docs(fake-timers): rename lolex to FakeTimers,mroderick,3,624330459,4,664486668,0,663815795,2020-07-27T16:03:36Z,"Great PR, thank you for your contribution to Sinon! We ❤️ documentation updates!

Due to an outdated publishing process, the documentation site won't actually display the changes until a new version of Sinon is published to NPM. Thank you for your patience.",False,0,MEMBER
https://api.github.com/repos/sinonjs/sinon/issues/2261,[ASK] Can I stub multiple method in the same class/object?,ibnukipa,3,625917782,1,625917782,0,0,2020-05-27T18:10:31Z,"* Sinon version : _latest_
* Environment   : MacOS
* Example URL   : -
* Other libraries you are using: mocha

_EXAMPLE_
![image](https://i.imgur.com/lHyu7Sb.png)

**What did you expect to happen?**
Stub another method in the same class/object should be possible.
e.g line 36,37,38,39 should be work.

**What actually happens**
Stub another method is not working. The instance calling the original method.
e.g line 36 and 38 that only calling the stub method. line 37 and 39 are calling the original method
",True,0,NONE
https://api.github.com/repos/sinonjs/sinon/issues/comments/635156100,[ASK] Can I stub multiple method in the same class/object?,mantoni,3,625917782,2,635156100,0,625917782,2020-05-28T07:15:44Z,"Sinon `does` support stubbing multiple methods on an object. Consider this example:

```js
const sinon = require('sinon');

const object = {
  foo: function () { console.log('foo'); },
  bar: function () { console.log('bar'); }
};

sinon.stub(object, 'foo');
sinon.stub(object, 'bar');

object.foo();
object.bar();
```

Running this does neither print ""foo"" nor ""bar"". I'm pretty sure there is something else going on that cannot be seen just from your example. Maybe the services are classes? You would need to stub the function on the prototype in that case. E.g. `sinon.stub(fileService.prototype, 'deleteFile')`, but that is just a guess.

---

We are trying to keep the GitHub issues list tidy and focused on bugs and feature discussions. This ticket looks like a usage question, please post it to the [`sinon` tag on Stack Overflow](https://stackoverflow.com/questions/tagged/sinon), so the bigger community can help answer your questions.

If you feel that your topic is an issue with Sinon.JS, please open a new ticket and follow the [guidelines for reporting an issue](https://github.com/sinonjs/sinon/blob/master/CONTRIBUTING.md#reporting-an-issue).",False,0,MEMBER
https://api.github.com/repos/sinonjs/sinon/issues/comments/635376012,[ASK] Can I stub multiple method in the same class/object?,ibnukipa,3,625917782,3,635376012,0,635156100,2020-05-28T14:13:33Z,"Hi @mantoni thanks for the response.

yes, I'm stubbing the class method. I'm sure that the `fileService` and `notificationService` are a class prototype.

what I'm wondering is the first stub method is working but the second is not, why?",False,0,NONE
https://api.github.com/repos/sinonjs/sinon/issues/comments/635706876,[ASK] Can I stub multiple method in the same class/object?,ibnukipa,3,625917782,4,635706876,0,635376012,2020-05-29T01:38:54Z,"@mantoni I think I capture the problem, do you mind to check it out here https://stackoverflow.com/questions/62077267/sinonjs-stub-is-not-working-with-on-listener",False,0,NONE
https://api.github.com/repos/sinonjs/sinon/issues/2262,Spy does not show an exception was thrown,suityou01,10,626502695,1,626502695,0,0,2020-05-28T13:19:39Z,"**Describe the bug**
I am spying on a function that throws a TypeError. When I assert that the spy threw anything at all it tells me that the spy did not throw any exception. This is patently untrue as evidence by the fact that the catch block handles the exception.

On a side note, I have spent a few hours hunting down code examples of what should be a common use case for this library and I cannot find something that is both ""descriptive"" and ""demonstrative"".

A 50$ code example would really really help.

**To Reproduce**
```
it('throws an exception and logs to exceptions file when connection is not available', async () => {
    const mockConnection = {}; //This means the connection object is not available
    const fs = new FormService(mockConnection);
    const form = {};
    let spy = sinon.spy(fs,'addForm'); //This is the function I wish to spy on
    sinon.replace(logger,'error',sinon.fake()); //This works just fine

    try {
        const uid = await fs.addForm(form);
    }
    catch(e)
    {
        console.log(e); //This catch block fires
    }
    sinon.assert.calledOnce(logger.error); //This works just fine
    console.log(spy.threw()); //This returns false! This is a lie
});
```
**Expected behavior**
The spy.threw() method returns true to reflect that actual truth.

**Context (please complete the following information):**

* Library version: ^9.0.2
* Environment: Linux, node 14
* Other libraries you are using: Mocha

",True,0,NONE
https://api.github.com/repos/sinonjs/sinon/issues/comments/635363787,Spy does not show an exception was thrown,mantoni,10,626502695,2,635363787,0,626502695,2020-05-28T13:52:36Z,"Can you post a runnable example of the issue? I tried to reproduce like this, but it prints `true`, as expected:

```js
const sinon = require('sinon');

const object = {
  test: function () {
    throw new TypeError();
  }
};

sinon.spy(object, 'test');

try {
  object.test();
} catch(e) {
}

console.log(object.test.threw());
```",False,0,MEMBER
https://api.github.com/repos/sinonjs/sinon/issues/comments/635365501,Spy does not show an exception was thrown,mantoni,10,626502695,3,635365501,0,635363787,2020-05-28T13:55:31Z,"Ah, I see now. You're using `await`, so `fs.addForm` doesn't throw, it returns a promise that gets rejected.",False,0,MEMBER
https://api.github.com/repos/sinonjs/sinon/issues/comments/635368545,Spy does not show an exception was thrown,suityou01,10,626502695,4,635368545,0,635365501,2020-05-28T14:00:40Z,"Give me a chance to answer before closing the question would you?

```
function bang(msg){
    throw new TypeError(msg);
}
```

```
let spy = sinon.spy(bang);
    try{
        bang('Yeehaw!');
    } catch(e) {
        console.log(`The exception fired ${e}`);
    }
    console.log(spy.threw());
```

This prints out false",False,0,NONE
https://api.github.com/repos/sinonjs/sinon/issues/comments/635369242,Spy does not show an exception was thrown,suityou01,10,626502695,5,635369242,0,635368545,2020-05-28T14:01:51Z,And yes it does throw as my catch block catches it (see OP)... ,False,0,NONE
https://api.github.com/repos/sinonjs/sinon/issues/comments/635370557,Spy does not show an exception was thrown,mantoni,10,626502695,6,635370557,0,635369242,2020-05-28T14:04:12Z,"Yes, now you're calling the original function and not through the spy. Obviously it's throwing, and yes, `spy.threw()` returns `false` because the spy wasn't even called.",False,0,MEMBER
https://api.github.com/repos/sinonjs/sinon/issues/comments/635372061,Spy does not show an exception was thrown,suityou01,10,626502695,7,635372061,0,635370557,2020-05-28T14:06:54Z,"Slow down, take a minute and put yourself in my shoes.

Your documentation sucks. 
You asked me to post an example after I already did.
Before I can, you close my ticket. Literally seconds after your posted the request you closed the ticket. This is not in the spirit of the game and is extremely poor form.
You didn't read my question properly.
You answer me in answers that are too short to mean anything.

PLEASE

Post a detailed example that shows me what the actual F you are talking about.

Thanks",False,0,NONE
https://api.github.com/repos/sinonjs/sinon/issues/comments/635374060,Spy does not show an exception was thrown,suityou01,10,626502695,8,635374060,0,635372061,2020-05-28T14:10:18Z,"Please also explain how your example goes ""through the spy""

```sinon.spy(object, 'test');```

```object.test();```

??",False,0,NONE
https://api.github.com/repos/sinonjs/sinon/issues/comments/635375377,Spy does not show an exception was thrown,mantoni,10,626502695,9,635375377,0,635374060,2020-05-28T14:12:34Z,"The only thing you're achiving with attacking me is that I regret trying to be helpful. If our documentation sucks, you're welcome to help improving it.",False,0,MEMBER
https://api.github.com/repos/sinonjs/sinon/issues/comments/635377248,Spy does not show an exception was thrown,suityou01,10,626502695,10,635377248,0,635375377,2020-05-28T14:15:48Z,"Don't behave in a way that is likely to cause upset and offence and waste the time of others. 

Sent from Yahoo Mail on Android 
 
  On Thu, 28 May 2020 at 15:12, Maximilian Antoni<notifications@github.com> wrote:   


The only thing you're achiving with attacking me is that I regret trying to be helpful. If our documentation sucks, you're welcome to help improving it.

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub, or unsubscribe.
  
",False,0,NONE
https://api.github.com/repos/sinonjs/sinon/issues/comments/635383345,Spy does not show an exception was thrown,mantoni,10,626502695,11,635383345,0,635377248,2020-05-28T14:26:30Z,"I showed you an example that proves that there is no issue with Sinon. I also explained to you what your actual issue is. I don't see why I shouldn't close this. There is a ""reopen"" feature that I'm happily utilizing if my assesment was wrong. If you're offended by that, I'm sorry. We can still have a discussion around your problem on a closed issue, but there is no issue with the library, therefore I closed.",False,0,MEMBER
https://api.github.com/repos/sinonjs/sinon/issues/2266,"stub readonly property throw ""Cannot stub non-existent property""",ljian3377,6,631493258,1,631493258,0,0,2020-06-05T10:40:47Z,"**Describe the bug**
* Library version: 9.0.2

**To Reproduce**
```
import * as sinon from ""sinon"";
class B {
    public readonly a: string;
    public get(): void {}
}

const bStub = sinon.createStubInstance(B);
sinon.stub(bStub , ""a"").value(""test"");

// let b = new B();
// sinon.stub(b, ""a"").value(""test"");
```
**Expected behavior**
stub properly.

There is an old issue mentioning the same issue but is closed with a comment that is not quite helpful for me. https://github.com/sinonjs/sinon/issues/829",True,0,NONE
https://api.github.com/repos/sinonjs/sinon/issues/comments/639409565,"stub readonly property throw ""Cannot stub non-existent property""",ljian3377,6,631493258,2,639409565,0,631493258,2020-06-05T10:56:39Z,"However, assigning value beforehand to the property, then the stub will work. But I really don't want to invoke the constructor as it's prettty complicated.

```
import * as sinon from ""sinon"";

class B {
    public readonly a: string;
    public get(): void {}
    constructor(aa: string) {
        this.a = aa;
    }
}

// const bStub = sinon.createStubInstance(B);
let b = new B(""t"");
sinon.stub(b, ""a"").value(""test"");
console.log(b.a);
```
output: test",False,0,NONE
https://api.github.com/repos/sinonjs/sinon/issues/comments/639412186,"stub readonly property throw ""Cannot stub non-existent property""",ljian3377,6,631493258,3,639412186,0,639409565,2020-06-05T11:02:30Z,"Currently working around with directly assigning to the stub object.
```
import * as sinon from ""sinon"";

class B {
    public readonly a: string;
    public get(): void {}
    constructor(aa: string) {
        this.a = aa;
    }
}

const bStub = sinon.createStubInstance(B);
(bStub as any).a = ""test"";
console.log(b.a);
```
output: test",False,0,NONE
https://api.github.com/repos/sinonjs/sinon/issues/comments/662141503,"stub readonly property throw ""Cannot stub non-existent property""",mroderick,6,631493258,4,662141503,0,639412186,2020-07-21T22:35:14Z,"We have made conscious decision to not allow stubbing non-existent properties, as that would make for some very confusing scenarios.

The submitted code doesn't look like JavaScript to me, I don't know how to run it.

Please create a new issue and fill in the template to save everyone some time.",False,0,MEMBER
https://api.github.com/repos/sinonjs/sinon/issues/comments/1674607057,"stub readonly property throw ""Cannot stub non-existent property""",gukoff,6,631493258,5,1674607057,0,662141503,2023-08-11T11:38:27Z,"> We have made conscious decision to not allow stubbing non-existent properties, as that would make for some very confusing scenarios.

What are the confusing scenarios?
Would it help to add this functionality behind a flag `stub(obj, 'propertyName', forceIfNonExistent=true)` to make sure the user knows what they are doing?",False,0,CONTRIBUTOR
https://api.github.com/repos/sinonjs/sinon/issues/comments/1674668313,"stub readonly property throw ""Cannot stub non-existent property""",fatso83,6,631493258,6,1674668313,0,1674607057,2023-08-11T12:19:21Z,"@gukoff You can end up spending a lot of time barking up the wrong tree when you stub something that is never supposed to exist. It could be you stubbed the wrong thing, the wrong way or misspelled the property. Better safe than sorry. That is why we would much rather have an explicit call that tells your _intent_ is to define a property that does not currently exist. The API we have talked about looks like `sinon.define(obj, prop, fake)` ([you can read more in that issue about this, might find it interesting from the history](https://github.com/sinonjs/sinon/issues/2195#issuecomment-625123599)), but someone needs to do the (arguably quite minimal) work. That would also go hand-in-hand with `sinon.replace*`.

The scenario above is about an object mutating itself. The changes are not persistent on any prototype and you do not need to clean it up afterwards. If you choose to construct an object without invoking its constructor, there's no big reason to not do the assignment directly, as he did, as you are already responsible for doing the construction yourself.",False,0,CONTRIBUTOR
https://api.github.com/repos/sinonjs/sinon/issues/comments/1675087265,"stub readonly property throw ""Cannot stub non-existent property""",gukoff,6,631493258,7,1675087265,0,1674668313,2023-08-11T16:50:54Z,"@fatso83 I see, thanks. Could you take a look if this is someting you're looking for? 
https://github.com/sinonjs/sinon/pull/2539

If yes, I could finish this PR next week.
",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/74988,[stable] Update to 1.45.2,Mark-Simulacrum,4,670181111,1,670181111,0,0,2020-07-31T20:11:30Z,"This just bumps the release number, which I forgot to do in the previous PR (#74958).

r? @ghost",True,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/667333173,[stable] Update to 1.45.2,Mark-Simulacrum,4,670181111,2,667333173,0,670181111,2020-07-31T20:11:49Z,@bors r+ rollup=never p=100,False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/667333204,[stable] Update to 1.45.2,bors,4,670181111,3,667333204,0,667333173,2020-07-31T20:11:50Z,":pushpin: Commit 77e9ebb5f4aab9a4e1135dd39c746403c666cfb4 has been approved by `Mark-Simulacrum`

<!-- @bors r=Mark-Simulacrum 77e9ebb5f4aab9a4e1135dd39c746403c666cfb4 -->
<!-- homu: {""type"":""Approved"",""sha"":""77e9ebb5f4aab9a4e1135dd39c746403c666cfb4"",""approver"":""Mark-Simulacrum""} -->",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/667336565,[stable] Update to 1.45.2,bors,4,670181111,4,667336565,0,667333204,2020-07-31T20:14:14Z,":hourglass: Testing commit 77e9ebb5f4aab9a4e1135dd39c746403c666cfb4 with merge d3fb005a39e62501b8b0b356166e515ae24e2e54...
<!-- homu: {""type"":""BuildStarted"",""head_sha"":""77e9ebb5f4aab9a4e1135dd39c746403c666cfb4"",""merge_sha"":""d3fb005a39e62501b8b0b356166e515ae24e2e54""} -->",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/667430427,[stable] Update to 1.45.2,bors,4,670181111,5,667430427,0,667336565,2020-07-31T23:52:34Z,":sunny: Test successful - [checks-actions](https://github.com/rust-lang-ci/rust/runs/933781004), [checks-azure](https://dev.azure.com/rust-lang/e71b0ddf-dd27-435a-873c-e30f86eea377/_build/results?buildId=35718)
Approved by: Mark-Simulacrum
Pushing d3fb005a39e62501b8b0b356166e515ae24e2e54 to stable...
<!-- homu: {""type"":""BuildCompleted"",""approved_by"":""Mark-Simulacrum"",""base_ref"":""stable"",""builders"":{""checks-azure"":""https://dev.azure.com/rust-lang/e71b0ddf-dd27-435a-873c-e30f86eea377/_build/results?buildId=35718"",""checks-actions"":""https://github.com/rust-lang-ci/rust/runs/933781004""},""merge_sha"":""d3fb005a39e62501b8b0b356166e515ae24e2e54""} -->",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/74989,Implement `Index` and `IndexMut` for arrays,pubfnbar,28,670198245,1,670198245,0,0,2020-07-31T20:30:42Z,"Adds implementations of `Index` and `IndexMut` for arrays that simply forward to the slice indexing implementation in order to fix the following problem:

If you implement `Index<MyIndexType>` for an array, you lose all the other indexing functionality that used to be available to the array via its implicit coercion to a slice. An example of what I'm talking about:
```rust
use std::ops::Index;

pub enum MyIndexType {
    _0, _1, _2, _3, _4, _5, _6, _7,
}

impl<T> Index<MyIndexType> for [T; 8] {
    type Output = T;

    fn index(&self, index: MyIndexType) -> &T {
        unsafe { self.get_unchecked(index as usize) }
    }
}

fn main() {
    let array = [11u8; 8];

    println!(""{:?}"", array[MyIndexType::_0]); // OK
    
    println!(""{:?}"", array[0usize]); // error[E0277]
    //               ^^^^^^^^^^^^^ `[u8; 8]` cannot be indexed by `usize`
}
```
",True,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/667343780,Implement `Index` and `IndexMut` for arrays,rust-highfive,28,670198245,2,667343780,0,670198245,2020-07-31T20:30:45Z,"Thanks for the pull request, and welcome! The Rust team is excited to review your changes, and you should hear from @hanna-kruppe (or someone else) soon.

If any changes to this PR are deemed necessary, please add them as extra commits. This ensures that the reviewer can see what has changed since they last reviewed the code. Due to the way GitHub handles out-of-date commits, this should also make it reasonably obvious what issues have or haven't been addressed. Large or tricky changes may require several passes of review and changes.

Please see [the contribution instructions](https://rustc-dev-guide.rust-lang.org/contributing.html) for more information.
",False,0,COLLABORATOR
https://api.github.com/repos/rust-lang/rust/issues/comments/667421806,Implement `Index` and `IndexMut` for arrays,scottmcm,28,670198245,3,667421806,0,667343780,2020-07-31T23:11:11Z,"You have some PR errors:
```rust
error: implementation has missing stability attribute
   --> library/core/src/array/mod.rs:201:1
    |
201 | / impl<T, I, const N: usize> Index<I> for [T; N]
202 | | where
203 | |     I: SliceIndex<[T]>,
204 | | {
...   |
212 | |     }
213 | | }
    | |_^

error: implementation has missing stability attribute
   --> library/core/src/array/mod.rs:215:1
    |
215 | / impl<T, I, const N: usize> IndexMut<I> for [T; N]
```

You'll need to add something like this to them:
```rust
#[stable(feature = ""index_trait_on_arrays"", since = ""1.47"")]
```
(Trait impls are insta-stable, hence the needs-fcp label and the attribute not being `unstable`, and [1.47 is the current nightly](https://forge.rust-lang.org/))",False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/667536735,Implement `Index` and `IndexMut` for arrays,pubfnbar,28,670198245,4,667536735,0,667421806,2020-08-01T14:01:33Z,"Just to speculate a bit... If it becomes possible to use generic parameters in evaluating constant expressions, and if a `BoundedUsize` type (that wraps a bounded `usize` value) is added to the standard library and we want to be able to use it to index (large enough) arrays without bounds checking, it might look something like this:
```rust
pub struct Predicate<const P: bool>;

pub trait Satisfied {}

impl Satisfied for Predicate<true> {}

// Guarantees that if `x` is a `BoundedUsize<A, B>` value, then `x.0 >= A && x.0 <= B && A <= B`
pub struct BoundedUsize<const A: usize, const B: usize>(usize)
where Predicate<{ A <= B }>: Satisfied;

impl<T, const N: usize, const A: usize, const B: usize> Index<BoundedUsize<A, B>> for [T; N]
where Predicate<{ A <= B && B < N }>: Satisfied
{
    type Output = T;

    fn index(&self, index: BoundedUsize<A, B>) -> &T {
        unsafe { self.get_unchecked(index.0) }
    }
}
```",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/667603596,Implement `Index` and `IndexMut` for arrays,scottmcm,28,670198245,5,667603596,0,667536735,2020-08-02T00:13:41Z,"Note that, when LLVM knows the index is in-bounds, it already removes the bounds check, even when indirected through a slice.
Demo: https://rust.godbolt.org/z/hWYG58",False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/667665302,Implement `Index` and `IndexMut` for arrays,pubfnbar,28,670198245,6,667665302,0,667603596,2020-08-02T12:01:50Z,"It would be interesting to test whether this PR breaks any code in crates.io (but I don't know how to do that). I'm pretty sure that at least the following code would stop compiling:
```rust
use std::ops::Index;

enum Idx {
    _0,
    _1,
}

impl<T> Index<Idx> for [T] {
    type Output = T;

    fn index(&self, idx: Idx) -> &T {
        Index::index(self, idx as usize)
    }
}

// This PR would cause there to be a clashing std library implementation of `Index<Idx> for [T; 2]`
impl<T> Index<Idx> for [T; 2] {
    type Output = T;

    fn index(&self, idx: Idx) -> &T {
        unsafe { self.get_unchecked(idx as usize) }
    }
}

fn main() {
    let array = [11, 22];
    let slice: &[u8] = &array;
    
    println!(""{:?}"", array[Idx::_0]);
    println!(""{:?}"", slice[Idx::_0]);
}
```
I don't know if this means that this PR can be merged only in the next Rust Edition?",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/672026277,Implement `Index` and `IndexMut` for arrays,Dylan-DPC-zz,28,670198245,7,672026277,0,667665302,2020-08-11T15:43:16Z,r? @KodrAus ,False,0,NONE
https://api.github.com/repos/rust-lang/rust/issues/comments/681621822,Implement `Index` and `IndexMut` for arrays,pubfnbar,28,670198245,8,681621822,0,672026277,2020-08-27T06:32:16Z,"I'd like to clarify something. You might be wondering how it is even possible (for some non-std code) to implement an external trait ([`Index`](https://doc.rust-lang.org/std/ops/trait.Index.html)) for an external type ([array](https://doc.rust-lang.org/std/primitive.array.html)) given that even [The Book says](https://doc.rust-lang.org/book/ch10-02-traits.html#implementing-a-trait-on-a-type) that the _orphan rule_ dictates that: **""But we can’t implement external traits on external types""**. The answer is that this rule was relaxed by [RFC #2451 - Re-Rebalancing Coherence](https://github.com/rust-lang/rfcs/pull/2451), and you can read more about it here:

- [Rust 1.41.0 accouncement](https://blog.rust-lang.org/2020/01/30/Rust-1.41.0.html#relaxed-restrictions-when-implementing-traits)
- [The stabilization report](https://github.com/rust-lang/rust/issues/63599)
- [The Rust RFC Book](https://rust-lang.github.io/rfcs/2451-re-rebalancing-coherence.html)",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/686870035,Implement `Index` and `IndexMut` for arrays,KodrAus,28,670198245,9,686870035,0,681621822,2020-09-04T02:54:15Z,"Based on the precedent of #74060 I'd be comfortable stabilizing these signatures with their use of const generics, and since this has only been possible to write for ~6months I wouldn't expect a lot of breakage. But just in case anybody else thinks a crater run is necessary I'll kick one off that we can cancel if we don't think it's needed.

@rfcbot fcp merge

This proposes stabilizing implementations of `Index` for `[T; N]` that forward to `[T]`.",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/686870040,Implement `Index` and `IndexMut` for arrays,rfcbot,28,670198245,10,686870040,0,686870035,2020-09-04T02:54:16Z,"Team member @KodrAus has proposed to merge this. The next step is review by the rest of the tagged team members:

* [x] @Amanieu
* [x] @KodrAus
* [ ] @dtolnay
* [x] @sfackler
* [ ] @withoutboats

No concerns currently listed.

Once a majority of reviewers approve (and at most 2 approvals are outstanding), this will enter its final comment period. If you spot a major issue that hasn't been raised at any point in this process, please speak up!

See [this document](https://github.com/rust-lang/rfcbot-rs/blob/master/README.md) for info about what commands tagged team members can give me.",False,0,NONE
https://api.github.com/repos/rust-lang/rust/issues/comments/686870081,Implement `Index` and `IndexMut` for arrays,KodrAus,28,670198245,11,686870081,0,686870040,2020-09-04T02:54:25Z,@bors try,False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/686870137,Implement `Index` and `IndexMut` for arrays,bors,28,670198245,12,686870137,0,686870081,2020-09-04T02:54:40Z,":hourglass: Trying commit ef61d686043f1df450d5a580978b76af985da6d6 with merge 72f88fc4e9458f89516a0b8b0868f3718aec5b47...
<!-- homu: {""type"":""TryBuildStarted"",""head_sha"":""ef61d686043f1df450d5a580978b76af985da6d6"",""merge_sha"":""72f88fc4e9458f89516a0b8b0868f3718aec5b47""} -->",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/686883601,Implement `Index` and `IndexMut` for arrays,bors,28,670198245,13,686883601,0,686870137,2020-09-04T03:38:42Z,":sunny: Try build successful - [checks-actions](https://github.com/rust-lang-ci/rust/runs/1070108983), [checks-azure](https://dev.azure.com/rust-lang/e71b0ddf-dd27-435a-873c-e30f86eea377/_build/results?buildId=36401)
Build commit: 72f88fc4e9458f89516a0b8b0868f3718aec5b47 (`72f88fc4e9458f89516a0b8b0868f3718aec5b47`)
<!-- homu: {""type"":""TryBuildCompleted"",""builders"":{""checks-azure"":""https://dev.azure.com/rust-lang/e71b0ddf-dd27-435a-873c-e30f86eea377/_build/results?buildId=36401"",""checks-actions"":""https://github.com/rust-lang-ci/rust/runs/1070108983""},""merge_sha"":""72f88fc4e9458f89516a0b8b0868f3718aec5b47""} -->",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/686885638,Implement `Index` and `IndexMut` for arrays,KodrAus,28,670198245,14,686885638,0,686883601,2020-09-04T03:45:59Z,@craterbot check,False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/686885655,Implement `Index` and `IndexMut` for arrays,craterbot,28,670198245,15,686885655,0,686885638,2020-09-04T03:46:03Z,":ok_hand: Experiment **`pr-74989`** created and queued.
:robot: Automatically detected try build 72f88fc4e9458f89516a0b8b0868f3718aec5b47
:mag: You can check out [the queue](https://crater.rust-lang.org) and [this experiment's details](https://crater.rust-lang.org/ex/pr-74989).

:information_source: **Crater** is a tool to run experiments across parts of the Rust ecosystem. [Learn more](https://github.com/rust-lang/crater)",False,0,COLLABORATOR
https://api.github.com/repos/rust-lang/rust/issues/comments/687081609,Implement `Index` and `IndexMut` for arrays,rfcbot,28,670198245,16,687081609,0,686885655,2020-09-04T11:13:46Z,":bell: **This is now entering its final comment period**, as per the [review above](https://github.com/rust-lang/rust/pull/74989#issuecomment-686870040). :bell:",False,0,NONE
https://api.github.com/repos/rust-lang/rust/issues/comments/691369874,Implement `Index` and `IndexMut` for arrays,craterbot,28,670198245,17,691369874,0,687081609,2020-09-12T00:55:49Z,":construction: Experiment **`pr-74989`** is now **running**

:information_source: **Crater** is a tool to run experiments across parts of the Rust ecosystem. [Learn more](https://github.com/rust-lang/crater)",False,0,COLLABORATOR
https://api.github.com/repos/rust-lang/rust/issues/comments/691694450,Implement `Index` and `IndexMut` for arrays,Aaron1011,28,670198245,18,691694450,0,691369874,2020-09-13T16:39:15Z,"cc @rust-lang/infra: One agent is marked as 'Online' instead of 'Running', so this job is taking much longer than it should.",False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/691720677,Implement `Index` and `IndexMut` for arrays,Dylan-DPC-zz,28,670198245,19,691720677,0,691694450,2020-09-13T20:25:46Z,"gonna try retrying it if poss

@craterbot retry",False,0,NONE
https://api.github.com/repos/rust-lang/rust/issues/comments/691720683,Implement `Index` and `IndexMut` for arrays,craterbot,28,670198245,20,691720683,0,691720677,2020-09-13T20:25:48Z,":rotating_light: **Error:** Experiment **`pr-74989`** didn't fail!

:sos: If you have any trouble with Crater please ping **`@rust-lang/infra`**!
:information_source: **Crater** is a tool to run experiments across parts of the Rust ecosystem. [Learn more](https://github.com/rust-lang/crater)",False,0,COLLABORATOR
https://api.github.com/repos/rust-lang/rust/issues/comments/691721318,Implement `Index` and `IndexMut` for arrays,Mark-Simulacrum,28,670198245,21,691721318,0,691720683,2020-09-13T20:30:51Z,"Restarted that agent. Generally speaking, you can ping or leave a note on Zulip and Pietro or I will restart it as soon as we can -- I don't think there's a way without ssh access currently to do so.",False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/691986686,Implement `Index` and `IndexMut` for arrays,rfcbot,28,670198245,22,691986686,0,691721318,2020-09-14T11:15:01Z,"The final comment period, with a disposition to **merge**, as per the [review above](https://github.com/rust-lang/rust/pull/74989#issuecomment-686870040), is now **complete**.

As the automated representative of the governance process, I would like to thank the author for their work and everyone else who contributed.

The RFC will be merged soon.",False,0,NONE
https://api.github.com/repos/rust-lang/rust/issues/comments/692779495,Implement `Index` and `IndexMut` for arrays,craterbot,28,670198245,23,692779495,0,691986686,2020-09-15T15:09:03Z,":tada: Experiment **`pr-74989`** is completed!
:bar_chart:  16 regressed and 3 fixed (120471 total)
:newspaper: [Open the full report](https://crater-reports.s3.amazonaws.com/pr-74989/index.html).

:warning: If you notice any spurious failure [please add them to the blacklist](https://github.com/rust-lang/crater/blob/master/config.toml)!
:information_source: **Crater** is a tool to run experiments across parts of the Rust ecosystem. [Learn more](https://github.com/rust-lang/crater)",False,0,COLLABORATOR
https://api.github.com/repos/rust-lang/rust/issues/comments/696468506,Implement `Index` and `IndexMut` for arrays,KodrAus,28,670198245,24,696468506,0,692779495,2020-09-22T01:46:27Z,"It looks like we have a handful of regressions here for 2d indexes:

- [`conway-rs`](https://crater-reports.s3.amazonaws.com/pr-74989/try%2372f88fc4e9458f89516a0b8b0868f3718aec5b47/gh/ryanavella.conway-rs/log.txt) https://github.com/ryanavella/conway-rs
- [`EnigmaMachine`](https://crater-reports.s3.amazonaws.com/pr-74989/try%2372f88fc4e9458f89516a0b8b0868f3718aec5b47/gh/ngc0202.EnigmaMachine/log.txt) https://github.com/ngc0202/EnigmaMachine
- [`kit`](https://crater-reports.s3.amazonaws.com/pr-74989/try%2372f88fc4e9458f89516a0b8b0868f3718aec5b47/reg/kit-0.0.2/log.txt) https://github.com/weshardee/kit

Before we merge I'll follow up with these libraries (it looks like `kit` is the only one up on `crates.io` right now)",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/726974124,Implement `Index` and `IndexMut` for arrays,pubfnbar,28,670198245,25,726974124,0,696468506,2020-11-13T18:59:04Z,"Just wondering, why hasn't this been merged already?",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/728004541,Implement `Index` and `IndexMut` for arrays,Mark-Simulacrum,28,670198245,26,728004541,0,726974124,2020-11-16T13:23:06Z,"Please squash commits into one, too.",False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/728065146,Implement `Index` and `IndexMut` for arrays,pubfnbar,28,670198245,27,728065146,0,728004541,2020-11-16T14:00:13Z,"> Please squash commits into one, too.

@Mark-Simulacrum 
If this was directed to me, then I must admit I don't know how to do that. After some googling I think it means I should download (or whatever the correct terminology is) this pull request (or maybe the whole Rust repository?) to my computer and use a command like `git rebase <something>`. I don't really know how to use git or GitHub - I created this pull request only by using this website (I've never done the git download thingy to my computer). But it seems that whoever is allowed to merge this can also ""squash"" the commits while he's at it (according to [this](https://stackoverflow.com/a/43858707/14642088)).",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/728079207,Implement `Index` and `IndexMut` for arrays,Mark-Simulacrum,28,670198245,28,728079207,0,728065146,2020-11-16T14:08:51Z,"No worries, squashed for you (also bumped to 1.50, as that's the current nightly version).

@bors r=KodrAus rollup

https://rustc-dev-guide.rust-lang.org/git.html has some documentation on getting started with git, if you're interested, and feel free to drop by [Zulip](https://rust-lang.zulipchat.com/#narrow/stream/182449-t-compiler.2Fhelp) with any questions!",False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/728079249,Implement `Index` and `IndexMut` for arrays,bors,28,670198245,29,728079249,0,728079207,2020-11-16T14:08:53Z,":pushpin: Commit c03dfa6671bb462d243c12c72c8829f98c99e394 has been approved by `KodrAus`

<!-- @bors r=KodrAus c03dfa6671bb462d243c12c72c8829f98c99e394 -->
<!-- homu: {""type"":""Approved"",""sha"":""c03dfa6671bb462d243c12c72c8829f98c99e394"",""approver"":""KodrAus""} -->",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/74990,"Tracking Issue for ""C-unwind ABI"", RFC 2945",nikomatsakis,51,670237997,1,670237997,0,0,2020-07-31T21:11:17Z,"<!--
Thank you for creating a tracking issue! 📜 Tracking issues are for tracking a
feature from implementation to stabilisation. Make sure to include the relevant
RFC for the feature if it has one. Otherwise provide a short summary of the
feature and link any relevant PRs or issues, and remove any sections that are
not relevant to the feature.

Remember to add team labels to the tracking issue.
For a language team feature, this would e.g., be `T-lang`.
Such a feature should also be labeled with e.g., `F-c_unwind`.
This label is used to associate issues (e.g., bugs and design questions) to the feature.
-->

This is a tracking issue for the RFC ""C-unwind ABI"" (rust-lang/rfcs#2945).

The feature gate for the issue is `#![feature(c_unwind)]`.

This RFC was created as part of the ffi-unwind project group tracked at https://github.com/rust-lang/lang-team/issues/19.

### About tracking issues

Tracking issues are used to record the overall progress of implementation.
They are also uses as hubs connecting to other relevant issues, e.g., bugs or open design questions.
A tracking issue is however *not* meant for large scale discussion, questions, or bug reports about a feature.
Instead, open a dedicated issue for the specific matter and add the relevant feature gate label.

### Steps
<!--
Include each step required to complete the feature. Typically this is a PR
implementing a feature, followed by a PR that stabilises the feature. However
for larger features an implementation could be broken up into multiple PRs.
-->

- [ ] Implement the RFC
- [ ] Adjust documentation ([see instructions on rustc-dev-guide][doc-guide])
- [ ] Stabilization PR ([see instructions on rustc-dev-guide][stabilization-guide])

[stabilization-guide]: https://rustc-dev-guide.rust-lang.org/stabilization_guide.html#stabilization-pr
[doc-guide]: https://rustc-dev-guide.rust-lang.org/stabilization_guide.html#documentation-prs

### Implementation notes

Major provisions in the RFC:

* [x] Add a `C-unwind` ABI and `system-unwind` (I think), we may need more variants.
* [ ] For external functions with the C ABI, we already (I believe) add the ""nounwind"" LLVM attributes when we build them. We want to continue doing this.
* [ ] For external functions with the C-unwind ABI, we do *not* want any such attributes.
* [ ] For Rust functions defined with the C ABI, e.g., `extern ""C"" fn foo() { ... }`, we want to force them to abort if there is a panic. The MIR helper function [`should_abort_on_panic`](https://doc.rust-lang.org/nightly/nightly-rustc/rustc_mir_build/build/fn.should_abort_on_panic.html) already exists and I think will modify the generated code to insert the required shims in such a case. They should also be marked as ""nounwind"" in LLVM, if they're not already. 
* [ ] Rust functions with the ""C-unwind"" ABI should **not** abort on panic.
* [ ] Use ABI to guide the ""nounwind"" attribute on callsites as well.
* [ ] Write suitable codegen tests to check generated LLVM IR.

### Unresolved Questions
<!--
Include any open questions that need to be answered before the feature can be
stabilised.
-->

None. The unresolved questions in the RFC were meant to be solved by future RFCs building on this one.

### Implementation history
* Initial implementation: https://github.com/rust-lang/rust/pull/76570
* Additional work (removing `#[unwind]`, adjusting panic handling): https://github.com/rust-lang/rust/pull/86155",True,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/667405657,"Tracking Issue for ""C-unwind ABI"", RFC 2945",cratelyn,51,670237997,2,667405657,0,670237997,2020-07-31T22:03:37Z,"Hello! I would be interested in helping implement this RFC. :raising_hand: 

(cc: @aturon)",False,0,NONE
https://api.github.com/repos/rust-lang/rust/issues/comments/667536451,"Tracking Issue for ""C-unwind ABI"", RFC 2945",nikomatsakis,51,670237997,3,667536451,0,667405657,2020-08-01T13:59:27Z,"Hey @katie-martin-fastly, that's great news! I'm going to assign you to the issue for now:

@rustbot assign @katie-martin-fastly 

One thing to mention is that most Rust compiler development discussion takes place on the [rust-lang zulip](https://rust-lang.zulipchat.com/), and this project in particular is chatting in `#project-ffi-unwind`. I or @Amanieu are probably reasonable people to ping with questions. Also, for general ""getting started"" tips on building and testing the Rust compiler, the [rustc-dev-guide](https://rustc-dev-guide.rust-lang.org/) is your friend. Also, rust-analyzer works well for IDE support (e.g., with vscode), though it requires a small bit of configuration since rustc doesn't build with cargo but rather the `x.py` script. (I couldn't find any documentation on that, I'll ping a few others and see...)

That said, in terms of mentoring and getting started, I think the idea is going to be to adapt an existing mechanism that the compiler offers. We have this attribute `#[unwind(allowed)]` which allows users to mark functions as permitting unwinding -- that mechanism is basically going to be deprecated and replaced with this new ABI, though I think it'd be best to add the ABI before trying to adapt the `unwind` attribute code. Still, searching for code related to that attribute will give you a good idea of what needs to change. 

I can do more mentoring instructions later but, as a starting point, I updated the head post with some of the major goals of the RFC (see the ""Implementation notes"") section. Also here are some tips to get you started in terms of reading into the rustc code:

* The [`Abi`](https://doc.rust-lang.org/nightly/nightly-rustc/rustc_codegen_llvm/abi/enum.Abi.html) enum lists out all the known ABIs (there may be more similar enums, not sure). We'll want to extend it with `C-unwind` and perhaps other unwind variants. One way to do this might be to change the `C` variant to `C { unwind: bool }` or something like that, or maybe just add a `Cunwind`, not sure.
* The [`UnwindAttr`](https://doc.rust-lang.org/nightly/nightly-rustc/rustc_attr/enum.UnwindAttr.html) type records what kind of unwind attribute is placed on a particular function (is unwinding [allowed](https://doc.rust-lang.org/nightly/nightly-rustc/rustc_attr/enum.UnwindAttr.html#variant.Aborts)? does it [force an abort](https://doc.rust-lang.org/nightly/nightly-rustc/rustc_attr/enum.UnwindAttr.html#variant.Aborts)?)
* The [`find_unwind_attr`](https://doc.rust-lang.org/nightly/nightly-rustc/rustc_attr/fn.find_unwind_attr.html) function checks for what unwind attribute is placed on a particular function.
* The [`should_abort_on_panic`](https://doc.rust-lang.org/nightly/nightly-rustc/rustc_mir_build/build/fn.should_abort_on_panic.html) function is used to decide when a function ought to, well, abort if a panic occurs (as the name suggests).
* The [`can_unwind`] field of this struct seems to be used to [set the LLVM attribute ""nounwind""](https://github.com/rust-lang/rust/blob/cfdf9d335501cc0a53ae69c940095cca7d4be0f8/src/librustc_codegen_llvm/abi.rs#L399-L402). I'm not quite sure where it gets set, but I have to stop now because it's Saturday :P so I'll leave that as an exercise to the reader.
",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/943543668,"Tracking Issue for ""C-unwind ABI"", RFC 2945",pravic,51,670237997,4,943543668,0,667536451,2021-10-14T16:57:17Z,"Given #76570 merged, shouldn't the first step be marked as checked? ",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/943594016,"Tracking Issue for ""C-unwind ABI"", RFC 2945",bjorn3,51,670237997,5,943594016,0,943543668,2021-10-14T18:03:18Z,It isn't completely implemented yet. For example trying to unwind through rust code compiled with support for panic=unwind doesn't abort yet if panic=abort is the final panic handling strategy.,False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/1147671255,"Tracking Issue for ""C-unwind ABI"", RFC 2945",BatmanAoD,51,670237997,6,1147671255,0,943594016,2022-06-06T17:01:16Z,Blocked on https://github.com/rust-lang/rust/issues/97659.,False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/1153002487,"Tracking Issue for ""C-unwind ABI"", RFC 2945",madsmtm,51,670237997,7,1153002487,0,1147671255,2022-06-11T21:43:20Z,"Should probably also be blocked on https://github.com/rust-lang/rust/pull/92964 (`""C-unwind""` fn-pointers don't implement common traits).",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/1233755768,"Tracking Issue for ""C-unwind ABI"", RFC 2945",lopopolo,51,670237997,8,1233755768,0,1153002487,2022-09-01T05:22:49Z,"> Should probably also be blocked on #92964 (`""C-unwind""` fn-pointers don't implement common traits).

@madsmtm @BatmanAoD I've put up a PR to resolve this stabilization blocker:

- https://github.com/rust-lang/rust/pull/101263",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/1234452199,"Tracking Issue for ""C-unwind ABI"", RFC 2945",lopopolo,51,670237997,9,1234452199,0,1233755768,2022-09-01T15:36:48Z,"> Blocked on #97659.

https://github.com/rust-lang/rust/issues/97659 was recently closed. It was addressed by https://github.com/rust-lang/rust/pull/92845.",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/1287540851,"Tracking Issue for ""C-unwind ABI"", RFC 2945",lopopolo,51,670237997,10,1287540851,0,1234452199,2022-10-21T23:50:16Z,"@madsmtm @BatmanAoD: https://github.com/rust-lang/rust/pull/101263 has been merged 🎉 What remains before the `C-unwind` ABI can be stabilized?

Once the next nightly drops I should be able to push up a build of Artichoke Ruby which oxidizes a `setjmp`/`longjmp` unwinding mechanism with `catch_unwind`/`panic` if that would help with a motivating usecase for the stabilization report.",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/1303795906,"Tracking Issue for ""C-unwind ABI"", RFC 2945",BatmanAoD,51,670237997,11,1303795906,0,1287540851,2022-11-04T15:53:21Z,@lopopolo We're ready for stabilization! Discussed here: https://rust-lang.zulipchat.com/#narrow/stream/210922-project-ffi-unwind/topic/weekly.20meeting/near/307806910,False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/1304212446,"Tracking Issue for ""C-unwind ABI"", RFC 2945",thomcc,51,670237997,12,1304212446,0,1303795906,2022-11-04T20:40:17Z,"Hey, I'm concerned about the fact that the current feature (and presumably the proposed stabilization) controls both the existence of the `""*-unwind""` ABI and whether or not the other ABIs are forbidden from unwinding or not (see https://github.com/rust-lang/rust/blob/15d7556de9babe4c1d8f367de1b827494782bd92/compiler/rustc_middle/src/ty/layout.rs#L1048-L1054).

If stabilized in this way, anybody using this functionality will likely need to implement compiler version (or feature) detection, in order to conditionally switch between `extern ""C""` and `extern ""C-unwind""` based on availability. They also have to release that in time to be ready day 1 when this hits stable. This isn't exactly hard, but seems pretty rough, especially because that may require breaking API changes (because of changing a function's ABI). Perhaps more importantly, doing this requires knowing about it in advance. Many Rust devs only find out about new features when they hit the stable release channel.

For what it's worth, I work on [a codebase](https://github.com/tcdi/pgx) that uses `extern ""C""` as if it's `extern ""C-unwind""`. This stabilization will *probably* cause no problems for us, since we've been prepared for it and [very recently](https://github.com/tcdi/pgx/pull/834)[^1] fixed the last of the design issues around it. Speaking way too optimistically, I don't anticipate many problems with changing this for PGX, but do note: This was not trivial to do, and was helped by having multiple Rust project members (myself and @workingjubilee) who have been paying attention to this issue, which is not common. I believe most projects using would be in a worse place, and might not find out about this in advance.

So, if we're going to make switching to a feature mandatory in the release that stabilizes it, then *at least* we need to publish a blog advising about this in advance. And even then, I think that it's pretty dodgy for us to do.

EDIT: Concretely, one plan for solving this would probably be to land `extern ""C-unwind""` first, along with a blog post saying that it will become required after N (for small N, maybe 3) versions, then after N versions, make it required. While this kind of error handling is common in C, the number of projects impacted may be small. (Hard to know though -- IDK if enough folks cover error behavior in their tests for crater or similar to be a good judge).

[^1]: After that lands we will be fully complaint with the RFC's rules (if you treat `extern ""C""` as `extern ""C-unwind""`) -- no forced-unwinding across non-POFs, Rust never unwinds out of C, etc.",False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/1304890338,"Tracking Issue for ""C-unwind ABI"", RFC 2945",BatmanAoD,51,670237997,13,1304890338,0,1304212446,2022-11-06T20:49:06Z,"As I mentioned in Zulip [in Zulip](https://rust-lang.zulipchat.com/#narrow/stream/210922-project-ffi-unwind/topic/weekly.20meeting), I'm okay with breaking this into two features and stabilizing them separately, but I don't know who would need to sign off on that decision. ",False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/1314492993,"Tracking Issue for ""C-unwind ABI"", RFC 2945",BatmanAoD,51,670237997,14,1314492993,0,1304890338,2022-11-14T22:27:31Z,"@nikomatsakis @joshtriplett Do either of you know who should make the decision on whether to stabilize `""C-unwind""` separately from the new `""C""` behavior? In the interim, `""C""` would behave identically to `""C-unwind""`.",False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/1314950833,"Tracking Issue for ""C-unwind ABI"", RFC 2945",RalfJung,51,670237997,15,1314950833,0,1314492993,2022-11-15T08:19:16Z,"Sounds like a lang team decision to me. I think this can probably be decided with the FCP for stabilizing the feature. So I'd propose suggest you propose one of these two options, ask for T-lang FCP on that, but add a note in the nomination message that there is an alternative here and we'd like to know which way T-lang prefers.

Do we usually do stabilization FCPs on the tracking issue or the stabilization PR?",False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/1355200651,"Tracking Issue for ""C-unwind ABI"", RFC 2945",pnkfelix,51,670237997,16,1355200651,0,1314950833,2022-12-16T16:45:10Z,"@rustbot label: I-lang-nominated

see [question(s) above](https://github.com/rust-lang/rust/issues/74990#issuecomment-1314492993)",False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/1355246537,"Tracking Issue for ""C-unwind ABI"", RFC 2945",RalfJung,51,670237997,17,1355246537,0,1355200651,2022-12-16T17:17:16Z,"To give some context to the decision here: currently the c_unwind feature flag has two effects:
- it lets you use `extern ""C-unwind""`
- it makes rustc assume that an `extern ""C""` is `nounwind`, and generate code accordingly (on stable, we currently treat `extern ""C""`  as allowing unwinding)

The question is whether when we unlock `extern ""C-unwind""` on stable, we should immediately also do the 2nd part on stable, or whether we should have a transition period where for now, we keep treating `extern ""C""`  as unwinding, and wait a few releases before making it `nounwind`.",False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/1355713657,"Tracking Issue for ""C-unwind ABI"", RFC 2945",jyn514,51,670237997,18,1355713657,0,1355246537,2022-12-16T22:06:52Z,"I'm very out of the loop so there's probably a simple answer, but why not keep the current `extern ""C""` (and guarantee it's not UB) and add a new `extern ""C-nounwind""` that people can opt-in to? That wouldn't be a breaking change.",False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/1355717859,"Tracking Issue for ""C-unwind ABI"", RFC 2945",bjorn3,51,670237997,19,1355717859,0,1355713657,2022-12-16T22:13:10Z,"For unwinding into Rust that would be an option. For unwinding out of Rust, that would remain a massive footgun as the other side likely doesn't allow unwinding and thus you get UB anyway. Having `extern ""C""` abort when unwinding out of Rust is required to fix this UB.",False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/1355974906,"Tracking Issue for ""C-unwind ABI"", RFC 2945",BatmanAoD,51,670237997,20,1355974906,0,1355717859,2022-12-17T02:39:40Z,"@jyn514 That was discussed as a possibility some time ago, but was ultimately rejected. Unfortunately I don't have a readily available link to the rationale for choosing to add `C-unwind` rather than adding `C-nounwind`, and I don't really remember what the pros and cons were. ",False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/1359993986,"Tracking Issue for ""C-unwind ABI"", RFC 2945",nikomatsakis,51,670237997,21,1359993986,0,1355974906,2022-12-20T18:51:21Z,"To my mind, the major pros/cons are:

* unwind is only expected and desired in a very niche set of cases
* it is not free in that the generated code for C-unwind is less efficient than C to account for possibility of unwinding
* doesn't solve the case of people unwinding *out* from Rust, as @bjorn3 noted",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/1360085494,"Tracking Issue for ""C-unwind ABI"", RFC 2945",joshtriplett,51,670237997,22,1360085494,0,1359993986,2022-12-20T20:01:36Z,"We discussed this in today's @rust-lang/lang meeting. We *would* like to see the stabilization split, so that we can stabilize `""C-unwind""` now, and switch over `""C""` to mean nounwind in a few versions. The stabilization of `""C-unwind""` should also have the `relnotes` tag and include a note that a future version will switch the behavior of `""C""`.",False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/1363473645,"Tracking Issue for ""C-unwind ABI"", RFC 2945",BatmanAoD,51,670237997,23,1363473645,0,1360085494,2022-12-23T00:39:17Z,"# Request for Stabilization

This is a request for *partial* stabilization of the `c_unwind` feature, [RFC-2945][rfc-text]. The newly-introduced ABIs will be stabilized, but the changes in behavior to existing ABIs (such as `extern ""C""`) will remain behind the `c_unwind` feature gate.

## Summary

This stabilization enables ABI strings ending in `-unwind`; specifically:

- `""C-unwind""`
- `""cdecl-unwind""`
- `""stdcall-unwind""`
- `""fastcall-unwind""`
- `""vectorcall-unwind""`
- `""thiscall-unwind""`
- `""aapcs-unwind""`
- `""win64-unwind""`
- `""sysv64-unwind""`
- `""system-unwind""`

The behavior for unforced unwinding (the typical case) is specified in [this table from the RFC][rfc-table], and has not been changed since the RFC was accepted. To summarize:

Each ABI is mostly equivalent to the same ABI without `-unwind`, except that the behavior is defined to be safe when an unwinding operation (`panic` or C++ style exception) crosses the ABI boundary. For `panic=unwind`, this is a valid way to let exceptions from one language unwind the stack in another language without terminating the process (as long as the exception is caught in the same language from which it originated); for `panic=abort`, this will typically abort the process immediately.

For initial stabilization, *no change* will be made to the existing ABIs. The existing ABIs have soundness holes, though, which will be fixed when the behavior described in the RFC is stabilized. Thus, we would like to stabilize the remainder of the `c_unwind` feature soon. We are splitting the stabilization into separate releases to give users time to adopt the new ABIs. 

## Examples

### Rust `panic` with `""C-unwind""`

```rust
#[no_mangle]
extern ""C-unwind"" fn example() {
    panic!(""Uh oh"");
}
```

This function is now permitted to unwind C++ stack frames.

```
[Rust function with `catch_unwind`, which stops the unwinding]
      |
     ...
      |
[C++ frames]
      |                           ^
      | (calls)                   | (unwinding
      v                           |  goes this
[Rust function `example`]         |  way)
      |                           |
      +--- rust function panics --+
```

If the C++ frames have objects, their destructors will be called.

### C++ `throw` with `""C-unwind""`

```rust
#[link(...)]
extern ""C-unwind"" {
    // A C++ function that may throw an exception
    fn may_throw();
}

#[no_mangle]
extern ""C-unwind"" fn rust_passthrough() {
    let b = Box::new(5);
    unsafe { may_throw(); }
    println!(""{:?}"", &b);
}
```

A C++ function with a `try` block may invoke `rust_passthrough` and `catch` an exception thrown by `may_throw`.

```
[C++ function with `try` block that invokes `rust_passthrough`]
      |
     ...
      |
[Rust function `rust_passthrough`]
      |                            ^
      | (calls)                    | (unwinding
      v                            |  goes this
[C++ function `may_throw`]         |  way)
      |                            |
      +--- C++ function throws ----+
```

If `may_throw` does throw an exception, `b` will be dropped. Otherwise, `5`
will be printed.

## Changes since the RFC

The implementation is as specified in the RFC, but there have been a few considerations not directly addressed in the text of the RFC.

### Additional ABI strings

The RFC, as written, only introduces the `""C-unwind""` ABI string; the others [listed above](#summary) were introduced later. Their semantics are exactly as one would expect: they are identical to their non-`unwind` counterparts except when an unwind reaches their ABI boundary, in which case the behavior is the same as the RFC specifies for `""C-unwind""`.

Similarly, the new rules for `extern ""C""` regarding unwinding are now applied to all non-`unwind` ABI strings other than `""Rust""`.

### Double unwinding

[PR #92911][pr-double-unwind] ensured that the following scenarios both safely abort the program:

* multiple foreign (e.g. C++) exceptions
* a `panic` occurring while a foreign exception is unwinding the stack, or vice-versa

### Mixing panic modes

We addressed a [soundness hole][issue-mixed-panic] regarding the behavior when a foreign exception enters the Rust runtime via a crate compiled with `panic=unwind`, but escapes into a crate compiled with `panic=abort`. We decided to [prohibit][pr-fix-mixed-panic] any crate from being linked with the `panic=abort` runtime if it has both of the following characteristics:

* It contains a call to an `-unwind` foreign function or function pointer
* It was compiled with `panic=unwind`

Note: `cargo` will automatically unify all crates to use the same `panic` runtime, so this prohibition does not apply to projects compiled with `cargo`.

[PR #97235][pr-fix-mixed-panic] implemented this prohibition.

#### Lint for the standard library

For libraries that are intended to be compiled once and linked against both the `panic=unwind` runtime and the `panic=abort` runtime, we have introduced a lint, `ffi_unwind_calls`, that will flag all uses of the new `-unwind` ABIs. The main use case is the Rust standard library, which is typically distributed as a binary rather than as source code.

### Unresolved questions

None of the [unresolved questions][rfc-unresolved] have been resolved. Specifically, the following are still considered undefined behavior:

* Letting a foreign exception unwind a Rust frame that calls `catch_unwind`
* Calling `pthread_exit` or `longjmp` in such a way that Rust frames are deallocated

## Tests

### Codegen

There is [a folder of codegen tests][codegen-unwind] for the new ABI strings.

Additional codegen tests are:

* [panic=abort][codegen-extra-1]
* [extern-exports][codegen-extra-2]
* [extern-imports][codegen-extra-3]

### `""C""` guaranteed to abort on panic

[This test][abort-on-panic] verifies that an `extern ""C""` function that `panic!`s will always abort if the panic would otherwise ""escape"".

### Full examples

Full example projects mixing Rust code with non-Rust code are:

* [a `panic` escaping into C][panic-into-c]
* [a C++ exception escapig into Rust][cpp-throw-into-rust]
* [double unwinding][double-unwind]

### Open PR

[PR #97235][pr-fix-mixed-panic] introduces tests for the [mixed-panic-modes issue](#mixing-panic-modes).

## Documentation

Here are documentation PRs for

* [the Reference][reference]
* [the Rustonomicon][nomicon]

I have not yet suggested any changes for the Book, but it may be appropriate to add something like this:

> Usually you want the non-unwind versions of ABI strings, but if you are
> messing around with FFI and unwinding, refer to the Nomicon.

I don't think Rust by Example needs to be updated.

<!-- links -->
[rfc-text]: https://github.com/rust-lang/rfcs/blob/master/text/2945-c-unwind-abi.md
[rfc-table]: https://github.com/rust-lang/rfcs/blob/master/text/2945-c-unwind-abi.md#abi-boundaries-and-unforced-unwinding
[rfc-unresolved]: https://github.com/rust-lang/rfcs/blob/master/text/2945-c-unwind-abi.md#unresolved-questions
[pr-fix-mixed-panic]: https://github.com/rust-lang/rust/pull/97235/files
[pr-double-unwind]: https://github.com/rust-lang/rust/pull/92911
[issue-mixed-panic]: https://github.com/rust-lang/rust/issues/96926
[codegen-unwind]: https://github.com/rust-lang/rust/tree/master/src/test/codegen/unwind-abis
[codegen-extra-1]: https://github.com/rust-lang/rust/blob/master/src/test/codegen/unwind-and-panic-abort.rs
[codegen-extra-2]: https://github.com/rust-lang/rust/blob/master/src/test/codegen/unwind-extern-exports.rs
[codegen-extra-3]: https://github.com/rust-lang/rust/blob/master/src/test/codegen/unwind-extern-imports.rs
[panic-into-c]: https://github.com/rust-lang/rust/tree/master/src/test/run-make-fulldeps/c-unwind-abi-catch-lib-panic
[cpp-throw-into-rust]: https://github.com/rust-lang/rust/tree/master/src/test/run-make-fulldeps/foreign-exceptions
[double-unwind]: https://github.com/rust-lang/rust/tree/master/src/test/run-make-fulldeps/foreign-double-unwind
[abort-on-panic]: https://github.com/rust-lang/rust/blob/master/src/test/ui/panics/abort-on-panic.rs
[nomicon]: https://github.com/rust-lang/nomicon/pull/365
[reference]: https://github.com/rust-lang/reference/pull/1226
",False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/1363474832,"Tracking Issue for ""C-unwind ABI"", RFC 2945",joshtriplett,51,670237997,24,1363474832,0,1363473645,2022-12-23T00:42:17Z,"Shall we stabilize the `extern ""C-unwind""` and other `-unwind` calling conventions? This change will leave `extern ""C""` unchanged for now, but have the existing feature gate continue to opt into the new behavior on nightly. We'll do a separate change later to make `extern ""C""` and similar not permit unwinding.

@rfcbot merge",False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/1363474839,"Tracking Issue for ""C-unwind ABI"", RFC 2945",rfcbot,51,670237997,25,1363474839,0,1363474832,2022-12-23T00:42:18Z,"Team member @joshtriplett has proposed to merge this. The next step is review by the rest of the tagged team members:

* [x] @joshtriplett
* [x] @nikomatsakis
* [ ] @pnkfelix
* [x] @scottmcm
* [x] @tmandry

Concerns:

* ~~docs~~ resolved by https://github.com/rust-lang/rust/issues/74990#issuecomment-1478379991

Once a majority of reviewers approve (and at most 2 approvals are outstanding), this will enter its final comment period. If you spot a major issue that hasn't been raised at any point in this process, please speak up!

cc @rust-lang/lang-advisors: FCP proposed for lang, please feel free to register concerns.
See [this document](https://github.com/rust-lang/rfcbot-rs/blob/master/README.md) for info about what commands tagged team members can give me.",False,0,NONE
https://api.github.com/repos/rust-lang/rust/issues/comments/1363475143,"Tracking Issue for ""C-unwind ABI"", RFC 2945",joshtriplett,51,670237997,26,1363475143,0,1363474839,2022-12-23T00:43:02Z,"Also, for future reference, feature gates should not normally change behavior in any way, they should only gate access to behavior. That helps avoid adding complexity to stabilizations.",False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/1363706827,"Tracking Issue for ""C-unwind ABI"", RFC 2945",nbdd0121,51,670237997,27,1363706827,0,1363475143,2022-12-23T07:54:15Z,Note that `vectorcall-unwind` and `thiscall-unwind` should not be stabilised; I'll change them to gate under `vectorcall` and `thiscall` instead.,False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/1364528436,"Tracking Issue for ""C-unwind ABI"", RFC 2945",nikomatsakis,51,670237997,28,1364528436,0,1363706827,2022-12-24T13:11:16Z,"@rfcbot fcp reviewed

I want to give a huge shout-out to @BatmanAoD for stewarding this work for so long. Also to @cratelyn, @Amanieu, @nbdd0121, @alexcrichton and others who participated in the implementation. It's been a slog!
",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/1364528477,"Tracking Issue for ""C-unwind ABI"", RFC 2945",nikomatsakis,51,670237997,29,1364528477,0,1364528436,2022-12-24T13:11:39Z,"@rfcbot concern docs

I did an initial read of the [documentation and left some comments](https://github.com/rust-lang/reference/pull/1226#pullrequestreview-1229631065). I'm filing a concern until we have approved the docs PR.",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/1370149769,"Tracking Issue for ""C-unwind ABI"", RFC 2945",nikomatsakis,51,670237997,30,1370149769,0,1364528477,2023-01-03T19:33:49Z,"@BatmanAoD also, we discussed in lang-team meeting that it'd be great to have a short description of the changes to unwinding that are being made here for release notes.",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/1382646568,"Tracking Issue for ""C-unwind ABI"", RFC 2945",tmandry,51,670237997,31,1382646568,0,1370149769,2023-01-14T03:11:43Z,"I'm a slightly weirded out by the fact that `extern ""C-unwind""` refers to two very different features (in my mind):

* Passing Rust exceptions through `Rust -> C++ [*] -> Rust [*]` call stacks
* Passing foreign exceptions through `C++ -> Rust [*] -> C++ [*]` call stacks

Where `A -> B` means ""A calling into B"". IIUC, `[*]` marks where you must have an `extern ""C-unwind""` function declaration or pointer declared in Rust for that function. (Substitute C and C++ for any ABI and language pair that has exceptions.)

The RFC says a goal is to allow Rust to choose a different unwinding mechanism from the ""native"" one used by C/C++, but having one syntax for both feels a bit like working backwards from the fact that they're the same today.

---

That being said, I can see how in an environment where you are mixing the two languages freely, you would want functions that support _both_. Let's work out an example where we might see interleaving from both languages, and either can throw an exception:

`Rust -> C++ catch(...) [R] -> Rust [CR] -> C++ [CR] -> Rust [CR] -> C++ [C]`

At minimum you would need all the functions marked `[C]` to support C++ unwinding through them, and all the functions marked `[R]` to support Rust unwinding through them. For the vast majority of functions at language boundaries in a real-world situation, you want both (`[CR]`).

But this is actually UB, because we might pass a Rust exception through the `catch` of the second frame. (If we added a Rust `catch_unwind` farther down to prevent that, a C++ exception passing through _there_ might cause UB). So for now we must avoid this situation entirely and be clear about which types of exceptions might go through a particular function in a particular context.

If one day we think we'll support this in some way that isn't UB, it makes more sense to me to have a single syntax that supports both kinds of exceptions.

Can someone tell me if I'm conceptualizing of this properly, or am I totally confused?",False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/74991,Fix Const-Generic Cycle ICE #74199,JulianKnodt,3,670244317,1,670244317,0,0,2020-07-31T21:19:10Z,"This PR intends to fix the bug in Issue #74199 by following the suggestion provided of ignoring the error that causes the ICE.

This does not fix the underlying cycle detection issue, but fixes the ICE.
Also adds a test to check that it doesn't causes an ICE but returns a valid error for now.

r? @lcnr 

Edit: Also it's funny how this PR number is an anagram of the issue number",True,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/667361062,Fix Const-Generic Cycle ICE #74199,rust-highfive,3,670244317,2,667361062,0,670244317,2020-07-31T21:19:12Z,"Thanks for the pull request, and welcome! The Rust team is excited to review your changes, and you should hear from @lcnr (or someone else) soon.

If any changes to this PR are deemed necessary, please add them as extra commits. This ensures that the reviewer can see what has changed since they last reviewed the code. Due to the way GitHub handles out-of-date commits, this should also make it reasonably obvious what issues have or haven't been addressed. Large or tricky changes may require several passes of review and changes.

Please see [the contribution instructions](https://rustc-dev-guide.rust-lang.org/contributing.html) for more information.
",False,0,COLLABORATOR
https://api.github.com/repos/rust-lang/rust/issues/comments/667405226,Fix Const-Generic Cycle ICE #74199,lcnr,3,670244317,3,667405226,0,667361062,2020-07-31T22:02:10Z,thanks :+1: @bors r+ rollup=always,False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/667405237,Fix Const-Generic Cycle ICE #74199,bors,3,670244317,4,667405237,0,667405226,2020-07-31T22:02:12Z,":pushpin: Commit 96b5dee9ab3b4b0c8f5086011b7a15b7c4aed48c has been approved by `lcnr`

<!-- @bors r=lcnr 96b5dee9ab3b4b0c8f5086011b7a15b7c4aed48c -->
<!-- homu: {""type"":""Approved"",""sha"":""96b5dee9ab3b4b0c8f5086011b7a15b7c4aed48c"",""approver"":""lcnr""} -->",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/3652,Make marker pointer advances past parent pointer advance parent point…,jejones3141,4,702773820,1,702773820,0,0,2020-09-16T13:37:59Z,"…er too

Why? fr_[sd]buff_moves() with marker source/destination will advance the
marker pointer... but if that moves it past the parent's pointer, then
bytes are used that aren't reflected in fr_[sd]buff_used(). For dbuffs,
at least, this breaks the convention for encoding functions.

This change causes setting a marker pointers to check the parent's pointer
and, if and only if the set moves the marker pointer past the parent
pointer, advance the parent pointer to match the marker pointer.",True,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/693707062,Make marker pointer advances past parent pointer advance parent point…,arr2036,4,702773820,2,693707062,0,702773820,2020-09-16T22:51:47Z,"Can you uninvert the order of the functions in the sbuff code, it makes it really hard to figure out what changed",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/693742702,Make marker pointer advances past parent pointer advance parent point…,jejones3141,4,702773820,3,693742702,0,693707062,2020-09-17T00:53:04Z,"Indeed I can and will.

On Wed, Sep 16, 2020 at 5:52 PM Arran Cudbard-Bell <notifications@github.com>
wrote:

> Can you uninvert the order of the functions in the sbuff code, it makes it
> really hard to figure out what changed
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/FreeRADIUS/freeradius-server/pull/3652#issuecomment-693707062>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ABV2HFH75QJ4XUQPGSFIXBDSGE6RBANCNFSM4RO3F3CA>
> .
>
",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/694239530,Make marker pointer advances past parent pointer advance parent point…,jejones3141,4,702773820,4,694239530,0,693742702,2020-09-17T13:36:02Z,"Change made and pushed.

On Wed, Sep 16, 2020 at 7:52 PM James Jones <jejones3141@gmail.com> wrote:

> Indeed I can and will.
>
> On Wed, Sep 16, 2020 at 5:52 PM Arran Cudbard-Bell <
> notifications@github.com> wrote:
>
>> Can you uninvert the order of the functions in the sbuff code, it makes
>> it really hard to figure out what changed
>>
>> —
>> You are receiving this because you authored the thread.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/FreeRADIUS/freeradius-server/pull/3652#issuecomment-693707062>,
>> or unsubscribe
>> <https://github.com/notifications/unsubscribe-auth/ABV2HFH75QJ4XUQPGSFIXBDSGE6RBANCNFSM4RO3F3CA>
>> .
>>
>
",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/694468899,Make marker pointer advances past parent pointer advance parent point…,jejones3141,4,702773820,5,694468899,0,694239530,2020-09-17T20:02:43Z,"Agreed, it's unexpected and surprising behavior. Closing.",False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/3655,Make problem 3.0.21,micron10,5,705170794,1,705170794,0,0,2020-09-20T19:33:40Z,"Hi i have small build system and try to build new freeradius 3.0.x i migrate from 2.2.10 and when migrate have this build problem 


make[2]: Entering directory '/build'
make -j 16 -C /build/buildorig/freeradius-server-3.0.21
make[3]: Entering directory '/build/buildorig/freeradius-server-3.0.21'
scripts/boiler.mk:628: /build/raddb/all.mk: No such file or directory
make[3]: *** No rule to make target '/build/raddb/all.mk'.  Stop.
make[3]: Leaving directory '/build/buildorig/freeradius-server-3.0.21'
make[2]: *** [package/freeradius/freeradius.mk:137: /build/buildorig/freeradius-server-3.0.21/.built] Error 2
make[2]: Leaving directory '/build'
make[1]: *** [Makefile:38: cross] Error 2
make[1]: Leaving directory '/build/'
make: *** [Makefile:32: all] Error 2


any help ",True,0,NONE
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/695838422,Make problem 3.0.21,jpereira,5,705170794,2,695838422,0,705170794,2020-09-20T21:24:41Z,Such comments belongs to the mailing list as can be seen in https://wiki.freeradius.org/guide/Users-Mailing-List,False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/695855394,Make problem 3.0.21,alandekok,5,705170794,3,695855394,0,695838422,2020-09-21T00:14:09Z,"The standard process of `configure`, `make`, and `make install` works.  I suspect you're not following that process.  Or, you're patching the make files.

Please explain _exactly_ what you're doing.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/695905374,Make problem 3.0.21,micron10,5,705170794,4,695905374,0,695855394,2020-09-21T05:22:13Z,"Hi  Alan

it is sample build system same that buildroot or other crosstool build
system.

i dont patch any in source .
Yes when i go im directory and run make all is fine

but when i run from outside script
check pwd and script run make in radius dir
but not set path for submake file



On Mon, Sep 21, 2020, 03:14 Alan DeKok <notifications@github.com> wrote:

> The standard process of configure, make, and make install works. I
> suspect you're not following that process. Or, you're patching the make
> files.
>
> Please explain *exactly* what you're doing.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/FreeRADIUS/freeradius-server/issues/3655#issuecomment-695855394>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ADCWD5BWC3URGZAP7TL6J2TSG2LFZANCNFSM4RTZ3EOA>
> .
>
",False,0,NONE
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/695913979,Make problem 3.0.21,micron10,5,705170794,5,695913979,0,695905374,2020-09-21T05:52:49Z,"I find a problem
in new Makefile freeradius use same variables that i use in my build system
( BUILD_DIR, TARGET_DIR ....)
and when i run from build system override this in radius Make..

hm..
how to easy fix this problem ..



На пн, 21.09.2020 г. в 8:21 Martin Zaharinov <micron10@gmail.com> написа:

> Hi  Alan
>
> it is sample build system same that buildroot or other crosstool build
> system.
>
> i dont patch any in source .
> Yes when i go im directory and run make all is fine
>
> but when i run from outside script
> check pwd and script run make in radius dir
> but not set path for submake file
>
>
>
> On Mon, Sep 21, 2020, 03:14 Alan DeKok <notifications@github.com> wrote:
>
>> The standard process of configure, make, and make install works. I
>> suspect you're not following that process. Or, you're patching the make
>> files.
>>
>> Please explain *exactly* what you're doing.
>>
>> —
>> You are receiving this because you authored the thread.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/FreeRADIUS/freeradius-server/issues/3655#issuecomment-695855394>,
>> or unsubscribe
>> <https://github.com/notifications/unsubscribe-auth/ADCWD5BWC3URGZAP7TL6J2TSG2LFZANCNFSM4RTZ3EOA>
>> .
>>
>
",False,0,NONE
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/696064065,Make problem 3.0.21,alandekok,5,705170794,6,696064065,0,695913979,2020-09-21T11:49:23Z,The solution is to spawn a shell with limited environment variables.  You can see the `make` documentation for how to *not* pass variables to a subshell.,False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/3680,Unable to use Python Module ````/usr/local/lib/rlm_python.so: undefined symbol: PyInt_AsLong````,gk-fschubert,3,717290138,1,717290138,0,0,2020-10-08T12:14:23Z,"- Defect - Crash or memory corruption.

# Defect description
Just want to write my own python module for RADIUS so i've started to enable the module and play around. 
Unfortunately the build server is not able to link the Module. 

## How to reproduce issue
* fresh Ubuntu 20.04 as lxc container
````
root@test-serv:~# lsb_release -a
No LSB modules are available.
Distributor ID: Ubuntu
Description:    Ubuntu 20.04.1 LTS
Release:        20.04
Codename:       focal
````
Install dependencies 
````
apt update -yq && apt upgrade -yq && apt install libc-dev libtalloc-dev libjson-c-dev openssl libssl-dev libpcre3 libpcre3-dev  libidn11-dev libkrb5-dev libcurl4-openssl-dev  python3-dev python3 python3-pip libhiredis-dev libmemcached-dev  gcc musl-dev libffi-dev -yq unzip
````
clone, unzip, configure and install FreeRADIUS Server
````
root@test-serv:~# wget https://github.com/FreeRADIUS/freeradius-server/archive/release_3_0_21.zip
root@test-serv:~# unzip release_3_0_21.zip
root@test-serv:~# cd freeradius-server-release_3_0_21/
root@test-serv:~# ./configure --with-raddbdir=/etc/raddb --with-openssl=yes --with-rlm_python=yes --with-rlm-python-bin=/usr/bin/python3
root@test-serv:~# make -j2
root@test-serv:~# make install
````
Add untouched python module to `radiusd.conf` in line 780
````
$INCLUDE mods-available/python
````

Start RADIUS server in Debug mode
````
root@test-serv:~# radiusd -X
FreeRADIUS Version 3.0.21
Copyright (C) 1999-2019 The FreeRADIUS server project and contributors
There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A
PARTICULAR PURPOSE
You may redistribute copies of FreeRADIUS under the terms of the
GNU General Public License
For more information about these matters, see the file named COPYRIGHT
Starting - reading configuration files ...
including dictionary file /usr/local/share/freeradius/dictionary
including dictionary file /usr/local/share/freeradius/dictionary.dhcp
including dictionary file /usr/local/share/freeradius/dictionary.vqp
including dictionary file /etc/raddb/dictionary
including configuration file /etc/raddb/radiusd.conf
including configuration file /etc/raddb/proxy.conf
including configuration file /etc/raddb/clients.conf
including files in directory /etc/raddb/mods-enabled/
including configuration file /etc/raddb/mods-enabled/always
including configuration file /etc/raddb/mods-enabled/attr_filter
including configuration file /etc/raddb/mods-enabled/cache_eap
including configuration file /etc/raddb/mods-enabled/chap
including configuration file /etc/raddb/mods-enabled/date
including configuration file /etc/raddb/mods-enabled/detail
including configuration file /etc/raddb/mods-enabled/detail.log
including configuration file /etc/raddb/mods-enabled/digest
including configuration file /etc/raddb/mods-enabled/dynamic_clients
including configuration file /etc/raddb/mods-enabled/eap
including configuration file /etc/raddb/mods-enabled/echo
including configuration file /etc/raddb/mods-enabled/exec
including configuration file /etc/raddb/mods-enabled/expiration
including configuration file /etc/raddb/mods-enabled/expr
including configuration file /etc/raddb/mods-enabled/files
including configuration file /etc/raddb/mods-enabled/linelog
including configuration file /etc/raddb/mods-enabled/logintime
including configuration file /etc/raddb/mods-enabled/mschap
including configuration file /etc/raddb/mods-enabled/ntlm_auth
including configuration file /etc/raddb/mods-enabled/pap
including configuration file /etc/raddb/mods-enabled/passwd
including configuration file /etc/raddb/mods-enabled/preprocess
including configuration file /etc/raddb/mods-enabled/radutmp
including configuration file /etc/raddb/mods-enabled/realm
including configuration file /etc/raddb/mods-enabled/replicate
including configuration file /etc/raddb/mods-enabled/soh
including configuration file /etc/raddb/mods-enabled/sradutmp
including configuration file /etc/raddb/mods-enabled/unix
including configuration file /etc/raddb/mods-enabled/unpack
including configuration file /etc/raddb/mods-enabled/utf8
including configuration file /etc/raddb/mods-available/python
including files in directory /etc/raddb/policy.d/
including configuration file /etc/raddb/policy.d/abfab-tr
including configuration file /etc/raddb/policy.d/accounting
including configuration file /etc/raddb/policy.d/canonicalization
including configuration file /etc/raddb/policy.d/control
including configuration file /etc/raddb/policy.d/cui
including configuration file /etc/raddb/policy.d/debug
including configuration file /etc/raddb/policy.d/dhcp
including configuration file /etc/raddb/policy.d/eap
including configuration file /etc/raddb/policy.d/filter
including configuration file /etc/raddb/policy.d/moonshot-targeted-ids
including configuration file /etc/raddb/policy.d/operator-name
including configuration file /etc/raddb/policy.d/rfc7542
including files in directory /etc/raddb/sites-enabled/
including configuration file /etc/raddb/sites-enabled/default
including configuration file /etc/raddb/sites-enabled/inner-tunnel
main {
 security {
        allow_core_dumps = no
 }
        name = ""radiusd""
        prefix = ""/usr/local""
        localstatedir = ""/usr/local/var""
        logdir = ""/usr/local/var/log/radius""
        run_dir = ""/usr/local/var/run/radiusd""
}
main {
        name = ""radiusd""
        prefix = ""/usr/local""
        localstatedir = ""/usr/local/var""
        sbindir = ""/usr/local/sbin""
        logdir = ""/usr/local/var/log/radius""
        run_dir = ""/usr/local/var/run/radiusd""
        libdir = ""/usr/local/lib""
        radacctdir = ""/usr/local/var/log/radius/radacct""
        hostname_lookups = no
        max_request_time = 30
        cleanup_delay = 5
        max_requests = 16384
        pidfile = ""/usr/local/var/run/radiusd/radiusd.pid""
        checkrad = ""/usr/local/sbin/checkrad""
        debug_level = 0
        proxy_requests = yes
 log {
        stripped_names = no
        auth = no
        auth_badpass = no
        auth_goodpass = no
        colourise = yes
        msg_denied = ""You are already logged in - access denied""
 }
 resources {
 }
 security {
        max_attributes = 200
        reject_delay = 1.000000
        status_server = yes
        allow_vulnerable_openssl = ""no""
 }
}
radiusd: #### Loading Realms and Home Servers ####
 proxy server {
        retry_delay = 5
        retry_count = 3
        default_fallback = no
        dead_time = 120
        wake_all_if_all_dead = no
 }
 home_server localhost {
        ipaddr = 127.0.0.1
        port = 1812
        type = ""auth""
        secret = <<< secret >>>
        response_window = 20.000000
        response_timeouts = 1
        max_outstanding = 65536
        zombie_period = 40
        status_check = ""status-server""
        ping_interval = 30
        check_interval = 30
        check_timeout = 4
        num_answers_to_alive = 3
        revive_interval = 120
  limit {
        max_connections = 16
        max_requests = 0
        lifetime = 0
        idle_timeout = 0
  }
  coa {
        irt = 2
        mrt = 16
        mrc = 5
        mrd = 30
  }
 }
 home_server_pool my_auth_failover {
        type = fail-over
        home_server = localhost
 }
 realm example.com {
        auth_pool = my_auth_failover
 }
 realm LOCAL {
 }
radiusd: #### Loading Clients ####
 client localhost {
        ipaddr = 127.0.0.1
        require_message_authenticator = no
        secret = <<< secret >>>
        nas_type = ""other""
        proto = ""*""
  limit {
        max_connections = 16
        lifetime = 0
        idle_timeout = 30
  }
 }
 client localhost_ipv6 {
        ipv6addr = ::1
        require_message_authenticator = no
        secret = <<< secret >>>
  limit {
        max_connections = 16
        lifetime = 0
        idle_timeout = 30
  }
 }
Debugger not attached
 # Creating Auth-Type = mschap
 # Creating Auth-Type = digest
 # Creating Auth-Type = eap
 # Creating Auth-Type = PAP
 # Creating Auth-Type = CHAP
 # Creating Auth-Type = MS-CHAP
radiusd: #### Instantiating modules ####
 modules {
  # Loaded module rlm_always
  # Loading module ""reject"" from file /etc/raddb/mods-enabled/always
  always reject {
        rcode = ""reject""
        simulcount = 0
        mpp = no
  }
  # Loading module ""fail"" from file /etc/raddb/mods-enabled/always
  always fail {
        rcode = ""fail""
        simulcount = 0
        mpp = no
  }
  # Loading module ""ok"" from file /etc/raddb/mods-enabled/always
  always ok {
        rcode = ""ok""
        simulcount = 0
        mpp = no
  }
  # Loading module ""handled"" from file /etc/raddb/mods-enabled/always
  always handled {
        rcode = ""handled""
        simulcount = 0
        mpp = no
  }
  # Loading module ""invalid"" from file /etc/raddb/mods-enabled/always
  always invalid {
        rcode = ""invalid""
        simulcount = 0
        mpp = no
  }
  # Loading module ""userlock"" from file /etc/raddb/mods-enabled/always
  always userlock {
        rcode = ""userlock""
        simulcount = 0
        mpp = no
  }
  # Loading module ""notfound"" from file /etc/raddb/mods-enabled/always
  always notfound {
        rcode = ""notfound""
        simulcount = 0
        mpp = no
  }
  # Loading module ""noop"" from file /etc/raddb/mods-enabled/always
  always noop {
        rcode = ""noop""
        simulcount = 0
        mpp = no
  }
  # Loading module ""updated"" from file /etc/raddb/mods-enabled/always
  always updated {
        rcode = ""updated""
        simulcount = 0
        mpp = no
  }
  # Loaded module rlm_attr_filter
  # Loading module ""attr_filter.post-proxy"" from file /etc/raddb/mods-enabled/attr_filter
  attr_filter attr_filter.post-proxy {
        filename = ""/etc/raddb/mods-config/attr_filter/post-proxy""
        key = ""%{Realm}""
        relaxed = no
  }
  # Loading module ""attr_filter.pre-proxy"" from file /etc/raddb/mods-enabled/attr_filter
  attr_filter attr_filter.pre-proxy {
        filename = ""/etc/raddb/mods-config/attr_filter/pre-proxy""
        key = ""%{Realm}""
        relaxed = no
  }
  # Loading module ""attr_filter.access_reject"" from file /etc/raddb/mods-enabled/attr_filter
  attr_filter attr_filter.access_reject {
        filename = ""/etc/raddb/mods-config/attr_filter/access_reject""
        key = ""%{User-Name}""
        relaxed = no
  }
  # Loading module ""attr_filter.access_challenge"" from file /etc/raddb/mods-enabled/attr_filter
  attr_filter attr_filter.access_challenge {
        filename = ""/etc/raddb/mods-config/attr_filter/access_challenge""
        key = ""%{User-Name}""
        relaxed = no
  }
  # Loading module ""attr_filter.accounting_response"" from file /etc/raddb/mods-enabled/attr_filter
  attr_filter attr_filter.accounting_response {
        filename = ""/etc/raddb/mods-config/attr_filter/accounting_response""
        key = ""%{User-Name}""
        relaxed = no
  }
  # Loaded module rlm_cache
  # Loading module ""cache_eap"" from file /etc/raddb/mods-enabled/cache_eap
  cache cache_eap {
        driver = ""rlm_cache_rbtree""
        key = ""%{%{control:State}:-%{%{reply:State}:-%{State}}}""
        ttl = 15
        max_entries = 0
        epoch = 0
        add_stats = no
  }
  # Loaded module rlm_chap
  # Loading module ""chap"" from file /etc/raddb/mods-enabled/chap
  # Loaded module rlm_date
  # Loading module ""date"" from file /etc/raddb/mods-enabled/date
  date {
        format = ""%b %e %Y %H:%M:%S %Z""
        utc = no
  }
  # Loading module ""wispr2date"" from file /etc/raddb/mods-enabled/date
  date wispr2date {
        format = ""%Y-%m-%dT%H:%M:%S""
        utc = no
  }
  # Loaded module rlm_detail
  # Loading module ""detail"" from file /etc/raddb/mods-enabled/detail
  detail {
        filename = ""/usr/local/var/log/radius/radacct/%{%{Packet-Src-IP-Address}:-%{Packet-Src-IPv6-Address}}/detail-%Y%m%d""
        header = ""%t""
        permissions = 384
        locking = no
        escape_filenames = no
        log_packet_header = no
  }
  # Loading module ""auth_log"" from file /etc/raddb/mods-enabled/detail.log
  detail auth_log {
        filename = ""/usr/local/var/log/radius/radacct/%{%{Packet-Src-IP-Address}:-%{Packet-Src-IPv6-Address}}/auth-detail-%Y%m%d""
        header = ""%t""
        permissions = 384
        locking = no
        escape_filenames = no
        log_packet_header = no
  }
  # Loading module ""reply_log"" from file /etc/raddb/mods-enabled/detail.log
  detail reply_log {
        filename = ""/usr/local/var/log/radius/radacct/%{%{Packet-Src-IP-Address}:-%{Packet-Src-IPv6-Address}}/reply-detail-%Y%m%d""
        header = ""%t""
        permissions = 384
        locking = no
        escape_filenames = no
        log_packet_header = no
  }
  # Loading module ""pre_proxy_log"" from file /etc/raddb/mods-enabled/detail.log
  detail pre_proxy_log {
        filename = ""/usr/local/var/log/radius/radacct/%{%{Packet-Src-IP-Address}:-%{Packet-Src-IPv6-Address}}/pre-proxy-detail-%Y%m%d""
        header = ""%t""
        permissions = 384
        locking = no
        escape_filenames = no
        log_packet_header = no
  }
  # Loading module ""post_proxy_log"" from file /etc/raddb/mods-enabled/detail.log
  detail post_proxy_log {
        filename = ""/usr/local/var/log/radius/radacct/%{%{Packet-Src-IP-Address}:-%{Packet-Src-IPv6-Address}}/post-proxy-detail-%Y%m%d""
        header = ""%t""
        permissions = 384
        locking = no
        escape_filenames = no
        log_packet_header = no
  }
  # Loaded module rlm_digest
  # Loading module ""digest"" from file /etc/raddb/mods-enabled/digest
  # Loaded module rlm_dynamic_clients
  # Loading module ""dynamic_clients"" from file /etc/raddb/mods-enabled/dynamic_clients
  # Loaded module rlm_eap
  # Loading module ""eap"" from file /etc/raddb/mods-enabled/eap
  eap {
        default_eap_type = ""md5""
        timer_expire = 60
        ignore_unknown_eap_types = no
        cisco_accounting_username_bug = no
        max_sessions = 16384
  }
  # Loaded module rlm_exec
  # Loading module ""echo"" from file /etc/raddb/mods-enabled/echo
  exec echo {
        wait = yes
        program = ""/bin/echo %{User-Name}""
        input_pairs = ""request""
        output_pairs = ""reply""
        shell_escape = yes
  }
  # Loading module ""exec"" from file /etc/raddb/mods-enabled/exec
  exec {
        wait = no
        input_pairs = ""request""
        shell_escape = yes
        timeout = 10
  }
  # Loaded module rlm_expiration
  # Loading module ""expiration"" from file /etc/raddb/mods-enabled/expiration
  # Loaded module rlm_expr
  # Loading module ""expr"" from file /etc/raddb/mods-enabled/expr
  expr {
        safe_characters = ""@abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789.-_: /äéöüàâæçèéêëîïôœùûüaÿÄÉÖÜßÀÂÆÇÈÉÊËÎÏÔŒÙÛÜŸ""
  }
  # Loaded module rlm_files
  # Loading module ""files"" from file /etc/raddb/mods-enabled/files
  files {
        filename = ""/etc/raddb/mods-config/files/authorize""
        acctusersfile = ""/etc/raddb/mods-config/files/accounting""
        preproxy_usersfile = ""/etc/raddb/mods-config/files/pre-proxy""
  }
  # Loaded module rlm_linelog
  # Loading module ""linelog"" from file /etc/raddb/mods-enabled/linelog
  linelog {
        filename = ""/usr/local/var/log/radius/linelog""
        escape_filenames = no
        syslog_severity = ""info""
        permissions = 384
        format = ""This is a log message for %{User-Name}""
        reference = ""messages.%{%{reply:Packet-Type}:-default}""
  }
  # Loading module ""log_accounting"" from file /etc/raddb/mods-enabled/linelog
  linelog log_accounting {
        filename = ""/usr/local/var/log/radius/linelog-accounting""
        escape_filenames = no
        syslog_severity = ""info""
        permissions = 384
        format = """"
        reference = ""Accounting-Request.%{%{Acct-Status-Type}:-unknown}""
  }
  # Loaded module rlm_logintime
  # Loading module ""logintime"" from file /etc/raddb/mods-enabled/logintime
  logintime {
        minimum_timeout = 60
  }
  # Loaded module rlm_mschap
  # Loading module ""mschap"" from file /etc/raddb/mods-enabled/mschap
  mschap {
        use_mppe = yes
        require_encryption = no
        require_strong = no
        with_ntdomain_hack = yes
   passchange {
   }
        allow_retry = yes
        winbind_retry_with_normalised_username = no
  }
  # Loading module ""ntlm_auth"" from file /etc/raddb/mods-enabled/ntlm_auth
  exec ntlm_auth {
        wait = yes
        program = ""/path/to/ntlm_auth --request-nt-key --domain=MYDOMAIN --username=%{mschap:User-Name} --password=%{User-Password}""
        shell_escape = yes
  }
  # Loaded module rlm_pap
  # Loading module ""pap"" from file /etc/raddb/mods-enabled/pap
  pap {
        normalise = yes
  }
  # Loaded module rlm_passwd
  # Loading module ""etc_passwd"" from file /etc/raddb/mods-enabled/passwd
  passwd etc_passwd {
        filename = ""/etc/passwd""
        format = ""*User-Name:Crypt-Password:""
        delimiter = "":""
        ignore_nislike = no
        ignore_empty = yes
        allow_multiple_keys = no
        hash_size = 100
  }
  # Loaded module rlm_preprocess
  # Loading module ""preprocess"" from file /etc/raddb/mods-enabled/preprocess
  preprocess {
        huntgroups = ""/etc/raddb/mods-config/preprocess/huntgroups""
        hints = ""/etc/raddb/mods-config/preprocess/hints""
        with_ascend_hack = no
        ascend_channels_per_line = 23
        with_ntdomain_hack = no
        with_specialix_jetstream_hack = no
        with_cisco_vsa_hack = no
        with_alvarion_vsa_hack = no
  }
  # Loaded module rlm_radutmp
  # Loading module ""radutmp"" from file /etc/raddb/mods-enabled/radutmp
  radutmp {
        filename = ""/usr/local/var/log/radius/radutmp""
        username = ""%{User-Name}""
        case_sensitive = yes
        check_with_nas = yes
        permissions = 384
        caller_id = yes
  }
  # Loaded module rlm_realm
  # Loading module ""IPASS"" from file /etc/raddb/mods-enabled/realm
  realm IPASS {
        format = ""prefix""
        delimiter = ""/""
        ignore_default = no
        ignore_null = no
  }
  # Loading module ""suffix"" from file /etc/raddb/mods-enabled/realm
  realm suffix {
        format = ""suffix""
        delimiter = ""@""
        ignore_default = no
        ignore_null = no
  }
  # Loading module ""bangpath"" from file /etc/raddb/mods-enabled/realm
  realm bangpath {
        format = ""prefix""
        delimiter = ""!""
        ignore_default = no
        ignore_null = no
  }
  # Loading module ""realmpercent"" from file /etc/raddb/mods-enabled/realm
  realm realmpercent {
        format = ""suffix""
        delimiter = ""%""
        ignore_default = no
        ignore_null = no
  }
  # Loading module ""ntdomain"" from file /etc/raddb/mods-enabled/realm
  realm ntdomain {
        format = ""prefix""
        delimiter = ""\\""
        ignore_default = no
        ignore_null = no
  }
  # Loaded module rlm_replicate
  # Loading module ""replicate"" from file /etc/raddb/mods-enabled/replicate
  # Loaded module rlm_soh
  # Loading module ""soh"" from file /etc/raddb/mods-enabled/soh
  soh {
        dhcp = yes
  }
  # Loading module ""sradutmp"" from file /etc/raddb/mods-enabled/sradutmp
  radutmp sradutmp {
        filename = ""/usr/local/var/log/radius/sradutmp""
        username = ""%{User-Name}""
        case_sensitive = yes
        check_with_nas = yes
        permissions = 420
        caller_id = no
  }
  # Loaded module rlm_unix
  # Loading module ""unix"" from file /etc/raddb/mods-enabled/unix
  unix {
        radwtmp = ""/usr/local/var/log/radius/radwtmp""
  }
Creating attribute Unix-Group
  # Loaded module rlm_unpack
  # Loading module ""unpack"" from file /etc/raddb/mods-enabled/unpack
  # Loaded module rlm_utf8
  # Loading module ""utf8"" from file /etc/raddb/mods-enabled/utf8
/etc/raddb/mods-available/python[9]: Failed to link to module 'rlm_python': /usr/local/lib/rlm_python.so: undefined symbol: PyInt_AsLong
````
",True,0,NONE
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/705529651,Unable to use Python Module ````/usr/local/lib/rlm_python.so: undefined symbol: PyInt_AsLong````,alandekok,3,717290138,2,705529651,0,717290138,2020-10-08T12:17:59Z,"`--with-rlm_python=yes --with-rlm-python-bin=/usr/bin/python3`

this is wrong.  The `rlm_python` module is for python2.  For python3, use the `rlm_python3`module.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/705534887,Unable to use Python Module ````/usr/local/lib/rlm_python.so: undefined symbol: PyInt_AsLong````,gk-fschubert,3,717290138,3,705534887,0,705529651,2020-10-08T12:28:43Z,"@alandekok tried it with different options. After reading trough feature requests and release notes it sounds that in build 3.0.21 module ""rlm_python3"" is obsolete because the default for ""rlm_python"" is now python3 
The issue is the same when the server was build with:

````--with-rlm_python3=yes````
",False,0,NONE
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/705540549,Unable to use Python Module ````/usr/local/lib/rlm_python.so: undefined symbol: PyInt_AsLong````,alandekok,3,717290138,4,705540549,0,705534887,2020-10-08T12:40:12Z,"The release notes do not say that.

The `rlm_python` module is for Python 2.  The `rlm_python3` module is for Python3.  I did NOT lie to you in my previous response.  And as I wrote the release notes, I know exactly what they say.

If the error is the same with python3, then I suggest trying the v3.0.x branch from github.  It has a bunch of more fixes.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/3685,DHCP: Dedicated rlm_sql instance to support option lookup,terryburton,3,719467028,1,719467028,0,0,2020-10-12T15:25:30Z,"New dhcp_sql instance of rlm_sql for use with DHCP:

  - Separate queries.conf and schema.sql, etc. for DHCP vs RADIUS.
  - Group lookup is disabled by default and there are no check queries provided
    to reduce query load for typical use cases.
  - No accounting-related configuration items and queries.

The schema provides dhcpreply, dhcpgroupreply and dhcpgroup (née ""usergroup"")
tables as per corresponding RADIUS authorize schema, except:

  - Rename column Username -> Identifier since the lookup key varies based on
    ""contexts"". There will typically be multiple option merges from different
    context to set network-specific options, device-specific options, classes,
    etc.
    - Set Identifier for lookup using the DHCP-SQL-Option-Identifier internal
      attribute (which gets escaped into SQL-User-Name, as usual).
  - Add a Context column (""network"", ""subnet"", ""group"", ""class-abc"", etc.) to
    support lookups using the same tables but with the options data partitioned
    between contexts.
    - Set current Context using the DHCP-SQL-Option-Context internal attribute.
      This is not SQL escaped, however it is not set from tainted data.

Example policy for performing SQL options lookup from SQL provided in
policy.d/dhcp.",True,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/707187889,DHCP: Dedicated rlm_sql instance to support option lookup,terryburton,3,719467028,2,707187889,0,719467028,2020-10-12T15:26:02Z,@ndptech FYI.,False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/708457697,DHCP: Dedicated rlm_sql instance to support option lookup,alandekok,3,719467028,3,708457697,0,707187889,2020-10-14T14:55:07Z,This looks ready for merging.  Any objections?,False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/708458412,DHCP: Dedicated rlm_sql instance to support option lookup,arr2036,3,719467028,4,708458412,0,708457697,2020-10-14T14:56:13Z,Not from me,False,0,MEMBER
https://api.github.com/repos/nextcloud/server/issues/23034,Fix numeric folders throwing on markDirty,nickvergessen,3,708153303,1,708153303,0,0,2020-09-24T13:03:40Z,"TypeError: strpos() expects parameter 1 to be string, int given

The problem is that in cacheNode() we strip of any slashes, so
a folder `0/` will be trimmed to `'0'` and be used as an array key.
Since PHP automatically casts numeric array keys to integers,
you afterwards get $nodePath as int(0). Since it's now a number,
the strpos() function does not accept it anymore. Simply casting
$nodePath to a string again in the foreach solves the issue",True,0,MEMBER
https://api.github.com/repos/nextcloud/server/issues/comments/698910927,Fix numeric folders throwing on markDirty,nickvergessen,3,708153303,2,698910927,0,708153303,2020-09-25T12:53:07Z,Backport I guess?,False,0,MEMBER
https://api.github.com/repos/nextcloud/server/issues/comments/698919822,Fix numeric folders throwing on markDirty,rullzer,3,708153303,3,698919822,0,698910927,2020-09-25T13:11:44Z,/backport to stable20,False,0,MEMBER
https://api.github.com/repos/nextcloud/server/issues/comments/698919890,Fix numeric folders throwing on markDirty,rullzer,3,708153303,4,698919890,0,698919822,2020-09-25T13:11:49Z,/backport to stable19,False,0,MEMBER
https://api.github.com/repos/nextcloud/server/issues/23035,Remove md5 from js globals,rullzer,4,708172545,1,708172545,0,0,2020-09-24T13:28:59Z,"In our fight against bit waste this is a few kb saves.

Signed-off-by: Roeland Jago Douma <roeland@famdouma.nl>",True,0,MEMBER
https://api.github.com/repos/nextcloud/server/issues/comments/698429893,Remove md5 from js globals,faily-bot[bot],4,708172545,2,698429893,0,708172545,2020-09-24T15:48:26Z,"🤖 beep boop beep 🤖

Here are the logs for the failed build:

### Status of [33366](https://drone.nextcloud.com/nextcloud/server/33366): failure

#### jsunit
<details><summary>Show full log</summary>

```
PhantomJS 2.1.1 (Linux 0.0.0) WARN: 'No OC found'
PhantomJS 2.1.1 (Linux 0.0.0) LOG: 'JQMIGRATE: Migrate is installed, version 1.4.1'
PhantomJS 2.1.1 (Linux 0.0.0) WARN: 'jQuery is deprecated: The global jQuery is deprecated. It will be updated to v3.x in Nextcloud 21. In later versions of Nextcloud it might be removed completely. Please ship your own.'
PhantomJS 2.1.1 (Linux 0.0.0) WARN: '$ is deprecated: The global jQuery is deprecated. It will be updated to v3.x in Nextcloud 21. In later versions of Nextcloud it might be removed completely. Please ship your own.'
PhantomJS 2.1.1 (Linux 0.0.0) WARN: 'Handlebars is deprecated: please ship your own, this will be removed in Nextcloud 20'
PhantomJS 2.1.1 (Linux 0.0.0) DEBUG: 'OCA.Files.Settings initialized'
PhantomJS 2.1.1 (Linux 0.0.0) DEBUG: 'OCA.Files.Sidebar initialized'
PhantomJS 2.1.1 (Linux 0.0.0) DEBUG: 'OCA.Sharing.ShareSearch initialized'
PhantomJS 2.1.1 (Linux 0.0.0) DEBUG: 'OCA.Sharing.ExternalLinkActions initialized'
PhantomJS 2.1.1 (Linux 0.0.0) OC.Upload tests Adding files for upload adds file when size is below limits FAILED
	ReferenceError: Can't find variable: md5 in apps/files/js/file-upload.js (line 42)
	FileUpload@apps/files/js/file-upload.js:42:36
	add@apps/files/js/file-upload.js:923:36
	apps/files/tests/js/fileUploadSpec.js:75:41
	dt@core/js/dist/main.js:1:317613
	addFiles@apps/files/tests/js/fileUploadSpec.js:65:15
	apps/files/tests/js/fileUploadSpec.js:88:25
PhantomJS 2.1.1 (Linux 0.0.0) OC.Upload tests Adding files for upload adds file when free space is unknown FAILED
	ReferenceError: Can't find variable: md5 in apps/files/js/file-upload.js (line 42)
	FileUpload@apps/files/js/file-upload.js:42:36
	add@apps/files/js/file-upload.js:923:36
	apps/files/tests/js/fileUploadSpec.js:75:41
	dt@core/js/dist/main.js:1:317613
	addFiles@apps/files/tests/js/fileUploadSpec.js:65:15
	apps/files/tests/js/fileUploadSpec.js:99:21
PhantomJS 2.1.1 (Linux 0.0.0) OC.Upload tests Adding files for upload does not add file if it exceeds free space FAILED
	ReferenceError: Can't find variable: md5 in apps/files/js/file-upload.js (line 42)
	FileUpload@apps/files/js/file-upload.js:42:36
	add@apps/files/js/file-upload.js:923:36
	apps/files/tests/js/fileUploadSpec.js:75:41
	dt@core/js/dist/main.js:1:317613
	addFiles@apps/files/tests/js/fileUploadSpec.js:65:15
	apps/files/tests/js/fileUploadSpec.js:119:21
PhantomJS 2.1.1 (Linux 0.0.0) OC.Upload tests Upload conflicts does not show conflict dialog when no client side conflict FAILED
	ReferenceError: Can't find variable: md5 in apps/files/js/file-upload.js (line 42)
	FileUpload@apps/files/js/file-upload.js:42:36
	add@apps/files/js/file-upload.js:923:36
	apps/files/tests/js/fileUploadSpec.js:75:41
	dt@core/js/dist/main.js:1:317613
	addFiles@apps/files/tests/js/fileUploadSpec.js:65:15
	apps/files/tests/js/fileUploadSpec.js:181:25
PhantomJS 2.1.1 (Linux 0.0.0) OC.Upload tests Upload conflicts shows conflict dialog when no client side conflict FAILED
	ReferenceError: Can't find variable: md5 in apps/files/js/file-upload.js (line 42)
	FileUpload@apps/files/js/file-upload.js:42:36
	add@apps/files/js/file-upload.js:923:36
	apps/files/tests/js/fileUploadSpec.js:75:41
	dt@core/js/dist/main.js:1:317613
	addFiles@apps/files/tests/js/fileUploadSpec.js:65:15
	apps/files/tests/js/fileUploadSpec.js:215:25
PhantomJS 2.1.1 (Linux 0.0.0) OC.Upload tests Upload conflicts cancels upload when skipping file in conflict mode FAILED
	ReferenceError: Can't find variable: md5 in apps/files/js/file-upload.js (line 42)
	FileUpload@apps/files/js/file-upload.js:42:36
	add@apps/files/js/file-upload.js:923:36
	apps/files/tests/js/fileUploadSpec.js:75:41
	dt@core/js/dist/main.js:1:317613
	addFiles@apps/files/tests/js/fileUploadSpec.js:65:15
	apps/files/tests/js/fileUploadSpec.js:224:29
PhantomJS 2.1.1 (Linux 0.0.0) OC.Upload tests Upload conflicts overwrites file when choosing replace in conflict mode FAILED
	ReferenceError: Can't find variable: md5 in apps/files/js/file-upload.js (line 42)
	FileUpload@apps/files/js/file-upload.js:42:36
	add@apps/files/js/file-upload.js:923:36
	apps/files/tests/js/fileUploadSpec.js:75:41
	dt@core/js/dist/main.js:1:317613
	addFiles@apps/files/tests/js/fileUploadSpec.js:65:15
	apps/files/tests/js/fileUploadSpec.js:239:29
PhantomJS 2.1.1 (Linux 0.0.0) OC.Upload tests Upload conflicts autorenames file when choosing replace in conflict mode FAILED
	ReferenceError: Can't find variable: md5 in apps/files/js/file-upload.js (line 42)
	FileUpload@apps/files/js/file-upload.js:42:36
	add@apps/files/js/file-upload.js:923:36
	apps/files/tests/js/fileUploadSpec.js:75:41
	dt@core/js/dist/main.js:1:317613
	addFiles@apps/files/tests/js/fileUploadSpec.js:65:15
	apps/files/tests/js/fileUploadSpec.js:257:29
PhantomJS 2.1.1 (Linux 0.0.0): Executed 847 of 850 (8 FAILED) (skipped 3) (10.622 secs / 10.044 secs)

```
</details>


#### mysql5.6-php7.3
 * I'm a little sad 🤖 and was not able to find the logs for this failed job - please improve me at https://github.com/MorrisJobke/drone-logs to provide this to you
",False,0,NONE
https://api.github.com/repos/nextcloud/server/issues/comments/703887523,Remove md5 from js globals,MorrisJobke,4,708172545,3,703887523,0,698429893,2020-10-05T21:03:22Z,The file upload seems to still need it 🙈 ,False,0,MEMBER
https://api.github.com/repos/nextcloud/server/issues/comments/704099109,Remove md5 from js globals,ChristophWurst,4,708172545,4,704099109,0,703887523,2020-10-06T07:56:09Z,"> [ChristophWurst](/ChristophWurst) added the [pending documentation](/nextcloud/server/labels/pending%20documentation) label [now](#event-3843993694)

Please please please always add this. Otherwise we will forget to document this critical change :pray: ",False,0,MEMBER
https://api.github.com/repos/nextcloud/server/issues/comments/704216988,Remove md5 from js globals,MorrisJobke,4,708172545,5,704216988,0,704099109,2020-10-06T11:52:58Z,"> Please please please always add this. Otherwise we will forget to document this critical change 🙏

![tenor](https://user-images.githubusercontent.com/245432/95198250-38f8e500-07db-11eb-952c-96cb2e3436fc.gif)
",False,0,MEMBER
https://api.github.com/repos/nextcloud/server/issues/23036,Activity notifications for groupmates by Comments (when using Group Folder app),chrisfritsche,14,708196696,1,708196696,0,0,2020-09-24T13:57:58Z,"Currently:
Comments on files in group folders does not generate activity notifications for the groupmates.

With this PR:
Also include groupmates to receive the notifications.",True,0,NONE
https://api.github.com/repos/nextcloud/server/issues/comments/698367952,Activity notifications for groupmates by Comments (when using Group Folder app),chrisfritsche,14,708196696,2,698367952,0,708196696,2020-09-24T14:07:06Z,"Hi @nickvergessen and @ChristophWurst ! Pls, when you have time, could you make the review on this PR? Thanks a lot in advance!!",False,0,NONE
https://api.github.com/repos/nextcloud/server/issues/comments/707148770,Activity notifications for groupmates by Comments (when using Group Folder app),nickvergessen,14,708196696,3,707148770,0,698367952,2020-10-12T14:17:27Z,/backport to stable20,False,0,MEMBER
https://api.github.com/repos/nextcloud/server/issues/comments/728106783,Activity notifications for groupmates by Comments (when using Group Folder app),nickvergessen,14,708196696,4,728106783,0,707148770,2020-11-16T14:44:22Z,@chrisfritsche can you rebase one last time?,False,0,MEMBER
https://api.github.com/repos/nextcloud/server/issues/comments/756375557,Activity notifications for groupmates by Comments (when using Group Folder app),MorrisJobke,14,708196696,5,756375557,0,728106783,2021-01-07T20:49:13Z,"> @chrisfritsche can you rebase one last time?

I rebased.",False,0,MEMBER
https://api.github.com/repos/nextcloud/server/issues/comments/756643195,Activity notifications for groupmates by Comments (when using Group Folder app),rullzer,14,708196696,6,756643195,0,756375557,2021-01-08T09:14:34Z,"CI is not happy
",False,0,MEMBER
https://api.github.com/repos/nextcloud/server/issues/comments/771973541,Activity notifications for groupmates by Comments (when using Group Folder app),rullzer,14,708196696,7,771973541,0,756643195,2021-02-02T20:49:04Z,"Master is Nextcloud 22 now.
If this should go into 21 it should be backported.",False,0,MEMBER
https://api.github.com/repos/nextcloud/server/issues/comments/801247202,Activity notifications for groupmates by Comments (when using Group Folder app),PVince81,14,708196696,8,801247202,0,771973541,2021-03-17T16:56:39Z,"CI not happy, but could be outdated. Needs another rebase, then :-S",False,0,MEMBER
https://api.github.com/repos/nextcloud/server/issues/comments/828423746,Activity notifications for groupmates by Comments (when using Group Folder app),J0WI,14,708196696,9,828423746,0,801247202,2021-04-28T12:43:05Z,The drone test fails in all recent PRs,False,0,CONTRIBUTOR
https://api.github.com/repos/nextcloud/server/issues/comments/844951948,Activity notifications for groupmates by Comments (when using Group Folder app),MorrisJobke,14,708196696,10,844951948,0,828423746,2021-05-20T10:16:21Z,@nickvergessen Should we try to get this in or close it for now?,False,0,MEMBER
https://api.github.com/repos/nextcloud/server/issues/comments/845864454,Activity notifications for groupmates by Comments (when using Group Folder app),nickvergessen,14,708196696,11,845864454,0,844951948,2021-05-21T10:50:40Z,Fine by me as per https://github.com/nextcloud/server/pull/23036#issuecomment-728106783,False,0,MEMBER
https://api.github.com/repos/nextcloud/server/issues/comments/845939734,Activity notifications for groupmates by Comments (when using Group Folder app),juliushaertl,14,708196696,12,845939734,0,845864454,2021-05-21T13:10:44Z,"Tests are not happy:

```
1) OCA\Comments\Tests\Unit\Activity\ListenerTest::testCommentEvent
ArgumentCountError: Too few arguments to function OCA\Comments\Activity\Listener::__construct(), 6 passed in /drone/src/apps/comments/tests/Unit/Activity/ListenerTest.php on line 84 and exactly 7 expected

/drone/src/apps/comments/lib/Activity/Listener.php:68
/drone/src/apps/comments/tests/Unit/Activity/ListenerTest.php:84
```",False,0,MEMBER
https://api.github.com/repos/nextcloud/server/issues/comments/852861694,Activity notifications for groupmates by Comments (when using Group Folder app),blizzz,14,708196696,13,852861694,0,845939734,2021-06-02T09:22:46Z,@chrisfritsche do you mind checking https://github.com/nextcloud/server/pull/23036#issuecomment-845939734,False,0,MEMBER
https://api.github.com/repos/nextcloud/server/issues/comments/942127419,Activity notifications for groupmates by Comments (when using Group Folder app),skjnldsv,14,708196696,14,942127419,0,852861694,2021-10-13T09:53:22Z,/rebase,False,0,MEMBER
https://api.github.com/repos/nextcloud/server/issues/comments/1458679321,Activity notifications for groupmates by Comments (when using Group Folder app),blizzz,14,708196696,15,1458679321,0,942127419,2023-03-07T19:04:38Z,Closing for inactivity. ,False,0,MEMBER
https://api.github.com/repos/nextcloud/server/issues/23039,Set language at user creation on WebUI,solracsf,4,708272410,1,708272410,0,0,2020-09-24T15:33:00Z,The ability to set the language on the user creation form could be something useful on a multi user environment.,True,0,MEMBER
https://api.github.com/repos/nextcloud/server/issues/comments/703806144,Set language at user creation on WebUI,gratuxri,4,708272410,2,703806144,0,708272410,2020-10-05T18:22:59Z,"Hello, I'm not sure, if this is a good idea, because of browser language setting, also if someone choose in browser preffered language, this language shoud use nextcloud. What do you think about that?",False,0,NONE
https://api.github.com/repos/nextcloud/server/issues/comments/703809368,Set language at user creation on WebUI,solracsf,4,708272410,3,703809368,0,703806144,2020-10-05T18:28:45Z,"My main problem is the welcome email language at user creation. If i set the user language to be Russian, welcome email should be sent in Russian. User has then the ability to change language if he wants to.",False,0,MEMBER
https://api.github.com/repos/nextcloud/server/issues/comments/723508519,Set language at user creation on WebUI,skjnldsv,4,708272410,4,723508519,0,703809368,2020-11-07T23:31:45Z,Might be easier to add with https://github.com/nextcloud/server/pull/23529,False,0,MEMBER
https://api.github.com/repos/nextcloud/server/issues/comments/1873365912,Set language at user creation on WebUI,joshtrichards,4,708272410,5,1873365912,0,723508519,2024-01-01T15:13:39Z,"I can't find the associated PR, but this is done in NC28:

![image](https://github.com/nextcloud/server/assets/1731941/13fd391d-c45c-4132-8f12-4937afe2b43e)

EDIT: And older versions too. As long as *Users->Settings->Show languages* is toggled on",False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/4335,Removal of getSQLResultCasing without alternative breaks ORM assumptions,beberlei,8,718882247,1,718882247,0,0,2020-10-11T17:13:35Z,"### BC Break Report

The ORM currently does not quote any identifier. This means the default case for unquoted columns of each database is used, which is a.) depends on server config for MySQL, but by default its case used at creation b.) lowercase for postgresql c.) uppercase for Oracle.

To allow the ORM to support arbitrary databases, the platform must need to know what this behavior is of each platform, so that when it fetches the result of an SQL query without quoted identifiers it can access the values correctly.

When you declare a field in the ORM with for example `<field name=""name"" />` then the quoting strategy uses `AbstractPlatform::getSQLResultCasing` to determine if the column for this field is `name` or `NAME`.

|    Q        |   A
|------------ | ------
| BC Break    | yes
| Version     | 3.0.0

#### Summary

`AbstractPlatform::getSQLResultCasing` was removed, is platform specific behavior needed in ORM. ORM can't offer this abstraction itself as it depends on Platform.",True,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/comments/709670745,Removal of getSQLResultCasing without alternative breaks ORM assumptions,morozov,8,718882247,2,709670745,0,718882247,2020-10-16T01:10:46Z,"As discussed offline, instead of mimicking the behavior of a specific database platform by using the API above, consumers may use the portability layer and normalize the behavior instead. @beberlei please let me know if you expect more work to be done on this issue.",False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/comments/725513698,Removal of getSQLResultCasing without alternative breaks ORM assumptions,morozov,8,718882247,3,725513698,0,709670745,2020-11-11T16:13:26Z,"As discussed offline, using the portability layer is the proper way to address this issue in consumers.",False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/comments/901630471,Removal of getSQLResultCasing without alternative breaks ORM assumptions,greg0ire,8,718882247,4,901630471,0,725513698,2021-08-19T05:52:47Z,"@morozov to be clear, this means calls to `getSQLResultCasing` should be removed from the ORM, and people should be advised to use https://github.com/doctrine/dbal/blob/3.1.x/docs/en/reference/portability.rst ?",False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/comments/901643891,Removal of getSQLResultCasing without alternative breaks ORM assumptions,morozov,8,718882247,5,901643891,0,901630471,2021-08-19T06:23:14Z,"In my understanding, the ORM itself currently relies on the column casing, so it should be using the portability middleware instead.",False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/comments/901654846,Removal of getSQLResultCasing without alternative breaks ORM assumptions,greg0ire,8,718882247,6,901654846,0,901643891,2021-08-19T06:47:56Z,"Ok, so in `Doctrine\ORM\Configuration::__construct()`, there should be the following call: `$this->setMiddlewares([new \Doctrine\DBAL\PortabilityMiddleware(NOT_SURE_WHAT_TO_PASS_HERE, NOT_SURE_WHAT_TO_PASS_HERE_EITHER)])`?",False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/comments/901693839,Removal of getSQLResultCasing without alternative breaks ORM assumptions,beberlei,8,718882247,7,901693839,0,901654846,2021-08-19T07:56:02Z,Referencing https://github.com/doctrine/orm/issues/8887 here as the first step in the 2.x branches.,False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/comments/902028697,Removal of getSQLResultCasing without alternative breaks ORM assumptions,morozov,8,718882247,8,902028697,0,901693839,2021-08-19T15:52:31Z,"The arguments should be `(Connection::PORTABILITY_FIX_CASE, ColumnCase::LOWER)`.",False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/comments/1193429382,Removal of getSQLResultCasing without alternative breaks ORM assumptions,github-actions[bot],8,718882247,9,1193429382,0,902028697,2022-07-25T00:23:16Z,This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.,False,0,NONE
https://api.github.com/repos/doctrine/dbal/issues/4337,Rename Comparator::diffTable() params - from/to instead of 1/2,mvorisek,7,719712881,1,719712881,0,0,2020-10-12T22:36:22Z,"|      Q       |   A
|------------- | -----------
| Type         | improvement
| BC Break     | no
| Fixed issues | no issue, pure refactor

#### Summary

swapping input of `Comparator::diffTable` will produce completely different result - the first gven table is expected to be the ""from"" table and the 2nd table is expected to be the ""to"" table

the names are also consistent with `Comparator::compare` (which uses `$fromSchema`, `$toSchema` names)

no more changes in `Comparator` class needed - `Comparator::diffSequence` uses `$sequence1` and `$sequence2` names, but the inputs can be swapped, so these names should stay",True,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/dbal/issues/comments/707524381,Rename Comparator::diffTable() params - from/to instead of 1/2,greg0ire,7,719712881,2,707524381,0,719712881,2020-10-13T06:37:07Z,"Please kindly squash your commits together. If you don't, we'll try to remember to do it for you but it's best if you save us this trouble.",False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/comments/707574335,Rename Comparator::diffTable() params - from/to instead of 1/2,mvorisek,7,719712881,3,707574335,0,707524381,2020-10-13T08:15:50Z,@greg0ire squashed,False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/dbal/issues/comments/709483123,Rename Comparator::diffTable() params - from/to instead of 1/2,greg0ire,7,719712881,4,709483123,0,707574335,2020-10-15T17:39:12Z,Rebasing because of new pipeline,False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/comments/709504675,Rename Comparator::diffTable() params - from/to instead of 1/2,greg0ire,7,719712881,5,709504675,0,709483123,2020-10-15T18:17:54Z,"Thanks @mvorisek !

@morozov Codecov is behaving a bit weird, it seems to need time to process the ~50 reports we send, then it show the right percentage diff in Github's UI, but in its own UI, it's correct in some places, outdated and alarming in some others, for example the Coverage change tab is wrong and so is the Overview graph cc @thomasrockhu ",False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/comments/709512021,Rename Comparator::diffTable() params - from/to instead of 1/2,thomasrockhu,7,719712881,6,709512021,0,709504675,2020-10-15T18:29:18Z,"@greg0ire, this is indeed strange. Would you be able to open a ticket in our community boards? I'll take a look.",False,0,NONE
https://api.github.com/repos/doctrine/dbal/issues/comments/709519213,Rename Comparator::diffTable() params - from/to instead of 1/2,greg0ire,7,719712881,7,709519213,0,709512021,2020-10-15T18:42:16Z,"Looks like it's fixed now, it just seems to take a lot of time. Should I still open the ticket? It will be hard for you to investigate anything I'm afraid.",False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/comments/709521797,Rename Comparator::diffTable() params - from/to instead of 1/2,thomasrockhu,7,719712881,8,709521797,0,709519213,2020-10-15T18:46:26Z,"@greg0ire, ah got it. I'll keep an eye out, but if you see it happening, please feel free to open.",False,0,NONE
https://api.github.com/repos/doctrine/dbal/issues/4339,Added filtered index support for SQL Server,cziegenberg,3,719942966,1,719942966,0,0,2020-10-13T07:13:03Z,"|      Q       |   A
|------------- | -----------
| Type         | improvement
| BC Break     | no
| Fixed issues | #3038

#### Summary

Added support for filtered (or partial) indexes in SQL Server (supported since version 2008). This is the second version after the closed pull request #4240. It contains the implementation for SQL Server only. I will try to add the implementation for SQLite later, in a separate pull request.

The implementation has the following limitation (same as with other platforms like PostgreSQL, see #3871):
The given ""where"" option may be modified by the server. So when reading it again for comparison, the result may differ, which can result in an unnecessary update when creating a migration. This depends on how the ""where"" option is defined and especially occurrs in case of unique constraints, because for each indexed column in SQL Server a ""IS NOT NULL"" filter is added automatically by DBAL (for compatibility with other platforms and the SQL standard). This has to be solved globally (i.e. by saving the original value as a comment or adding a normalization step before the comparison) and is independent of this pull request.
",True,0,NONE
https://api.github.com/repos/doctrine/dbal/issues/comments/707591423,Added filtered index support for SQL Server,cziegenberg,3,719942966,2,707591423,0,719942966,2020-10-13T08:45:37Z,"@morozov As requested, I created an updated pull request for the right branch and with additional tests. Would be great if you could review it once again. Thanks.",False,0,NONE
https://api.github.com/repos/doctrine/dbal/issues/comments/708064658,Added filtered index support for SQL Server,morozov,3,719942966,3,708064658,0,707591423,2020-10-13T23:31:33Z,"@cziegenberg since `2.11.0` has been released, `2.11.x` only accepts bugfixes and improvements for the upgrade path to 3.0. Please retarget against `3.0.x` (no need to file another PR, use the Edit button at the top of the page).",False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/comments/708180737,Added filtered index support for SQL Server,cziegenberg,3,719942966,4,708180737,0,708064658,2020-10-14T06:09:56Z,"Sorry, I seems like I did something wrong. I changed the target branch, but could not change the source for this pull request, although I switched the branch on my site...?! So the only thing I could do was to create a new pull request (#4342). So closing this one...

BTW: Good to see, that all the old SQL Server code has been removed now.",False,0,NONE
https://api.github.com/repos/doctrine/dbal/issues/4342,Added filtered index support for SQL Server,cziegenberg,8,721150006,1,721150006,0,0,2020-10-14T05:31:34Z,"<!-- Fill in the relevant information below to help triage your pull request. -->

|      Q       |   A
|------------- | -----------
| Type         | improvement
| BC Break     | no
| Fixed issues | #3038

#### Summary

Added support for filtered (or partial) indexes in SQL Server (supported since version 2008).

The implementation has the following limitation (same as with other platforms like PostgreSQL, see #3871):
The given ""where"" option may be modified by the server. So when reading it again for comparison, the result may differ, which can result in an unnecessary update when creating a migration. This depends on how the ""where"" option is defined and especially occurrs in case of unique indexes (but not unique constraints), because for each indexed column in SQL Server a ""IS NOT NULL"" filter is added automatically by DBAL (for compatibility with other platforms and the SQL standard). This has to be solved globally (i.e. by saving the original value as a comment or adding a normalization step before the comparison) and is independent of this pull request.
",True,0,NONE
https://api.github.com/repos/doctrine/dbal/issues/comments/712878274,Added filtered index support for SQL Server,cziegenberg,8,721150006,2,712878274,0,721150006,2020-10-20T14:06:03Z,"I just saw that some checks have been added in the meantime, although all check have been passed before. Can you merge it without these additional checks or how do I trigger their execution?",False,0,NONE
https://api.github.com/repos/doctrine/dbal/issues/comments/712882148,Added filtered index support for SQL Server,mvorisek,8,721150006,3,712882148,0,712878274,2020-10-20T14:11:54Z,"> 
> 
> I just saw that some checks have been added in the meantime, although all check have been passed before. Can you merge it without these additional checks or how do I trigger their execution?

I think you need to rebase your PR on the latest commit of branch you target (and force-push of course)",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/dbal/issues/comments/713324407,Added filtered index support for SQL Server,cziegenberg,8,721150006,4,713324407,0,712882148,2020-10-21T05:59:53Z,"Okay, all new checks passed too.",False,0,NONE
https://api.github.com/repos/doctrine/dbal/issues/comments/713617672,Added filtered index support for SQL Server,morozov,8,721150006,5,713617672,0,713324407,2020-10-21T14:27:53Z,Please see https://github.com/doctrine/dbal/pull/4339#discussion_r504321722.,False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/comments/713645483,Added filtered index support for SQL Server,cziegenberg,8,721150006,6,713645483,0,713617672,2020-10-21T15:07:29Z,"> Please see [#4339 (comment)](https://github.com/doctrine/dbal/pull/4339#discussion_r504321722).

I replied to it and also mentioned this general problem in the summary. The problem is, that the output of the stored condition is platform dependent and in most cases doesn't match the input. For example brackets are added (PG), identifiers are modified (MS), types are added (PG), duplicate conditions are removed (MS) and - in case of SQL Server - some additional conditions are added automatically by DBAL for unique indexes. I don't see a chance to create a test that works in both platforms, without a general normalization step for the SQL returned by the platform and the user defined condition before comparing them (see #3871).",False,0,NONE
https://api.github.com/repos/doctrine/dbal/issues/comments/715450064,Added filtered index support for SQL Server,morozov,8,721150006,7,715450064,0,713645483,2020-10-23T16:37:35Z,"> The problem is, that the output of the stored condition is platform dependent and in most cases doesn't match the input.

This is indeed a problem. Apart from the existing tests, this change requires a test that make sure that once a table with the newly implemented indexes is deployed and introspected, it doesn't cause false diffs.

See this for example:
https://github.com/doctrine/dbal/blob/3d8c57560d46f9cdd299e6e26de49f2ec25b349f/tests/Functional/Schema/ComparatorTest.php#L28-L43",False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/comments/855711635,Added filtered index support for SQL Server,masacc,8,721150006,8,855711635,0,715450064,2021-06-07T08:18:27Z,"Hello, this PR was closed without being merged. Has it been transferred to another PR for branch 3.1.x (I didn't find it) ?",False,0,NONE
https://api.github.com/repos/doctrine/dbal/issues/comments/856111075,Added filtered index support for SQL Server,morozov,8,721150006,9,856111075,0,855711635,2021-06-07T17:08:20Z,"No, the PR got closed after I deleted the `3.0.x` branch. I cannot reopen it since the original branch is gone as well. The PR will have to be recreated.",False,0,MEMBER
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/420,D.tube support,Serkan-devel,16,724770156,1,724770156,0,0,2018-02-22T13:05:53Z,"D.tube is a decentralized video streaming platform, backed by the IPFS Network and the STEEM Blockchain.

IPFS is used for torrent-style hosting while STEEM is used for decentralized account management, comments, ratings and more.
Everything there is open source but didn't get the recognition which it deserves ",True,0,NONE
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/367697203,D.tube support,theScrabi,16,724770156,2,367697203,0,724770156,2018-02-22T14:28:25Z,Yes pls. I am currently working on a tutorial about how to write own services for the NewPipeExtractor. This way everyone with simple java and webexperience can write support for any streaming service. Including d.tube :D,False,0,MEMBER
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/379424624,D.tube support,trymeouteh,16,724770156,3,379424624,0,367697203,2018-04-07T02:04:55Z,D.Tube and Bitchute in newpip would be great. I know DTube and Bitchute are working on their own apps but to haven then all in one app would be amazing.,False,0,NONE
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/379459995,D.tube support,theScrabi,16,724770156,4,379459995,0,379424624,2018-04-07T10:36:07Z,"I'm currently working on a tutorial for 3. party developer to add support for certain services. It's not yet ready but if you want to give it a shot take a look here :D 
https://teamnewpipe.github.io/tutorial/",False,0,MEMBER
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/381395984,D.tube support,FlorianSteenbuck,16,724770156,5,381395984,0,379459995,2018-04-15T10:31:30Z,"Working on a D.Tube Implementation and some better URL parsing. Not finished yet, but if I get my mail account recovered and a approved steemit account I can create a pull request next week. Its a little bit tricky because I think the user should select which ipfs gateways they want to use. Maybe if we get the d.tube implementation their could be a possibility to more easily implement other steemit services, because dtube strongly depends on the steemit RPC Api and the asksteemit rest Api. And other service like Dlive also strongly depending on the steemit RPC Api.",False,0,NONE
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/381400796,D.tube support,theScrabi,16,724770156,6,381400796,0,381395984,2018-04-15T11:56:42Z,"Did you try to parse the dtube website or did you use the APi?

For now I think its ok if the user can't switch the gateway. However you are right, it was better if he could. We need to find a way to pass user defined parameter to the service. This way we could also allow services which need support for login for example spodify.",False,0,MEMBER
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/381407962,D.tube support,FlorianSteenbuck,16,724770156,7,381407962,0,381400796,2018-04-15T13:47:01Z,"The Website is a Javascript Client for videos that get published with DTube on steemit.

Steemit looks somehow like ipfs with a gateway (api.steemit.com), that every steemit based application is using, but with a extra frontend with crftoken that is required by the steemit.com/api/v1, but even this frontend using the api (api.steemit.com).

You could use rhino and a Virtual DOM envirment to parse the website or parse the steemit frontend with crftokens on it. And that is not what I have done.

Their is no api key or client id like in SoundCloud. I just replace the JavaScript logic from DTube with Java logic from NewPipe. Anyway the third party asksteemit.com DTube using for searching and for suggestions. And the ""official""/application api (api.steemit.com) for the everything else. Their is no ""no script client"" where I can parse it from. The APIs that are in usage got no request visible request limits. And if they got in future their can tricked by Just using identical request or parsing the website. DTube only got a settings in json format, translations in json, one weird looking sockjs/info?cb=xxxxx endpoint that just response a empty json object, all what is needed to setup a static html website + JavaScript + emb.d.tube for everything that is needed for the player, snap1.d.tube for saving the thumbnails just a ipfs gateway, dmca.d.tube for handle dmca claims return as api a object with one key (""dmca"") and and int value 0 or 1. The only thing I am using from this endpoints are the settings and with that the ipfs gateways.

They claim to save videos but I never seen that also they not using a extra gateway for display the video its just the official ipfs gateway. So I think it is quit important for users to setup own ipfs gateways that do not delete their videos and do not get censored.

A Steemit Applications are united by just airdrops of power in the Steemit system, that get controled by its devs. A Steemit Application is somehow centralized over the steemit plattform.",False,0,NONE
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/381424342,D.tube support,Serkan-devel,16,724770156,8,381424342,0,381407962,2018-04-15T17:44:46Z,Where is actually the tutorial for implementing it?,False,0,NONE
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/381424611,D.tube support,TobiGr,16,724770156,9,381424611,0,381424342,2018-04-15T17:49:00Z,The tutorial has been renamed to documentation: https://teamnewpipe.github.io/documentation,False,0,MEMBER
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/381877113,D.tube support,FlorianSteenbuck,16,724770156,10,381877113,0,381424611,2018-04-17T07:27:09Z,"Short Answer yes I am using the APIs but the app also using this APIs like I do.

Its not exactly the same way, but this is only because I want to write it in a light way with less requests.",False,0,NONE
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/382322282,D.tube support,theScrabi,16,724770156,11,382322282,0,381877113,2018-04-18T09:20:02Z,"> Short Answer yes I am using the APIs but the app also using this APIs like I do.

muy bien",False,0,MEMBER
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/402320215,D.tube support,FlorianSteenbuck,16,724770156,12,402320215,0,382322282,2018-07-03T23:30:46Z,"My Current Pushed Version of the Implementation:
https://github.com/FlorianSteenbuck/NewPipeExtractorDTube
I got some trouble with splitting the whole project in mutiple projects and connect them over jitpack. It only needs a Dynamic Settings Implementation, some extending of the current downloader (dtube using head requests and post requests with body), the subscribtion import that is public and is the same request like the one that shows https://steemit.com/@floriandev/followed content. Uploading and Perform requires some keys.

The parsing part of my code also needs some fixes.

Also I have worked on some other thing and got some problems AFK in my life.
One of this projects is a NewPipe Tracker that is based on checksums so the user never get injected data from peers.
The other one is a complete python clone of the NewPipeExtractor.
Both are basically not finished and are things that I need to work on, while fixing problems with my current life and doing even more stuff in the direction of IRC Protocols und Javascript (and DOM) Fixing things.

Somehow I need to clone myself for doing all this stuff.",False,0,NONE
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/402511397,D.tube support,theScrabi,16,724770156,13,402511397,0,402320215,2018-07-04T15:35:22Z,"@FlorianSteenbuck awesome, however you might want to hold back you're changes a bit, there where huge changes on the SearchEngine which will be deplored with the next version of the extractor.
SearchEngine basically got removed in favor of a new SearchExtractor.

> Somehow I need to clone myself for doing all this stuff.

Be careful not burn out.",False,0,MEMBER
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/443422387,D.tube support,stale[bot],16,724770156,14,443422387,0,402511397,2018-12-01T12:20:57Z,"This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.
",False,0,NONE
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/443497050,D.tube support,Serkan-devel,16,724770156,15,443497050,0,443422387,2018-12-02T10:29:37Z,Why does this bot exist? Closing issues don't automatically resolve it,False,0,NONE
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/478265918,D.tube support,wuniversales,16,724770156,16,478265918,0,443497050,2019-03-30T17:09:36Z,Great idea!!!,False,0,NONE
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/834587746,D.tube support,CypherpunkSamurai,16,724770156,17,834587746,0,478265918,2021-05-07T16:19:13Z,"@TobiGr @theScrabi Is it possible to provide a updated service template? I searched github and tested a few extractors i found. All of them are outdated and conflict with current NewPipeExtractor code.

I can extract DTube, Dailymotion API, but i'm not very skilled with large Java projects. It would be very helpfull if you guys can provide a sample service template :)",False,0,NONE
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/421,Compatibility with Video Hostings,ghost,4,724770486,1,724770486,0,0,2018-04-02T14:25:03Z,"- [x] I carefully read the [contribution guidelines](https://github.com/TeamNewPipe/NewPipe/blob/HEAD/.github/CONTRIBUTING.md) and agree to them.
- [x] I checked if the issue/feature exists in the latest version.

I would like Newpipe to be compatible with Video Hostings such as streamplay, streamcloud, streamango, powvideo, gamovideo, etc... and the search engine in these cases would be used to enter the URL that directs you to the video.  ",True,0,NONE
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/378004960,Compatibility with Video Hostings,theScrabi,4,724770486,2,378004960,0,724770486,2018-04-02T18:36:23Z,"Yea ... I thought about such services. Maybe we can (later on) create some interface where you can enter information that some services need to work. Like a url.
Also we might need to think about generik services later, where you can add multiple services for different instances of streamplay etc.",False,0,MEMBER
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/378005180,Compatibility with Video Hostings,theScrabi,4,724770486,3,378005180,0,378004960,2018-04-02T18:37:03Z,For now however lets get the multyservice thing. We can think about the future if the presence work ;D,False,0,MEMBER
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/443437761,Compatibility with Video Hostings,stale[bot],4,724770486,4,443437761,0,378005180,2018-12-01T16:20:57Z,"This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.
",False,0,NONE
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/1256620732,Compatibility with Video Hostings,opusforlife2,4,724770486,5,1256620732,0,443437761,2022-09-23T19:59:52Z,Closing this due to multiple services being requested. Feel free to open a new issue for each.,False,0,COLLABORATOR
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/422,Add bandcamp support,ghost,10,724770883,1,724770883,0,0,2018-04-07T23:17:37Z,"Is it possible to add support for bandcamp, doesn't require login and have preview and sometimes complete albums available ",True,0,NONE
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/379540263,Add bandcamp support,theScrabi,10,724770883,2,379540263,0,724770883,2018-04-08T10:44:42Z,Maybe later when multi service support is more advanced. ,False,0,MEMBER
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/379540413,Add bandcamp support,ghost,10,724770883,3,379540413,0,379540263,2018-04-08T10:47:11Z,"You're free to implement it yourself in NewPipeExtractor though
",False,0,NONE
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/379541271,Add bandcamp support,theScrabi,10,724770883,4,379541271,0,379540413,2018-04-08T11:02:15Z,"Yes. I'm currently working on the documentation/tutorial of the extractor. If you are interested you can give it a shot:
https://teamnewpipe.github.io/documentation",False,0,MEMBER
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/379542373,Add bandcamp support,ghost,10,724770883,5,379542373,0,379541271,2018-04-08T11:20:55Z,I will give it a try thanks !,False,0,NONE
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/379962301,Add bandcamp support,ghost,10,724770883,6,379962301,0,379542373,2018-04-10T03:26:26Z,"This really interests me, I use a lot of bandcamp and newpipe. It would be great not to require the bandcamp app",False,0,NONE
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/380591523,Add bandcamp support,theScrabi,10,724770883,7,380591523,0,379962301,2018-04-11T20:51:20Z,please remember to put a [bounty](https://www.bountysource.com/issues/56781245-add-bandcamp-support) to the feature if you want to support it but you are not a dev. ;),False,0,MEMBER
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/443437709,Add bandcamp support,stale[bot],10,724770883,8,443437709,0,380591523,2018-12-01T16:20:35Z,"This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.
",False,0,NONE
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/538935187,Add bandcamp support,albjeremias,10,724770883,9,538935187,0,443437709,2019-10-07T10:15:23Z,"don't forget to add references of code already downloading from bandcamp! ;)

 - https://github.com/iheanyi/bandcamp-dl

@theScrabi what was this tutorial? not available anymore...",False,0,NONE
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/539056507,Add bandcamp support,theScrabi,10,724770883,10,539056507,0,538935187,2019-10-07T15:04:47Z,https://teamnewpipe.github.io/documentation it is now,False,0,MEMBER
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/821831979,Add bandcamp support,triallax,10,724770883,11,821831979,0,539056507,2021-04-17T14:33:25Z,Added in 0.21.0.,False,0,CONTRIBUTOR
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/423,Add llucy support.,gergesh,4,724771238,1,724771238,0,0,2018-04-30T15:01:55Z,"[llucy](https://llucy.net/) is an alluc successor, a service that searches for videos in various streaming sites.

I can try implementing this myself (though I haven't done any real android development before so it may take a while or just straight-up fail) but was wondering, given the legal-but-shady nature of the site, if that's a service that'd be welcome as an addition to NewPipe.",True,0,NONE
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/385630742,Add llucy support.,theScrabi,4,724771238,2,385630742,0,724771238,2018-05-01T09:10:56Z,Does this require login?,False,0,MEMBER
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/385630819,Add llucy support.,theScrabi,4,724771238,3,385630819,0,385630742,2018-05-01T09:11:20Z,But yes please give it a shot :),False,0,MEMBER
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/385775123,Add llucy support.,gergesh,4,724771238,4,385775123,0,385630819,2018-05-01T20:08:52Z,"Yes, it does require login. A free account will get you 200 results per day and (as I just found out) is limited to 1000 all-time. I can still try implementing it, but not sure if it's worth it at this point.",False,0,NONE
https://api.github.com/repos/TeamNewPipe/NewPipeExtractor/issues/comments/443433609,Add llucy support.,stale[bot],4,724771238,5,443433609,0,385775123,2018-12-01T15:20:33Z,"This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.
",False,0,NONE
https://api.github.com/repos/rubygems/rubygems/issues/4013,EditorConfig creation option for `bundle gem` command,ismailarilik,3,719465655,1,719465655,0,0,2020-10-12T15:23:30Z,"Hi. I am wondering if `bundle gem` command can ask for the creation of an EditorConfig file and creates if the answer is positive. As you know, [EditorConfig](https://editorconfig.org/) is for some common editor configuration and by the time most editors respect it with or without a plugin. As I see, its usage is common and increasing by time. So `bundle init` command may have an option for it. I have researched how to implement it; writing plugin is not an option I think (for this structure, at least). So necessary changes should be in this repo. If you think positive about this change, I can implement it and send you a PR to be reviewed. Thanks, stay healthy!",True,0,NONE
https://api.github.com/repos/rubygems/rubygems/issues/comments/708526029,EditorConfig creation option for `bundle gem` command,deivid-rodriguez,3,719465655,2,708526029,0,719465655,2020-10-14T16:47:04Z,"Hi @ismailarilik!

I'm not sure how many people will be interested in an option like this, specially since there's very little code being generated with a new gem skeleton. Also, I haven't seen any adoption of this configuration file in gems out there. I'd rather see some adoption first before adding it to the gem generator. Could you point to me to some gems using this? Also, what rules would you be interested in as defaults?

All that said, I have to say I love `EditorConfig` :)",False,0,MEMBER
https://api.github.com/repos/rubygems/rubygems/issues/comments/717837433,EditorConfig creation option for `bundle gem` command,deivid-rodriguez,3,719465655,3,717837433,0,708526029,2020-10-28T10:21:15Z,I'll close this now since there was no further feedback and in principle I think this is too much for a `bundle gem` option. But I'm happy to keep discussing on the closed ticket and eventually change my mind :),False,0,MEMBER
https://api.github.com/repos/rubygems/rubygems/issues/comments/717846585,EditorConfig creation option for `bundle gem` command,hsbt,3,719465655,4,717846585,0,717837433,2020-10-28T10:38:46Z,"> I think this is too much for a `bundle gem` option.

I also use EditorConfig. But I agreed this.",False,0,MEMBER
https://api.github.com/repos/rubygems/rubygems/issues/4017,Clean built extensions after install,eloyesp,31,722435100,1,722435100,0,0,2020-10-15T15:21:38Z,"This should fix #3958, it is based on a comment of @simi there.

It just adds a `clean` step after `install` to remove object files.

## Make sure he following tasks are checked

- [x] Describe the problem / feature
- [x] Write [tests](https://github.com/rubygems/rubygems/blob/master/bundler/doc/development/PULL_REQUESTS.md#tests) for features and bug fixes
- [x] Write code to solve the problem
- [x] Make sure you follow the [current code style](https://github.com/rubygems/rubygems/blob/master/bundler/doc/development/PULL_REQUESTS.md#code-formatting) and [write meaningful commit messages without tags](https://github.com/rubygems/rubygems/blob/master/bundler/doc/development/PULL_REQUESTS.md#commit-messages)",True,0,CONTRIBUTOR
https://api.github.com/repos/rubygems/rubygems/issues/comments/709399433,Clean built extensions after install,welcome[bot],31,722435100,2,709399433,0,722435100,2020-10-15T15:21:40Z,"Thanks for opening a pull request and helping make RubyGems and Bundler better! Someone from the RubyGems team will take a look at your pull request shortly and leave any feedback. Please make sure that your pull request has tests for any changes or added functionality.

We use GitHub Actions to test and make sure your change works functionally and uses acceptable conventions, you can review the current progress of GitHub Actions in the PR status window below.

If you have any questions or concerns that you wish to ask, feel free to leave a comment in this PR or join our #rubygems or #bundler channel on [Slack](http://slack.bundler.io/).

For more information about contributing to the RubyGems project feel free to review our [CONTRIBUTING](https://github.com/rubygems/rubygems/blob/master/CONTRIBUTING.md) guide
",False,0,NONE
https://api.github.com/repos/rubygems/rubygems/issues/comments/712878725,Clean built extensions after install,simi,31,722435100,3,712878725,0,709399433,2020-10-20T14:06:43Z,"1. Some tests do rely on this.
2. I think it would be great to make this configurable somehow and start with this disabled by default.",False,0,MEMBER
https://api.github.com/repos/rubygems/rubygems/issues/comments/713458323,Clean built extensions after install,deivid-rodriguez,31,722435100,4,713458323,0,712878725,2020-10-21T10:04:07Z,"It's probably worth investigating the failing tests first before making a call on how to handle this. The only failing tests are some tests I added very recently to test rubygems custom require behaviour regarding `.rb` vs `.so` selection, and the issue might be perfectly with the tests themselves :shrug: ",False,0,MEMBER
https://api.github.com/repos/rubygems/rubygems/issues/comments/1189398459,Clean built extensions after install,simi,31,722435100,5,1189398459,0,713458323,2022-07-19T18:07:19Z,Any news in here?,False,0,MEMBER
https://api.github.com/repos/rubygems/rubygems/issues/comments/1189404678,Clean built extensions after install,deivid-rodriguez,31,722435100,6,1189404678,0,1189398459,2022-07-19T18:14:29Z,"I just rebased this PR, and fixed the test failure, which was indeed expected and doesn't signal any problem with doing this. I think doing this is safe.",False,0,MEMBER
https://api.github.com/repos/rubygems/rubygems/issues/comments/1189448964,Clean built extensions after install,deivid-rodriguez,31,722435100,7,1189448964,0,1189404678,2022-07-19T19:02:07Z,"Oh wow, let me take back my previous message, this seems to break a lot of Bundler specs, actually. I will have a look.",False,0,MEMBER
https://api.github.com/repos/rubygems/rubygems/issues/comments/1330692831,Clean built extensions after install,eloyesp,31,722435100,8,1330692831,0,1189448964,2022-11-29T13:59:40Z,"As far as I could research, there is one remaining issue in [`Gem::Ext::ExtConfBuilder#build`](https://github.com/rubygems/rubygems/blob/master/lib/rubygems/ext/ext_conf_builder.rb#L13) that install the gem extensions within the gem itself by seting the `sitedir` argument for make, and making the `clean` task remove the actual installed files. The failure raises when the `full_tmp_dir` is being accessed after being cleaned up.

But I'm not sure why is ExtConfBuilder being used and why the sitedir is set to a tmpdir on the gem folder in that case.",False,0,CONTRIBUTOR
https://api.github.com/repos/rubygems/rubygems/issues/comments/1331607755,Clean built extensions after install,eloyesp,31,722435100,9,1331607755,0,1330692831,2022-11-30T03:46:54Z,"Ok, I now:

- fixed the failing tests properly (the ones checking the intermediate files instead of the installed ones).
- Added clean step on builder (that is called on install) that is quite simple to understand and have proper tests.
- Added an option `--dirty` that skip that step, just in case there is some gem broken by this change and added tests for it.
- Rebased everything on top of the `master` branch.

As far as I could run the tests everything just pass, but it seems that CI won't run without approval.",False,0,CONTRIBUTOR
https://api.github.com/repos/rubygems/rubygems/issues/comments/1331978354,Clean built extensions after install,deivid-rodriguez,31,722435100,10,1331978354,0,1331607755,2022-11-30T11:03:26Z,"Thanks for working on this @eloyesp, Since this would be your first contribution to this repo, CI needs manual approval. Just did that!

I'm not sure about `--dirty` option? I can't think of a case why someone would need artifacts to be left around, so I rather not commit to a new public CLI option that may not be used by anyone.",False,0,MEMBER
https://api.github.com/repos/rubygems/rubygems/issues/comments/1332084408,Clean built extensions after install,eloyesp,31,722435100,11,1332084408,0,1331978354,2022-11-30T12:40:14Z,"The  `dirty` option is added because of a possible gem that may depend on the build artifacts, it could be replaced by an environment variable, the idea is simply to give an easy workaround for a broken gem.

Also, I were reviewing the failures and it seems that the cargo builder depends on the build artifacts (or at least the tests do), I cannot reproduce it here because I could not make cargo run here.

There is a single failure for bundler, but could not reproduce the issue (the test pass locally).

And there were two warnings because of an unused variable, I've fixed those.",False,0,CONTRIBUTOR
https://api.github.com/repos/rubygems/rubygems/issues/comments/1332152157,Clean built extensions after install,deivid-rodriguez,31,722435100,12,1332152157,0,1332084408,2022-11-30T13:26:44Z,"> As far as I could research, there is one remaining issue in [Gem::Ext::ExtConfBuilder#build](https://github.com/rubygems/rubygems/blob/master/lib/rubygems/ext/ext_conf_builder.rb#L13) that install the gem extensions within the gem itself by seting the sitedir argument for make, and making the clean task remove the actual installed files. The failure raises when the full_tmp_dir is being accessed after being cleaned up.

> But I'm not sure why is ExtConfBuilder being used and why the sitedir is set to a tmpdir on the gem folder in that case.

I don't understand this case well, but I'd like to because using `make clean` feels... cleaner 😄. So, with the previous `make clean` approach, there was a single test failure, correct? Can you link push a separate branch with that approach and the failures it creates, I'd like to have a look.",False,0,MEMBER
https://api.github.com/repos/rubygems/rubygems/issues/comments/1332156268,Clean built extensions after install,simi,31,722435100,13,1332156268,0,1332152157,2022-11-30T13:30:30Z,"I can provide more detailed comment later, but indeed I think we should go with `make clean` (created by mkmf) is possible. I'm a little afraid this can cause troubles when compiled stuff relies on some intermediate files. For that reason I would like to make this optional (opt-in) initially and suggest in all related cases to test this first.

Once we will be brave enough, we can switch to make this default behaviour.",False,0,MEMBER
https://api.github.com/repos/rubygems/rubygems/issues/comments/1332200132,Clean built extensions after install,eloyesp,31,722435100,14,1332200132,0,1332156268,2022-11-30T14:04:55Z,"The problem with that approach is that the make method is a class method with many parameters, it is already doing too much and having lots of smells (in the [reek](https://github.com/troessner/reek) sense), adding the clean step there makes it much harder to debug and understand what happens.

While adding the single ""clean"" step in the array is clean enough adding that as an optional step adds lots of noise and making that cleaner would require a real refactor (or adding the seventh argument to that method).",False,0,CONTRIBUTOR
https://api.github.com/repos/rubygems/rubygems/issues/comments/1332778501,Clean built extensions after install,simi,31,722435100,15,1332778501,0,1332200132,2022-11-30T21:52:13Z,"I don't see problem with 7th optional argument. We need to maximize backward compatibility, this is the price we need to pay sometimes. Refactoring would be welcomed as well (not changing behaviour for now, just restructuring the code). All `ext` part of rubygems is a little confusing IMHO.

:thinking: I don't think `FileUtils.rm Dir[""#{@spec.gem_dir}/**/*.{so,o,bundle}""]` is good approach, since extension can do actually a lot of different stuff (create various files) on different platforms (when extension can differ). What about linux static builds? `*.a` What about rules files `*.d`? What about Mac OS dynlibs aka `*.dylib`? We should go with `make clean` as standard task to cleanup environment. That is supported by `mkmf`, it seems to be supported by next release of rust `mkmf`, ...",False,0,MEMBER
https://api.github.com/repos/rubygems/rubygems/issues/comments/1332798178,Clean built extensions after install,eloyesp,31,722435100,16,1332798178,0,1332778501,2022-11-30T22:11:59Z,"I understand that doing an actual removal with `FileUtils.rm` is not beautiful, but it have a clear advantage it is easier to understand and extend, that is this should get rid of all that you listed:

    FileUtils.rm Dir[""#{@spec.gem_dir}/**/*.{so,o,bundle,a,d,dylib}""]

Refactoring everything on `ext` is actually an important task, but it is impossible for me (because I lack the time and the confidence with the code). The main issue with such a refactor is that there is a lot of coupling between the tests and the code, making any refactor require rewrite most of the test suite.

I were exploring the option of simply adding a ""clean"" step, and the least ugly way to get that working was using a global variable or something like that, that would make the needed refactor even harder to implement (adding more technical debt).

Once the refactor is actually done, I think that the best approach would be to use ""make clean"" as you all recomend, it is obviously cleaner that way.",False,0,CONTRIBUTOR
https://api.github.com/repos/rubygems/rubygems/issues/comments/1332826766,Clean built extensions after install,simi,31,722435100,17,1332826766,0,1332798178,2022-11-30T22:38:13Z,"I understand, but I still think we just can't remove random files we don't own in RubyGems. Those files are owned (created) by make tasks and they should be cleaned using the same owner.

For now, to keep it simple, what about to extend this line with post optional task?

https://github.com/rubygems/rubygems/blob/a09fdd10145d065d7f45917cd72a5a2f16720511/lib/rubygems/ext/builder.rb#L43

```ruby
[""clean"", """", ""install"", ENV['RUBYGEMS_POST_MAKE_TASK']].compact.each do |target|
```

Would that be enough for now for opt-in behaviour of running `make clean` doing something like `RUBYGEMS_POST_MAKE_TASK=clean gem install xyzl`? Would you mind to give it a try?",False,0,MEMBER
https://api.github.com/repos/rubygems/rubygems/issues/comments/1332854097,Clean built extensions after install,eloyesp,31,722435100,18,1332854097,0,1332826766,2022-11-30T23:07:37Z,"Ok, I've created another pull-request with that implementation, it uses an ENV variable (that is another way to use global state) making testing and refactoring even harder.",False,0,CONTRIBUTOR
https://api.github.com/repos/rubygems/rubygems/issues/comments/1332865441,Clean built extensions after install,deivid-rodriguez,31,722435100,19,1332865441,0,1332854097,2022-11-30T23:21:39Z,"From what I understand, there's two discussions going on:

* Whether to `make clean` or remove specific files. I agree with @simi here.
* Whether to make this opt in, or not. I'm not necessarily against making this opt-in, but I don't know of any gem relying on intermediate build artifacts present in the final installation directory. Maybe one such gem exists, but I tend towards potentially breaking some users of this potential gem in favor of benefiting the rest of the community by default. Apparently the cargo builder relies on intermediate build artifacts being present in the installation folder? Can we look a bit more into that? Maybe it's just a problem with the tests?",False,0,MEMBER
https://api.github.com/repos/rubygems/rubygems/issues/comments/1332880853,Clean built extensions after install,eloyesp,31,722435100,20,1332880853,0,1332865441,2022-11-30T23:31:23Z,"Yes and no, I do think as everyone here that using ""make clean"" is better than removing files using a glob, but I prefer the last given the current implementation of the extension building process complexity. That is, adding more complexity there adds more technical debt and makes it even harder to refactor the code.

So, I'm not against using ""make clean"", I'm against the environment variable. That is the trade-off I'm talking about.

Regarding the opt-in or opt-out, I also think that opt-out is the way to go, but it is quite important to make that opt-out very clear, that is why I've added the `dirty` flag there, it sounds bad.",False,0,CONTRIBUTOR
https://api.github.com/repos/rubygems/rubygems/issues/comments/1332891284,Clean built extensions after install,simi,31,722435100,21,1332891284,0,1332880853,2022-11-30T23:36:14Z,"> Ok, I've created another pull-request with that implementation, it uses an ENV variable (that is another way to use global state) making testing and refactoring even harder.

That was just a quick idea to roll it out quickly for testing. Later we can integrate this in better way and turn it opt-out (enabled) by default. If you don't like this idea, we can continue exploring.",False,0,MEMBER
https://api.github.com/repos/rubygems/rubygems/issues/comments/1332893322,Clean built extensions after install,simi,31,722435100,22,1332893322,0,1332891284,2022-11-30T23:37:09Z,@deivid-rodriguez cargo/ruby connection did this recently -https://github.com/oxidize-rb/rb-sys/pull/107.,False,0,MEMBER
https://api.github.com/repos/rubygems/rubygems/issues/comments/1334034489,Clean built extensions after install,eloyesp,31,722435100,23,1334034489,0,1332893322,2022-12-01T16:30:59Z,"Ok, I'm almost sure I found the bug with cargo builder... It seems that when installing it adds a ""release"" subfolder that makes require fail.

```
# doing this manually in the middle of the test make it pass
cp tmp/test_rubygems_20221201-5322-h1rss4/gemhome/extensions/x86_64-linux/3.1.0-static/rust_ruby_example-0.1.0/release/rust_ruby_example.so tmp/test_rubygems_20221201-5322-h1rss4/gemhome/extensions/x86_64-linux/3.1.0-static/rust_ruby_example-0.1.0/
```

I'm working on a proper fix.",False,0,CONTRIBUTOR
https://api.github.com/repos/rubygems/rubygems/issues/comments/1338697427,Clean built extensions after install,eloyesp,31,722435100,24,1338697427,0,1334034489,2022-12-06T03:41:49Z,"That last commit should fix most of the failing tests (I could not reproduce the bundler related failure locally so I hope this fix that issue).

Now, we can:

- leave that clean task as is, and improve it in a later iteration with more information.
- add a little bit of love to that glob with the information we already have.
- try different strategies like running ""make clean"", something like a partial pristine (remove anything not listed in the gem itself). (with the current implementation this would require adding ~50 LOC)

My recommendation would be the first or the second one, leaving the improvements to a later iteration. I think that after a proper refactor the `make clean` option should be a one-liner, but adding it now will just make that refactor even harder (as it will need to duplicate most of the `build_extensions` related code.)
",False,0,CONTRIBUTOR
https://api.github.com/repos/rubygems/rubygems/issues/comments/1340036872,Clean built extensions after install,eloyesp,31,722435100,25,1340036872,0,1338697427,2022-12-06T21:31:03Z,"I think that the windows rubygems failures should be fixed with the latest changes (but I don't have a windows to test).

As mentioned before, I have not been able to reproduce the bundler failure because for some reason it is not doing the clean step.

As far as I can see the extensions are being installed by bundler in a folder like:

``` tree
│   │       ├── bundler
│   │       │   └── gems
│   │       │       └── gems-c8d776cc497b
│   │       │           ├── c_extension_one
│   │       │           │   ├── c_extension_one.gemspec
│   │       │           │   ├── ext
│   │       │           │   │   ├── c_extension_one.c
│   │       │           │   │   ├── c_extension_one.o   # <-- build artifact
│   │       │           │   │   ├── extconf.rb
│   │       │           │   │   └── Makefile
│   │       │           │   └── lib
│   │       │           │       ├── c_extension_bundle_one.so   # <-- build artifact copy
│   │       │           │       ├── c_extension_one
│   │       │           │       │   └── source.rb
│   │       │           │       └── c_extension_one.rb
│   │       │           ├── c_extension_two
│   │       │           │   ├── c_extension_two.gemspec
│   │       │           │   ├── ext
│   │       │           │   │   ├── c_extension_two.c
│   │       │           │   │   ├── c_extension_two.o   # <-- build artifact
│   │       │           │   │   ├── extconf.rb
│   │       │           │   │   └── Makefile
│   │       │           │   └── lib
│   │       │           │       ├── c_extension_bundle_two.so   # <-- build artifact copy
│   │       │           │       ├── c_extension_two
│   │       │           │       │   └── source.rb
│   │       │           │       └── c_extension_two.rb
│   │       │           ├── extensions
│   │       │           │   └── x86_64-linux
│   │       │           │       └── 3.1.0-static
│   │       │           │           ├── gems-c8d776cc497b-c_extension_one
│   │       │           │           │   ├── c_extension_bundle_one.so   # <-- installed file
│   │       │           │           │   ├── gem.build_complete
│   │       │           │           │   └── gem_make.out
│   │       │           │           └── gems-c8d776cc497b-c_extension_two
│   │       │           │               ├── c_extension_bundle_two.so   # <-- installed file
│   │       │           │               ├── gem.build_complete
│   │       │           │               └── gem_make.out
```

In my computer the test is not making the clean step (it seems that something is not working on the test setup) so it loads the build artifact copy thus passing the test. (I can reproduce that removing the artifact manually on the middle of the test).

The problem is that the `$LOAD_PATH` is not correct as it is missing the extension name...

``` diff
+ extensions/x86_64-linux/3.1.0-static/gems-c8d776cc497b
- extensions/x86_64-linux/3.1.0-static/gems-c8d776cc497b-c_extension_one
+ extensions/x86_64-linux/3.1.0-static/gems-c8d776cc497b
- extensions/x86_64-linux/3.1.0-static/gems-c8d776cc497b-c_extension_two
```

",False,0,CONTRIBUTOR
https://api.github.com/repos/rubygems/rubygems/issues/comments/1340049250,Clean built extensions after install,eloyesp,31,722435100,26,1340049250,0,1340036872,2022-12-06T21:43:08Z,"This extra line makes the test fail in a much clear way:

``` ruby
run 'puts $LOAD_PATH.grep(/extensions/).each { |path| raise ""Invalid LOAD_PATH: #{ path }
  "" unless File.directory?(path) }'
```",False,0,CONTRIBUTOR
https://api.github.com/repos/rubygems/rubygems/issues/comments/1340155216,Clean built extensions after install,eloyesp,31,722435100,27,1340155216,0,1340049250,2022-12-06T23:30:14Z,"Found the issue, but I will not be able to fix it in the near future. The problem is that bundler when looking for performance is breaking the DRY rule duplicating the Specification using different implementations on different stages.

While the gem is being installed the extensions_path is defined in [rubygems_ext.rb](https://github.com/rubygems/rubygems/blob/master/bundler/lib/bundler/rubygems_ext.rb#L67) monkeypatching Gem::Specification.

But afterwards on [runtime](https://github.com/rubygems/rubygems/blob/master/bundler/lib/bundler/runtime.rb#L24) those specs are [a special collection](https://github.com/rubygems/rubygems/blob/771c94e14d6c86c8df3d1df0d2679ed59316252a/bundler/lib/bundler/spec_set.rb) of [stub specifications](https://github.com/rubygems/rubygems/blob/771c94e14d6c86c8df3d1df0d2679ed59316252a/bundler/lib/bundler/stub_specification.rb) that should not be confused with [stub specifications](https://github.com/rubygems/rubygems/blob/771c94e14d6c86c8df3d1df0d2679ed59316252a/lib/rubygems/stub_specification.rb).

The problem is that there is a mismatch regarding what the `extension_dir` actually is.

I've been digging several hours in this, but I cannot fix that as it requires much more knowledge about how to debug this.",False,0,CONTRIBUTOR
https://api.github.com/repos/rubygems/rubygems/issues/comments/1340903767,Clean built extensions after install,eloyesp,31,722435100,28,1340903767,0,1340155216,2022-12-07T12:34:51Z,"I mostly sure I fixed the bundler bug, but it would need a proper refactor to reuse instead of duplicate. I've just changed the stub implementation to match.",False,0,CONTRIBUTOR
https://api.github.com/repos/rubygems/rubygems/issues/comments/1341551202,Clean built extensions after install,eloyesp,31,722435100,29,1341551202,0,1340903767,2022-12-07T20:28:50Z,"It seems that _some_ extensions are being installed in different paths, so now that I modify the ""extension_path"" to make it work for one gem, it is broken for other gem, may be there is a better way to modify the ""extension_path"" to make everyone happy.",False,0,CONTRIBUTOR
https://api.github.com/repos/rubygems/rubygems/issues/comments/1352516109,Clean built extensions after install,eloyesp,31,722435100,30,1352516109,0,1341551202,2022-12-15T03:41:07Z,"I'm still working on this bug, it seems that bundler installs git sourced gems extensions on two different paths depending something (not sure what).

The two cases are on the specs, but they are not specified, so the specs pass because ruby finds the build artifacts (`$LOAD_PATH` is set to a non-existing directory but that is ok for the specs).

The test on `spec/install/gems/native_extensions_spec.rb:93` install extensions on something like:

    #{ stub.base_dir }/#{ source.extension_dir_name }/extensions/etc

While the test `./spec/install/gemfile/git_spec.rb:1203` installs the extensions on:

    #{ stub.base_dir }/extensions/etc

I could not find where is the difference, what makes this case use different folder structure. But without fixing this bug, adding the `clean artifacts` feature on rubygems might break some bundler setups with git gems.

I would greatly appreciate some help here. Regards.",False,0,CONTRIBUTOR
https://api.github.com/repos/rubygems/rubygems/issues/comments/1352931161,Clean built extensions after install,deivid-rodriguez,31,722435100,31,1352931161,0,1352516109,2022-12-15T11:34:10Z,"@eloyesp I'll try to have a look and see if I can figure this out. Thanks so much for your persistence on this issue, it's of great help!",False,0,MEMBER
https://api.github.com/repos/rubygems/rubygems/issues/4020,Bring back the possibility to install a plugin from path,deivid-rodriguez,3,723112329,1,723112329,0,0,2020-10-16T10:47:19Z,"This PR supersedes https://github.com/rubygems/rubygems/pull/3828, adding a spec on top of the bug fix.

Fixes #3355.

## Make sure he following tasks are checked

- [x] Describe the problem / feature
- [x] Write [tests](https://github.com/rubygems/rubygems/blob/master/bundler/doc/development/PULL_REQUESTS.md#tests) for features and bug fixes
- [x] Write code to solve the problem
- [x] Make sure you follow the [current code style](https://github.com/rubygems/rubygems/blob/master/bundler/doc/development/PULL_REQUESTS.md#code-formatting) and [write meaningful commit messages without tags](https://github.com/rubygems/rubygems/blob/master/bundler/doc/development/PULL_REQUESTS.md#commit-messages)",True,0,MEMBER
https://api.github.com/repos/rubygems/rubygems/issues/comments/709999311,Bring back the possibility to install a plugin from path,deivid-rodriguez,3,723112329,2,709999311,0,723112329,2020-10-16T11:52:30Z,"It was just pending a spec, so merging!

Thanks @nijikon!",False,0,MEMBER
https://api.github.com/repos/rubygems/rubygems/issues/comments/714592334,Bring back the possibility to install a plugin from path,ngan,3,723112329,3,714592334,0,709999311,2020-10-22T15:58:35Z,@deivid-rodriguez ty so much for doing this. Was wondering if this will go out with Bundler 2.1.5 or 2.2.0?,False,0,CONTRIBUTOR
https://api.github.com/repos/rubygems/rubygems/issues/comments/714593152,Bring back the possibility to install a plugin from path,deivid-rodriguez,3,723112329,4,714593152,0,714592334,2020-10-22T15:59:53Z,2.2.0,False,0,MEMBER
https://api.github.com/repos/rubygems/rubygems/issues/4023,Omit deprecated commands from command help output,landongrindheim,3,725804743,1,725804743,0,0,2020-10-20T17:36:54Z,"## What was the end-user or developer problem that led to this PR?
`gem query` was deprecated in rubygems 3.2. It was noted in #3984 that there should be a deprecation warning in the CLI (done in #4021) and a message in [the guides](https://guides.rubygems.org/command-reference/#gem-query).

A PR was opened to address the message (rubygems/guides#270) in Guides, but it [was pointed out](https://github.com/rubygems/guides/pull/270#issuecomment-712832643) that the file being changed is auto-generated. This change leans into that auto-generation and should make rubygems/guides#270 redundant.

Closes #3984 

## What is your fix for the problem, implemented in this PR?

Add the deprecation note to the command's summary so that it can be relied upon for auto-generating the documentation. This note will display near the heading in the guides.

## Make sure he following tasks are checked

- [x] Describe the problem / feature
- [x] Write [tests](https://github.com/rubygems/rubygems/blob/master/bundler/doc/development/PULL_REQUESTS.md#tests) for features and bug fixes
- [x] Write code to solve the problem
- [x] Make sure you follow the [current code style](https://github.com/rubygems/rubygems/blob/master/bundler/doc/development/PULL_REQUESTS.md#code-formatting) and [write meaningful commit messages without tags](https://github.com/rubygems/rubygems/blob/master/bundler/doc/development/PULL_REQUESTS.md#commit-messages)
",True,0,CONTRIBUTOR
https://api.github.com/repos/rubygems/rubygems/issues/comments/713549266,Omit deprecated commands from command help output,landongrindheim,3,725804743,2,713549266,0,725804743,2020-10-21T12:56:58Z,"> What if, instead, we change the script in https://github.com/rubygems/guides/ to ignore deprecated commands and don't list them in the command reference section at all. I think, once we deprecate a command, it's no worth documenting it at all?

@deivid-rodriguez This makes sense to me -- why hold the user's hand when the intent is to get them to stop using the functionality? I've poked around online for approaches to documenting deprecated functionality. This is what I've seen so far:

* Ruby stopped documenting `Fixnum` in [v2.4](https://ruby-doc.org/core-2.4.0/Fixnum.html) (It was present in [v2.3](https://ruby-doc.org/core-2.3.0/Fixnum.html))
* Ruby still [documents `safe_level`](https://docs.ruby-lang.org/en/2.6.0/ERB.html) as an argument to `ERB.new`, even though it was [deprecated in v2.6](https://www.ruby-lang.org/en/news/2018/12/25/ruby-2-6-0-released/)
* ActiveRecord still [documents `update_attributes`](https://api.rubyonrails.org/classes/ActiveRecord/Persistence.html#method-i-update_attributes) (with aliasing) even though it has been deprecated.
* Elixir documents [the Behaviour module](https://hexdocs.pm/elixir/Behaviour.html), noting that it has been deprecated.

You're doing the heavy lifting here, so I think you should feel free to choose the direction you'd like this to go 🙂

If this PR can be helpful, (say, adding `**deprecated**` to the summary _instead of_ the newline which breaks functionality with `gem help`), please let me know and I'll adjust accordingly.",False,0,CONTRIBUTOR
https://api.github.com/repos/rubygems/rubygems/issues/comments/713677413,Omit deprecated commands from command help output,deivid-rodriguez,3,725804743,3,713677413,0,713549266,2020-10-21T15:54:38Z,"Thanks for the research! Yeah, that's exactly what I was thinking. If we intend users to stop using a command, not documenting it sounds like a good step in that direction.

> The deprecation is removed altogether in favour of not rendering documentation for deprecated commands

I'd go with this one.

>  Should gem help commands be consistent with the guides and skip deprecated commands?

Yes, that's sounds like the right way forward to me.

> Should there be mention of the deprecation anywhere other than in CLI output upon use?

I don't think so, just warning on usage and recommending alternatives seems fine to me.",False,0,MEMBER
https://api.github.com/repos/rubygems/rubygems/issues/comments/714430992,Omit deprecated commands from command help output,landongrindheim,3,725804743,4,714430992,0,713677413,2020-10-22T11:32:37Z,@deivid-rodriguez What do you think of this approach?,False,0,CONTRIBUTOR
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/3706,server.pem contains the wrong key,enoch85,5,729735095,1,729735095,0,0,2020-10-26T16:51:59Z,"# Defect
## How to reproduce the issue

1. Install FreeRADIUS on Ubuntu 20.04 using their packaging.
2. Try to create new certs according to ../certs/README
3. Issue the commands described in the README for CA and SERVER

 
## Output of ``[radiusd|freeradius] -X`` showing issue occurring

First of all, server.pem are created with the wrong permissions, so you need to manually `chmod 644`. When that's done, this happens:

```
tls: Failed reading private key file ""/etc/freeradius/3.0/certs/server.pem"": error:0B080074:x509 certificate routines:X509_check_private_key:key values mismatch
rlm_eap_tls: Failed initializing SSL context
rlm_eap (EAP): Failed to initialise rlm_eap_tls
/etc/freeradius/3.0/mods-enabled/eap[14]: Instantiation failed for module ""eap""
```

I've been over this several times, and it's always the same. I also tried to run only `make`, but that failed as well, saying that an certificate already exists, even if I did `make destroycerts` **just** before.

Thanks for looking into this!

## Full backtrace from LLDB or GDB

```text
???
```
",True,0,NONE
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/716785349,server.pem contains the wrong key,alandekok,5,729735095,2,716785349,0,729735095,2020-10-26T19:52:51Z,"> server.pem are created with the wrong permissions, so you need to manually chmod 644

The `server.pem` file is created using the default ""umask"" taken from your shell.  The only `chmod` done by the scripts are to set `g+r` on it

If you run the scripts and OpenSSL can't start, then they created the wrong / incorrect certificates.

To be honest, it looks like Ubuntu has broken the server.  These errors do *not* occur in the default configuration.  We run these checks (and more) in Travis all of the time, and it passes:  https://travis-ci.org/github/FreeRADIUS/freeradius-server

Please try this using the files taken from _our_ release.  If they still fail, we'll look into it.  Otherwise it looks like an Ubuntu issue.


",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/716786892,server.pem contains the wrong key,jpereira,5,729735095,3,716786892,0,716785349,2020-10-26T19:55:12Z,Official packages could be found at https://networkradius.com/packages/,False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/716792372,server.pem contains the wrong key,enoch85,5,729735095,4,716792372,0,716786892,2020-10-26T20:05:45Z,"Thanks guys! <3

Will probably reinstall the server tomorrow for the 10:th time :D This time with the official packages.",False,0,NONE
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/717124640,server.pem contains the wrong key,enoch85,5,729735095,5,717124640,0,716792372,2020-10-27T09:56:54Z,"@jpereira @alandekok Noticed now that Focal isn't supported. 

Do you know when support will be added, or does the Bionic repo work for Focal as well?

Thanks again!",False,0,NONE
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/717982688,server.pem contains the wrong key,enoch85,5,729735095,6,717982688,0,717124640,2020-10-28T14:46:35Z,"Installed from source, everything is working. 🥇 ",False,0,NONE
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/3729,Add TFTP support,jpereira,5,739501498,1,739501498,0,0,2020-11-10T01:49:47Z,,True,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/724408587,Add TFTP support,lgtm-com[bot],5,739501498,2,724408587,0,739501498,2020-11-10T02:27:04Z,"This pull request **introduces 2 alerts** when merging 8db158c56fb6346fe6ac7264e920054d916d134a into 20c8f24d67df69f0f0c4f228b9212888cf606db5 - [view on LGTM.com](https://lgtm.com/projects/g/FreeRADIUS/freeradius-server/rev/pr-96a75738f5d52e7e4b35a27c6f4735c60bf9ef7b)

**new alerts:**

* 1 for Use of goto
* 1 for Implicit function declaration",False,0,NONE
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/725471001,Add TFTP support,arr2036,5,739501498,3,725471001,0,724408587,2020-11-11T14:58:17Z,Still needs the decoder moving to dbuffs.  I was checking out the dbuff functions for decoding and I think we have enough of the API there now.,False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/816526451,Add TFTP support,arr2036,5,739501498,4,816526451,0,725471001,2021-04-09T08:45:16Z,The resolution in the meeting was to leave this as a PR until we've figured out how to do large file transfers in the server core.,False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/829280416,Add TFTP support,alandekok,5,739501498,5,829280416,0,816526451,2021-04-29T14:22:39Z,"This should be separated based on #4051 .  so this PR should just be the new `src/process/tftp/` and `src/listen/tftp` code.

We also need to figure out a ""read file"" API which can be used by multiple modules.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/829630959,Add TFTP support,jpereira,5,739501498,6,829630959,0,829280416,2021-04-29T22:15:32Z,"> This should be separated based on #4051 . so this PR should just be the new `src/process/tftp/` and `src/listen/tftp` code.
> 
> We also need to figure out a ""read file"" API which can be used by multiple modules.

@alandekok Alright. As soon as we merge the https://github.com/FreeRADIUS/freeradius-server/pull/4051, I will rebase that branch against the `HEAD`.",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/3741,Master CI time saving,terryburton,4,741133193,1,741133193,0,0,2020-11-11T23:10:27Z,,True,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/725712966,Master CI time saving,arr2036,4,741133193,2,725712966,0,741133193,2020-11-11T23:12:15Z,I saw there's a wrapper around apt called 'apt-fast' that parallelises downloads we might want to look into too.,False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/725716964,Master CI time saving,terryburton,4,741133193,3,725716964,0,725712966,2020-11-11T23:23:02Z,"I think apt-fast may optimise the wrong thing. The data transfer is actually quite fast:

```
2020-11-11T23:06:33.0395818Z Get:1 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libwbclient-dev amd64 2:4.7.6+dfsg~ubuntu-0ubuntu2.21 [12.5 kB]
2020-11-11T23:06:33.0412781Z Get:2 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 autopoint all 0.19.8.1-6ubuntu0.3 [426 kB]
2020-11-11T23:06:33.0552026Z Get:3 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 dh-autoreconf all 17 [15.8 kB]
2020-11-11T23:06:33.0558422Z Get:4 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libarchive-zip-perl all 1.60-1ubuntu0.1 [84.6 kB]
2020-11-11T23:06:33.0596455Z Get:5 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libfile-stripnondeterminism-perl all 0.040-1.1~build1 [13.8 kB]
2020-11-11T23:06:33.0601552Z Get:6 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 dh-strip-nondeterminism all 0.040-1.1~build1 [5208 B]
2020-11-11T23:06:33.0606831Z Get:7 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 gettext amd64 0.19.8.1-6ubuntu0.3 [1293 kB]
2020-11-11T23:06:33.0815459Z Get:8 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 intltool-debian all 0.35.0+20060710.4 [24.9 kB]
2020-11-11T23:06:33.0820024Z Get:9 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 po-debconf all 1.0.20 [232 kB]
2020-11-11T23:06:33.0851630Z Get:10 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 debhelper all 11.1.6ubuntu2 [902 kB]
2020-11-11T23:06:33.1006573Z Get:11 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libfile-which-perl all 1.21-1 [11.8 kB]
2020-11-11T23:06:33.1013067Z Get:12 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libfile-homedir-perl all 1.002-1 [37.1 kB]
2020-11-11T23:06:33.1020138Z Get:13 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 devscripts amd64 2.17.12ubuntu1.1 [870 kB]
2020-11-11T23:06:33.1156904Z Get:14 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 dh-make all 2.201701 [31.6 kB]
2020-11-11T23:06:33.1163519Z Get:15 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 diffstat amd64 1.61-1build1 [24.1 kB]
2020-11-11T23:06:33.1171007Z Get:16 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 dovecot-dev amd64 1:2.2.33.2-1ubuntu4.6 [308 kB]
2020-11-11T23:06:33.1226160Z Get:17 http://azure.archive.ubuntu.com/ubuntu bionic/universe amd64 libib-util amd64 3.0.2.32703.ds4-11ubuntu2 [3248 B]
2020-11-11T23:06:33.1231356Z Get:18 http://azure.archive.ubuntu.com/ubuntu bionic/universe amd64 firebird-dev amd64 3.0.2.32703.ds4-11ubuntu2 [117 kB]
2020-11-11T23:06:33.1245870Z Get:19 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libct4 amd64 1.00.82-2ubuntu0.1 [147 kB]
2020-11-11T23:06:33.1271049Z Get:20 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 freetds-dev amd64 1.00.82-2ubuntu0.1 [258 kB]
2020-11-11T23:06:33.1315898Z Get:21 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgssrpc4 amd64 1.16-2ubuntu0.1 [54.2 kB]
2020-11-11T23:06:33.1325995Z Get:22 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libkdb5-9 amd64 1.16-2ubuntu0.1 [37.2 kB]
2020-11-11T23:06:33.1334062Z Get:23 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libkadm5srv-mit11 amd64 1.16-2ubuntu0.1 [49.7 kB]
2020-11-11T23:06:33.1358199Z Get:24 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libkadm5clnt-mit11 amd64 1.16-2ubuntu0.1 [38.2 kB]
2020-11-11T23:06:33.1365912Z Get:25 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 comerr-dev amd64 2.1-1.44.1-1ubuntu1.3 [38.5 kB]
2020-11-11T23:06:33.1380627Z Get:26 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 krb5-multidev amd64 1.16-2ubuntu0.1 [120 kB]
2020-11-11T23:06:33.1394442Z Get:27 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libapt-pkg-perl amd64 0.1.33build1 [68.0 kB]
2020-11-11T23:06:33.1405160Z Get:28 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libcap-dev amd64 1:2.25-1.2 [23.2 kB]
2020-11-11T23:06:33.1411755Z Get:29 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libsub-name-perl amd64 0.21-1build1 [11.6 kB]
2020-11-11T23:06:33.1418630Z Get:30 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libclass-accessor-perl all 0.51-1 [21.2 kB]
2020-11-11T23:06:33.1424736Z Get:31 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libclone-perl amd64 0.39-1 [10.4 kB]
2020-11-11T23:06:33.1430400Z Get:32 http://azure.archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libcollectdclient1 amd64 5.7.2-2ubuntu1.2 [44.1 kB]
2020-11-11T23:06:33.1435990Z Get:33 http://azure.archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libcollectdclient-dev amd64 5.7.2-2ubuntu1.2 [12.1 kB]
2020-11-11T23:06:33.1441562Z Get:34 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcurl4-openssl-dev amd64 7.58.0-2ubuntu3.10 [294 kB]
2020-11-11T23:06:33.1484154Z Get:35 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libdigest-hmac-perl all 1.03+dfsg-1 [12.1 kB]
2020-11-11T23:06:33.1489588Z Get:36 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libsocket6-perl amd64 0.27-1build2 [23.0 kB]
2020-11-11T23:06:33.1494879Z Get:37 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libio-socket-inet6-perl all 2.72-2 [13.8 kB]
2020-11-11T23:06:33.1499584Z Get:38 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libnet-ip-perl all 1.26-1 [31.5 kB]
2020-11-11T23:06:33.1505815Z Get:39 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libnet-dns-perl all 1.10-2 [335 kB]
2020-11-11T23:06:33.1544345Z Get:40 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libnet-domain-tld-perl all 1.75-1 [29.1 kB]
2020-11-11T23:06:33.1549593Z Get:41 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libemail-valid-perl all 1.202-1 [16.3 kB]
2020-11-11T23:06:33.1554232Z Get:42 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libexporter-tiny-perl all 1.000000-2 [34.6 kB]
2020-11-11T23:06:33.1558812Z Get:43 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libgdbm-dev amd64 1.14.1-6 [79.3 kB]
2020-11-11T23:06:33.1570711Z Get:44 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libtcmalloc-minimal4 amd64 2.5-2.2ubuntu3 [91.6 kB]
2020-11-11T23:06:33.1583552Z Get:45 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libgoogle-perftools4 amd64 2.5-2.2ubuntu3 [190 kB]
2020-11-11T23:06:33.1608293Z Get:46 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libunwind-dev amd64 1.2.1-8 [423 kB]
2020-11-11T23:06:33.1667649Z Get:47 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libgoogle-perftools-dev amd64 2.5-2.2ubuntu3 [204 kB]
2020-11-11T23:06:33.1695262Z Get:48 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libhashkit2 amd64 1.0.18-4.2ubuntu0.18.04.1 [35.4 kB]
2020-11-11T23:06:33.1703444Z Get:49 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libhashkit-dev amd64 1.0.18-4.2ubuntu0.18.04.1 [23.9 kB]
2020-11-11T23:06:33.1709144Z Get:50 http://azure.archive.ubuntu.com/ubuntu bionic/universe amd64 libhiredis0.13 amd64 0.13.3-2.2 [25.3 kB]
2020-11-11T23:06:33.1713848Z Get:51 http://azure.archive.ubuntu.com/ubuntu bionic/universe amd64 libhiredis-dev amd64 0.13.3-2.2 [39.6 kB]
2020-11-11T23:06:33.1721762Z Get:52 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libidn11-dev amd64 1.33-2.1ubuntu1.2 [520 kB]
2020-11-11T23:06:33.1805587Z Get:53 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libio-pty-perl amd64 1:1.08-1.1build4 [30.1 kB]
2020-11-11T23:06:33.1810267Z Get:54 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libio-string-perl all 1.08-3 [11.1 kB]
2020-11-11T23:06:33.1814778Z Get:55 http://azure.archive.ubuntu.com/ubuntu bionic/universe amd64 libiodbc2 amd64 3.52.9-2.1 [140 kB]
2020-11-11T23:06:33.1835793Z Get:56 http://azure.archive.ubuntu.com/ubuntu bionic/universe amd64 libiodbc2-dev amd64 3.52.9-2.1 [36.3 kB]
2020-11-11T23:06:33.1841182Z Get:57 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libipc-run-perl all 0.96-1 [89.9 kB]
2020-11-11T23:06:33.1853438Z Get:58 http://azure.archive.ubuntu.com/ubuntu bionic/universe amd64 libjson-perl all 2.97001-1 [73.3 kB]
2020-11-11T23:06:33.1865228Z Get:59 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 liblist-moreutils-perl amd64 0.416-1build3 [55.5 kB]
2020-11-11T23:06:33.1873886Z Get:60 http://azure.archive.ubuntu.com/ubuntu bionic/universe amd64 libluajit-5.1-common all 2.1.0~beta3+dfsg-5.1 [44.3 kB]
2020-11-11T23:06:33.1880463Z Get:61 http://azure.archive.ubuntu.com/ubuntu bionic/universe amd64 libluajit-5.1-2 amd64 2.1.0~beta3+dfsg-5.1 [227 kB]
2020-11-11T23:06:33.1913249Z Get:62 http://azure.archive.ubuntu.com/ubuntu bionic/universe amd64 libluajit-5.1-dev amd64 2.1.0~beta3+dfsg-5.1 [243 kB]
2020-11-11T23:06:33.1944029Z Get:63 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmemcachedutil2 amd64 1.0.18-4.2ubuntu0.18.04.1 [9532 B]
2020-11-11T23:06:33.1949920Z Get:64 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libnl-3-dev amd64 3.2.29-0ubuntu3 [90.6 kB]
2020-11-11T23:06:33.1964589Z Get:65 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libnl-genl-3-dev amd64 3.2.29-0ubuntu3 [10.7 kB]
2020-11-11T23:06:33.1966075Z Get:66 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpam0g-dev amd64 1.1.8-3.6ubuntu2.18.04.2 [110 kB]
2020-11-11T23:06:33.2002998Z Get:67 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libparse-debianchangelog-perl all 1.2.0-12 [49.5 kB]
2020-11-11T23:06:33.2010555Z Get:68 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpcap0.8-dev amd64 1.8.1-6ubuntu1.18.04.2 [218 kB]
2020-11-11T23:06:33.2050999Z Get:69 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpcap-dev amd64 1.8.1-6ubuntu1.18.04.2 [3480 B]
2020-11-11T23:06:33.2052502Z Get:70 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libudev-dev amd64 237-3ubuntu10.42 [19.1 kB]
2020-11-11T23:06:33.2064873Z Get:71 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpci-dev amd64 1:3.5.2-1ubuntu1.1 [43.5 kB]
2020-11-11T23:06:33.2075587Z Get:72 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libperl-dev amd64 5.26.1-6ubuntu0.5 [2862 kB]
2020-11-11T23:06:33.2563208Z Get:73 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libpython-all-dev amd64 2.7.15~rc1-1 [1092 B]
2020-11-11T23:06:33.2566329Z Get:74 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsasl2-dev amd64 2.1.27~101-g0780600+dfsg-3ubuntu2.1 [256 kB]
2020-11-11T23:06:33.2591771Z Get:75 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libwrap0-dev amd64 7.6.q-27 [21.5 kB]
2020-11-11T23:06:33.2597265Z Get:76 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libsensors4-dev amd64 1:3.4.0-4 [34.6 kB]
2020-11-11T23:06:33.2612984Z Get:77 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsnmp-dev amd64 5.7.3+dfsg-1.8ubuntu3.6 [1093 kB]
2020-11-11T23:06:33.2790934Z Get:78 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libtalloc-dev amd64 2.1.10-2ubuntu1 [60.0 kB]
2020-11-11T23:06:33.2799764Z Get:79 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libtext-levenshtein-perl all 0.13-1 [9612 B]
2020-11-11T23:06:33.2805800Z Get:80 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libunbound2 amd64 1.6.7-1ubuntu2.3 [267 kB]
2020-11-11T23:06:33.2850678Z Get:81 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libunbound-dev amd64 1.6.7-1ubuntu2.3 [5712 kB]
2020-11-11T23:06:33.3800091Z Get:82 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libxml-simple-perl all 2.24-1 [63.6 kB]
2020-11-11T23:06:33.3838779Z Get:83 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 libyaml-libyaml-perl amd64 0.69+repack-1 [26.4 kB]
2020-11-11T23:06:33.3840328Z Get:84 http://azure.archive.ubuntu.com/ubuntu bionic/universe amd64 libykclient3 amd64 2.15-1 [22.3 kB]
2020-11-11T23:06:33.3842157Z Get:85 http://azure.archive.ubuntu.com/ubuntu bionic/universe amd64 libykclient-dev amd64 2.15-1 [24.9 kB]
2020-11-11T23:06:33.3845240Z Get:86 http://azure.archive.ubuntu.com/ubuntu bionic/universe amd64 libyubikey0 amd64 1.13-2 [7452 B]
2020-11-11T23:06:33.3847564Z Get:87 http://azure.archive.ubuntu.com/ubuntu bionic/universe amd64 libyubikey-dev amd64 1.13-2 [14.3 kB]
2020-11-11T23:06:33.3850076Z Get:88 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 patchutils amd64 0.3.4-2 [71.1 kB]
2020-11-11T23:06:33.3852314Z Get:89 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 t1utils amd64 1.41-2 [56.0 kB]
2020-11-11T23:06:33.3858352Z Get:90 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 lintian all 2.5.81ubuntu1 [847 kB]
2020-11-11T23:06:33.3955091Z Get:91 http://azure.archive.ubuntu.com/ubuntu bionic/universe amd64 luajit amd64 2.1.0~beta3+dfsg-5.1 [229 kB]
2020-11-11T23:06:33.3985243Z Get:92 http://azure.archive.ubuntu.com/ubuntu bionic/universe amd64 quilt all 0.63-8.2 [293 kB]
2020-11-11T23:06:33.4023372Z Get:93 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 debootstrap all 1.0.95ubuntu0.8 [35.3 kB]
2020-11-11T23:06:33.4031157Z Get:94 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libjson-c-dev amd64 0.12.1-1.3ubuntu0.3 [31.9 kB]
2020-11-11T23:06:33.4036701Z Get:95 http://azure.archive.ubuntu.com/ubuntu bionic/universe amd64 libkqueue0 amd64 2.0.3-1.1 [23.3 kB]
2020-11-11T23:06:33.4042152Z Get:96 http://azure.archive.ubuntu.com/ubuntu bionic/universe amd64 libkqueue-dev amd64 2.0.3-1.1 [32.5 kB]
2020-11-11T23:06:33.4047359Z Get:97 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libkrb5-dev amd64 1.16-2ubuntu0.1 [11.8 kB]
2020-11-11T23:06:33.4052753Z Get:98 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libldap2-dev amd64 2.4.45+dfsg-1ubuntu1.7 [261 kB]
2020-11-11T23:06:33.4094678Z Get:99 http://azure.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmemcached-dev amd64 1.0.18-4.2ubuntu0.18.04.1 [238 kB]
2020-11-11T23:06:33.4134164Z Get:100 http://azure.archive.ubuntu.com/ubuntu bionic/main amd64 pbuilder all 0.229.1 [317 kB]
```",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/725717462,Master CI time saving,arr2036,4,741133193,4,725717462,0,725716964,2020-11-11T23:24:06Z,"Mmm, yes.  Well this seems to more than halve the install time for the common dependencies so seems good to me!",False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/725717902,Master CI time saving,arr2036,4,741133193,5,725717902,0,725717462,2020-11-11T23:24:26Z,Also saves LFS bandwidth which isn't free.,False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/3747,CI: Add GitHub Super-Linter workflow,terryburton,4,743915262,1,743915262,0,0,2020-11-16T15:11:25Z,"This adds a workflow that runs Super-Linter, which runs a battery of linters over the codebase: https://github.com/github/super-linter

The output of some of the linters (e.g. ShellCheck) is somewhat vexatious but there is some stuff in there that should be cleaned up, so I haven't silenced any of the checks for now.

To keep the noise down it is configured to ordinarily perform a lint of only changed files. However, all files will be linted on push to the ""linter"" branch so that we can see cleanup progress.",True,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/728131800,CI: Add GitHub Super-Linter workflow,arr2036,4,743915262,2,728131800,0,743915262,2020-11-16T15:24:53Z,If you look at the output it doesn't seem to be checking for C files?,False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/728132196,CI: Add GitHub Super-Linter workflow,arr2036,4,743915262,3,728132196,0,728131800,2020-11-16T15:25:29Z,Yeah... doesn't support C. Only C #,False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/728136291,CI: Add GitHub Super-Linter workflow,terryburton,4,743915262,4,728136291,0,728132196,2020-11-16T15:31:45Z,ACK.,False,0,MEMBER
https://api.github.com/repos/FreeRADIUS/freeradius-server/issues/comments/728311021,CI: Add GitHub Super-Linter workflow,terryburton,4,743915262,5,728311021,0,728136291,2020-11-16T20:34:39Z,"> Yeah... doesn't support C. Only C #

Probably covers the ""everything else"" bit which should help catch issues with things such as scripts, SQL, Markdown, Dockerfile anti-patterns...

Example full run: https://github.com/terryburton/freeradius-server/runs/1408381484?check_suite_focus=true

A couple of things that I can see it detected from a brief skim of the output:

  * Bug with passwords containing space in the certificate scripts
  * Typos and uninitialised variables in the init scripts and other scripts
  * Failed expansions: echo 'graph_vlabel Exchanged / ${graph_period}'",False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/39051,[WebProfilerBundle] Possibility to dynamically set mode,brusch,4,740577094,1,740577094,0,0,2020-11-11T08:37:41Z,"| Q             | A
| ------------- | ---
| Branch?       | 5.x
| Bug fix?      | no
| New feature?  | no
| Deprecations? | no
| License       | MIT

Sometimes it is necessary to dynamically decide whether the debug toolbar should be injected or not. ",True,0,CONTRIBUTOR
https://api.github.com/repos/symfony/symfony/issues/comments/725285447,[WebProfilerBundle] Possibility to dynamically set mode,carsonbot,4,740577094,2,725285447,0,740577094,2020-11-11T08:37:43Z,"Hey!

I see that this is your first PR. That is great! Welcome!

Symfony has a [contribution guide](https://symfony.com/doc/current/contributing/index.html) which I suggest you to read.

In short:
- Always add tests
- Keep backward compatibility (see https://symfony.com/bc).
- Bug fixes must be submitted against the lowest maintained branch where they apply (see https://symfony.com/releases)
- Features and deprecations must be submitted against the 5.x branch.

Review the GitHub status checks of your pull request and try to solve the reported issues. If some tests are failing, try to see if they are failing because of this change.

When two Symfony core team members approve this change, it will be merged and you will become an official Symfony contributor!
If this PR is merged in a lower version branch, it will be merged up to all maintained branches within a few days.

I am going to sit back now and wait for the reviews.

Cheers!

Carsonbot",False,0,NONE
https://api.github.com/repos/symfony/symfony/issues/comments/751659890,[WebProfilerBundle] Possibility to dynamically set mode,fabpot,4,740577094,3,751659890,0,725285447,2020-12-28T10:08:33Z,"Can you share the use cases you have in mind?
",False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/comments/751667025,[WebProfilerBundle] Possibility to dynamically set mode,brusch,4,740577094,4,751667025,0,751659890,2020-12-28T10:34:39Z,"Yep, of course 😊
One use case for us is, that we want to disable the debug toolbar for certain admin functionalities which are embedded by an `<iframe>`, because it's just not necessary and (sometimes) breaks the layout of the embedded contents: 
![image](https://user-images.githubusercontent.com/142037/103207948-d574e400-48ff-11eb-96fb-87489fdc63f7.png)

We're currently doing this by removing the subscriber, which is also working fine. But as the functionality is already there, I thought it would make sense to also let it change dynamically 😉
https://github.com/pimcore/pimcore/blob/master/bundles/CoreBundle/EventListener/WebDebugToolbarListener.php#L97",False,0,CONTRIBUTOR
https://api.github.com/repos/symfony/symfony/issues/comments/754430936,[WebProfilerBundle] Possibility to dynamically set mode,fabpot,4,740577094,5,754430936,0,751667025,2021-01-05T06:31:04Z,Thank you @brusch.,False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/39052,[TwigBridge] - AppVariable check on Environment::isStrictVariables() to throw exception,ybenhssaien,3,740634999,1,740634999,0,0,2020-11-11T10:00:59Z,"**Symfony version(s) affected**: >= 4.4.*

**Description**  
As described in the [The App Global Variable](https://symfony.com/doc/4.4/templates.html#the-app-global-variable) section, the variable `app.user` should return the current user or `null` (same for `app.token`).

If the `Security` components is not installed and calling one of `app.user` or `app.token` the twig renderer always throws a `Twig\Error\RuntimeError` exception whatever the value of `twig.strict_variables`

![image](https://user-images.githubusercontent.com/7301643/98794890-df06c300-2409-11eb-907c-5fa38f6d3b98.png)

![image](https://user-images.githubusercontent.com/7301643/98794243-1a54c200-2409-11eb-93c3-d7b78dce0a5e.png)


**How to reproduce**  

Either create a symfony project from `symfony/skeleton` then install `twig` dependencies (`Twig` + `TwigBridge` + `TwigBundle`) or create from `symfony/website-skeleton` then remove `Security` component.

Or just create from the following `composer.json` (may remove some unnecessary components)
```composer
{
    ""type"": ""project"",
    ""license"": ""proprietary"",
    ""require"": {
        ""php"": ""^7.2.5"",
        ""ext-ctype"": ""*"",
        ""ext-iconv"": ""*"",
        ""symfony/console"": ""5.0.*"",
        ""symfony/debug-bundle"": ""5.0.*"",
        ""symfony/dotenv"": ""5.0.*"",
        ""symfony/flex"": ""^1.3.1"",
        ""symfony/framework-bundle"": ""5.0.*"",
        ""symfony/monolog-bundle"": ""^3.0"",
        ""symfony/stopwatch"": ""^5.0"",
        ""symfony/twig-bundle"": ""5.0.*"",
        ""symfony/var-dumper"": ""5.0.*"",
        ""symfony/web-profiler-bundle"": ""^5.0"",
        ""symfony/yaml"": ""5.0.*""
    },
    ""require-dev"": {
    },
    ""config"": {
        ""preferred-install"": {
            ""*"": ""dist""
        },
        ""sort-packages"": true
    },
    ""autoload"": {
        ""psr-4"": {
            ""App\\"": ""src/""
        }
    },
    ""autoload-dev"": {
        ""psr-4"": {
            ""App\\Tests\\"": ""tests/""
        }
    },
    ""replace"": {
        ""paragonie/random_compat"": ""2.*"",
        ""symfony/polyfill-ctype"": ""*"",
        ""symfony/polyfill-iconv"": ""*"",
        ""symfony/polyfill-php72"": ""*"",
        ""symfony/polyfill-php71"": ""*"",
        ""symfony/polyfill-php70"": ""*"",
        ""symfony/polyfill-php56"": ""*""
    },
    ""scripts"": {
        ""auto-scripts"": {
            ""cache:clear"": ""symfony-cmd"",
            ""assets:install %PUBLIC_DIR%"": ""symfony-cmd""
        },
        ""post-install-cmd"": [
            ""@auto-scripts""
        ],
        ""post-update-cmd"": [
            ""@auto-scripts""
        ]
    },
    ""conflict"": {
        ""symfony/symfony"": ""*""
    },
    ""extra"": {
        ""symfony"": {
            ""allow-contrib"": false,
            ""require"": ""5.0.*""
        }
    }
}
```

Add a twig template to debug global variable `app` (paste just 
```twig
{# index.html.twig #}

{{ dump(app) }}
{{ dump(app.request) }}
{{ dump(app.session) }}
{{ dump(app.flashes) }}
{{ dump(app.token) }}
{{ dump(app.user) }}
```
and a controller to render the twig page
```php
<?php

namespace App\Controller;

use Symfony\Bundle\FrameworkBundle\Controller\AbstractController;
use Symfony\Component\HttpFoundation\Response;
use Symfony\Component\Routing\Annotation\Route;

/**
 * @Route(""/"", name=""home"")
 */
class HomeController extends AbstractController
{
    public function __invoke(): Response
    {
        return $this->render('index.html.twig');
    }
}
```

**Possible Solution**  
Inject `Twig\Environment` in `Symfony\Bridge\Twig\AppVariable` to check on `Twig\Environment::isStrictVariables` before throwing exception

> Merge request for the implementation: #39053

After applying the solution
![image](https://user-images.githubusercontent.com/7301643/98796624-e0d18600-240b-11eb-9dea-5949f466e70c.png)

**Additional context**  

It may not be reproducable in the real life since without `Security` component we may not use `app.user` or `app.token`, but the idea is to keep all config consistent and make it possible to control this behaviour in a non symfony app.

> `$strictVariables = true` will be the default value for the new property to not BC
",True,0,CONTRIBUTOR
https://api.github.com/repos/symfony/symfony/issues/comments/839755531,[TwigBridge] - AppVariable check on Environment::isStrictVariables() to throw exception,carsonbot,3,740634999,2,839755531,0,740634999,2021-05-12T13:04:22Z,"Hey, thanks for your report!
There has not been a lot of activity here for a while. Is this bug still relevant? Have you managed to find a workaround?",False,0,NONE
https://api.github.com/repos/symfony/symfony/issues/comments/848755349,[TwigBridge] - AppVariable check on Environment::isStrictVariables() to throw exception,carsonbot,3,740634999,3,848755349,0,839755531,2021-05-26T13:08:40Z,Friendly ping? Should this still be open? I will close if I don't hear anything.,False,0,NONE
https://api.github.com/repos/symfony/symfony/issues/comments/848771908,[TwigBridge] - AppVariable check on Environment::isStrictVariables() to throw exception,ybenhssaien,3,740634999,4,848771908,0,848755349,2021-05-26T13:30:43Z,Hi the pull request still open I will check what going wrong ,False,0,CONTRIBUTOR
https://api.github.com/repos/symfony/symfony/issues/39053,[TwigBridge] AppVariable add $strictVariables,ybenhssaien,3,740640179,1,740640179,0,0,2020-11-11T10:08:01Z,"| Q             | A
| ------------- | ---
| Branch?       | 5.x
| Bug fix?      | no
| New feature?  | yes <!-- please update src/**/CHANGELOG.md files -->
| Deprecations? | no <!-- please update UPGRADE-*.md and src/**/CHANGELOG.md files -->
| Tickets       | Fix #39052 <!-- prefix each issue number with ""Fix #"", no need to create an issue if none exist, explain below instead -->
| License       | MIT
| Doc PR        | 

# To do
- [x] Update CHANGELOG
- [x] Add unit tests

# Description
D not throw exception on `AppVariable` if `twig.strict_variables=false` and `Security` components is not installed

# Example
![image](https://user-images.githubusercontent.com/7301643/98798380-1f684000-240e-11eb-96c8-af5613a2e2b3.png)

![image](https://user-images.githubusercontent.com/7301643/98798356-18413200-240e-11eb-8e93-453d7432d3fe.png)


# Before
![image](https://user-images.githubusercontent.com/7301643/98798291-03fd3500-240e-11eb-8f37-464357fb9acc.png)

# After
![image](https://user-images.githubusercontent.com/7301643/98798319-0b244300-240e-11eb-8b7f-4425cc17dbd1.png)


",True,0,CONTRIBUTOR
https://api.github.com/repos/symfony/symfony/issues/comments/725335443,[TwigBridge] AppVariable add $strictVariables,nicolas-grekas,3,740640179,2,725335443,0,740640179,2020-11-11T10:16:30Z,"I think this change is going to break apps that currently expect `null` to be returned.
I understand why you're proposing this, but the ""app"" variable is separate from twig's strict mode: it can ignore the setting. Changing the behavior is possible but we must first resolve the BC issue.
In any way, this would be a new feature.",False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/comments/725341581,[TwigBridge] AppVariable add $strictVariables,ybenhssaien,3,740640179,3,725341581,0,725335443,2020-11-11T10:28:51Z,I will update my pull request to make it as a new feature on `5.x` branch,False,0,CONTRIBUTOR
https://api.github.com/repos/symfony/symfony/issues/comments/924003624,[TwigBridge] AppVariable add $strictVariables,fabpot,3,740640179,4,924003624,0,725341581,2021-09-21T13:43:44Z,"I'm not convinced by this change, let's close.
",False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/39054,@Autowired annotation,Microtribute,5,740669717,1,740669717,0,0,2020-11-11T10:51:39Z,"**Description**  
It would be nice if we had `@Autowired` annotation like Spring. Rather than injecting services via the constructor, we could use `@Autowired` annotation to make it even simpler. Check out the examples below:

**Example**  
Currently we're injecting services via the constructor.

```php
namespace App\Manager;

use Psr\Log\LoggerInterface;
use Symfony\Component\Routing\Matcher\UrlMatcherInterface;

class TrafficManager
{
    private UrlMatcherInterface $urlMatcher;
    private LoggerInterface $logger;

    public function __construct(UrlMatcherInterface $urlMatcher, LoggerInterface $logger)
    {
        $this->urlMatcher = $urlMatcher;
        $this->logger = $logger;
    }

    public function match(string $url)
    {
        try {
             $this->urlMatcher->match($url);
        } catch (\Throwable $e) {
            $this->logger->error($e->getMessage());
        }
    }
}
```

If we had `@Autowired` annotation, we could make this simpler eliminating the need of creating a constructor.

```php
namespace App\Manager;

use Psr\Log\LoggerInterface;
use Symfony\Component\Routing\Matcher\UrlMatcherInterface;
use Symfony\Comonent\DependencyInjection\Annotations\Autowired;

class TrafficManager
{
    #[Autowired]
    private UrlMatcherInterface $urlMatcher;
    
    #[Autowired]
    private LoggerInterface $logger;

    public function match(string $url)
    {
        try {
             $this->urlMatcher->match($url);
        } catch (\Throwable $e) {
            $this->logger->error($e->getMessage());
        }
    }
}
```
",True,0,NONE
https://api.github.com/repos/symfony/symfony/issues/comments/725356986,@Autowired annotation,michaljusiega,5,740669717,2,725356986,0,740669717,2020-11-11T11:01:03Z,"Currently is `@required` annotation, but working only on public properties. See https://symfony.com/doc/current/service_container/autowiring.html#autowiring-other-methods-e-g-setters-and-public-typed-properties",False,0,CONTRIBUTOR
https://api.github.com/repos/symfony/symfony/issues/comments/725383110,@Autowired annotation,derrabus,5,740669717,3,725383110,0,725356986,2020-11-11T11:58:57Z,"We have `#[Required]` that does just that for public properties. For private properties, use constructor injection instead. If you have php 8 available, you can use constructor property promotion.

```php
namespace App\Manager;

use Psr\Log\LoggerInterface;
use Symfony\Component\Routing\Matcher\UrlMatcherInterface;

class TrafficManager
{
    public function __construct(
        private UrlMatcherInterface $urlMatcher,
        private LoggerInterface $logger,
    ) {}

    public function match(string $url)
    {
        try {
             $this->urlMatcher->match($url);
        } catch (\Throwable $e) {
            $this->logger->error($e->getMessage());
        }
    }
}
```",False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/comments/725384058,@Autowired annotation,Microtribute,5,740669717,4,725384058,0,725383110,2020-11-11T12:01:13Z,"A deadly simple example of injecting a service into a non-public property would look like this.

```php
class Service
{
    /**
     * @Autowired
     */
    private LoggerInterface $logger;

    public function getLogger(): LoggerInterface
    {
        return $this->logger;
    }
}


$service = new Service();

$ref = new ReflectionObject($service);

$properties = $ref->getProperties();

foreach ($properties as $property) {
    $isAutowired = false !== strpos($property->getDocComment(), '@Autowired');

    if ($isAutowired) {
        $type = $property->getType();

        if ($type && $container->hasService($type)) {
            $property->setAccessible(true);
            $property->setValue($service, $container->getService($type));
        } else {
            throw new TypeError('Invalid type for autowired service property');
        }
    }
}
```

> Btw, this code only works for PHP 7.4+",False,0,NONE
https://api.github.com/repos/symfony/symfony/issues/comments/725397072,@Autowired annotation,derrabus,5,740669717,5,725397072,0,725384058,2020-11-11T12:31:00Z,"Yes, this feature isn't hard to build. But we have rejected injecting private properties in the past (see the discussion on #34769), so I doubt that it's going to happen this time.

The main problem for me is that you would create classes that cannot be instantiated without a DIC or similar tooling anymore. That is a situation that should be avoided imho.",False,0,MEMBER
https://api.github.com/repos/symfony/symfony/issues/comments/725404369,@Autowired annotation,xabbuh,5,740669717,6,725404369,0,725397072,2020-11-11T12:47:38Z,"> The main problem for me is that you would create classes that cannot be instantiated without a DIC or similar tooling anymore. That is a situation that should be avoided imho.

I agree with this reasoning. Thus 👎  from me for adding this feature.",False,0,MEMBER
https://api.github.com/repos/ipython/ipython/issues/12729,Unable to pass argument with space to cell magic,memeplex,3,767087029,1,767087029,0,0,2020-12-15T02:03:13Z,"<!-- This is the repository for IPython command line, if you can try to make sure this question/bug/feature belong here and not on one of the Jupyter repositories. 

If it's a generic Python/Jupyter question, try other forums or discourse.jupyter.org.

If you are unsure, it's ok to post here, though, there are few maintainer so you might not get a fast response. 

Ability of maintainers to spend time and resources on project like IPython is heavily influenced by US politics, and the current government policies have been harmful to the IPython Maintainers and Community. 

If you are on the fence on who to vote for or wether to vote, please cast your vote in for the democrat party in the US.
-->

Cython defines this argument for the `%%cython` margin:

```
    @magic_arguments.argument(
        '--link-args', action='append', default=[],
        help=""Extra flags to pass to linker via the `extra_link_args` ""
             ""Extension flag (can be specified  multiple times).""
    )
```

But trying to pass `%%cython --link-args=""-L/Users/carlos/Desktop/Test LGBM API""` I get:

```
UsageError: unrecognized arguments: LGBM API""
```

If I mimic what I believe this should be doing, I get:

EDIT: there is a typo in this code, please see comments below.

```
In [15]: l = shlex.shlex('%%cython --link-args=""-L/Users/carlos/Desktop/Test LGBM API""', posix=False)

In [16]: a.whitespace_split=True

In [17]: a.commenters=''

In [18]: list(l)
Out[18]:
['%',
 '%',
 'cython',
 '-',
 '-',
 'link',
 '-',
 'args',
 '=',
 '""-L/Users/carlos/Desktop/Test LGBM API""']
```

which seems fine.

My system is MacOS 11.0.1. I'm using python 3.8.6 with ipython 7.19.0.
",True,0,CONTRIBUTOR
https://api.github.com/repos/ipython/ipython/issues/comments/745009113,Unable to pass argument with space to cell magic,memeplex,3,767087029,2,745009113,0,767087029,2020-12-15T02:22:39Z,"Well, debugging `arg_split` shows that it is indeed splitting the argument:

```
ipdb>  p list(lex)
['--link-args=""-L/Users/carlos/Desktop/Test', 'LGBM', 'API""']
```

I have `posix = False` and `strict = True`. The problem is with `whitespace_split = True`. I didn't catch it above because of a typo (used `a` which was in my history instead of `l`). 

Now, this seems excessive to me, why are you splitting in every whitespace disregarding quoting? If this is on purpose, how can I introduce whitespace in my arguments?",False,0,CONTRIBUTOR
https://api.github.com/repos/ipython/ipython/issues/comments/745016291,Unable to pass argument with space to cell magic,memeplex,3,767087029,3,745016291,0,745009113,2020-12-15T02:46:54Z,"Ok, I think it's not that serious, the problem is caused because of the `=` before the `""`, the lexer somehow gets confused by this:

```
In [22]: s = shlex.shlex('--link-args ""-L/Users/carlos/Desktop/Test LGBM API""', posix=False)

In [23]: s.whitespace_split = True

In [24]: list(s)
Out[24]: ['--link-args', '""-L/Users/carlos/Desktop/Test LGBM API""']

In [25]: s = shlex.shlex('--link-args=""-L/Users/carlos/Desktop/Test LGBM API""', posix=False)

In [26]: s.whitespace_split = True

In [27]: list(s)
Out[27]: ['--link-args=""-L/Users/carlos/Desktop/Test', 'LGBM', 'API""']
```

The documentation states

> When operating in non-POSIX mode, shlex will try to obey to the following rules.
> - Quote characters are not recognized within words (Do""Not""Separate is parsed as the single word Do""Not""Separate);
> - Closing quotes separate words (""Do""Separate is parsed as ""Do"" and Separate);

Indeed in POSIX mode the behavior is more sensible:

```
In [28]: s = shlex.shlex('--link-args=""-L/Users/carlos/Desktop/Test LGBM API""', posix=True)

In [29]: s.whitespace_split = True

In [30]: list(s)
Out[30]: ['--link-args=-L/Users/carlos/Desktop/Test LGBM API']
```

So I change my question: why do you set `posix = False` by default? But the other question remains: how can I solve my immediate problem?

Alternatives that don't work:

* `--link-args ""-L/Users/carlos/Desktop/Test LGBM API""`: passes the quotes alongside the argument.

* `--link-args=-L/Users/carlos/Desktop/Test\ LGBM\ API`: still splits on whitespace.

Regarding the second option, again `posix = True` should be preferable:

> shlex.escape
> Characters that will be considered as escape. This will be only used in POSIX mode, and includes just '\' by default.
",False,0,CONTRIBUTOR
https://api.github.com/repos/ipython/ipython/issues/comments/823697960,Unable to pass argument with space to cell magic,MrMino,3,767087029,4,823697960,0,745016291,2021-04-21T00:53:35Z,"I have a feeling that `posix=True` might break under Windows - haven't checked though. Anyway, you should be able to pass paths with spaces inside them here, so let's treat this as a bug.",False,0,MEMBER
https://api.github.com/repos/ipython/ipython/issues/12734,Feature add autoreload option 3,skalaydzhiyski,3,770039478,1,770039478,0,0,2020-12-17T13:36:31Z,"This feature will allow us to synchonise a script/module with an open IPython session. 

Currently:
  With the option %autoreload 2 , we can only update the state of existing objects loaded from a module.
Now:
  We will be able to automatically load newly added objects to a module without us having to re-run our import statements.
  Also we can load and autoreload global vars of built-in types, which wasn't possible with previous versions of the autoreload extension.

Example Usage:
 
1. Make sure you load the extension with the new option 3
![image](https://user-images.githubusercontent.com/49019817/102493963-dc803480-406b-11eb-8fa9-3fe9af250740.png)

2. We have a **mod.py** (currently empty)
![image](https://user-images.githubusercontent.com/49019817/102494358-747e1e00-406c-11eb-843d-3675cdf82fed.png)
![image](https://user-images.githubusercontent.com/49019817/102494404-82cc3a00-406c-11eb-8453-ed0629f4df58.png)

3. We create a bunch of objects inside **mod.py**
![image](https://user-images.githubusercontent.com/49019817/102494433-8bbd0b80-406c-11eb-9cc0-fa7fc3a0738d.png)

4. Then all of them automatically appear in the local context of our open session
![image](https://user-images.githubusercontent.com/49019817/102494530-af805180-406c-11eb-953e-000434f70a55.png)

5. We change the values of the loaded objects
![image](https://user-images.githubusercontent.com/49019817/102494550-bb6c1380-406c-11eb-8fba-0325169f2978.png)

6. And we can see they are updated automatically in the session, keeping the existing functionality:
![image](https://user-images.githubusercontent.com/49019817/102527089-8a9fd480-4094-11eb-9f7b-d8a5c28ce0af.png)


For an example run, please see the unit test I have added as part of the PR.
",True,0,CONTRIBUTOR
https://api.github.com/repos/ipython/ipython/issues/comments/812942519,Feature add autoreload option 3,MrMino,3,770039478,2,812942519,0,770039478,2021-04-03T23:48:50Z,"Is this a duplicate of #12733? If so, could you please close one one of these PRs?",False,0,MEMBER
https://api.github.com/repos/ipython/ipython/issues/comments/813010350,Feature add autoreload option 3,skalaydzhiyski,3,770039478,3,813010350,0,812942519,2021-04-04T10:35:46Z,"> Is this a duplicate of #12733? If so, could you please close one one of these PRs?
Yes, it was a duplicate, thanks for that. Just deleted it.
",False,0,CONTRIBUTOR
https://api.github.com/repos/ipython/ipython/issues/comments/821737998,Feature add autoreload option 3,Carreau,3,770039478,4,821737998,0,813010350,2021-04-17T00:45:58Z,"Apologies for the delay in reviewing.

That looks good, let try to get that in master.

Thanks both.",False,0,MEMBER
https://api.github.com/repos/ipython/ipython/issues/12737,Errors were randomly raised while using Ipython in CMD.,GasinAn,6,772226105,1,772226105,0,0,2020-12-21T14:51:21Z,"When I used Ipython in CMD, randomly it showed this:

Unhandled exception in event loop:
  File ""C:\ProgramData\Anaconda3\lib\asyncio\proactor_events.py"", line 768, in _loop_self_reading
    f.result()  # may raise
  File ""C:\ProgramData\Anaconda3\lib\asyncio\windows_events.py"", line 808, in _poll
    value = callback(transferred, key, ov)
  File ""C:\ProgramData\Anaconda3\lib\asyncio\windows_events.py"", line 457, in finish_recv
    raise ConnectionResetError(*exc.args)

Exception [WinError 995] 由于线程退出或应用程序请求，已中止 I/O 操作。
Press ENTER to continue...

(""由于线程退出或应用程序请求，已中止 I/O 操作。"" means ""The I/O operation was aborted due to thread exit or application request."")

However, I still could continue using Ipython. An example:

Python 3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]
Type 'copyright', 'credits' or 'license' for more information
IPython 7.19.0 -- An enhanced Interactive Python. Type '?' for help.

In [1]: print('Hello, world!')
Hello, world!

In [2]: print('Hello, world!')
Hello, world!

In [3]: print('Hello, world!')
Hello, world!

In [4]: print('Hello, world!')
Hello, world!


Unhandled exception in event loop:
  File ""C:\ProgramData\Anaconda3\lib\asyncio\proactor_events.py"", line 768, in _loop_self_reading
    f.result()  # may raise
  File ""C:\ProgramData\Anaconda3\lib\asyncio\windows_events.py"", line 808, in _poll
    value = callback(transferred, key, ov)
  File ""C:\ProgramData\Anaconda3\lib\asyncio\windows_events.py"", line 457, in finish_recv
    raise ConnectionResetError(*exc.args)

Exception [WinError 995] 由于线程退出或应用程序请求，已中止 I/O 操作。
Press ENTER to continue...
In [5]: print('Hello, world!')
Hello, world!

I am really unwilling to see these :(.

",True,0,NONE
https://api.github.com/repos/ipython/ipython/issues/comments/749015556,Errors were randomly raised while using Ipython in CMD.,GasinAn,6,772226105,2,749015556,0,772226105,2020-12-21T14:57:44Z,These errors were never raised until I reinstall Anaconda in December.,False,0,NONE
https://api.github.com/repos/ipython/ipython/issues/comments/823583896,Errors were randomly raised while using Ipython in CMD.,MrMino,6,772226105,3,823583896,0,749015556,2021-04-20T20:36:42Z,"@GasinAn is this still an issue for you? Have you tried with an updated IPython version? I remember seeing these errors a while ago, when working on Windows, but I thought it's due to the particularities of my setup.",False,0,MEMBER
https://api.github.com/repos/ipython/ipython/issues/comments/823708007,Errors were randomly raised while using Ipython in CMD.,MrMino,6,772226105,4,823708007,0,823583896,2021-04-21T01:26:14Z,Duplicate of #12722. @GasinAn if you still need - let's continue there.,False,0,MEMBER
https://api.github.com/repos/ipython/ipython/issues/comments/825943158,Errors were randomly raised while using Ipython in CMD.,GasinAn,6,772226105,5,825943158,0,823708007,2021-04-23T21:50:51Z,"@MrMino Thank you, now everything is well.",False,0,NONE
https://api.github.com/repos/ipython/ipython/issues/comments/825945146,Errors were randomly raised while using Ipython in CMD.,GasinAn,6,772226105,6,825945146,0,825943158,2021-04-23T21:56:43Z,"@MrMino But I don't know when it was fixed :). When I faced that problem, I commented the line which raised exceptions, and also one day I uninstalled Anaconda and installed Miniconda, all in all now everything goes well.",False,0,NONE
https://api.github.com/repos/ipython/ipython/issues/comments/825950344,Errors were randomly raised while using Ipython in CMD.,MrMino,6,772226105,7,825950344,0,825945146,2021-04-23T22:12:13Z,"@GasinAn Me neither :) Probably I just wasn't around when the fix happened. In any case, if you happen to trigger the error again in the future, please put the logs into #12722 ",False,0,MEMBER
https://api.github.com/repos/ipython/ipython/issues/12739,BUG: The `%conda` magic doesn't work,farisachugthai,3,774658458,1,774658458,0,0,2020-12-25T07:10:24Z,"Due to moving the repo away from os.path to pathlib, the wrong method is called on a Path object.

In addition, no checks are provided when trying to slice the args objects that the user provides. As a result, if they don't provide enough arguments (which can happen in normal use very frequently), running the magic  raises.",True,0,CONTRIBUTOR
https://api.github.com/repos/ipython/ipython/issues/comments/757133290,BUG: The `%conda` magic doesn't work,farisachugthai,3,774658458,2,757133290,0,774658458,2021-01-09T11:06:46Z,"Just wanna note the only test that seems to have failed, did so because SQLite attempted to operate on a readonly database? ",False,0,CONTRIBUTOR
https://api.github.com/repos/ipython/ipython/issues/comments/758068436,BUG: The `%conda` magic doesn't work,Carreau,3,774658458,3,758068436,0,757133290,2021-01-11T16:29:19Z,"> Just wanna note the only test that seems to have failed, did so because SQLite attempted to operate on a readonly database?

that's unrelated, it's a race condition on travis. Thanks.",False,0,MEMBER
https://api.github.com/repos/ipython/ipython/issues/comments/758068672,BUG: The `%conda` magic doesn't work,lumberbot-app[bot],3,774658458,4,758068672,0,758068436,2021-01-11T16:29:41Z,"Owee, I'm MrMeeseeks, Look at me.

There seem to be a conflict, please backport manually. Here are approximate instructions:

1. Checkout backport branch and update it.

```
$ git checkout 7.x
$ git pull
```

2. Cherry pick the first parent branch of the this PR on top of the older branch:
```
$ git cherry-pick -m1 6a7c488093026577db0d5c5f21d2aea129e5b6c9
```

3. You will likely have some merge/cherry-pick conflict here, fix them and commit:

```
$ git commit -am ""Backport PR #12739: BUG: The `%conda` magic doesn't work""
```

4. Push to a named branch :

```
git push YOURFORK 7.x:auto-backport-of-pr-12739-on-7.x
```

5. Create a PR against branch 7.x, I would have named this PR:

> ""Backport PR #12739 on branch 7.x""

And apply the correct labels and milestones.

Congratulation you did some good work ! Hopefully your backport PR will be tested by the continuous integration and merged soon!

If these instruction are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).
                ",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/552,Add `isSubmarine` to unitdefs' movedef subtable,sprunk,4,822134836,1,822134836,0,0,2021-03-04T13:30:43Z,,True,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/842668011,Add `isSubmarine` to unitdefs' movedef subtable,lhog,4,822134836,2,842668011,0,822134836,2021-05-17T21:54:24Z,Is this one needed/wanted still?,False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/842669061,Add `isSubmarine` to unitdefs' movedef subtable,sprunk,4,822134836,3,842669061,0,842668011,2021-05-17T21:56:52Z,"Yes but it should probably be PR'd to `transition` instead, and/or to BAR. I'm unsure where to PR things nowadays.",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/842671292,Add `isSubmarine` to unitdefs' movedef subtable,lhog,4,822134836,4,842671292,0,842669061,2021-05-17T22:01:50Z,I'm unsure either. I guess the final decision is on Kloot as the one who put tremendous effort in spring in general and on develop specifically. ,False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/844496556,Add `isSubmarine` to unitdefs' movedef subtable,rtri,4,822134836,5,844496556,0,842671292,2021-05-19T21:45:42Z,"FTR I don't anticipate much non-rendering work being done for the foreseeable future, so PR's following the usual develop->transition path are fine.",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/558,Provide PCG32::result_type,AMDmi3,3,865023334,1,865023334,0,0,2021-04-22T14:32:20Z,"Provide result_type member type in PCG32, which makes it compatible with C++ UniformRandomBitGenerator and, as result, makes it usable in std::shuffle (which deprecated std::random_shuffle calls in Spring should be replaced with).",True,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/825803818,Provide PCG32::result_type,sprunk,3,865023334,2,825803818,0,865023334,2021-04-23T17:23:01Z,"```
/home/travis/build/spring/spring/rts/System/GlobalRNG.h:49:22: error: unknown type name 'rng_res_type'; did you mean 'res_type'?

        using result_type = rng_res_type;

                            ^~~~~~~~~~~~

                            res_type

/home/travis/build/spring/spring/rts/System/GlobalRNG.h:46:19: note: 'res_type' declared here

        typedef uint32_t res_type;

                         ^
```",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/825807387,Provide PCG32::result_type,AMDmi3,3,865023334,3,825807387,0,825803818,2021-04-23T17:29:21Z,"Fixed. This was originally a patch against 105.0, hence the difference.",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/826583279,Provide PCG32::result_type,abma,3,865023334,4,826583279,0,825807387,2021-04-26T07:30:54Z,thank you!,False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/559,This is to merge back BAR branch into spring/transition,lhog,51,889808682,1,889808682,0,0,2021-05-12T08:17:50Z,This revision of the branch should have near 100% compatibility with 105.,True,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/839615583,This is to merge back BAR branch into spring/transition,rtri,51,889808682,2,839615583,0,889808682,2021-05-12T09:24:14Z,There are too many changes in too many places here for me to hit merge directly. I'll take some time to review this first if you don't mind.,False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/839630332,This is to merge back BAR branch into spring/transition,lhog,51,889808682,3,839630332,0,839615583,2021-05-12T09:40:02Z,"Oh hey Kloot!

Sure, I warned that the amount would soon be unmanageable several months ago and indeed it has become such. Sadly back in the day I hadn't seen any interest to get it merged. Hopefully these days it's gonna be different.

I want to continue what started as BAR branch at spring/spring as per https://springrts.com/phpbb/viewtopic.php?p=598472#p598472",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/839830152,This is to merge back BAR branch into spring/transition,rtri,51,889808682,4,839830152,0,839630332,2021-05-12T14:43:13Z,"Fine with me, so long as you can accept and respect other people's reduced availability since (at least on my end) working from home has sadly not created more free time to spend elsewhere. Tomorrow is a national holiday around these parts so I'll dive into this then.",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/839944667,This is to merge back BAR branch into spring/transition,lhog,51,889808682,5,839944667,0,839830152,2021-05-12T17:03:50Z,"It's fine, take your time. The life has not become easier for many of us since the pandemic started.
I personally struggle to share the time between the work, family, spring/BAR and recreation.

I also want to set certain expectations from my side:
* I'm not a programmer by trades, nor I have dealt with C++ largely before. I learn as I go, so any coding advises from you, @gajop , @ashdnazg or anyone proficient are welcome.
* With PR of such size, I hope to not see remarks like number of spaces, new lines, etc. Some glaring style violations (if any) can be fixed of course.
* Since I was asked to keep BAR way of migration up to date, I'll need commit rights to spring/spring.",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/841343801,This is to merge back BAR branch into spring/transition,lhog,51,889808682,6,841343801,0,839944667,2021-05-14T16:13:53Z,"As far as I can tell for now only one big item left undecided/unfixed: heightmap ref map.
The rest are more or less cosmetic issues.",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/841875345,This is to merge back BAR branch into spring/transition,abma,51,889808682,7,841875345,0,841343801,2021-05-16T20:47:07Z,"can you please cherry pick the changes which where made to .travis.yml, especially

https://github.com/spring/spring/commit/d667ad0cafc4a286070ac15d8ff5fe335a4b0ca9

",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/842097819,This is to merge back BAR branch into spring/transition,lhog,51,889808682,8,842097819,0,841875345,2021-05-17T07:50:25Z,"Sure it can be done here or afterwards.

But why bother with travis?

I heard in November they announced new pricing plan that made a lot of projects migrate away from them. https://travis-ci.org/ itself says they will be shutting down the former domain and continue under the new one. For this PR it doesn't seem to work at all.

Moreover we have github actions. Right now they are launched on-demand to save free tier minutes, but with usual spring commits activity it can probably be run on commits and PRs too.",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/842100383,This is to merge back BAR branch into spring/transition,lhog,51,889808682,9,842100383,0,842097819,2021-05-17T07:53:49Z,"BTW, please fork https://github.com/beyond-all-reason/spring-static-libs into spring or give me fork rights.
This is my reverse engineering work to build linux static libs necessary to build linux version of spring.",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/842144072,This is to merge back BAR branch into spring/transition,abma,51,889808682,10,842144072,0,842100383,2021-05-17T08:48:54Z,"> But why bother with travis?

because it does compile test + unit tests on every commit.
",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/842144532,This is to merge back BAR branch into spring/transition,abma,51,889808682,11,842144532,0,842144072,2021-05-17T08:49:34Z,"> BTW, please fork https://github.com/beyond-all-reason/spring-static-libs into spring or give me fork rights.
> This is my reverse engineering work to build linux static libs necessary to build linux version of spring.

why not change it upstream? duplicating code should be really avoided.",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/842189789,This is to merge back BAR branch into spring/transition,lhog,51,889808682,12,842189789,0,842144532,2021-05-17T09:55:52Z,"> because it does compile test + unit tests on every commit.

Github CI can absolutely do same. But whatever... not worth the argument at the present time.
Is https://github.com/spring/spring/commit/d667ad0cafc4a286070ac15d8ff5fe335a4b0ca9 the only one needs cherry-picking? Perhaps I can just checkout the whole files from 105.0.1 if there are too many others?

> why not change it upstream? duplicating code should be really avoided.

Whatever your prefer. I was going to just follow the cargo cult and do like others did for their side work (example: https://github.com/spring/CircuitAI ), i.e. to fork to spring and continue here.
That said I cannot do forks nor create new repos (insufficient set of rights). Thus my ask to give rights or do stuff yourself.",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/842202098,This is to merge back BAR branch into spring/transition,abma,51,889808682,13,842202098,0,842189789,2021-05-17T10:14:33Z,"> Github CI can absolutely do same. But whatever... not worth the argument at the present time.
> Is [d667ad0](https://github.com/spring/spring/commit/d667ad0cafc4a286070ac15d8ff5fe335a4b0ca9) the only one needs cherry-picking? Perhaps I can just checkout the whole files from 105.0.1 if there are too many others?

i have no clue as it fails at a very early stage and have no clue how large the diff between develop and ""transition"". just please cherry-pick the commit to reduce the diff and very likely fix travis compile.
",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/842514280,This is to merge back BAR branch into spring/transition,lhog,51,889808682,14,842514280,0,842202098,2021-05-17T17:47:26Z,Now .travis.yml are identical between develop and this one. Probably some other files diverged.,False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/842574932,This is to merge back BAR branch into spring/transition,lhog,51,889808682,15,842574932,0,842514280,2021-05-17T19:27:06Z,Ok travis doesn't seem to work with this PR and it probably won't work w/o adaptation to the changes I did to make it build-able on github CI (and in Docker container).,False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/842587860,This is to merge back BAR branch into spring/transition,abma,51,889808682,16,842587860,0,842574932,2021-05-17T19:51:38Z,"https://travis-ci.org/github/spring/spring/jobs/771462288#L867 ->
this is what fails: https://github.com/spring/spring/pull/559/files#diff-48b508d8a5702095973f36f384be2a8b74834092bb7ed47c536f1af80015b20bR4

seems the check is invalid: https://cmake.org/cmake/help/latest/policy/CMP0077.html
CMP0077 requires cmake >= 3.12 and travis seems to use  3.12.4: not sure why ""NOT CMAKE_VERSION VERSION_LESS 3.12"" is used, i would use 
if (CMAKE_VERSION VERSION_GREATER_EQUAL 3.13)

edit: https://github.com/zeux/meshoptimizer/pull/283
",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/842661553,This is to merge back BAR branch into spring/transition,lhog,51,889808682,17,842661553,0,842587860,2021-05-17T21:42:44Z,"Ok this is above my paygrade so to speak. Glad you know stuff.

Does travis have no cmake replacement procedure? Like here: https://github.com/beyond-all-reason/spring/blob/BAR/.github/workflows/build.yml#L98-L101 ?

We will also need newer GCC. Something like 9.x or better 10.x.",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/847350987,This is to merge back BAR branch into spring/transition,abma,51,889808682,18,847350987,0,842661553,2021-05-24T21:33:34Z,"1. can you please readd the AIs? for the failing ais see
https://travis-ci.org/github/spring/spring/jobs/771996375

2. fix the tests, linking fails https://travis-ci.org/github/spring/spring/jobs/771996376:
[ 91%] Linking CXX executable test_Matrix44f
CMakeFiles/test_Matrix44f.dir/__/rts/System/Matrix44f.cpp.o:Matrix44f.cpp:function CMatrix44f::ClipOrthoProj01(): error: undefined reference to 'globalRendering'
collect2: error: ld returned 1 exit status
test/CMakeFiles/test_Matrix44f.dir/build.make:353: recipe for target 'test/test_Matrix44f' failed
make[3]: *** [test/test_Matrix44f] Error 1
make[3]: Target 'test/CMakeFiles/test_Matrix44f.dir/build' not remade because of errors.
CMakeFiles/Makefile2:5189: recipe for target 'test/CMakeFiles/test_Matrix44f.dir/all' failed
make[2]: *** [test/CMakeFiles/test_Matrix44f.dir/all] Error 2
",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/847369639,This is to merge back BAR branch into spring/transition,lhog,51,889808682,19,847369639,0,847350987,2021-05-24T22:00:32Z,"> can you please readd the AIs? for the failing ais see

Generally yes, but I think we need to do certain things:
* Remove ancient AIs: HughAI, some others(if any) no one uses
* Add new BARbarian, a modified CircuitAI that works with BAR
* Agree how to rewrite the part of builder script that I'm least proud of: https://github.com/beyond-all-reason/spring/blob/BAR/.github/workflows/build.yml#L422-L433

> fix the tests, linking fails https://travis-ci.org/github/spring/spring/jobs/771996376:

Sure. In the tasks queue.",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/847539151,This is to merge back BAR branch into spring/transition,abma,51,889808682,20,847539151,0,847369639,2021-05-25T05:17:16Z,"@rtri:

what do you think about renaming the branch ""transition"" to ""develop"" and ""develop"" to ""opengl4-test""?

(as renaming seems not possbile, it would be a revert + merge commit in the develop branch)

we really need to get rid of two development branches.",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/847542143,This is to merge back BAR branch into spring/transition,abma,51,889808682,21,847542143,0,847539151,2021-05-25T05:23:09Z,"
> * Remove ancient AIs: HughAI, some others(if any) no one uses

i don't care much about which ai's are kept: but the tests needs to be fixed.

> Agree how to rewrite the part of builder script that I'm least proud of: https://github.com/beyond-all-reason/spring/blob/BAR/.github/workflows/build.yml#L422-L433

for now use ""make install"" instead of manually coping files and hard-coding a lot of paths.
",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/847706236,This is to merge back BAR branch into spring/transition,lhog,51,889808682,22,847706236,0,847542143,2021-05-25T09:21:32Z,"> i don't care much about which ai's are kept: but the tests needs to be fixed.

Ok, I'll have a look some time later

> for now use ""make install"" instead of manually coping files and hard-coding a lot of paths.

Last time I checked `make install` did not produce the operational files/directory structure, that one could put into zip and distribute as minimal standalone engine package. Can you work on `make install` or say `make distro` script so it copies all files into the install dir such that it can be packaged as zip later on?

> side node: some additions in rts/lib seems to not contain the ""LICENSE"" files

Yeah it's accidental. I'll restore.

> when possible IMHO it would be better to use git submodules: this should make it easier to keep dependencies up to date.

Not sure it's the for the best. Some libs have ""fat"" like tests, benchmarks, examples, additional libs, etc. trimmed off.",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/847906784,This is to merge back BAR branch into spring/transition,abma,51,889808682,23,847906784,0,847706236,2021-05-25T14:14:32Z,"> Can you work on make install or say make distro script so it copies all files into the install dir such that it can be packaged as zip later on?

done: https://github.com/spring/spring/blob/develop/buildbot/slave/linux/create_linux_static_bundle.sh :-) (thats exactly what happens in this script)
",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/847951373,This is to merge back BAR branch into spring/transition,lhog,51,889808682,24,847951373,0,847906784,2021-05-25T15:09:26Z,"I'm yet to find out how you dealt with AI versions/tags. Yet in principle it is only marginally to what github builder does. I was talking about make command implementation, which everyone in Nix world are used to.",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/847957561,This is to merge back BAR branch into spring/transition,lhog,51,889808682,25,847957561,0,847951373,2021-05-25T15:15:53Z,"I'm yet to find out how you dealt with AI versions/tags. But in principle it is only marginally better to what github builder does. I was talking about make command implementation, which everyone in Nix world are used to.",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/847980691,This is to merge back BAR branch into spring/transition,abma,51,889808682,26,847980691,0,847957561,2021-05-25T15:40:58Z,"> I'm yet to find out how you dealt with AI versions/tags. But in principle it is only marginally better to what github builder does. I was talking about make command implementation, which everyone in Nix world are used to.

i don't understand what you mean. the script uses ""make install"": https://github.com/spring/spring/blob/develop/buildbot/slave/linux/create_linux_static_bundle.sh#L19

ai versions/tags are handled with cmake. the only thing which happens in the .sh is stripping + creating the .7z archives.
maybe you are looking for https://github.com/spring/spring/blob/a8cf33ad1d2ac775e6008cd04baa7e859d1f23ec/AI/Interfaces/C/CMakeLists.txt#L16 ?",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/848184703,This is to merge back BAR branch into spring/transition,lhog,51,889808682,27,848184703,0,847980691,2021-05-25T19:02:46Z,"> i don't understand what you mean. the script uses ""make install"": https://github.com/spring/spring/blob/develop/buildbot/slave/linux/create_linux_static_bundle.sh#L19

Ah I missed that. Makes sense. I'll give it a try again.",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/849481069,This is to merge back BAR branch into spring/transition,lhog,51,889808682,28,849481069,0,848184703,2021-05-27T09:23:18Z,"@abma  I fixed tests compilation, AI tests and test results.",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/849920337,This is to merge back BAR branch into spring/transition,abma,51,889808682,29,849920337,0,849481069,2021-05-27T20:29:49Z,"> @abma I fixed tests compilation, AI tests and test results.

nice, thanks!",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/850010243,This is to merge back BAR branch into spring/transition,lhog,51,889808682,30,850010243,0,849920337,2021-05-27T23:39:15Z,"@abma I rechecked `make install`. Here are my findings:
* if `AI_TYPES` = `NONE`, then no AI dir is created by install. Is this expected? I'd expect it to create AI dir and put interfaces there, but not the actual skirmishers.
* Files structure is a bit different from what I get from buildbot:

```
ls -al /spring/build-linux-64/install/
total 940488
drwxr-xr-x 10 root root      4096 May 28 02:24 .
drwxr-xr-x 12 root root      4096 May 28 02:29 ..
drwxr-xr-x  4 root root      4096 May 28 02:24 AI
drwxr-xr-x  9 root root      4096 May 28 02:21 LuaUI
drwxr-xr-x  3 root root      4096 May 28 02:21 base
-rw-r--r--  1 root root      2308 Jan 28 13:40 cmdcolors.txt
-rw-r--r--  1 root root      2757 Jan 28 13:40 ctrlpanel.txt
drwxr-xr-x  3 root root      4096 May 28 02:21 examples
drwxr-xr-x  2 root root      4096 May 28 02:21 fonts
drwxr-xr-x  3 root root      4096 May 28 02:21 include
drwxr-xr-x  4 root root      4096 May 28 02:21 lib
-rw-r--r--  1 root root  49744456 May 28 02:18 libunitsync.so
-rw-r--r--  1 root root      1822 Jan 28 13:40 luaui.lua
-rwxr-xr-x  1 root root   9010144 May 28 02:18 mapcompile
-rwxr-xr-x  1 root root   8911312 May 28 02:18 mapdecompile
-rwxr-xr-x  1 root root  16018080 May 28 02:18 pr-downloader
drwxr-xr-x  5 root root      4096 May 28 02:21 share
-rw-r--r--  1 root root      3987 Jan 28 13:40 socket.lua
-rwxr-xr-x  1 root root 415526072 May 28 02:20 spring
-rwxr-xr-x  1 root root  62483160 May 28 02:20 spring-dedicated
-rwxr-xr-x  1 root root 401292680 May 28 02:21 spring-headless
```
I have redundant `include` and `lib`:

```
ls -al /spring/build-linux-64/install/include/
total 72
drwxr-xr-x  3 root root  4096 May 28 02:34 .
drwxr-xr-x 10 root root  4096 May 28 02:34 ..
drwxr-xr-x  3 root root  4096 May 28 02:34 git2
-rw-r--r--  1 root root  1803 Jan 28 13:40 git2.h
-rw-r--r--  1 root root 54819 May 28 02:04 meshoptimizer.h

ls -al /spring/build-linux-64/install/lib/
total 14776
drwxr-xr-x  4 root root     4096 May 28 02:34 .
drwxr-xr-x 10 root root     4096 May 28 02:34 ..
drwxr-xr-x  3 root root     4096 May 28 02:34 cmake
-rw-r--r--  1 root root 13579140 May 28 02:18 libgit2.a
-rw-r--r--  1 root root  1529636 May 28 02:17 libmeshoptimizer.a
drwxr-xr-x  2 root root     4096 May 28 02:34 pkgconfig
```
Do you know where they might come from?

This step probably makes sense https://github.com/spring/spring/blob/develop/buildbot/slave/linux/create_linux_static_bundle.sh#L57 to port over to `make install` too.

All in all include & lib aside seems like I can replace my github script crap mostly with just `make install`",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/850320360,This is to merge back BAR branch into spring/transition,abma,51,889808682,31,850320360,0,850010243,2021-05-28T10:27:51Z,"> if AI_TYPES = NONE, then no AI dir is created by install. Is this expected? I'd expect it to create AI dir and put interfaces there, but not the actual skirmishers.

afaik only the ai interfaces are build which are required for the requests ai's so yes.

> Do you know where they might come from?

different cmake flags. these files shouldn't be installed, thats a bug in the CMakeLists.txt. libgit stuff comes from pr-downloader, 
libmeshoptimizer.a is very likely there because of ""install()"" here: https://github.com/spring/spring/blob/382db9ff77fb842bab9d9ba2175442100ed652b1/rts/lib/meshoptimizer/CMakeLists.txt#L68

this maybe is partly fixed in ""develop"".

",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/563,All whispers are visible in a replay,sprunk,4,908179374,1,908179374,0,0,2021-06-01T11:10:05Z,,True,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/854970717,All whispers are visible in a replay,ashdnazg,4,908179374,2,854970717,0,908179374,2021-06-04T20:03:51Z,"I never knew whispers are even recorded in a demo. In any case, this won't help anything except making people speccheat in other ways.",False,0,MEMBER
https://api.github.com/repos/spring/spring/issues/comments/855001506,All whispers are visible in a replay,sprunk,4,908179374,3,855001506,0,854970717,2021-06-04T21:15:46Z,"Who said it's just for spec cheating? Maybe I would like to learn how to play FFA by watching a high skill replay and seeing how pros ~~lie to each other~~ conduct diplomacy would be helpful.

I consider the current state of affairs a bug, because I think everything in a replay should be visible unless there is a good reason not to. I don't consider privacy a good reason in this case because whispers are already in the demo so anybody dedicated can extract them anyway. Possibly whispers shouldn't be recorded in the demo instead, but I think that would go against the point of a replay.",False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/855008623,All whispers are visible in a replay,lhog,4,908179374,4,855008623,0,855001506,2021-06-04T21:31:35Z,Please don't forget to cherry-pick into transition.,False,0,CONTRIBUTOR
https://api.github.com/repos/spring/spring/issues/comments/1010380946,All whispers are visible in a replay,abma,4,908179374,5,1010380946,0,855008623,2022-01-11T21:36:18Z,as its stored in the replay file its IMHO correct to show it.,False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/39158,Minor typo on warnings,MicaelJarniac,12,785539756,1,785539756,0,0,2021-01-13T23:50:07Z,"https://github.com/pandas-dev/pandas/blob/25110a92b291de6688c3accad4c34d84837445e8/pandas/_libs/parsers.pyx#L1993-L1996
`""Columns ({warning_names}) have mixed types.Specify dtype option on import or set low_memory=False.""`
Note the lack of a space after the period on `types.Specify`. That's because there's no comma separating the strings inside the list, so they get appended while still inside the list, and get passed as a single string to `"" "".join(...)`, thus it has nothing to join.
Simply adding the missing comma should fix it.
",True,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/759830931,Minor typo on warnings,MicaelJarniac,12,785539756,2,759830931,0,785539756,2021-01-13T23:50:16Z,take,False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/901273144,Minor typo on warnings,Kavya9986,12,785539756,3,901273144,0,759830931,2021-08-18T16:54:45Z,"Hi !
I am new to the open source contribution community .
Can I take this issue ?",False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/901277281,Minor typo on warnings,MarcoGorelli,12,785539756,4,901277281,0,901273144,2021-08-18T17:00:55Z,go ahead,False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/901312917,Minor typo on warnings,Kavya9986,12,785539756,5,901312917,0,901277281,2021-08-18T17:53:46Z,"Just wanted to know if this issue still persists ? Because I think it is already fixed in #39159 .
Am I supposed to find such warning messages in the source code and fix them?",False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/901320303,Minor typo on warnings,MarcoGorelli,12,785539756,6,901320303,0,901312917,2021-08-18T18:04:52Z,"https://github.com/pandas-dev/pandas/pull/39159 wasn't merged, so it looks like this is still open",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/901325351,Minor typo on warnings,Kavya9986,12,785539756,7,901325351,0,901320303,2021-08-18T18:12:41Z,"> #39159 wasn't merged, so it looks like this is still open

Okay ! Will try fixing this ",False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/903323020,Minor typo on warnings,karthik200116,12,785539756,8,903323020,0,901325351,2021-08-22T20:02:53Z,Hey found this issue still open. Can I take this issue?. I'm new to the open-source community willing to do some useful contributions.,False,0,NONE
https://api.github.com/repos/pandas-dev/pandas/issues/comments/903328148,Minor typo on warnings,MarcoGorelli,12,785539756,9,903328148,0,903323020,2021-08-22T20:47:24Z,"it's being worked on, look up",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/903403857,Minor typo on warnings,Kavya9986,12,785539756,10,903403857,0,903328148,2021-08-23T02:59:33Z,"> Hey found this issue still open. Can I take this issue?. I'm new to the open-source community willing to do some useful contributions.

Hey! 
I'm working on this issue .",False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/903505762,Minor typo on warnings,Kavya9986,12,785539756,11,903505762,0,903403857,2021-08-23T07:14:13Z,"@MarcoGorelli . I have fixed all the warning.warn messages in the entire code .
Here is the pull request Fixed all warning.warn messages for space,full-stop etc issues #43163 .
Could you just review it ?",False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/904636024,Minor typo on warnings,Kavya9986,12,785539756,12,904636024,0,903505762,2021-08-24T13:19:44Z,"Gentle ping @MarcoGorelli .
Pull request : #43163",False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/905391690,Minor typo on warnings,Kavya9986,12,785539756,13,905391690,0,904636024,2021-08-25T10:51:31Z,"@MarcoGorelli  Could you check the pull request ? #43163

fixed flake8
104e786


![precommit](https://user-images.githubusercontent.com/60135021/130777759-714426bd-20cd-48f1-b63f-1eb60151778f.png)
",False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/39159,ERR: Fix missing space in warning message,MicaelJarniac,5,785540082,1,785540082,0,0,2021-01-13T23:51:03Z,"- [x] closes #39158 
- [x] tests added / passed
- [x] Ensure all linting tests pass, see [here](https://pandas.pydata.org/pandas-docs/dev/development/contributing.html#code-standards) for how to run them
",True,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/760170684,ERR: Fix missing space in warning message,MicaelJarniac,5,785540082,2,760170684,0,785540082,2021-01-14T12:39:14Z,"> Thanks @MicaelJarniac for the PR.
> 
> We normally check error messages in the tests so we would normally expect that changing a message would also require a change in the tests.
> 
> so it maybe that there are no tests that hit this or the message is only partially checked. so further investigation welcome.

I'll try locating the tests related to this specific message (if any), and fix (or add) them.

And I'll also try to think of a way for catching similar issues in future tests, but I don't think it'd be easy, as simply saying ""fail if no space after period"" would catch this one, but would probably have about a thousand false-positives in other messages, because in Python syntax it's perfectly valid to have `some.Thing`. A test for catching issues similar to this one might end up being overkill.",False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/760292056,ERR: Fix missing space in warning message,simonjayhawkins,5,785540082,3,760292056,0,760170684,2021-01-14T16:03:21Z,"> so it maybe that there are no tests that hit this or the message is only partially checked. so further investigation welcome.

it appears that test_warn_if_chunks_have_mismatched_type[c_low] hits this. so can modify that test to also check message.",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/775464573,ERR: Fix missing space in warning message,MicaelJarniac,5,785540082,4,775464573,0,760292056,2021-02-08T21:11:28Z,"`151214 passed, 5674 skipped, 925 xfailed, 4 xpassed, 1 warning in 1126.89s (0:18:46)`",False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/798772574,ERR: Fix missing space in warning message,jbrockmendel,5,785540082,5,798772574,0,775464573,2021-03-13T19:30:25Z,@MicaelJarniac can you merge master and we'll try to get this in,False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/848405617,ERR: Fix missing space in warning message,jreback,5,785540082,6,848405617,0,798772574,2021-05-26T02:20:11Z,closing as stale. @MicaelJarniac if you'd like to rebase and fix this up pls ping.,False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/39162,BUG: Calling tz_localize suppresses ValueError when converting from NaT to np.int64,vdonato,4,785550073,1,785550073,0,0,2021-01-14T00:16:33Z,"- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the latest version of pandas.

- [ ] (optional) I have confirmed this bug exists on the master branch of pandas.

---

#### Code Sample, a copy-pastable example

```python
import numpy as np
import pandas as pd

ser = pd.Series([pd.NaT], dtype=""datetime64[ns]"")
ser = ser.dt.tz_localize(""America/Los_Angeles"")

print(ser.astype(np.int64)[0])
```

#### Problem description
The code snippet above prints `-9223372036854775808` (-2<sup>63</sup>) instead of raising a `ValueError`, which is the behavior that would occur if `tz_localize` were not called.

#### Expected Output
Should raise a `ValueError: Cannot convert NaT values to integer`.

#### Output of ``pd.show_versions()``

<details>


INSTALLED VERSIONS
------------------
commit           : 3e89b4c4b1580aa890023fc550774e63d499da25
python           : 3.8.5.final.0
python-bits      : 64
OS               : Linux
OS-release       : 5.8.0-36-generic
Version          : #40~20.04.1-Ubuntu SMP Wed Jan 6 10:15:55 UTC 2021
machine          : x86_64
processor        : x86_64
byteorder        : little
LC_ALL           : None
LANG             : en_US.UTF-8
LOCALE           : en_US.UTF-8

pandas           : 1.2.0
numpy            : 1.19.5
pytz             : 2020.5
dateutil         : 2.8.1
pip              : 20.3.3
setuptools       : 51.0.0
Cython           : None
pytest           : None
hypothesis       : None
sphinx           : None
blosc            : None
feather          : None
xlsxwriter       : None
lxml.etree       : None
html5lib         : None
pymysql          : None
psycopg2         : None
jinja2           : None
IPython          : None
pandas_datareader: None
bs4              : None
bottleneck       : None
fsspec           : None
fastparquet      : None
gcsfs            : None
matplotlib       : None
numexpr          : None
odfpy            : None
openpyxl         : None
pandas_gbq       : None
pyarrow          : None
pyxlsb           : None
s3fs             : None
scipy            : None
sqlalchemy       : None
tables           : None
tabulate         : None
xarray           : None
xlrd             : None
xlwt             : None
numba            : None

</details>
",True,0,NONE
https://api.github.com/repos/pandas-dev/pandas/issues/comments/759844037,BUG: Calling tz_localize suppresses ValueError when converting from NaT to np.int64,jreback,4,785550073,2,759844037,0,785550073,2021-01-14T00:28:15Z,"hmm the error is not that a `datetime64[ns, UTC}` is raise, rather its the reverse, we are raising on a all-NaT `datetime64[ns]` when converting to `np.int64` which is unlike numpy

```
In [51]: ser.dt.tz_localize(None).values.astype('int64')
Out[51]: array([-9223372036854775808])
```

while we raise

note that there is a warning on this in current master for using `.astype` though `.view` has the same behavior",False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/759844085,BUG: Calling tz_localize suppresses ValueError when converting from NaT to np.int64,jreback,4,785550073,3,759844085,0,759844037,2021-01-14T00:28:23Z,cc @jbrockmendel ,False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/811506305,BUG: Calling tz_localize suppresses ValueError when converting from NaT to np.int64,jbrockmendel,4,785550073,4,811506305,0,759844085,2021-03-31T22:25:56Z,ATM both of these cases issue a FutureWarning that the astype is deprecated and will raise.  i.e. i think this is as correct as its going to get until 2.0,False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/898988411,BUG: Calling tz_localize suppresses ValueError when converting from NaT to np.int64,mroeschke,4,785550073,5,898988411,0,811506305,2021-08-15T03:09:21Z,"Agreed. Since this behavior was deprecated, closing",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/39163,"API/BUG: always try to operate inplace when setting with loc/iloc[foo, bar]",jbrockmendel,16,785606324,1,785606324,0,0,2021-01-14T02:49:27Z,"- [x] closes #38896
- [x] tests added / passed
- [x] Ensure all linting tests pass, see [here](https://pandas.pydata.org/pandas-docs/dev/development/contributing.html#code-standards) for how to run them
- [ ] whatsnew entry

(The PR title should have a caveat ""in cases that make it to `BlockManager.setitem`)

Discussed briefly on today's call.  The main idea, as discussed in #38896 and #33457, is that `df[col] = ser` should _not_ alter the existing `df[col]._values`, while `df.iloc[:, num] = ser` should _always_ try to operate inplace before falling back to casting.  This PR focuses on the latter case.

ATM, restricting to cases where we a) get to Block.setitem, b) _could_ do the setitem inplace, and c) are setting all the entries in the array, we have 4 different behaviors.  Examples are posted at the bottom of this post.

This PR changes Block.setitem so that in the _can_hold_element case we _always_ operate inplace, always retain the same underlying array.


------
Existing Behavior

1) If  the `new_values` being set are categorical, we overwrite existing values and then discard them, do _not_ get a view on new_values.  (only can replicate with Series until #39136)

```
ser = pd.Series(np.arange(5), dtype=object)
cat = pd.Categorical(ser)[::-1]

vals = ser.values
ser.iloc[ser.index] = cat

assert (vals == cat).all()            # <-- vals are overwritten
assert ser.dtype == cat.dtype   # < -- vals are discarded
assert not np.shares_memory(ser._values.codes, cat.codes)  # <-- we also dont get a view on the new values
```

2) If the new_values are any other EA, we do _not_ overwrite existing values and _do_ get a view on the new_values.  

```
df = pd.DataFrame({""A"": np.arange(5, dtype=np.int32)})
arr = pd.array(df[""A""].values)  + 1

vals = df.values
df.iloc[df.index, 0] = arr

assert (df.dtypes == arr.dtype).all()      # <-- cast
assert not (vals == df).any(axis=None)    # <-- did not overwrite original
```

3) If the new_values are a new non-EA dtype, we overwrite the old values and create a new array, get a view on neither.

```
df = tm.makeDataFrame()  #  <-- float64
old = df.values
new = np.arange(df.size).astype(np.int16).reshape(df.shape)
df.iloc[:, [0, 1, 2, 3]] = new

assert (old == new).all()
assert not np.shares_memory(df.values, old)
assert not np.shares_memory(df.values, new)
```

4) If the new_values have the same dtype as the existing, we overwrite existing and keep the same array

```
df = tm.makeDataFrame()  #  <-- float64
old = df.values
new = np.arange(df.size).astype(np.float64).reshape(df.shape)
df.iloc[:, [0, 1, 2, 3]] = new

assert (old == new).all()
assert np.shares_memory(df.values, old)
assert not np.shares_memory(df.values, new)
```
",True,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/759923085,"API/BUG: always try to operate inplace when setting with loc/iloc[foo, bar]",jbrockmendel,16,785606324,2,759923085,0,785606324,2021-01-14T04:48:11Z,"One potential issue here is that we don't have a nice way of doing a not-inplace `df.iloc[:, i] = ser` (if df.columns is unique we can do `df[df.columns[i]] = ser`)",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/764022227,"API/BUG: always try to operate inplace when setting with loc/iloc[foo, bar]",jreback,16,785606324,3,764022227,0,759923085,2021-01-20T23:27:42Z,this lgtm. can you merge master and add a whatsnew sub-section (that we can update later for other issues). this is very subtle and need to make it clear what is happening.,False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/767136655,"API/BUG: always try to operate inplace when setting with loc/iloc[foo, bar]",jbrockmendel,16,785606324,4,767136655,0,764022227,2021-01-25T21:53:18Z,rebased + green,False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/775542736,"API/BUG: always try to operate inplace when setting with loc/iloc[foo, bar]",jorisvandenbossche,16,785606324,5,775542736,0,767136655,2021-02-08T23:50:51Z,"Only looked at the whatsnew note for now, will try to take a look at the actual code tomorrow.

I find the whatsnew note a bit hard to follow. Currently it focuses on the aspect of how it impacts a potential viewing array on the data. But that's already a quite advanced use case that I think many users won't follow/do. Doesn't have the change impact on the actual dtypes (something more visible). Eg setting ints in a float column preserves the float dtype? (according to your example in the top post). Starting the whatsnew note with such an example might make it easier to grasp what it's about.",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/776875697,"API/BUG: always try to operate inplace when setting with loc/iloc[foo, bar]",jbrockmendel,16,785606324,6,776875697,0,775542736,2021-02-10T17:20:51Z,"updated the whatsnew, is that clearer @jorisvandenbossche ?",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/776898888,"API/BUG: always try to operate inplace when setting with loc/iloc[foo, bar]",jorisvandenbossche,16,785606324,7,776898888,0,776875697,2021-02-10T17:57:22Z,"Thanks, yes, I think that's clearer!",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/776900631,"API/BUG: always try to operate inplace when setting with loc/iloc[foo, bar]",jorisvandenbossche,16,785606324,8,776900631,0,776898888,2021-02-10T18:00:16Z,"Looking at the changed tests, I think one potentially problematic aspect is that object dtype gets preserved now when you start from an ""empty"" (all-NaN object dtype) DataFrame. 
That's mainly a limitation of how we create empty dataframes, but still a breaking change.",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/776941469,"API/BUG: always try to operate inplace when setting with loc/iloc[foo, bar]",jbrockmendel,16,785606324,9,776941469,0,776900631,2021-02-10T19:06:50Z,"> when you start from an ""empty"" (all-NaN object dtype) DataFrame.

Just checking, when you say ""empty"", you dont mean `df.size == 0`?

What would you want to do here?  Could special-case the all-NaN-object case i guess",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/790622427,"API/BUG: always try to operate inplace when setting with loc/iloc[foo, bar]",jreback,16,785606324,10,790622427,0,776941469,2021-03-04T13:36:01Z,"looks fine, can you rebase and ping on green",False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/790984334,"API/BUG: always try to operate inplace when setting with loc/iloc[foo, bar]",jorisvandenbossche,16,785606324,11,790984334,0,790622427,2021-03-04T22:17:44Z,"> > when you start from an ""empty"" (all-NaN object dtype) DataFrame.
>
> Just checking, when you say ""empty"", you dont mean df.size == 0?
>
> What would you want to do here? Could special-case the all-NaN-object case i guess

Sorry for the late answer here. But yes, not size=0, but all NaN (eg `df = pd.DataFrame(index=.., columns=..)`).

That might indeed require special casing all-NaN object.",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/791044215,"API/BUG: always try to operate inplace when setting with loc/iloc[foo, bar]",jreback,16,785606324,12,791044215,0,790984334,2021-03-05T00:09:38Z,thanks @jbrockmendel ,False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/791707779,"API/BUG: always try to operate inplace when setting with loc/iloc[foo, bar]",jorisvandenbossche,16,785606324,13,791707779,0,791044215,2021-03-05T21:12:08Z,"@jbrockmendel can you do the all-NaN object case as a follow-up?

@jreback yes, I know, I just commented and didn't mark it with ""request changes"", but it would be good if you can *read* the last comment before merging",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/791719858,"API/BUG: always try to operate inplace when setting with loc/iloc[foo, bar]",jreback,16,785606324,14,791719858,0,791707779,2021-03-05T21:25:52Z,"@jorisvandenbossche i would suggest you request changes

we have a lot of PRa",False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/791797354,"API/BUG: always try to operate inplace when setting with loc/iloc[foo, bar]",jbrockmendel,16,785606324,15,791797354,0,791719858,2021-03-05T23:51:57Z,"> can you do the all-NaN object case as a follow-up?

sure.  let's double-check we're on the same page about what the issue is.  The example case is `pd.DataFrame(index=..., columns=...)` which is all-NA-single-block DataFrame.  Should this special treatment cover any other cases?  e.g. an all-NA column in a not-all-NA DataFrame?",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/792892312,"API/BUG: always try to operate inplace when setting with loc/iloc[foo, bar]",jorisvandenbossche,16,785606324,16,792892312,0,791797354,2021-03-08T16:47:31Z,">  Should this special treatment cover any other cases? e.g. an all-NA column in a not-all-NA DataFrame?

Yes, is the column that is being set is all-NA object dtype (regardless whether other columns are not all-NA or not), it got inferred to a new dtype:

```
In [7]: df = pd.DataFrame(index=[0, 1], columns=['a', 'b'])

In [8]: df.loc[:, 'a'] = 1

In [9]: df.loc[:, 'b'] = pd.Timestamp(""2012-01-01"")

In [10]: df.dtypes
Out[10]: 
a             int64
b    datetime64[ns]
dtype: object
```",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/793121178,"API/BUG: always try to operate inplace when setting with loc/iloc[foo, bar]",jbrockmendel,16,785606324,17,793121178,0,792892312,2021-03-08T22:15:38Z,im OK with this special case.  any objections @jreback @TomAugspurger@phofl before i implement?,False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/8434,fixed entity generation for numeric values,julianullrich99,4,791086514,1,791086514,0,0,2021-01-21T13:26:01Z,"Originally doctrine adds integer and float default-values as 

`private $property = '12';`

With this fix it correctly inserts

`private $property = 12;`",True,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/765699998,fixed entity generation for numeric values,SenseException,4,791086514,2,765699998,0,791086514,2021-01-22T21:39:30Z,Thanks for your contribution. Does this fix a specific bug?,False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/766088355,fixed entity generation for numeric values,julianullrich99,4,791086514,3,766088355,0,765699998,2021-01-23T14:31:48Z,"Yes, it fixes a bug that I discovered at work where when you declare a default value for a db field as an integer 0 it generates something like

```
/**
* @type INTEGER
*/
private $field = '0';
```

So it creates a String. With my fix it properly generates an integer for it

```
/**
* @type INTEGER
*/
private $field = 0;
```

So without this bug it hurts type safety.",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/767074610,fixed entity generation for numeric values,SenseException,4,791086514,4,767074610,0,766088355,2021-01-25T19:56:31Z,In that case please create a test that covers your changes.,False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/774344701,fixed entity generation for numeric values,beberlei,4,791086514,5,774344701,0,767074610,2021-02-05T23:34:21Z,"We can take our chances on this one without new tests, integer default values are already tested and should break if this code was wrong.

https://github.com/doctrine/orm/blob/2.8.x/tests/Doctrine/Tests/ORM/Tools/EntityGeneratorTest.php#L1289",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/8435,Minor rewording,ThomasLandauer,6,791351356,1,791351356,0,0,2021-01-21T17:24:50Z,"Emphasizing the (counter-intuitive) fact that preUpdate is called inside **flush** - cause this was causing me some confusion, see https://github.com/symfony/symfony/issues/39894

In general: This entire page is confusing, for two reasons:
* The list of events appears *twice* (as ""overview"" list on top, then as separate headings below), with neither being complete.
* The description of each event is inconsistent.

To improve this, I'm suggesting an **overview table** on top, with the events being the rows (linked to their respective heading below), and the following columns:
* called inside which of *my* function calls (i.e. `em->persist` or `$em->flush`)
* Is allowed to change the *current* entity?
* Is allowed to change *associated* entities?
* Is allowed to create *new* entities?
* Is calling `persist` or `flush` inside it allowed/required?
* Can access ID?
* ...?

I can start the table, but I'd need some help, since I don't know all the details myself.",True,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/765708820,Minor rewording,SenseException,6,791351356,2,765708820,0,791351356,2021-01-22T22:00:45Z,"> To improve this, I'm suggesting an overview table on top, with the events being the rows (linked to their respective heading below), and the following columns:

Your suggestion sounds interesting and the redundant events can be confusing. Can you post an example ob such a row?
For which details do you need help?",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/766094906,Minor rewording,ThomasLandauer,6,791351356,3,766094906,0,765708820,2021-01-23T15:18:32Z,"Here's just some quick sketch:
Event | Dispatched by | Can change current entity | Generated ID available
--| -- | -- | --
[preUpdate]() | `$em->flush()` | ? 
[postUpdate]() | `$em->flush()` | No
[postRemove]() | `$em->flush()` | No
[postPersist]() |  `$em->flush()` | No
[preRemove]() | `$em->remove()` | Yes, but useless | Yes
[prePersist]() | `$em->persist()` on *initial* persist | ? | No

Main advantage: Whenever I setup a listener, I have some requirements in mind (e.g.: I need the ID). So an overview table makes searching for events in question much faster and easier.

Since the table will get wide, maybe you could change the overall layout of https://www.doctrine-project.org/projects/doctrine-orm/en/2.8/reference/events.html and increase `.container { max-width: 1140px; }`

I wrote this with `entity` listeners in mind (therefore ""Can change *current* entity""). So my first question would be: What's the difference to ""general"" listeners? IMHO, entity listeners should be mentioned first and foremost, cause doing stuff on *any* flush doesn't make much sense to me - or does it?

> For which details do you need help?

Probably for many ;-) It would be some work and it would take some time, so I wanted to find out first if you're interested at all.
",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/768565594,Minor rewording,SenseException,6,791351356,4,768565594,0,766094906,2021-01-27T20:45:10Z,"A additional small matrix for the events can give a helpful overview if that table doesn't become too wide with too many columns. It would lose its lucidity. I would also expect the yes/no values you had in your example.

> What's the difference to ""general"" listeners?

Entity Listeners are bound to just one entity and will only be triggered for this entity alone. If you e.g. want to have a `prePersist` only for `Foo` entity, but not for the others, the Entity Listeners can help here. The ""general"" `prePersist` listener is for every entity.

> The list of events appears twice

I just realized that the events at the top are representing the Lifecycle Events while the bottom ones are Event Listeners. Maybe that table can combine those different event types.",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/769940427,Minor rewording,ThomasLandauer,6,791351356,5,769940427,0,768565594,2021-01-29T17:26:31Z,"Here's my plan: I'll take the list at https://www.doctrine-project.org/projects/doctrine-orm/en/2.8/reference/events.html#lifecycle-events as a starting point and set up a table with these rows, starting with *only one column*: ""Dispatched by"". So we can see if this works fine, then continue adding more columns.

If, at some point, this all-in-one table gets too wide, here's my plan B:
Under each heading of https://www.doctrine-project.org/projects/doctrine-orm/en/2.8/reference/events.html#implementing-event-listeners, start each event's description with an *identical* overview table:
|  |  |
| -- | -- |
| Dispatched by | `->foo()` |
| Can change current entity | Yes |
| Generated ID available | No |
| ... | ... |

Questions:
1. Should I reuse this PR or start a new one? If new: On the 2.8 branch?
2. Which table syntax? There are four at https://www.sphinx-doc.org/en/master/usage/restructuredtext/directives.html#table-directives",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/771076967,Minor rewording,SenseException,6,791351356,6,771076967,0,769940427,2021-02-01T18:51:28Z,"Yes, you can use this PR for your table. Your minor rewording was targeting an improvement of understanding anyway.

Used table syntax:

```
+--------+--------+--------+
| head 1 | head 2 | head 3 | 
+=================+========+
| row 1  | row 1  | row 1  |
+--------+--------+--------+
| row 2  | row 2  | row 2  |
+--------+--------+--------+
```",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/928356568,Minor rewording,ThomasLandauer,6,791351356,7,928356568,0,771076967,2021-09-27T22:18:24Z,"Please merge this; since some time has passed, I've started a separate PR for the overview table.",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/8438,DDC-2076 Remove useless join over target table of ManyToMany relationship,plfort,5,793722661,1,793722661,0,0,2021-01-25T21:01:59Z,"Quite an old issue : https://github.com/doctrine/orm/issues/2758

I noticed this additional ""join"" while trying to optimize a query. As mentioned in the issue, I don't see a case when this join is useful.
In my case (query optimization), this PR provides a significant reduction of the query cost given by Postgresql
",True,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/774338970,DDC-2076 Remove useless join over target table of ManyToMany relationship,beberlei,5,793722661,2,774338970,0,793722661,2021-02-05T23:16:15Z,"@SenseException The `SelectSqlGenerationTest` is the integration test for `SqlWalker`, so this is fine. 

I think the patch is good, thanks.

unrelated however I realized this must provide wrong results on composite keys or not? It seems weird to iterate the columns and add multiple in conditions, maybe I am wrong.",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/774340576,DDC-2076 Remove useless join over target table of ManyToMany relationship,beberlei,5,793722661,3,774340576,0,774338970,2021-02-05T23:21:09Z,"@plfort i am a bit hesitant to merge a cosmetic PR into a branch in bugfix mode, the old code works, so this is an improvement and changing the SQL is a bit more risky, so I would like you to rebase this on 2.9 and we can merge it there.",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/774726461,DDC-2076 Remove useless join over target table of ManyToMany relationship,plfort,5,793722661,4,774726461,0,774340576,2021-02-07T18:22:44Z,"I agree with you about composite keys, it requires further tests. I thought about it but for this change I wanted to keep the behaviour.",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/783985392,DDC-2076 Remove useless join over target table of ManyToMany relationship,plfort,5,793722661,5,783985392,0,774726461,2021-02-23T07:56:31Z,Rebase on 2.9 done BTW,False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/847187234,DDC-2076 Remove useless join over target table of ManyToMany relationship,rvanlaak,5,793722661,6,847187234,0,783985392,2021-05-24T16:47:01Z,"if this PR did fix #2758, that issue can get closed now",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/8439,Use typed properties for default metadata for #7939,Lustmored,13,794225748,1,794225748,0,0,2021-01-26T13:20:19Z,"This is simple implementation of idea outlined in #7939. During completion step of a field mapping completion or association mapping completion it looks for typed property and, when existent, uses it to determine default for `type`, `targetEntity` and `nullable` (in fields and `joinTable`).

I have added simple tests covering all cases I found.

I am not a great fan of encapsulating code in `PHP_VERSION_ID >= 70400`, but at the time of writing got no better idea.

I couldn't get master branch to work locally and that's the only reason why I target '2.9.x' (Composer has problem resolving doctrine/dbal).

This is my first PR to Doctrine project, so if anything is done wrong please let me know and I will do my best to fix it :)",True,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/767546448,Use typed properties for default metadata for #7939,Lustmored,13,794225748,2,767546448,0,794225748,2021-01-26T13:39:02Z,"I don't know how to proceed with tests under PHP < 7.4 as there are no typed properties and entity class required for new test cases fails there. I probably could move it to other namespace, but that seems like complicating file structure without much benefit. Please help me with any suggestion :)",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/774427275,Use typed properties for default metadata for #7939,Lustmored,13,794225748,3,774427275,0,767546448,2021-02-06T08:49:33Z,Thanks for the review. I will work on it next week 👍 ,False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/775105154,Use typed properties for default metadata for #7939,Lustmored,13,794225748,4,775105154,0,774427275,2021-02-08T12:17:46Z,"I have rebased onto 2.9.x (still some conflicts pop out, don't know why) and handled suggestions :+1: ",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/775853360,Use typed properties for default metadata for #7939,Lustmored,13,794225748,5,775853360,0,775105154,2021-02-09T10:55:16Z,"I think I addressed all current comments to some degree. I see that checks are somehow stuck and I see no way to ""unstuck"" them to see if my code passes. Is it possible somehow to run them?",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/776131761,Use typed properties for default metadata for #7939,beberlei,13,794225748,6,776131761,0,775853360,2021-02-09T18:06:23Z,"@Lustmored this is because of the conflict in `ClassMetadataInfo.php`, you need to fix that before the checks run.",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/776546484,Use typed properties for default metadata for #7939,Lustmored,13,794225748,7,776546484,0,776131761,2021-02-10T08:52:07Z,"I think I have complied with all your comments. I have also rebased onto 2.9.x and pushed CS fixed.

Only remaining failing check is CS complaing about method names starting with underscore - I don't have the confidence to change them without asking first.",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/781217291,Use typed properties for default metadata for #7939,Lustmored,13,794225748,8,781217291,0,776546484,2021-02-18T09:42:58Z,I have rebased onto 2.9 and made a simple change to use `Types::` constants instead of strings for types. Is there anything else I can do to make this happen? :),False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/788293046,Use typed properties for default metadata for #7939,beberlei,13,794225748,9,788293046,0,781217291,2021-03-01T21:14:22Z,@Lustmored thank you very much!,False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/813003368,Use typed properties for default metadata for #7939,beberlei,13,794225748,10,813003368,0,788293046,2021-04-04T09:35:26Z,"@Lustmored FYI, This doesn't work anymore with AttributeDriver (does it with Annotations?) Because of the default value of `Column::$type = ""string""`. The typed mapping completion only works when `$mapping['type']` is not set. I am going to investigate more.",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/813011395,Use typed properties for default metadata for #7939,Lustmored,13,794225748,11,813011395,0,813003368,2021-04-04T10:44:04Z,"@beberlei I see the problem and I see how I missed it in tests (I have created only tests for `ClassMetadataInfo` and not metadata obtained from mapping drivers). I am also looking into it. Probably simplest solution would be to change the rule from `isset` to `! isset($foo) || $foo === 'string'`, but that would lead to obvious problem of impossibility to overwrite type inherited from typed property with a simple `string` type.",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/813012896,Use typed properties for default metadata for #7939,beberlei,13,794225748,12,813012896,0,813011395,2021-04-04T10:56:15Z,@Lustmored i think setting Column::$type to nullable & default null is better,False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/813013093,Use typed properties for default metadata for #7939,Lustmored,13,794225748,13,813013093,0,813012896,2021-04-04T10:57:55Z,@beberlei That's exactly what I'm experimenting with right now. Probably will come with a PR fixing the issue and introducing more tests to ensure it works with mapping later today :+1: ,False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/813025138,Use typed properties for default metadata for #7939,Lustmored,13,794225748,14,813025138,0,813013093,2021-04-04T12:30:57Z,@beberlei let's continue in #8589. Hopefully all cases are covered there this time :),False,0,CONTRIBUTOR
https://api.github.com/repos/rstudio/rstudio/issues/8954,Malformed bookdown index hangs UI,mirh,4,805964034,1,805964034,0,0,2021-02-10T23:37:40Z,"### System details

    RStudio Edition : Desktop
    RStudio Version : 1.4.1103
    OS Version      : Windows 10
    R Version       : 4.0.3

### Steps to reproduce the problem

1. Create a bookdown document 
2. Edit index.rmd, and put `library(bookdown)` *before* the YAML header
3. Reload the project

### Describe the problem in detail

The UI (or whatever the ""interface viewport"" could be called) becomes grey and FUBAR

### Describe the behavior you expected

Just about anything that doesn't make the program unusable. Maybe the bad file should be outright rejected, maybe the wrong part could just be skipped and a big error printed, but I shouldn't have to use task manager to kill the whole program. 

- [x] I have read the guide for [submitting good bug reports](https://github.com/rstudio/rstudio/wiki/Writing-Good-Bug-Reports).
- [x] I have installed the latest version of RStudio, and confirmed that the issue still persists.
- [x] If I am reporting a RStudio crash, I have included a [diagnostics report](https://support.rstudio.com/hc/en-us/articles/200321257-Running-a-Diagnostics-Report).
- [x] I have done my best to include a minimal, self-contained set of instructions for consistently reproducing the issue.

",True,0,NONE
https://api.github.com/repos/rstudio/rstudio/issues/comments/777135195,Malformed bookdown index hangs UI,kevinushey,4,805964034,2,777135195,0,805964034,2021-02-11T00:35:35Z,"Thanks for the bug report! It looks like this is actually a bug in the `rmarkdown` package -- I've filed an associated issue here:

https://github.com/rstudio/rmarkdown/issues/2043

I think this issue is more easily fixed on the `rmarkdown` side, but will keep this issue open just in case.",False,0,CONTRIBUTOR
https://api.github.com/repos/rstudio/rstudio/issues/comments/777142396,Malformed bookdown index hangs UI,mirh,4,805964034,3,777142396,0,777135195,2021-02-11T00:58:38Z,"Thank you for your way more comprehensive and precise bug report. 

***Though*** I'm wondering if ""waiting for input"" is even a good reason for the whole program to pass ~~out~~ away. ",False,0,NONE
https://api.github.com/repos/rstudio/rstudio/issues/comments/843186592,Malformed bookdown index hangs UI,yihui,4,805964034,4,843186592,0,777142396,2021-05-18T13:47:24Z,"This has been fixed in the development version of **rmarkdown**:

```r
remotes::install_github('rstudio/rmarkdown')
```

Thanks for the report!",False,0,MEMBER
https://api.github.com/repos/rstudio/rstudio/issues/comments/843225536,Malformed bookdown index hangs UI,mirh,4,805964034,5,843225536,0,843186592,2021-05-18T14:34:08Z,Nice then I guess. ,False,0,NONE
https://api.github.com/repos/rstudio/rstudio/issues/8955,Unexpected behaviour when backspacing numbered list below code chunk in visual editor,matthew-law,6,806402033,1,806402033,0,0,2021-02-11T13:43:02Z,"<!--
IMPORTANT: Please fill out this template fully! Failure to do so will result in the issue being closed automatically.

This issue tracker is for bugs and feature requests in the RStudio IDE. If you're having trouble with R itself or an R package, see https://www.r-project.org/help.html, and if you want to ask a question rather than report a bug, go to https://community.rstudio.com/. Finally, if you use RStudio Server Pro, get in touch with our Pro support team at support@rstudio.com.

-->

### System details

    RStudio Edition : Desktop
    RStudio Version : 1.4.1103
    OS Version      : Mac OS X 10.15.7
    R Version       : 3.6.3

### Steps to reproduce the problem

When backspacing from the start of a numbered list located below a code chunk, press backspace when the cursor is immediately to the right of the number (ie '1.' etc).

It doesn't happen if you have only just typed the numbered list (ie the last thing you typed was '1. foobar'), but it does if you have previously created a numbered list, then moved the cursor away, and then back.

### Describe the problem in detail

When backspacing from the start of a numbered list below a code chunk, the list number isn't backspaced, but instead the cursor moves from the right of the number to the end of the code chunk above. As seen in the screen recording below, the scrolling behaviour is also affected in order to include the whole code chunk in view when the cursor moves to it.

![gif](https://user-images.githubusercontent.com/18603830/107642704-200ead80-6c6d-11eb-88f6-3a516f193dd4.gif)

### Describe the behavior you expected

The formatted numbered list would revert to unformatted (ie not indented but just plain text with '1. foobar'), and the cursor would remain in the same place (allowing the user to backspace the number if desired.

<!-- 
Please keep the below portion in your issue, and check `[x]` the applicable boxes.
-->

- [x] I have read the guide for [submitting good bug reports](https://github.com/rstudio/rstudio/wiki/Writing-Good-Bug-Reports).
- [x] I have installed the latest version of RStudio, and confirmed that the issue still persists.
- [x] If I am reporting a RStudio crash, I have included a [diagnostics report](https://support.rstudio.com/hc/en-us/articles/200321257-Running-a-Diagnostics-Report).
- [x] I have done my best to include a minimal, self-contained set of instructions for consistently reproducing the issue.

",True,0,NONE
https://api.github.com/repos/rstudio/rstudio/issues/comments/782164695,Unexpected behaviour when backspacing numbered list below code chunk in visual editor,ronblum,6,806402033,2,782164695,0,806402033,2021-02-19T15:55:21Z,"@matthew-law Thank you for raising the issue. We'll review it as we continue development of RStudio, including the visual markdown editor.

Also, I can reproduce this in
- RStudio Desktop 1.4.1572 on MacOS 11.3
- RStudio Server 1.4.1572 on Red Hat 8.3 using Chrome on MacOS 11.3",False,0,CONTRIBUTOR
https://api.github.com/repos/rstudio/rstudio/issues/comments/1424890817,Unexpected behaviour when backspacing numbered list below code chunk in visual editor,jjallaire,6,806402033,3,1424890817,0,782164695,2023-02-09T21:58:50Z,This should be resolved here: https://github.com/quarto-dev/quarto/commit/5219cd664b7231268fac34b0843df3e530ab0ca0,False,0,MEMBER
https://api.github.com/repos/rstudio/rstudio/issues/comments/1429904604,Unexpected behaviour when backspacing numbered list below code chunk in visual editor,ronblum,6,806402033,4,1429904604,0,1424890817,2023-02-14T15:11:51Z,This seems to still be happening—same reprex steps—in RStudio Desktop and RStudio Server 2023.03.0-daily+318.,False,0,CONTRIBUTOR
https://api.github.com/repos/rstudio/rstudio/issues/comments/1440029575,Unexpected behaviour when backspacing numbered list below code chunk in visual editor,jjallaire,6,806402033,5,1440029575,0,1429904604,2023-02-22T13:35:59Z,Took a closer look and I think I can see my way to a fix but it has too much regression risk at this stage of the release.,False,0,MEMBER
https://api.github.com/repos/rstudio/rstudio/issues/comments/1466456242,Unexpected behaviour when backspacing numbered list below code chunk in visual editor,mikebessuille,6,806402033,6,1466456242,0,1440029575,2023-03-13T16:15:59Z,"@jjallaire are you planning on fixing this on main for next release (mountain hydrangea?)
",False,0,CONTRIBUTOR
https://api.github.com/repos/rstudio/rstudio/issues/comments/1520511459,Unexpected behaviour when backspacing numbered list below code chunk in visual editor,jjallaire,6,806402033,7,1520511459,0,1466456242,2023-04-24T16:49:48Z,I am not planning on fixing in this release.,False,0,MEMBER
https://api.github.com/repos/rstudio/rstudio/issues/8956,RStudio stops working properly (Can not create projects or set global options) when Rtools40 is in path,ermueller,6,806517131,1,806517131,0,0,2021-02-11T15:51:53Z,"### System details

    RStudio Edition : Desktop
    RStudio Version : 1.4.1103
    OS Version      :  Windows 10
    R Version       :  4.0.3

### Steps to reproduce the problem

I installed RStudio Version 1.4.1103 in the standard path and installed Rtools40 in the standard C:/rtools40 directory. The only prerequisite is that C:/rtools40/usr/bin is in the system PATH variable.
I can reproduce the problem, even if I completely remove everything R-related (R, RStudio, Rtools) and reinstall it in the standard paths and re-add Rtools to the PATH. This problem stops immediately when I take Rtools40 out of the PATH.

### Describe the problem in detail

When trying to click on ""File"" -> ""New Project..."" or trying to open the ""Tools"" -> ""Global Options..."" from the dropdown menu, RStudio does nothing, even if I try repeatedly. Also, the window doesn't exactly crash, as I can still input text, but I can neither save nor do anything other substantial. When trying to close RStudio in this state, nothing happens either, and I need to close it using the task manager. This also means that I can not supply a crash report. 

Furthermore, for every time I try to create a new project, a new ""make.exe"" process gets spawned, I can see this in the Task Manager, so it could be possible that the Rtools40 make is responsible for this problem? 

The same problem was already described in 2019 here:
https://community.rstudio.com/t/new-project-problem-dialog-to-create-new-project-is-not-appearing/24037/8

but no concrete solution was found. To reiterate, this problem stops occurring when Rtools40 is not in the PATH anymore.

### Describe the behavior you expected

Rstudio should open the dialog window for eithere creating a new project or for setting global options.

- [X ] I have read the guide for [submitting good bug reports](https://github.com/rstudio/rstudio/wiki/Writing-Good-Bug-Reports).
- [X ] I have installed the latest version of RStudio, and confirmed that the issue still persists.
- [ ] If I am reporting a RStudio crash, I have included a [diagnostics report](https://support.rstudio.com/hc/en-us/articles/200321257-Running-a-Diagnostics-Report).
- [X ] I have done my best to include a minimal, self-contained set of instructions for consistently reproducing the issue.",True,0,NONE
https://api.github.com/repos/rstudio/rstudio/issues/comments/777597891,RStudio stops working properly (Can not create projects or set global options) when Rtools40 is in path,ermueller,6,806517131,2,777597891,0,806517131,2021-02-11T15:56:02Z,"I just noticed that trying to create a new project also spawns an ""sh.exe"" process, and the dialogue window to let me create a new project actually appears when I kill this ""sh.exe"" process.",False,0,NONE
https://api.github.com/repos/rstudio/rstudio/issues/comments/782160684,RStudio stops working properly (Can not create projects or set global options) when Rtools40 is in path,ronblum,6,806517131,3,782160684,0,777597891,2021-02-19T15:49:08Z,"@ermueller Thank you for raising the issue, and the additional investigation! We'll mark it for review and reproducibility as part of our ongoing development of RStudio.",False,0,CONTRIBUTOR
https://api.github.com/repos/rstudio/rstudio/issues/comments/829640309,RStudio stops working properly (Can not create projects or set global options) when Rtools40 is in path,kevinushey,6,806517131,4,829640309,0,782160684,2021-04-29T22:37:51Z,I'm not able to reproduce this on my Windows VM. Is there anything else unique about the way you've configured your machine? Anything else that might be necessary in order to reproduce?,False,0,CONTRIBUTOR
https://api.github.com/repos/rstudio/rstudio/issues/comments/842880769,RStudio stops working properly (Can not create projects or set global options) when Rtools40 is in path,ermueller,6,806517131,5,842880769,0,829640309,2021-05-18T06:20:45Z,"I actually tried this again recently after freshly installing Windows and it happened again, so I cant't really say for sure that there's anything particularly unusual about my set-up. I installed R and some other programming language related stuff (python mostly), but nothing comes to mind that could or should interfere with Rstudio or RTools.",False,0,NONE
https://api.github.com/repos/rstudio/rstudio/issues/comments/968436030,RStudio stops working properly (Can not create projects or set global options) when Rtools40 is in path,github-actions[bot],6,806517131,6,968436030,0,842880769,2021-11-15T01:47:48Z,"This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs, per  https://github.com/rstudio/rstudio/wiki/Issue-Grooming. Thank you for your contributions.",False,0,NONE
https://api.github.com/repos/rstudio/rstudio/issues/comments/981221795,RStudio stops working properly (Can not create projects or set global options) when Rtools40 is in path,github-actions[bot],6,806517131,7,981221795,0,968436030,2021-11-29T01:47:54Z,This issue has been automatically closed due to inactivity.,False,0,NONE
https://api.github.com/repos/rstudio/rstudio/issues/8960,Cleaning R workspace to free memory doesn't appear to work,jmcphers,3,806782866,1,806782866,0,0,2021-02-11T22:10:01Z,"### System details

    RStudio Edition : Both
    RStudio Version : 1.4.1566

### Steps to reproduce the problem

Fill R's memory with a lot of data. I like to use something like this:

```r
foo <- runif(1e8)
bar <- runif(1e8)
baz <- runif(1e8)
```

![image](https://user-images.githubusercontent.com/470418/107704621-6ca8b780-6c72-11eb-8f24-c9e7be54f135.png)

Next, click the ""Remove Objects"" (broom) button and confirm that you want to remove everything.

### Describe the problem in detail

The objects go away, but mysteriously memory usage has not gone down.

![image](https://user-images.githubusercontent.com/470418/107704690-89dd8600-6c72-11eb-95ec-9012bcc0fab2.png)

### Describe the behavior you expected

This is _technically_ correct behavior, because even though the objects have been removed, R hasn't garbage collected yet. 

However, it _looks_ wrong since average users don't know anything about garbage collection. After a user removes objects using this command, we should trigger a gc() and then refresh memory usage so they can immediately see that they have successfully freed up memory.

- [x] I have read the guide for [submitting good bug reports](https://github.com/rstudio/rstudio/wiki/Writing-Good-Bug-Reports).
- [x] I have installed the latest version of RStudio, and confirmed that the issue still persists.
- [x] If I am reporting a RStudio crash, I have included a [diagnostics report](https://support.rstudio.com/hc/en-us/articles/200321257-Running-a-Diagnostics-Report).
- [x] I have done my best to include a minimal, self-contained set of instructions for consistently reproducing the issue.

",True,0,MEMBER
https://api.github.com/repos/rstudio/rstudio/issues/comments/778461976,Cleaning R workspace to free memory doesn't appear to work,jmcphers,3,806782866,2,778461976,0,806782866,2021-02-12T21:21:51Z,"In my testing so far, it's very difficult to get this to work. For reasons that are unclear to me, R doesn't necessarily free memory right away when you call `gc()`; sometimes `gc()` doesn't do much until you call it again. Will have to figure out whether we can make `gc()` deterministically clean up everything before we can fix this.",False,0,MEMBER
https://api.github.com/repos/rstudio/rstudio/issues/comments/778462568,Cleaning R workspace to free memory doesn't appear to work,jmcphers,3,806782866,3,778462568,0,778461976,2021-02-12T21:23:12Z,"Example:

```r
> foo <- runif(1e8)
> rm(foo)
> gc()
            used  (Mb) gc trigger   (Mb) limit (Mb)  max used  (Mb)
Ncells   3150898 168.3    4845632  258.8         NA   4845632 258.8
Vcells 108174982 825.4  179970664 1373.1      32768 111637209 851.8
> 
> gc()
          used  (Mb) gc trigger   (Mb) limit (Mb)  max used  (Mb)
Ncells 3150905 168.3    4845632  258.8         NA   4845632 258.8
Vcells 8175006  62.4  143976532 1098.5      32768 111637209 851.8
```

The first `gc()` didn't remove the object ... why?",False,0,MEMBER
https://api.github.com/repos/rstudio/rstudio/issues/comments/784524944,Cleaning R workspace to free memory doesn't appear to work,jmcphers,3,806782866,4,784524944,0,778462568,2021-02-23T21:28:16Z,I'm moving this out of Juliet Rose because we don't have a deterministic mechanism to force R to free memory (as demonstrated above). This is probably due to something internal to RStudio since I don't see the same behavior with R at the command prompt. ,False,0,MEMBER
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/7614,Allowing singleblock generators to have top and bottom output sides,CatsLeftEar,5,830064677,1,830064677,0,0,2021-03-12T12:18:48Z,"#### Which modpack version are you using?
2.1.0.0
#
#### If in multiplayer; On which server does this happen? 
Eta
#
#### What did you try to do, and what did you expect to happen?
I tried to turn singleblock turbine/combustion generator to output energy out of top or bottom sides
#
#### What happened instead? (Attach screenshots if needed)
Weird, that we can do anything with the wrench and turn any mechanism, but not generators. Sometimes it can be helpful and i got such sutiation several times.
#
#### What do you suggest instead/what changes do you propose?
Every mechanism can have output on every side possible, so why not generators also? Minecraft is sandbox and such restriction does nothing
#
#### What is your GTNH Discord username?
CatsLeftEar",True,0,NONE
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/858603902,Allowing singleblock generators to have top and bottom output sides,github-actions[bot],5,830064677,2,858603902,0,830064677,2021-06-10T13:04:27Z,This issue is stale because it has been open 90 days with no activity. Remove stale label or comment or this will be closed in 3 days,False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/858638202,Allowing singleblock generators to have top and bottom output sides,CatsLeftEar,5,830064677,3,858638202,0,858603902,2021-06-10T13:47:52Z,"This would be a great feature, why dont you like it?",False,0,NONE
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/858682293,Allowing singleblock generators to have top and bottom output sides,Autowinto,5,830064677,4,858682293,0,858638202,2021-06-10T14:41:47Z,I think it's a good idea as well. I wonder if it's a design choice or if the implementation of generators is so different from regular machines that it's too cumbersome to do.,False,0,NONE
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/858705728,Allowing singleblock generators to have top and bottom output sides,YannickMG,5,830064677,5,858705728,0,858682293,2021-06-10T15:09:40Z,"I understand that this change would have balance implications in terms of superconductor cable design or cable loss.

Beyond that there's not a clear logical reason this couldn't happen.",False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/915349579,Allowing singleblock generators to have top and bottom output sides,github-actions[bot],5,830064677,6,915349579,0,858705728,2021-09-08T15:39:15Z,This issue is stale because it has been open 90 days with no activity. Remove stale label or comment or this will be closed in 3 days,False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/7616,TT Oil Cracker,Florexiz,28,830090253,1,830090253,0,0,2021-03-12T12:52:45Z,"#### Which modpack version are you using?
2.1.0.4
#
#### If in multiplayer; On which server does this happen? 
Zeta
#
#### What did you try to do, and what did you expect to happen?
Build Oil Cracker
#
#### What happened instead? (Attach screenshots if needed)
TT Replacement of Oil Cracker have very strict build requirements  that aren't present in regular GT cracker
1) Input hatch can be placed at left side, while output on the right. You can turn cracker upside down, but esthetics... Ugh
2) Side hatches can be only be placed in center block of the side. Prev version example:
![image](https://user-images.githubusercontent.com/29033773/110942440-de941f80-834a-11eb-8448-8e906dc8ac19.png)
Now fluid hatch can be placed only on central block
#
#### What do you suggest instead/what changes do you propose?
Change oil cracker structure so it match GT one
#
#### What is your GTNH Discord username?
FalseColor",True,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/797479921,TT Oil Cracker,Florexiz,28,830090253,2,797479921,0,830090253,2021-03-12T13:09:48Z,@Ethryan I think its more related to bartworks? Multis replacement to TT code located there,False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/797529989,TT Oil Cracker,bartimaeusnek,28,830090253,3,797529989,0,797479921,2021-03-12T14:38:21Z,The multi itself can be rotated/flipped to accommodate for io on left/right side. the 90° angle of the controller to hydrogen/steam input was introduced to limit Wallsharing to 4x instead of endless Wallsharing.,False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/797542796,TT Oil Cracker,Ethryan,28,830090253,4,797542796,0,797529989,2021-03-12T14:58:03Z,Will close this then since an answer has been made available.,False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/797587935,TT Oil Cracker,KiloJoel,28,830090253,5,797587935,0,797542796,2021-03-12T16:06:45Z,"This is even more restrictive than i thought, this seriously needs looking at because it breaks a LOT of current setups, including ones that don't wallshare at all",False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/797590760,TT Oil Cracker,Prometheus0000,28,830090253,6,797590760,0,797587935,2021-03-12T16:11:19Z,"Bart just doesn't want to merge https://github.com/GTNewHorizons/bartworks/pull/4

I mean, just merge it for now, and then work on preventing wallsharing for all the multis and add the double casing thing discussed before.

Or just merge it for our fork, but not the original repo.

Why should this multi be special?",False,0,MEMBER
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/797682104,TT Oil Cracker,Dream-Master,28,830090253,7,797682104,0,797590760,2021-03-12T18:52:48Z,i reopen the issue. So feel free to discuss here.,False,0,MEMBER
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/797696604,TT Oil Cracker,Florexiz,28,830090253,8,797696604,0,797682104,2021-03-12T19:16:15Z,"Imo there are no reason to remove wall sharing. It was always been here and nobody complain about it afaik. It doesn't change too much in terms of saving resources, when you need more than 1 multi of that type few casings doesn't really matter. I cant remember using wall sharing for saving resources, only for sharing inputs or aesthetics",False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/797740852,TT Oil Cracker,mitchej123,28,830090253,9,797740852,0,797696604,2021-03-12T20:36:34Z,"I vote we address the wall sharing independent of the Oil Cracker move to TT.  Enable the new oil cracker code with the existing behavior, and start an RFC to discuss potential limitations on wall sharing [of which I'm in favor of].",False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/797741787,TT Oil Cracker,Prometheus0000,28,830090253,10,797741787,0,797740852,2021-03-12T20:38:26Z,By 'new oil cracker code with the existing behavior' do you mean bot's PR? Or anything else needed to fix it so it works the same as before the TT change regarding structure check?,False,0,MEMBER
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/797742481,TT Oil Cracker,mitchej123,28,830090253,11,797742481,0,797741787,2021-03-12T20:39:53Z,"Bots PR + anything else needed to continue with the legacy behavior until we've decided how to address wall sharing.  Not trying to put off the wall sharing discussion, but it should be addressed globally, not on a one off basis.",False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/797812430,TT Oil Cracker,bartimaeusnek,28,830090253,12,797812430,0,797742481,2021-03-12T23:29:34Z,"If you want legacy behavior, remove the class entirely. But don't just buff another part of the game with no downsides. You're eroding balance, again and i don't like it at all.",False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/797812854,TT Oil Cracker,mitchej123,28,830090253,13,797812854,0,797812430,2021-03-12T23:30:54Z,"> If you want legacy behavior, remove the class entirely. But don't just buff another part of the game with no downsides. You're eroding balance, again and i don't like it at all.

Or, we merge Bot's PR, and address wall sharing as a separate concern globally instead of with a one off bespoke hacky implementation.",False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/797813280,TT Oil Cracker,Prometheus0000,28,830090253,14,797813280,0,797812854,2021-03-12T23:32:33Z,"The downside is that you have to make higher tiers of coils to get the bonus? That _is_ what you're talking about, right?",False,0,MEMBER
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/797877110,TT Oil Cracker,Florexiz,28,830090253,15,797877110,0,797813280,2021-03-13T06:31:53Z,"> But don't just buff another part of the game with no downsides.

Leaving things as they are isn't a buff
",False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/798016936,TT Oil Cracker,Leche-Caliente,28,830090253,16,798016936,0,797877110,2021-03-13T09:25:51Z,"When I discovered the oil cracker change, I was also puzzled. When I learned it was done in an effort to curb wall sharing, I was annoyed.

People choosing to make caterpillar oil crackers in their own bases is not my problem. It isn't anyone's problem. Quite frankly, the cult of anti-wall sharing needs to lay off. It was fine when they were just trying to remove it from the game, but now failing that, they've decided to reduce functionality in other areas just to compensate. Now suddenly it is my problem.

The new overly-strict structure requirement for the oil cracker is simply goofy. The phrase ""cutting off one's nose to spite one's face"" comes to mind.",False,0,NONE
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/798208998,TT Oil Cracker,bartimaeusnek,28,830090253,17,798208998,0,798016936,2021-03-13T11:36:31Z,"> > But don't just buff another part of the game with no downsides.
> 
> Leaving things as they are isn't a buff
> 

Ye that's what I suggested. Remove the buff that's currently active in the zeta release, and remove the harder structure check or keep both. But I won't accept both active at the same time just because mitchej will eventually fix them somewhen in the future, maybe.",False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/798469590,TT Oil Cracker,mitchej123,28,830090253,18,798469590,0,798208998,2021-03-13T14:48:09Z,"> Ye that's what I suggested. Remove the buff that's currently active in the zeta release, and remove the harder structure check or keep both. But I won't accept both active at the same time just because mitchej will eventually fix them somewhen in the future, maybe.

You are picking a very strange battle here Bart.  Why is the oil cracker, of all things, so out of balance?  Remove the 90 degree requirement and leave it as a TT multi. 


You won't accept both active?  Didn't you say dream has say over this?  Stop trying to force your view on everyone to such an extreme.  I don't even want wall sharing and think this absurd requirement and your unwillingness to budge is ridiculous.


Also stop with the attacks on me.  The wall sharing adjustment should 💯 be addressed separately, regardless of who may or may not do it.",False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/799002493,TT Oil Cracker,basdxz,28,830090253,19,799002493,0,798469590,2021-03-14T23:38:35Z,"Just fix your setups and move on. The cracker has been buffed and appropriately nerfed, and wall sharing itself is a mechanic that hardly needs addressing. It is the QoL you love so much is it not? 3 multis for the cost of 2 sounds rather convenient to me,",False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/799003356,TT Oil Cracker,mitchej123,28,830090253,20,799003356,0,799002493,2021-03-14T23:43:55Z,"> Just fix your setups and move on. The cracker has been buffed and appropriately nerfed, and wall sharing itself is a mechanic that hardly needs addressing. It is the QoL you love so much is it not? 3 multis for the cost of 2 sounds rather convenient to me,

My non wall sharing setup has been broken because of this inane fight against wall sharing.  Remove the unnecessary 90 degree requirement and move on.",False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/799004162,TT Oil Cracker,basdxz,28,830090253,21,799004162,0,799003356,2021-03-14T23:48:23Z,"Changes require setup adjustment all the time, it's hardly a game changing thing for people to have to move a few machines around. Regardless like Bart said, undo the buff to the coils along with the slight structure adjustment.",False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/799004292,TT Oil Cracker,mitchej123,28,830090253,22,799004292,0,799004162,2021-03-14T23:49:07Z,"How about we update the structure to TT, and move the wall sharing adjustments to a DIFFERENT RFC like was suggested?",False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/799004447,TT Oil Cracker,basdxz,28,830090253,23,799004447,0,799004292,2021-03-14T23:50:06Z,@bartimaeusnek Hey can we undo the TT structure all together? I don't see why we really need it here.,False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/799004584,TT Oil Cracker,mitchej123,28,830090253,24,799004584,0,799004447,2021-03-14T23:50:59Z,[Wall sharing removal RFC](https://github.com/GTNewHorizons/GT-New-Horizons-Modpack/issues/7633),False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/799004726,TT Oil Cracker,basdxz,28,830090253,25,799004726,0,799004584,2021-03-14T23:51:47Z,sqrt(-1),False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/799005231,TT Oil Cracker,mitchej123,28,830090253,26,799005231,0,799004726,2021-03-14T23:54:49Z,"> Changes require setup adjustment all the time, 

Changes for no valid reason other than you and bart want to.  Stop trying to shove stuff through without Dream and others agreeing with them.  ""omg so cheap"" at a point it doesn't really matter much. 
",False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/799006748,TT Oil Cracker,Leche-Caliente,28,830090253,27,799006748,0,799005231,2021-03-15T00:02:56Z,"> > Changes require setup adjustment all the time,
> 
> Changes for no valid reason other than you and bart want to. Stop trying to shove stuff through without Dream and others agreeing with them. ""omg so cheap"" at a point it doesn't really matter much.

Aye. It's pretty clear at this point that bart and basdxz have a personal vendetta against wall sharing, and they don't care what else they break, so long as they can get their white whale.

And it isn't just about breaking current  setups --although that should be reason enough not to push through this inane change. Oil crackers are just silly now. The inputs have to go from left to right, unless you turn the entire machine upside down? It's like I've been transported back to a time where we didn't know how to make modular multiblocks, and it is a stark comparison to every other multiblock in my base.",False,0,NONE
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/799007141,TT Oil Cracker,mitchej123,28,830090253,28,799007141,0,799006748,2021-03-15T00:04:30Z,"
> Aye. It's pretty clear at this point that bart and basdxz have a personal vendetta against wall sharing, and they don't care what else they break, so long as they can get their white whale.
> 
> And it isn't just about breaking current setups --although that should be reason enough not to push through this inane change. Oil crackers are just silly now. The inputs have to go from left to right, unless you turn the entire machine upside down? It's like I've been transported back to a time where we didn't know how to make modular multiblocks, and it is a stark comparison to every other multiblock in my base.

To be 100% clear I'm in favor of removing wall sharing, but not by forcing it in as a dumb requirement to a structure check like you mention.  They should be two separate issues.",False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/799007619,TT Oil Cracker,Leche-Caliente,28,830090253,29,799007619,0,799007141,2021-03-15T00:06:37Z,"> To be 100% clear I'm in favor of removing wall sharing, but not by forcing it in as a dumb requirement to a structure check like you mention. They should be two separate issues.

Same, I have no issue with wallsharing getting cut, but not these kinds of hacky changes.",False,0,NONE
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/7617,Turn off pollution on officials until it gets reworked,Sphyix,11,830285557,1,830285557,0,0,2021-03-12T16:43:43Z,"Right now there's no way to deal with pollution..
Pollution scrubbers are buggy, and the only way to be able to stay in your base without an hazmat is by spreading it enough so every chunk is kept under 500k (which is REEEEEALLY easy to get to)
I think that the fact that pollution is not adding literally anything to the gameplay right now has already been said multiple times, but I guess I'll mention it aswell, pollution is just annoying and doesn't add anything interesting to the gameplay, except making sure you spread your base enough (which is kinda bad, I mean, long cable runs cause lag, and power needs to be centralized for efficiency most of the times)
So the request is to turn off pollution on official servers while waiting for the next update, as right now it's just an annoyance causing ppl to change the way they build their bases that could cause issues in the long run (like mentioned above, the power part)

tl;dr pollution is bad, base is smol, turn off pollution so I don't choke",True,0,NONE
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/797612643,Turn off pollution on officials until it gets reworked,basdxz,11,830285557,2,797612643,0,830285557,2021-03-12T16:45:06Z,"Wow, amazing, absolutely astonishing. Duplicate of #7341 But still needs attention.",False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/797613306,Turn off pollution on officials until it gets reworked,Sphyix,11,830285557,3,797613306,0,797612643,2021-03-12T16:46:14Z,"Well, I mean, it's saying the same things, but I'm asking to temporarily turn it off on officials
Idk when the rework is going to happen, I just want to play without pollution for now :P",False,0,NONE
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/797614852,Turn off pollution on officials until it gets reworked,basdxz,11,830285557,4,797614852,0,797613306,2021-03-12T16:48:37Z,Rework has been stagnant. Too many cooks in the kitchen and no drive to get anything done.,False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/797615398,Turn off pollution on officials until it gets reworked,Prometheus0000,11,830285557,5,797615398,0,797614852,2021-03-12T16:49:34Z,Didn't DvDmanDT say they were going to work on it?,False,0,MEMBER
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/797616352,Turn off pollution on officials until it gets reworked,Sphyix,11,830285557,6,797616352,0,797615398,2021-03-12T16:51:08Z,"> Rework has been stagnant. Too many cooks in the kitchen and no drive to get anything done.

Then the request to turn it off until it's reworked is more than valid I think?
At least even if they never rework it, we can play without something ruining the experience
It's just that right now we are waiting for the next update, where hopefully it's reworked or turned off, and suffering with pollution turned on, on the official servers.",False,0,NONE
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/797623524,Turn off pollution on officials until it gets reworked,boubou19,11,830285557,7,797623524,0,797616352,2021-03-12T17:00:55Z,"@Sphyix iirc, pollution option only disable the creation of pollution, but chunks stay polluted. So officials are doomed until it's either reworked or disabled in the next version the officials will receive.",False,0,MEMBER
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/797648449,Turn off pollution on officials until it gets reworked,dvdmandt,11,830285557,8,797648449,0,797623524,2021-03-12T17:42:10Z,"For the record, I am in early stages of revamping this indeed, but my work is more or less a ground up redesign that is not going to be done in an afternoon (think months). Also, the stuff I'm working on hasn't really been generally approved or anything, so there isn't even a guarantee that it'll be merged/included in the pack even when implemented.

So we may need some quick fixes for now if the current situation is unbearable for a significant portion of the player base. If not a disable, perhaps we can speed up dissipation and/or adjust the effect limits to be less destructive and annoying for now?",False,0,NONE
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/798029738,Turn off pollution on officials until it gets reworked,Leche-Caliente,11,830285557,9,798029738,0,797648449,2021-03-13T09:34:53Z,"@boubou19 not my experience on my personal world. I had pollution on until I started getting really bad constant status effects, then I turned it off in config. The chunks still read as polluted on my scanner, but no status effects at all.",False,0,NONE
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/799838175,Turn off pollution on officials until it gets reworked,azunaVT,11,830285557,10,799838175,0,798029738,2021-03-15T23:52:58Z,"I would really like to see this happening, 

I've been playing for almost 1 year now, I experienced pollution once in LV. I'm progressing very slowly on officials, mainly because that's how I play. I plan everything in advance (sometimes very poorly), and for me pollution is just an obstacle for my base build and its planning (spoiler: I wanna go vertical).

I hear really crazy stories about it and don't know what to expect , but I understand it will be a pain. I gathered a few points of why I think it should be disabled asap on officials : 
- It has a negative impact on how players could get creative with their builds, in a game that's all about that I find that mucho sad. I read way too often something along the lines of ""you should spread your base because **pollution**""
- Also, spreading your base seems like a band-aid solution to me, more chunks will be loaded, potentially more lag and makes it more expensive to progress (need more cable/pipes/diode/chunkloaders/etc.)
- It's a really bad mechanic, I assume it was to prevent some sort of abuse but the reason behind it seems to have been lost or is unclear to me.
- Could be a really great mechanic with a good rework, but in its current state is just a pain in the booty, hence why it should be turned off asap
- IMO, it should in no way arm the terrain _permanently_
- A.K.A the current state of pollution is destructive, way more than a simple machine blowing up because of rain; I can easily see how that could remove some fun in the game for some people.

Please be gentle, I am still a newbie at this modpack, I haven't experienced pollution at higher tiers and I'm talking mainly based on the one experience I had, as a new player and from the fear that has grown in me after a few discussions about pollution.

If this issue/proposition is not going anywhere, I would really like to see this transformed into a petition and share it to players on officials, to see if anyone else (and how many) have a similar point of view and get things moving with whoever it may concern afterwards. I just have a feeling I am not alone feeling this way towards pollution.
Also, I really think this would create a really good opportunity for the devs to take their time to rework it properly.

Most of my points are based on these revamp visions : 
https://gtnh.miraheze.org/wiki/Pollution_revamp_visions
https://gtnh.miraheze.org/wiki/Pollution_revamp
If you haven't seen them, I suggest to take a look, there are lots of great ideas in there, but most of them agree that : 
### Pollution is annoying, it is a bad mechanic for a non-issue and should be less destructive.

edit: Fixed some typos / wording.",False,0,NONE
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/800195779,Turn off pollution on officials until it gets reworked,MadeofGold,11,830285557,11,800195779,0,799838175,2021-03-16T11:56:13Z,"Considering the fact that big pollution shouldn't be an issue untill HV, you could just make the carbon nanosuit (all pieces give full hazmat) or Quantum suit ( full hazmat)",False,0,NONE
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/869220247,Turn off pollution on officials until it gets reworked,github-actions[bot],11,830285557,12,869220247,0,800195779,2021-06-27T20:33:45Z,This issue is stale because it has been open 90 days with no activity. Remove stale label or comment or this will be closed in 3 days,False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/7618,Oreberry maceration broken in 2.1.0.4,rv-jgentile,4,830331805,1,830331805,0,0,2021-03-12T17:51:30Z,"#### Which modpack version are you using?
2.1.0.4
#
#### If in multiplayer; On which server does this happen? 
n/a
#
#### What did you try to do, and what did you expect to happen?
Macerate oreberries, expected the macerator to operate and crush them into tiny piles.
#
#### What happened instead? (Attach screenshots if needed)
The macerator's inventory accepts them but doesn't actually do anything.
![image](https://user-images.githubusercontent.com/5657339/110978405-f490e880-8328-11eb-9379-45198085553d.png)

#
#### What do you suggest instead/what changes do you propose?
Fix oreberry maceration or document the change.
#
#### What is your GTNH Discord username?
aburger",True,0,NONE
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/797679954,Oreberry maceration broken in 2.1.0.4,Dream-Master,4,830331805,2,797679954,0,830331805,2021-03-12T18:49:41Z,ah yes another one i need to fix :),False,0,MEMBER
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/797689861,Oreberry maceration broken in 2.1.0.4,Prometheus0000,4,830331805,3,797689861,0,797679954,2021-03-12T19:04:51Z,"BTW I looked in the tinkers script file and the coremod and couldn't find the recipe, or it's removal. I wonder if someone changed something in GT related to finding materials?",False,0,MEMBER
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/797691382,Oreberry maceration broken in 2.1.0.4,Dream-Master,4,830331805,4,797691382,0,797689861,2021-03-12T19:07:29Z,"it was a change by mitch or was it bart cant remeber. Make the gt code loads faster and remove some unused compat stuff.
Now we see some compat is gone and i need to readd it manual like ardite and cobalt crushed recipes. Nothing to worry ill take care.",False,0,MEMBER
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/798959889,Oreberry maceration broken in 2.1.0.4,rv-jgentile,4,830331805,5,798959889,0,797691382,2021-03-14T18:56:51Z,"@Dream-Master I dug into this because I was bored and curious about ZenScript, hope you don't mind. PR up @ [PR 7630](https://github.com/GTNewHorizons/GT-New-Horizons-Modpack/pull/7630). Feel free to reject it - I was just curious if I could get it to work and figured I might as well put up a PR with what I ended up with on local.

_edit:_ closed the pr re: feedback. Definitely not familiar enough with the codebase to have the right change up any time soon. Good luck! ",False,0,NONE
https://api.github.com/repos/MvvmCross/MvvmCross/issues/4124,Mvx.IoCProvider.Resolve can't resolve type when internet is on,SerlokPK,3,822814509,1,822814509,0,0,2021-03-05T07:09:40Z,"## 🔙 Regression

<!--- Summary description of the regression --->
When internet is on on my android phone, I get `Failed to resolve type Telexis.TSU.MonitoringService.IMonitoringReportingService'`, and when it's off, everything is fine. After some time even with internet on, it starts working and I don't have this exception anymore.

### Old (and correct) behavior
Type was resolved.

### Current behavior
Exception that type can't be resolved

### Reproduction steps
Class is inheriting `Worker` class from `AndroidX.Work` and I can't use DI inside constructor, so inside `DoWork` method I am doing this `_monitoringReportingService = _monitoringReportingService ?? Mvx.IoCProvider.Resolve<IMonitoringReportingService>();` and get exception.

### Configuration

**Version:** 6.x
6.3.1

**Platform:** 
- [ ] :iphone: iOS
- [X ] :robot: Android
- [ ] :checkered_flag: WPF
- [ ] :earth_americas: UWP
- [ ] :apple: MacOS
- [ ] :tv: tvOS
- [ X] :monkey: Xamarin.Forms
",True,0,NONE
https://api.github.com/repos/MvvmCross/MvvmCross/issues/comments/791410676,Mvx.IoCProvider.Resolve can't resolve type when internet is on,Cheesebaron,3,822814509,2,791410676,0,822814509,2021-03-05T13:11:56Z,"Uhm. What? The IoC container knows nothing about the ""internet"" state. Not sure how `AndroidX.Work` works. However, if it is in a different process, that might not work for you.

Can you please provide a minimal reproducible sample?",False,0,MEMBER
https://api.github.com/repos/MvvmCross/MvvmCross/issues/comments/797547950,Mvx.IoCProvider.Resolve can't resolve type when internet is on,tbalcom,3,822814509,3,797547950,0,791410676,2021-03-12T15:05:45Z,"This can be avoided by calling `MvxAndroidSetupSingleton.EnsureSingletonAvailable(Context).EnsureInitialized()` at the beginning of the `Worker.DoWork` override. Android can restart the process and MvvmCross doesn't (can't?) hook into that, so it's up to us to reinitialize MvvmCross in components that aren't tied to an activity (Service, AndroidX.Worker, etc.).",False,0,CONTRIBUTOR
https://api.github.com/repos/MvvmCross/MvvmCross/issues/comments/804014451,Mvx.IoCProvider.Resolve can't resolve type when internet is on,SerlokPK,3,822814509,4,804014451,0,797547950,2021-03-22T12:10:28Z,"@tbalcom You are right, I was testing this in multiple scenarios and it is working, right now I don't get any exception",False,0,NONE
https://api.github.com/repos/MvvmCross/MvvmCross/issues/4151,Support for iOS 14 Split View's 3 column layout and compact width controller,winstonpang,6,851462743,1,851462743,0,0,2021-04-06T14:06:08Z,"So we've been looking at the improvements made to iOS 14's UISplitViewController, namely, you can now have 3 columns with the primary, supplementary and secondary.

Also it now supports the ability to show a different ViewController for CompactWidth's.

As I understand it, the MvxSplitViewPresentationAttribute enables us to describe which controller maps to the Master and which maps to the Detail. But that's the pre-iOS 14 setup.

Can anyone provide me of some guidance or tips what I might need to write or change in the view presenter so that it could recognise an extra column as well as being able to work with the CompactWidth alternate view controller?",True,0,NONE
https://api.github.com/repos/MvvmCross/MvvmCross/issues/comments/814160188,Support for iOS 14 Split View's 3 column layout and compact width controller,Cheesebaron,6,851462743,2,814160188,0,851462743,2021-04-06T14:20:21Z,"Add another attribute similar to `MvxSplitViewPresentationAttribute`. Register it in the presenter and add the required code to handle this.

Where exactly are you having issues?",False,0,MEMBER
https://api.github.com/repos/MvvmCross/MvvmCross/issues/comments/815453087,Support for iOS 14 Split View's 3 column layout and compact width controller,winstonpang,6,851462743,3,815453087,0,814160188,2021-04-08T05:15:31Z,"Apologies for being brief.

But in the MvxIosViewPresenter, the SplitViewController's property is IMvxSplitViewController, which is a bit of an issue in that, there's only ShowDetailView and ShowMasterView. iOS 14's new columns need to be called and set through the UISplitViewControllers SetViewController method call. 

So I guess my only option would be to cast SplitViewController to MvxSplitViewController to be able to call the SetViewController method.

Is there a better way to approaching this or is this the best option for now?

Thanks.",False,0,NONE
https://api.github.com/repos/MvvmCross/MvvmCross/issues/comments/815549801,Support for iOS 14 Split View's 3 column layout and compact width controller,Cheesebaron,6,851462743,4,815549801,0,815453087,2021-04-08T08:07:30Z,"To be honest, I don't know. I haven't looked into the new SplitViewController stuff in iOS myself.

My answer would be, do whatever works for you.",False,0,MEMBER
https://api.github.com/repos/MvvmCross/MvvmCross/issues/comments/822011366,Support for iOS 14 Split View's 3 column layout and compact width controller,Hackmodford,6,851462743,5,822011366,0,815549801,2021-04-18T15:38:27Z,"Are you looking to create a custom presenter? Or to update MvvmCross?

If we're talking about updating MvvmCross, we probably need to add a new method to IMvxSplitViewController to handle the third pane.",False,0,CONTRIBUTOR
https://api.github.com/repos/MvvmCross/MvvmCross/issues/comments/839013560,Support for iOS 14 Split View's 3 column layout and compact width controller,ivmirx,6,851462743,6,839013560,0,822011366,2021-05-11T19:04:50Z,"I was recently going through the iOS presenter and no, the new three-column layout with a supplementary view and various display modes are [not supported](https://github.com/MvvmCross/MvvmCross/blob/25f695377d4a9d1074273fdac57f04f001d1e951/MvvmCross/Platforms/Ios/Presenters/MvxIosViewPresenter.cs#L126).

You can subclass the existing `MvxIosViewPresenter` and add required behavior based on the existing methods `ShowMasterSplitViewController()`, `ShowDetailSplitViewController()`, `CloseMasterSplitViewController()`, `CloseDetailSplitViewController()`. It will also require subclassing/replacing `MvxSplitViewPresentationAttribute` to store more data (like the display mode) inside attributes.",False,0,CONTRIBUTOR
https://api.github.com/repos/MvvmCross/MvvmCross/issues/comments/845542660,Support for iOS 14 Split View's 3 column layout and compact width controller,winstonpang,6,851462743,7,845542660,0,839013560,2021-05-20T23:14:56Z,"Alright so we've got it semi-working, here's what we've whipped up in our prototype:

`   public class ExtendedIosViewPresenter : MvxIosViewPresenter
    {
        public ExtendedIosViewPresenter (IUIApplicationDelegate applicationDelegate, UIWindow window) : base(applicationDelegate, window)
        {
        }

        public override void RegisterAttributeTypes()
        {
            base.RegisterAttributeTypes();

            AttributeTypesToActionsDictionary.Register<ExtendedMvxSplitViewPresentationAttribute>(
                (viewType, attribute, request) =>
                {
                    var viewController = (UIViewController)this.CreateViewControllerFor(request);
                    var splitAttribute = attribute;
                    return splitAttribute.Position switch
                    {
                        ExtendedMasterDetailPosition.Primary =>
                            ShowPrimarySplitViewController(viewController, request),
                        ExtendedMasterDetailPosition.Supplementary =>
                            ShowSupplementarySplitViewController(viewController, request),
                        ExtendedMasterDetailPosition.Secondary =>
                            ShowSecondarySplitViewController(viewController, request),
                        ExtendedMasterDetailPosition.Compact =>
                            ShowCompactSplitViewController(viewController, request),
                        _ => Task.FromResult(true)
                    };
                    //return Task.FromResult(true);
                },
                (viewModel, attribute) =>
                {
                    //var splitAttribute = attribute;
                    //return splitAttribute.Position switch
                    //{
                    //    ExtendedMasterDetailPosition.Master => CloseMasterSplitViewController(viewModel, splitAttribute),
                    //    ExtendedMasterDetailPosition.Detail => CloseDetailSplitViewController(viewModel, splitAttribute),
                    //    _ => CloseDetailSplitViewController(viewModel, splitAttribute)
                    //};
                    return Task.FromResult(true);
                });
        }

        private Task<bool> ShowSupplementarySplitViewController(UIViewController viewController, MvxViewModelRequest request)
        {
            if (SplitViewController == null)
                throw new MvxException(""No split view controller"");

            var mvxSplitViewController = SplitViewController as MvxSplitViewController;

            mvxSplitViewController.SetViewController(viewController, UISplitViewControllerColumn.Supplementary);
            
            return Task.FromResult(true);
        }

        private Task<bool> ShowSecondarySplitViewController(UIViewController viewController, MvxViewModelRequest request)
        {
            if (SplitViewController == null)
                throw new MvxException(""No split view controller"");

            var mvxSplitViewController = SplitViewController as MvxSplitViewController;

            mvxSplitViewController.SetViewController(null, UISplitViewControllerColumn.Secondary);


            mvxSplitViewController.SetViewController(viewController, UISplitViewControllerColumn.Secondary);
            
            return Task.FromResult(true);
        }

        private Task<bool> ShowPrimarySplitViewController(UIViewController viewController, MvxViewModelRequest request)
        {
            if (SplitViewController == null)
                throw new MvxException(""No split view controller"");

            var mvxSplitViewController = SplitViewController as MvxSplitViewController;

            mvxSplitViewController.SetViewController(viewController, UISplitViewControllerColumn.Primary);

            return Task.FromResult(true);
        }

        private Task<bool> ShowCompactSplitViewController(UIViewController viewController, MvxViewModelRequest request)
        {
            if (SplitViewController == null)
                return Task.FromResult(false);

            var mvxSplitViewController = SplitViewController as MvxSplitViewController;

            mvxSplitViewController.SetViewController(viewController, UISplitViewControllerColumn.Compact);

            return Task.FromResult(true);
        }
    }`


Which works more or less correctly however.

Generally the usage pattern of a 3 column split is like:

Primary - Sidebar menu - same as how it is originally
Supplementary - A table list of your items
Secondary - The a selected detail view of one of the items in the table.

However if you have a view inside the Secondary column, where there are some links that perform a Navigation typically, the navigation won't work correctly because the MasterNavigationController inside the Presenter would be basically the root view controller, so if you perform a sub-navigation in a view that sits inside the Secondary column it ends up completely replacing the entire UISplitViewController.

Not sure how to combat this though",False,0,NONE
https://api.github.com/repos/MvvmCross/MvvmCross/issues/4160,iOS back button text disappears,markuspalme,7,868837666,1,868837666,0,0,2021-04-27T13:15:40Z,"In a MvvmCross (latest stable) project with iOS the back button *sometimes* behaves likes this. When clicking it, the title text disappears and I have to click on the arrow on the left to go back:

![nav1](https://user-images.githubusercontent.com/1481801/116247371-12949a00-a76b-11eb-9909-1f0095f52498.gif)

I have also observed that holding down on the button (without releasing the mouse/finger) consistently makes the text dissappear:

![nav2](https://user-images.githubusercontent.com/1481801/116247388-16282100-a76b-11eb-86eb-06e997ccbe63.gif)

I'm not sure whether this is a MvvmCross problem or an iOS issue. Has anyone experienced someting similar?

This is a `MvxNavigationController` inside a `MvxTabController`.
",True,0,CONTRIBUTOR
https://api.github.com/repos/MvvmCross/MvvmCross/issues/comments/827611015,iOS back button text disappears,Cheesebaron,7,868837666,2,827611015,0,868837666,2021-04-27T13:34:52Z,I haven't seen this. Is this Xamarin.Forms?,False,0,MEMBER
https://api.github.com/repos/MvvmCross/MvvmCross/issues/comments/827612292,iOS back button text disappears,markuspalme,7,868837666,3,827612292,0,827611015,2021-04-27T13:36:36Z,Xamarin.iOS without forms.,False,0,CONTRIBUTOR
https://api.github.com/repos/MvvmCross/MvvmCross/issues/comments/827633705,iOS back button text disappears,Cheesebaron,7,868837666,4,827633705,0,827612292,2021-04-27T14:05:38Z,"Is this a custom back button, or the one that iOS adds when you navigate to a child?",False,0,MEMBER
https://api.github.com/repos/MvvmCross/MvvmCross/issues/comments/827637297,iOS back button text disappears,markuspalme,7,868837666,5,827637297,0,827633705,2021-04-27T14:10:25Z,"It's the default button, no changes whatsoever.",False,0,CONTRIBUTOR
https://api.github.com/repos/MvvmCross/MvvmCross/issues/comments/827665006,iOS back button text disappears,Cheesebaron,7,868837666,6,827665006,0,827637297,2021-04-27T14:47:39Z,"I haven't seen it before. If you find repro steps, I'd be happy to help fix it.",False,0,MEMBER
https://api.github.com/repos/MvvmCross/MvvmCross/issues/comments/827671565,iOS back button text disappears,markuspalme,7,868837666,7,827671565,0,827665006,2021-04-27T14:55:55Z,"I think I have found the root cause. I was setting the font attributes in a theme on the `UIBarButtonItem.Appearance` proxy by creating new `UITextAttributes` :

```
var proxyUIBarButton = UIBarButtonItem.Appearance;
proxyUIBarButton.SetTitleTextAttributes(new UITextAttributes { Font = UIFont.FromName(RegularFontName, 20), TextColor = AtxBlue }, UIControlState.Normal);
```

It works when basing the attributes on the default attributes:

```
var attr = proxyUIBarButton.GetTitleTextAttributes(UIControlState.Application);
attr.Font = UIFont.FromName(RegularFontName, 20);
attr.TextColor = AtxBlue;
proxyUIBarButton.SetTitleTextAttributes(attr, UIControlState.Normal);
```

So the issue was a) completely on my end and b) not related to MvX.",False,0,CONTRIBUTOR
https://api.github.com/repos/MvvmCross/MvvmCross/issues/comments/827682628,iOS back button text disappears,Cheesebaron,7,868837666,8,827682628,0,827671565,2021-04-27T15:08:22Z,Good to know you found the issue 👍,False,0,MEMBER
https://api.github.com/repos/MvvmCross/MvvmCross/issues/4169,Bump Newtonsoft.Json from 12.0.3 to 13.0.1,dependabot[bot],5,875245201,1,875245201,0,0,2021-05-04T08:47:11Z,"Bumps [Newtonsoft.Json](https://github.com/JamesNK/Newtonsoft.Json) from 12.0.3 to 13.0.1.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/JamesNK/Newtonsoft.Json/releases"">Newtonsoft.Json's releases</a>.</em></p>
<blockquote>
<h2>13.0.1</h2>
<ul>
<li>New feature - Add JsonSelectSettings with configuration for a regex timeout</li>
<li>Change - Remove portable assemblies from NuGet package</li>
<li>Change - JsonReader and JsonSerializer MaxDepth defaults to 64</li>
<li>Fix - Fixed throwing missing member error on ignored fields</li>
<li>Fix - Fixed various nullable annotations</li>
<li>Fix - Fixed annotations not being copied when tokens are cloned</li>
<li>Fix - Fixed naming strategy not being used when deserializing dictionary enum keys</li>
<li>Fix - Fixed serializing nullable struct dictionaries</li>
<li>Fix - Fixed JsonWriter.WriteToken to allow null with string token</li>
<li>Fix - Fixed missing error when deserializing JToken with a contract type mismatch</li>
<li>Fix - Fixed JTokenWriter when writing comment to an object</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/JamesNK/Newtonsoft.Json/commit/ae9fe44e1323e91bcbd185ca1a14099fba7c021f""><code>ae9fe44</code></a> Remove compiler package and update sourcelink (<a href=""https://github-redirect.dependabot.com/JamesNK/Newtonsoft.Json/issues/2498"">#2498</a>)</li>
<li><a href=""https://github.com/JamesNK/Newtonsoft.Json/commit/8ef662189dd7fc890c8fcd832d3e283edb90ef31""><code>8ef6621</code></a> Remove prerelease for 13.0.1</li>
<li><a href=""https://github.com/JamesNK/Newtonsoft.Json/commit/11331f50fd1c09dc1f44fe17ef26aba7c460b42c""><code>11331f5</code></a> Update SDK to 5.0.200 (<a href=""https://github-redirect.dependabot.com/JamesNK/Newtonsoft.Json/issues/2495"">#2495</a>)</li>
<li><a href=""https://github.com/JamesNK/Newtonsoft.Json/commit/c7e8abc09de751785355e3f972150f8a72379b02""><code>c7e8abc</code></a> Update to 13.0.1-beta2</li>
<li><a href=""https://github.com/JamesNK/Newtonsoft.Json/commit/1745d7c14ec7e4244a5ca1c7ddf5d955cf7d1f43""><code>1745d7c</code></a> Fix JTokenWriter when writing comment to an object (<a href=""https://github-redirect.dependabot.com/JamesNK/Newtonsoft.Json/issues/2493"">#2493</a>)</li>
<li><a href=""https://github.com/JamesNK/Newtonsoft.Json/commit/583eb120152f8b6332df2fe3d4b9f4c947c944d0""><code>583eb12</code></a> Fix missing error when deserializing JToken with a contract type mismatch (<a href=""https://github-redirect.dependabot.com/JamesNK/Newtonsoft.Json/issues/2"">#2</a>...</li>
<li><a href=""https://github.com/JamesNK/Newtonsoft.Json/commit/b6dc05be5a0f4808f06ec430f3bb59b24d3fbc3e""><code>b6dc05b</code></a> Change MaxDepth default to 64 (<a href=""https://github-redirect.dependabot.com/JamesNK/Newtonsoft.Json/issues/2473"">#2473</a>)</li>
<li><a href=""https://github.com/JamesNK/Newtonsoft.Json/commit/15525f1c44e0d99ef8fdee73430853e22239181d""><code>15525f1</code></a> Fix JsonWriter.WriteToken to allow null with string token (<a href=""https://github-redirect.dependabot.com/JamesNK/Newtonsoft.Json/issues/2472"">#2472</a>)</li>
<li><a href=""https://github.com/JamesNK/Newtonsoft.Json/commit/926d2f0f42292cfcdf07cdadeb501b73fd5b1d52""><code>926d2f0</code></a> Enable embed untracked sources (<a href=""https://github-redirect.dependabot.com/JamesNK/Newtonsoft.Json/issues/2471"">#2471</a>)</li>
<li><a href=""https://github.com/JamesNK/Newtonsoft.Json/commit/0a56633b6cd4fccc860a8486260ee67636f3fe90""><code>0a56633</code></a> Fixes <a href=""https://github-redirect.dependabot.com/JamesNK/Newtonsoft.Json/issues/2372"">#2372</a> - variable typos (<a href=""https://github-redirect.dependabot.com/JamesNK/Newtonsoft.Json/issues/2465"">#2465</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/JamesNK/Newtonsoft.Json/compare/12.0.3...13.0.1"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=Newtonsoft.Json&package-manager=nuget&previous-version=12.0.3&new-version=13.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",True,0,CONTRIBUTOR
https://api.github.com/repos/MvvmCross/MvvmCross/issues/comments/831808400,Bump Newtonsoft.Json from 12.0.3 to 13.0.1,sonarcloud[bot],5,875245201,2,831808400,0,875245201,2021-05-04T09:31:49Z,"Kudos, SonarCloud Quality Gate passed!

[<img src='https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/bug.png' alt='Bug' width='16' height='16' />](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=BUG) [<img src='https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/A.png' alt='A' width='16' height='16' />](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=BUG) [0 Bugs](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=BUG)  
[<img src='https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/vulnerability.png' alt='Vulnerability' width='16' height='16' />](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=VULNERABILITY) [<img src='https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/A.png' alt='A' width='16' height='16' />](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=VULNERABILITY) [0 Vulnerabilities](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=VULNERABILITY)  
[<img src='https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/security_hotspot.png' alt='Security Hotspot' width='16' height='16' />](https://sonarcloud.io/project/security_hotspots?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=SECURITY_HOTSPOT) [<img src='https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/A.png' alt='A' width='16' height='16' />](https://sonarcloud.io/project/security_hotspots?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=SECURITY_HOTSPOT) [0 Security Hotspots](https://sonarcloud.io/project/security_hotspots?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=SECURITY_HOTSPOT)  
[<img src='https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/code_smell.png' alt='Code Smell' width='16' height='16' />](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=CODE_SMELL) [<img src='https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/A.png' alt='A' width='16' height='16' />](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=CODE_SMELL) [0 Code Smells](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=CODE_SMELL)

[<img src='https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/CoverageChart/NoCoverageInfo.png' alt='No Coverage information' width='16' height='16' />](https://sonarcloud.io/component_measures?id=MvvmCross_MvvmCross&pullRequest=4169&metric=coverage&view=list) No Coverage information  
[<img src='https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/Duplications/NoDuplicationInfo.png' alt='No Duplication information' width='16' height='16' />](https://sonarcloud.io/component_measures?id=MvvmCross_MvvmCross&pullRequest=4169&metric=duplicated_lines_density&view=list) No Duplication information

",False,0,NONE
https://api.github.com/repos/MvvmCross/MvvmCross/issues/comments/943757585,Bump Newtonsoft.Json from 12.0.3 to 13.0.1,sonarcloud[bot],5,875245201,3,943757585,0,831808400,2021-10-14T21:41:52Z,"Kudos, SonarCloud Quality Gate passed!&nbsp; &nbsp; ![Quality Gate passed](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/QualityGateBadge/passed-16px.png 'Quality Gate passed')

[![Bug](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/bug-16px.png 'Bug')](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=BUG) [![A](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/A-16px.png 'A')](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=BUG) [0 Bugs](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=BUG)  
[![Vulnerability](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/vulnerability-16px.png 'Vulnerability')](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=VULNERABILITY) [![A](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/A-16px.png 'A')](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=VULNERABILITY) [0 Vulnerabilities](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=VULNERABILITY)  
[![Security Hotspot](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/security_hotspot-16px.png 'Security Hotspot')](https://sonarcloud.io/project/security_hotspots?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=SECURITY_HOTSPOT) [![A](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/A-16px.png 'A')](https://sonarcloud.io/project/security_hotspots?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=SECURITY_HOTSPOT) [0 Security Hotspots](https://sonarcloud.io/project/security_hotspots?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=SECURITY_HOTSPOT)  
[![Code Smell](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/code_smell-16px.png 'Code Smell')](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=CODE_SMELL) [![A](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/A-16px.png 'A')](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=CODE_SMELL) [0 Code Smells](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=CODE_SMELL)

[![No Coverage information](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/CoverageChart/NoCoverageInfo-16px.png 'No Coverage information')](https://sonarcloud.io/component_measures?id=MvvmCross_MvvmCross&pullRequest=4169&metric=coverage&view=list) No Coverage information  
[![No Duplication information](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/Duplications/NoDuplicationInfo-16px.png 'No Duplication information')](https://sonarcloud.io/component_measures?id=MvvmCross_MvvmCross&pullRequest=4169&metric=duplicated_lines_density&view=list) No Duplication information

",False,0,NONE
https://api.github.com/repos/MvvmCross/MvvmCross/issues/comments/997183498,Bump Newtonsoft.Json from 12.0.3 to 13.0.1,sonarcloud[bot],5,875245201,4,997183498,0,943757585,2021-12-18T10:40:14Z,"Kudos, SonarCloud Quality Gate passed!&nbsp; &nbsp; ![Quality Gate passed](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/QualityGateBadge/passed-16px.png 'Quality Gate passed')

[![Bug](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/bug-16px.png 'Bug')](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=BUG) [![A](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/A-16px.png 'A')](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=BUG) [0 Bugs](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=BUG)  
[![Vulnerability](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/vulnerability-16px.png 'Vulnerability')](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=VULNERABILITY) [![A](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/A-16px.png 'A')](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=VULNERABILITY) [0 Vulnerabilities](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=VULNERABILITY)  
[![Security Hotspot](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/security_hotspot-16px.png 'Security Hotspot')](https://sonarcloud.io/project/security_hotspots?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=SECURITY_HOTSPOT) [![A](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/A-16px.png 'A')](https://sonarcloud.io/project/security_hotspots?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=SECURITY_HOTSPOT) [0 Security Hotspots](https://sonarcloud.io/project/security_hotspots?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=SECURITY_HOTSPOT)  
[![Code Smell](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/code_smell-16px.png 'Code Smell')](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=CODE_SMELL) [![A](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/A-16px.png 'A')](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=CODE_SMELL) [0 Code Smells](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=CODE_SMELL)

[![No Coverage information](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/CoverageChart/NoCoverageInfo-16px.png 'No Coverage information')](https://sonarcloud.io/component_measures?id=MvvmCross_MvvmCross&pullRequest=4169&metric=coverage&view=list) No Coverage information  
[![No Duplication information](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/Duplications/NoDuplicationInfo-16px.png 'No Duplication information')](https://sonarcloud.io/component_measures?id=MvvmCross_MvvmCross&pullRequest=4169&metric=duplicated_lines_density&view=list) No Duplication information

",False,0,NONE
https://api.github.com/repos/MvvmCross/MvvmCross/issues/comments/1042754240,Bump Newtonsoft.Json from 12.0.3 to 13.0.1,sonarcloud[bot],5,875245201,5,1042754240,0,997183498,2022-02-17T09:41:59Z,"Kudos, SonarCloud Quality Gate passed!&nbsp; &nbsp; ![Quality Gate passed](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/QualityGateBadge/passed-16px.png 'Quality Gate passed')

[![Bug](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/bug-16px.png 'Bug')](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=BUG) [![A](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/A-16px.png 'A')](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=BUG) [0 Bugs](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=BUG)  
[![Vulnerability](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/vulnerability-16px.png 'Vulnerability')](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=VULNERABILITY) [![A](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/A-16px.png 'A')](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=VULNERABILITY) [0 Vulnerabilities](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=VULNERABILITY)  
[![Security Hotspot](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/security_hotspot-16px.png 'Security Hotspot')](https://sonarcloud.io/project/security_hotspots?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=SECURITY_HOTSPOT) [![A](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/A-16px.png 'A')](https://sonarcloud.io/project/security_hotspots?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=SECURITY_HOTSPOT) [0 Security Hotspots](https://sonarcloud.io/project/security_hotspots?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=SECURITY_HOTSPOT)  
[![Code Smell](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/common/code_smell-16px.png 'Code Smell')](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=CODE_SMELL) [![A](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/RatingBadge/A-16px.png 'A')](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=CODE_SMELL) [0 Code Smells](https://sonarcloud.io/project/issues?id=MvvmCross_MvvmCross&pullRequest=4169&resolved=false&types=CODE_SMELL)

[![No Coverage information](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/CoverageChart/NoCoverageInfo-16px.png 'No Coverage information')](https://sonarcloud.io/component_measures?id=MvvmCross_MvvmCross&pullRequest=4169&metric=coverage&view=list) No Coverage information  
[![No Duplication information](https://sonarsource.github.io/sonarcloud-github-static-resources/v2/checks/Duplications/NoDuplicationInfo-16px.png 'No Duplication information')](https://sonarcloud.io/component_measures?id=MvvmCross_MvvmCross&pullRequest=4169&metric=duplicated_lines_density&view=list) No Duplication information

",False,0,NONE
https://api.github.com/repos/MvvmCross/MvvmCross/issues/comments/1170442858,Bump Newtonsoft.Json from 12.0.3 to 13.0.1,Cheesebaron,5,875245201,6,1170442858,0,1042754240,2022-06-29T20:04:41Z,@dependabot close,False,0,MEMBER
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/3867,Add Zwift intervals to Erg intervals + Add intervals to FIT export,comediebenji,4,855390932,1,855390932,0,0,2021-04-11T19:41:55Z,"Hey, I just add the possibility to have Zwo training sessions beeing automatically divided into intervals (laps) in order to be able to analyze the phases of the training afterwards. (and in the future to add cadence target for each interval: i'm working on that, pull request soon normally).

The intervals created during workout are now integrated into the FIT export (which I personally use). In addition, I added the possibility of having intervals of a duration of 1s in the RideDB.json and in the summary (just to be synchronous with the JSON files of the saved activities).
",True,0,CONTRIBUTOR
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/817387344,Add Zwift intervals to Erg intervals + Add intervals to FIT export,amtriathlon,4,855390932,2,817387344,0,855390932,2021-04-11T22:57:47Z,"First, thanks for your contribution. Second, some comments:
1) This seems 2 completely independent features, please make 2 separate pull request
2) At first sight creation of laps from zwo files seems to be ok, you can check in qwkcode and erg export.
3) For FitRideFile to access intervals you can make it a friend class like in: https://github.com/GoldenCheetah/GoldenCheetah/blob/e9b192d84a2461e01558bfbbd54122789bb533f3/src/FileIO/RideFile.h#L183, but don't make any other change to RideFile class.
4) GoldenCheetah intervals can overlap, this needs to be tested on fit export.",False,0,MEMBER
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/820631004,Add Zwift intervals to Erg intervals + Add intervals to FIT export,comediebenji,4,855390932,3,820631004,0,817387344,2021-04-15T18:12:05Z,"Hello,
1. Okay, I'll do it like this. Sorry, I'm going to do two pull requests: i'm just a newcomer on Github and it was a handling error (I don't know if this sentence makes sense in English^^).
2. It seems that if we modify the ZWO workout with qwkcode and export it to ERG, it keeps the original laps but starts with lap ""0"" whereas with Zwo workout, Laps start from ""1""; after the workout with the ERG file, 1 lap is missing, and their duration does not match as well (see attached pictures). So I have indeed more works to do.
![pb](https://user-images.githubusercontent.com/81979063/114916964-b7d37800-9e25-11eb-8292-bb642fa3ae98.png)
3. Okay, will change that
4. How is it possible (to reproduce that phenomemon)? I tested with a workout and add during it a manual Lap, and it's Okay with the FIT export.",False,0,CONTRIBUTOR
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/821398647,Add Zwift intervals to Erg intervals + Add intervals to FIT export,amtriathlon,4,855390932,4,821398647,0,820631004,2021-04-16T18:17:01Z,"Hi, for 1) you can see https://docs.github.com/en/github/collaborating-with-issues-and-pull-requests/proposing-changes-to-your-work-with-pull-requests

WRT to 2) I don't know, but once it is on a separate PR we can test and compare, ideally the behavior should match.

For 4) you can add interval manually in Activity chart. Since the export FIT feature is a general one, it needs to behave well with free laps, not only with sequential/contiguous like the ones generated by Train or Devices. I am not saying it doesn't work, only it is something to test.",False,0,MEMBER
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/830874094,Add Zwift intervals to Erg intervals + Add intervals to FIT export,amtriathlon,4,855390932,5,830874094,0,821398647,2021-05-02T21:21:44Z,">I'm going to do two pull requests

Then let’s close this one.

Please check https://github.com/GoldenCheetah/GoldenCheetah/wiki/Guidelines-for-submitting-a-patch",False,0,MEMBER
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/3872,Correcting bug with quote character in workout Textevents and ZWO export,comediebenji,4,860686889,1,860686889,0,0,2021-04-18T15:07:03Z,"When adding a Zwo workout, modify it (or not) and save it with .zwo format, if some Textevents have ""some words"" inside quotes, they were not replaced with XML comptible characters ""\&quot\;"".",True,0,CONTRIBUTOR
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/822020156,Correcting bug with quote character in workout Textevents and ZWO export,amtriathlon,4,860686889,2,822020156,0,860686889,2021-04-18T16:34:51Z,"Good catch, but since this is a common problem with strings included in xml files, it would be better to use the available utility function for that task: https://github.com/GoldenCheetah/GoldenCheetah/blob/696a04e8a0d2175d4bb5f6de8c628026c7049924/src/Core/Utils.cpp#L144",False,0,MEMBER
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/822020546,Correcting bug with quote character in workout Textevents and ZWO export,comediebenji,4,860686889,3,822020546,0,822020156,2021-04-18T16:37:34Z,"Ok, I will do the change",False,0,CONTRIBUTOR
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/822022436,Correcting bug with quote character in workout Textevents and ZWO export,amtriathlon,4,860686889,4,822022436,0,822020546,2021-04-18T16:50:23Z,And the reverse function needs to be used on import ,False,0,MEMBER
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/822023750,Correcting bug with quote character in workout Textevents and ZWO export,comediebenji,4,860686889,5,822023750,0,822022436,2021-04-18T16:59:18Z,"It seems to be already the case, with the Qxml-InputSource-SimpleReader",False,0,CONTRIBUTOR
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/3882,SARIS H3 ADDED BTLE BUT NOT WORKING. NO POWER AND NOT MOVING DURING WORKOUT.,iamjones2,3,872435276,1,872435276,0,0,2021-04-30T12:33:24Z,"I am running Golden Cheetah v3.6 developmental build jan 2021 on Windows 10. My Saris H3 trainer is connected BTLE. The workout time starts when I ride but no watts appear and I do not move.

GC Google Group not responding to my join request.
",True,0,NONE
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/830074028,SARIS H3 ADDED BTLE BUT NOT WORKING. NO POWER AND NOT MOVING DURING WORKOUT.,amtriathlon,3,872435276,2,830074028,0,872435276,2021-04-30T12:53:24Z,"First message to the group is moderated to avoid spam, be patient. In the meantime you can read the FAQs on Train and Troubleshooting.",False,0,MEMBER
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/830075257,SARIS H3 ADDED BTLE BUT NOT WORKING. NO POWER AND NOT MOVING DURING WORKOUT.,iamjones2,3,872435276,3,830075257,0,830074028,2021-04-30T12:55:34Z,I get the moderated but why close it?,False,0,NONE
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/830083789,SARIS H3 ADDED BTLE BUT NOT WORKING. NO POWER AND NOT MOVING DURING WORKOUT.,amtriathlon,3,872435276,4,830083789,0,830075257,2021-04-30T13:09:45Z,"Because we use the tracker for bugs and features only, not technical support, help or questions.",False,0,MEMBER
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/3883,Importing files or borwsing the file system causes system hang on OS X,edemattia,4,873231643,1,873231643,0,0,2021-04-30T20:13:06Z,"Latest snapshot (as of this post). Any function in GC that requires loading a file by browsing the file system (import activity, import workout, choose backup directory, etc.) causes OS X to hang for 20-90 seconds. It happens every time regardless of where in GC I am.  The common action is any function that needs to open the OS X finder process.

OS X Mojave",True,0,NONE
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/830397837,Importing files or borwsing the file system causes system hang on OS X,amtriathlon,4,873231643,2,830397837,0,873231643,2021-04-30T21:12:22Z,"This is a known issue on Mojave, please read the FAQs and use the users forum before open issues.",False,0,MEMBER
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/830411150,Importing files or borwsing the file system causes system hang on OS X,edemattia,4,873231643,3,830411150,0,830397837,2021-04-30T21:31:05Z,"Thank you for the reply.  I searched the forums for ""Mojave"" and didn't see anything related to my issue (other issues for sure). I may have missed it but did sincerely look.",False,0,NONE
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/830431049,Importing files or borwsing the file system causes system hang on OS X,amtriathlon,4,873231643,4,830431049,0,830411150,2021-04-30T22:20:58Z,It has been discussed in the forum and there is an entry in FAQs: https://github.com/GoldenCheetah/GoldenCheetah/wiki/Severe-Performance-Issues,False,0,MEMBER
https://api.github.com/repos/GoldenCheetah/GoldenCheetah/issues/comments/830433784,Importing files or borwsing the file system causes system hang on OS X,edemattia,4,873231643,5,830433784,0,830431049,2021-04-30T22:27:41Z,Thank you.  Greatly appreciated!,False,0,NONE
https://api.github.com/repos/Leaflet/Leaflet/issues/7560,Add possibility to set Authorization (or any custom) HTTP headers for web-based layers,stefano-xy,3,870218880,1,870218880,0,0,2021-04-28T18:13:46Z,"It should be possible to use XHR ` setRequestHeader()` method to specify custom HTTP headers for HTTP calls web-based layers as `TileLayer` send, or an equivalent method.

Goal is to be able to pass a custom `Authorization` HTTP header. Browsers should allow it as this header is not one of the restricted ones. For more information, please see https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest/setRequestHeader.

Motivation is that sometimes tile maps, or content in general, is served by APIs that requires authentication that is different than what the browser provides. A library like ipyleaftlet should then be extended to expose this functionality, it's being discussed here: https://github.com/jupyter-widgets/ipyleaflet/issues/802, if leaflet would support it explicitly it would help.

A similar solution is already provided for CORS headers. If a generic solution is considered out of scope, please add support for just `Authorization`.",True,0,NONE
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/954172781,Add possibility to set Authorization (or any custom) HTTP headers for web-based layers,Falke-Design,3,870218880,2,954172781,0,870218880,2021-10-28T20:20:06Z,Linking:  #7117,False,0,MEMBER
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/1611603102,Add possibility to set Authorization (or any custom) HTTP headers for web-based layers,tobiasso85,3,870218880,3,1611603102,0,954172781,2023-06-28T14:58:04Z,"Hi,

we face a similar issue with regards to auth headers.
We use a GET request, but we require the headers.

It would already help, if it would be possible to override `createTile` in the `TileLayer`
e.g.

```js
L.TileLayer.MyLayer = L.TileLayer.extend({
    createTile: function (coords, done) {
      const url = this.getTileUrl(coords);
      const img = document.createElement('img');
      img.setAttribute('role', 'presentation');
        const response = await fetch(url, {
        method: 'GET',
        headers: headersWithAuths,
        mode: 'cors',
        signal,
      });
      const blob = await response.blob();
      const reader = new FileReader();
       reader.onload = () => {
            img.src = reader.result;
          };
       reader.readAsDataURL(blob);
       done(null, img);
       return img;
    }
});
```

like https://leafletjs.com/examples/extending/extending-2-layers.html

Having this extension possibility by default makes our life easier :-)

For now there are quite some custom plugins out there, just for that:
https://github.com/Leaflet/Leaflet/issues/2091#issuecomment-302706529
and
https://github.com/jaq316/leaflet-header
with 26 Forks :)",False,0,NONE
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/1631560050,Add possibility to set Authorization (or any custom) HTTP headers for web-based layers,ppete2,3,870218880,4,1631560050,0,1611603102,2023-07-11T21:54:03Z,"I support this feature request! Please add an option for TileLayers to define custom HTTP-headers, e.g. for defining authorization or token values. A similar request has been writen here: #https://github.com/Leaflet/Leaflet/issues/2091
This basic feature of Tile image requests should be implemented in core-Leaflet and not need to install a Plug-In.",False,0,CONTRIBUTOR
https://api.github.com/repos/Leaflet/Leaflet/issues/7563,Fix Bug: permanent & sticky tooltip,Falke-Design,5,872658458,1,872658458,0,0,2021-04-30T14:55:30Z,"Fixes bug: if tooltip is sticky and permanent it was not following the mouse https://github.com/Leaflet/Leaflet/issues/7201#issuecomment-655746354

Demo: https://plnkr.co/edit/dPPR4QQ4rBwVwQH2

Removed from the PR #7406",True,0,MEMBER
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/963032629,Fix Bug: permanent & sticky tooltip,johnd0e,5,872658458,2,963032629,0,872658458,2021-11-08T10:55:14Z,"> Fixes bug: if tooltip is sticky and permanent it was not following the mouse [#7201 (comment)](https://github.com/Leaflet/Leaflet/issues/7201#issuecomment-655746354)

Seems provided link is not relevant here",False,0,COLLABORATOR
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/963034484,Fix Bug: permanent & sticky tooltip,johnd0e,5,872658458,3,963034484,0,963032629,2021-11-08T10:57:55Z,"Please add plunkr to illustrate the issue.
Also, we need unit tests for this.",False,0,COLLABORATOR
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/968260748,Fix Bug: permanent & sticky tooltip,Falke-Design,5,872658458,4,968260748,0,963034484,2021-11-14T10:06:21Z,@johnd0e plunkr and tests added,False,0,MEMBER
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/970475228,Fix Bug: permanent & sticky tooltip,johnd0e,5,872658458,5,970475228,0,968260748,2021-11-16T17:02:46Z,"> Fixes bug: if tooltip is sticky and permanent it was not following the mouse

Just thought: the bug might be fixed easier, by documenting that such option combination is not allowed.

Is there useful case for sticky+permanent, which not looks ugly?",False,0,COLLABORATOR
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/984865049,Fix Bug: permanent & sticky tooltip,mourner,5,872658458,6,984865049,0,970475228,2021-12-02T17:58:52Z,"> Just thought: the bug might be fixed easier, by documenting that such option combination is not allowed.

Easy enough in the current form, so I think it's not a big deal to allow it. Never know how people might make use of it.",False,0,MEMBER
https://api.github.com/repos/Leaflet/Leaflet/issues/7565,Null pointer in Draggable.js,JonatanRydh,9,877792434,1,877792434,0,0,2021-05-06T17:47:52Z,"in Draggable.js

This line:
`var first = e.touches ? e.touches[0] : e,`

will cause a null pointer here:
`this._startPoint = new Point(first.clientX, first.clientY);`

 if e.touches is [] which can happen.

It should probably be changed to:
`var first = (e.touches && e.touches.length === 1 ? e.touches[0] : e),`

as is the case further down in the same class.

I stumbled across this issue since leaflet breaks when dragging if it is in a popout from the flexlayout-react package.",True,0,NONE
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/833762734,Null pointer in Draggable.js,johnd0e,9,877792434,2,833762734,0,877792434,2021-05-06T18:33:34Z,"> if e.touches is [] which can happen.

Under what circumstances?",False,0,COLLABORATOR
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/833767493,Null pointer in Draggable.js,JonatanRydh,9,877792434,3,833767493,0,833762734,2021-05-06T18:40:53Z,"> > if e.touches is [] which can happen.
> 
> Under what circumstances?

I'm not sure what causes that. But it can and does happen at the very least in the scenario I highlighted. (when dragging if it is in a popout from the flexlayout-react package)",False,0,NONE
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/834243673,Null pointer in Draggable.js,JonatanRydh,9,877792434,4,834243673,0,833767493,2021-05-07T10:20:55Z,"Been digging this a bit more. It seems the bigger issue here is that when you open the map in a popout with flexlayout-react, binding events to document doesn't work. The same issue will probably happen for any scenario involving a secondary window and probably iframes. I was able to fix the issues by binding events to `element.ownerDocument` instead of `document` in a couple of places.",False,0,NONE
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/834248712,Null pointer in Draggable.js,JonatanRydh,9,877792434,5,834248712,0,834243673,2021-05-07T10:29:15Z,Related: https://github.com/Leaflet/Leaflet/issues/7376#issue-761125480,False,0,NONE
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/834263977,Null pointer in Draggable.js,johnd0e,9,877792434,6,834263977,0,834248712,2021-05-07T10:53:17Z,"@JonatanRydh 
So may be you will propose PR to fix your issue?

And I still interested why your event object lacks `.clientX`/`Y` properties.
They are mouse properties, not tied to touch https://developer.mozilla.org/en-US/docs/Web/API/MouseEvent/clientX
",False,0,COLLABORATOR
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/834278915,Null pointer in Draggable.js,JonatanRydh,9,877792434,7,834278915,0,834263977,2021-05-07T11:15:01Z,"The event object does have `.clientX` and `.clientY` properties. The issue is that it `e.touches = []` and therefor truthy, making `first undefined` in the line `var first = e.touches ? e.touches[0] : e,` instead of `e`.

I've no idea why `e.touches = []` in the case where leaflet is in a secondary window, but it seems to be the case.

I'm not very familiar with the code so I'm not sure if this should be fixed to 
`var first = (e.touches && e.touches.length === 1 ? e.touches[0] : e),`
or
`var first = (e.touches && e.touches.length > 0 ? e.touches[0] : e),`
or something else.

This change together with `element.ownerDocument` instead of `document` in a couple of places seems to make leaflet work correctly in the popout window.

I think there are at least two ways to solve the second problem. Either an option could be provided to override which document to use, or alternativly  the ownerDocument of the map container for binding events could always be used. The first may be safer to not break backwardcompatibility but the second may fix things automatically in many cases.",False,0,NONE
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/834298726,Null pointer in Draggable.js,johnd0e,9,877792434,8,834298726,0,834278915,2021-05-07T11:43:50Z,"> I've no idea why `e.touches = []` in the case

But you could track it down to the root


> so I'm not sure if this should be fixed to

Neither, as we should fix the cause, not the symptom.

> Either an option could be provided

Not good.

> or alternativly the ownerDocument of the map container for binding events could always be used.

You could change it, make tests, and make sure that all is working as expected.
",False,0,COLLABORATOR
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/834301392,Null pointer in Draggable.js,johnd0e,9,877792434,9,834301392,0,834298726,2021-05-07T11:47:34Z,"> I've no idea why `e.touches = []`

You could try these fixes: #7084 or #7059 or #7029.",False,0,COLLABORATOR
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/876330181,Null pointer in Draggable.js,psimonazzi,9,877792434,10,876330181,0,834301392,2021-07-08T10:38:32Z,"I'm also affected by this issue. `e.touches` is an empty array and the check fails because it does not take into account javascript 'truthiness'.
Admittedly I'm using Leaflet from a GWT script, inside iframes etc. so this may be a corner case, but I would consider fixing this and making the check more robust anyway.
Actually the very same check in the `_onMove` method already checks empty arrays.",False,0,NONE
https://api.github.com/repos/Leaflet/Leaflet/issues/7566,"Error: Invalid LatLng object: (NaN, NaN) with the firefox debugger in the mobile simluator mode",SuperPat45,4,878659180,1,878659180,0,0,2021-05-07T09:24:30Z,"- [X] I've looked at the [documentation](http://leafletjs.com/reference.html) to make sure the behavior is documented and expected
- [X] I'm sure this is a Leaflet code issue, not an issue with my own code nor with the framework I'm using (Cordova, Ionic, Angular, React…)
- [X] I've searched through the issues to make sure it's not yet reported

**Steps to reproduce**
_ Open the firefox debugger in the adaptive view mode
_ Select a mobile device in the list
_ Try to move the map

**Expected behavior**
We should be able to move the map

**Current behavior**
This exception occurs:
> Error: Invalid LatLng object: (NaN, NaN)
>     LatLng leaflet-src.js:1365
>     unproject leaflet-src.js:1667
>     pointToLatLng leaflet-src.js:1506
>     unproject leaflet-src.js:3963
>     _onTouchMove leaflet-src.js:13923
>     handler leaflet-src.js:2669
>     _handlePointer leaflet-src.js:2102
>     onMove leaflet-src.js:2112
>     _addPointerMove leaflet-src.js:2116
>     addPointerListener leaflet-src.js:2030
>     addOne leaflet-src.js:2676
>     on leaflet-src.js:2611
>     _onTouchStart leaflet-src.js:13894
>     handler leaflet-src.js:2669
>     _handlePointer leaflet-src.js:2102
>     onDown leaflet-src.js:2063
>     _addPointerStart leaflet-src.js:2067
>     addPointerListener leaflet-src.js:2027
>     addOne leaflet-src.js:2676
>     on leaflet-src.js:2611
>     addHooks leaflet-src.js:13865
>     enable leaflet-src.js:5707
>     addHandler leaflet-src.js:3707
>     init leaflet-src.js:380
>     callInitHooks leaflet-src.js:352
>     initialize leaflet-src.js:3119
>     NewClass leaflet-src.js:296
>     createMap leaflet-src.js:4691

**Environment**
- Leaflet version: 1.7.1
- Browser (with version): Firefox 88 in mobile simulated mode
- OS/Platform (with version): Windows

**Additional context**
Debuggin my webApp with the firefox debugger in mobile simulation mode throw a lot of exception
After investigation, the problem is the crappy simulated pointerdown event received have two touches with the same coordinate which leaflet does not handle correctly.
Due to this, in the _onTouchMove function, the _startDist variable is equals to 0 and the calculated scale and _zoom is Infinity
This can be fixed easily by changing line:
`scale = p1.distanceTo(p2) / this._startDist;`
to:
`scale = this._startDist !== 0 ? p1.distanceTo(p2) / this._startDist : 1;`

**Minimal example reproducing the issue**
Any page containing a map",True,0,NONE
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/834270888,"Error: Invalid LatLng object: (NaN, NaN) with the firefox debugger in the mobile simluator mode",johnd0e,4,878659180,2,834270888,0,878659180,2021-05-07T11:02:52Z,"What if you disable tap handler?
See map options.
",False,0,COLLABORATOR
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/1018516375,"Error: Invalid LatLng object: (NaN, NaN) with the firefox debugger in the mobile simluator mode",Falke-Design,4,878659180,3,1018516375,0,834270888,2022-01-21T13:43:05Z,"I downloaded FF 88 and tried to reproduce the error but it always worked. I will close this until there is a new confirm that the bug still exists.

I tried it with tab-simulation enabled / disabled, with a selected phone and with a custom one.
![ff_drag_map](https://user-images.githubusercontent.com/19800037/150536876-bd2281ff-c63f-44b9-9619-715d111fa35b.gif)



@SuperPat45 are you still able to reproduce this?",False,0,MEMBER
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/1018711319,"Error: Invalid LatLng object: (NaN, NaN) with the firefox debugger in the mobile simluator mode",SuperPat45,4,878659180,4,1018711319,0,1018516375,2022-01-21T17:23:25Z,"With the last version of Firefox, I can't reproduce it anymore",False,0,NONE
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/1018712296,"Error: Invalid LatLng object: (NaN, NaN) with the firefox debugger in the mobile simluator mode",Falke-Design,4,878659180,5,1018712296,0,1018711319,2022-01-21T17:24:31Z,Thanks for the check and response,False,0,MEMBER
https://api.github.com/repos/Leaflet/Leaflet/issues/7567,"Fix exception Invalid LatLng object: (NaN, NaN) with the firefox debu…",SuperPat45,3,878664037,1,878664037,0,0,2021-05-07T09:28:16Z,"…gger in the mobile simluator mode

Fix a problem with the Firefox debugger in simulated mobile mode who pointerdown event received have two touches with the same coordinate which leaflet does not handle correctly.

Fix bug #7566",True,0,NONE
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/1016328705,"Fix exception Invalid LatLng object: (NaN, NaN) with the firefox debu…",Falke-Design,3,878664037,2,1016328705,0,878664037,2022-01-19T10:57:05Z,@mourner have you closed this? Or is this automatically happened with deleting the master branch? There are many other PRs too,False,0,MEMBER
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/1016338370,"Fix exception Invalid LatLng object: (NaN, NaN) with the firefox debu…",Falke-Design,3,878664037,3,1016338370,0,1016328705,2022-01-19T11:03:55Z,"PRs which are auto-closed:
- #7567 
- #3955 
- #6066 
- #6248 
- #7364 
- #6676 
- #6935

maybe more?",False,0,MEMBER
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/1016347194,"Fix exception Invalid LatLng object: (NaN, NaN) with the firefox debu…",mourner,3,878664037,4,1016347194,0,1016338370,2022-01-19T11:10:52Z,"> Or is this automatically happened with deleting the master branch? There are many other PRs too

Yeah, it appears this happened automatically, I didn't anticipate this. Let's open an issue and track closed PRs we're still interested in.",False,0,MEMBER
https://api.github.com/repos/Leaflet/Leaflet/issues/7568,"Varnish 4.1 + Drupal 7 + Leaflet 1.6 = js with ""*""",denics,5,887343654,1,887343654,0,0,2021-05-11T13:48:37Z,"- [x] I've looked at the [documentation](http://leafletjs.com/reference.html) to make sure the behavior is documented and expected
- [x] I'm sure this is a Leaflet code issue, not an issue with my own code nor with the framework I'm using (Cordova, Ionic, Angular, React…)
- [x] I've searched through the issues to make sure it's not yet reported

**Steps to reproduce**
Steps to reproduce the behavior:
- Install Varnish 4.1, Drupal 7.80, Leafletjs 1.6
- Enable js preprocess in Drupal
- All Leaflet maps are broken

**Expected behavior**
Not preprocessing js in Drupal is very important to optimize site speed and load.

**Current behavior**
Some, very randomly, Lat or Long are replaced by **,******* kind of format which break LeafletJS. However the right values are in the DB. Without varnish, no problem.

**Environment**
- Leaflet version: 1.6 (tested with all version since 1.0.2)
- Browser (with version): browser independent
- OS/Platform (with version): OS independent

**Minimal example reproducing the issue**
You can see the issue here: https://en.unesco.org/countries",True,0,NONE
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/838593745,"Varnish 4.1 + Drupal 7 + Leaflet 1.6 = js with ""*""",IvanSanchez,5,887343654,2,838593745,0,887343654,2021-05-11T14:38:55Z,"The reproducible example (which is **not** minimal) throws an exception around this fragment...

```
Te={R:6378137,R_MINOR:*****************,bounds:new O([-20037508.34279,-15496570.73972],[20037508.34279,18764656.23138]),project:function(t){
```

... which is the minified version of L.Projection.Mercator, as per https://github.com/Leaflet/Leaflet/blob/0f904a515879fcd08f69b7f51799ee7f18f23fd8/src/geo/projection/Projection.Mercator.js#L12-L18

Whatever is minifying the code is causing the issue. Not a Leaflet bug.",False,0,MEMBER
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/838594007,"Varnish 4.1 + Drupal 7 + Leaflet 1.6 = js with ""*""",IvanSanchez,5,887343654,3,838594007,0,838593745,2021-05-11T14:39:06Z,"Hi, and thanks for taking the time to open a bug report in Leaflet.

However, in this repository we only handle bugs in ""[vanilla](http://vanilla-js.com/)"" Leaflet. This means that we do **not** handle bugs which are specific to frameworks such as:
* React
* Ractive
* AngularJS
* Bootstrap
* Leaflet for R
* Joomla
* Wordpress
* Ionic
* Cordova
* Vue
* Electron
* Polymer
* TypeScript
* D3
* Folium
* NativeScript
* ...etc

Please understand that we only have the time and energy to test Leaflet in plain web browsers.

Please try to either reproduce the bug without using any frameworks, or submit a bug to the appropriate repo.",False,0,MEMBER
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/838595130,"Varnish 4.1 + Drupal 7 + Leaflet 1.6 = js with ""*""",IvanSanchez,5,887343654,4,838595130,0,838594007,2021-05-11T14:39:51Z,"Oh, and this is where I go snarky and point at the checkbox next to the ""I'm sure this is a Leaflet code issue, not an issue with my own code nor with the framework I'm using (Cordova, Ionic, Angular, React…)"" bit of text.",False,0,MEMBER
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/838596591,"Varnish 4.1 + Drupal 7 + Leaflet 1.6 = js with ""*""",denics,5,887343654,5,838596591,0,838595130,2021-05-11T14:40:46Z,"Without varnish:
![image](https://user-images.githubusercontent.com/2407163/117833914-059d9d80-b277-11eb-8a39-9118b2dd7336.png)

with varnish:
![image](https://user-images.githubusercontent.com/2407163/117834369-60cf9000-b277-11eb-9996-b816fa0e1028.png)
",False,0,NONE
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/838599279,"Varnish 4.1 + Drupal 7 + Leaflet 1.6 = js with ""*""",denics,5,887343654,6,838599279,0,838596591,2021-05-11T14:42:33Z,"Thank you @IvanSanchez  than you suggest that I should looking in varnish or drupal.
",False,0,NONE
https://api.github.com/repos/Leaflet/Leaflet/issues/7571,Change absolute units(px) to relative units(rem),Chandu-4444,5,891972914,1,891972914,0,0,2021-05-14T14:32:54Z,"Hey, I've changed the units mentioned here #7548 . I'm a beginner, please let me know if anything's wrong.",True,0,CONTRIBUTOR
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/960906568,Change absolute units(px) to relative units(rem),jonkoops,5,891972914,2,960906568,0,891972914,2021-11-04T13:17:54Z,I believe this might actually be a breaking change as the `rem` unit is relative to the font-size of the root element of the page. Since this can be different for each page Leaflet is embedded in this might cause unexpected side-effects.,False,0,COLLABORATOR
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/960993954,Change absolute units(px) to relative units(rem),mourner,5,891972914,3,960993954,0,960906568,2021-11-04T14:00:20Z,"It's also breaking because `rem` has no or partial support in older versions of IE, which we still formally support: https://caniuse.com/rem, so I'll close this for now and revisit once we drop the old IE versions in v2.",False,0,MEMBER
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/961001947,Change absolute units(px) to relative units(rem),jonkoops,5,891972914,4,961001947,0,960993954,2021-11-04T14:04:08Z,I don't believe compatibility with Internet Explorer needs to be a problem as we can provide a [fallback value](https://w3bits.com/rem-fallback/).,False,0,COLLABORATOR
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/975316013,Change absolute units(px) to relative units(rem),mourner,5,891972914,5,975316013,0,961001947,2021-11-22T09:19:46Z,"I tried reopening but it doesn't allow me to, saying that the repo of the PR has been deleted — want to update @Chandu-4444, or submit a new PR if it's not easily possible?",False,0,MEMBER
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/975319300,Change absolute units(px) to relative units(rem),Chandu-4444,5,891972914,6,975319300,0,975316013,2021-11-22T09:23:26Z,"> I tried reopening but it doesn't allow me to, saying that the repo of the PR has been deleted — want to update @Chandu-4444, or submit a new PR if it's not easily possible?

I'll submit a new PR then.",False,0,CONTRIBUTOR
https://api.github.com/repos/Leaflet/Leaflet/issues/7575,Tiles won't load while dragging map,pupvogel,7,896467123,1,896467123,0,0,2021-05-20T08:19:36Z,"When dragging any Leaflet-map out of the ""preloaded tile-zone"", missing tiles will not load until user lifts finger (on iPhone or iPad, currently iOS 14.5.1, using Safari).

**Expected behavior**
Missing tiles load while user is still dragging the map (works in other configurations or Google Maps or newer versions of OpenLayers)

**Current behavior**
they don't 8o)

**Environment**
- Leaflet version: 1.7.1 (and earlier)
- Browser (with version): Safari
- OS/Platform (with version): iOS 14.5.1 (and earlier)

**Additional context**
none

**Minimal example reproducing the issue**
Can be reproduced with *any* Leaflet-map, just drag the map far enough until new tiles need to be fetched

Please create an example using https://leafletjs.com/edit.html or any other jsfiddle-like site.
https://jsfiddle.net/f85gp2j0/5/show

- [x] this example is as simple as possible
- [x] this example does not rely on any third party code
",True,0,NONE
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/854847077,Tiles won't load while dragging map,pupvogel,7,896467123,2,854847077,0,896467123,2021-06-04T16:16:52Z,Same problem in Chrome on iOS. ,False,0,NONE
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/1030611200,Tiles won't load while dragging map,Malvoz,7,896467123,3,1030611200,0,854847077,2022-02-05T12:15:06Z,"Also reproducible on Android 12 (Chrome 97.0.4692.98):

https://user-images.githubusercontent.com/26493779/152641279-82cd2d02-620e-4928-a52d-748a77d92587.mp4
",False,0,MEMBER
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/1030621563,Tiles won't load while dragging map,Falke-Design,7,896467123,4,1030621563,0,1030611200,2022-02-05T13:05:29Z,"@Malvoz the video is not loading.

![grafik](https://user-images.githubusercontent.com/19800037/152643320-85f844aa-005f-48a3-b4d8-4e90bfce0304.png)
",False,0,MEMBER
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/1030621832,Tiles won't load while dragging map,Malvoz,7,896467123,5,1030621832,0,1030621563,2022-02-05T13:07:08Z,"@Falke-Design I get the same behavior in Firefox, strange. Do you have Chrome installed?",False,0,MEMBER
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/1030621937,Tiles won't load while dragging map,Falke-Design,7,896467123,6,1030621937,0,1030621832,2022-02-05T13:07:51Z,"ui, working in Chrome 🤯",False,0,MEMBER
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/1030669112,Tiles won't load while dragging map,mourner,7,896467123,7,1030669112,0,1030621937,2022-02-05T17:53:07Z,"I vaguely remember this being done intentionally for performance considerations many years ago, but perhaps it's not relevant anymore — needs checking out.",False,0,MEMBER
https://api.github.com/repos/Leaflet/Leaflet/issues/comments/1030685458,Tiles won't load while dragging map,IvanSanchez,7,896467123,8,1030685458,0,1030669112,2022-02-05T19:29:21Z,"It's Not A Bug, It's A Feature™

https://github.com/Leaflet/Leaflet/blob/48a38c797b19cefb28002f7d09199d947260106a/src/layer/tile/GridLayer.js#L88-L93

I agree with @mourner - perhaps it's time to revisit the default setting of that.
",False,0,MEMBER
https://api.github.com/repos/frappe/frappe/issues/13545,DateTime displayed incorrectly after save,p-andreas,7,926899171,1,926899171,0,0,2021-05-25T13:36:13Z,"**Description:**

After updating my erpnext installtion from v12 to v13 I noticed that the DateTime in the Timesheet was displayed incorrectly.

When I choose the DateTime both the date and the time are displayed correctly. However as soon as I save the time part of the date time is displayed like ""2021-05-25 un22fin22"". 
This also happens when I click save and navigate back to the document later.

**Steps to Reproduce:**

1. Create new Timesheet 
2. Add an Activity, select the start time, add the duration
3. click save

Now the date time of the activity is displayed incorrectly.


**Version Number:** 
Helm Version: 3.1.10 which is v13.3.1 (version-13)
However I noticed this behaviour as soon as I updated from version 12 to 13.



Screenshots: 

![datetime error](https://user-images.githubusercontent.com/13085073/119507131-d9057d80-bd6e-11eb-98ae-394195a46d77.png)

https://user-images.githubusercontent.com/13085073/119507186-e458a900-bd6e-11eb-8d8e-2f6ed69daffd.mp4

",True,0,NONE
https://api.github.com/repos/frappe/frappe/issues/comments/856696645,DateTime displayed incorrectly after save,p-andreas,7,926899171,2,856696645,0,926899171,2021-06-08T11:51:13Z,"Hi guys,

can you please let me know if you can reproduce this issue and when the issue will be fixed?

Best regards,",False,0,NONE
https://api.github.com/repos/frappe/frappe/issues/comments/856701979,DateTime displayed incorrectly after save,ankush,7,926899171,3,856701979,0,856696645,2021-06-08T11:59:24Z,"I can't reproduce this on my system but I've seen a similar error before. Can you tell me what's system language?

Seems to be related to issues with parsing dates. `undefined` ~ `un22fin22`",False,0,MEMBER
https://api.github.com/repos/frappe/frappe/issues/comments/857466434,DateTime displayed incorrectly after save,p-andreas,7,926899171,4,857466434,0,856701979,2021-06-09T07:42:20Z,"Hi, thanks for looking into this.

My Browser Language is as follows:

> Your browser's Accept-Language header:
> en-US,en;q=0.9,de;q=0.8

My ERP-Next User is set to the following settings:

![image](https://user-images.githubusercontent.com/13085073/121313605-d8d8b680-c906-11eb-8967-99b5e007cbcf.png)


The ERP-Next System settings are configured like this:

![image](https://user-images.githubusercontent.com/13085073/121313711-f279fe00-c906-11eb-8054-12414445eeee.png)


Best regards,


",False,0,NONE
https://api.github.com/repos/frappe/frappe/issues/comments/857473186,DateTime displayed incorrectly after save,p-andreas,7,926899171,5,857473186,0,857466434,2021-06-09T07:52:45Z,"Ad: My colleague also has the same issue. His user language settings are all set to ""de"", his browser is also set to ""de"" and his operating system is set to ""de"" as well.",False,0,NONE
https://api.github.com/repos/frappe/frappe/issues/comments/865638881,DateTime displayed incorrectly after save,p-andreas,7,926899171,6,865638881,0,857473186,2021-06-22T06:35:19Z,"any new updates on this?

I have checked both the chrome console for errors and the logs of the erpnext instance. However none of them displayed any errors.

Can you point me into the right direction as I might be able to fix this issue myself?


EDIT: I just checked the XHR calls and noticed that the the `time_logs` which contain the `Timesheet details`  have the following json ` from_time: ""2021-06-14 09:00:00""`. However the creation and timestamps look something like this `""2021-06-14 11:55:06.955353""`. Maybe because the `from_time` is missing the millisecond part?",False,0,NONE
https://api.github.com/repos/frappe/frappe/issues/comments/865651804,DateTime displayed incorrectly after save,ankush,7,926899171,7,865651804,0,865638881,2021-06-22T06:59:11Z,"Yeah, I guess it should get fixed with this PR. https://github.com/frappe/frappe/pull/13532 

Moving to issue to FF. @shariquerik can confirm.",False,0,MEMBER
https://api.github.com/repos/frappe/frappe/issues/comments/984308368,DateTime displayed incorrectly after save,ankush,7,926899171,8,984308368,0,865651804,2021-12-02T05:34:11Z,closed by https://github.com/frappe/frappe/pull/15150 ,False,0,MEMBER
https://api.github.com/repos/frappe/erpnext/issues/25837,feat: fetching of qty as per received qty from PR to PI,AfshanKhan,6,901193101,1,901193101,0,0,2021-05-25T18:26:24Z,"### Added a checkbox **""Consider Rejected Quantity For Purchase Invoice""** in Buying Settings.
![Screenshot 2021-05-25 at 11 32 47 PM](https://user-images.githubusercontent.com/33727827/119548295-b053a700-bdb3-11eb-8655-a09996bfc0a9.png)

### Purpose
Consider following Purchase Receipt.
![Screenshot 2021-05-25 at 11 34 58 PM](https://user-images.githubusercontent.com/33727827/119548540-f01a8e80-bdb3-11eb-876c-ae16b4f42d0b.png)

When the checkbox is checked the _Purchase Invoice from the above Purchase Receipt_ will consider **Received Qty** as **Accepted Qty** for **Total Qty**.
![Screenshot 2021-05-25 at 11 37 17 PM](https://user-images.githubusercontent.com/33727827/119548748-27893b00-bdb4-11eb-9909-d15f74c042c0.png)

When the checkbox is not checked the _Purchase Invoice from the above Purchase Receipt_ will consider **Accepted Qty** as **Accepted Qty** for **Total Qty**.
![Screenshot 2021-05-25 at 11 36 13 PM](https://user-images.githubusercontent.com/33727827/119548793-353ec080-bdb4-11eb-91a5-caacc2c75e27.png)


Documentation PR: https://github.com/frappe/erpnext_documentation/pull/355",True,0,CONTRIBUTOR
https://api.github.com/repos/frappe/erpnext/issues/comments/848938973,feat: fetching of qty as per received qty from PR to PI,coveralls,6,901193101,2,848938973,0,901193101,2021-05-26T16:46:22Z,"
[![Coverage Status](https://coveralls.io/builds/40817514/badge)](https://coveralls.io/builds/40817514)

Coverage decreased (-0.04%) to 42.758% when pulling **e1dcfef4b99efdf651b253ee05b2f03ee4529e52 on AfshanKhan:consider-rejected-quantity-for-purchase-invoice** into **da66cefefc9c5f249c78f7ecf04e9a11719d8fcf on frappe:develop**.
",False,0,NONE
https://api.github.com/repos/frappe/erpnext/issues/comments/862217336,feat: fetching of qty as per received qty from PR to PI,nextchamp-saqib,6,901193101,3,862217336,0,848938973,2021-06-16T09:48:55Z,"Unhandled case,
- Purchase Receipt of 10 received qty, 2 rejected qty
- Create Purchase Invoice with 5 accepted qty
- Create another Invoice it will fetch accepted qty as 10, instead, it should have been 5

You can check the previous behaviour by unchecking the `consider_rejected_quantity_for_purchase_invoice` checkbox",False,0,MEMBER
https://api.github.com/repos/frappe/erpnext/issues/comments/863170586,feat: fetching of qty as per received qty from PR to PI,AfshanKhan,6,901193101,4,863170586,0,862217336,2021-06-17T11:46:21Z,"> Unhandled case,
> 
> * Purchase Receipt of 10 received qty, 2 rejected qty
> * Create Purchase Invoice with 5 accepted qty
> * Create another Invoice it will fetch accepted qty as 10, instead, it should have been 5
> 
> You can check the previous behaviour by unchecking the `consider_rejected_quantity_for_purchase_invoice` checkbox

Added the fix for this",False,0,CONTRIBUTOR
https://api.github.com/repos/frappe/erpnext/issues/comments/864894686,feat: fetching of qty as per received qty from PR to PI,nextchamp-saqib,6,901193101,5,864894686,0,863170586,2021-06-21T09:46:10Z,"Another Case to fix:

- Purchase Receipt created for 10 received qty, 8 accepted qty, 2 rejected qty
- Trying to create a return using Create -> Purchase Return button, change received qty to -4, and accepted qty to -4, then saved & submit the return
- Now create an Invoice against the original receipt, the qty is fetched as 10 and the invoice can be submitted too. 
- If you submit the invoice, the billed amount is for 10 qty while it shouldn't have been possible to bill amount more than 10 - returned qty = 6 qty

P.S: This case is handled if `consider_rejected_quantity_for_purchase_invoice` is unchecked",False,0,MEMBER
https://api.github.com/repos/frappe/erpnext/issues/comments/865916447,feat: fetching of qty as per received qty from PR to PI,AfshanKhan,6,901193101,6,865916447,0,864894686,2021-06-22T11:51:10Z,"> Another Case to fix:
> 
> * Purchase Receipt created for 10 received qty, 8 accepted qty, 2 rejected qty
> * Trying to create a return using Create -> Purchase Return button, change received qty to -4, and accepted qty to -4, then saved & submit the return
> * Now create an Invoice against the original receipt, the qty is fetched as 10 and the invoice can be submitted too.
> * If you submit the invoice, the billed amount is for 10 qty while it shouldn't have been possible to bill amount more than 10 - returned qty = 6 qty
> 
> P.S: This case is handled if `consider_rejected_quantity_for_purchase_invoice` is unchecked

Fixed",False,0,CONTRIBUTOR
https://api.github.com/repos/frappe/erpnext/issues/comments/867328704,feat: fetching of qty as per received qty from PR to PI,nextchamp-saqib,6,901193101,7,867328704,0,865916447,2021-06-24T04:39:48Z,@AfshanKhan You can backport now on `version-13-hotfix`,False,0,MEMBER
https://api.github.com/repos/frappe/erpnext/issues/25846,Bug in merge two items in version 13.3,me2ne,5,902432450,1,902432450,0,0,2021-05-26T13:55:53Z,"Hi
There is a bug in merge item in v13.3 , for example we have 2 pcs of item A in stock and no stock for item B . if we merge item B with item A after merge when we open item B in stock level doesn’t show that 2 pcs and in stock level show “No Stock Available Currently”.
but when we open stock balance show 2 pcs of item B available .
i checked in 2 different site and it was same problem .
Regards

",True,0,NONE
https://api.github.com/repos/frappe/erpnext/issues/comments/1171388909,Bug in merge two items in version 13.3,mro-admin,5,902432450,2,1171388909,0,902432450,2022-06-30T15:52:27Z,"Can confirm this is still happening on 
ERPNext: v13.34.1 
Frappe Framework: v13.33.1 

Seems like it is an issue with the dashboard for the item. ",False,0,NONE
https://api.github.com/repos/frappe/erpnext/issues/comments/1325492780,Bug in merge two items in version 13.3,dj12djdjs,5,902432450,3,1325492780,0,1171388909,2022-11-23T18:27:57Z,"Steps to reproduce.

1. Create Items: (Item A, Item B)
2. Create New Stock Entry of Material Receipt
     2pc Item A to Stores - DC
     2pc Item B to Stores - DC
3. Merge Item B into Item A

Observed: Balance qty shows only 2.00
Expected: Balance qty should be 4.00
![image](https://user-images.githubusercontent.com/29856401/203621400-f16a31d7-4e8c-493c-9ae6-658e2815e537.png)


Item A stock levels show nothing
![image](https://user-images.githubusercontent.com/29856401/203621586-b59739fa-29cb-4f19-83c1-3e50c9c7488f.png)



",False,0,MEMBER
https://api.github.com/repos/frappe/erpnext/issues/comments/1325648126,Bug in merge two items in version 13.3,dj12djdjs,5,902432450,4,1325648126,0,1325492780,2022-11-23T20:55:38Z,"Additional information:

Once Repost Item Valuation is completed, the stock level shows correctly.

This is unclear at first because I thought Repost Item Valuation is just handling costing.",False,0,MEMBER
https://api.github.com/repos/frappe/erpnext/issues/comments/1440395875,Bug in merge two items in version 13.3,sabgaby,5,902432450,5,1440395875,0,1325648126,2023-02-22T16:42:07Z,"@dj12djdjs How did you do the ""Repost Item Valuation"". I am having the same issue with merging items. I am pretty new at ERPnext so we are still familiarizing ourselves with it.",False,0,NONE
https://api.github.com/repos/frappe/erpnext/issues/comments/1441095873,Bug in merge two items in version 13.3,dj12djdjs,5,902432450,6,1441095873,0,1440395875,2023-02-23T01:06:36Z,"@sabgaby if I remember correctly after merging the item, the system will automatically create the Repost Item Valuation. 

Depending on how your scheduler is set up this could take some time. 

Did you check the Repost Item Valuation list if the item you merged exists there around the time of the merge?",False,0,MEMBER
https://api.github.com/repos/frappe/erpnext/issues/25848,Bug: Renamed documents revert to Doctype default name on save - v13.2.0,dawoodjee,4,903398009,1,903398009,0,0,2021-05-13T06:21:40Z,"I'm convinced this is a bug

![rename_err](https://user-images.githubusercontent.com/7912989/118086383-2e7f7900-b3c4-11eb-8a9c-f969789b39ef.gif)
",True,0,CONTRIBUTOR
https://api.github.com/repos/frappe/erpnext/issues/comments/844713590,Bug: Renamed documents revert to Doctype default name on save - v13.2.0,hasnain2808,4,903398009,2,844713590,0,903398009,2021-05-20T05:38:28Z,"Not able to replicate the issue, Please try again. reopen the issue with more details if the problem persists.

![rename_doc](https://user-images.githubusercontent.com/28212972/118925040-a1a46480-b95b-11eb-9c04-3f0326532dcc.gif)
",False,0,CONTRIBUTOR
https://api.github.com/repos/frappe/erpnext/issues/comments/849374489,Bug: Renamed documents revert to Doctype default name on save - v13.2.0,dawoodjee,4,903398009,3,849374489,0,844713590,2021-05-27T06:44:22Z,You're not able to replicate because you just renamed. Try changing other details after rename and save,False,0,CONTRIBUTOR
https://api.github.com/repos/frappe/erpnext/issues/comments/849442737,Bug: Renamed documents revert to Doctype default name on save - v13.2.0,hasnain2808,4,903398009,4,849442737,0,849374489,2021-05-27T08:26:38Z,"> You're not able to replicate because you just renamed. Try changing other details after rename and save

It was out of the gif so it wasn't visible

Moreover on validate the lead doctype manually sets the title field(there is a fieldname called title) as the person name hence it is getting changed, looks like it is by design in the CRM
![image](https://user-images.githubusercontent.com/28212972/119792233-27dc2000-bef3-11eb-9d38-7634c2c7d4c5.png)


",False,0,CONTRIBUTOR
https://api.github.com/repos/frappe/erpnext/issues/comments/850927560,Bug: Renamed documents revert to Doctype default name on save - v13.2.0,dawoodjee,4,903398009,5,850927560,0,849442737,2021-05-30T02:06:25Z,Sorry about that. I hope we'll can amend this issue. Otherwise rename doesn't make sense,False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/85760,Possible errors when accessing file metadata are platform specific,ChrisDenton,7,904059471,1,904059471,0,0,2021-05-27T18:23:04Z,"In particular the `is_dir`, `is_file` and `exists` functions suggests that querying a file requires querying the directory. On Windows this is not normally true.

r? @m-ou-se ",True,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/849848429,Possible errors when accessing file metadata are platform specific,m-ou-se,7,904059471,2,849848429,0,904059471,2021-05-27T18:29:04Z,"Are you saying that on windows you can always query the metadata of *any* file, regardless of the permissions you have to any of the directories it is in? That sounds wrong.",False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/849854510,Possible errors when accessing file metadata are platform specific,ChrisDenton,7,904059471,3,849854510,0,849848429,2021-05-27T18:39:11Z,Yes that's what I'm saying. On Windows permissions are based on the file only. There is a setting to do [traverse-checking](https://docs.microsoft.com/en-us/windows/security/threat-protection/security-policy-settings/bypass-traverse-checking#potential-impact) but doing so would likely break things. Both the OS and Windows software would not expect this behaviour.,False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/849860360,Possible errors when accessing file metadata are platform specific,ChrisDenton,7,904059471,4,849860360,0,849854510,2021-05-27T18:49:12Z,"I'm trying to find a good explanatory article but in most of what I can find it's taken as a given. Perhaps this (scroll to ""Traverse Folder/Execute File""): https://www.techrepublic.com/article/windows-101-know-the-basics-about-ntfs-permissions/",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/849899020,Possible errors when accessing file metadata are platform specific,m-ou-se,7,904059471,5,849899020,0,849860360,2021-05-27T19:54:14Z,"The ""access the file"" wording is also not accurate, since you can read the metadata of a file even without having any (read/write) access to it.

Maybe instead of adding platform-specific notes here, it could just say:
```
    /// If you cannot access the metadata of the file, e.g. because of a
    /// permission error or broken symbolic links, this will return `false`.
```",False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/849939574,Possible errors when accessing file metadata are platform specific,ChrisDenton,7,904059471,6,849939574,0,849899020,2021-05-27T21:03:07Z,"I was slightly concerned about removing an explicitly documented situation in case it was documented for a good reason. But looking back at [the commit that added it](https://github.com/rust-lang/rust/pull/42926) it seems the intent was only to document what happens on error without being too specific about implementation details.

So I agree that the simpler wording is much clearer. I'll push the revised wording.",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/855252022,Possible errors when accessing file metadata are platform specific,m-ou-se,7,904059471,7,855252022,0,849939574,2021-06-05T14:59:22Z,"Thanks!

@bors r+ rollup",False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/855252025,Possible errors when accessing file metadata are platform specific,bors,7,904059471,8,855252025,0,855252022,2021-06-05T14:59:24Z,":pushpin: Commit 536d98238c8d1e63c316708d082bce063f1c3f84 has been approved by `m-ou-se`

<!-- @bors r=m-ou-se 536d98238c8d1e63c316708d082bce063f1c3f84 -->
<!-- homu: {""type"":""Approved"",""sha"":""536d98238c8d1e63c316708d082bce063f1c3f84"",""approver"":""m-ou-se""} -->",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/85762,Do not try to build LLVM with Zlib on Windows,mati865,10,904202634,1,904202634,0,0,2021-05-27T21:21:45Z,"Fixes https://github.com/rust-lang/rust/issues/85422
Fixes https://github.com/rust-lang/rust/issues/85624

We do not install Zlib on the CI but recent builds somehow started picking it's shared version.
To avoid relying on CI binaries so let's explicitly disable it.",True,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/849950792,Do not try to build LLVM with Zlib on Windows,rust-highfive,10,904202634,2,849950792,0,904202634,2021-05-27T21:21:48Z,"r? @Mark-Simulacrum

(rust-highfive has picked a reviewer for you, use r? to override)",False,0,COLLABORATOR
https://api.github.com/repos/rust-lang/rust/issues/comments/849950908,Do not try to build LLVM with Zlib on Windows,mati865,10,904202634,3,849950908,0,849950792,2021-05-27T21:22:02Z,"This is untested, can I have `@bors try` please?",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/849952959,Do not try to build LLVM with Zlib on Windows,tmiasko,10,904202634,4,849952959,0,849950908,2021-05-27T21:25:55Z,@bors try,False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/849953025,Do not try to build LLVM with Zlib on Windows,bors,10,904202634,5,849953025,0,849952959,2021-05-27T21:26:04Z,":hourglass: Trying commit 0100e7ed0e8ce6f751a48a480d1ac6e5b99eafc4 with merge f0c2c0aa6ba5b8eceb6adf9bd81195452e550cc1...
<!-- homu: {""type"":""TryBuildStarted"",""head_sha"":""0100e7ed0e8ce6f751a48a480d1ac6e5b99eafc4"",""merge_sha"":""f0c2c0aa6ba5b8eceb6adf9bd81195452e550cc1""} -->",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/849986134,Do not try to build LLVM with Zlib on Windows,bors,10,904202634,6,849986134,0,849953025,2021-05-27T22:37:02Z,":sunny: Try build successful - [checks-actions](https://github.com/rust-lang-ci/rust/runs/2689514590)
Build commit: f0c2c0aa6ba5b8eceb6adf9bd81195452e550cc1 (`f0c2c0aa6ba5b8eceb6adf9bd81195452e550cc1`)
<!-- homu: {""type"":""TryBuildCompleted"",""builders"":{""checks-actions"":""https://github.com/rust-lang-ci/rust/runs/2689514590""},""merge_sha"":""f0c2c0aa6ba5b8eceb6adf9bd81195452e550cc1""} -->",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/850023786,Do not try to build LLVM with Zlib on Windows,mati865,10,904202634,7,850023786,0,849986134,2021-05-28T00:15:35Z,"Okay this worked:
```
$ ntldd /c/Users/mateusz/.rustup/toolchains/f0c2c0aa6ba5b8eceb6adf9bd81195452e550cc1/lib/rustlib/x86_64-pc-windows-gnu/bin/rust-lld.exe
        ADVAPI32.dll => C:\Windows\SYSTEM32\ADVAPI32.dll (0x0000018861b80000)
        libgcc_s_seh-1.dll => D:\msys64\mingw64\bin\libgcc_s_seh-1.dll (0x0000018861960000)
        KERNEL32.dll => C:\Windows\SYSTEM32\KERNEL32.dll (0x0000018868b00000)
        msvcrt.dll => C:\Windows\SYSTEM32\msvcrt.dll (0x0000018868b00000)
        ole32.dll => C:\Windows\SYSTEM32\ole32.dll (0x0000018868b00000)
        libwinpthread-1.dll => D:\msys64\mingw64\bin\libwinpthread-1.dll (0x0000018861980000)
        SHELL32.dll => C:\Windows\SYSTEM32\SHELL32.dll (0x0000018868f90000)

$ /c/Users/mateusz/.rustup/toolchains/f0c2c0aa6ba5b8eceb6adf9bd81195452e550cc1/lib/rustlib/x86_64-pc-windows-gnu/bin/rust-lld -v
lld is a generic driver.
Invoke ld.lld (Unix), ld64.lld (macOS), lld-link (Windows), wasm-ld (WebAssembly) instead
```

For the completeness this is nightly (the error is misleading):
```
$ ntldd /c/Users/mateusz/.rustup/toolchains/nightly-x86_64-pc-windows-gnu/lib/rustlib/x86_64-pc-windows-gnu/bin/rust-lld.exe
        zlib1__.dll => not found
        ADVAPI32.dll => C:\Windows\SYSTEM32\ADVAPI32.dll (0x00000184c2800000)
        libgcc_s_seh-1.dll => D:\msys64\mingw64\bin\libgcc_s_seh-1.dll (0x00000184bb8d0000)
        KERNEL32.dll => C:\Windows\SYSTEM32\KERNEL32.dll (0x00000184c28b0000)
        msvcrt.dll => C:\Windows\SYSTEM32\msvcrt.dll (0x00000184c28b0000)
        ole32.dll => C:\Windows\SYSTEM32\ole32.dll (0x00000184c2800000)
        libwinpthread-1.dll => D:\msys64\mingw64\bin\libwinpthread-1.dll (0x00000184bb8f0000)
        SHELL32.dll => C:\Windows\SYSTEM32\SHELL32.dll (0x00000184c2d30000)

$ /c/Users/mateusz/.rustup/toolchains/nightly-x86_64-pc-windows-gnu/lib/rustlib/x86_64-pc-windows-gnu/bin/rust-lld
C:/Users/mateusz/.rustup/toolchains/nightly-x86_64-pc-windows-gnu/lib/rustlib/x86_64-pc-windows-gnu/bin/rust-lld.exe: error while loading shared libraries: libwinpthread-1.dll: cannot open shared object file: No such file or directory
```",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/850565462,Do not try to build LLVM with Zlib on Windows,nagisa,10,904202634,8,850565462,0,850023786,2021-05-28T17:29:33Z,cc @rylev ,False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/850900874,Do not try to build LLVM with Zlib on Windows,Mark-Simulacrum,10,904202634,9,850900874,0,850565462,2021-05-29T21:23:15Z,"Hmm... I'm worried that in the long run this may not be the right fix, in the sense that we should either link in zlib statically or otherwise avoid this. For now it seems OK though. @bors r+",False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/850900878,Do not try to build LLVM with Zlib on Windows,bors,10,904202634,10,850900878,0,850900874,2021-05-29T21:23:17Z,":pushpin: Commit 53bf79e11c136d8e177ad83cfab371af43100b4f has been approved by `Mark-Simulacrum`

<!-- @bors r=Mark-Simulacrum 53bf79e11c136d8e177ad83cfab371af43100b4f -->
<!-- homu: {""type"":""Approved"",""sha"":""53bf79e11c136d8e177ad83cfab371af43100b4f"",""approver"":""Mark-Simulacrum""} -->",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/850923303,Do not try to build LLVM with Zlib on Windows,mati865,10,904202634,11,850923303,0,850900878,2021-05-30T01:18:19Z,The problem with Windows CI is it doesn't use Docker like Linux so building Zlib will slow down everything. Unless we use prebuilt Zlib from MSYS2 which we never did so far.,False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/85763,rustdoc doesn't include all text that cross attribute type boundaries in the summary,Nemo157,3,904220542,1,904220542,0,0,2021-05-27T21:37:38Z,"I tried this code:

```rust
#[doc = "" Some text""]
#[doc = "" that should""]
/// be concatenated.
pub fn main() {
    println!(""Hello, world!"");
}
```

I expected to see this happen: The entire first paragraph is used as the summary for the function in the module docs: ""Some text that should be concatenated""

Instead, this happened: Only the unsugared doc attributes are used: ""Some text that should""

![image](https://user-images.githubusercontent.com/81079/119900107-56ceb200-bf44-11eb-81fb-534a700d1163.png)

![image](https://user-images.githubusercontent.com/81079/119900125-5c2bfc80-bf44-11eb-997a-7e1586cd17a0.png)


### Meta
`rustc --version --verbose`:
```
rustc 1.54.0-nightly (4e3e6db01 2021-05-18)
binary: rustc
commit-hash: 4e3e6db011c5b482d2bef8ba02274657f93b5e0d
commit-date: 2021-05-18
host: x86_64-unknown-linux-gnu
release: 1.54.0-nightly
LLVM version: 12.0.1
```",True,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/858301309,rustdoc doesn't include all text that cross attribute type boundaries in the summary,ben0x539,3,904220542,2,858301309,0,904220542,2021-06-10T05:02:05Z,"This seems to be achieved here: https://github.com/rust-lang/rust/blob/1639a16ebfaad2aa74fd535c778fd1614475b53d/src/librustdoc/clean/types.rs#L1060 (probably from #80261?)

We're concatenating the text from doc attrs here, but only until we find one of a different kind. Seems intentional enough but I don't know what it's for.

To me naively it only makes sense to concatenate single-line doc comments to generate the summary; with either multiline doc comments or explicit attrs I would expect that where they end is a good place to end the summary.",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/comments/858406920,rustdoc doesn't include all text that cross attribute type boundaries in the summary,Nemo157,3,904220542,3,858406920,0,858301309,2021-06-10T08:05:09Z,"My usecase is dynamically generating some words in the first sentence based on `cfg`. I don't see any reason that rustdoc should distinguish between attribute types here, it has markdown's concept of a _paragraph_ to determine how much to look at for the summary, there's no need to limit how users can construct that first paragraph.",False,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/859972213,rustdoc doesn't include all text that cross attribute type boundaries in the summary,ben0x539,3,904220542,4,859972213,0,858406920,2021-06-12T00:50:49Z,"Right, that's a compelling use case for sure! My take was ""separate attributes are probably intended as separate paragraphs"", but I didn't consider that you'd dynamically construct the set of attributes. I'm curious if that was the original motivation for the `kind` comparison or if it's needed for another reason.",False,0,CONTRIBUTOR
https://api.github.com/repos/rust-lang/rust/issues/85764,Implement coherence checks for negative trait impls,yaahc,8,904246849,1,904246849,0,0,2021-05-27T21:57:14Z,"## Motivation

This change is needed as part of https://github.com/rust-lang/project-error-handling/issues/3. We need to be able to define `From<&str> for Box<dyn Error>` in order to maintain our existing stable APIs but moving the `Error` trait upstream of this implementation introduces a future incompatibility error. `rustc` can't tell that future incompatibility is meaningless between `core` and `std` nor that we never intend to implement `Error` for `&str`. Adjusting the coherence rules to consider negative trait impls lets us add `impl !Error for &str` to `core` to make an API guarantee that we will never implement `Error` for `&str` and let's us implement the previously mentioned `From` impl without getting errors of it potentially overlapping with `From<E> for Box<dyn Error> where E: Error`.

## Alternatives Considered

* Design and Implement a feature for wider coherence boundaries that allows multiple crates to be treated like one crate for coherence purposes then use this feature on `core` and `alloc`
  * This feels like a substantial amount of work and I don't even have confidence I could come up with something and get it through the RFC process in a reasonable amount of time.
* Add a special case exception for the future incompatibility error which ignores it when the crates involved are part of the rust distribution and thus versioned in lockstep.
  * Sounds icky, not confident people would even want this in the compiler, feels like a low budget version of the wider coherence feature

## Current Status

_these notes are as much for myself as for anyone else, and are just recording the state as of the last time I paused for the day on this PR_

Recent convo: https://rust-lang.zulipchat.com/#narrow/stream/144729-wg-traits/topic/negative.20impls.20in.20coherence

I met up with niko to talk about the approach a bit and we sketched out how we'd implement this in `rustc`:

* add a new kind of predicate that is `T: !Trait`
    * or extend the existing predicate with a polarity
* teach the trait checker to prove `T: !Trait` if there are negative impls
  * update `overlap_with_probe` to check for negation before checking for overlap

```rust
.find(|o| {
    if let Some(o_neg) = negate_obligation(o) {
        // given o = `T: Trait` this produces `T: !Trait`
        if selcx.predicate_must_hold(o_neg) {
            // we can prove `T: !Trait` is true based on the impls we see
            return true;
        }
    }
    !selcx.predicate_may_hold_fatal(o)
})
```

Still figuring out what the second step means for now. ",True,0,MEMBER
https://api.github.com/repos/rust-lang/rust/issues/comments/849968249,Implement coherence checks for negative trait impls,rust-highfive,8,904246849,2,849968249,0,904246849,2021-05-27T21:57:17Z,"r? @jackh726

(rust-highfive has picked a reviewer for you, use r? to override)",False,0,COLLABORATOR
https://api.github.com/repos/rust-lang/rust/issues/comments/849972370,Implement coherence checks for negative trait impls,rust-log-analyzer,8,904246849,3,849972370,0,849968249,2021-05-27T22:05:08Z,"
The job **`x86_64-gnu-llvm-10`** failed! Check out the build log: [(web)](https://github.com/rust-lang/rust/runs/2689273279) [(plain)](https://github.com/rust-lang/rust/commit/2be9af737221f2a2de3306e3d0445acce0dc2422/checks/2689273279/logs)

<details><summary><i>Click to see the possible cause of the failure (guessed by this bot)</i></summary>

```plain
   Compiling alloc v0.0.0 (/checkout/library/alloc)
   Compiling cfg-if v0.1.10
   Compiling adler v0.2.3
   Compiling rustc-demangle v0.1.18
error: internal compiler error: compiler/rustc_metadata/src/rmeta/decoder.rs:937:18: impossible case reached
thread 'rustc' panicked at 'Box<Any>', /checkout/library/std/src/panic.rs:59:5
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace

note: the compiler unexpectedly panicked. this is a bug.
note: the compiler unexpectedly panicked. this is a bug.

note: we would appreciate a bug report: https://github.com/rust-lang/rust/issues/new?labels=C-bug%2C+I-ICE%2C+T-compiler&template=ice.md

note: rustc 1.54.0-nightly (fc4158791 2021-05-27) running on x86_64-unknown-linux-gnu

note: compiler flags: -Z macro-backtrace -Z binary-dep-depinfo -Z force-unstable-if-unmarked -C opt-level=3 -C embed-bitcode=no -C codegen-units=1 -C debuginfo=0 -C debug-assertions=on -C overflow-checks=off -C link-args=-Wl,-rpath,$ORIGIN/../lib -C prefer-dynamic -C llvm-args=-import-instr-limit=10 -C embed-bitcode=yes --crate-type lib
note: some of the compiler flags provided by cargo are hidden

query stack during panic:
query stack during panic:
#0 [impl_polarity] computing implementation polarity of `core::convert::Into`
#1 [specialization_graph_of] building specialization graph of trait `core::convert::TryFrom`
error: aborting due to previous error

error: could not compile `alloc`

```

</details>
        ",False,0,COLLABORATOR
https://api.github.com/repos/rust-lang/rust/issues/comments/850010106,Implement coherence checks for negative trait impls,rust-log-analyzer,8,904246849,4,850010106,0,849972370,2021-05-27T23:38:47Z,"
The job **`x86_64-gnu-llvm-10`** failed! Check out the build log: [(web)](https://github.com/rust-lang/rust/runs/2689799281) [(plain)](https://github.com/rust-lang/rust/commit/5e84e4da0dbb7be8584f1c42e1a8e6c3baa503ee/checks/2689799281/logs)

<details><summary><i>Click to see the possible cause of the failure (guessed by this bot)</i></summary>

```plain
   Compiling thread_local v1.0.1
   Compiling sharded-slab v0.1.1
   Compiling itertools v0.9.0
   Compiling getopts v0.2.21
error: internal compiler error: compiler/rustc_metadata/src/rmeta/decoder.rs:937:18: impossible case reached
thread 'rustc' panicked at 'Box<Any>', /checkout/library/std/src/panic.rs:59:5
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace

note: the compiler unexpectedly panicked. this is a bug.
note: the compiler unexpectedly panicked. this is a bug.

note: we would appreciate a bug report: https://github.com/rust-lang/rust/issues/new?labels=C-bug%2C+I-ICE%2C+T-compiler&template=ice.md

note: rustc 1.54.0-nightly (5cbd93c7c 2021-05-27) running on x86_64-unknown-linux-gnu

note: compiler flags: -Z macro-backtrace -Z tls-model=initial-exec -Z unstable-options -Z binary-dep-depinfo -Z force-unstable-if-unmarked -C opt-level=3 -C embed-bitcode=no -C debuginfo=0 -C debug-assertions=on -C overflow-checks=off -C link-args=-Wl,-rpath,$ORIGIN/../lib -C prefer-dynamic -C llvm-args=-import-instr-limit=10 --crate-type lib
note: some of the compiler flags provided by cargo are hidden

query stack during panic:
query stack during panic:
#0 [impl_polarity] computing implementation polarity of `std::iter::Iterator`
#1 [specialization_graph_of] building specialization graph of trait `std::convert::From`
error: aborting due to previous error


error: could not compile `itertools`
To learn more, run the command again with --verbose.
warning: build failed, waiting for other jobs to finish...
error: build failed
command did not execute successfully: ""/checkout/obj/build/x86_64-unknown-linux-gnu/stage0/bin/cargo"" ""build"" ""--target"" ""x86_64-unknown-linux-gnu"" ""-Zbinary-dep-depinfo"" ""-j"" ""16"" ""--release"" ""--locked"" ""--color"" ""always"" ""--features"" "" llvm"" ""--manifest-path"" ""/checkout/compiler/rustc/Cargo.toml"" ""--message-format"" ""json-render-diagnostics""
```

</details>
        ",False,0,COLLABORATOR
https://api.github.com/repos/rust-lang/rust/issues/comments/850027068,Implement coherence checks for negative trait impls,rust-log-analyzer,8,904246849,5,850027068,0,850010106,2021-05-28T00:23:22Z,"
The job **`x86_64-gnu-llvm-10`** failed! Check out the build log: [(web)](https://github.com/rust-lang/rust/runs/2690024382) [(plain)](https://github.com/rust-lang/rust/commit/5d2f0ee6b18c73678901b1ca6968342c280f5da0/checks/2690024382/logs)

<details><summary><i>Click to see the possible cause of the failure (guessed by this bot)</i></summary>

```plain
   Compiling chalk-ir v0.55.0
   Compiling tracing v0.1.25
   Compiling rustc_index v0.0.0 (/checkout/compiler/rustc_index)
   Compiling rustc_data_structures v0.0.0 (/checkout/compiler/rustc_data_structures)
error: internal compiler error: compiler/rustc_trait_selection/src/traits/select/candidate_assembly.rs:109:41: we shouldn't actually return an error here
thread 'rustc' panicked at 'Box<Any>', /checkout/library/std/src/panic.rs:59:5
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace

note: the compiler unexpectedly panicked. this is a bug.
note: the compiler unexpectedly panicked. this is a bug.

note: we would appreciate a bug report: https://github.com/rust-lang/rust/issues/new?labels=C-bug%2C+I-ICE%2C+T-compiler&template=ice.md

note: rustc 1.54.0-nightly (7b8619042 2021-05-28) running on x86_64-unknown-linux-gnu

note: compiler flags: -Z macro-backtrace -Z tls-model=initial-exec -Z unstable-options -Z binary-dep-depinfo -Z force-unstable-if-unmarked -C opt-level=3 -C embed-bitcode=no -C debuginfo=0 -C debug-assertions=on -C overflow-checks=off -C link-args=-Wl,-rpath,$ORIGIN/../lib -C prefer-dynamic -C llvm-args=-import-instr-limit=10 --crate-type lib
note: some of the compiler flags provided by cargo are hidden

query stack during panic:
query stack during panic:
#0 [specialization_graph_of] building specialization graph of trait `std::convert::From`
#1 [check_mod_impl_wf] checking that impls are well-formed in module `owning_ref`
error: aborting due to previous error

error: could not compile `rustc_data_structures`

```

</details>
        ",False,0,COLLABORATOR
https://api.github.com/repos/rust-lang/rust/issues/comments/878508234,Implement coherence checks for negative trait impls,rust-log-analyzer,8,904246849,6,878508234,0,850027068,2021-07-12T18:43:39Z,"
The job **`mingw-check`** failed! Check out the build log: [(web)](https://github.com/rust-lang/rust/runs/3049710495) [(plain)](https://github.com/rust-lang/rust/commit/6d508f804b090bfa75b64537ca759f6979f8a056/checks/3049710495/logs)

<details><summary><i>Click to see the possible cause of the failure (guessed by this bot)</i></summary>

```plain
    Checking rustc_codegen_ssa v0.0.0 (/checkout/compiler/rustc_codegen_ssa)
    Checking rustc_resolve v0.0.0 (/checkout/compiler/rustc_resolve)
    Checking rustc_trait_selection v0.0.0 (/checkout/compiler/rustc_trait_selection)
    Checking rustc_codegen_llvm v0.0.0 (/checkout/compiler/rustc_codegen_llvm)
error[E0599]: no method named `predicate_must_hold` found for mutable reference `&mut traits::select::SelectionContext<'cx, 'tcx>` in the current scope
    |
    |
207 |                 if selcx.predicate_must_hold(o_neg) {
    |                          ^^^^^^^^^^^^^^^^^^^ method not found in `&mut traits::select::SelectionContext<'cx, 'tcx>`
error: aborting due to previous error

For more information about this error, try `rustc --explain E0599`.
error: could not compile `rustc_trait_selection`
```

</details>
        ",False,0,COLLABORATOR
https://api.github.com/repos/rust-lang/rust/issues/comments/880927752,Implement coherence checks for negative trait impls,rust-log-analyzer,8,904246849,7,880927752,0,878508234,2021-07-15T18:41:10Z,"
The job **`mingw-check`** failed! Check out the build log: [(web)](https://github.com/rust-lang/rust/runs/3079749272) [(plain)](https://github.com/rust-lang/rust/commit/914428df89e0e19691fe0ebcfc18ae6d9c744fa4/checks/3079749272/logs)

<details><summary><i>Click to see the possible cause of the failure (guessed by this bot)</i></summary>

```plain
    Checking rustc_codegen_llvm v0.0.0 (/checkout/compiler/rustc_codegen_llvm)
error[E0282]: type annotations needed
   --> compiler/rustc_trait_selection/src/traits/coherence.rs:187:30
    |
187 |     let negate_obligation = |mut obligation| {
    |                              ^^^^^^^^^^^^^^ consider giving this closure parameter a type
    = note: type must be known at this point


error[E0599]: no method named `predicate_must_hold` found for mutable reference `&mut traits::select::SelectionContext<'cx, 'tcx>` in the current scope
    |
    |
220 |                 if selcx.predicate_must_hold(o_neg) {
    |                          ^^^^^^^^^^^^^^^^^^^ method not found in `&mut traits::select::SelectionContext<'cx, 'tcx>`
error: aborting due to 2 previous errors

Some errors have detailed explanations: E0282, E0599.
For more information about an error, try `rustc --explain E0282`.
```

</details>
        ",False,0,COLLABORATOR
https://api.github.com/repos/rust-lang/rust/issues/comments/880931058,Implement coherence checks for negative trait impls,rust-log-analyzer,8,904246849,8,880931058,0,880927752,2021-07-15T18:46:47Z,"
The job **`mingw-check`** failed! Check out the build log: [(web)](https://github.com/rust-lang/rust/runs/3079791788) [(plain)](https://github.com/rust-lang/rust/commit/e3c459cd13b79065ee9edcbd10ec534c87eca02d/checks/3079791788/logs)

<details><summary><i>Click to see the possible cause of the failure (guessed by this bot)</i></summary>

```plain
    Checking rustc_codegen_llvm v0.0.0 (/checkout/compiler/rustc_codegen_llvm)
error[E0282]: type annotations needed
   --> compiler/rustc_trait_selection/src/traits/coherence.rs:187:30
    |
187 |     let negate_obligation = |mut obligation| {
    |                              ^^^^^^^^^^^^^^ consider giving this closure parameter a type
    = note: type must be known at this point


error[E0599]: no method named `predicate_must_hold` found for mutable reference `&mut traits::select::SelectionContext<'cx, 'tcx>` in the current scope
    |
    |
217 |                 if selcx.predicate_must_hold(o_neg) {
    |                          ^^^^^^^^^^^^^^^^^^^ method not found in `&mut traits::select::SelectionContext<'cx, 'tcx>`
error: aborting due to 2 previous errors

Some errors have detailed explanations: E0282, E0599.
For more information about an error, try `rustc --explain E0282`.
```

</details>
        ",False,0,COLLABORATOR
https://api.github.com/repos/rust-lang/rust/issues/comments/950204880,Implement coherence checks for negative trait impls,spastorino,8,904246849,9,950204880,0,880931058,2021-10-23T19:56:47Z,Closing this one given that #90104 is already merged.,False,0,MEMBER
https://api.github.com/repos/libretro/RetroArch/issues/12439,A more automated crowdin sync script,DisasterMo,6,901470437,1,901470437,0,0,2021-05-25T22:53:46Z,"## Description

This is again not very useful to anyone at the moment, but I was kind of inspired to do it anyway.

Now the Crowdin synchronisation script can be executed at any time (i.e. one doesn't need to switch branches or commit/stash changes) and from any location (i.e. one does not need to cd to the intl folder and can execute the script by path/to/file; it should itself still remain in the intl folder, though)! 

The script will now:

- stash the changes of your current branch & restore them once finished! 
- create an 'upstream' remote or change its url to match the main RetroArch repo & revert the change (but not the creation; I mean, should it?) once finished!
- create a new clean branch to sync the translations with Crowdin from!
- add and commit the changes & ask you, whether you'd like it to push them to origin!
- ask you, whether it should clean up after itself (i.e. delete the newly created branch)!

Now, ain't that a thing!

## Reviewers
I hope you like it, @guoyunhe !",True,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/848326572,A more automated crowdin sync script,lgtm-com[bot],6,901470437,2,848326572,0,901470437,2021-05-25T23:02:50Z,"This pull request **introduces 6 alerts** when merging b4dfcb4f6a1fdbd8861f472d800d24c288f79d48 into a84c9022affec92d8ff56579aba276122c049795 - [view on LGTM.com](https://lgtm.com/projects/g/libretro/RetroArch/rev/pr-bf5bc7acbd24d456ef5cd7e14173ccca8e38f242)

**new alerts:**

* 6 for Variable defined multiple times",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/859724952,A more automated crowdin sync script,lgtm-com[bot],6,901470437,3,859724952,0,848326572,2021-06-11T17:13:34Z,"This pull request **introduces 6 alerts** when merging 3fd319303262dc84a192c6393c9025adfbba7dce into 766c59d469efb802a4705dfd9b82477249723e26 - [view on LGTM.com](https://lgtm.com/projects/g/libretro/RetroArch/rev/pr-dc48fb788c9bc88ec4eb1ddae7da9b6911573adf)

**new alerts:**

* 6 for Variable defined multiple times",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/864205578,A more automated crowdin sync script,lgtm-com[bot],6,901470437,4,864205578,0,859724952,2021-06-18T18:23:18Z,"This pull request **introduces 6 alerts** when merging d4de7560d8c4e7e3bd9a77c31b7944d882fd6326 into 81075aa5fabcca3cb8c7e1b7725613d1ed167c2a - [view on LGTM.com](https://lgtm.com/projects/g/libretro/RetroArch/rev/pr-5faaefdf97e958fd4bbeb29db2ff6128ef726e6d)

**new alerts:**

* 6 for Variable defined multiple times",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/874331103,A more automated crowdin sync script,lgtm-com[bot],6,901470437,5,874331103,0,864205578,2021-07-05T21:12:52Z,"This pull request **introduces 3 alerts** when merging 4ecb01e18d50734a707b2a0ed23c5707011bb093 into f93499181c3dbeeccec8cfe384cc174fea818426 - [view on LGTM.com](https://lgtm.com/projects/g/libretro/RetroArch/rev/pr-2ebfc71b4c2c60d6102712b3304e250bd8774112)

**new alerts:**

* 3 for Variable defined multiple times",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/935476814,A more automated crowdin sync script,ofry,6,901470437,6,935476814,0,874331103,2021-10-06T05:16:17Z,@DisasterMo Is this PR still actual?,False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/935595668,A more automated crowdin sync script,DisasterMo,6,901470437,7,935595668,0,935476814,2021-10-06T06:49:56Z,@ofry Not really. I'll just close this. Thanks for the reminder!,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/12442,(cheevos) upgrade to rcheevos 10.0,Jamiras,3,903180718,1,903180718,0,0,2021-05-27T03:49:42Z,"## Description

Updates the `deps/rcheevos` directory to the latest release. Includes a few changes to other files to accommodate changes in the rcheevos APIs (only ~180 lines of the 5700 reported). New features will be incorporated through future PRs.

Primarily brings support for the new syntax introduced by the 0.79 RA_Integration.dll:
* Trigger
* ResetNextIf
* SubHits
* ranges in rich presence lookups
* support for maxof($) operator when using Measured in leaderboard values
* support for ResetIf and PauseIf when using Measured in leaderboard values

I've been testing this off-and-on for the last 10 days, and everything seems to be working as expected.

## Related Issues

n/a

## Related Pull Requests

n/a

## Reviewers

@Sanaki @meleu 
",True,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/849297927,(cheevos) upgrade to rcheevos 10.0,Jamiras,3,903180718,2,849297927,0,903180718,2021-05-27T03:50:49Z,"Marking as draft until I can validate the CI results, which won't happen until tomorrow.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/849696980,(cheevos) upgrade to rcheevos 10.0,Jamiras,3,903180718,3,849696980,0,849297927,2021-05-27T14:46:33Z,"Remaining travis error is unrelated to this change. Removing Draft tag.
```retroarch.c:22056:37: error: ‘OVERLAY_SHOW_INPUT_NONE’ undeclared (first use in this function); did you mean ‘OVERLAY_STATUS_NONE’?```",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/849796689,(cheevos) upgrade to rcheevos 10.0,jdgleaver,3,903180718,4,849796689,0,849696980,2021-05-27T17:06:34Z,"Just for info, that particular error was fixed by #12441",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/12445,Improve message wrapping with CJK languages,txorion,8,904762849,1,904762849,0,0,2021-05-28T05:58:10Z,"## Description

This PR combines #12399 and #12400.
I have reimplemented it based on the comments and suggestions I received in above PRs.

- When using with languages their fonts contain wider glyph than alphabet (e.g. CJK), use the width for message wrapping.
- The process above is separated from word_wrap() and implemented as word_wrap_wideglyph(), to prevent performance overhead when using with languages other than above.

## Related Issues

#7439, #9731

## Related Pull Requests

#12399, #12400, #12435
",True,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/850183070,Improve message wrapping with CJK languages,lgtm-com[bot],8,904762849,2,850183070,0,904762849,2021-05-28T06:40:42Z,"This pull request **introduces 1 alert** when merging ae29cb39ddf69d2b31bf75318ac66bfe7c5f39a5 into 2c21e3df8b91885e5ace58bab4bec617f1874fff - [view on LGTM.com](https://lgtm.com/projects/g/libretro/RetroArch/rev/pr-48830d9c8310dc955bc84121fbb530cc48d4c079)

**new alerts:**

* 1 for Comparison result is always the same",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/850498531,Improve message wrapping with CJK languages,jdgleaver,8,904762849,3,850498531,0,850183070,2021-05-28T15:28:46Z,"@toshixm Thank you, this is impressive! I am sure that many users will appreciate your work.

I'm afraid it will take a little while to review/merge this - we're planning a new stable release at the weekend, and want to avoid any significant 'non-essential' changes until this is done (to minimise potential last-minute regressions). I am also in the middle of preparing a long-overdue libretro API extension, which I need to get finished before I take on anything else.

So please bear with us! I will review and test the PR as soon as I can next week :)",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/850511148,Improve message wrapping with CJK languages,txorion,8,904762849,4,850511148,0,850498531,2021-05-28T15:49:12Z,"@jdgleaver No problem. You should prioritize your own work.
I hope that the fix should be merged without any regressions, so I want you to review the fix thoroughly after next week.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/853091731,Improve message wrapping with CJK languages,jdgleaver,8,904762849,5,853091731,0,850511148,2021-06-02T14:47:16Z,"@toshixm I am very impressed! Your implementation works incredibly well. As a nice side benefit, the changes also reduce the performance overheads of `word_wrap()` for Latin languages by ~9% :)

There are only a handful of very trivial things that I would ask you to add/modify - I will leave these as comments in the code itself.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/853691801,Improve message wrapping with CJK languages,txorion,8,904762849,6,853691801,0,853091731,2021-06-03T08:34:21Z,"@jdgleaver Thank you for the review and great feedback!
I have added comments to describe about my implementation, but some of them may be wrong or confusing for native English speakers because I am not good at English.
Please let me know if there are such ones.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/853808667,Improve message wrapping with CJK languages,jdgleaver,8,904762849,7,853808667,0,853691801,2021-06-03T11:48:09Z,"@toshixm Thank you!

Please don't be apologetic about your use of English. I only know one language, so you are already better than me :)

I understood your comments just fine, but I think there are a few places where clarifications could be made. I have therefore prepared a patch with some changes: 
[comments.zip](https://github.com/libretro/RetroArch/files/6591365/comments.zip)

If you apply this and squash your commits, we should be ready to merge!",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/853825154,Improve message wrapping with CJK languages,txorion,8,904762849,8,853825154,0,853808667,2021-06-03T12:18:37Z,"@jdgleaver Thank you. Your description is very clear and expresses my intention perfectly.
I have applied your patch and squashed my commits.
Thanks for all your support!",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/853829779,Improve message wrapping with CJK languages,jdgleaver,8,904762849,9,853829779,0,853825154,2021-06-03T12:26:58Z,"You are very welcome! Thank you for the great contribution :)

@twinaphex This is ready for merging!",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/12462,Weird bug when loading content from a compressed file (zip or 7z). It has to do with the file extension?,ChoquePumper,6,906636956,1,906636956,0,0,2021-05-30T05:33:31Z,"[Edit 07/16/2021] I specified the wrong RA versions when I created the issue (v1.4.0 instead of v1.9.4), now they are correct.
## Description

Weird bug when loading content from a compressed file (zip or 7z). If the file inside is named with certain file extensions, then RetroArch throws an error like ""Failed to extract content from compressed file: /path/to/compressed_file.7z#ASegaGenesisGame.68k"" (""68k"" is a supported extension by the Genesis Plus GX core). However, if that name has another file extension (e.g. ""ASegaGenesisGame.bin""), the content is loaded sucessfully without errors.
The log file says nothing other than the error message even if the logging level is set to 0 (Debug).

The content can have any supported file extension when it's not compressed and be loaded correctly, but this doesn't work if it's in a compressed file.

### Expected behavior

The content has to be loaded regardless its file extension from the compressed file without issues.

### Actual behavior

It shows a notification saying ""Failed to extract content from compressed file"" and...
Prior v1.9.4:
- For compressed 7z files, it actually extracts and loads the content despite the notification.
- For zip files: on v1.9.2, it loads the content once despite the notification, and crashes at the second time with ""double free or memory corruption"". On v1.9.1, (apparently) it gets stuck in an infinite loop.

On **v1.9.4 (stable)**:
- **It doesn't load the content and it won't let me play the game** compared to the previous version.

### Steps to reproduce the bug

1. Open the frontend and boot to the menu
2. Go to Import content.
3. Select a directory with a compressed file which contains a file named with a file extension that may cause an error (e.g. ""68k"" extension).
4. Go to the corresponding playlist.
5. Select the entry that points to a content in a compressed file (see the path) (e.g. ""/path/to/compressed_file.7z#ASegaGenesisGame.68k"")
6. Select ""Play"" to start the content. It should show notification that says ""Failed to extract content from compressed file"" and the game won't start (or something from the ""Actual behaviour"" section).

### Bisect Results

I just installed RetroArch for Android (apk file from buildbot) and I thought that I may save storage memory if I create a zip file for every content file. But when I tried to load the content, it got stuck in an infinite loop (v1.9.1). I tried to replicate the bug on Windows and Linux, and it happened the same exact thing.

### Version/Commit
You can find this information under Information/System Information

Tested versions
- RetroArch: 1.9.1 (stable), 1.9.2 (stable), 1.9.3 (stable), 1.9.4 (stable / c226bd87f4)

### Environment information

For versions 1.9.1 to 1.9.3:
- OS: Zorin OS 15.3 (based on Ubuntu 18.04) 64-bit; Android (v1.9.1 (32-bit build) only) 4.4 and 7.0; Windows 10 version 1709 64-bit

For version 1.9.4:
- OS: Zorin OS 15.3 (based on Ubuntu 18.04) 64-bit",True,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/880027647,Weird bug when loading content from a compressed file (zip or 7z). It has to do with the file extension?,Kallin,6,906636956,2,880027647,0,906636956,2021-07-14T16:15:50Z,"I think I'm experiencing the same issue, but thought it was core-specific as reported here: https://github.com/libretro/desmume/issues/89 . I notice that other cores can open zips fine, but just noticed I'm having the same issue with blueMSX core opening zips. This didn't used to happen so I feel it's a recent regression.",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/881739343,Weird bug when loading content from a compressed file (zip or 7z). It has to do with the file extension?,ChoquePumper,6,906636956,3,881739343,0,880027647,2021-07-16T21:55:47Z,"I'm so dumb! I just realized that I put the wrong RetroArch versions when I created the issue (v1.1.0 instead of v1.9.1, v1.2.0 instead of v1.9.2, and so on).",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/886724073,Weird bug when loading content from a compressed file (zip or 7z). It has to do with the file extension?,Kallin,6,906636956,4,886724073,0,881739343,2021-07-26T13:54:16Z,Still an issue in 1.9.7,False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/890511387,Weird bug when loading content from a compressed file (zip or 7z). It has to do with the file extension?,jordigo,6,906636956,5,890511387,0,886724073,2021-08-01T12:22:43Z,Still present in 1.9.8,False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/1670428010,Weird bug when loading content from a compressed file (zip or 7z). It has to do with the file extension?,ultratiem,6,906636956,6,1670428010,0,890511387,2023-08-08T23:06:06Z,Still present in 1.16.0,False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/1752350229,Weird bug when loading content from a compressed file (zip or 7z). It has to do with the file extension?,dewmguy,6,906636956,7,1752350229,0,1670428010,2023-10-09T05:02:24Z,"i have this issue in .1.16 in windows. i did not have this issue in 1.16 for ubuntu 22.04

from log:
[ERROR] [Content]: Failed to extract content from compressed file: ""\\192.168.1.10\Storage\Emulation\Roms\SNES\Super Mario World 2 - Yoshis Island.7z#Super Mario World 2 - Yoshis Island.smc"".

I don't think it's an issue with 7z, because certain emulators load them fine",False,0,NONE
https://api.github.com/repos/zeromq/libzmq/issues/4188,Support so_busy_poll,imkcy9,3,891827256,1,891827256,0,0,2021-05-14T10:59:23Z,,True,0,CONTRIBUTOR
https://api.github.com/repos/zeromq/libzmq/issues/comments/841231430,Support so_busy_poll,bluca,3,891827256,2,841231430,0,891827256,2021-05-14T13:05:30Z,"There's a build failure that I don't quite understand, as I don't use CMake very often:

```
CMake Error at tests/CMakeLists.txt:246 (add_executable):
  Cannot find source file:
    test_busy_poll.cpp
```

You can reproduce it by building with `cmake -DENABLE_DRAFTS=OFF`",False,0,MEMBER
https://api.github.com/repos/zeromq/libzmq/issues/comments/841263959,Support so_busy_poll,bluca,3,891827256,3,841263959,0,841231430,2021-05-14T14:02:25Z,"CMake is still erroring out:

```
CMake Error at tests/CMakeLists.txt:242 (add_executable):
  Cannot find source file:
    test_busy_poll.cpp
```",False,0,MEMBER
https://api.github.com/repos/zeromq/libzmq/issues/comments/841329260,Support so_busy_poll,bluca,3,891827256,4,841329260,0,841263959,2021-05-14T15:49:22Z,"Cmake is now working, but valgrind is still failing - you need to initialize the busy_poll variable in the options class constructor, here:

https://github.com/zeromq/libzmq/blob/5c22bfd8c203acf128d5d8348710fa8351b0221c/src/options.cpp#L257",False,0,MEMBER
https://api.github.com/repos/zeromq/libzmq/issues/4189,IPC server memory unlimited grow,dkonyshev,13,892175924,1,892175924,0,0,2021-05-14T18:50:09Z,"Hello,

Could someone please explain what is wrong with my server code below? The problem is that the server keeps allocating memory every time a short-living client connects to its IPC socket but never seems to release that memory when the clients exit. In my real embedded system app the servers ends up devouring all the system memory and the system crashes.

I narrowed down the problem code to this server code:

```
#!/usr/bin/python3

import zmq, time

url = 'ipc:///tmp/my'

context = zmq.Context()
sock = context.socket(zmq.PUB)
sock.bind(url)

while True:
    time.sleep(1)
```
And the client code:

```
#!/usr/bin/python3

import zmq

url = 'ipc:///tmp/my'

context = zmq.Context()
sock = context.socket(zmq.SUB)
sock.connect(url)
sock.close();
context.destroy();
```
Then, I run the server in one terminal as follows to keep track of used memory:

`python3 zmq-send.py & while :; do cat /proc/$!/statm; sleep 5; done`

And the clients are launching in another terminal as follows:

`while :; do python3 zmq-rcv.py; done`

It can be seen in the server memory printouts that its used memory grows very fast but never shrinks.

Any help will be very much appreciated.

Regards,
Dmitry",True,0,NONE
https://api.github.com/repos/zeromq/libzmq/issues/comments/841494704,IPC server memory unlimited grow,shishirpy,13,892175924,2,841494704,0,892175924,2021-05-14T20:45:23Z,"The server code does not work as it is. I get error regarding missing `os` import, if I include that I get error regarding
`os.makedirs(dir, exist_ok=True)` line in the server.",False,0,NONE
https://api.github.com/repos/zeromq/libzmq/issues/comments/841600420,IPC server memory unlimited grow,dkonyshev,13,892175924,3,841600420,0,841494704,2021-05-15T04:54:04Z,Sorry about that. Just fixed the code in the comment.,False,0,NONE
https://api.github.com/repos/zeromq/libzmq/issues/comments/841759984,IPC server memory unlimited grow,shishirpy,13,892175924,4,841759984,0,841600420,2021-05-16T03:25:55Z,"I see the same lines printed again and again.  Could you post the output for 
`print(sock.getsockopt(zmq.SNDHWM))`

before `while True` in the server code.",False,0,NONE
https://api.github.com/repos/zeromq/libzmq/issues/comments/841843342,IPC server memory unlimited grow,dkonyshev,13,892175924,5,841843342,0,841759984,2021-05-16T16:49:42Z,"`print(sock.getsockopt(zmq.SNDHWM))` yields 1000.

Here is console output demonstrating the server used memory (6th number in the statm output) growing over time:

```
$ python3 zmq-send.py & while :; do cat /proc/$!/statm; sleep 5; done
[2] 1335088
2451 211 187 660 0 171 0
1000
27515 4258 2608 660 0 6417 0
27515 4588 2608 660 0 7620 0
27515 4984 2608 660 0 8809 0
27515 5380 2608 660 0 10006 0
27515 5776 2608 660 0 11192 0
```",False,0,NONE
https://api.github.com/repos/zeromq/libzmq/issues/comments/841864180,IPC server memory unlimited grow,shishirpy,13,892175924,6,841864180,0,841843342,2021-05-16T19:19:28Z,"I see a similar output when I reduce the sleep duration but after a point it remains constant. I guess that it just takes that long to grow to the true size. I am not sure why it takes so long for you for me it reaches the limit withing 1 sec

```
(venv)$ python3 server.py & while :; do cat /proc/$!/statm; sleep 0.02; done
[15] 21437
5326 442 338 660 0 2197 0
6153 1811 821 660 0 2977 0
7979 2669 1185 660 0 3446 0
1000
28461 2796 1298 660 0 23928 0
28461 2796 1298 660 0 23928 0
28461 2796 1298 660 0 23928 0
28461 2796 1298 660 0 23928 0
```",False,0,NONE
https://api.github.com/repos/zeromq/libzmq/issues/comments/841975634,IPC server memory unlimited grow,dkonyshev,13,892175924,7,841975634,0,841864180,2021-05-17T04:29:47Z,"I left the test running over a night and the server used memory still keeps growing:
```
10005371 3028276 2592 660 0 9988941 0
10005371 3028672 2592 660 0 9990120 0
10005371 3029002 2592 660 0 9991316 0
10005371 3027685 2592 660 0 9992512 0
10005371 3028015 2592 660 0 9993708 0
10005371 3028411 2592 660 0 9994895 0
```
`top` says the server takes 73,8% of system memory at the moment.

My system is Ubuntu 20.04:

Current libzmq version is 4.3.2
Current pyzmq version is 18.1.1",False,0,NONE
https://api.github.com/repos/zeromq/libzmq/issues/comments/842453559,IPC server memory unlimited grow,shishirpy,13,892175924,8,842453559,0,841975634,2021-05-17T16:14:08Z,"Not sure what's going on. I am using the following versions:

- WSL Ubuntu 20.04
- libzmq version 4.3.4
- pyzmq version 22.0.3",False,0,NONE
https://api.github.com/repos/zeromq/libzmq/issues/comments/842481268,IPC server memory unlimited grow,shishirpy,13,892175924,9,842481268,0,842453559,2021-05-17T16:55:00Z,"I don't see any memory increase with the versions you mentioned on WSL.

- libzmq version 4.3.2
- pyzmq version 18.1.1",False,0,NONE
https://api.github.com/repos/zeromq/libzmq/issues/comments/843776162,IPC server memory unlimited grow,dkonyshev,13,892175924,10,843776162,0,842481268,2021-05-19T06:11:04Z,"This is really confusing. 

Besides Ubuntu 20.04, I observe the same behavior with memory allocated by the server indefinitely:

- Fedora 31 x86_64 (libzmq 4.3.2, pyzmq 18.0.2)
- Custom ARM64 Zeus Yocto build (libzmq 4.2.5, pyzmq 19.0.0)",False,0,NONE
https://api.github.com/repos/zeromq/libzmq/issues/comments/845827867,IPC server memory unlimited grow,Keynib,13,892175924,11,845827867,0,843776162,2021-05-21T09:44:44Z,"I tried to reproduce the given problem and caught the memory growth too. I probably think, that problem is in epoll() function of zmq thread.
If you allocate memory by using `context = zmq.Context()` and don't destroy this context, valgrind will show a lot of leaks, one is interested:

```
==220861== 164,000 bytes in 10 blocks are still reachable in loss record 88 of 90
==220861==    at 0x4C31DFB: malloc (vg_replace_malloc.c:309)
==220861==    by 0x40A21A5: allocate_chunk (yqueue.hpp:189)
==220861==    by 0x40A21A5: yqueue_t (yqueue.hpp:68)
==220861==    by 0x40A21A5: zmq::pipe_t::hiccup() (ypipe.hpp:51)
==220861==    by 0x40ADE97: zmq::session_base_t::reconnect() (session_base.cpp:519)
==220861==    by 0x40ADFBF: zmq::session_base_t::engine_error(zmq::stream_engine_t::error_reason_t) (session_base.cpp:437)
==220861==    by 0x40BA003: zmq::stream_engine_t::error(zmq::stream_engine_t::error_reason_t) (stream_engine.cpp:986)
==220861==    by 0x40BC167: zmq::stream_engine_t::in_event() (stream_engine.cpp:321)
==220861==    by 0x409114B: zmq::epoll_t::loop() [clone .part.11] (epoll.cpp:198)
==220861==    by 0x40C250C: thread_routine (thread.cpp:182)
==220861==    by 0x504E6DA: start_thread (pthread_create.c:463)
==220861==    by 0x5EAD71E: clone (clone.S:95)
```
",False,0,NONE
https://api.github.com/repos/zeromq/libzmq/issues/comments/846400799,IPC server memory unlimited grow,shishirpy,13,892175924,12,846400799,0,845827867,2021-05-22T12:23:05Z,"Do you see the same results if you do not run the `zmq-rcv.py` code? 

- The server code is continuously running. But, it does not publish any messages.
- The receiver is created and closed but it does not do anything other than connect to the `ipc` address, which I think also does not happen because the by the time it connects, the socket is also closed.",False,0,NONE
https://api.github.com/repos/zeromq/libzmq/issues/comments/920872293,IPC server memory unlimited grow,giampaolo,13,892175924,13,920872293,0,846400799,2021-09-16T12:50:06Z,"> I tried to reproduce the given problem and caught the memory growth too. I probably think, that problem is in epoll() function of zmq thread.

FWIW, this is the `strace -p PID` output when a new connection is accepted. 

```
epoll_wait(8, [{EPOLLIN, {u32=872418144, u64=140356108684128}}], 256, -1) = 1
accept4(10, NULL, NULL, SOCK_CLOEXEC)   = 11
getpeername(11, {sa_family=AF_UNIX}, [128->2]) = 0
getsockname(11, {sa_family=AF_UNIX, sun_path=""/tmp/my""}, [128->10]) = 0
getpeername(11, {sa_family=AF_UNIX}, [128->2]) = 0
getsockopt(11, SOL_SOCKET, SO_PEERCRED, {pid=95371, uid=1000, gid=1000}, [12]) = 0
fcntl(11, F_GETFL)                      = 0x2 (flags O_RDWR)
fcntl(11, F_SETFL, O_RDWR|O_NONBLOCK)   = 0
write(7, ""\1\0\0\0\0\0\0\0"", 8)         = 8
epoll_wait(8, [{EPOLLIN, {u32=30834208, u64=30834208}}], 256, -1) = 1
poll([{fd=7, events=POLLIN}], 1, 0)     = 1 ([{fd=7, revents=POLLIN}])
read(7, ""\1\0\0\0\0\0\0\0"", 8)          = 8
epoll_ctl(8, EPOLL_CTL_ADD, 11, {0, {u32=872421776, u64=140356108687760}}) = 0
epoll_ctl(8, EPOLL_CTL_MOD, 11, {EPOLLIN, {u32=872421776, u64=140356108687760}}) = 0
epoll_ctl(8, EPOLL_CTL_MOD, 11, {EPOLLIN|EPOLLOUT, {u32=872421776, u64=140356108687760}}) = 0
recvfrom(11, ""\377\0\0\0\0\0\0\0\1\177"", 12, 0, NULL, NULL) = 10
recvfrom(11, """", 2, 0, NULL, NULL)      = 0
epoll_ctl(8, EPOLL_CTL_DEL, 11, 0x7fa734001994) = 0
close(11)                               = 0
poll([{fd=7, events=POLLIN}], 1, 0)     = 0 (Timeout)
epoll_wait(8, 
```",False,0,NONE
https://api.github.com/repos/zeromq/libzmq/issues/comments/920917503,IPC server memory unlimited grow,jimklimov,13,892175924,14,920917503,0,920872293,2021-09-16T13:46:35Z,"Couldn't find a link quickly, but this sounds like another discussion from
a year or two ago about, IIRC, zero-copy mechanism to speed up
communications. Effectively, many network packets come into a buffer,
pointers to insides of that are given as zmq protocol message contents, and
the big buffer is only released when no references remain alive.

In that other thread, people saw large memory consumptions because (I
think) did not quickly process and free the messages.

The older non-zerocopy can be enabled somehow, it is less stressful on
memory at a CPU time cost of copying each message into its own buffer.

On Thu, Sep 16, 2021, 14:50 Giampaolo Rodola ***@***.***>
wrote:

> I tried to reproduce the given problem and caught the memory growth too. I
> probably think, that problem is in epoll() function of zmq thread.
>
> FWIW, this is the strace -p PID output when a new connection is accepted.
>
> epoll_wait(8, [{EPOLLIN, {u32=872418144, u64=140356108684128}}], 256, -1) = 1
> accept4(10, NULL, NULL, SOCK_CLOEXEC)   = 11
> getpeername(11, {sa_family=AF_UNIX}, [128->2]) = 0
> getsockname(11, {sa_family=AF_UNIX, sun_path=""/tmp/my""}, [128->10]) = 0
> getpeername(11, {sa_family=AF_UNIX}, [128->2]) = 0
> getsockopt(11, SOL_SOCKET, SO_PEERCRED, {pid=95371, uid=1000, gid=1000}, [12]) = 0
> fcntl(11, F_GETFL)                      = 0x2 (flags O_RDWR)
> fcntl(11, F_SETFL, O_RDWR|O_NONBLOCK)   = 0
> write(7, ""\1\0\0\0\0\0\0\0"", 8)         = 8
> epoll_wait(8, [{EPOLLIN, {u32=30834208, u64=30834208}}], 256, -1) = 1
> poll([{fd=7, events=POLLIN}], 1, 0)     = 1 ([{fd=7, revents=POLLIN}])
> read(7, ""\1\0\0\0\0\0\0\0"", 8)          = 8
> epoll_ctl(8, EPOLL_CTL_ADD, 11, {0, {u32=872421776, u64=140356108687760}}) = 0
> epoll_ctl(8, EPOLL_CTL_MOD, 11, {EPOLLIN, {u32=872421776, u64=140356108687760}}) = 0
> epoll_ctl(8, EPOLL_CTL_MOD, 11, {EPOLLIN|EPOLLOUT, {u32=872421776, u64=140356108687760}}) = 0
> recvfrom(11, ""\377\0\0\0\0\0\0\0\1\177"", 12, 0, NULL, NULL) = 10
> recvfrom(11, """", 2, 0, NULL, NULL)      = 0
> epoll_ctl(8, EPOLL_CTL_DEL, 11, 0x7fa734001994) = 0
> close(11)                               = 0
> poll([{fd=7, events=POLLIN}], 1, 0)     = 0 (Timeout)
> epoll_wait(8,
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/zeromq/libzmq/issues/4189#issuecomment-920872293>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAMPTFADKJTN56BWBVQ7CDDUCHRY7ANCNFSM4446U42A>
> .
> Triage notifications on the go with GitHub Mobile for iOS
> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>
> or Android
> <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.
>
>
",False,0,MEMBER
https://api.github.com/repos/zeromq/libzmq/issues/4191,Problem: no downloads available for Windows builds,minrk,12,892749088,1,892749088,0,0,2021-05-16T20:06:53Z,"# Issue description

bintray is [shutdown](https://jfrog.com/blog/into-the-sunset-bintray-jcenter-gocenter-and-chartcenter/), so all the Windows releases published from appveyor are inaccessible. They are still being built on appveyor, but can no longer be downloaded (and future uploads will presumably fail).

This is *not* a duplicate of https://github.com/zeromq/zeromq.org/issues/113 which was closed as a docs-only issue because the dead links are removed from the docs. This issue should only be closed when:

- a new destination is picked for Windows artifacts ([github packages](https://github.com/features/packages)?)
- Windows build [currently still configured to send to bintray](https://github.com/zeromq/libzmq/blob/04c37982b152945731188f8a149de99a72aef29c/appveyor.yml#L274-L28) is updated to use the new destination
- at least the current stable builds are uploaded to the new destination

pyzmq Windows releases rely on these builds, which means I can't make a pyzmq release until this is fixed or I find another source of libzmq builds.

# Environment

* libzmq version (commit hash if unreleased):  all
* OS: Windows

# Minimal test code / Steps to reproduce the issue

Try to download a Windows release, e.g. `wget https://dl.bintray.com/zeromq/generic/libzmq-v141-x64-4_3_2.zip`

# What's the actual result? (include assertion message & call stack if applicable)

403 forbidden

# What's the expected result?

Windows dll builds of libzmq",True,0,MEMBER
https://api.github.com/repos/zeromq/libzmq/issues/comments/841870607,Problem: no downloads available for Windows builds,bluca,12,892749088,2,841870607,0,892749088,2021-05-16T20:08:36Z,"There's some stuff published on package managers like Conda, are you able to use those for pyzmq?",False,0,MEMBER
https://api.github.com/repos/zeromq/libzmq/issues/comments/842236211,Problem: no downloads available for Windows builds,minrk,12,892749088,3,842236211,0,841870607,2021-05-17T11:10:22Z,"Interesting idea! I can try extracting libraries from the conda packages in the meantime, I'm not sure if that will work. Do you think libzmq should stop publishing releases for Windows? The infrastructure is all already in place, but needs a new host for the artifacts.",False,0,MEMBER
https://api.github.com/repos/zeromq/libzmq/issues/comments/842238708,Problem: no downloads available for Windows builds,bluca,12,892749088,4,842238708,0,842236211,2021-05-17T11:14:34Z,"No opinion on the subject, I'm really not involved in that side - if anyone can find an alternative and make it work, it would be fine too",False,0,MEMBER
https://api.github.com/repos/zeromq/libzmq/issues/comments/842276123,Problem: no downloads available for Windows builds,minrk,12,892749088,5,842276123,0,842238708,2021-05-17T12:14:52Z,"Looked into it for a bit and conda's a no go since they only do 64b builds on Windows, and pyzmq publishes 32b builds for Windows as well.

[cloudsmith](https://cloudsmith.com) seems to be the closest replacement. Doesn't have a built-in appveyor deploy plugin, but it does have a CLI so `cloudsmith-cli push ...` should be all that's needed.


Appveyor supports publishing to GitHub releases, which might work - I can't tell if the multiple artifacts from mutliple builds for one release is a problem, though.",False,0,MEMBER
https://api.github.com/repos/zeromq/libzmq/issues/comments/842320143,Problem: no downloads available for Windows builds,sigiesec,12,892749088,6,842320143,0,842276123,2021-05-17T13:22:17Z,"FWIW, I think zeromq is already available via vcpkg, would that work for you?",False,0,MEMBER
https://api.github.com/repos/zeromq/libzmq/issues/comments/842927110,Problem: no downloads available for Windows builds,minrk,12,892749088,7,842927110,0,842320143,2021-05-18T07:27:35Z,"Looks like appveyor with GitHub releases might work. I tested with [this change](https://github.com/zeromq/libzmq/compare/master...minrk:appveyor-gh-release), which made [this release](https://github.com/minrk/libzmq/releases/tag/v4.3.3.post0). I don't know if that would conflict with your release process because it seems to clobber the release text on each upload (it does remain as an unpublished draft). So to make a release, you would have to push a tag, wait for appveyor to finish uploading builds, then edit and publish the release. If that's acceptable, I think this is the simplest solution. Then pushing a `.post0` tag on 4.3.3 (or just copying over the artifacts from [here](https://github.com/minrk/libzmq/releases/tag/v4.3.3.post0) to 4.3.3) should work.

To get that ready for merge, we would need to get a github token for uploading releases (I used a personal access token for my fork). GitHub makes this unnecessarily tedious if you want to confine permissions to a single repo, which usually means creating a bot github account and granting the bot access to the repo.",False,0,MEMBER
https://api.github.com/repos/zeromq/libzmq/issues/comments/842942210,Problem: no downloads available for Windows builds,minrk,12,892749088,8,842942210,0,842927110,2021-05-18T07:50:46Z,"@sigiesec it might! I'm not sure where vcpkg installs DLLs, but I'll see if I can find it.",False,0,MEMBER
https://api.github.com/repos/zeromq/libzmq/issues/comments/842969231,Problem: no downloads available for Windows builds,bluca,12,892749088,9,842969231,0,842942210,2021-05-18T08:29:31Z,"We always edit the text manually to add the changeling, so that's not an issue - it must not remove existing artifacts though, which are created by Travis - that's the important part",False,0,MEMBER
https://api.github.com/repos/zeromq/libzmq/issues/comments/843091626,Problem: no downloads available for Windows builds,minrk,12,892749088,10,843091626,0,842969231,2021-05-18T11:33:20Z,"Yeah, it seems to only add them (each artifact is an upload from a different build, so there would only be one if it removed existing artifacts). So it should be fine then, pending the credentials. What credentials are used for travis?",False,0,MEMBER
https://api.github.com/repos/zeromq/libzmq/issues/comments/843181462,Problem: no downloads available for Windows builds,bluca,12,892749088,11,843181462,0,843091626,2021-05-18T13:40:52Z,"I'm not sure we can get it anymore, as it's encrypted for Travis - but I've created a new one and encrypted it for Appveyor, here it is:

```
vmAeVtN2qiQgFBCB2I5FDDRtADQ7GUdR9NwAJJyakbiV5OHzLHExDcC/D9Oh5r67
```",False,0,MEMBER
https://api.github.com/repos/zeromq/libzmq/issues/comments/843838364,Problem: no downloads available for Windows builds,minrk,12,892749088,12,843838364,0,843181462,2021-05-19T07:46:02Z,Thanks! #4192 should upload artifacts to releases now. You can see an example of its output [on my fork](https://github.com/minrk/libzmq/releases/tag/v4.3.3.post0),False,0,MEMBER
https://api.github.com/repos/zeromq/libzmq/issues/comments/843909405,Problem: no downloads available for Windows builds,bluca,12,892749088,13,843909405,0,843838364,2021-05-19T09:11:58Z,PR merged and binaries uploaded to https://github.com/zeromq/libzmq/releases/tag/v4.3.4 - thanks!,False,0,MEMBER
https://api.github.com/repos/zeromq/libzmq/issues/4194,CMake build on Linux does not export ZMQ_BUILD_DRAFT_API as a compile_definition with the target,datax1969,3,897609200,1,897609200,0,0,2021-05-21T02:01:49Z,"libzmq version = 4.3.4

* OS: 
Ubuntu 20.04 with cmake 3.16.3

Building with the following command after extracting the tarball and mkdir build; cd build.

cmake -D BUILD_SHARED=OFF -D ENABLE_CURVE=OFF -D ENABLE_DRAFTS=ON =WITH_LIBBSD=OFF -D WITH_LIBSODIUM=OFF ..
sudo make install

The FindPackage config module in /usr/local/lib/cmake/ZeroMQ has no mention of ZMQ_BUILD_DRAFT_API even though you now need it to use the cmake target libzmq-static.

I add the compile definition in my own CMakeLists.txt but the general idea of CMake is that I shouldn't need to.  This is further exacerbated when using cppzmq which also requires the definition.



",True,0,NONE
https://api.github.com/repos/zeromq/libzmq/issues/comments/845788301,CMake build on Linux does not export ZMQ_BUILD_DRAFT_API as a compile_definition with the target,bluca,3,897609200,2,845788301,0,897609200,2021-05-21T08:45:46Z,"It's exported in pkgconfig, you can use that instead. If you want something cmake specific, please send a PR to implement it.",False,0,MEMBER
https://api.github.com/repos/zeromq/libzmq/issues/comments/846647356,CMake build on Linux does not export ZMQ_BUILD_DRAFT_API as a compile_definition with the target,datax1969,3,897609200,3,846647356,0,845788301,2021-05-24T00:00:15Z,"The difficulty arises through a combination of two slightly different issues:
1) Building and installing using cmake has a different effect to building and installing using autconf/configure.  With a CMake build on Linux you get a pkgconfig.pc file and a ZeroMQConfig.cmake file installed in the correct places.  With autoconf/configure you only get the .pc file.
2) The .pc file correctly exports ZMQ_BUILD_DRAFT_API.  The .cmake file, if present, does not.  This also means that all Windows builds (where cmake is forced) will not export that define.

CMake does not have a tight integration between when finding packages using its own mechanisms or that provided by pkg-config.  cppzmq for instance tries first using find_package() and if that fails then falls back to the pkg-config method using pkg_check_modules().

So when I want to use libzmq in my project its much cleaner to know that either find_package() will work OR that I have to use the pkg-config method.

With Windows builds only supporting cmake and Windows not having pkg-config, I believe the proper multi-platform solution is to fix both these problems by ALWAYS installing ZeroMQConfig.cmake regardless of build method and fixing it to export the necessary #defines.

I can probably raise a PR to fix the ZeroMQConfig.cmake but autoconf is absolute black magic to me and I would not feel confident in doing this.",False,0,NONE
https://api.github.com/repos/zeromq/libzmq/issues/comments/846889312,CMake build on Linux does not export ZMQ_BUILD_DRAFT_API as a compile_definition with the target,bluca,3,897609200,4,846889312,0,846647356,2021-05-24T08:49:34Z,"We can't support cmake stuff in autotools, that's not supported upstream and just too much work to do these kind of bol-ons. It's cmake-specific stuff, so to keep maintenance overhead down it's better to leave it with cmake alone. Please do send a PR to fix the variable exporting if you can.",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/41743,BUG: groupby().agg( ) with min/max on Int64 leads to incorrect results,ppletscher,3,907469276,1,907469276,0,0,2021-05-31T13:23:49Z,"- [x ] I have checked that this issue has not already been reported.

- [x ] I have confirmed this bug exists on the latest version of pandas.

- [ ] (optional) I have confirmed this bug exists on the master branch of pandas.

---

#### Code Sample, a copy-pastable example

```python
import pandas as pd

ts = 1618556707013635762
pdf = pd.DataFrame([{""id"": 2, ""ts"": ts}, {""id"": 2, ""ts"": ts+1}])
pdf[""ts""] = pd.array(pdf[""ts""], dtype=""Int64"")
pdf.groupby(""id"").agg({""ts"": ""min""})

```

#### Problem description

The above code will output `1618556707013635840` as the minimum which is incorrect.

#### Expected Output

Minimum should be `1618556707013635762`. I suspect there is a cast happening somewhere during the aggregation.  If we keep the `ts` column at `int64` (i.e. use the non-nullable type) the result is as expected.


#### Output of ``pd.show_versions()``

<details>


INSTALLED VERSIONS
------------------
commit           : 2cb96529396d93b46abab7bbc73a208e708c642e
python           : 3.9.5.final.0
python-bits      : 64
OS               : Linux
OS-release       : 5.11.7-200.fc33.x86_64
Version          : #1 SMP Wed Mar 17 18:55:20 UTC 2021
machine          : x86_64
processor        : x86_64
byteorder        : little
LC_ALL           : 
LANG             : en_US.UTF-8
LOCALE           : en_US.UTF-8

pandas           : 1.2.4
numpy            : 1.20.3
pytz             : 2021.1
dateutil         : 2.8.1
pip              : 21.1.1
setuptools       : 56.0.0
Cython           : None
pytest           : None
hypothesis       : None
sphinx           : None
blosc            : None
feather          : None
xlsxwriter       : None
lxml.etree       : None
html5lib         : None
pymysql          : None
psycopg2         : None
jinja2           : None
IPython          : 7.24.0
pandas_datareader: None
bs4              : None
bottleneck       : None
fsspec           : None
fastparquet      : None
gcsfs            : None
matplotlib       : None
numexpr          : None
odfpy            : None
openpyxl         : None
pandas_gbq       : None
pyarrow          : None
pyxlsb           : None
s3fs             : None
scipy            : None
sqlalchemy       : None
tables           : None
tabulate         : None
xarray           : None
xlrd             : None
xlwt             : None
numba            : None

</details>

#### Potentially related issues


The issues below seem related, but from what I can see are slightly different:

* https://github.com/pandas-dev/pandas/issues/37494 seems like a more general problem where it is a priori unclear what the resulting `dtype` of the output column should be. For the `min` and `max` I would expect to get the same `dtype` as in the input column.
* https://github.com/pandas-dev/pandas/issues/41137 For the present issue we actually want to keep the original precision and not cast to float.",True,0,NONE
https://api.github.com/repos/pandas-dev/pandas/issues/comments/851503283,BUG: groupby().agg( ) with min/max on Int64 leads to incorrect results,jreback,3,907469276,2,851503283,0,907469276,2021-05-31T13:46:56Z,try this in master as pretty sure this is fixed,False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/851559969,BUG: groupby().agg( ) with min/max on Int64 leads to incorrect results,ppletscher,3,907469276,3,851559969,0,851503283,2021-05-31T15:27:17Z,"Thanks a lot for the quick reply.

I've just tried this inside a Docker build as described [here](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html#using-a-docker-container) and unfortunately I also see the same behaviour there.

`pd.show_versions()` shows the following:

```
INSTALLED VERSIONS
------------------
commit           : bc9b470711cd2126d0a834186103a4ea2215f7eb
python           : 3.8.10.final.0
python-bits      : 64
OS               : Linux
OS-release       : 5.11.7-200.fc33.x86_64
Version          : #1 SMP Wed Mar 17 18:55:20 UTC 2021
machine          : x86_64
processor        : x86_64
byteorder        : little
LC_ALL           : C.UTF-8
LANG             : C.UTF-8
LOCALE           : en_US.UTF-8

pandas           : 1.3.0.dev0+1766.gbc9b470711
numpy            : 1.20.3
pytz             : 2021.1
dateutil         : 2.8.1
pip              : 21.1.2
setuptools       : 49.6.0.post20210108
Cython           : 0.29.23
pytest           : 6.2.4
hypothesis       : 6.13.10
sphinx           : 3.5.4
blosc            : None
feather          : None
xlsxwriter       : 1.4.3
lxml.etree       : 4.6.3
html5lib         : 1.1
pymysql          : None
psycopg2         : None
jinja2           : 2.11.3
IPython          : 7.24.0
pandas_datareader: None
bs4              : 4.9.3
bottleneck       : 1.3.2
fsspec           : 2021.05.0
fastparquet      : 0.6.3
gcsfs            : 2021.05.0
matplotlib       : 3.4.2
numexpr          : 2.7.3
odfpy            : None
openpyxl         : 3.0.7
pandas_gbq       : None
pyarrow          : 4.0.0
pyxlsb           : None
s3fs             : 0.4.2
scipy            : 1.6.3
sqlalchemy       : 1.4.17
tables           : 3.6.1
tabulate         : 0.8.9
xarray           : 0.18.2
xlrd             : 2.0.1
xlwt             : 1.3.0
numba            : 0.53.1
```",False,0,NONE
https://api.github.com/repos/pandas-dev/pandas/issues/comments/851562086,BUG: groupby().agg( ) with min/max on Int64 leads to incorrect results,mzeitlin11,3,907469276,4,851562086,0,851559969,2021-05-31T15:31:36Z,"Thanks for trying this in master!  This cast was avoided for `cummin/max` in #40651, still needs to be done for `min/max`, xref #37493",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/41747,whatsnew 1.3.0,rhshadrach,15,907650269,1,907650269,0,0,2021-05-31T18:21:33Z,"- [x] Ensure all linting tests pass, see [here](https://pandas.pydata.org/pandas-docs/dev/development/contributing.html#code-standards) for how to run them

Minor fixups. After I get feedback here, I plan to make a PR with detailed instructions about adding to the whatsnew.

cc @attack68 - the Styler sections had a major revisions, wanted to get any feedback here.

cc @jorisvandenbossche @simonjayhawkins ",True,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/851779839,whatsnew 1.3.0,rhshadrach,15,907650269,2,851779839,0,907650269,2021-06-01T03:34:12Z,@jreback - agreed with all your suggestions above but would like to hold off and do in a followup to keep the diff here reasonable. I think it's okay for the changes to happen during the RC period (but won't be waiting for the RC period either),False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/851781033,whatsnew 1.3.0,rhshadrach,15,907650269,3,851781033,0,851779839,2021-06-01T03:38:13Z,"@attack68 - The performance improvement of the HTML rendering referenced #37792 but this is unrelated, not sure what issue/PR was meant. Also from the line

> - The method :meth:`.Styler.format` has been improved to easily format missing data, precision, and perform HTML escaping (:issue:`40437`, :issue:`40134`)

I think the ""format missing data"" is referring to #40134, but I can't find changes to na_rep there. Can you help me understand what changed?",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/852285933,whatsnew 1.3.0,attack68,15,907650269,4,852285933,0,851781033,2021-06-01T16:57:01Z,"> @attack68 - The performance improvement of the HTML rendering referenced #37792 but this is unrelated, not sure what issue/PR was meant. Also from the line
> 
> > * The method :meth:`.Styler.format` has been improved to easily format missing data, precision, and perform HTML escaping (:issue:`40437`, :issue:`40134`)
> 
> I think the ""format missing data"" is referring to #40134, but I can't find changes to na_rep there. Can you help me understand what changed?

there was a function called `Styler.set_na_rep()`, which set a property on `self` and the `format` method with an `na_rep` arg which conflicted at times. So, yes, it was there previously but it didn't always do what you thought. Now the missing data in `Styler` is handled exclusively and consistently by `Styler.format`, and `Styler.set_na_rep` is deprecated. 
",False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/852287635,whatsnew 1.3.0,attack68,15,907650269,5,852287635,0,852285933,2021-06-01T16:59:45Z,"> @attack68 - The performance improvement of the HTML rendering referenced #37792 but this is unrelated, not sure what issue/PR was meant. Also from the line

#39972 and #39952
",False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/852361219,whatsnew 1.3.0,jbrockmendel,15,907650269,6,852361219,0,852287635,2021-06-01T18:45:39Z,@rhshadrach there's a lot here.  id suggest breaking off the non-controversial bits into a precursor PR,False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/852364323,whatsnew 1.3.0,simonjayhawkins,15,907650269,7,852364323,0,852361219,2021-06-01T18:50:59Z,"> @rhshadrach there's a lot here. id suggest breaking off the non-controversial bits into a precursor PR

maybe start with the sphinx directive syntax errors, then another PR for the sphinx directives with broken links, then the grammer and then finally move stuff.",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/852364954,whatsnew 1.3.0,simonjayhawkins,15,907650269,8,852364954,0,852364323,2021-06-01T18:52:09Z,The first one (maybe 2) would be good for the rc,False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/852580637,whatsnew 1.3.0,rhshadrach,15,907650269,9,852580637,0,852364954,2021-06-02T00:08:34Z,"Going back on what I said in https://github.com/pandas-dev/pandas/pull/41747#issuecomment-851779839, I only plan to finish up this what's in this PR. I'll break it up as @simonjayhawkins recommended.",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/854957835,whatsnew 1.3.0,jbrockmendel,15,907650269,10,854957835,0,852580637,2021-06-04T19:37:11Z,@rhshadrach is more of this getting broken off or can you mark as Ready For Review?,False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/855178928,whatsnew 1.3.0,rhshadrach,15,907650269,11,855178928,0,854957835,2021-06-05T04:00:15Z,"@jbrockmendel - one last one (#41822).

The main reason for draft status is https://github.com/pandas-dev/pandas/pull/41747#discussion_r642758379. Currently the top section of styler duplicates many of the other notes in the whatsnew. Need to deduplicate and decide whether enhancements for the Styler should appear in the top enhancement section or as line items in the Other Enhancements (grouped together). Any thoughts here would be appreciated.

I think it is clear that bugfixes should go in the Styler bugfixes section and not in the top enhancement section.",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/855293318,whatsnew 1.3.0,rhshadrach,15,907650269,12,855293318,0,855178928,2021-06-05T20:42:15Z,"I've deduplicated the Styler notes and reorganized so that all enhancements are in `Enhancements` in their own section, while Performance, Deprecation, and Bugfix notes appear below in the appropriate sections.",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/856246318,whatsnew 1.3.0,rhshadrach,15,907650269,13,856246318,0,855293318,2021-06-07T20:47:19Z,"I can siphon off the Styler relevant pieces into a separate PR as well if that will make this easier to review. Let me know if that's desirable @simonjayhawkins, @jbrockmendel  (or anyone else)",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/856780324,whatsnew 1.3.0,simonjayhawkins,15,907650269,14,856780324,0,856246318,2021-06-08T13:43:48Z,@rhshadrach merge conflicts,False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/857623191,whatsnew 1.3.0,rhshadrach,15,907650269,15,857623191,0,856780324,2021-06-09T11:41:07Z,"Thanks @attack68 and @simonjayhawkins for the comments/requests, adjustments made and conflicts resolved.",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/857632753,whatsnew 1.3.0,simonjayhawkins,15,907650269,16,857632753,0,857623191,2021-06-09T11:57:41Z,Thanks @rhshadrach I think just @jreback comments about moving stuff to do in follow-up.,False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/41748,DOC: whatsnew format for minor enhancements/bug-fixes,rhshadrach,4,907703137,1,907703137,0,0,2021-05-31T20:33:56Z,"Admittedly this is extremely minor, but it's something that has always irked me. Currently for minor (single-line, not a section) enhancements and bug-fixes, we have the format:

> This is sentence one (GH28527)

which on its own is perfectly fine. However when a line has multiple sentences:

> This is sentence one. This is sentence two (GH28527)

the lack of a period at the end looks off to me. I'd prefer if we did full sentences for each line followed by the GH link at the end, this way a multi-sentence doesn't look so odd.

> This is sentence one. (GH28527)
> This is sentence one. This is sentence two. (GH28527)

Another option is to limit one-line notes to being a single sentence (which I'm opposed to), and of course we could  just stay with it as is. If we are to make any changes, I'd do it for the version minor/major version after 1.3.0.

cc @simonjayhawkins ",True,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/853582069,DOC: whatsnew format for minor enhancements/bug-fixes,attack68,4,907703137,2,853582069,0,907703137,2021-06-03T05:45:14Z,"when committing for first time I looked to copy this structure and I agree with you, albeit this is tiny.

what about:

> This is one issue (GH12345).
> This is another issue (GH23456). And a related component (GH34567).
> This is a fourth. And a final note (GH45678).


",False,0,CONTRIBUTOR
https://api.github.com/repos/pandas-dev/pandas/issues/comments/857351019,DOC: whatsnew format for minor enhancements/bug-fixes,rhshadrach,4,907703137,3,857351019,0,853582069,2021-06-09T03:53:20Z,"Thanks @attack68 - if two issues have different references to a GH issue/PR, then I think they should be separate line items, even if related.",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/1000950510,DOC: whatsnew format for minor enhancements/bug-fixes,jbrockmendel,4,907703137,4,1000950510,0,857351019,2021-12-25T00:16:25Z,"This is 100% not worth bikeshedding, but I often use a semicolon to avoid getting into the 2-sentence situation.",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/1000950535,DOC: whatsnew format for minor enhancements/bug-fixes,jbrockmendel,4,907703137,5,1000950535,0,1000950510,2021-12-25T00:16:51Z,is this actionable?,False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/41759,ENH: allow groupby (and drop_duplicates) on columns containing unhashable types,ezerkar,6,908215312,1,908215312,0,0,2021-06-01T11:57:47Z,"#### Is your feature request related to a problem?

well sort of, currently one can not groupby on a column containing unhashable types (e.g dicts)

#### Describe the solution you'd like

an easy workaround is to groupby on that column as type str and then remap the strings back to their orig type,
wondering if we can provide this process built in so one can groupby on unhashable types if she desires to 

#### Describe alternatives you've considered

add a try except to allow hash(str(x)) in case hash(x) is impossible, or convert the column to str and add it back later

```python
# Your code here, if applicable

```
",True,0,NONE
https://api.github.com/repos/pandas-dev/pandas/issues/comments/852138771,ENH: allow groupby (and drop_duplicates) on columns containing unhashable types,mzeitlin11,6,908215312,2,852138771,0,908215312,2021-06-01T13:47:23Z,"Thanks for the request @ezerkar! I'd be -1 on this - I think this would add considerable complexity for uncertain payoff. This sounds like a workaround better done on the user side - implicitly hashing mutable objects sounds like something which could lead to very confusing behavior. On the user side, you can make sure mutable objects aren't being mutated and breaking hash invariants. ",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/852347018,ENH: allow groupby (and drop_duplicates) on columns containing unhashable types,ezerkar,6,908215312,3,852347018,0,852138771,2021-06-01T18:22:12Z,"Thanks for your comment,
Let me disagree here, having mutable objects in df cells is possible (and explode, for instance, is designed for that specific situation) and [[1,2,3], [1,2,3]] are duplicates by all means, so why should someone expect an error when running drop_duplicates on a df that happens to have lists in one of its columns? 
I get that not being able to hash disturbs the regular implementation of groupby and it does make sense that having a mutables will cause delay, but I don't think it should raise an error.
At any rate please refer me to the duplicate

Thanks",False,0,NONE
https://api.github.com/repos/pandas-dev/pandas/issues/comments/852372456,ENH: allow groupby (and drop_duplicates) on columns containing unhashable types,mzeitlin11,6,908215312,4,852372456,0,852347018,2021-06-01T19:04:18Z,"> At any rate please refer me to the duplicate

That label just refers to the fact that this is related to `drop_duplicates` :)

> why should someone expect an error when running drop_duplicates on a df that happens to have lists in one of its columns?

I think this makes sense given that it is default python behavior, eg
```
>>> set([[1]])
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
TypeError: unhashable type: 'list'
```

I think hashing mutable objects might surprise users who have a mutable object in their frame by mistake (which a failure would make very clear). If the intent actually is to drop duplicates of something mutable, I think it makes for the user to have to explicitly define how the hashing should be done (eg by converting to string first)",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/852377608,ENH: allow groupby (and drop_duplicates) on columns containing unhashable types,mzeitlin11,6,908215312,5,852377608,0,852372456,2021-06-01T19:09:21Z,"(As a sidenote, if your use case is specifically in reference to better list support, this probably falls under the category of something which would probably be supported if we ever have a specific ListDType (xref https://github.com/pandas-dev/pandas/issues/35176))",False,0,MEMBER
https://api.github.com/repos/pandas-dev/pandas/issues/comments/852424987,ENH: allow groupby (and drop_duplicates) on columns containing unhashable types,ezerkar,6,908215312,6,852424987,0,852377608,2021-06-01T20:29:52Z,"Thanks for clarifying the label LOL
while I see your point, In my opinion since the basic logic of groupby/drop_duplicates does not necessarily include hashing it should not fail. At any rate, for the very least the documents should reflect this.
But I guess, if leaving the situation as is has its pros, we should not make any changes.",False,0,NONE
https://api.github.com/repos/pandas-dev/pandas/issues/comments/903036601,ENH: allow groupby (and drop_duplicates) on columns containing unhashable types,mroeschke,6,908215312,7,903036601,0,852424987,2021-08-21T02:01:37Z,"Thanks for the report, but agreed I would be -1 due the unexpected behavior as well and best if an external extension array could contain the logic to support this case. Closing since this enhancement request hasn't gotten support from the core team, but happy to reopen if there is revived interest",False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/4472,[Feature Request] Implement iLink capabilities,gtgamer468,25,907651890,1,907651890,0,0,2021-05-31T18:25:38Z,"**Description**
<!-- A concise description of the feature you want. --> I would like Firewire and iLink to be fully implemented.
<!-- Include step by step examples of how the feature should work under various circumstances. -->

**Reason**
<!-- Give a reason why you want this feature. --> The Firewire has always been a stub and never was implemented so to me, this seems long overdue. 
<!-- We are not accepting feature requests related to the libretro core as it's being maintained separately at this time. -->
<!-- How does this feature help your enjoyment of the emulator? --> The iLink feature was used in over a dozen titles, mostly first party ones such as Gran Turismo 3 and Concept and providing support for it would allow such games to be played like LAN titles paired with a VPN like Radmin.
<!-- What does it provide that isn't being provided currently? --> There's currently nothing in terms of support as iLink hasn't been implemented with any plugins in the past and the plugin system is going to be fully gone soon.
<!-- How will it make things easier for you? -->
",True,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/1033349904,[Feature Request] Implement iLink capabilities,RedDevilus,25,907651890,2,1033349904,0,907651890,2022-02-09T04:57:18Z,Could maybe need a new label like Firewire?,False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/1047848682,[Feature Request] Implement iLink capabilities,darkphoenixfox,25,907651890,3,1047848682,0,1033349904,2022-02-22T14:23:52Z,iLink support would be great to be able to play TIme Crisis 2 and Time Crisis 3 with 2 separate screens and 2 modern lightguns like the Sinden,False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/1188708599,[Feature Request] Implement iLink capabilities,Thigoron,25,907651890,4,1188708599,0,1047848682,2022-07-19T07:39:52Z,If this would be implemented I'd be making a twin arcade cabinet. ^^,False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/1228214273,[Feature Request] Implement iLink capabilities,shanethmoore,25,907651890,5,1228214273,0,1188708599,2022-08-26T08:31:28Z,"I actually thought this already existed in the wild https://youtu.be/-K6rgnaZoms

Was very surprised to see its not.

Does anyone have any ballpark of how difficult this will be to develop?",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/1228219589,[Feature Request] Implement iLink capabilities,refractionpcsx2,25,907651890,6,1228219589,0,1228214273,2022-08-26T08:36:20Z,"I call bullshit on that video.  Light guns don't work on LCD screens, and no, there's no iLink in PCSX2 right now.",False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/1228222340,[Feature Request] Implement iLink capabilities,Thigoron,25,907651890,7,1228222340,0,1228219589,2022-08-26T08:38:50Z,"> I call bullshit on that video. Light guns don't work on LCD screens, and no, there's no iLink in PCSX2 right now.


Sinden lightgun's are not ""true"" light guns. They do work on LCD's. Not sure how he ran the games in iLink tho'.

",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/1228223824,[Feature Request] Implement iLink capabilities,refractionpcsx2,25,907651890,8,1228223824,0,1228222340,2022-08-26T08:40:13Z,"oh they're custom light guns? okay.  Yeah I have no idea, we've never implemented ilink.",False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/1228239549,[Feature Request] Implement iLink capabilities,shanethmoore,25,907651890,9,1228239549,0,1228223824,2022-08-26T08:54:18Z,"@refractionpcsx2 I have 2 of the sinden guns with the recoil, gotta say they're pretty awesome. 

Its basically just a HID mouse with a webcam attached. Theres No IR sensors or CRT needed.

They come with software that paints a white bezel around the game window. Then theres a camera build into the gun which uses some trained model to detect where the sqaure is painted and then from that it determines where the mouse cursor should go.


That all said, I have no idea how the guy in that video managed to do what he's done. I've seen examples where people literally drag their pcsx2 instance halfway across two screens and then use a white border on each, but I don't think thats what he's doing here as he somehow managed to get P1's screen centered right in the middle of Monitor 0. It looks like he did some split screen magic.

Anywho, I was just asking if there were any sizes on how complex ilink would be to implement. If I recall it was some weird firewire cable that had a 6mbs limit. I expect that would be hard to replicate across two pcsx2 instances but I'm hoping someone will prove me wrong.",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/1228247470,[Feature Request] Implement iLink capabilities,darkphoenixfox,25,907651890,10,1228247470,0,1228239549,2022-08-26T09:02:56Z,"> I call bullshit on that video. Light guns don't work on LCD screens, and no, there's no iLink in PCSX2 right now.

That is _my_ video.

There is no iLink on PCSX2. That video was achieved by playing the single-console 2 Player mode and stretching the picture to fill two screens. Calibration for the guns didn't really work.

P1 is centered on the ultrawide screen because the screen was set up in Windows to a lower non-ultrawide resolution, but it's the trick @shanethmoore described.

[Sindens](https://www.sindenlightgun.com/) work on [any screen](https://www.youtube.com/watch?v=wZ8JQNxExNM) as stated above. 

I wish we didn't need to resort to alchemy-level tricks to get something like this working.",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/1228248407,[Feature Request] Implement iLink capabilities,refractionpcsx2,25,907651890,11,1228248407,0,1228247470,2022-08-26T09:03:57Z,That would explain it,False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/1228260112,[Feature Request] Implement iLink capabilities,shanethmoore,25,907651890,12,1228260112,0,1228248407,2022-08-26T09:14:52Z,"@darkphoenixfox Good to meet you man 👋  

Aye, calibration for TC2 has been a pain with Sindens. I'm doing some autoloading of state once the calibration is complete just to avoid going through it over and over. Tempted to try just using lilipad with a mouse instead of nuvee to see how it works.

You had comments disabled on YT so I wasn't able to ask how you did it. Indeed that is some top tier alchemy ☣️  
So your left hand screen has a narrower resolution than the monitor supports and thats how you got the 4:3 centered bezel. Clever. And your pcsx2 instance is probably windowed (as oppossed to maximized) and the application window header is hidden behind the sinden border.

Makes total sense now (if I've got that right)",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/1228268743,[Feature Request] Implement iLink capabilities,darkphoenixfox,25,907651890,13,1228268743,0,1228260112,2022-08-26T09:23:31Z,"@shanethmoore you are correct .
Don't want to derrail the thread; if you want to talk more about sindens,etc ask for JCT in the Sinden discord",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/1228270993,[Feature Request] Implement iLink capabilities,shanethmoore,25,907651890,14,1228270993,0,1228268743,2022-08-26T09:25:38Z,"Agreed!

So back on track, I still think Ilink support would be neat. Whats the best way for muggles and/or devs to support this?",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/1228288625,[Feature Request] Implement iLink capabilities,RedDevilus,25,907651890,15,1228288625,0,1228270993,2022-08-26T09:44:03Z,"> Agreed!
> 
> So back on track, I still think Ilink support would be neat. Whats the best way for muggles and/or devs to support this?

Foremost there has to be some interest in it, the knowledge and lastly the research in the protocols and how it differs from the normal FireWire if at all.

It's pretty niche all things considered and not many games support, and you can see nobody bothered making an iLink plugin besides null, but that's just a placeholder without any real functionality.

I can understand you making that simple inquiry but there isn't an easy and concise way to answer to finally get the support.",False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/1228312073,[Feature Request] Implement iLink capabilities,shanethmoore,25,907651890,16,1228312073,0,1228288625,2022-08-26T10:09:00Z,"Good to have a todo list, thanks @RedDevilus ",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/1228385156,[Feature Request] Implement iLink capabilities,ProfgLX,25,907651890,17,1228385156,0,1228312073,2022-08-26T11:36:05Z,"Hi, I'm an admin from the sinden discord. iLink (2 players time crisis 2 and 3) and lightgun support in pcsx2 are some of the most asked about subjects in the discord, which has 7400 members. Same for the users of gun4ir, another lightgun system. Niche yes, but very popular still. Love your work btw.",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/1228414756,[Feature Request] Implement iLink capabilities,titchgamer,25,907651890,18,1228414756,0,1228385156,2022-08-26T12:13:46Z,"Another Sinden/Gun4IR user here and can confirm what Prof says to be true.
Lightgun support for PCSX2 Is discussed daily in the discords along with 2 player options.

Time Crisis is a beloved franchise and one of the most popular requested games to be played.

if you can get easier gun support along with Ilink support you will make 1000’s of people very happy!!

",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/1228446792,[Feature Request] Implement iLink capabilities,shanethmoore,25,907651890,19,1228446792,0,1228414756,2022-08-26T12:48:16Z,"I mean I'd be happy to hit that sponsor button if I knew iLink was on the menu ;)

(I wonder if other discordians would feel the same. Only slightly kidding... I'll be more liquid in 2 months and can start contributing then anyways)",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/1228505165,[Feature Request] Implement iLink capabilities,stenzek,25,907651890,20,1228505165,0,1228446792,2022-08-26T13:41:26Z,"Nagging for it and saying how things like how many people are waiting isn't going to make it happen any faster.

The USB subsystem is a complete mess and needs a fairly large refactor before it can be added to Qt, let alone adding lightgun support. Personally it doesn't really interest me, so I'm not doing it, however anyone else is welcome to, and it would be appreciated.

But until someone takes it on, please stop effectively spamming the thread, it's not helpful at all.",False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/1228524334,[Feature Request] Implement iLink capabilities,shanethmoore,25,907651890,21,1228524334,0,1228505165,2022-08-26T13:57:53Z,"I think those people were just trying to make the case that theres more demand out there as initially thought rather than spamming or nagging. If theres more tangible things people can help with outside of sponsoring then that might be a more productive way to make this feature deliverable

I'm just trying to see whats required to make it happen. So far I've listed

- [x] USB subsystem refactor - Fixed with https://github.com/PCSX2/pcsx2/pull/7534
- [ ] Probably needs to come after 1.7 because the plugin system is going away
- [ ] Some sort of abstraction for interaction with the protocols for iLink

I think Lightgun support is probably out of scope. If mice work in 1.7+ then I imagine most HID compliant devices would too.

@stenzek Fair enough if it doesn't interest you. I'd love to take it on but I'm coming in blind. If you've any more comprehensive or high level lists TODO's to make this happen, please do let us know.

",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/1228773791,[Feature Request] Implement iLink capabilities,RedDevilus,25,907651890,22,1228773791,0,1228524334,2022-08-26T18:02:34Z,"I understand it's nice to have for a decent amount of people. From my point of view, most developers tend to do what they like to work on above the demands of people, not saying they can't align or users are ignored.",False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/1228780630,[Feature Request] Implement iLink capabilities,refractionpcsx2,25,907651890,23,1228780630,0,1228773791,2022-08-26T18:09:58Z,"It's worth noting that we *are* an open source project.  If somebody else wants to implement it, it's welcomed and very possible, you don't have to wait for us to do it.  Of course we will check the code when it's submitted, and we frown upon people just stealing other peoples code and committing it (This happens a lot more often than I would like), so please don't do that.",False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/1555941649,[Feature Request] Implement iLink capabilities,RageAShadey,25,907651890,24,1555941649,0,1228780630,2023-05-20T16:00:01Z,"*A wild Snake appears*
Seems Like a good test of my skills. I'm on it >:3",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/1809620482,[Feature Request] Implement iLink capabilities,jamesbailey999,25,907651890,25,1809620482,0,1555941649,2023-11-14T06:31:44Z,"Hi all,

I just wanted to resurrect this and to see if this is still being worked on as mentioned above?

Thanks for any update someone may give",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/1809683242,[Feature Request] Implement iLink capabilities,stenzek,25,907651890,26,1809683242,0,1809620482,2023-11-14T07:39:59Z,"Nothing has changed (nobody working on it, no plans), please don't bump/spam threads - it doesn't achieve anything.",False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/4473,[Feature Request] Dark Mode for PCSX2 UI,Hartwelg,4,909049845,1,909049845,0,0,2021-06-02T03:32:14Z,"**Description**
<!-- A concise description of the feature you want. -->
Dark mode for the PCSX2 UI. 
<!-- Include step by step examples of how the feature should work under various circumstances. -->
Dark mode would work over the whole UI. Every program window could be included in this change (options menus, console windows, main program window, configuration windows, etc.)
**Reason**
<!-- Give a reason why you want this feature. -->
This is a feature that seems to be missing from the PCSX2 UI. Dark mode would be great for those of us who like to use Dark mode UI features in other programs, and it would be helpful for those who do not want to use a bright UI that could be harsh on the eyes.
<!-- We are not accepting feature requests related to the libretro core as it's being maintained separately at this time. -->
<!-- How does this feature help your enjoyment of the emulator? -->
This feature would make the PCSX2 UI easier on the eyes for many users.
<!-- What does it provide that isn't being provided currently? -->
Dark mode currently does not seem to be implemented in the PCSX2 UI, and it is a common feature in other pieces of software.
<!-- How will it make things easier for you? -->

**Examples**
<!-- Provide examples of the feature as implemented by other software. -->
Dark mode is included in the Windows Explorer UI, Microsoft's Visual Studio IDE's, and even the Android UI. 
<!-- Include screenshots or video if you like to help demonstrate how you'd like this feature to work. -->
",True,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/852692743,[Feature Request] Dark Mode for PCSX2 UI,RedDevilus,4,909049845,2,852692743,0,909049845,2021-06-02T03:41:36Z,"This will likely have to wait till PCSX2 goes from WX/Winapi/GTK etc to QT.
Dark mode is currently limited only to the console/program log.",False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/870537603,[Feature Request] Dark Mode for PCSX2 UI,Squall-Leonhart,4,909049845,3,870537603,0,852692743,2021-06-29T12:07:59Z,"> This will likely have to wait till PCSX2 goes from WX/Winapi/GTK etc to QT.
> Dark mode is currently limited only to the console/program log.

Dark mode can be implemented on Wx in a few lines of code.",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/870624261,[Feature Request] Dark Mode for PCSX2 UI,F0bes,4,909049845,4,870624261,0,870537603,2021-06-29T13:57:29Z,"> > This will likely have to wait till PCSX2 goes from WX/Winapi/GTK etc to QT.
> > Dark mode is currently limited only to the console/program log.
> 
> Dark mode can be implemented on Wx in a few lines of code.

Could you pr this then?",False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/1122462741,[Feature Request] Dark Mode for PCSX2 UI,lightningterror,4,909049845,5,1122462741,0,870624261,2022-05-10T14:20:14Z,"Done on Qt, won't be done on wx.",False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/4475,IOP: Run the SPU at a consistent rate,Ziemas,5,909504291,1,909504291,0,0,2021-06-02T13:29:17Z,"I guess this is more of an RFC than a PR, but having this code here doesn't make much sense to me so let's figure out if it's still useful.

```
Run the SPU once per 768th IOP cycle. And stop adjusting the SPU's
target cycle in IopDma, doing this makes little sense the SPU2 is so eager
about running itself on interactions from the core.

If we need finer timing for DMA transfers we could just run the SPU2
more often than every 765th cycle, it should handle that fine as far as
I can tell.
```",True,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/853030876,IOP: Run the SPU at a consistent rate,refractionpcsx2,5,909504291,2,853030876,0,909504291,2021-06-02T13:32:11Z,"There's a bit of a problem with running every 768 cycles, that french game Titeuf Mega-compet' [SLES 52711] runs slow and stutters internally if you sync every 768 cycles, * 12 is fine, any less and it gets weird.

I had changed this back to 768 cycles earlier until I discovered it caused problems and I changed it back again.

So that needs to be solved before we can change this back.",False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/853033554,IOP: Run the SPU at a consistent rate,Ziemas,5,909504291,3,853033554,0,853030876,2021-06-02T13:35:31Z,"Ok, good to know. I'll check that out myself and see if I can figure anything out.",False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/993237960,IOP: Run the SPU at a consistent rate,ghost,5,909504291,4,993237960,0,853033554,2021-12-14T07:31:57Z,What is the status of this PR?,False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/993258422,IOP: Run the SPU at a consistent rate,refractionpcsx2,5,909504291,5,993258422,0,993237960,2021-12-14T08:05:51Z,I believe last it was touched Titeuf Mega-compet still had the stuttering issue with this.,False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/1242977536,IOP: Run the SPU at a consistent rate,lightningterror,5,909504291,6,1242977536,0,993258422,2022-09-11T14:31:38Z,Closing as it's not worked on atm.,False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/4476,Add PString,weirdbeardgame,12,909879807,1,909879807,0,0,2021-06-02T21:00:09Z,"### Description of Changes
<!-- Brief description or overview on what was changed in the PR -->
This PR adds a new common string lib PString that can currently handle UTF8 and UTF16 types

### Rationale behind Changes
<!-- Why were these changes made?  What problem does it solve / area does it improve? -->
To enable easier conversion and handling of all string types through the use of a common type handler

### Suggested Testing Steps
<!-- If applicable, including examples you've already tested with / recommendations for how to test further is very helpful! -->
Attempt use of string and wxString types to test string conversions and containment.",True,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/853379820,Add PString,weirdbeardgame,12,909879807,2,853379820,0,909879807,2021-06-02T21:01:21Z,"Note I've experimented with use between const char* and basic string types here

basic_string: https://github.com/kenshen112/pcsx2-string/commit/fe97d84ea02466cd1a87c6c974d86315ab389382
const char*: https://github.com/kenshen112/pcsx2-string/commit/c13034eeacf9966df19b03cc56d111cc6a04c890",False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/853381259,Add PString,weirdbeardgame,12,909879807,3,853381259,0,853379820,2021-06-02T21:03:58Z,Currently tested functionality: https://hatebin.com/vswpjetubl,False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/874685978,Add PString,CookiePLMonster,12,909879807,4,874685978,0,853381259,2021-07-06T11:37:26Z,"Consider adding a `PString(std::string str)` constructor that *moves* `str` to the class. Also consider replacing a `const char*` constructor with `std::string_view`, as it can do everything a plain char pointer constructor could do and more (gives the user an option to construct a string with a known length).",False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/874815879,Add PString,weirdbeardgame,12,909879807,5,874815879,0,874685978,2021-07-06T14:34:55Z,"> Looking at all these review remarks, I believe this PR could work better as a set of conversion functions instead of a string wrapper, like:
> 
>     * `ToWxString`
> 
>     * `FromWxString`
> 
>     * `ToWString`
> 
>     * `FromWString`

The idea behind this PR was to make a full assed string class rather than a plain set of functions to make copying data or even just using it as a string itself easier / possible. Originally I had a char* base and was doing the memory management myself. That turned into this. plus for functions like that we also have. https://github.com/PCSX2/pcsx2/pull/4361 and https://github.com/PCSX2/pcsx2/pull/4005 which implements them",False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/874833231,Add PString,CookiePLMonster,12,909879807,6,874833231,0,874815879,2021-07-06T14:55:46Z,"> The idea behind this PR was to make a full assed string class rather than a plain set of functions to make copying data or even just using it as a string itself easier / possible.

The fact you ended up with essentially a thin wrapper around `std::string` makes me think the thing you really need is a set of well defined conversion functions operating on `string/wstring/wxString`.",False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/875308999,Add PString,TellowKrinkle,12,909879807,7,875308999,0,874833231,2021-07-07T06:02:00Z,"> The fact you ended up with essentially a thin wrapper around `std::string` makes me think the thing you really need is a set of well defined conversion functions operating on `string/wstring/wxString`.

I think the main thing I would want is a string type where the conversions to other types that most people would expect to be able use don't do anything dumb.  We currently use ""UTF-8 in a `std::string`"" and it has the following issues:

1. `std::string` ↔︎ `fs::path` currently works fine, but if we ever switch to `std::filesystem::path`, it will assume all `std::string`s are not UTF-8.  Since `std::string` is not our type, we have no say in this
2. `std::string` ↔︎ `wxString` is an implicit conversion and once again assumes `std::string`s are not UTF-8.  We have some control over this one, since we currently bundle our own copy of WX and could edit it, but it's still kind of messy
3. Other stdlib functions (like `std::iostream`) assume `std::string` is not UTF-8.  Less of an issue because we will hopefully be using `fs::path`s with them in the future, but the temptation will continue to exist.

In fact there already are well defined conversion functions operating on `wxString`.  There's `wxString::FromUTF8()` and `wxString::utf8_string()` built into wx.  But clearly the implicit conversions are just too easy to accidentally use, because we still have plenty of places where we use them.  We need to stop using types whose encoding isn't agreed on by everyone.  We could use `std::u8string` in C++20, but personally, I like having implicit conversions to other string types when possible, and it has zero.  Won't even have explicit conversions, we'll need helper methods for literally everything.  Also we're not on C++20 yet.

As for conversions, my preferences:
- `wxString`, `QString`: Implicit.  No chances of data loss or corruption in this conversion
- `std::u8string`: Implicit.  Like above, no chances of data loss or corruption in this conversion
- `std::wstring`: Implicit, Windows only.  No chance of data loss, but no one uses wstring/wchar_t outside of Windows.
- `std::string`: Not sure.  The other conversions will prevent (1) and (2) above leaving just (3).  I expect a lot of our interaction with `std::string` will actually be in file IO (e.g. yaml reading, etc), which will actually be UTF-8.  For now I'd go explicit and see how annoying that gets.  Add a `.u8()` method too, for easier conversion at least in one direction.  We'll probably also want a `.mb()` method to convert to platform encoding, for libraries that were designed for unix and don't support wchars (like chd).
- `fs::path`: Explicit.  Paths and strings should be treated separately.

Not sure how I feel about the `const char*` constructor for the same reason.  Maybe if you add a custom string literal operator we can continue to use string literals without having to have an implicit conversion from `const char*`",False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/875391897,Add PString,CookiePLMonster,12,909879807,8,875391897,0,875308999,2021-07-07T08:14:33Z,"> As for conversions, my preferences:

While I generally don't disagree with these preferences, both conversions to wx/Qt types and `wstring` should be as rare as possible and so I don't see the need to make them implicit. Implicit conversion also has a potential side effect of the programmer unknowingly converting the strings more than it is needed.



> Not sure how I feel about the `const char*` constructor for the same reason.

I think the way wx/Qt solves this issue (static creation methods) is quite sensible - `PcsxString::FromUTF8(char_array);` is very consise and obvious, `PcsxString(char_array);` requires the programmer to be aware of UTF-8 behaviour.



> 1. `std::string` ↔︎ `fs::path` currently works fine, but if we ever switch to `std::filesystem::path`, it will assume all `std::string`s are not UTF-8.

I thought `ghc::filesystem` is supposed to be a drop-in replacement for `std::filesystem`? That is kind of worrying then.

---------------------------------------------------------------

I think I understand the need for a string type better now, then. In this case I believe it might be best to make this type as much of a thin wrapper as possible, and maybe expose a `const std::string& str() const { return m_stdString; }` method instead of forwarding half of the API to it? I think it might be a good idea to make such a type immutable, i.e. narrow it down to a set of constructors, conversion functions and a read-only UTF-8 getter. ",False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/876421024,Add PString,gulrak,12,909879807,9,876421024,0,875391897,2021-07-08T13:03:24Z,"> > 1. `std::string` ↔︎ `fs::path` currently works fine, but if we ever switch to `std::filesystem::path`, it will assume all `std::string`s are not UTF-8.
> 
> I thought `ghc::filesystem` is supposed to be a drop-in replacement for `std::filesystem`? That is kind of worrying then.

Just to clarify this: `ghc::filesystem` is developed as a drop-in replacement of `std::filesystem` and starting with 1.5.x, where the Windows backend is using `std::wstring` it came as close at it might get to that target. Still, it is an utf8-everywhere philosophy approach and I say so in the docs. What that means in respect to `std::filesystem` from C++17 is, that in `std::filesystem` std::string interfaces are the expected to be in the current locale and if that is an UTF-8 type of locale than both behave the same. If instead the current locale encoding is non-UTF-8 based then the behavior is different and only the explicit interfaces (`fs::u8path()` and `fs::path::u8string()`) are exactly behaving the same. `ghc::filesystem` contains no locale handling that is able to handle anything else than UTF-8 for `std::string` (besides 7-bit clean ASCII of course, as that is a subset).

All this is made to make Windows/Linux/macOS portable development as easy as possible and works in multiple projects with mixed `std::filesystem`/`ghc::filesystem` depending on the OS and compiler available on the target (e.g. all Win-API calls should be the W-Version and simply use `p.c_str()` _not `p.wstring().cstr()`_ as the parameter to ensure that even non-utf-8 supporting Windows-Version versions work well with international characters) and as long as you stick to UTF-8-locales or use the explicit interfaces into and from `fs::path` everything works the same when switching to `std::filesystem` (besides the differences between the existing `std::filesystem` implementations that is ;-)).

I admit that this approach might not be perfect or fitting for every project. I just want to make clear where the differences are and I'm sorry, if that might be an issue and was not clear enough from the readme.
",False,0,NONE
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/876428937,Add PString,CookiePLMonster,12,909879807,10,876428937,0,876421024,2021-07-08T13:13:52Z,"> I admit that this approach might not be perfect or fitting for every project. I just want to make clear where the differences are and I'm sorry, if that might be an issue and was not clear enough from the readme.

From what you say `ghc::filesystem` is behaving as expected regardless, and any assumptions about `fs::path` being UTF-8 at all times (without using `u8path`) are dangerous as they're relying on an implementation detail.",False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/890904948,Add PString,Mrlinkwii,12,909879807,11,890904948,0,876428937,2021-08-02T10:14:14Z,"you seem to be updating libchdr  , that that intended  :confused: ?",False,0,CONTRIBUTOR
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/890912088,Add PString,tadanokojin,12,909879807,12,890912088,0,890904948,2021-08-02T10:24:19Z,"Not an upgrade, downgrade. He needed to run `git submodule update` and instead committed the change.",False,0,MEMBER
https://api.github.com/repos/PCSX2/pcsx2/issues/comments/987533605,Add PString,TellowKrinkle,12,909879807,13,987533605,0,890912088,2021-12-07T03:25:00Z,"After discussion with other team members, we finally decided that the best solution to the problems this PR solves would be to stay away from `std::filesystem` and continue to use `ghc::filesystem` for the foreseeable future.

Maybe in the future we can migrate the whole codebase to `std::u8string`, but I wouldn't consider that high priority (especially since C++20 has to come first).",False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/20388,Radial grid missing in polar plots with ax.set_theta_direction(-1) and ax.set_theta_zero_location,olehy,3,914898486,1,914898486,0,0,2021-06-08T11:45:28Z,"When creating a polar plot with inverted theta direction and modifying the location of zero, the radial grid and outer boundary are missing for some locations of zero.

```python
import numpy as np
import matplotlib.pyplot as plt

r = np.arange(0, 2, 0.01)
theta = 2 * np.pi * r

fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})
ax.plot(theta, r)

ax.set_theta_direction(-1)

angle = 10 # 20 is not working, 10 is working
ax.set_theta_zero_location(""N"",angle) 
plt.savefig('expected-outcome.png')

angle = 20 # 20 is not working, 10 is working
ax.set_theta_zero_location(""N"",angle) 
plt.savefig('actual-outcome.png')
```
This is the outcome (can be reproduced with angle=20):
![actual-outcome](https://user-images.githubusercontent.com/29770911/121178497-d4f15980-c85e-11eb-8150-6b8a2f2cd40a.png)

And this is what it should look like (can be reproduced with angle=10):
![expected-outcome](https://user-images.githubusercontent.com/29770911/121178520-da4ea400-c85e-11eb-8e98-6b84e705746f.png)

```python
import matplotlib
print(matplotlib.__version__)
import platform
print(platform.python_version())
3.4.2
3.9.2
```

When I go back to matplotlib release v3.2.2 I don't have this issue.

",True,0,NONE
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/858118996,Radial grid missing in polar plots with ax.set_theta_direction(-1) and ax.set_theta_zero_location,timhoffm,3,914898486,2,858118996,0,914898486,2021-06-09T21:36:24Z,This is a regression since v3.3.0.,False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/858133227,Radial grid missing in polar plots with ax.set_theta_direction(-1) and ax.set_theta_zero_location,anntzer,3,914898486,3,858133227,0,858118996,2021-06-09T22:06:08Z,"This bisects to 73a763a and basically arises from the fact that PolarTransform needs to try to undo Path.arc's ""helpful"" behavior of unwrapping angles before generating a path (i.e. `Path.arc(0, 360+180)` generates a half-turn path, not one-and-a-half-turns, but PolarTransform actually wants to generate one-and-a-half-turn), but the ""is that a full turn"" check is different between PolarTransform and Path.arc, so in the specific case here, PolarTransform wants asks Path.arc to generate an arc going from -250.000000eps° to +110°, and Path.arc says, oh, that's actually going from +109.9999999eps to +110°, and generates basically a trivial (near empty) path.
```patch
diff --git i/lib/matplotlib/projections/polar.py w/lib/matplotlib/projections/polar.py
index db34dbfcfe..69e68cd147 100644
--- i/lib/matplotlib/projections/polar.py
+++ w/lib/matplotlib/projections/polar.py
@@ -72,7 +72,7 @@ class PolarTransform(mtransforms.Transform):
                         r = ((r - self._axis.get_rorigin())
                              * self._axis.get_rsign())
                     if last_td <= td:
-                        while td - last_td > 360:
+                        while td > last_td + 360:
                             arc = Path.arc(last_td, last_td + 360)
                             xys.extend(arc.vertices[1:] * r)
                             codes.extend(arc.codes[1:])
@@ -83,7 +83,7 @@ class PolarTransform(mtransforms.Transform):
                     else:
                         # The reverse version also relies on the fact that all
                         # codes but the first one are the same.
-                        while last_td - td > 360:
+                        while last_td > td + 360:
                             arc = Path.arc(last_td - 360, last_td)
                             xys.extend(arc.vertices[::-1][1:] * r)
                             codes.extend(arc.codes[1:])
```
appears to fix the case shown above(!), but may well introduce the same floating point errors in other cases, and I think a correct fix requires either careful consideration of floating point handling, or perhaps more simply introducing a variant on Path.arc() that doesn't unwrap angles first.",False,0,CONTRIBUTOR
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/858138836,Radial grid missing in polar plots with ax.set_theta_direction(-1) and ax.set_theta_zero_location,timhoffm,3,914898486,4,858138836,0,858133227,2021-06-09T22:18:24Z,"> or perhaps more simply introducing a variant on Path.arc() that doesn't unwrap angles first.

Simplest solution seems to be introducing a flag `Path.arc(..., unwrap_angles=True)`.",False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/20389,shrink argument in matplotlib.patches.annotate does not exist in FancyArrow,Martititi,4,915042919,1,915042919,0,0,2021-06-08T13:17:33Z,"Hi,
### Problem

The documentation here:
https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.annotate.html
suggests that you can use a ""shrink"" argument in a dictionary arrowprops containing options for drawing the FancyArrowPath.
However, it looks like it doesn't exist anymore and has been replaced by shrinkA and shrinkB, as documented here:
https://matplotlib.org/stable/api/_as_gen/matplotlib.patches.FancyArrowPatch.html#matplotlib.patches.FancyArrowPatch

### Suggested Improvement
Instead of writing shrink, maybe you can write shrinkA and shrinkB in the matplotlib.pyplot.annotate.html

**Matplotlib version**
  * Matplotlib documentation version (is listed under the logo): v3.4.2-2-gf801f04d09-dirty.
I see it's written dirty, I hope I'm on the right documentation haha ^^


Have a good one!
M.D.",True,0,NONE
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/856771180,shrink argument in matplotlib.patches.annotate does not exist in FancyArrow,jklymak,4,915042919,2,856771180,0,915042919,2021-06-08T13:32:36Z,Shrink is a shortcut.  ShrinkA and shrinkB are described lower down in the annotate doc.  Did you try using shrink and it didn't work?  ,False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/856778761,shrink argument in matplotlib.patches.annotate does not exist in FancyArrow,Martititi,4,915042919,3,856778761,0,856771180,2021-06-08T13:41:55Z,"I see. Indeed, I didn't see shinkA/B in there.


Yes, I used shrink, but I got this:
AttributeError: 'FancyArrowPatch' object has no property 'shrink'",False,0,NONE
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/856781407,shrink argument in matplotlib.patches.annotate does not exist in FancyArrow,Martititi,4,915042919,4,856781407,0,856778761,2021-06-08T13:45:06Z,"Nevermind, I didn't read well enough.
It's written shrink is forbidden in case I use the arrowstyle argument.

Sorry for the time spent here, and thank you for your work.",False,0,NONE
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/856781411,shrink argument in matplotlib.patches.annotate does not exist in FancyArrow,jklymak,4,915042919,5,856781411,0,856781407,2021-06-08T13:45:06Z,Please provide more details how you got that error.  Shrink is only a valid key for the dict passed to arrowprops on the annotate method.  If that is not working that is a bug.  ,False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/20390,Cleanup arrow_demo.,anntzer,7,915082033,1,915082033,0,0,2021-06-08T13:56:34Z,"- Skip unnecessary numbered_bases_to_rates, lettered_bases_to_rates.
- Don't use pyplot, but pass axes to make_arrow_plot.
- letter colors only depend on the start point, not the end point.
- Don't hard-code coordinates of arrows, but compute them from the
  letter coordinates.
- Only include one dataset.
- Directly show all three possibilities (length, width, alpha).
- head_starts_at_zero=True resulted in incorrect alignment e.g. when
  calling `arrow_demo.py realistic length` previously; one should use
  the default value of head_starts_at_zero=False.

Before, when called with arguments `realistic length` (note the completely incorrect alignment):
![old](https://user-images.githubusercontent.com/1322974/121197529-acbf2600-c871-11eb-9d39-60262691e8ea.png)
After:
![new](https://user-images.githubusercontent.com/1322974/121197543-ae88e980-c871-11eb-86c4-9fc25230e8ed.png)

## PR Summary

## PR Checklist

<!-- Please mark any checkboxes that do not apply to this PR as [N/A]. -->

- [ ] Has pytest style unit tests (and `pytest` passes).
- [ ] Is [Flake 8](https://flake8.pycqa.org/en/latest/) compliant (run `flake8` on changed files to check).
- [ ] New features are documented, with examples if plot related.
- [ ] Documentation is sphinx and numpydoc compliant (the docs should [build](https://matplotlib.org/devel/documenting_mpl.html#building-the-docs) without error).
- [ ] Conforms to Matplotlib style conventions (install `flake8-docstrings` and run `flake8 --docstring-convention=all`).
- [ ] New features have an entry in `doc/users/next_whats_new/` (follow instructions in README.rst there).
- [ ] API changes documented in `doc/api/next_api_changes/` (follow instructions in README.rst there).

<!--
Thank you so much for your PR!  To help us review your contribution, please
consider the following points:

- A development guide is available at https://matplotlib.org/devdocs/devel/index.html.

- Help with git and github is available at
  https://matplotlib.org/devel/gitwash/development_workflow.html.

- Do not create the PR out of master, but out of a separate branch.

- The PR title should summarize the changes, for example ""Raise ValueError on
  non-numeric input to set_xlim"".  Avoid non-descriptive titles such as
  ""Addresses issue #8576"".

- The summary should provide at least 1-2 sentences describing the pull request
  in detail (Why is this change required?  What problem does it solve?) and
  link to any relevant issues.

- If you are contributing fixes to docstrings, please pay attention to
  http://matplotlib.org/devel/documenting_mpl.html#formatting.  In particular,
  note the difference between using single backquotes, double backquotes, and
  asterisks in the markup.

We understand that PRs can sometimes be overwhelming, especially as the
reviews start coming in.  Please let us know if the reviews are unclear or
the recommended next step seems overly demanding, if you would like help in
addressing a reviewer's comments, or if you have been waiting too long to hear
back on your PR.
-->
",True,0,CONTRIBUTOR
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/857167514,Cleanup arrow_demo.,QuLogic,7,915082033,2,857167514,0,915082033,2021-06-08T21:25:55Z,"It seems like the text size has some meaning, but it also appears that only $C_3$ is any different. I wonder if there's any point to sizing those?",False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/857497053,Cleanup arrow_demo.,anntzer,7,915082033,3,857497053,0,857167514,2021-06-09T08:28:09Z,"Re: text size: actually they're all differently sized, but the difference is a bit subtle.  I increased the size of G to improve contrast (actually the sizes should probably be given by an eigenvector of the transition matrix, but let's not get there).",False,0,CONTRIBUTOR
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/857719875,Cleanup arrow_demo.,timhoffm,7,915082033,4,857719875,0,857497053,2021-06-09T14:00:51Z,"> Directly show all three possibilities (length, width, alpha).

This is rather confusing without further context. I'm not convinced that this option is useful at all. It's definition and impelmentation are quite far apart. It complicates the code. And Having three different axes without any explanation is rather confusing.

I did not dig into the implementation, but I have the impression the author got carried away with making a fancy visualization, and the extra code obscures the actual demonstration of arrow usage. Possibly this should have been something much simpler in the first place.

I don't require to rewrite this whole thing, but as an incremental change

- either ditch the display variants alltogether
- or if you want to show all, write a sentence in the description that the different axes show certain variations in parameters and add titles ""length modified"", ""width modified"", ""alpha modified"" or similar.",False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/857768510,Cleanup arrow_demo.,anntzer,7,915082033,5,857768510,0,857719875,2021-06-09T14:56:59Z,"I extended the description at the axes corner to ""flux encoded as arrow {length,width,alpha}"".  I guess this may be a bit domain-specific but I thought that the example use case was actually quite clear.",False,0,CONTRIBUTOR
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/857854570,Cleanup arrow_demo.,timhoffm,7,915082033,6,857854570,0,857768510,2021-06-09T16:35:17Z,"> may be a bit domain-specific

Is *a bit* of an understatement. I did not have any clue that the arrows were fluxes. And I still don't have any idea what this diagram shows - which in itself is not a problem because all I want to learn is how to draw arrows. But the description doesn't really help much.

I have the impression that this example is more of the ""show fancy plot"" category similar to 
https://matplotlib.org/stable/gallery/lines_bars_and_markers/horizontal_barchart_distribution.html or https://matplotlib.org/stable/gallery/showcase/bachelors_degrees_by_gender.html
and not primarily an ""Arrow Demo"".

If this is some kind of standard domain specific plot, I suggest to rewrite the description to

```
[domain specific plot name]
===========================

This example illustrates how one can encode flux densities in [domian specific plot name]
using different `~.Axes.arrow` properties like, length, width or transparency.""
```",False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/859121844,Cleanup arrow_demo.,anntzer,7,915082033,7,859121844,0,857854570,2021-06-10T22:26:12Z,"I went mostly for @jklymak's suggestion, also mentioning that this can be used e.g. for Markov models (which is what I think this likely represented).  You can find Markov model graphs on google, although most of them just write the numbers next to the arrows without varying arrow width/height/alpha (but that's likely just for simpler drawing...).",False,0,CONTRIBUTOR
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/859137280,Cleanup arrow_demo.,jklymak,7,915082033,8,859137280,0,859121844,2021-06-10T22:55:11Z,Anyone can merge after CI passes...  I'll open #20409 an issue tracking the concerns with this being overly specialized...,False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/20391,Type42 subsetting in PS/PDF,aitikgupta,34,915102608,1,915102608,0,0,2021-06-08T14:16:19Z,"## PR Summary
This PR is a fresh rebase from https://github.com/matplotlib/matplotlib/pull/18143.

- Adds a dependency: [`fonttools`](https://github.com/fonttools/fonttools) to handle font subsetting for us
  (we already have an external ttconv dependency, which does not handle subsetting)
- Interfaces a `getSubset` utility to get file-like objects containing subsetted font data

Possibly fixes https://github.com/matplotlib/matplotlib/issues/11303 (large file sizes)
Fixes https://github.com/matplotlib/matplotlib/issues/18191.

## PR Checklist

<!-- Please mark any checkboxes that do not apply to this PR as [N/A]. -->

- [ ] Has pytest style unit tests (and `pytest` passes).
- [x] Is [Flake 8](https://flake8.pycqa.org/en/latest/) compliant (run `flake8` on changed files to check).
- [ ] New features are documented, with examples if plot related.
- [x] Documentation is sphinx and numpydoc compliant (the docs should [build](https://matplotlib.org/devel/documenting_mpl.html#building-the-docs) without error).
- [x] Conforms to Matplotlib style conventions (install `flake8-docstrings` and run `flake8 --docstring-convention=all`).
- [ ] New features have an entry in `doc/users/next_whats_new/` (follow instructions in README.rst there).
- [ ] API changes documented in `doc/api/next_api_changes/` (follow instructions in README.rst there).

<!--
Thank you so much for your PR!  To help us review your contribution, please
consider the following points:

- A development guide is available at https://matplotlib.org/devdocs/devel/index.html.

- Help with git and github is available at
  https://matplotlib.org/devel/gitwash/development_workflow.html.

- Do not create the PR out of master, but out of a separate branch.

- The PR title should summarize the changes, for example ""Raise ValueError on
  non-numeric input to set_xlim"".  Avoid non-descriptive titles such as
  ""Addresses issue #8576"".

- The summary should provide at least 1-2 sentences describing the pull request
  in detail (Why is this change required?  What problem does it solve?) and
  link to any relevant issues.

- If you are contributing fixes to docstrings, please pay attention to
  http://matplotlib.org/devel/documenting_mpl.html#formatting.  In particular,
  note the difference between using single backquotes, double backquotes, and
  asterisks in the markup.

We understand that PRs can sometimes be overwhelming, especially as the
reviews start coming in.  Please let us know if the reviews are unclear or
the recommended next step seems overly demanding, if you would like help in
addressing a reviewer's comments, or if you have been waiting too long to hear
back on your PR.
-->
",True,0,CONTRIBUTOR
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/858952185,Type42 subsetting in PS/PDF,lumberbot-app[bot],34,915102608,2,858952185,0,915102608,2021-06-10T19:25:33Z,"I'm Mr. Meeseek, @aitikgupta, Look at meee ! ",False,0,NONE
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/860179401,Type42 subsetting in PS/PDF,aitikgupta,34,915102608,3,860179401,0,858952185,2021-06-13T09:14:41Z,"The last commit subsets and embeds Type 42 PS/EPS, here's the size difference in outputs:

```
nosub-dejavu.ps                ----> 1.2 MB
sub-dejavu.ps                  ----> 8.5 kB
```

(To test it out on your machine, apply this patch for `nosub-dejavu.ps`:)
```diff
diff --git a/lib/matplotlib/backends/backend_ps.py b/lib/matplotlib/backends/backend_ps.py
index 2a3ab64a1c..ed0af4ea85 100644
--- a/lib/matplotlib/backends/backend_ps.py
+++ b/lib/matplotlib/backends/backend_ps.py
@@ -997,12 +997,8 @@ class FigureCanvasPS(FigureCanvasBase):
                             ) as tmp:
                                 tmp.write(fontdata)
                                 tmp.seek(0, 0)
-                                font = FT2Font(tmp.name)
-                                glyph_ids = [
-                                    font.get_char_index(c) for c in chars
-                                ]
                                 convert_ttf_to_ps(
-                                    os.fsencode(tmp.name),
+                                    os.fsencode(font_path),
                                     fh,
                                     fonttype,
                                     glyph_ids,
```

The script:
```python
import matplotlib.pyplot as plt

plt.rcParams[""ps.fonttype""] = 42
plt.figtext(0.5, 0.5, ""hello"")
# plt.savefig('sub-dejavu.ps')                    # before applying the patch
# plt.savefig('nosub-dejavu.ps')                  # after applying the patch
```
",False,0,CONTRIBUTOR
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/864287173,Type42 subsetting in PS/PDF,aitikgupta,34,915102608,4,864287173,0,860179401,2021-06-18T21:38:20Z,"> https://github.com/matplotlib/matplotlib/pull/20391#discussion_r653337251: This appears to require testing.

I think it's difficult to test `get_glyphs_subset`, since it really depends on font files, and if we chose certain characters to test with a fixed font (lets say), there's no guarantee that the subset will be the same for different versions of the library.

Is there any other way to test this?

edit: @jklymak this isn't a draft anymore, just needed to address review comments 😄 ",False,0,CONTRIBUTOR
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/864290605,Type42 subsetting in PS/PDF,jklymak,34,915102608,5,864290605,0,864287173,2021-06-18T21:48:49Z,You can mark as ready-to-review at any point.  I just kick things to Draft so they don't show up in the queue if the PR requires action on the part of the author.  (this one is still not passing the tests). ,False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/864292146,Type42 subsetting in PS/PDF,aitikgupta,34,915102608,6,864292146,0,864290605,2021-06-18T21:54:03Z,"> (this one is still not passing the tests).

Yeah, CI isn't installing fonttools, which is why `NoModuleFound` is all over the place (even after adding it to `minvers.txt`: https://github.com/matplotlib/matplotlib/pull/20391#discussion_r654688358)",False,0,CONTRIBUTOR
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/864329097,Type42 subsetting in PS/PDF,QuLogic,34,915102608,7,864329097,0,864292146,2021-06-19T00:26:18Z,"Install is done with `--no-deps`, so hard dependencies also need to be listed here: https://github.com/matplotlib/matplotlib/blob/master/.github/workflows/tests.yml#L148 `minver.txt` is only a _constraint_ on versions.",False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/864329718,Type42 subsetting in PS/PDF,QuLogic,34,915102608,8,864329718,0,864329097,2021-06-19T00:29:58Z,"> I think it's difficult to test `get_glyphs_subset`, since it really depends on font files, and if we chose certain characters to test with a fixed font (lets say), there's no guarantee that the subset will be the same for different versions of the library.

We ship DejaVu ourselves, so that should always be available for testing.
 
> Is there any other way to test this?

A file with just 'A' embedded should be smaller than one with the full alphabet, say?
Also, a subsetted PDF should appear the same as one without subsetting (assuming Ghostscript doesn't happen to substitute the same glyphs.)",False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/864450964,Type42 subsetting in PS/PDF,aitikgupta,34,915102608,9,864450964,0,864329718,2021-06-19T19:07:18Z,"> A file with just 'A' embedded should be smaller than one with the full alphabet, say?

Oh, if we just test the subset being 'smaller' yeah we can do it, but not with the exact number glyphs, since that will definitely vary. (we also set `recommeded_glyphs`=True)

But even so, isn't that the 'full-time job' of the fonttools library itself? or in other words wouldn't testing the `get_glyphs_subset` function be the same as testing the library itself (that it does reduce the number of glyphs)?",False,0,CONTRIBUTOR
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/866905954,Type42 subsetting in PS/PDF,jkseppan,34,915102608,10,866905954,0,864450964,2021-06-23T14:50:38Z,"Oh, and one more thing (sorry for not remembering this earlier): the [PDF specification](https://www.adobe.com/content/dam/acom/en/devnet/pdf/pdfs/PDF32000_2008.pdf) has some extra requirements for font subsets in section 9.6.4. The PostScript name of subsetted fonts needs to have a prepended tag of six random uppercase letters and a plus sign, e.g. `EOODIA+Poetica` if the original font name is `Poetica`. This is relevant in the case that multiple Matplotlib plots are combined in the same document, e.g. in a LaTeX paper with several figures. The random tags prevent collisions between the different versions of the same font.",False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/867246824,Type42 subsetting in PS/PDF,aitikgupta,34,915102608,11,867246824,0,866905954,2021-06-24T00:38:55Z,"> extra requirements for font subsets ... PostScript name of subsetted fonts needs to have a prepended tag of six random uppercase letters and a plus sign

I think we don't do this even for Type 3 subsetting?
Since we _always_ try to subset those, I can probably just add a function to modify the name for Type 3 and Type 42 both.",False,0,CONTRIBUTOR
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/867270954,Type42 subsetting in PS/PDF,aitikgupta,34,915102608,12,867270954,0,867246824,2021-06-24T01:51:28Z,"This breaks the `test_determinism_check`:
https://github.com/matplotlib/matplotlib/blob/593de3550e578aed1fc2e392041bb7796fcc3ce1/lib/matplotlib/tests/test_determinism.py#L85-L88

This is for obvious reasons, since we have random string inside font postscript name. (due to the specification)",False,0,CONTRIBUTOR
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/867295169,Type42 subsetting in PS/PDF,jkseppan,34,915102608,13,867295169,0,867270954,2021-06-24T02:55:29Z,"Then the string shouldn't be random, but perhaps something derived from the subset of glyphs? Take `hash(frozenset(glyphs))`, convert it to base 26 and take the first six letters, or something like that.

The PDF specification only requires the tag for Type 1 and TrueType fonts. It probably doesn't hurt with Type 3 fonts either.",False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/867298010,Type42 subsetting in PS/PDF,aitikgupta,34,915102608,14,867298010,0,867295169,2021-06-24T03:03:55Z,"> Then the string shouldn't be random, but perhaps something derived from the subset of glyphs?

That totally makes sense! Let me try this out 👍🏼 ",False,0,CONTRIBUTOR
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/877741233,Type42 subsetting in PS/PDF,jkseppan,34,915102608,15,877741233,0,867298010,2021-07-11T04:52:58Z,"I think this is getting close to mergeable. Changes requested are the `.flush` call, the `filterwarnings` thing, and some minor points about the added test. This should also be documented in `doc/users/next_whats_new/`.",False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/878068414,Type42 subsetting in PS/PDF,aitikgupta,34,915102608,16,878068414,0,877741233,2021-07-12T08:10:48Z,"Bringing up what @jkseppan said on gitter a while ago:
> We should probably try to default to Type 42 and fix any problems our Type 42 conversion has, because that's what publishers expect and it's probably more useful for other tools that consume pdf files.

Should we consider changing matplotlib's default fonttype from `3` to `42`?",False,0,CONTRIBUTOR
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/878257826,Type42 subsetting in PS/PDF,sauerburger,34,915102608,17,878257826,0,878068414,2021-07-12T12:58:59Z,"Over the last few days I've submitted a couple of issues (https://github.com/matplotlib/matplotlib/issues/20628, https://github.com/matplotlib/matplotlib/issues/20616, https://github.com/matplotlib/matplotlib/issues/20614, https://github.com/matplotlib/matplotlib/issues/20612) and corresponding PRs, all addressing specific issues I've encountered with Type 42 fonts. I just wanted to give a heads up, that this PR does not interfere with any of the other PRs (after one manual merge).",False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/879076645,Type42 subsetting in PS/PDF,aitikgupta,34,915102608,18,879076645,0,878257826,2021-07-13T13:13:07Z,"As discussed on dev call, we could add a test triggering the whole route for Type 42 subsetting in PostScript backend.",False,0,CONTRIBUTOR
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/879078903,Type42 subsetting in PS/PDF,aitikgupta,34,915102608,19,879078903,0,879076645,2021-07-13T13:15:59Z,^^ Also check out PS /fontname output,False,0,CONTRIBUTOR
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/881933494,Type42 subsetting in PS/PDF,aitikgupta,34,915102608,20,881933494,0,879078903,2021-07-17T17:43:38Z,"^Rebased, fixed subset tests, added a new test for multiple fonttypes in PS backend.",False,0,CONTRIBUTOR
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/882057180,Type42 subsetting in PS/PDF,aitikgupta,34,915102608,21,882057180,0,881933494,2021-07-18T13:32:18Z,"Seems like we can't do a `tempfile.NamedTemporaryFile` in tests, it raises a:
```console
PermissionError: [Errno 13] Permission denied: 'C:\\Users\\VSSADM~1\\AppData\\Local\\Temp\\tmpp1lzen9i.ps'
```
for Azure pipelines..

Can we otherwise get a buffer from a figure? (so instead of fig.savefig() we could use something like a  fig.get_buffer(), which can get the job done)
",False,0,CONTRIBUTOR
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/882057920,Type42 subsetting in PS/PDF,anntzer,34,915102608,22,882057920,0,882057180,2021-07-18T13:38:20Z,"`buf = io.BytesIO(); fig.savefig(buf, fmt=""ps""); buf.getvalue()`?",False,0,CONTRIBUTOR
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/882058474,Type42 subsetting in PS/PDF,aitikgupta,34,915102608,23,882058474,0,882057920,2021-07-18T13:42:51Z,"> buf = io.BytesIO(); fig.savefig(buf, fmt=""ps""); buf.getvalue()?

It was right there in one of the tests too, I completely forgot about it. I'll push again..",False,0,CONTRIBUTOR
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/882060698,Type42 subsetting in PS/PDF,jkseppan,34,915102608,24,882060698,0,882058474,2021-07-18T14:00:01Z,"pytest has a tmpdir fixture, perhaps it does whatever tricks are needed on Windows:  https://docs.pytest.org/en/6.2.x/tmpdir.html

It's being used in some tests (e.g. https://github.com/matplotlib/matplotlib/blob/c4dcf5e628d0441b21df1c8fe7cac4834a6944e9/lib/matplotlib/tests/test_mathtext.py#L371).",False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/882083444,Type42 subsetting in PS/PDF,aitikgupta,34,915102608,25,882083444,0,882060698,2021-07-18T16:36:21Z,"> https://dev.azure.com/matplotlib/matplotlib/_build/results?buildId=20011&view=logs&j=a0e323ef-73e6-5069-91af-81f1eca08ea9&t=aaf81cb8-bb95-512e-5f32-9726d69a7874&l=152

`>     fig.savefig(buf, format=""ps"")`
this raises :(


```console
RuntimeError: Failed to open TrueType font
```


This is triggered by ttconv here:
> https://dev.azure.com/matplotlib/matplotlib/_build/results?buildId=20011&view=logs&j=a0e323ef-73e6-5069-91af-81f1eca08ea9&t=aaf81cb8-bb95-512e-5f32-9726d69a7874&l=241

`>    convert_ttf_to_ps(`


I don't get this locally, and also, all the tests pass except the azure pipeline.. I'm not sure how can I reproduce? 😅 ",False,0,CONTRIBUTOR
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/882317436,Type42 subsetting in PS/PDF,jkseppan,34,915102608,26,882317436,0,882083444,2021-07-19T07:38:08Z,"It could be because of this: https://bugs.python.org/issue14243

Apparently on Windows you have to close the file before opening it for reading, and then clean it up manually.",False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/882327877,Type42 subsetting in PS/PDF,anntzer,34,915102608,27,882327877,0,882317436,2021-07-19T07:54:25Z,"Haven't followed the whole thread so I'm not sure it's the problem at hand, but my usual strategy is to never (well, rarely) use NamedTemporaryFile exactly because of Windows support, and to always instead use a TemporaryDirectory and create a file with whatever name you want in it.",False,0,CONTRIBUTOR
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/882447621,Type42 subsetting in PS/PDF,aitikgupta,34,915102608,28,882447621,0,882327877,2021-07-19T10:49:32Z,"That worked!
I wonder, if `tempfile.NamedTemporaryFile` is really that buggy (or doesn't exactly work on Windows in the same way), should it really be a part of Python's API?

Or from a different perspective, since `TemporaryDirectory` worked, it wouldn't be so hard to create a `NamedTemporaryFile` from it, right? But one works, the other doesn't..",False,0,CONTRIBUTOR
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/882501827,Type42 subsetting in PS/PDF,jkseppan,34,915102608,29,882501827,0,882447621,2021-07-19T12:18:22Z,"> That worked!
> I wonder, if `tempfile.NamedTemporaryFile` is really that buggy (or doesn't exactly work on Windows in the same way), should it really be a part of Python's API?

As you can see from the discussion on that 9-year-old bug, reasonable people disagree on the solution. Or looking at some of the later messages, perhaps the issue needs someone to choose a solution, submit a PR and keep pushing until it is fixed. In any case, changing the API of anything in the Python standard library is a slow process, since someone somewhere is going to depend on the current behaviour.

> Or from a different perspective, since `TemporaryDirectory` worked, it wouldn't be so hard to create a `NamedTemporaryFile` from it, right? But one works, the other doesn't..

The current Windows implementation of `NamedTemporaryFile` guarantees that the file is deleted if the process exits abruptly, and I don't think the `TemporaryDirectory` solution can do that.
",False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/883322682,Type42 subsetting in PS/PDF,jkseppan,34,915102608,30,883322682,0,882501827,2021-07-20T11:37:45Z,"I removed the ""needs revision"" label - I think some busy developers use them to organize their reviews, so removing the label is a signal to take another look.",False,0,MEMBER
https://api.github.com/repos/matplotlib/matplotlib/issues/comments/883416953,Type42 subsetting in PS/PDF,tacaswell,34,915102608,31,883416953,0,883322682,2021-07-20T13:59:25Z,It may also be worth at API change note that we added a new dependency?,False,0,MEMBER
https://api.github.com/repos/joncampbell123/dosbox-x/issues/2628,DOSBox-X 0.83.15 crashes on Mac due to missing dylibs,dixius99,3,935043642,1,935043642,0,0,2021-07-01T17:02:11Z,"**Describe the bug**
When trying to launch DOSBox-X on macOS Big Sur (Intel), the app does not launch, and I get the macOS error report.

It appears that the current builds are missing the following dylibs:

- libslirp
- fluid-synth
- ffmpeg

Installing these manually with `brew install libslirp fluid-synth ffmpeg` (which installs several dependencies, especially for `ffmpeg`) fixes the issue.

**To Reproduce**
Steps to reproduce the behavior:
1. Double-click either the SDL or SDL-2 version of the app

**Expected behavior**
Expectation is that the app will load, with no need to manually install the libraries manually.

**Environment (please complete the following information):**
 - macOS 11.4
 - DOSBox-X release version 0.83.15",True,0,NONE
https://api.github.com/repos/joncampbell123/dosbox-x/issues/comments/872410866,DOSBox-X 0.83.15 crashes on Mac due to missing dylibs,joncampbell123,3,935043642,2,872410866,0,935043642,2021-07-01T17:05:09Z,"That doesn't sound right... if you look in the .app bundle, there should be .dylib files alongside the DOSBoxX executable for FFMPEG, libslirp and FluidSynth.

Also, duplicate of #2627 which indicates that libglib didn't make it.",False,0,OWNER
https://api.github.com/repos/joncampbell123/dosbox-x/issues/comments/872411712,DOSBox-X 0.83.15 crashes on Mac due to missing dylibs,joncampbell123,3,935043642,3,872411712,0,872410866,2021-07-01T17:06:26Z,"The Makefile used to force the .dylib files to refer to the executable by modifying them, but that breaks code signing and completely prevents DOSBox-X from running, so it was removed. otool -L seemed to imply that it was supposed to search the same directory anyway, so I assumed it would work.",False,0,OWNER
https://api.github.com/repos/joncampbell123/dosbox-x/issues/comments/872439191,DOSBox-X 0.83.15 crashes on Mac due to missing dylibs,dixius99,3,935043642,4,872439191,0,872411712,2021-07-01T17:52:49Z,"> Also, duplicate of #2627 which indicates that libglib didn't make it.

Sorry, I didn't see that one. I can close this one and share info there. ",False,0,NONE
https://api.github.com/repos/joncampbell123/dosbox-x/issues/2629,Does Dosbox-X support CD Audio directly from the CD?,WhyIsntTouhouBuntuRealYet,6,935297235,1,935297235,0,0,2021-07-01T23:54:53Z,"I'm using the SDL1 build of Dosbox-X on a Raspberry pi 4 8GB model with TwisterOS installed.
I use the command ""mount d /media/QUAKE101 -t cdrom -usecd 0 -ioctl"" and get the message ""MSCDEX installed: Limited support.""

Whenever I do this, Quake struggles to even go past 5 frames per second, and I don't get any music. I type in ""CD PLAY 2"" in the console, but nothing happens.

What I'm trying to do is to play the music files directly off the CD so I don't have to take up precious space on my 16GB SD card.
Am I doing something wrong?",True,0,NONE
https://api.github.com/repos/joncampbell123/dosbox-x/issues/comments/872698687,Does Dosbox-X support CD Audio directly from the CD?,Wengier,6,935297235,2,872698687,0,935297235,2021-07-02T04:12:05Z,"Is this the message you saw from the command?

`MSCDEX: Mounted subdirectory: limited support`

DOSBox-X does support CD Audio directly from the CD, but this feature may sometimes depend on your platform. Is the path `/media/QUAKE101` indeed referring to a CD? If not, the above message will appear. Also, the ""-ioctl"" option may not be supported in all platforms, even though it should work on most systems, such as my own Windows system.",False,0,COLLABORATOR
https://api.github.com/repos/joncampbell123/dosbox-x/issues/comments/872705892,Does Dosbox-X support CD Audio directly from the CD?,WhyIsntTouhouBuntuRealYet,6,935297235,3,872705892,0,872698687,2021-07-02T04:33:55Z,"Yes, it refers to a CD. I have an original Quake CD, version 1.0.1.
Also, Dosbox slows down considerably whenever I use this command. Perhaps it's too taxing on the program.

I know it's not my Pi, because Quakespasm plays CD Audio perfectly. Maybe a future build can remedy this?",False,0,NONE
https://api.github.com/repos/joncampbell123/dosbox-x/issues/comments/872710264,Does Dosbox-X support CD Audio directly from the CD?,Wengier,6,935297235,4,872710264,0,872705892,2021-07-02T04:47:26Z,"I do not have TwisterOS to test myself, but the issue could be specific to this environment, or there is something in the said path which is not supported at this time. If I personally have such an environment I would be able to test it myself and see if there is anything to fix.",False,0,COLLABORATOR
https://api.github.com/repos/joncampbell123/dosbox-x/issues/comments/873259056,Does Dosbox-X support CD Audio directly from the CD?,rderooy,6,935297235,5,873259056,0,872710264,2021-07-02T21:13:03Z,"As the message when mounting already hints at, it is a mounted **directory**, and therefore there will not be any CD Audio.

For there to be CD Audio, there should be a way to point DOSBox-X to the actual CD device, not the mounted directory. This will normally be something like ``/dev/sr0`` (there is typically also a ``/dev/cdrom`` symlink). However that will not work, as there is no support in DOSBox-X to directly access a raw CD-ROM device on Linux.

The real solution is to convert the CD-ROM into a CUE/BIN image, and IMGMOUNT that.",False,0,CONTRIBUTOR
https://api.github.com/repos/joncampbell123/dosbox-x/issues/comments/873278529,Does Dosbox-X support CD Audio directly from the CD?,WhyIsntTouhouBuntuRealYet,6,935297235,6,873278529,0,873259056,2021-07-02T22:07:34Z,Is there a Dosbox build that CAN directly access the CD drive?,False,0,NONE
https://api.github.com/repos/joncampbell123/dosbox-x/issues/comments/873347931,Does Dosbox-X support CD Audio directly from the CD?,Wengier,6,935297235,7,873347931,0,873278529,2021-07-03T05:13:57Z,"@WhyIsntTouhouBuntuRealYet Yes, of course, although maybe not for specific platforms.

On Windows, a command like `mount c d:\ -t cdrom -usecd 0 -ioctl` should work just fine for CD drive D: for Windows builds.

On macOS, a command like `mount c /Volumes/cddrive -t cdrom -usecd 0 -ioctl` is supposed to work for CD drive /Volumes/cddrive too for macOS builds (just confirmed myself).

CD drives may be expected to work differently for different platforms.",False,0,COLLABORATOR
https://api.github.com/repos/joncampbell123/dosbox-x/issues/2631,[SDL2]Debug menu breaks help menu display when using CGA/EGA/Tandy/PCJr rendering mode.,FredBezies,9,935578436,1,935578436,0,0,2021-07-02T09:12:34Z,"**Describe the bug**
Hello.

I noticed that in Dosbox-X 0.83.15, if you're using CGA/EGA/Tandy/PCJr, you cannot access to help items under DOS Commands.

Commands list it too wide to let mouse cursor goes under it.

**To Reproduce**
Steps to reproduce the behavior:
1. Build Dosbox-X with commit 4dddd79
2. In Configuration Tool, go to main and choose  CGA/EGA/Tandy/PCJr rendering mode
3. Save and restart with the new configuration file.
4. Go to help menu and click on it. Go down to DOS Commands.

**Expected behavior**
DOS Commands box to be a little on the right to get access to other menu items.

**Screenshots**

![Capture d’écran de 2021-07-02 11-10-29](https://user-images.githubusercontent.com/8571419/124251403-28855900-db26-11eb-8c3f-0b08bd653827.png)


**Environment (please complete the following information):**
 - Archlinux
 - DOSBox-X commit 4dddd79 with SDL2 enabled.
 - Only modified main/machine to use  CGA/EGA/Tandy/PCJr rendering mode instead of svga_s3
",True,0,CONTRIBUTOR
https://api.github.com/repos/joncampbell123/dosbox-x/issues/comments/872854493,[SDL2]Debug menu breaks help menu display when using CGA/EGA/Tandy/PCJr rendering mode.,FredBezies,9,935578436,2,872854493,0,935578436,2021-07-02T09:22:33Z,"Here is the result with DosBox using SDL1.

![Capture d’écran de 2021-07-02 11-19-54](https://user-images.githubusercontent.com/8571419/124252712-87979d80-db27-11eb-96ea-1a121458cd71.png)

So something is broken with SDL2 and help menu items.
",False,0,CONTRIBUTOR
https://api.github.com/repos/joncampbell123/dosbox-x/issues/comments/872893659,[SDL2]Debug menu breaks help menu display when using CGA/EGA/Tandy/PCJr rendering mode.,grapeli,9,935578436,3,872893659,0,872854493,2021-07-02T10:26:17Z,"I do not note anything like that.
Though I don't know why this window goes full screen and back to its original size.

https://user-images.githubusercontent.com/452325/124260944-c590c380-db1f-11eb-917d-3d0705e48fcc.mp4

edit: Only now did I notice. In the SDL2 version you have an additional menu item - `Debug`, which you do not have in SDL1.",False,0,NONE
https://api.github.com/repos/joncampbell123/dosbox-x/issues/comments/872894941,[SDL2]Debug menu breaks help menu display when using CGA/EGA/Tandy/PCJr rendering mode.,grapeli,9,935578436,4,872894941,0,872893659,2021-07-02T10:28:16Z,"It works badly under the wayland. Due to a malfunctioning fullscreen (zoom 100x).
It does not return to its original size by itself.

https://user-images.githubusercontent.com/452325/124261325-2c15e180-db20-11eb-8dca-3abf51472cf7.mp4
",False,0,NONE
https://api.github.com/repos/joncampbell123/dosbox-x/issues/comments/872915908,[SDL2]Debug menu breaks help menu display when using CGA/EGA/Tandy/PCJr rendering mode.,FredBezies,9,935578436,5,872915908,0,872894941,2021-07-02T11:06:49Z,"I noticed this bug only with CGA/EGA/Tandy/PCJr rendering mode. When I go back to svga_s3, bug is dead.

I tried replacing --enable-debug by --disable-debug in configure line.

Here is the result:

![Capture d’écran de 2021-07-02 13-05-02](https://user-images.githubusercontent.com/8571419/124265634-3d69e880-db36-11eb-87eb-90ea45c562c9.png)

Looks like Debug menu is guilty here. Modifying bug title.

Fixed both dosbox-x-sdl2 and dosbox-x-sdl2-git on AUR in order to workaround this bug.",False,0,CONTRIBUTOR
https://api.github.com/repos/joncampbell123/dosbox-x/issues/comments/872945193,[SDL2]Debug menu breaks help menu display when using CGA/EGA/Tandy/PCJr rendering mode.,grapeli,9,935578436,6,872945193,0,872915908,2021-07-02T12:02:06Z,"With the additional ""Debug"" item in the menu, you can also access all items. A bit more difficult. However, they are achievable.

https://user-images.githubusercontent.com/452325/124271611-31c5f400-db2d-11eb-9ccd-1f8e5692af8c.mp4
",False,0,NONE
https://api.github.com/repos/joncampbell123/dosbox-x/issues/comments/872964213,[SDL2]Debug menu breaks help menu display when using CGA/EGA/Tandy/PCJr rendering mode.,FredBezies,9,935578436,7,872964213,0,872945193,2021-07-02T12:34:31Z,"> With the additional ""Debug"" item in the menu, you can also access all items. A bit more difficult. However, they are achievable.
> dosbox-x-sdl2-i3.mp4

This is a manual workaround :smile: ",False,0,CONTRIBUTOR
https://api.github.com/repos/joncampbell123/dosbox-x/issues/comments/873082690,[SDL2]Debug menu breaks help menu display when using CGA/EGA/Tandy/PCJr rendering mode.,grapeli,9,935578436,8,873082690,0,872964213,2021-07-02T15:29:07Z,"Possible.

Run any game in 320x200 resolution from dosbox-x running like this.
`dosbox-x -set doublescan=false -set scaler=none`
You cannot access any menu items beyond Capture - Drive, [Debug], Help.

",False,0,NONE
https://api.github.com/repos/joncampbell123/dosbox-x/issues/comments/873352990,[SDL2]Debug menu breaks help menu display when using CGA/EGA/Tandy/PCJr rendering mode.,Wengier,9,935578436,9,873352990,0,873082690,2021-07-03T06:03:16Z,"I agree that the SDL-drawn menu can be sometimes inflexible with small windows like in this case. It is possible to address this later, but for Linux SDL2 build, you can start the DOSBox-X window maximized with the setting `maximize=true`, and such issues won’t occur with bigger windows.",False,0,COLLABORATOR
https://api.github.com/repos/joncampbell123/dosbox-x/issues/comments/873478400,[SDL2]Debug menu breaks help menu display when using CGA/EGA/Tandy/PCJr rendering mode.,grapeli,9,935578436,10,873478400,0,873352990,2021-07-03T22:22:32Z,"Unfortunately, the non-maximized window (SDL2) does not work completely properly.
It looks the worst under JSLinux.

https://user-images.githubusercontent.com/452325/124368094-f6bae200-dc4c-11eb-89c3-8d8bed8b13ee.mp4

Fully static DOSBox-X 0.83.14 (no fluidsynth, opengl, slirp).
[dosbox-x-0.83.14.linux.static.tar.gz](https://github.com/joncampbell123/dosbox-x/files/6759115/dosbox-x-0.83.14.linux.static.tar.gz)
Under [JSLinux](https://bellard.org/jslinux/vm.html?url=alpine-x86-xwin.cfg&mem=256&graphic=1) you can run like this:
```
gzip -dc dosbox-x-0.83.14.linux.static.tar.gz | tar xf - -C/
dosbox-x
```
",False,0,NONE
https://api.github.com/repos/joncampbell123/dosbox-x/issues/2632,"macOS Parallel ""openps"" fails with ""lpr -r output1.prn"", succeeds with shell script ",emendelson,3,936124011,1,936124011,0,0,2021-07-03T00:03:25Z,"I'm working on a project that uses DOSBox-X under macOS to run word-processing applications. Thanks to @Wengier's recent work, I can easily set different programs to run when a word-processor prints to a PCL or PostScript driver. This works perfectly, except that I can't get the `lpr` command to work correctly. Here's the relevant part of my conf file (DOSBox-X is deep inside an AppleScript app, thus the ../../.. strings.)

```
parallel1 = file file:../../../output1.prn timeout:1000 openpcl:""../../../printpcl.sh output1.prn"" openps:""/usr/bin/lpr -r output1.prn""
``` 

When printing a PS file, this always produces an error message; and the same error message happens if I use a shell script to run the `lpr -r` command instead of running it directly. If I run the `lpr` command from a macOS terminal in the same folder with the output1.prn file, the file prints correctly - the command only fails when run from DOSBox-X.

I know that the PostScript file is valid and that PS detection works, because when I print PS to a different port that uses a shell script to process the PS output works correctly. For some reason, I can't get `lpr` to work from the conf file.

I'll continue to work on this, but if anyone has any insight, I'll be grateful for any suggestions.

EDIT: I've worked around this by writing a shell script that converts the PS file to a PDF and then prints the PDF with the `lpr` command. But this doesn't solve one remaining problem: I've set up this system to print raw data to a printer when the user prints to lpt2, by using the command `lpr -l -r output2.prn` - but again, this fails when run from the conf file, so it would be good to have a fix. Is it possible that the ""openps"" and similar options in the conf file won't work with built-in unix-style commands?

EDIT: And now I was able to solve this for printing with `lpr` by writing shell scripts that use the osascript application to run an AppleScript that runs `lpr`. This is very roundabout - the shell script runs AppleScript which runs a shell command, but it works. It would be much easier if the internal command could be run from the conf file, but maybe that's impossible.",True,0,CONTRIBUTOR
https://api.github.com/repos/joncampbell123/dosbox-x/issues/comments/873344568,"macOS Parallel ""openps"" fails with ""lpr -r output1.prn"", succeeds with shell script ",Wengier,3,936124011,2,873344568,0,936124011,2021-07-03T04:42:01Z,"@emendelson For the ""openpcl"" and ""openps"" options (and for ""openwith"" option too), you don't need to specify the output file (""output1.prn"" in your case), as it is automatically implied from the ""file"" option - the command specified by ""openpcl"" and ""openps"" options will operate on the output file specified by ""file"" (the output file automatically becomes the last parameter). So you can for example try `openpcl:../../../printpcl.sh` and `openps:""/usr/bin/lpr -r""` instead. You did not mentioned exactly what error message you saw from the lpr command, but I hope the above will solve this. But if not, posting the actual error message will likely help solve the issue. Hope this helps.",False,0,COLLABORATOR
https://api.github.com/repos/joncampbell123/dosbox-x/issues/comments/873415376,"macOS Parallel ""openps"" fails with ""lpr -r output1.prn"", succeeds with shell script ",emendelson,3,936124011,3,873415376,0,873344568,2021-07-03T14:27:31Z,"@Wengier Thank you! I was able to fix the `lpr` issue simply by removing the filename from the command string, as you suggested. I was using the filename because my shell scripts required the filename in the command string (I realize that I can probably hard-code the filename into the shell script, but I may use the scripts for more than one output, so it seemed best to use the filename as a parameter that the script can process as ""$1"".)

The lpr command did not display an error message; I only got the DOSBox-X message saying that the print handler did not complete correctly. I couldn't find an option to display the specific message, but maybe there is one?

So, in summary: My shell scripts need the ""output1.prn"" filename as a parameter, but lpr does not work if the filename is used as a parameter. Someday I'll study the code and try to figure out why it happens. Meanwhile, the problem is solved.",False,0,CONTRIBUTOR
https://api.github.com/repos/joncampbell123/dosbox-x/issues/comments/873515995,"macOS Parallel ""openps"" fails with ""lpr -r output1.prn"", succeeds with shell script ",Wengier,3,936124011,4,873515995,0,873415376,2021-07-04T03:51:32Z,"@emendelson Glad to hear that the problem is already solved. There is no particular option just for displaying error messages from lpr, but if DOSBox-X is launched from the macOS Terminal, you may see the output of the lpr command in the Terminal window.

DOSBox-X automatically appends the file name to the command handler, so if you add it manually then there will be a duplicate parameter, thus cause errors. You can just assume the file name is already provided. Hope this helps.",False,0,COLLABORATOR
https://api.github.com/repos/mozilla/sccache/issues/1011,Hang / deadlock while compiling?,roy-work,4,918989320,1,918989320,0,0,2021-06-11T17:01:40Z,"We seem to be seeing a hang / deadlock while compiling with `sccache`:

```
62315 root       20   0 9682M  428M  7120 S  0.0  0.3  0:31.03 │     ├─ /usr/local/cargo/bin/sccache
43861 root       20   0  255M  117M 79048 S  0.0  0.1  0:00.80 │     │  ├─ /usr/local/rustup/toolchains/1.50.0-x86_64-unknown-linux-gnu/bin/rustc --crate-name actix_service --edition=2018 /usr/local/cargo/r
43563 root       20   0  427M  241M  145M S  0.0  0.2  0:01.27 │     │  ├─ /usr/local/rustup/toolchains/1.50.0-x86_64-unknown-linux-gnu/bin/rustc --crate-name parse_zoneinfo /usr/local/cargo/registry/src/-e
42975 root       20   0  631M  400M  142M S  0.0  0.3  0:10.65 │     │  ├─ /usr/local/rustup/toolchains/1.50.0-x86_64-unknown-linux-gnu/bin/rustc --crate-name regex /usr/local/cargo/registry/src/-e91f24c38b
38792 root       20   0  939M  693M 89236 S  0.0  0.5  0:30.71 │     │  ├─ /usr/local/rustup/toolchains/1.50.0-x86_64-unknown-linux-gnu/bin/rustc --crate-name log4rs --edition=2018 /usr/local/cargo/registry
36525 root       20   0  638M  426M  160M S  0.0  0.3  0:10.27 │     │  └─ /usr/local/rustup/toolchains/1.50.0-x86_64-unknown-linux-gnu/bin/rustc --crate-name tokio --edition=2018 /usr/local/cargo/registry/
```

All of these seem to be stuck on a pipe (FD 6, specifically; they're all writing to it, include `sccache`.)

Specifically, we can grab all the `rustc` PIDs:
```
/proc# pgrep rustc
36525
38792
42975
43563
43861
```

We can see that they're all stuck writing to FD 6:

<details>
<summary>Output</summary>

```
/proc# strace $(cd 36525/task; for d in *; do printf ' -p %s' ""$d""; done)
strace: Process 36525 attached
strace: Process 36627 attached
strace: Process 43551 attached
strace: Process 43553 attached
[pid 43553] write(6, ""|"", 1 <unfinished ...>
[pid 43551] futex(0x7fbd66d5df4c, FUTEX_WAIT_PRIVATE, 0, NULL <unfinished ...>
[pid 36627] futex(0x7fbd700df9b8, FUTEX_WAIT_PRIVATE, 4294967295, NULL <unfinished ...>
[pid 36525] futex(0x7fbd6f97f9d0, FUTEX_WAIT, 15701, NULL^Cstrace: Process 36525 detached
 <detached ...>
strace: Process 36627 detached
strace: Process 43551 detached
strace: Process 43553 detached
/proc# strace $(cd 38792/task; for d in *; do printf ' -p %s' ""$d""; done)
strace: Process 38792 attached
strace: Process 39121 attached
strace: Process 42643 attached
strace: Process 42648 attached
[pid 42648] write(6, ""|"", 1 <unfinished ...>
[pid 42643] futex(0x7fd5defe6d2c, FUTEX_WAIT_PRIVATE, 0, NULL <unfinished ...>
[pid 39121] futex(0x7fd5ea8df9b8, FUTEX_WAIT_PRIVATE, 4294967295, NULL <unfinished ...>
[pid 38792] futex(0x7fd5ea17f9d0, FUTEX_WAIT, 17910, NULL^Cstrace: Process 38792 detached
 <detached ...>
strace: Process 39121 detached
strace: Process 42643 detached
strace: Process 42648 detached
/proc# strace $(cd 42975/task; for d in *; do printf ' -p %s' ""$d""; done)
strace: Process 42975 attached
strace: Process 43005 attached
strace: Process 43742 attached
strace: Process 43745 attached
[pid 43745] write(6, ""|"", 1 <unfinished ...>
[pid 43742] futex(0x7f4b877f958c, FUTEX_WAIT_PRIVATE, 0, NULL <unfinished ...>
[pid 43005] futex(0x7f4b920df9b8, FUTEX_WAIT_PRIVATE, 4294967295, NULL <unfinished ...>
[pid 42975] futex(0x7f4b9197f9d0, FUTEX_WAIT, 21597, NULL^Cstrace: Process 42975 detached
 <detached ...>
strace: Process 43005 detached
strace: Process 43742 detached
strace: Process 43745 detached
/proc# strace $(cd 43563/task; for d in *; do printf ' -p %s' ""$d""; done)
strace: Process 43563 attached
strace: Process 43722 attached
strace: Process 44076 attached
strace: Process 44077 attached
[pid 44077] write(6, ""|"", 1 <unfinished ...>
[pid 44076] futex(0x7fdb4c367dcc, FUTEX_WAIT_PRIVATE, 0, NULL <unfinished ...>
[pid 43722] futex(0x7fdb55adf958, FUTEX_WAIT_PRIVATE, 4294967295, NULL <unfinished ...>
[pid 43563] futex(0x7fdb5537f9d0, FUTEX_WAIT, 22132, NULL^Cstrace: Process 43563 detached
 <detached ...>
strace: Process 43722 detached
strace: Process 44076 detached
strace: Process 44077 detached
root@agent-9vgr9nLE-vm:/proc# strace $(cd 43861/task; for d in *; do printf ' -p %s' ""$d""; done)
strace: Process 43861 attached
strace: Process 44024 attached
strace: Process 44196 attached
strace: Process 44197 attached
[pid 44197] write(6, ""|"", 1 <unfinished ...>
[pid 44196] futex(0x7f12af3c417c, FUTEX_WAIT_PRIVATE, 0, NULL <unfinished ...>
[pid 43861] futex(0x7f12b957f9d0, FUTEX_WAIT, 22386, NULL <unfinished ...>
[pid 44024] futex(0x7f12b9cdf9b8, FUTEX_WAIT_PRIVATE, 4294967295, NULL^Cstrace: Process 43861 detached
strace: Process 44024 detached
 <detached ...>
strace: Process 44196 detached
strace: Process 44197 detached
```

</details>

And that FD 6 is a pipe, and the _same_ pipe:

```
/proc# ls -l {36525,38792,42975,43563,43861}/fd/6
l-wx------ 1 root root 64 Jun  3 18:38 36525/fd/6 -> 'pipe:[604355]'
l-wx------ 1 root root 64 Jun  3 18:38 38792/fd/6 -> 'pipe:[604355]'
l-wx------ 1 root root 64 Jun  3 18:38 42975/fd/6 -> 'pipe:[604355]'
l-wx------ 1 root root 64 Jun  3 18:38 43563/fd/6 -> 'pipe:[604355]'
l-wx------ 1 root root 64 Jun  3 18:38 43861/fd/6 -> 'pipe:[604355]'
```

It's also what `sccache` itself is stuck on:

```
# ps -ef | grep sccache
[snip]
root     62315 17967  0 18:35 ?        00:00:31 /usr/local/cargo/bin/sccache
```

```
# strace -p 62315
strace: Process 62315 attached
write(6, ""|"", 1^Cstrace: Process 62315 detached
 <detached ...>
```

I know that's not a lot to go on; I'm mostly hoping that pipe write looks familiar to someone & then it would be known from there what high-level system is implicated here. I'm not clear on how `rustc` even gets this pipe, though, since it doesn't seem like any argument would inform it of the existence of this pipe…?",True,0,NONE
https://api.github.com/repos/mozilla/sccache/issues/comments/860968105,Hang / deadlock while compiling?,luser,4,918989320,2,860968105,0,918989320,2021-06-14T20:24:08Z,"This is the jobserver pipe, which is implemented in the `jobserver` crate:
https://github.com/alexcrichton/jobserver-rs/blob/5756d028d0fcf73e62ef8811674925c699b78a41/src/unix.rs#L29
",False,0,CONTRIBUTOR
https://api.github.com/repos/mozilla/sccache/issues/comments/862673569,Hang / deadlock while compiling?,roy-work,4,918989320,3,862673569,0,860968105,2021-06-16T20:00:46Z,"Do you know why `rustc` would be writing to that? (That part seemed confusing to me; while I expected some IPC from `sccache`, seeing `rustc` waiting on the same pipe was surprising. I figured `sccache` would just kick off `rustc` & wait for the child to finish.)",False,0,NONE
https://api.github.com/repos/mozilla/sccache/issues/comments/863262363,Hang / deadlock while compiling?,luser,4,918989320,4,863262363,0,862673569,2021-06-17T13:57:50Z,"rustc has internal parallelism for codegen, it uses the jobserver so it can let cargo dictate the maximum amount of parallelism when multiple rustc processes are running.",False,0,CONTRIBUTOR
https://api.github.com/repos/mozilla/sccache/issues/comments/863404466,Hang / deadlock while compiling?,roy-work,4,918989320,5,863404466,0,863262363,2021-06-17T16:56:41Z,"Ah. Do you know what is the mechanism by which it knows which FD the pipe is? (It doesn't seem to get passed in either the command line args or the environment, but perhaps I've missed something?)",False,0,NONE
https://api.github.com/repos/mozilla/sccache/issues/1018,fix NVCC hash key generate error on windows,zhwesky2010,3,938682436,1,938682436,0,0,2021-07-07T09:24:02Z,"Resolve https://github.com/mozilla/sccache/issues/1017
===


The `-P` option causes all of the pre-processed content to be written to the file (please refer to
https://docs.microsoft.com/en-gb/cpp/build/reference/p-preprocess-to-a-file?view=msvc-160). The STDOUT content is 0, and the hash key is generated according to the contents of the STDOUT. Therefore, the hash key of any CUDA source file is the same, which makes it can only cache one CUDA file. In order to make the contents of the CUDA source file preprocessed output to STDOUT, the preprocess option should  be  ``-EP``, then different hash values will be generated, have you detected this bug？

https://github.com/mozilla/sccache/blob/master/src/compiler/nvcc.rs#L121

```
[0m [math_function.cu.obj]: Preprocessor output is 0 bytes
[0m Hashed 0 files in 8.913 s
[0m [math_function.cu.obj]: generate_hash_key took 8.913 s
[0m [math_function.cu.obj]: Hash key: 7e5027a5bb3d395b95819336d7def508c0c4125d11fc8bc862c15daafd3a0cc1
[0m DiskCache::get(7e5027a5bb3d395b95819336d7def508c0c4125d11fc8bc862c15daafd3a0cc1)
[0m loop process - 0 events, 0.000s
```

All hash key is ``7e5027a5bb3d395b95819336d7def508c0c4125d11fc8bc862c15daafd3a0cc1``, no matter which CUDA source files!!!",True,0,NONE
https://api.github.com/repos/mozilla/sccache/issues/comments/1042654505,fix NVCC hash key generate error on windows,zhwesky2010,3,938682436,2,1042654505,0,938682436,2022-02-17T07:36:05Z,"`-EP` and `-E` preprocess to stdout, `-P` preprocess to file, and no cache will hit. So, it can only use `-EP` or `-E`",False,0,NONE
https://api.github.com/repos/mozilla/sccache/issues/comments/1043063449,fix NVCC hash key generate error on windows,mitchhentges,3,938682436,3,1043063449,0,1042654505,2022-02-17T15:21:02Z,"> -EP and -E preprocess to stdout, -P preprocess to file, and no cache will hit. So, it can only use -EP or -E

Ok, that makes sense. The previous behaviour just did `-P`, so a file was created - do we depend on this file being created as well (will things break if we don't have it)?",False,0,CONTRIBUTOR
https://api.github.com/repos/mozilla/sccache/issues/comments/1375788319,fix NVCC hash key generate error on windows,sylvestre,3,938682436,4,1375788319,0,1043063449,2023-01-09T15:22:52Z,"sorry, I make a mistake, could you please resend/recreate it if you still want to land it?",False,0,COLLABORATOR
https://api.github.com/repos/mozilla/sccache/issues/1020,[feature] Multiple cache levels,browdus,3,943628968,1,943628968,0,0,2021-07-13T16:48:07Z,"Hi everyone! Is it possible, or has it been considered, to allow multiple levels of cache? For instance, using local disk as an L1 cache, and s3/azure/gcs as L2.

I envision it working something like the following:

```
Check disk cache according to current rules
if (found)
    return item

check s3/azure/gcs according to current rules
if (found)
    return item

compile item
populate disk cache
populate s3/azure/gcs cache

return item
```

This lets us use nvme as a hot cache, while still being able to hit the network cache if needed. This (theoretically) avoids a lot of network traffic and associated costs, and reduces build times on average. It also gives us a transparent way to seed new build hosts when they spin up, which makes automatic scaling of the build fleet more effective. Since each host has it's own hot cache, the load on s3/azure/gcs should scale better than linearly with the number of build hosts (on average; linear being the worst case).

Generically, it could be useful to mix/match all the cache types. For example, local disk as L1, on-prem memcached/redis as L2, and s3/azure/gcs as L3. Such a setup could be used to share build cache with all the devs in an office without hitting the internet as much, while still being able to share that build cache with other offices, etc.

Thanks!",True,0,NONE
https://api.github.com/repos/mozilla/sccache/issues/comments/879355340,[feature] Multiple cache levels,browdus,3,943628968,2,879355340,0,943628968,2021-07-13T19:49:13Z,"related: https://github.com/mozilla/sccache/pull/241, https://github.com/electron/electron/issues/21006, https://github.com/mozilla/sccache/issues/30",False,0,NONE
https://api.github.com/repos/mozilla/sccache/issues/comments/879951142,[feature] Multiple cache levels,browdus,3,943628968,3,879951142,0,879355340,2021-07-14T14:40:03Z,"For anyone wanting to do something similar, you can hack something together by combining `ccache` and `sccache`. The result is not optimal (multiple compression steps, for example), but it works reasonably well. This effectively gives you an L1 disk cache, and an L2 of anything `sccache` can handle.

```bash
export CCACHE_PREFIX=""sccache""
ccache gcc ...
```

If you are using cmake, make sure you don't have something like the following, as `sccache` will fail to handle linking (as designed).

```cmake
set_property(GLOBAL PROPERTY RULE_LAUNCH_LINK ccache)
```",False,0,NONE
https://api.github.com/repos/mozilla/sccache/issues/comments/889163481,[feature] Multiple cache levels,Be-ing,3,943628968,4,889163481,0,879951142,2021-07-29T13:53:20Z,"> set_property(GLOBAL PROPERTY RULE_LAUNCH_LINK ccache)

Use CMAKE_C_COMPILER_LAUNCHER / CMAKE_CXX_COMPILER_LAUNCHER rather than RULE_LAUNCH_COMPILE:
https://github.com/mozilla/sccache/issues/947",False,0,CONTRIBUTOR
https://api.github.com/repos/mozilla/sccache/issues/1024,fix Date header,lightsing,3,955546204,1,955546204,0,0,2021-07-29T07:28:50Z,"The `Date` header in s3 module doesn't obey the RFC7231 definition.
Causing s3-compatible server refuses sccache's request.

original request:
```
GET /0/1/2/012620f0a29db1fa159c8471bb82f9c25cad332cfffa5f680f7bb0cfd9c30e62 HTTP/1.1
date: Thu, 29 Jul 2021 06:56:44 +0000
authorization: AWS **RETRACTED**
user-agent: reqwest/0.9.24
accept: */*
accept-encoding: gzip
host: **RETRACTED**.oss-accelerate.aliyuncs.com
```
server response:
```
HTTP/1.1 403 Forbidden
Server: AliyunOSS
Date: Thu, 29 Jul 2021 06:56:44 GMT
Content-Type: application/xml
Content-Length: 252
Connection: keep-alive
x-amz-request-id: **RETRACTED**
x-oss-server-time: 0

<?xml version=""1.0"" encoding=""UTF-8""?>
<Error>
  <Code>AccessDenied</Code>
  <Message>OSS authentication requires a valid Date.</Message>
  <RequestId>6102512CBB04C5A3079D59B5</RequestId>
  <HostId>sccache.oss-accelerate.aliyuncs.com</HostId>
</Error>
```

patched request:
```
GET /c/c/6/cc65e6de3e04ef4f9eaae65e71fbba04019c78792364467217248f1b06bc3e71 HTTP/1.1
date: Thu, 29 Jul 2021 07:28:02 GMT
authorization: AWS **RETRACTED**
user-agent: reqwest/0.9.24
accept: */*
accept-encoding: gzip
host: **RETRACTED**.oss-accelerate.aliyuncs.com
```",True,0,CONTRIBUTOR
https://api.github.com/repos/mozilla/sccache/issues/comments/951826921,fix Date header,sylvestre,3,955546204,2,951826921,0,955546204,2021-10-26T11:07:49Z,"Could you please add a unit test for this? thanks
",False,0,COLLABORATOR
https://api.github.com/repos/mozilla/sccache/issues/comments/957205211,fix Date header,sylvestre,3,955546204,3,957205211,0,951826921,2021-11-02T08:27:52Z,"I was hoping for a unit test for the feature or the sccache function, not the date function itself :) ",False,0,COLLABORATOR
https://api.github.com/repos/mozilla/sccache/issues/comments/957280817,fix Date header,lightsing,3,955546204,4,957280817,0,957205211,2021-11-02T09:54:16Z,The `s3::Bucket::get` doesn't have unit test. It would be way more complex for mocking s3 request. And it doesn't make sense to add unit test on  `s3::Bucket::get` for this change.,False,0,CONTRIBUTOR
https://api.github.com/repos/rustdesk/rustdesk/issues/162,UOS Chinese input,open-trade,8,942734629,1,942734629,0,0,2021-07-13T04:51:36Z,Not work (chat window),True,0,CONTRIBUTOR
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/878783727,UOS Chinese input,gxon2019,8,942734629,2,878783727,0,942734629,2021-07-13T05:08:42Z,在统信uos系统里面，在其它软件里crtl+space可以切换到中文界入法并输入文字，但是在rustdesk软件上，无法切换。即使在系统里设置默认中文，也无法输入。,False,0,NONE
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/886997149,UOS Chinese input,rustdesk,8,942734629,3,886997149,0,878783727,2021-07-26T20:16:21Z,"https://sciter.com/forums/topic/cant-input-chinese-in-windows-2/#post-73074
Sciter does not support IME
@c-smile",False,0,OWNER
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/887100936,UOS Chinese input,c-smile,8,942734629,4,887100936,0,886997149,2021-07-26T23:42:47Z,"> https://sciter.com/forums/topic/cant-input-chinese-in-windows-2/#post-73074
> Sciter does not support IME
> @c-smile

That's not correct. IME is supported on Windows and Mac. 
But not Linux at the moment - to many Linuxes and IME mechanisms.
",False,0,NONE
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/887162008,UOS Chinese input,rustdesk,8,942734629,5,887162008,0,887100936,2021-07-27T02:36:37Z,"@c-smile Thanks, you can choose to support the most popular one on Linux, no need to support all.",False,0,OWNER
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/887162804,UOS Chinese input,rustdesk,8,942734629,6,887162804,0,887162008,2021-07-27T02:39:09Z,"@c-smile at the moment, deepin (derived from Ubuntu, UOS is the deepin enterprise version) is the most popular Linux in China, and it is widely used because of domestic substitution policy.",False,0,OWNER
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/903234485,UOS Chinese input,rustdesk,8,942734629,7,903234485,0,887162804,2021-08-22T08:40:38Z,"my memo

> 1、1.1.6win客户端 托盘图标 停止 启动 停止 启动 会掉中继服务器 1.1.5无此问题
2、1.1.6添加快捷方式后链接的名称不能更新过来 希望能在后续版本得到解决
3、远程对话框中间的ID建议改成备注名称 或者一起显示ID最好
4、主界面ID字太小啦 建议调大点
5、建议后续增加通讯录功能 通讯录内容存在配置文件那里就可以 如有需要 用其他同步软件直接同步到其他电脑
6、建议在通讯录里面增加查找功能
7、建议客户端链接那里显示最近连接客户端 下面显示通讯录
8、建议后续在配置文件里面可以手动选择显示托盘图标跟隐藏托盘图标 个人建议隐藏最好 我看到1.1.4是隐藏的
9、默认链接客户端希望可以自动调节窗口 免得每次都要点调节窗口 还有画面放大后比例最好是自动伸展
10、建议主界面添加一个设置按钮把所有的设置都放在 这个设置按钮里面 以及远程参数的默认设置
11、还有就是连接的默认密码 也放在以上的参数里面 目前好多参数都在配置文件里面 使用起来不方便",False,0,OWNER
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/1454358986,UOS Chinese input,da-liii,8,942734629,8,1454358986,0,903234485,2023-03-04T03:29:40Z,"> 在统信uos系统里面，在其它软件里crtl+space可以切换到中文界入法并输入文字，但是在rustdesk软件上，无法切换。即使在系统里设置默认中文，也无法输入。

这可能是具体某个软件的问题，这类问题我遇到过。我自己的软件，墨干编辑器就有这样的问题。我发现同样一个快捷键，直接在Linux系统里面用是没有问题的。如果我用远程桌面（zoho的远程桌面），那个快捷键就无法识别。",False,0,NONE
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/1482327301,UOS Chinese input,rustdesk,8,942734629,9,1482327301,0,1454358986,2023-03-24T06:39:43Z,fixed in nightly build.,False,0,OWNER
https://api.github.com/repos/rustdesk/rustdesk/issues/165,Compile on MacOs 11 (M1) fails,diegotibi,15,942977802,1,942977802,0,0,2021-07-13T08:29:56Z,"I've followed the build instructions, but I can't go thorught this error.

Here's the complete log:

cargo run --verbose
       Fresh cfg-if v1.0.0
       Fresh autocfg v1.0.1
       Fresh unicode-xid v0.2.2
       Fresh rand_core v0.4.2
       Fresh autocfg v0.1.7
       Fresh cfg-if v0.1.10
       Fresh adler v1.0.2
       Fresh regex-syntax v0.6.24
       Fresh glob v0.3.0
       Fresh gimli v0.23.0
       Fresh lazy_static v1.4.0
       Fresh termcolor v1.1.2
       Fresh rustc-demangle v0.1.18
       Fresh version_check v0.1.5
       Fresh object v0.23.0
       Fresh quick-error v1.2.3
       Fresh unicode-width v0.1.8
       Fresh vec_map v0.8.2
       Fresh strsim v0.8.0
       Fresh siphasher v0.2.3
       Fresh ansi_term v0.11.0
       Fresh shlex v0.1.1
       Fresh rustc-hash v1.1.0
       Fresh lazycell v1.3.0
       Fresh peeking_take_while v0.1.2
       Fresh pkg-config v0.3.19
       Fresh pin-project-lite v0.2.6
       Fresh futures-core v0.3.14
       Fresh futures-sink v0.3.14
       Fresh dasp_sample v0.11.0
       Fresh serde v0.9.15
       Fresh slab v0.4.3
       Fresh itoa v0.3.4
       Fresh scopeguard v1.1.0
       Fresh futures-io v0.3.14
       Fresh dtoa v0.4.8
       Fresh smallvec v1.6.1
       Fresh pin-utils v0.1.0
       Fresh once_cell v1.7.2
       Fresh futures-task v0.3.14
       Fresh version_check v0.9.3
       Fresh foreign-types-shared v0.1.1
       Fresh bytes v1.0.1
       Fresh ppv-lite86 v0.2.10
       Fresh dasp_ring_buffer v0.11.0
       Fresh block v0.1.6
       Fresh humantime v2.1.0
       Fresh void v1.0.2
       Fresh byteorder v1.4.3
       Fresh platforms v0.2.1
       Fresh mio-named-pipes v0.1.7
       Fresh yansi v0.5.0
       Fresh unescape v0.1.0
       Fresh opaque-debug v0.3.0
       Fresh itoa v0.4.7
       Fresh unicode-segmentation v1.7.1
       Fresh machine-uid v0.2.0
       Fresh dispatch v0.2.0
       Fresh instant v0.1.9
       Fresh rand_core v0.3.1
       Fresh addr2line v0.14.1
       Fresh textwrap v0.11.0
       Fresh humantime v1.3.0
       Fresh phf_shared v0.7.24
       Fresh futures-channel v0.3.14
       Fresh lock_api v0.4.4
       Fresh dasp_frame v0.11.0
       Fresh dasp_window v0.11.1
       Fresh foreign-types v0.3.2
       Fresh libc v0.2.94
       Fresh proc-macro2 v1.0.26
       Fresh memchr v2.4.0
       Fresh bitflags v1.2.1
       Fresh log v0.4.14
       Fresh rand_xorshift v0.1.1
       Fresh rand_isaac v0.1.1
       Fresh rand_hc v0.1.0
       Fresh proc-macro-hack v0.5.19
       Fresh phf v0.7.24
       Fresh proc-macro-nested v0.1.7
       Fresh serde v1.0.125
       Fresh protobuf v3.0.0-pre (https://github.com/stepancheg/rust-protobuf#bbe35a98)
       Fresh core-foundation-sys v0.8.2
       Fresh typenum v1.13.0
       Fresh dasp_peak v0.11.0
       Fresh dasp_rms v0.11.0
       Fresh dasp_interpolate v0.11.0
       Fresh dasp_slice v0.11.0
       Fresh winapi v0.3.9
       Fresh anyhow v1.0.40
       Fresh crc32fast v1.2.1
       Fresh ryu v1.0.5
       Fresh jobserver v0.1.22
       Fresh quote v1.0.9
       Fresh atty v0.2.14
       Fresh aho-corasick v0.7.18
       Fresh rand_os v0.1.3
       Fresh rand_jitter v0.1.4
       Fresh num_cpus v1.13.0
       Fresh getrandom v0.2.2
       Fresh malloc_buf v0.0.6
       Fresh parking_lot_core v0.8.3
       Fresh signal-hook-registry v1.3.0
       Fresh dirs-sys v0.3.6
       Fresh dirs-sys-next v0.1.2
       Fresh socket2 v0.3.19
       Fresh filetime v0.2.14
       Fresh time v0.1.43
       Fresh darwin-libproc-sys v0.1.2
       Fresh mach v0.3.2
       Fresh core-foundation-sys v0.6.2
       Fresh whoami v1.1.2
       Fresh rpassword v5.0.1
   Compiling sciter-rs v0.5.53 (/Users/ceres/rustdesk/libs/rust-sciter)
       Fresh miniz_oxide v0.4.4
       Fresh nom v4.2.3
       Fresh num-traits v0.2.14
       Fresh mio v0.7.13
       Fresh nix v0.19.1
       Fresh nix v0.17.0
       Fresh rand_chacha v0.1.1
       Fresh rand_pcg v0.1.2
       Fresh protobuf-codegen v3.0.0-pre (https://github.com/stepancheg/rust-protobuf#bbe35a98)
     Running `rustc --crate-name sciter libs/rust-sciter/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi --crate-type rlib --emit=dep-info,metadata,link -C embed-bitcode=no -C split-debuginfo=unpacked -C debuginfo=2 --cfg 'feature=""default""' --cfg 'feature=""dynamic""' -C metadata=1eeae39b6a83eb8a -C extra-filename=-1eeae39b6a83eb8a --out-dir /Users/ceres/rustdesk/target/debug/deps -C incremental=/Users/ceres/rustdesk/target/debug/incremental -L dependency=/Users/ceres/rustdesk/target/debug/deps --extern lazy_static=/Users/ceres/rustdesk/target/debug/deps/liblazy_static-6a58226798bc48d9.rmeta --extern libc=/Users/ceres/rustdesk/target/debug/deps/liblibc-c831fa18cfd367ff.rmeta`
       Fresh core-foundation v0.9.1
       Fresh toml v0.5.8
       Fresh generic-array v0.14.4
       Fresh cc v1.0.67
       Fresh dasp_envelope v0.11.0
       Fresh miow v0.3.7
       Fresh serde_json v1.0.64
       Fresh syn v1.0.71
       Fresh regex v1.5.2
       Fresh clap v2.33.3
       Fresh objc v0.2.7
       Fresh rand_core v0.6.2
       Fresh uuid v0.8.2
       Fresh parking_lot v0.11.1
       Fresh directories v2.0.2
       Fresh directories-next v2.0.0
       Fresh dirs-next v2.0.0
       Fresh darwin-libproc v0.1.2
       Fresh cexpr v0.3.6
       Fresh flate2 v1.0.20
       Fresh rand v0.6.5
       Fresh num-traits v0.1.43
       Fresh protobuf-codegen-pure v3.0.0-pre (https://github.com/stepancheg/rust-protobuf#bbe35a98)
       Fresh mac_address v1.1.1
       Fresh num-integer v0.1.44
       Fresh core-graphics-types v0.1.1
       Fresh block-buffer v0.9.0
       Fresh digest v0.9.0
       Fresh dasp_signal v0.11.0
       Fresh env_logger v0.7.1
       Fresh futures-macro v0.3.14
       Fresh tokio-macros v1.2.0
       Fresh rand_chacha v0.3.0
       Fresh thiserror-impl v1.0.24
       Fresh serde_derive v1.0.125
       Fresh env_logger v0.8.3
       Fresh objc_id v0.1.1
       Fresh derive_more v0.99.13
       Fresh async-trait v0.1.50
       Fresh phf_generator v0.7.24
       Fresh confy v0.4.1 (/Users/ceres/rustdesk/libs/confy)
       Fresh repng v0.2.2
   Compiling serde_json v0.9.10
   Compiling zstd-sys v1.6.1+zstd.1.5.0
   Compiling hbb_common v0.1.0 (/Users/ceres/rustdesk/libs/hbb_common)
   Compiling chrono v0.4.19
   Compiling libsodium-sys v0.2.6
   Compiling core-graphics v0.22.2
   Compiling runas v0.2.1
     Running `rustc --crate-name serde_json /Users/ceres/.cargo/registry/src/github.com-1ecc6299db9ec823/serde_json-0.9.10/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C embed-bitcode=no -C split-debuginfo=unpacked -C debuginfo=2 -C metadata=79dcd633288c9b95 -C extra-filename=-79dcd633288c9b95 --out-dir /Users/ceres/rustdesk/target/debug/deps -L dependency=/Users/ceres/rustdesk/target/debug/deps --extern dtoa=/Users/ceres/rustdesk/target/debug/deps/libdtoa-14e6732d8e5fbcfc.rmeta --extern itoa=/Users/ceres/rustdesk/target/debug/deps/libitoa-617bd1dfc7634f5f.rmeta --extern num_traits=/Users/ceres/rustdesk/target/debug/deps/libnum_traits-103f1462273aa985.rmeta --extern serde=/Users/ceres/rustdesk/target/debug/deps/libserde-7dd813a1301acdd6.rmeta --cap-lints allow`
     Running `rustc --crate-name build_script_build --edition=2018 libs/hbb_common/build.rs --error-format=json --json=diagnostic-rendered-ansi --crate-type bin --emit=dep-info,link -C embed-bitcode=no -C split-debuginfo=unpacked -C debuginfo=2 -C metadata=7131513008fc03bd -C extra-filename=-7131513008fc03bd --out-dir /Users/ceres/rustdesk/target/debug/build/hbb_common-7131513008fc03bd -C incremental=/Users/ceres/rustdesk/target/debug/incremental -L dependency=/Users/ceres/rustdesk/target/debug/deps --extern protobuf_codegen_pure=/Users/ceres/rustdesk/target/debug/deps/libprotobuf_codegen_pure-3142143ab310ee13.rlib`
     Running `/Users/ceres/rustdesk/target/debug/build/zstd-sys-d34e468130b1fd2b/build-script-build`
     Running `rustc --crate-name chrono /Users/ceres/.cargo/registry/src/github.com-1ecc6299db9ec823/chrono-0.4.19/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C embed-bitcode=no -C split-debuginfo=unpacked -C debuginfo=2 --cfg 'feature=""clock""' --cfg 'feature=""default""' --cfg 'feature=""libc""' --cfg 'feature=""oldtime""' --cfg 'feature=""std""' --cfg 'feature=""time""' --cfg 'feature=""winapi""' -C metadata=300240e1eb544418 -C extra-filename=-300240e1eb544418 --out-dir /Users/ceres/rustdesk/target/debug/deps -L dependency=/Users/ceres/rustdesk/target/debug/deps --extern libc=/Users/ceres/rustdesk/target/debug/deps/liblibc-c831fa18cfd367ff.rmeta --extern num_integer=/Users/ceres/rustdesk/target/debug/deps/libnum_integer-6197bfb5dc3b0ac8.rmeta --extern num_traits=/Users/ceres/rustdesk/target/debug/deps/libnum_traits-f33c92569ccbcf54.rmeta --extern time=/Users/ceres/rustdesk/target/debug/deps/libtime-78c718ecafacbc48.rmeta --cap-lints allow`
     Running `/Users/ceres/rustdesk/target/debug/build/libsodium-sys-b6b7f83318cdd91d/build-script-build`
     Running `rustc --crate-name core_graphics /Users/ceres/.cargo/registry/src/github.com-1ecc6299db9ec823/core-graphics-0.22.2/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C embed-bitcode=no -C split-debuginfo=unpacked -C debuginfo=2 --cfg 'feature=""default""' -C metadata=8624252f2a9737a8 -C extra-filename=-8624252f2a9737a8 --out-dir /Users/ceres/rustdesk/target/debug/deps -L dependency=/Users/ceres/rustdesk/target/debug/deps --extern bitflags=/Users/ceres/rustdesk/target/debug/deps/libbitflags-7e8c35729097e448.rmeta --extern core_foundation=/Users/ceres/rustdesk/target/debug/deps/libcore_foundation-5ef3218507057593.rmeta --extern core_graphics_types=/Users/ceres/rustdesk/target/debug/deps/libcore_graphics_types-c2811ab0e74c52a6.rmeta --extern foreign_types=/Users/ceres/rustdesk/target/debug/deps/libforeign_types-50ae9eea9c0ae293.rmeta --extern libc=/Users/ceres/rustdesk/target/debug/deps/liblibc-c831fa18cfd367ff.rmeta --cap-lints allow`
     Running `/Users/ceres/rustdesk/target/debug/build/runas-f06eb0293aed57e5/build-script-build`
error[E0463]: can't find crate for `objc`
  --> libs/rust-sciter/src/lib.rs:75:14
   |
75 | #[macro_use] extern crate objc;
   |              ^^^^^^^^^^^^^^^^^^ can't find crate

error: aborting due to previous error

For more information about this error, try `rustc --explain E0463`.
error: could not compile `sciter-rs`

Caused by:
  process didn't exit successfully: `rustc --crate-name sciter libs/rust-sciter/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi --crate-type rlib --emit=dep-info,metadata,link -C embed-bitcode=no -C split-debuginfo=unpacked -C debuginfo=2 --cfg 'feature=""default""' --cfg 'feature=""dynamic""' -C metadata=1eeae39b6a83eb8a -C extra-filename=-1eeae39b6a83eb8a --out-dir /Users/ceres/rustdesk/target/debug/deps -C incremental=/Users/ceres/rustdesk/target/debug/incremental -L dependency=/Users/ceres/rustdesk/target/debug/deps --extern lazy_static=/Users/ceres/rustdesk/target/debug/deps/liblazy_static-6a58226798bc48d9.rmeta --extern libc=/Users/ceres/rustdesk/target/debug/deps/liblibc-c831fa18cfd367ff.rmeta` (exit status: 1)
warning: build failed, waiting for other jobs to finish...
error: build failed",True,0,NONE
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/880698772,Compile on MacOs 11 (M1) fails,iakuf,15,942977802,2,880698772,0,942977802,2021-07-15T13:33:43Z,I have the same problem,False,0,NONE
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/880705631,Compile on MacOs 11 (M1) fails,diegotibi,15,942977802,3,880705631,0,880698772,2021-07-15T13:43:06Z,"No, it's not the same problem. I've compiled on another machine (Intel based mac) with no problems at all.

It's something due to the fact that M1 cpu is arm based, so the architecture can't be x86.",False,0,NONE
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/880707462,Compile on MacOs 11 (M1) fails,rustdesk,15,942977802,4,880707462,0,880705631,2021-07-15T13:45:36Z,"then you have to help youself, i have no m1",False,0,OWNER
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/880708823,Compile on MacOs 11 (M1) fails,rustdesk,15,942977802,5,880708823,0,880707462,2021-07-15T13:47:27Z,@diegotibi please contribute your compilation steps on m1 arm after you figure out.,False,0,OWNER
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/880714132,Compile on MacOs 11 (M1) fails,diegotibi,15,942977802,6,880714132,0,880708823,2021-07-15T13:54:17Z,"@rustdesk it's what I'm traying to do... So far the only step I've made is to change ""target.x86_64-apple-darwin.dependencies"" with ""target.'cfg(target_os = ""macos"")'.dependencies"" in libs/rust-sciter/Cargo.toml

The compilation still fails, at least for another reason",False,0,NONE
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/880740295,Compile on MacOs 11 (M1) fails,iakuf,15,942977802,7,880740295,0,880714132,2021-07-15T14:27:14Z,"> No, it's not the same problem. I've compiled on another machine (Intel based mac) with no problems at all.
> 
> It's something due to the fact that M1 cpu is arm based, so the architecture can't be x86.

my other notebook is ok. it only occur at M1 cpu.
",False,0,NONE
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/880783096,Compile on MacOs 11 (M1) fails,diegotibi,15,942977802,8,880783096,0,880740295,2021-07-15T15:18:07Z,"Now the error is:

Compiling scrap v0.5.0 (/Users/ceres/rustdesk/libs/scrap)
error[E0425]: cannot find value `DLL_NAMES` in this scope
   --> libs/rust-sciter/src/lib.rs:264:17
    |
264 |       let dll = DLL_NAMES.iter()
    |                 ^^^^^^^^^ not found in this scope

error[E0425]: cannot find value `DLL_NAMES` in this scope
   --> libs/rust-sciter/src/lib.rs:346:101
    |
346 |     Err(format!(""error: '{}' was not found neither in PATH nor near the current executable.\n  {}"", DLL_NAMES[0], msg))
    |                                                                                                     ^^^^^^^^^ not found in this scope

error[E0277]: the size for values of type `[u8]` cannot be known at compilation time
   --> libs/rust-sciter/src/lib.rs:270:15
    |
270 |         .map(|path| try_load(&path))
    |               ^^^^ doesn't have a size known at compile-time
    |
    = help: within `std::path::Path`, the trait `Sized` is not implemented for `[u8]`
    = note: required because it appears within the type `std::path::Path`
help: function arguments must have a statically known size, borrowed types always have a known size
    |
270 |         .map(|&path| try_load(&path))
    |               ^

error: failed to run custom build command for `magnum-opus v0.3.4 (/Users/ceres/rustdesk/libs/magnum-opus)`

Anyone knows where DLL_NAMES comes from? Is it something releted to vcpkg?",False,0,NONE
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/880801159,Compile on MacOs 11 (M1) fails,iakuf,15,942977802,9,880801159,0,880783096,2021-07-15T15:40:02Z,"I only use rust-sciter, this dir examples can run and is ok. ",False,0,NONE
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/880802195,Compile on MacOs 11 (M1) fails,iakuf,15,942977802,10,880802195,0,880801159,2021-07-15T15:41:26Z,"> Now the error is:
> 
> Compiling scrap v0.5.0 (/Users/ceres/rustdesk/libs/scrap)
> error[E0425]: cannot find value `DLL_NAMES` in this scope
> --> libs/rust-sciter/src/lib.rs:264:17
> |
> 264 | let dll = DLL_NAMES.iter()
> | ^^^^^^^^^ not found in this scope
> 
> error[E0425]: cannot find value `DLL_NAMES` in this scope
> --> libs/rust-sciter/src/lib.rs:346:101
> |
> 346 | Err(format!(""error: '{}' was not found neither in PATH nor near the current executable.\n {}"", DLL_NAMES[0], msg))
> | ^^^^^^^^^ not found in this scope
> 
> error[E0277]: the size for values of type `[u8]` cannot be known at compilation time
> --> libs/rust-sciter/src/lib.rs:270:15
> |
> 270 | .map(|path| try_load(&path))
> | ^^^^ doesn't have a size known at compile-time
> |
> = help: within `std::path::Path`, the trait `Sized` is not implemented for `[u8]`
> = note: required because it appears within the type `std::path::Path`
> help: function arguments must have a statically known size, borrowed types always have a known size
> |
> 270 | .map(|&path| try_load(&path))
> | ^
> 
> error: failed to run custom build command for `magnum-opus v0.3.4 (/Users/ceres/rustdesk/libs/magnum-opus)`
> 
> Anyone knows where DLL_NAMES comes from? Is it something releted to vcpkg?
you can set the env if vcpkg work under you home dir.
export VCPKG_ROOT=$HOME/vcpkg",False,0,NONE
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/880813952,Compile on MacOs 11 (M1) fails,diegotibi,15,942977802,11,880813952,0,880802195,2021-07-15T15:57:22Z,"> > you can set this env if vcpkg work under you home dir.
> > export VCPKG_ROOT=$HOME/vcpkg

Yep, already done, the path is ok, maybe there's a missing library, something that's not been ported on arm, I don't know.

In my MacBook, with the same software config (big sur 11.4, brew, vcpkg....) everithing works like a charm. 

",False,0,NONE
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/880877193,Compile on MacOs 11 (M1) fails,iakuf,15,942977802,12,880877193,0,880813952,2021-07-15T17:20:30Z,"  = note: ld: in /Users/Documents/data/rust/rustdesk.nosync/target/debug/deps/libscrap-7490b2efe03b6282.rlib(convert_argb.cc.o), archive member 'convert_argb.cc.o' with length 33944 is not mach-o or llvm bitcode for architecture arm64
          clang: error: linker command failed with exit code 1 (use -v to see invocation)
          
          
 I have a new error message. I use ""vcpkg/vcpkg install opus:arm64-osx"" to solve opus that doesn`t support arm64 at M1.
 what I can do if I want to make scrap support arm64 ?",False,0,NONE
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/881239026,Compile on MacOs 11 (M1) fails,iakuf,15,942977802,13,881239026,0,880877193,2021-07-16T07:30:24Z,"error[E0463]: can't find crate for `objc`
  --> libs/rust-sciter/src/lib.rs:75:14
   |
75 | #[macro_use] extern crate objc;
   |              ^^^^^^^^^^^^^^^^^^ can't find crate

error: aborting due to previous error

For more information about this error, try `rustc --explain E0463`.
error: could not compile `sciter-rs`

To learn more, run the command again with --verbose.
warning: build failed, waiting for other jobs to finish...
error: build failed


if the show as is the error above at macos m1. I modify Cargo.toml, use sciter-rs crate get crates.io, don`t use local dir. the problem is fixed. ",False,0,NONE
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/881246468,Compile on MacOs 11 (M1) fails,iakuf,15,942977802,14,881246468,0,881239026,2021-07-16T07:44:42Z,"error: failed to run custom build command for `magnum-opus v0.3.4 (/Users/Documents/data/rust/rustdesk.nosync/libs/magnum-opus)`

Caused by:
  process didn't exit successfully: `/Users/Documents/data/rust/rustdesk.nosync/target/debug/build/magnum-opus-d1d4fd09c644f155/build-script-build` (exit status: 101)
  --- stdout
  cargo:info=x64-osx
  cargo:rustc-link-lib=opus
  cargo:rustc-link-search=/Users/vcpkg/installed/x64-osx/lib
  cargo:include=/Users/vcpkg/installed/x64-osx/include
  rerun-if-changed=/Users/Documents/data/rust/rustdesk.nosync/libs/magnum-opus/opus_ffi.h
  rerun-if-changed=/Users/vcpkg/installed/x64-osx/include
  cargo:warning=couldn't execute `llvm-config --prefix` (error: No such file or directory (os error 2))
  cargo:warning=set the LLVM_CONFIG_PATH environment variable to a valid `llvm-config` executable
  
  and then have new error above. I think that build.rs not correctly the architecture. so i change the build.rs 
  `
  let target =  ""arm64-osx"".to_owned()
`
magnum-opus scrap is same.",False,0,NONE
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/881250662,Compile on MacOs 11 (M1) fails,iakuf,15,942977802,15,881250662,0,881246468,2021-07-16T07:52:13Z,"Please install the latest vcpkg， Before that, apple M1 will be mistakenly identified as x86_ OSX, the new one will be identified as arm64_ osx. ",False,0,NONE
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/881251193,Compile on MacOs 11 (M1) fails,iakuf,15,942977802,16,881251193,0,881250662,2021-07-16T07:53:11Z,Now I can compile normally,False,0,NONE
https://api.github.com/repos/rustdesk/rustdesk/issues/167,No menu to full exit in windows,CyrilTaylor,5,943965400,1,943965400,0,0,2021-07-14T02:06:55Z,There is not any menu to full exit in windows setup version,True,0,NONE
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/879529983,No menu to full exit in windows,rustdesk,5,943965400,2,879529983,0,943965400,2021-07-14T02:09:37Z,https://github.com/rustdesk/rustdesk/issues/38,False,0,OWNER
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/905158881,No menu to full exit in windows,rustdesk,5,943965400,3,905158881,0,879529983,2021-08-25T03:46:29Z,will redesign full exit on 1.1.9,False,0,OWNER
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/908192395,No menu to full exit in windows,open-trade,5,943965400,4,908192395,0,905158881,2021-08-30T09:30:51Z,and hide tray icon,False,0,CONTRIBUTOR
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/1397743462,No menu to full exit in windows,grummbeer,5,943965400,5,1397743462,0,908192395,2023-01-19T23:32:45Z,"> will redesign full exit on 1.1.9

done?",False,0,CONTRIBUTOR
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/1397769122,No menu to full exit in windows,rustdesk,5,943965400,6,1397769122,0,1397743462,2023-01-20T00:13:07Z,redesigned in nightly build,False,0,OWNER
https://api.github.com/repos/rustdesk/rustdesk/issues/170,Replace InnoSetup with improved NSIS Setup,sitiom,3,945369934,1,945369934,0,0,2021-07-15T13:16:50Z,"Thanks for putting the InnoSetup file. However, I have noticed a couple of problems with it:
- InnoSetup creates its own uninstaller and registry key. Rustdesk already has an uninstall parameter (`--uninstall`) and the InnoSetup uninstaller would just cause inconsistencies. The NSIS Setup uses the `--uninstall` parameter instead and installs in the correct reg key.
- Cannot overwrite RustDesk.exe and does not close process before installing (Fixed in NSIS)
- [Can be run in 32-bit](https://stackoverflow.com/questions/54335154/inno-setup-gets-launched-in-32-bit-even-after-specifying-architecturesinstallin6) (NSIS can still be run in 32-bit stops with an error message)

Here is the [setup file](https://github.com/rustdesk/rustdesk/files/6823235/rustdesk-1.1.6-setup.zip) for testing. If you want to compile it yourself, you need to have NSIS of course.

Closes #100.",True,0,CONTRIBUTOR
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/880705218,Replace InnoSetup with improved NSIS Setup,rustdesk,3,945369934,2,880705218,0,945369934,2021-07-15T13:42:32Z,[UninstallRun]? are you sure we can uninstall from control penel and it calls --uninstall?,False,0,OWNER
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/880707263,Replace InnoSetup with improved NSIS Setup,sitiom,3,945369934,3,880707263,0,880705218,2021-07-15T13:45:21Z,"> are you sure we can uninstall from control penel and it calls --uninstall?

Yeah, check the NSIS code and try the setup above.",False,0,CONTRIBUTOR
https://api.github.com/repos/rustdesk/rustdesk/issues/comments/880710499,Replace InnoSetup with improved NSIS Setup,rustdesk,3,945369934,4,880710499,0,880707263,2021-07-15T13:49:36Z,thanks,False,0,OWNER
https://api.github.com/repos/SevenTV/chatterino7/issues/24,"Snapping chatterino to the edge of the screen extends left, right, and bottom sides of the app off screen",7JEO,3,934090244,1,934090244,0,0,2021-06-30T20:14:00Z,"Chatterino 7.3.3 (commit 20a71273e)

When I drag chatterino to the edge of the screen on windows 10 to make it half the screen, the left edge is partly on my other monitor and the bottom is partly off screen.

I hope this video makes sense

https://user-images.githubusercontent.com/79304571/124025166-00bab780-d9a5-11eb-9974-ddd3e9031194.mp4

",True,0,NONE
https://api.github.com/repos/SevenTV/chatterino7/issues/comments/871704984,"Snapping chatterino to the edge of the screen extends left, right, and bottom sides of the app off screen",isabelcoolaf,3,934090244,2,871704984,0,934090244,2021-06-30T20:27:14Z,This occurs on the main Chatterino app as well. Might want to open this issue there instead.,False,0,NONE
https://api.github.com/repos/SevenTV/chatterino7/issues/comments/871705573,"Snapping chatterino to the edge of the screen extends left, right, and bottom sides of the app off screen",StephanBruh,3,934090244,3,871705573,0,871704984,2021-06-30T20:28:07Z,"This is a upstream issue, nothing to do with the chatterino7 fork",False,0,NONE
https://api.github.com/repos/SevenTV/chatterino7/issues/comments/871709204,"Snapping chatterino to the edge of the screen extends left, right, and bottom sides of the app off screen",zneix,3,934090244,4,871709204,0,871705573,2021-06-30T20:34:07Z,"I believe there was an exactly same issue reported on upstream Chatterino however the closest I could find is #2205, please try a [potential fix](https://github.com/Chatterino/chatterino2/issues/2205#issuecomment-868001183) from there.
I believe the same would happen on regular Chatterino - you can download [regular Chatterino nightly build](https://github.com/Chatterino/chatterino2/releases/tag/nightly-build) and I'm almost certain that the issue would occur there as well.
As StephanBruh mentioned, this has nothing to do with our fork so I'll close the issue for now. Please comment below if you have any questions.",False,0,NONE
https://api.github.com/repos/SevenTV/chatterino7/issues/27,Certain 7TV emotes not rendering,ichigo-gyunyu,3,941414579,1,941414579,0,0,2021-07-11T09:46:58Z,"### **Describe your issue**
Certain 7TV emotes do not render both in chat and the emote menu. 
Example: 
chatterino.image: Error while reading image ""https://cdn.7tv.app/emote/60b23db5f659090a743e147e/1x"" : ' ""Unsupported image format"" ' is the output on the terminal



### Screenshots

Actual Behaviour:
![image](https://user-images.githubusercontent.com/15829692/125190307-0b553680-e25a-11eb-816a-4425dc83764c.png)
Expected Behaviour:
![image](https://user-images.githubusercontent.com/15829692/125190344-3b9cd500-e25a-11eb-94a9-da8681b1e9cb.png)





### **OS and Chatterino Version**

OS: Artix Linux
Chatterino Version: Tried both the chatterino2-7tv-git aur and building from the chatterino7 branch


P.S. The expected behaviour screenshot was obtained by using the appimage from the 7.3.3 release, but I don't use that as audio from pings do not work in the appimage. 

",True,0,NONE
https://api.github.com/repos/SevenTV/chatterino7/issues/comments/881478353,Certain 7TV emotes not rendering,Melonify,3,941414579,2,881478353,0,941414579,2021-07-16T14:08:50Z,"Have you tried to install the `qt5imageformats` package or equivalent?
I had a similar issue with emotes like this, which I believe is caused by `libwebp` not being installed, the emotes which do render seem to be old ones which were uploaded prior to 7TV converting all emotes to webp.",False,0,NONE
https://api.github.com/repos/SevenTV/chatterino7/issues/comments/881496713,Certain 7TV emotes not rendering,ichigo-gyunyu,3,941414579,3,881496713,0,881478353,2021-07-16T14:35:05Z,"I had a feeling it was due to some missing library, which probably came bundled with the appimage. 
Downloading the `qt5-imageformats` package from the standard Arch repos seemes to have solved the issue. Thanks!",False,0,NONE
https://api.github.com/repos/SevenTV/chatterino7/issues/comments/947284374,Certain 7TV emotes not rendering,hugeblank,3,941414579,4,947284374,0,881496713,2021-10-20T03:13:54Z,"I'm having this issue in a Debian based OS, and can't find an apt package named `qt5-imageformats` or `libwebp`. If they do exist what is their equivalent name for dpkg/apt?

EDIT: Nevermind! I found it. For anyone curious, it's `qt5-image-formats-plugins`.",False,0,NONE
https://api.github.com/repos/SevenTV/chatterino7/issues/30,Loading previous messages not working,gryyyfin,3,946432482,1,946432482,0,0,2021-07-16T16:20:09Z,"Loading previous messages that were sent before Chatterino was open is not functional anymore, stopped working this morning when I started Chatterino. I tried reinstalling, didn't work. This feature was working as intended yesterday.",True,0,NONE
https://api.github.com/repos/SevenTV/chatterino7/issues/comments/881568207,Loading previous messages not working,gryyyfin,3,946432482,2,881568207,0,946432482,2021-07-16T16:23:28Z,"Running latest stable version, 7.3.3",False,0,NONE
https://api.github.com/repos/SevenTV/chatterino7/issues/comments/881583777,Loading previous messages not working,talneoran,3,946432482,3,881583777,0,881568207,2021-07-16T16:50:48Z,"This isn't a problem specific to this fork, but rather a temporary issue with the external service used to load recent messages. It seems to currently be down and loading recent messages will fail on both the fork and upstream (and on any version). ",False,0,COLLABORATOR
https://api.github.com/repos/SevenTV/chatterino7/issues/comments/881583854,Loading previous messages not working,AnatoleAM,3,946432482,4,881583854,0,881583777,2021-07-16T16:50:55Z,This isn't an issue with Chatterino 7.x.x as it would be occuring on upstream as well. But it is most likely the service used to fetch recent messages is currently offline,False,0,NONE
https://api.github.com/repos/SevenTV/chatterino7/issues/32,BTTV doesn't have priority over 7TV,brian6932,5,952029173,1,952029173,0,0,2021-07-24T08:26:25Z,"**Describe your issue**
On FFZ's 7TV add-on, BTTV has priority, however on the Chatterino version, 7TV added emotes with the same name have priority over BTTV. Messing with priority settings on the 7TV emote didn't fix it either.



**Screenshots**
![image_203](https://user-images.githubusercontent.com/18603393/126862387-663884a7-4e2b-4664-beb9-b9064d1a0772.png)
![image_204](https://user-images.githubusercontent.com/18603393/126862479-8bc1b186-e72f-4f56-87a6-4f6f7a2f4421.png)



**OS and Chatterino Version**
Windows 10, Chatterino 452da6bdd

",True,0,NONE
https://api.github.com/repos/SevenTV/chatterino7/issues/comments/886056132,BTTV doesn't have priority over 7TV,AnatoleAM,5,952029173,2,886056132,0,952029173,2021-07-24T13:47:37Z,At the moment emote priority is arbitrary. It primarily depends on which provider loads up first. It's up to the individual channels to ensure there are no conflicts,False,0,NONE
https://api.github.com/repos/SevenTV/chatterino7/issues/comments/886071372,BTTV doesn't have priority over 7TV,brian6932,5,952029173,3,886071372,0,886056132,2021-07-24T15:52:29Z,"ohhh, then what is this tab supposed to do? 
![image_207](https://user-images.githubusercontent.com/18603393/126873969-5f2c2856-60f1-47ea-92cc-242252cae3c1.png)
",False,0,NONE
https://api.github.com/repos/SevenTV/chatterino7/issues/comments/886071645,BTTV doesn't have priority over 7TV,AnatoleAM,5,952029173,4,886071645,0,886071372,2021-07-24T15:54:48Z,It exists as a backend value but it lacks wider client-side implementation for now,False,0,NONE
https://api.github.com/repos/SevenTV/chatterino7/issues/comments/886071766,BTTV doesn't have priority over 7TV,brian6932,5,952029173,5,886071766,0,886071645,2021-07-24T15:55:43Z,"Ah, makes sense, thank you",False,0,NONE
https://api.github.com/repos/SevenTV/chatterino7/issues/comments/1322916416,BTTV doesn't have priority over 7TV,Felanbird,5,952029173,6,1322916416,0,886071766,2022-11-22T02:06:49Z,Closing this because it's chatterino7 and it makes sense to have 7TV priority on the build that existed specifically to add 7TV. Also BTTV has re-taken priority in the chatterino2 implementation.,False,0,NONE
https://api.github.com/repos/znc/znc/issues/1796,"Add options to deny editing of Ident, RealName, QuitMsg, Networks/Servers & CTCP Replies",BradleyShaw,11,930820172,1,930820172,0,0,2021-06-27T00:29:38Z,"Closes #1682 

Add the following options:
* `DenySetIdent` - Denies setting ident
* `DenySetNetwork` - Denies adding/removing networks/servers
* `DenySetRealName` - Denies setting realname
* `DenySetQuitMsg` - Denies setting quitmsg
* `DenySetCTCPReplies` - Denies adding/removing CTCP replies",True,0,CONTRIBUTOR
https://api.github.com/repos/znc/znc/issues/comments/869182333,"Add options to deny editing of Ident, RealName, QuitMsg, Networks/Servers & CTCP Replies",mtnz0r,11,930820172,2,869182333,0,930820172,2021-06-27T15:34:41Z,incrediblenews thanksbuddy,False,0,NONE
https://api.github.com/repos/znc/znc/issues/comments/870129119,"Add options to deny editing of Ident, RealName, QuitMsg, Networks/Servers & CTCP Replies",loop-de-r00t,11,930820172,3,870129119,0,869182333,2021-06-29T00:09:22Z,Just tried this branch on a throwaway VPS and it works nicely. Awesome job,False,0,NONE
https://api.github.com/repos/znc/znc/issues/comments/873305277,"Add options to deny editing of Ident, RealName, QuitMsg, Networks/Servers & CTCP Replies",DarthGandalf,11,930820172,4,873305277,0,870129119,2021-07-02T23:41:12Z,Can you add any tests?,False,0,MEMBER
https://api.github.com/repos/znc/znc/issues/comments/873433669,"Add options to deny editing of Ident, RealName, QuitMsg, Networks/Servers & CTCP Replies",BradleyShaw,11,930820172,5,873433669,0,873305277,2021-07-03T16:30:16Z,"I've made the changes suggested in review, I'm not sure how to add tests",False,0,CONTRIBUTOR
https://api.github.com/repos/znc/znc/issues/comments/873435755,"Add options to deny editing of Ident, RealName, QuitMsg, Networks/Servers & CTCP Replies",DarthGandalf,11,930820172,6,873435755,0,873433669,2021-07-03T16:47:13Z,Take a look at test/integration/test directory,False,0,MEMBER
https://api.github.com/repos/znc/znc/issues/comments/873455752,"Add options to deny editing of Ident, RealName, QuitMsg, Networks/Servers & CTCP Replies",BradleyShaw,11,930820172,7,873455752,0,873435755,2021-07-03T19:05:56Z,Added tests for all DenySet* options,False,0,CONTRIBUTOR
https://api.github.com/repos/znc/znc/issues/comments/873459280,"Add options to deny editing of Ident, RealName, QuitMsg, Networks/Servers & CTCP Replies",codecov[bot],11,930820172,8,873459280,0,873455752,2021-07-03T19:32:35Z,"# [Codecov](https://codecov.io/gh/znc/znc/pull/1796?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=znc) Report
> Merging [#1796](https://codecov.io/gh/znc/znc/pull/1796?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=znc) (8a9423d) into [master](https://codecov.io/gh/znc/znc/commit/7035b378a8f8b14020057998cfc1c0c0f64ef3a7?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=znc) (7035b37) will **decrease** coverage by `5.37%`.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/znc/znc/pull/1796/graphs/tree.svg?width=650&height=150&src=pr&token=zrTmEzmqoi&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=znc)](https://codecov.io/gh/znc/znc/pull/1796?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=znc)

```diff
@@            Coverage Diff             @@
##           master    #1796      +/-   ##
==========================================
- Coverage   39.35%   33.98%   -5.38%     
==========================================
  Files         123        2     -121     
  Lines       28306      512   -27794     
  Branches      100       33      -67     
==========================================
- Hits        11140      174   -10966     
+ Misses      17119      313   -16806     
+ Partials       47       25      -22     
```


| [Impacted Files](https://codecov.io/gh/znc/znc/pull/1796?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=znc) | Coverage Δ | |
|---|---|---|
| [modules/modperl/startup.pl](https://codecov.io/gh/znc/znc/pull/1796/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=znc#diff-bW9kdWxlcy9tb2RwZXJsL3N0YXJ0dXAucGw=) | `33.59% <ø> (ø)` | |
| [modules/perleval.pm](https://codecov.io/gh/znc/znc/pull/1796/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=znc#diff-bW9kdWxlcy9wZXJsZXZhbC5wbQ==) | `100.00% <ø> (ø)` | |
| [include/znc/SHA256.h](https://codecov.io/gh/znc/znc/pull/1796/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=znc#diff-aW5jbHVkZS96bmMvU0hBMjU2Lmg=) | | |
| [include/znc/MD5.h](https://codecov.io/gh/znc/znc/pull/1796/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=znc#diff-aW5jbHVkZS96bmMvTUQ1Lmg=) | | |
| [src/SHA256.cpp](https://codecov.io/gh/znc/znc/pull/1796/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=znc#diff-c3JjL1NIQTI1Ni5jcHA=) | | |
| [src/MD5.cpp](https://codecov.io/gh/znc/znc/pull/1796/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=znc#diff-c3JjL01ENS5jcHA=) | | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/znc/znc/pull/1796?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=znc).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=znc)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/znc/znc/pull/1796?src=pr&el=footer&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=znc). Last update [6886454...8a9423d](https://codecov.io/gh/znc/znc/pull/1796?src=pr&el=lastupdated&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=znc). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=znc).
",False,0,NONE
https://api.github.com/repos/znc/znc/issues/comments/873461180,"Add options to deny editing of Ident, RealName, QuitMsg, Networks/Servers & CTCP Replies",DarthGandalf,11,930820172,9,873461180,0,873459280,2021-07-03T19:49:33Z,"> will decrease coverage by 5.37%.

Ignore this. It accidentally only measures perl coverage right now, after switch from Travis several days ago, ignoring any C++. I'm trying to fix it at #1798 ",False,0,MEMBER
https://api.github.com/repos/znc/znc/issues/comments/875938098,"Add options to deny editing of Ident, RealName, QuitMsg, Networks/Servers & CTCP Replies",DarthGandalf,11,930820172,10,875938098,0,873461180,2021-07-07T21:15:00Z,"![Выделение_379](https://user-images.githubusercontent.com/325092/124829591-b622d780-df70-11eb-8ab5-e8e111cb7fd0.png)

Could this show a better error message than a weird gray rectangle?",False,0,MEMBER
https://api.github.com/repos/znc/znc/issues/comments/875940851,"Add options to deny editing of Ident, RealName, QuitMsg, Networks/Servers & CTCP Replies",DarthGandalf,11,930820172,11,875940851,0,875938098,2021-07-07T21:19:10Z,"When JS is disabled, CTCP/Server editors are still editable. Also I think ""disabled"" is probably better than ""readonly"" for text fields, because it's more obvious that it's not editable",False,0,MEMBER
https://api.github.com/repos/znc/znc/issues/comments/933271481,"Add options to deny editing of Ident, RealName, QuitMsg, Networks/Servers & CTCP Replies",bashgeek,11,930820172,12,933271481,0,875940851,2021-10-04T08:41:29Z,"@BradleyShaw I apologise for jumping in here unannounced, but are you still working on this or could someone else take this over to get this to the finish line? We'd be willing to take this on if nobody objects, seems only small cosmetic changes are required to get this done. Thanks!",False,0,CONTRIBUTOR
https://api.github.com/repos/znc/znc/issues/1800,Remove freenode as default network option on initial setup,Code-Lyoko0,9,941083690,1,941083690,0,0,2021-07-09T21:48:11Z,"Due to freenode essentially being taken over by a hostile entity (see [here](https://gist.github.com/joepie91/df80d8d36cd9d1bde46ba018af497409) )I would suggest the default options for setup be changed to a different server. I would recommend  [LiberaChat](https://libera.chat/) as it is run by former staff that where forced to step down due to the takeover of the network, but any other network other then freenode would probably be a good change.",True,0,NONE
https://api.github.com/repos/znc/znc/issues/comments/877475969,Remove freenode as default network option on initial setup,MetaNova,9,941083690,2,877475969,0,941083690,2021-07-09T21:54:32Z,"Realistically, it also should be irc.libera.chat as this is where the official #znc channel is located.",False,0,NONE
https://api.github.com/repos/znc/znc/issues/comments/877480722,Remove freenode as default network option on initial setup,DarthGandalf,9,941083690,3,877480722,0,877475969,2021-07-09T22:06:40Z,"That's good to know, thanks!

Fortunately, we switched already. Both the default network in the configuration wizard, and #znc are on libera for a while now.",False,0,MEMBER
https://api.github.com/repos/znc/znc/issues/comments/877480888,Remove freenode as default network option on initial setup,DarthGandalf,9,941083690,4,877480888,0,877480722,2021-07-09T22:07:01Z,"Well, the wizard change is not in the release yet",False,0,MEMBER
https://api.github.com/repos/znc/znc/issues/comments/877482113,Remove freenode as default network option on initial setup,Code-Lyoko0,9,941083690,5,877482113,0,877480888,2021-07-09T22:09:53Z,"My mistake then! I just setup ZNC again and noticed that it was still freenode, so I wanted to raise the issue here. Thank you for changing the defaults so quickly.",False,0,NONE
https://api.github.com/repos/znc/znc/issues/comments/877734460,Remove freenode as default network option on initial setup,iczero,9,941083690,6,877734460,0,877482113,2021-07-11T03:14:51Z,"@CensorshipAlert that is bullshit and you know it. ZNC left freenode because their channel was nuked, and you (cmpunches/bagira/phanes, as freenode staff) were entirely complicit in this and hundreds of other unauthorized takeovers of channels belonging to FOSS projects. What other reason is needed?",False,0,NONE
https://api.github.com/repos/znc/znc/issues/comments/877753673,Remove freenode as default network option on initial setup,Code-Lyoko0,9,941083690,7,877753673,0,877734460,2021-07-11T07:15:59Z,"I would also like to make it clear, I have had no interactions with any staff at Libera about this, I am doing this of my own accord as a concerned former user of freenode. I simply think that since Freenode is basically a completely different network now, it should not be the default option anymore, and like MetaNova said above, the official #znc channel  is also on Libera so it only makes sense.",False,0,NONE
https://api.github.com/repos/znc/znc/issues/comments/877761849,Remove freenode as default network option on initial setup,DarthGandalf,9,941083690,8,877761849,0,877753673,2021-07-11T08:29:03Z,"@CensorshipAlert rasengan, did you register on github under a new name just to post this? Honestly, this only looks like a desperate attempt to get users back.

Re ZNC defaults: even if there would be no direct actions against #znc itself (there were), still, the majority of people and projects are now at libera. So it only makes sense to have libera as default now.

Re censorship: if I really wanted to censor people, I'd make ZNC to ignore user's server, and replace freenode with libera for all ZNC users, don't you think? Or do you want me to actually implement such censorship?
There's not much to do now on freenode other than trolling, but people are free to connect to it if they wish. It's just not the default.",False,0,MEMBER
https://api.github.com/repos/znc/znc/issues/comments/877805149,Remove freenode as default network option on initial setup,PlasmaStar,9,941083690,9,877805149,0,877761849,2021-07-11T14:00:55Z,"What's ironic, is certain entities trying to censor out the fact that thousands of users witnessed an exchange of power, by using petty immature comments.",False,0,NONE
https://api.github.com/repos/znc/znc/issues/1801,Someone help me. I'm having this problem when compiling znc.,GScripter,7,946333312,1,946333312,0,0,2021-07-16T14:13:41Z,"![Screenshot_20210716-110232](https://user-images.githubusercontent.com/69887726/125961231-c98d85c8-c74c-4b7c-8306-cb19417fe8c2.png)
",True,0,NONE
https://api.github.com/repos/znc/znc/issues/comments/881504885,Someone help me. I'm having this problem when compiling znc.,DarthGandalf,7,946333312,2,881504885,0,946333312,2021-07-16T14:47:17Z,You didn't provide ANY details there. OS? Version?,False,0,MEMBER
https://api.github.com/repos/znc/znc/issues/comments/881570626,Someone help me. I'm having this problem when compiling znc.,GScripter,7,946333312,3,881570626,0,881504885,2021-07-16T16:27:30Z,"@DarthGandalf This is my system:

![Screenshot_20210716-131702](https://user-images.githubusercontent.com/69887726/125979151-2ba4250c-e7f4-4ef7-af15-63239cb041fb.png)
",False,0,NONE
https://api.github.com/repos/znc/znc/issues/comments/881574892,Someone help me. I'm having this problem when compiling znc.,DarthGandalf,7,946333312,4,881574892,0,881570626,2021-07-16T16:34:45Z,Why are you trying to build it on Android?,False,0,MEMBER
https://api.github.com/repos/znc/znc/issues/comments/881608259,Someone help me. I'm having this problem when compiling znc.,RealKindOne,7,946333312,5,881608259,0,881574892,2021-07-16T17:34:51Z,"This?

https://play.google.com/store/apps/details?id=com.termux&hl=en_US&gl=US


https://wiki.termux.com/wiki/Main_Page",False,0,CONTRIBUTOR
https://api.github.com/repos/znc/znc/issues/comments/881621080,Someone help me. I'm having this problem when compiling znc.,GScripter,7,946333312,6,881621080,0,881608259,2021-07-16T17:58:04Z,@DarthGandalf I don't have pc so I do everything on android.,False,0,NONE
https://api.github.com/repos/znc/znc/issues/comments/881621716,Someone help me. I'm having this problem when compiling znc.,GScripter,7,946333312,7,881621716,0,881621080,2021-07-16T17:59:10Z,@RealKindOne Yes,False,0,NONE
https://api.github.com/repos/znc/znc/issues/comments/881624406,Someone help me. I'm having this problem when compiling znc.,DarthGandalf,7,946333312,8,881624406,0,881621716,2021-07-16T18:03:58Z,"Why didn't you provide all the details in the initial question? First, please read http://www.catb.org/~esr/faqs/smart-questions.html

Quick google search points at https://stackoverflow.com/questions/4610086/pthread-cancel-alternatives-in-android-ndk and https://github.com/tux-mind/libbthread
You can try those",False,0,MEMBER
https://api.github.com/repos/znc/znc/issues/1802,modpython socket creation does not persist,arfNZ,5,954501290,1,954501290,0,0,2021-07-28T05:53:43Z,"I am attempting to open a telnet socket using the example socket code from https://wiki.znc.in/Modpython - the socket creates and connects ok, but immediately disconnects and shuts down without ever triggering OnReadLine().  OnReadData triggers, despite EnableReadLine() having been used prior.  If I put Write() statements immediately after Connect() the data is transmitted (and received) but the connection then closes.  OnSockError() sees nothing (assuming this is exposed in modpython).

How do I get the socket to persist?",True,0,NONE
https://api.github.com/repos/znc/znc/issues/comments/888171491,modpython socket creation does not persist,arfNZ,5,954501290,2,888171491,0,954501290,2021-07-28T09:48:34Z,"Sorry, should have included the code.  The host in question is an eggdrop bot, FYI.
```
# telnettest.py
import znc
    
class telnettest(znc.Module):
    description = ""Telnet Test Module""
    
    def OnRaw(self, rawline):
        self.PutStatus(rawline.s)
        return znc.CONTINUE
    
    def OnModCommand(self, cmd):
        #any command to start the test
        self.sock = self.CreateSocket(telconn, ""localhost"", 30200)
        return znc.CONTINUE
        

class telconn(znc.Socket):
    def Init(self, host, port):
        self.Connect(host,port,timeout=60)
        self.EnableReadLine()
        return znc.CONTINUE
        
    def OnReadLine(self, line):
        self.GetModule().PutStatus(""OnReadLine: {0}"".format(line))
        return znc.CONTINUE
    
    def OnConnected(self):
        self.GetModule().PutStatus(""connected"")
        self.GetModule().PutStatus(self.GetRemoteIP())
        return znc.CONTINUE
    
    def OnReadData(self, data):
        #self.GetModule().PutStatus(""OnReadData: {0}"".format(data))
        self.GetModule().PutStatus(""OnReadData: {0}"".format("""".join(map(chr, data))))
        return znc.CONTINUE
    
    def OnDisconnected(self):
        self.GetModule().PutStatus(""disconnected"")
        return znc.CONTINUE
```
Output to *status is:
```
<*status> connected
<*status> 127.0.0.1
<*status> OnReadData: ÿû
<*status> Botname  (Eggdrop v1.8.4 (C) 1997 Robey Pointer (C) 2010-2018 Eggheads)
<*status> Please enter your nickname.
<*status> disconnected
```",False,0,NONE
https://api.github.com/repos/znc/znc/issues/comments/888178434,modpython socket creation does not persist,DarthGandalf,5,954501290,3,888178434,0,888171491,2021-07-28T09:59:31Z,"Can you check `znc -D`?

`ÿû�` looks concerning. Does the module stay loaded after the disconnect?

My suspicion is that it can't parse the line as UTF-8 (the default encoding), and reports the error via closing it.

> OnReadData triggers, despite EnableReadLine() having been used prior

Correct. OnReadData triggers for all data. OnReadLine is triggered for lines only, after parsing them from raw bytes with the specified encoding.",False,0,MEMBER
https://api.github.com/repos/znc/znc/issues/comments/888186305,modpython socket creation does not persist,arfNZ,5,954501290,4,888186305,0,888178434,2021-07-28T10:11:34Z,"> Can you check `znc -D`?

I think you're onto something - znc -D shows: 
```
[2021-07-28 22:06:31.886761] python socket failed in OnReadLine: UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\x0A
```
> `ÿû�` looks concerning. Does the module stay loaded after the disconnect?

Yes, the module stays loaded. 

> Correct. OnReadData triggers for all data. OnReadLine is triggered for lines only, after parsing them from raw bytes with the specified encoding.

So possibly I'm never getting to that point as it's erroring and closing the socket when the decode fails.
",False,0,NONE
https://api.github.com/repos/znc/znc/issues/comments/888188576,modpython socket creation does not persist,DarthGandalf,5,954501290,5,888188576,0,888186305,2021-07-28T10:15:07Z,"Either don't use `EnableReadLine()`, so that it doesn't try to decode the bytes at all, or specify the encoding via `SetEncoding()`, which supports some fallback options between UTF-8 and something else (which I should document somewhere...)",False,0,MEMBER
https://api.github.com/repos/znc/znc/issues/comments/888204225,modpython socket creation does not persist,arfNZ,5,954501290,6,888204225,0,888188576,2021-07-28T10:35:10Z,"> Either don't use `EnableReadLine()`, so that it doesn't try to decode the bytes at all, or specify the encoding via `SetEncoding()`, which supports some fallback options between UTF-8 and something else (which I should document somewhere...)

Awesome, thanks.  Using `SetEncoding('utf8')` gets me past that point - will soldier on - thanks a lot!",False,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/1165,Require a local-part to be a valid email address in AUTOMAIL_RE.,nzlosh,4,957429802,1,957429802,0,0,2021-08-01T08:26:16Z,"Valid email addresses require a _local-part_ before the `@` followed by _domain_.  This PR updates the `AUTOMAIL_RE` to use the `+` quantifier to require 1 or more characters in the _local-part_ instead of the `*` quantifier which allows 0 characters.

The current regex allows the invalid addresses in the form `<@domain>`.  My particular use case is formatting messages in Slack, where mentioned users take the form `<@Uxxxxx>`.  markdown is incorrectly processing the mention string form as an email address.  I still want markdown's automail feature for processing email addressing in the text.

The below code demonstrates the current and new behaviour:

```
>>> AUTOMAIL_RE = r'<([^<> !]*@[^@<> ]*)>'
>>> print(re.match(AUTOMAIL_RE, ""<@localhost>""))
<re.Match object; span=(0, 12), match='<@localhost>'>
>>> print(re.match(AUTOMAIL_RE, ""<bob@localhost>""))
<re.Match object; span=(0, 15), match='<bob@localhost>'>

>>> AUTOMAIL_RE = r'<([^<> !]+@[^@<> ]*)>'
>>> print(re.match(AUTOMAIL_RE, ""<@localhost>""))
None
>>> print(re.match(AUTOMAIL_RE, ""<bob@localhost>""))
<re.Match object; span=(0, 15), match='<bob@localhost>'>
```
",True,0,CONTRIBUTOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/890489833,Require a local-part to be a valid email address in AUTOMAIL_RE.,mitya57,4,957429802,2,890489833,0,957429802,2021-08-01T10:12:53Z,"Make it makes sense to also replace `*` with `+` in the domain part? With your fix it still allows for addresses like `bob@`:

```python
>>> AUTOMAIL_RE = r'<([^<> !]+@[^@<> ]*)>'
>>> re.match(AUTOMAIL_RE, ""<bob@>"")
<re.Match object; span=(0, 6), match='<bob@>'>
```",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/890569157,Require a local-part to be a valid email address in AUTOMAIL_RE.,nzlosh,4,957429802,3,890569157,0,890489833,2021-08-01T18:58:05Z,I've updated the regex to require both `local-part` and `domain`.,False,0,CONTRIBUTOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/890887848,Require a local-part to be a valid email address in AUTOMAIL_RE.,nzlosh,4,957429802,4,890887848,0,890569157,2021-08-02T09:49:11Z,"I've added tests for the missing local-part and domain.  I noticed that the `<>` characters are encoded in html form `&lt;&gt;` for the missing local-part, but not for the missing domain part.  The tests mirror this behaviour, but I don't know if it's expected behaviour or not. ",False,0,CONTRIBUTOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/892524941,Require a local-part to be a valid email address in AUTOMAIL_RE.,nzlosh,4,957429802,5,892524941,0,890887848,2021-08-04T09:53:58Z,"Thanks for the pointers, I've updated the PR with the recommended changes.",False,0,CONTRIBUTOR
https://api.github.com/repos/Python-Markdown/markdown/issues/1169,Re-use compiled regex for block level checks,HebaruSan,5,963448527,1,963448527,0,0,2021-08-08T14:49:09Z,"## Problem

This page takes several seconds to load:

- https://spacedock.info/mod/795

## Cause

We've hit a somewhat exceptional case in that there are 76+ different markdown documents to render to HTML for that page (the author of the mod has been very prolific with creating releases, see [the ""changelog"" list at the bottom](https://spacedock.info/mod/795#changelog)).

With profiling enabled, it turns out that about one second is spent (re-)compiling a regex inside of `isblocklevel`, once per markdown document:

![image](https://user-images.githubusercontent.com/1559108/128635975-5e3ca35b-89fa-4e1a-aebb-b2cebb9ef40e.png)

## Other ideas

We (site developers) will probably take a number of other actions to address this slowness, such as paginating the releases and pre-rendering the markdown to HTML when saving to SQL rather than at render. But that regex still represents some low-hanging fruit for other users with many documents to render.

## Changes

Now that regex is compiled once at startup and re-used in compiled form as needed. Should speed up rendering multiple documents modestly.

FYI to @DasSkelett, going to see how this goes.",True,0,CONTRIBUTOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/894831554,Re-use compiled regex for block level checks,HebaruSan,5,963448527,2,894831554,0,963448527,2021-08-08T17:49:23Z,"Which changelog file should I update? I see one recent commit editing `index.md` and another editing `release-3.3.md`.

https://github.com/Python-Markdown/markdown/commit/4b20c168bc4afa0a3775080d803e38694fac17b3

https://github.com/Python-Markdown/markdown/commit/e11cd255cae5fd3c5ef5fdd6352cd28e212fd328",False,0,CONTRIBUTOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/894845929,Re-use compiled regex for block level checks,mitya57,5,963448527,3,894845929,0,894831554,2021-08-08T19:46:43Z,"Please edit `docs/change_log/index.md`. The second commit is wrong (Cc @facelessuser; and 0e6dc4c4f5dc8d66 was wrong too…)

By the way, thanks for the change. Compiling regular expressions is almost always the right thing to do.",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/894902011,Re-use compiled regex for block level checks,facelessuser,5,963448527,4,894902011,0,894845929,2021-08-09T01:38:04Z,"@mitya57 thanks for pinging me, I'll get that fixed. I always forget how the changelogs work.",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/971509610,Re-use compiled regex for block level checks,remusao,5,963448527,5,971509610,0,894902011,2021-11-17T11:55:48Z,"> By the way, thanks for the change. Compiling regular expressions is almost always the right thing to do.

Sorry for jumping in but this part got me curious. As far as I know CPython will always cache[1] the compiled regexps internally so using compile and storing globally should not be the right thing to do (maybe unless there are enough different regexps in the program that the internal cache is too small to hold all of them). I am a bit surprised that you got a performance improvement from this change. Can you confirm that the slowness initially reported is fixed after this change was applied?

[1] https://stackoverflow.com/a/12514276",False,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/972722996,Re-use compiled regex for block level checks,mitya57,5,963448527,6,972722996,0,971509610,2021-11-18T10:12:18Z,"Python-Markdown itself has around 70 various regular expressions. `grep -Er 're\.(sub|match|compile|search)' markdown | wc -l` returns 79 for me. CPython's `re._MAXCACHE` is 512 by default.

Small projects are unlikely to reach that limit. But projects may import other modules with regular expressions, not only markdown. And in such case this limit will be reached sooner or later.

So I think even if compiling is not always useful, in some cases it is, and because it causes no harm, why not use it.",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/1172,"Multi-paragraph list items don't (always?) work, example inside",ell1e,11,965558043,1,965558043,0,0,2021-08-10T23:43:05Z,"This is accepted by most other major markdown renderers I have tried, but python markdown doesn't seem to like multiple paragraphs in a list item - at least not indented like here:

**Input:**
```
* abcd.
  this is paragraph 1.

  efgh

* blubb
```

**Expected output** (Github):

> * abcd.
>   this is paragraph 1.
>
>   efgh
>
> * blubb

**Actual output** (python markdown):

```
>>> markdown.markdown(""* abcd.\n  this is paragraph 1.\n\n  efgh\n\n* blubb"")
'<ul>\n<li>abcd.\n  this is paragraph 1.</li>\n</ul>\n<p>efgh</p>\n<ul>\n<li>blubb</li>\n</ul>'
>>> 
```
*(two separate `<ul>` lists, and `efgh` is not part of first list item as expected)*",True,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/896386681,"Multi-paragraph list items don't (always?) work, example inside",facelessuser,11,965558043,2,896386681,0,965558043,2021-08-10T23:48:47Z,New paragraphs need to start with 4 spaces for the indentation. This is mentioned in the documentation.,False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/896397081,"Multi-paragraph list items don't (always?) work, example inside",ell1e,11,965558043,3,896397081,0,896386681,2021-08-11T00:14:45Z,"Consider it a feature request then. All other markdown libs (+that I have tried) support it like this, too, so why not python markdown? People writing markdown tend to do so intuitively, not matching an exact indent that might be documented in whatever spot, so I feel like this would be a great improvement for user friendliness.",False,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/896447065,"Multi-paragraph list items don't (always?) work, example inside",facelessuser,11,965558043,4,896447065,0,896397081,2021-08-11T02:16:23Z,"Python Markdown is an old school parser. This question has been asked multiple times.

Python Markdown is also not alone either: https://johnmacfarlane.net/babelmark2/?normalize=1&text=*+abcd.%0A++this+is+paragraph+1.%0A%0A++efgh%0A%0A*+blubb. But yes, it is in the minority.

Anyways, @waylan (the maintainer) has mentioned before that there are no plans to change this behavior. I'll let him weigh in, but I imagine the stance is still the same",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/896822455,"Multi-paragraph list items don't (always?) work, example inside",waylan,11,965558043,5,896822455,0,896447065,2021-08-11T13:21:22Z,"@facelessuser is correct. Based on a strict reading of the original rules, any other behavior is a bug IMO. If you want different behavior, then you are free to create your own extension.",False,0,MEMBER
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/896924956,"Multi-paragraph list items don't (always?) work, example inside",ell1e,11,965558043,6,896924956,0,896822455,2021-08-11T15:28:32Z,"Is there an extension for this? Or any other python library for markdown that cares more about the end user expectations? (I also think how markdown has grown to be used, sticking religiously to specs isn't really in the spirit of the format, but that's just me.)

Edit: just to be more clear on that point,

> Based on a strict reading of the original rules

I could be wrong, but my confident guess would be 99% of people using markdown don't know the ""original rules"" and likely prefer not to need to know what they are",False,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/896951944,"Multi-paragraph list items don't (always?) work, example inside",facelessuser,11,965558043,7,896951944,0,896924956,2021-08-11T16:02:47Z,"> Is there an extension for this? Or any other python library for markdown that cares more about the end user expectations? (I also think how markdown has grown to be used, sticking religiously to specs isn't really in the spirit of the format, but that's just me.)

There are a number of CommonMark and/or CommonMark-ish libraries, and some other various Markdown libraries available for Python. I do not have a list of what they are and what they can and cannot do. You are free to research them and find one that best suits you. I imagine a CommonMark(ish) library may have more consistency with what you are used to.

There are many libraries out there, all with slightly different quirks. Some libraries approached things a bit differently than maybe others. This is kind of why CommonMark came about.  Some libraries out there may arguably be better than Python Markdown depending on what you are measuring by. 

Python Markdown is not a CommonMark(ish) library but follows the admittedly loose, original spec.  While I have never viewed Python Markdown's indentation requirement as a weakness, Python Markdown does have its share of weaknesses, but despite those weaknesses, the reason why I continue to use and contribute to Python Markdown is its ease of extendibility. I have valued that more than having a CommonMark(ish) library.


",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/896963971,"Multi-paragraph list items don't (always?) work, example inside",ell1e,11,965558043,8,896963971,0,896951944,2021-08-11T16:18:09Z,"> This is kind of why CommonMark came about. 

Thanks, this was a very useful hint! There appears to be a `commonmark.py` project, I will check that one out then. Thanks again",False,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/985723502,"Multi-paragraph list items don't (always?) work, example inside",alkisg,11,965558043,9,985723502,0,896963971,2021-12-03T18:06:10Z,"I was just affected by this issue. I saw that github, gitlab etc were using `- bullet` when I clicked on the comments toolbar bullet button, and some sites like [mkdocs-material](https://raw.githubusercontent.com/squidfunk/mkdocs-material/master/docs/reference/lists.md) was using two spaces as well, so I spent a few hours to adjust our documentation to use this consistently.

Then I bumped into a page that needed a fenced code block inside a bullet, and I searched and I found this issue; now I'll need to spend a few more hours to realign everything to four spaces!... :D",False,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/985731225,"Multi-paragraph list items don't (always?) work, example inside",alkisg,11,965558043,10,985731225,0,985723502,2021-12-03T18:18:45Z,"Btw is there any way to use bulleted lists with 2 spaces, and *then* use 4 spaces indentation for whatever's inside them?
I wasn't able to make this work in python-markdown:

````
- bullet

      shell code

  How to continue the bullet?
````

It displays fine on github, the bullet (html li tag) can be continued properly:

- bullet

      shell code

  How to continue the bullet?",False,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/987120301,"Multi-paragraph list items don't (always?) work, example inside",waylan,11,965558043,11,987120301,0,985731225,2021-12-06T19:39:32Z,"@alkisg whenever you are working with complex nesting I suggest you first structure the section of the document as if it was at the root level. Then, when you have that right, indent the entire section by one additional level. For you example, the final document should be as follows (with `·` used to represent spaces for clarity):

```
-···bullet

········shell code

····How to continue the bullet?
```

The extra two spaces on the first line are optional, but I prefer them as if keeps everything lined up. Remember, each level is four spaces. That means that any final level of indent must be divisible by four (6 is not). 

Oh and for the record, ""it works on GitHub"" is not relevant because we are following a different set of rules (Markdown, not Commonmark).",False,0,MEMBER
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/987263732,"Multi-paragraph list items don't (always?) work, example inside",alkisg,11,965558043,12,987263732,0,987120301,2021-12-06T21:48:24Z,"Thank you @waylan, this example cleared things up in my mind about the markdown levels.

> we are following a different set of rules

I understand; but, C reached version C16 (2017), ECMAScript reached version 12 (2021) etc. In order to do that, they improved their specifications trying as much as they could not to break things. Maybe some similar things could happen with markdown whenever appropriate... if not, sure, that's understandable as well.

",False,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/1174,"Feature Request: Set HTML ""id"" for admonition blocks",iBug,3,970346459,1,970346459,0,0,2021-08-13T12:15:06Z,"As far as I understand, admonition blocks support extra classes via the syntax `!!! class1 class2 class3`. It would be nice if this could be extended to support an `id` for navigation.

Example input:

    !!! class1 class2 #my_admonition

Example output:

    <div class=""admonition class1 class2"" id=""my_admonition"">

It would be better if the hash tag can appear in the class list, so `!!! class1 #my_admonition class2` should produce the same output. The behavior would be undefined if multiple ""hash tags"" are present for the same admonition block, as it's up to the user to ensure the syntax is valid (it's invalid HTML that one element has multiple IDs).

I've seen #685 and it seems at first glance it wouldn't be too complex to add this support, but I'm open to any thoughts and ideas you may have.",True,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/898501692,"Feature Request: Set HTML ""id"" for admonition blocks",waylan,3,970346459,2,898501692,0,970346459,2021-08-13T14:35:30Z,"Interesting proposal. I'm wondering if perhaps a better solution is to add support for [attr_list][0], much like we do with [fenced code blocks][1]. The simple (one class) form can continue to work as it does now, but for more complex situations, the user should provide a curly bracket wrapped attr_list. The tricky part about that is that attr_lists always go at the end, but in admonitions, the title is at the end. How about this:

```
!!! type ""Title"" { #id class1 class2 }
```

Or maybe we use a second line. Like this:

```
!!! type ""Title"" 
    { #id class1 class2 }
```

The problem is that that is not compatible with #685. In retrospect, we probably should have implemented this instead. But it's too late to change that now. I would propose that the attr_list should only be supported when the `attr_list` extension is also enabled. When the `attr_list` extension is not enabled, we can continue to support multiple classes as we do now (but no longer document it).

[0]: https://python-markdown.github.io/extensions/attr_list/
[1]: https://python-markdown.github.io/extensions/fenced_code_blocks/#attributes",False,0,MEMBER
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/898540445,"Feature Request: Set HTML ""id"" for admonition blocks",waylan,3,970346459,3,898540445,0,898501692,2021-08-13T15:23:43Z,"BTW, I've been kicking around the idea of creating a new extension for a general purpose block, which could complexly negate the need for the admonition extension. I'm thinking that if this new extension was to be built, then our efforts would be better spent there than on improving the admonitions extension. A rough sketch is outlined in #1175.",False,0,MEMBER
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1799922719,"Feature Request: Set HTML ""id"" for admonition blocks",waylan,3,970346459,4,1799922719,0,898540445,2023-11-07T20:18:58Z,"I'm closing this in favor of [admonition blocks](https://facelessuser.github.io/pymdown-extensions/extensions/blocks/plugins/admonition/), which is the result of my proposal in #1175. As one of the examples in the documentation demonstrates, any HTML attributes can be defined on the admonition:

```
/// note | Some title
    attrs: {class: class-name: id: id-name}

Some content
///
```",False,0,MEMBER
https://api.github.com/repos/WordPress/gutenberg/issues/34320,[wordpress/env] Service 'wordpress' failed to build: The command '/bin/sh -c pecl install xdebug && docker-php-ext-enable xdebug' returned a non-zero code: 1,brylie,19,979989344,1,979989344,0,0,2021-08-26T08:42:26Z,"### Description

When making changes to `.wp-env.json`, such as adding a directory mapping, the ""Wordpress"" Docker service fails to build, with the following error:

```sh
Step 3/6 : RUN pecl install xdebug && docker-php-ext-enable xdebug
 ---> Running in 18fb0d7ebafd
pecl/xdebug is already installed and is the same as the released version 3.0.4
install failed
Building wordpress
Service 'wordpress' failed to build: The command '/bin/sh -c pecl install xdebug && docker-php-ext-enable xdebug' returned a non-zero code: 1
```

Similar issues have been reported, but it has not been mentioned that this is a recurring issue when re-building the `wordpress` service.

- https://github.com/WordPress/gutenberg/issues/30213
- https://github.com/WordPress/gutenberg/issues/27783

### Step-by-step reproduction instructions

1. set up a `wordpress/env` project and run it once successfully
2. make changes to `.wp-env.json`, such as adding a directory mapping
3. run `wp-env start` again

Note: running `wp-env destroy` does not resolve the issue as the ""Wordpress"" service doesn't seem to get destroyed/rebuilt unless, e.g., changing the PHP version.

### Screenshots, screen recording, code snippet

_No response_

### Environment info

wp-env:
- 4.1.2

node:
- 12.22.x

npm:
- 6.14.12
- 8.0.0

### Pre-checks

- [X] I have searched the existing issues.
- [x] I have tested with all plugins deactivated except Gutenberg.",True,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/906217236,[wordpress/env] Service 'wordpress' failed to build: The command '/bin/sh -c pecl install xdebug && docker-php-ext-enable xdebug' returned a non-zero code: 1,brylie,19,979989344,2,906217236,0,979989344,2021-08-26T08:48:26Z,"Running `docker ps -a` shows the failed container is not destroyed, despite having run the `wp-env destroy` command:

![image](https://user-images.githubusercontent.com/17307/130932159-ffdd0b30-6adf-426c-8120-45c198b3d262.png)
",False,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/906220804,[wordpress/env] Service 'wordpress' failed to build: The command '/bin/sh -c pecl install xdebug && docker-php-ext-enable xdebug' returned a non-zero code: 1,brylie,19,979989344,3,906220804,0,906217236,2021-08-26T08:53:24Z,"I have tried

- removing all docker containers and volumes
    -  `docker rm -f $(docker ps -a -q)`
    - `docker volume rm $(docker volume ls -q)`
- destroying the `wp-env` directory
    - `wp-env destroy`
- changing the `phpVersion` to 7.3, 7.4, and 8.0

However, the problem still persists.",False,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/906222689,[wordpress/env] Service 'wordpress' failed to build: The command '/bin/sh -c pecl install xdebug && docker-php-ext-enable xdebug' returned a non-zero code: 1,brylie,19,979989344,4,906222689,0,906220804,2021-08-26T08:56:05Z,Perhaps the command `pecl install xdebug && docker-php-ext-enable xdebug` is trying to do too much? It seems odd that it is exiting with status code 1.,False,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/915648271,[wordpress/env] Service 'wordpress' failed to build: The command '/bin/sh -c pecl install xdebug && docker-php-ext-enable xdebug' returned a non-zero code: 1,timnolte,19,979989344,5,915648271,0,906222689,2021-09-08T23:51:09Z,@brylie what version of Node/NPM are you using. I ran into this recently and it was due to using an incompatible version of Node/NPM.,False,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/915926904,[wordpress/env] Service 'wordpress' failed to build: The command '/bin/sh -c pecl install xdebug && docker-php-ext-enable xdebug' returned a non-zero code: 1,brylie,19,979989344,6,915926904,0,915648271,2021-09-09T09:38:28Z,"My default node/npm versions are:

- node v14.17.0
- npm 7.21.0

I have nvm installed, so can switch to whichever version is compatible/recommended.",False,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/915979071,[wordpress/env] Service 'wordpress' failed to build: The command '/bin/sh -c pecl install xdebug && docker-php-ext-enable xdebug' returned a non-zero code: 1,timnolte,19,979989344,7,915979071,0,915926904,2021-09-09T10:54:18Z,"@brylie can you do a switch to Node v12, delete the `node_modules` directory and try again? In your original report I don't see explicitly that you are doing an `nom install` but I assume you are, and likewise you are performing a `wp-env stop` in there as well? Your steps only mention executing multiple `wp-env start` commands. I guess I should note one difference between your setup and mine is that I install `wp-env` locally in my projects. I then have `wp-env` setup in my `package.json` such that I can execute NPM commands that are relative to my current working project. So I actually call `npm start` which is setup to execute `wp-env start`. Oh, one other note, if you are making changes to the setup you should be executing `wp-env start --update` which will update the docker setup with your `.wp-env.json` changes.",False,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/924963571,[wordpress/env] Service 'wordpress' failed to build: The command '/bin/sh -c pecl install xdebug && docker-php-ext-enable xdebug' returned a non-zero code: 1,brylie,19,979989344,8,924963571,0,915979071,2021-09-22T14:04:05Z,"@timnolte, so far, we haven't been using NPM for local project dependencies, but are relying on a global installation of `wordpress/env` as per the instructions on npm.org.

![image](https://user-images.githubusercontent.com/17307/134357383-7655ad80-d3fc-4917-8544-091660f4339f.png)

As you suggest, I have created a local NPM project with the following configuration:

```json
{
  ""name"": ""project_creativecommons.org"",
  ""version"": ""0.0.1"",
  ""description"": ""Project to combine software components for the creativecommons.org website"",
  ""main"": ""index.js"",
  ""scripts"": {
    ""wp-env"": ""wp-env""
  },
  ""devDependencies"": {
    ""@wordpress/env"": ""^4.1.1""
  }
}
```

I still get the `xdebug` error when trying `npm run wp-env start` under node version `12.22.1` and npm `6.14.12`.

> Service 'wordpress' failed to build: The command '/bin/sh -c pecl install xdebug && docker-php-ext-enable xdebug' returned a non-zero code: 1

This underlying issue seems related to the Docker-compose file trying to install XDebug on an image that hasn't been pruned and where the dependency is already installed.

I have opened a [pull request](https://github.com/WordPress/gutenberg/pull/34324) to bypass installing XDebug where it isn't explicitly required, which will at least let us work around this issue to move on with development:",False,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/924965927,[wordpress/env] Service 'wordpress' failed to build: The command '/bin/sh -c pecl install xdebug && docker-php-ext-enable xdebug' returned a non-zero code: 1,brylie,19,979989344,9,924965927,0,924963571,2021-09-22T14:06:37Z,"Note: the issue is temporarily resolved when I run `docker image prune -a`. However, that isn't the ideal solution since it prunes all images. Likewise, the issue still recurs later when using `wordpress/env` in another project or a new environment.",False,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/931106440,[wordpress/env] Service 'wordpress' failed to build: The command '/bin/sh -c pecl install xdebug && docker-php-ext-enable xdebug' returned a non-zero code: 1,tmdk,19,979989344,10,931106440,0,924965927,2021-09-30T09:13:03Z,"While investigating this issue for a colleague, I noticed that xdebug was actually included in the `wordpress` image on his machine. Running `docker run --rm wordpress pecl list` would return:

```
Installed packages, channel pecl.php.net:
=========================================
Package Version State
imagick 3.5.0   stable
xdebug  3.0.4   stable
```

Inspecting the image showed that the image was actually the build result of the wp-env Dockerfile (it was showing the last of the `RUN` commands adding xdebug config to the php.ini file in `ContainerConfig.Cmd`).

So maybe my understanding of how Docker resolves images is lacking, but if this line in the wp-env Dockerfile

```
FROM wordpress
```

resolves to an image already containing xdebug (i.e. its own build result), then that would surely result in this issue.",False,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/943344485,[wordpress/env] Service 'wordpress' failed to build: The command '/bin/sh -c pecl install xdebug && docker-php-ext-enable xdebug' returned a non-zero code: 1,madeinnordeste,19,979989344,11,943344485,0,931106440,2021-10-14T13:14:23Z,"To me, works when update wp-env version for ^4.1.2

**package.json**

```
{
    ""devDependencies"": {
        ""@wordpress/env"": ""^4.1.2""
    }
}
```

is important remove **package-lock.json** case this have a previous version
",False,0,NONE
https://api.github.com/repos/WordPress/gutenberg/issues/comments/944232233,[wordpress/env] Service 'wordpress' failed to build: The command '/bin/sh -c pecl install xdebug && docker-php-ext-enable xdebug' returned a non-zero code: 1,brylie,19,979989344,12,944232233,0,943344485,2021-10-15T11:44:45Z,"I am getting this error on a fresh project created with `npm` version 8 and `node` version 12.22.6.
![image](https://user-images.githubusercontent.com/17307/137482474-c03a16ba-5f85-4194-8b05-4c085117764d.png)

",False,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/944233025,[wordpress/env] Service 'wordpress' failed to build: The command '/bin/sh -c pecl install xdebug && docker-php-ext-enable xdebug' returned a non-zero code: 1,brylie,19,979989344,13,944233025,0,944232233,2021-10-15T11:46:29Z,"It seems like the line `RUN pecl install xdebug ‚‚ docker-php-ext-enable xdebug` is doing too much and not failing gracefully. 

In my opinion, `xdebug` should be an optional dependency, only when it is explicitly enabled by the developer. I have opened a pull request to that effect: #34324 

Granted, PR #34324 is just a work-around and won't resolve the underlying issue causing this error.

> This underlying issue seems related to the Docker-compose file trying to install XDebug on an image that hasn't been pruned and where the dependency is already installed.",False,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/944238134,[wordpress/env] Service 'wordpress' failed to build: The command '/bin/sh -c pecl install xdebug && docker-php-ext-enable xdebug' returned a non-zero code: 1,brylie,19,979989344,14,944238134,0,944233025,2021-10-15T11:56:19Z,"I can confirm @tmdk's observation that the `wordpress` image already contains `xdebug`

![image](https://user-images.githubusercontent.com/17307/137482894-ac48b6ba-6cf3-42bb-829d-be94a8d81719.png)

So, it seems like `@wordpress/env` should not attempt to install `xdebug`.",False,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/944243150,[wordpress/env] Service 'wordpress' failed to build: The command '/bin/sh -c pecl install xdebug && docker-php-ext-enable xdebug' returned a non-zero code: 1,brylie,19,979989344,15,944243150,0,944238134,2021-10-15T12:05:15Z,"Following @tmdk's observation, I've opened a pull request to remove the Xdebug installation code from the `@wordpress/env` Docker container.

https://github.com/WordPress/gutenberg/pull/35667",False,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/952752289,[wordpress/env] Service 'wordpress' failed to build: The command '/bin/sh -c pecl install xdebug && docker-php-ext-enable xdebug' returned a non-zero code: 1,brylie,19,979989344,16,952752289,0,944243150,2021-10-27T10:02:04Z,"I bumped into this issue again today.

![image](https://user-images.githubusercontent.com/17307/139044786-a15a5226-127e-42a6-bc1c-a2ea34d6738d.png)
",False,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/952753740,[wordpress/env] Service 'wordpress' failed to build: The command '/bin/sh -c pecl install xdebug && docker-php-ext-enable xdebug' returned a non-zero code: 1,brylie,19,979989344,17,952753740,0,952752289,2021-10-27T10:03:37Z,I believe this is a bug and should be categorized as such. Please help us resolve this issue as it is recurring.,False,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/952763497,[wordpress/env] Service 'wordpress' failed to build: The command '/bin/sh -c pecl install xdebug && docker-php-ext-enable xdebug' returned a non-zero code: 1,brylie,19,979989344,18,952763497,0,952753740,2021-10-27T10:14:29Z,"Today, I am not able to get past the error despite running:

- `docker image prune -a`
- `docker system prune -a`

Each time I encounter this issue, it wastes around 15-30 minutes with troubleshooting.

Would you please review the related pull request to fix this issue #35667",False,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/952767108,[wordpress/env] Service 'wordpress' failed to build: The command '/bin/sh -c pecl install xdebug && docker-php-ext-enable xdebug' returned a non-zero code: 1,brylie,19,979989344,19,952767108,0,952763497,2021-10-27T10:18:51Z,"> delete the node_modules directory and try again? In your original report I don't see explicitly that you are doing an nom install but I assume you are, and likewise you are performing a wp-env stop in there as well? Your steps only mention executing multiple wp-env start commands. I guess I should note one difference between your setup and mine is that I install wp-env locally in my projects. I then have wp-env setup in my package.json such that I can execute NPM commands that are relative to my current working project. So I actually call npm start which is setup to execute wp-env start. Oh, one other note, if you are making changes to the setup you should be executing wp-env start --update which will update the docker setup with your .wp-env.json changes.

@timnolte, I have tried all of the above suggestions and the problem persists. 

As @tmdk has documented, the issue seems to stem from the `wordpress` Docker image.

Note: I just realized that I have multiple projects that use `wp-env`. When one of the other projects is running, the is a collision when trying to launch a second project. In that case, I would need to make sure to manually kill the docker containers from the previous project or run `wp-env stop`",False,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/964854365,[wordpress/env] Service 'wordpress' failed to build: The command '/bin/sh -c pecl install xdebug && docker-php-ext-enable xdebug' returned a non-zero code: 1,tmdk,19,979989344,20,964854365,0,952767108,2021-11-10T07:28:55Z,"Please note that the **official** wordpress docker image has never, and most likely never will include xdebug.

AFAICS, the `FROM wordpress` directive in the Dockerfile ends up basing a new build on its own previous build result, instead of basing the new build on the official wordpress docker image. If this behaviour is fixed, this issue should go away.",False,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/34322,Remove confusing punctuation,brylie,5,980024149,1,980024149,0,0,2021-08-26T09:19:33Z,"The text inside of the quote represents a WordPress version number. However, the trailing period is, while grammatically correct, confusing when reading the error output.

<!-- Learn the overall process and best practices for pull requests at https://github.com/WordPress/gutenberg/blob/HEAD/docs/contributors/repository-management.md#pull-requests. -->

<!-- Gutenberg's license is in the process of updating to be dual-licensed under the GPL and MPL. As part of that transition, all new contributions are dual-licensed. For more information, see: https://github.com/WordPress/gutenberg/blob/trunk/LICENSE.md -->

## Description
<!-- Please describe what you have changed or added -->

Remove confusing punctuation inside of quote.

## How has this been tested?
<!-- Please describe in detail how you tested your changes. -->
<!-- Include details of your testing environment, tests ran to see how -->
<!-- your change affects other areas of the code, etc. -->

## Screenshots <!-- if applicable -->

![image](https://user-images.githubusercontent.com/17307/130937068-b662124e-6ceb-43a2-995e-e7eb5c891a4b.png)


## Types of changes
<!-- What types of changes does your code introduce?  -->
<!-- Bug fix (non-breaking change which fixes an issue) -->
<!-- New feature (non-breaking change which adds functionality) -->
<!-- Breaking change (fix or feature that would cause existing functionality to not work as expected) -->
Small punctuation fix.

## Checklist:
- [ ] My code is tested.
- [ ] My code follows the WordPress code style. <!-- Check code: `npm run lint`, Guidelines: https://developer.wordpress.org/coding-standards/wordpress-coding-standards/javascript/ -->
- [ ] My code follows the accessibility standards. <!-- Guidelines: https://developer.wordpress.org/coding-standards/wordpress-coding-standards/accessibility/ -->
- [ ] I've tested my changes with keyboard and screen readers. <!-- Instructions: https://github.com/WordPress/gutenberg/blob/HEAD/docs/contributors/accessibility-testing.md -->
- [ ] My code has proper inline documentation. <!-- Guidelines: https://developer.wordpress.org/coding-standards/inline-documentation-standards/javascript/ -->
- [ ] I've included developer documentation if appropriate. <!-- Handbook: https://developer.wordpress.org/block-editor/ -->
- [ ] I've updated all React Native files affected by any refactorings/renamings in this PR (please manually search all `*.native.js` files for terms that need renaming or removal). <!-- React Native mobile Gutenberg guidelines: https://github.com/WordPress/gutenberg/blob/HEAD/docs/contributors/code/native-mobile.md -->
",True,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/906239646,Remove confusing punctuation,github-actions[bot],5,980024149,2,906239646,0,980024149,2021-08-26T09:20:01Z,":wave: Thanks for your first Pull Request and for helping build the future of Gutenberg and WordPress, @brylie! In case you missed it, we'd love to have you join us in our [Slack community](https://make.wordpress.org/chat/), where we hold [regularly weekly meetings](https://make.wordpress.org/core/tag/core-editor-summary/) open to anyone to coordinate with each other.

If you want to learn more about WordPress development in general, check out the [Core Handbook](https://make.wordpress.org/core/handbook/) full of helpful information.",False,0,NONE
https://api.github.com/repos/WordPress/gutenberg/issues/comments/914055014,Remove confusing punctuation,Mamaduka,5,980024149,3,914055014,0,906239646,2021-09-07T07:18:49Z,"Hi, @brylie

Can you rebase on top of the current trunk? E2E tests issue should be fixed now.",False,0,MEMBER
https://api.github.com/repos/WordPress/gutenberg/issues/comments/914069308,Remove confusing punctuation,brylie,5,980024149,4,914069308,0,914055014,2021-09-07T07:42:19Z,This is an example of why it would be beneficial to separate the WP-env project from the Gutenberg repository. A cross-repo rebase operation is difficult for new contributors and seems disproportionate for a one-line change to documentation.,False,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/914072280,Remove confusing punctuation,Mamaduka,5,980024149,5,914072280,0,914069308,2021-09-07T07:46:59Z,"@brylie, I think that makes sense.

I don't have the information if this was discussed before, but @gziolo might have more context.",False,0,MEMBER
https://api.github.com/repos/WordPress/gutenberg/issues/comments/914073487,Remove confusing punctuation,github-actions[bot],5,980024149,6,914073487,0,914072280,2021-09-07T07:48:51Z,"Congratulations on your first merged pull request, @brylie! We'd like to credit you for your contribution in the post announcing the next WordPress release, but we can't find a WordPress.org profile associated with your GitHub account. When you have a moment, visit the following URL and click ""link your GitHub account"" under ""GitHub Username"" to link your accounts:

https://profiles.wordpress.org/me/profile/edit/

And if you don't have a WordPress.org account, you can create one on this page:

https://login.wordpress.org/register

Kudos!",False,0,NONE
https://api.github.com/repos/WordPress/gutenberg/issues/34324,Disable Xdebug by default unless specified by user,brylie,15,980046035,1,980046035,0,0,2021-08-26T09:44:08Z,"<!-- Learn the overall process and best practices for pull requests at https://github.com/WordPress/gutenberg/blob/HEAD/docs/contributors/repository-management.md#pull-requests. -->

<!-- Gutenberg's license is in the process of updating to be dual-licensed under the GPL and MPL. As part of that transition, all new contributions are dual-licensed. For more information, see: https://github.com/WordPress/gutenberg/blob/trunk/LICENSE.md -->

## Description
<!-- Please describe what you have changed or added -->

Currently, `wp-env` installs Xdebug regardless of whether the user has requested it. The only installation check is based on PHP version being 7.2+.

Xdebug shouldn't be installed unless specified by the user. Likewise, the Docker file should be more careful when running the `pecl install xdebug`  command, as [noted by @noahtallen](https://github.com/WordPress/gutenberg/pull/35667#issuecomment-953278245). 

The added complexity of the Xdebug installation is causing some other issues:

- https://github.com/WordPress/gutenberg/issues/30213
- https://github.com/WordPress/gutenberg/issues/27783
- https://github.com/WordPress/gutenberg/issues/34320

## How has this been tested?
<!-- Please describe in detail how you tested your changes. -->
<!-- Include details of your testing environment, tests ran to see how -->
<!-- your change affects other areas of the code, etc. -->

## Types of changes
<!-- What types of changes does your code introduce?  -->
<!-- Bug fix (non-breaking change which fixes an issue) -->
<!-- New feature (non-breaking change which adds functionality) -->
<!-- Breaking change (fix or feature that would cause existing functionality to not work as expected) -->

## Checklist:
- [x] My code is tested.
- [ ] My code follows the WordPress code style. <!-- Check code: `npm run lint`, Guidelines: https://developer.wordpress.org/coding-standards/wordpress-coding-standards/javascript/ -->
- [ ] My code follows the accessibility standards. <!-- Guidelines: https://developer.wordpress.org/coding-standards/wordpress-coding-standards/accessibility/ -->
- [ ] I've tested my changes with keyboard and screen readers. <!-- Instructions: https://github.com/WordPress/gutenberg/blob/HEAD/docs/contributors/accessibility-testing.md -->
- [ ] My code has proper inline documentation. <!-- Guidelines: https://developer.wordpress.org/coding-standards/inline-documentation-standards/javascript/ -->
- [ ] I've included developer documentation if appropriate. <!-- Handbook: https://developer.wordpress.org/block-editor/ -->
- [ ] I've updated all React Native files affected by any refactorings/renamings in this PR (please manually search all `*.native.js` files for terms that need renaming or removal). <!-- React Native mobile Gutenberg guidelines: https://github.com/WordPress/gutenberg/blob/HEAD/docs/contributors/code/native-mobile.md -->
",True,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/906255732,Disable Xdebug by default unless specified by user,github-actions[bot],15,980046035,2,906255732,0,980046035,2021-08-26T09:44:36Z,":wave: Thanks for your first Pull Request and for helping build the future of Gutenberg and WordPress, @brylie! In case you missed it, we'd love to have you join us in our [Slack community](https://make.wordpress.org/chat/), where we hold [regularly weekly meetings](https://make.wordpress.org/core/tag/core-editor-summary/) open to anyone to coordinate with each other.

If you want to learn more about WordPress development in general, check out the [Core Handbook](https://make.wordpress.org/core/handbook/) full of helpful information.",False,0,NONE
https://api.github.com/repos/WordPress/gutenberg/issues/comments/907760740,Disable Xdebug by default unless specified by user,derickr,15,980046035,3,907760740,0,906255732,2021-08-29T09:33:50Z,"It's spelled ""Xdebug"" (no capital ""D"").

> XDebug shouldn't be installed unless specified by the user.

FWIW, I don't think this is wise, as you're going to make it harder for people to get a working debugging setup.",False,0,NONE
https://api.github.com/repos/WordPress/gutenberg/issues/comments/908132858,Disable Xdebug by default unless specified by user,brylie,15,980046035,4,908132858,0,907760740,2021-08-30T08:04:08Z,"> It's spelled ""Xdebug"" (no capital ""D"").

Thanks for pointing that out. I corrected the title and description :smiley: 

> FWIW, I don't think this is wise, as you're going to make it harder for people to get a working debugging setup.

From what I understand `config.xdebug` defaults to `off`.

This pull request avoids automatically installing Xdebug when `config.xdebug === 'off'`. When the developer specifies an `xdebug` value other than `off`, Xdebug will be installed.

It may be worth pointing out that `wp-env`/Docker will re-build the development container when enabling Xdebug, so it may be OK to omit the Xdebug installation step in cases where it isn't needed.",False,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/908202842,Disable Xdebug by default unless specified by user,brylie,15,980046035,5,908202842,0,908132858,2021-08-30T09:48:07Z,"There is currently no way to disable the Xdebug installation, even when it is desirable to do so. I am encountering a bug during the Xdebug installation (#34320) step and would just like to bypass the Xdebug installation to continue with my development task.

![image](https://user-images.githubusercontent.com/17307/131320850-32a2fa24-feb4-4091-b9fa-256a15e0b62c.png)

For simplicity's sake, it is important only to install dependencies that are needed.",False,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/930041960,Disable Xdebug by default unless specified by user,koengabriels,15,980046035,6,930041960,0,908202842,2021-09-29T10:15:57Z,"hope this gets through because I am working for a client that uses wp-env to set up unit tests on their precommit hook
since I am getting this error and have been unable to bypass it... I can not commit anything :(",False,0,NONE
https://api.github.com/repos/WordPress/gutenberg/issues/comments/930044486,Disable Xdebug by default unless specified by user,brylie,15,980046035,7,930044486,0,930041960,2021-09-29T10:19:18Z,@koengabriels would you mind taking a close look at the code and possibly testing it on your end? Your peer review would be much appreciated :smiley: ,False,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/930064808,Disable Xdebug by default unless specified by user,koengabriels,15,980046035,8,930064808,0,930044486,2021-09-29T10:50:33Z,"@brylie I have to look into how to do that, I have zero experience with testing a PR from Github or wp-env code base 
if I can I will post feedback here, appreciate the time you took to create a pull request for this issue :slightly_smiling_face: ",False,0,NONE
https://api.github.com/repos/WordPress/gutenberg/issues/comments/953680598,Disable Xdebug by default unless specified by user,brylie,15,980046035,9,953680598,0,930064808,2021-10-28T09:38:05Z,"@noahtallen, I've incorporated your suggested changes to the nested logic and conditional as well as the suggestion from PR #35667

Are there any other changes you would recommend?",False,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/954510550,Disable Xdebug by default unless specified by user,brylie,15,980046035,10,954510550,0,953680598,2021-10-29T07:53:00Z,"Sorry for the review request bonanza. I tried to rebase changes from `trunk` into this branch so the CI tasks would succeed.

Would someone with admin rights please help bypass the CI review since most tasks are unrelated to this pull request?

@noahtallen, would you please review the recent changes to this PR? I've refactored the PHP compatibility check into its own function so the `dockerFileContents` function is single-purpose. ",False,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/954524147,Disable Xdebug by default unless specified by user,swissspidy,15,980046035,11,954524147,0,954510550,2021-10-29T08:04:43Z,"Why bypass CI review?

There are some actual lint errors in `packages/env/lib/init-config.js` that need to get addressed.",False,0,MEMBER
https://api.github.com/repos/WordPress/gutenberg/issues/comments/954531354,Disable Xdebug by default unless specified by user,brylie,15,980046035,12,954531354,0,954524147,2021-10-29T08:08:18Z,"> Another note is to run prettier locally to get the lint check passing

When I run `npm run format-js` locally, I get the following error:

```
$ npm run format-js

> gutenberg@11.8.0 format-js
> wp-scripts format-js

sh: 1: wp-scripts: not found
```

When I have tried running `npm install`, I get many errors related to `Tracker ""idealTree:inflate:s"" already exists`

[2021-10-29T08_01_35_754Z-debug.log.txt](https://github.com/WordPress/gutenberg/files/7440050/2021-10-29T08_01_35_754Z-debug.log.txt)

I believe these issues are related to the monorepo nature of this project whereby it is necessary to install the entire Gutenberg development stack as well as any other libraries published by `@wordpress` in order to work on `wp-env`

#34325 


",False,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/954559911,Disable Xdebug by default unless specified by user,swissspidy,15,980046035,13,954559911,0,954531354,2021-10-29T08:40:48Z,"Yes it's a monorepo and you'd need to run `npm install` from the repo root.

You should also be using the latest Node LTS, Node 16 (run `nvm install` to fix). According to your logs you are still on Node 12",False,0,MEMBER
https://api.github.com/repos/WordPress/gutenberg/issues/comments/954567170,Disable Xdebug by default unless specified by user,brylie,15,980046035,14,954567170,0,954559911,2021-10-29T08:51:51Z,"I ran `nvm install 16 && nvm use 16`:
![image](https://user-images.githubusercontent.com/17307/139406026-a8eff94a-d7a1-4357-9baa-de69dea1e0de.png)


Running `npm install` in the monorepo root seems to have produced pretty much the same errors:

[2021-10-29T08_48_38_880Z-debug.log.txt](https://github.com/WordPress/gutenberg/files/7440406/2021-10-29T08_48_38_880Z-debug.log.txt)
",False,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/954657561,Disable Xdebug by default unless specified by user,brylie,15,980046035,15,954657561,0,954567170,2021-10-29T11:11:25Z,"@noahtallen, it seems like the CI checks are all passing or skipped. Would you mind giving this another review?",False,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/954988304,Disable Xdebug by default unless specified by user,noahtallen,15,980046035,16,954988304,0,954657561,2021-10-29T19:15:24Z,"> I ran nvm install 16 && nvm use 16:

For future reference, I think this is because gutenberg still requires [npm v6](https://github.com/WordPress/gutenberg/blob/211eebe72d84a13da1f7d0fbefc08329aed1040b/package.json#L19). I think there is a project to update that, though.

But now that CI is passing, it shouldn't be a problem for this PR :)",False,0,MEMBER
https://api.github.com/repos/WordPress/gutenberg/issues/34330,Components: Rename `PolymorphicComponent*` types to `WordPressComponent*`,ciampo,3,980230464,1,980230464,0,0,2021-08-26T13:11:38Z,"<!-- Learn the overall process and best practices for pull requests at https://github.com/WordPress/gutenberg/blob/HEAD/docs/contributors/repository-management.md#pull-requests. -->

<!-- Gutenberg's license is in the process of updating to be dual-licensed under the GPL and MPL. As part of that transition, all new contributions are dual-licensed. For more information, see: https://github.com/WordPress/gutenberg/blob/trunk/LICENSE.md -->

## Description
<!-- Please describe what you have changed or added -->

Renames the following types:

| From | To |
|---|---|
| `PolymorphicComponent` | `WordPressComponent` |
| `PolymorphicComponentProps` | `WordPressComponentProps` |
| `PolymorphicComponentFromProps` | `WordPressComponentFromProps` |

This PR also renames the file containing the type definitions from `polymoprhic-component.ts` to `wordpress-component.ts`, and adds a CHANGELOG entry.

## How has this been tested?
<!-- Please describe in detail how you tested your changes. -->
<!-- Include details of your testing environment, tests ran to see how -->
<!-- your change affects other areas of the code, etc. -->

The project builds correctly, tests pass, smoke tested in Storybook.

## Screenshots <!-- if applicable -->

N/A

## Types of changes
<!-- What types of changes does your code introduce?  -->
<!-- Bug fix (non-breaking change which fixes an issue) -->
<!-- New feature (non-breaking change which adds functionality) -->
<!-- Breaking change (fix or feature that would cause existing functionality to not work as expected) -->

Refactor (type renaming)

## Checklist:
- [x] My code is tested.
- [x] My code follows the WordPress code style. <!-- Check code: `npm run lint`, Guidelines: https://developer.wordpress.org/coding-standards/wordpress-coding-standards/javascript/ -->
- [x] My code follows the accessibility standards. <!-- Guidelines: https://developer.wordpress.org/coding-standards/wordpress-coding-standards/accessibility/ -->
- [x] I've tested my changes with keyboard and screen readers. <!-- Instructions: https://github.com/WordPress/gutenberg/blob/HEAD/docs/contributors/accessibility-testing.md -->
- [x] My code has proper inline documentation. <!-- Guidelines: https://developer.wordpress.org/coding-standards/inline-documentation-standards/javascript/ -->
- [x] I've included developer documentation if appropriate. <!-- Handbook: https://developer.wordpress.org/block-editor/ -->
- [x] I've updated all React Native files affected by any refactorings/renamings in this PR (please manually search all `*.native.js` files for terms that need renaming or removal). <!-- React Native mobile Gutenberg guidelines: https://github.com/WordPress/gutenberg/blob/HEAD/docs/contributors/code/native-mobile.md -->


Closes #34291
",True,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/906411180,Components: Rename `PolymorphicComponent*` types to `WordPressComponent*`,github-actions[bot],3,980230464,2,906411180,0,980230464,2021-08-26T13:24:24Z,"**Size Change:** 0 B 

**Total Size:** 1.04 MB



<details><summary>ℹ️ <strong>View Unchanged</strong></summary>

| Filename | Size |
| :--- | :---: |
| `build/a11y/index.min.js` | 931 B |
| `build/admin-manifest/index.min.js` | 1.09 kB |
| `build/annotations/index.min.js` | 2.7 kB |
| `build/api-fetch/index.min.js` | 2.19 kB |
| `build/autop/index.min.js` | 2.08 kB |
| `build/blob/index.min.js` | 459 B |
| `build/block-directory/index.min.js` | 6.2 kB |
| `build/block-directory/style-rtl.css` | 1.01 kB |
| `build/block-directory/style.css` | 1.01 kB |
| `build/block-editor/index.min.js` | 119 kB |
| `build/block-editor/style-rtl.css` | 13.8 kB |
| `build/block-editor/style.css` | 13.8 kB |
| `build/block-library/blocks/archives/editor-rtl.css` | 61 B |
| `build/block-library/blocks/archives/editor.css` | 60 B |
| `build/block-library/blocks/archives/style-rtl.css` | 65 B |
| `build/block-library/blocks/archives/style.css` | 65 B |
| `build/block-library/blocks/audio/editor-rtl.css` | 58 B |
| `build/block-library/blocks/audio/editor.css` | 58 B |
| `build/block-library/blocks/audio/style-rtl.css` | 111 B |
| `build/block-library/blocks/audio/style.css` | 111 B |
| `build/block-library/blocks/audio/theme-rtl.css` | 125 B |
| `build/block-library/blocks/audio/theme.css` | 125 B |
| `build/block-library/blocks/block/editor-rtl.css` | 161 B |
| `build/block-library/blocks/block/editor.css` | 161 B |
| `build/block-library/blocks/button/editor-rtl.css` | 474 B |
| `build/block-library/blocks/button/editor.css` | 474 B |
| `build/block-library/blocks/button/style-rtl.css` | 600 B |
| `build/block-library/blocks/button/style.css` | 600 B |
| `build/block-library/blocks/buttons/editor-rtl.css` | 315 B |
| `build/block-library/blocks/buttons/editor.css` | 315 B |
| `build/block-library/blocks/buttons/style-rtl.css` | 370 B |
| `build/block-library/blocks/buttons/style.css` | 370 B |
| `build/block-library/blocks/calendar/style-rtl.css` | 207 B |
| `build/block-library/blocks/calendar/style.css` | 207 B |
| `build/block-library/blocks/categories/editor-rtl.css` | 84 B |
| `build/block-library/blocks/categories/editor.css` | 83 B |
| `build/block-library/blocks/categories/style-rtl.css` | 79 B |
| `build/block-library/blocks/categories/style.css` | 79 B |
| `build/block-library/blocks/code/style-rtl.css` | 90 B |
| `build/block-library/blocks/code/style.css` | 90 B |
| `build/block-library/blocks/code/theme-rtl.css` | 131 B |
| `build/block-library/blocks/code/theme.css` | 131 B |
| `build/block-library/blocks/columns/editor-rtl.css` | 194 B |
| `build/block-library/blocks/columns/editor.css` | 193 B |
| `build/block-library/blocks/columns/style-rtl.css` | 474 B |
| `build/block-library/blocks/columns/style.css` | 475 B |
| `build/block-library/blocks/cover/editor-rtl.css` | 666 B |
| `build/block-library/blocks/cover/editor.css` | 670 B |
| `build/block-library/blocks/cover/style-rtl.css` | 1.23 kB |
| `build/block-library/blocks/cover/style.css` | 1.23 kB |
| `build/block-library/blocks/embed/editor-rtl.css` | 488 B |
| `build/block-library/blocks/embed/editor.css` | 488 B |
| `build/block-library/blocks/embed/style-rtl.css` | 417 B |
| `build/block-library/blocks/embed/style.css` | 417 B |
| `build/block-library/blocks/embed/theme-rtl.css` | 124 B |
| `build/block-library/blocks/embed/theme.css` | 124 B |
| `build/block-library/blocks/file/editor-rtl.css` | 300 B |
| `build/block-library/blocks/file/editor.css` | 300 B |
| `build/block-library/blocks/file/style-rtl.css` | 255 B |
| `build/block-library/blocks/file/style.css` | 255 B |
| `build/block-library/blocks/file/view.min.js` | 322 B |
| `build/block-library/blocks/freeform/editor-rtl.css` | 2.44 kB |
| `build/block-library/blocks/freeform/editor.css` | 2.44 kB |
| `build/block-library/blocks/gallery/editor-rtl.css` | 879 B |
| `build/block-library/blocks/gallery/editor.css` | 876 B |
| `build/block-library/blocks/gallery/style-rtl.css` | 1.61 kB |
| `build/block-library/blocks/gallery/style.css` | 1.61 kB |
| `build/block-library/blocks/gallery/theme-rtl.css` | 122 B |
| `build/block-library/blocks/gallery/theme.css` | 122 B |
| `build/block-library/blocks/group/editor-rtl.css` | 159 B |
| `build/block-library/blocks/group/editor.css` | 159 B |
| `build/block-library/blocks/group/style-rtl.css` | 57 B |
| `build/block-library/blocks/group/style.css` | 57 B |
| `build/block-library/blocks/group/theme-rtl.css` | 70 B |
| `build/block-library/blocks/group/theme.css` | 70 B |
| `build/block-library/blocks/heading/style-rtl.css` | 114 B |
| `build/block-library/blocks/heading/style.css` | 114 B |
| `build/block-library/blocks/home-link/style-rtl.css` | 247 B |
| `build/block-library/blocks/home-link/style.css` | 247 B |
| `build/block-library/blocks/html/editor-rtl.css` | 283 B |
| `build/block-library/blocks/html/editor.css` | 284 B |
| `build/block-library/blocks/image/editor-rtl.css` | 728 B |
| `build/block-library/blocks/image/editor.css` | 728 B |
| `build/block-library/blocks/image/style-rtl.css` | 482 B |
| `build/block-library/blocks/image/style.css` | 487 B |
| `build/block-library/blocks/image/theme-rtl.css` | 124 B |
| `build/block-library/blocks/image/theme.css` | 124 B |
| `build/block-library/blocks/latest-comments/style-rtl.css` | 284 B |
| `build/block-library/blocks/latest-comments/style.css` | 284 B |
| `build/block-library/blocks/latest-posts/editor-rtl.css` | 137 B |
| `build/block-library/blocks/latest-posts/editor.css` | 137 B |
| `build/block-library/blocks/latest-posts/style-rtl.css` | 528 B |
| `build/block-library/blocks/latest-posts/style.css` | 527 B |
| `build/block-library/blocks/list/style-rtl.css` | 94 B |
| `build/block-library/blocks/list/style.css` | 94 B |
| `build/block-library/blocks/media-text/editor-rtl.css` | 266 B |
| `build/block-library/blocks/media-text/editor.css` | 263 B |
| `build/block-library/blocks/media-text/style-rtl.css` | 488 B |
| `build/block-library/blocks/media-text/style.css` | 485 B |
| `build/block-library/blocks/more/editor-rtl.css` | 431 B |
| `build/block-library/blocks/more/editor.css` | 431 B |
| `build/block-library/blocks/navigation-link/editor-rtl.css` | 489 B |
| `build/block-library/blocks/navigation-link/editor.css` | 488 B |
| `build/block-library/blocks/navigation-link/style-rtl.css` | 94 B |
| `build/block-library/blocks/navigation-link/style.css` | 94 B |
| `build/block-library/blocks/navigation/editor-rtl.css` | 1.72 kB |
| `build/block-library/blocks/navigation/editor.css` | 1.72 kB |
| `build/block-library/blocks/navigation/style-rtl.css` | 1.42 kB |
| `build/block-library/blocks/navigation/style.css` | 1.41 kB |
| `build/block-library/blocks/navigation/view.min.js` | 2.52 kB |
| `build/block-library/blocks/nextpage/editor-rtl.css` | 395 B |
| `build/block-library/blocks/nextpage/editor.css` | 395 B |
| `build/block-library/blocks/page-list/editor-rtl.css` | 310 B |
| `build/block-library/blocks/page-list/editor.css` | 310 B |
| `build/block-library/blocks/page-list/style-rtl.css` | 241 B |
| `build/block-library/blocks/page-list/style.css` | 241 B |
| `build/block-library/blocks/paragraph/editor-rtl.css` | 157 B |
| `build/block-library/blocks/paragraph/editor.css` | 157 B |
| `build/block-library/blocks/paragraph/style-rtl.css` | 261 B |
| `build/block-library/blocks/paragraph/style.css` | 261 B |
| `build/block-library/blocks/post-author/editor-rtl.css` | 210 B |
| `build/block-library/blocks/post-author/editor.css` | 210 B |
| `build/block-library/blocks/post-author/style-rtl.css` | 182 B |
| `build/block-library/blocks/post-author/style.css` | 181 B |
| `build/block-library/blocks/post-comments-form/style-rtl.css` | 140 B |
| `build/block-library/blocks/post-comments-form/style.css` | 140 B |
| `build/block-library/blocks/post-comments/style-rtl.css` | 360 B |
| `build/block-library/blocks/post-comments/style.css` | 359 B |
| `build/block-library/blocks/post-content/editor-rtl.css` | 138 B |
| `build/block-library/blocks/post-content/editor.css` | 138 B |
| `build/block-library/blocks/post-excerpt/editor-rtl.css` | 73 B |
| `build/block-library/blocks/post-excerpt/editor.css` | 73 B |
| `build/block-library/blocks/post-excerpt/style-rtl.css` | 69 B |
| `build/block-library/blocks/post-excerpt/style.css` | 69 B |
| `build/block-library/blocks/post-featured-image/editor-rtl.css` | 398 B |
| `build/block-library/blocks/post-featured-image/editor.css` | 398 B |
| `build/block-library/blocks/post-featured-image/style-rtl.css` | 143 B |
| `build/block-library/blocks/post-featured-image/style.css` | 143 B |
| `build/block-library/blocks/post-template/editor-rtl.css` | 99 B |
| `build/block-library/blocks/post-template/editor.css` | 98 B |
| `build/block-library/blocks/post-template/style-rtl.css` | 378 B |
| `build/block-library/blocks/post-template/style.css` | 379 B |
| `build/block-library/blocks/post-terms/style-rtl.css` | 73 B |
| `build/block-library/blocks/post-terms/style.css` | 73 B |
| `build/block-library/blocks/post-title/style-rtl.css` | 60 B |
| `build/block-library/blocks/post-title/style.css` | 60 B |
| `build/block-library/blocks/preformatted/style-rtl.css` | 103 B |
| `build/block-library/blocks/preformatted/style.css` | 103 B |
| `build/block-library/blocks/pullquote/editor-rtl.css` | 198 B |
| `build/block-library/blocks/pullquote/editor.css` | 198 B |
| `build/block-library/blocks/pullquote/style-rtl.css` | 378 B |
| `build/block-library/blocks/pullquote/style.css` | 378 B |
| `build/block-library/blocks/pullquote/theme-rtl.css` | 167 B |
| `build/block-library/blocks/pullquote/theme.css` | 167 B |
| `build/block-library/blocks/query-pagination-numbers/editor-rtl.css` | 122 B |
| `build/block-library/blocks/query-pagination-numbers/editor.css` | 121 B |
| `build/block-library/blocks/query-pagination/editor-rtl.css` | 270 B |
| `build/block-library/blocks/query-pagination/editor.css` | 262 B |
| `build/block-library/blocks/query-pagination/style-rtl.css` | 168 B |
| `build/block-library/blocks/query-pagination/style.css` | 168 B |
| `build/block-library/blocks/query-title/editor-rtl.css` | 85 B |
| `build/block-library/blocks/query-title/editor.css` | 85 B |
| `build/block-library/blocks/query/editor-rtl.css` | 131 B |
| `build/block-library/blocks/query/editor.css` | 132 B |
| `build/block-library/blocks/quote/style-rtl.css` | 187 B |
| `build/block-library/blocks/quote/style.css` | 187 B |
| `build/block-library/blocks/quote/theme-rtl.css` | 220 B |
| `build/block-library/blocks/quote/theme.css` | 222 B |
| `build/block-library/blocks/rss/editor-rtl.css` | 202 B |
| `build/block-library/blocks/rss/editor.css` | 204 B |
| `build/block-library/blocks/rss/style-rtl.css` | 289 B |
| `build/block-library/blocks/rss/style.css` | 288 B |
| `build/block-library/blocks/search/editor-rtl.css` | 165 B |
| `build/block-library/blocks/search/editor.css` | 165 B |
| `build/block-library/blocks/search/style-rtl.css` | 374 B |
| `build/block-library/blocks/search/style.css` | 375 B |
| `build/block-library/blocks/search/theme-rtl.css` | 64 B |
| `build/block-library/blocks/search/theme.css` | 64 B |
| `build/block-library/blocks/separator/editor-rtl.css` | 99 B |
| `build/block-library/blocks/separator/editor.css` | 99 B |
| `build/block-library/blocks/separator/style-rtl.css` | 250 B |
| `build/block-library/blocks/separator/style.css` | 250 B |
| `build/block-library/blocks/separator/theme-rtl.css` | 172 B |
| `build/block-library/blocks/separator/theme.css` | 172 B |
| `build/block-library/blocks/shortcode/editor-rtl.css` | 474 B |
| `build/block-library/blocks/shortcode/editor.css` | 474 B |
| `build/block-library/blocks/site-logo/editor-rtl.css` | 462 B |
| `build/block-library/blocks/site-logo/editor.css` | 464 B |
| `build/block-library/blocks/site-logo/style-rtl.css` | 153 B |
| `build/block-library/blocks/site-logo/style.css` | 153 B |
| `build/block-library/blocks/site-tagline/editor-rtl.css` | 86 B |
| `build/block-library/blocks/site-tagline/editor.css` | 86 B |
| `build/block-library/blocks/site-title/editor-rtl.css` | 84 B |
| `build/block-library/blocks/site-title/editor.css` | 84 B |
| `build/block-library/blocks/social-link/editor-rtl.css` | 165 B |
| `build/block-library/blocks/social-link/editor.css` | 165 B |
| `build/block-library/blocks/social-links/editor-rtl.css` | 812 B |
| `build/block-library/blocks/social-links/editor.css` | 811 B |
| `build/block-library/blocks/social-links/style-rtl.css` | 1.33 kB |
| `build/block-library/blocks/social-links/style.css` | 1.33 kB |
| `build/block-library/blocks/spacer/editor-rtl.css` | 307 B |
| `build/block-library/blocks/spacer/editor.css` | 307 B |
| `build/block-library/blocks/spacer/style-rtl.css` | 48 B |
| `build/block-library/blocks/spacer/style.css` | 48 B |
| `build/block-library/blocks/table/editor-rtl.css` | 471 B |
| `build/block-library/blocks/table/editor.css` | 472 B |
| `build/block-library/blocks/table/style-rtl.css` | 481 B |
| `build/block-library/blocks/table/style.css` | 481 B |
| `build/block-library/blocks/table/theme-rtl.css` | 188 B |
| `build/block-library/blocks/table/theme.css` | 188 B |
| `build/block-library/blocks/tag-cloud/style-rtl.css` | 146 B |
| `build/block-library/blocks/tag-cloud/style.css` | 146 B |
| `build/block-library/blocks/template-part/editor-rtl.css` | 636 B |
| `build/block-library/blocks/template-part/editor.css` | 635 B |
| `build/block-library/blocks/template-part/theme-rtl.css` | 101 B |
| `build/block-library/blocks/template-part/theme.css` | 101 B |
| `build/block-library/blocks/term-description/editor-rtl.css` | 90 B |
| `build/block-library/blocks/term-description/editor.css` | 90 B |
| `build/block-library/blocks/text-columns/editor-rtl.css` | 95 B |
| `build/block-library/blocks/text-columns/editor.css` | 95 B |
| `build/block-library/blocks/text-columns/style-rtl.css` | 166 B |
| `build/block-library/blocks/text-columns/style.css` | 166 B |
| `build/block-library/blocks/verse/style-rtl.css` | 87 B |
| `build/block-library/blocks/verse/style.css` | 87 B |
| `build/block-library/blocks/video/editor-rtl.css` | 571 B |
| `build/block-library/blocks/video/editor.css` | 572 B |
| `build/block-library/blocks/video/style-rtl.css` | 173 B |
| `build/block-library/blocks/video/style.css` | 173 B |
| `build/block-library/blocks/video/theme-rtl.css` | 124 B |
| `build/block-library/blocks/video/theme.css` | 124 B |
| `build/block-library/common-rtl.css` | 1.29 kB |
| `build/block-library/common.css` | 1.29 kB |
| `build/block-library/editor-rtl.css` | 9.93 kB |
| `build/block-library/editor.css` | 9.92 kB |
| `build/block-library/index.min.js` | 150 kB |
| `build/block-library/reset-rtl.css` | 527 B |
| `build/block-library/reset.css` | 527 B |
| `build/block-library/style-rtl.css` | 10.6 kB |
| `build/block-library/style.css` | 10.6 kB |
| `build/block-library/theme-rtl.css` | 658 B |
| `build/block-library/theme.css` | 663 B |
| `build/block-serialization-default-parser/index.min.js` | 1.09 kB |
| `build/block-serialization-spec-parser/index.min.js` | 2.79 kB |
| `build/blocks/index.min.js` | 46.9 kB |
| `build/components/index.min.js` | 209 kB |
| `build/components/style-rtl.css` | 15.8 kB |
| `build/components/style.css` | 15.8 kB |
| `build/compose/index.min.js` | 10.2 kB |
| `build/core-data/index.min.js` | 12.4 kB |
| `build/customize-widgets/index.min.js` | 11.1 kB |
| `build/customize-widgets/style-rtl.css` | 1.5 kB |
| `build/customize-widgets/style.css` | 1.49 kB |
| `build/data-controls/index.min.js` | 614 B |
| `build/data/index.min.js` | 7.1 kB |
| `build/date/index.min.js` | 31.5 kB |
| `build/deprecated/index.min.js` | 428 B |
| `build/dom-ready/index.min.js` | 304 B |
| `build/dom/index.min.js` | 4.53 kB |
| `build/edit-navigation/index.min.js` | 13.6 kB |
| `build/edit-navigation/style-rtl.css` | 3.14 kB |
| `build/edit-navigation/style.css` | 3.14 kB |
| `build/edit-post/classic-rtl.css` | 492 B |
| `build/edit-post/classic.css` | 494 B |
| `build/edit-post/index.min.js` | 28.9 kB |
| `build/edit-post/style-rtl.css` | 7.2 kB |
| `build/edit-post/style.css` | 7.19 kB |
| `build/edit-site/index.min.js` | 26.3 kB |
| `build/edit-site/style-rtl.css` | 5.07 kB |
| `build/edit-site/style.css` | 5.07 kB |
| `build/edit-widgets/index.min.js` | 16 kB |
| `build/edit-widgets/style-rtl.css` | 4.06 kB |
| `build/edit-widgets/style.css` | 4.06 kB |
| `build/editor/index.min.js` | 37.6 kB |
| `build/editor/style-rtl.css` | 3.74 kB |
| `build/editor/style.css` | 3.73 kB |
| `build/element/index.min.js` | 3.17 kB |
| `build/escape-html/index.min.js` | 517 B |
| `build/format-library/index.min.js` | 5.36 kB |
| `build/format-library/style-rtl.css` | 668 B |
| `build/format-library/style.css` | 669 B |
| `build/hooks/index.min.js` | 1.55 kB |
| `build/html-entities/index.min.js` | 424 B |
| `build/i18n/index.min.js` | 3.6 kB |
| `build/is-shallow-equal/index.min.js` | 501 B |
| `build/keyboard-shortcuts/index.min.js` | 1.49 kB |
| `build/keycodes/index.min.js` | 1.25 kB |
| `build/list-reusable-blocks/index.min.js` | 1.85 kB |
| `build/list-reusable-blocks/style-rtl.css` | 838 B |
| `build/list-reusable-blocks/style.css` | 838 B |
| `build/media-utils/index.min.js` | 2.88 kB |
| `build/notices/index.min.js` | 845 B |
| `build/nux/index.min.js` | 2.03 kB |
| `build/nux/style-rtl.css` | 747 B |
| `build/nux/style.css` | 743 B |
| `build/plugins/index.min.js` | 1.83 kB |
| `build/primitives/index.min.js` | 921 B |
| `build/priority-queue/index.min.js` | 582 B |
| `build/react-i18n/index.min.js` | 671 B |
| `build/redux-routine/index.min.js` | 2.63 kB |
| `build/reusable-blocks/index.min.js` | 2.28 kB |
| `build/reusable-blocks/style-rtl.css` | 256 B |
| `build/reusable-blocks/style.css` | 256 B |
| `build/rich-text/index.min.js` | 10.6 kB |
| `build/server-side-render/index.min.js` | 1.32 kB |
| `build/shortcode/index.min.js` | 1.48 kB |
| `build/token-list/index.min.js` | 562 B |
| `build/url/index.min.js` | 1.74 kB |
| `build/viewport/index.min.js` | 1.02 kB |
| `build/warning/index.min.js` | 248 B |
| `build/widgets/index.min.js` | 6.37 kB |
| `build/widgets/style-rtl.css` | 1.05 kB |
| `build/widgets/style.css` | 1.05 kB |
| `build/wordcount/index.min.js` | 1.04 kB |

</details>



<a href=""https://github.com/preactjs/compressed-size-action""><sub>compressed-size-action</sub></a>",False,0,NONE
https://api.github.com/repos/WordPress/gutenberg/issues/comments/908971939,Components: Rename `PolymorphicComponent*` types to `WordPressComponent*`,ciampo,3,980230464,3,908971939,0,906411180,2021-08-31T07:24:57Z,"> I noticed that in some places we're using import type and in others we're just importing the types directly. Are we following any convention in that regard?

From what I can gather, until recently our preferred option in TypeScript files was to keep the type imports separate from importing runtime code. I believe this technique was used in an attempt to keep the bundle size as small as possible, e.g.

```typescript
import { myFunction } from './file';
import type { MyType } from './file';
```

Recently, though, it was discussed and agreed that optimisation isn't really necessary, and so we started switching to merging those import statements into one, e.g.


```typescript
import { myFunction, MyType } from './file';
```

Still, it is possible to still encounter an `import type` statement, in case all of the imported variables are actually TypeScript types, e.g.

```typescript
import type { MyType, MyOtherType } from './file';
```

Following the rationale that I just explained, I had a look at the code in this PR and merged import declarations where possible in [`6508cd9` (#34330)](https://github.com/WordPress/gutenberg/pull/34330/commits/6508cd9db5111b3c1e3220e62ccdaa8c7a39abc7)",False,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/gutenberg/issues/comments/908981600,Components: Rename `PolymorphicComponent*` types to `WordPressComponent*`,ciampo,3,980230464,4,908981600,0,908971939,2021-08-31T07:40:51Z,"All CI tasks seemed to be failing after the last commit — I've tried to rebase on top of `trunk` hoping it will fix these issues (it may be related to #34377)

Update: the issues seem to persist

Update: all good after last rebase! Going to merge",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/12981,Add workaround to fix keyboard input when using x11+udev,jdgleaver,3,994986134,1,994986134,0,0,2021-09-13T14:49:46Z,"## Description

At present, keyboard input is broken when running RetroArch under X11 when using the udev input driver.

- Each key press generates two simultaneous inputs
- Only one of the inputs is correct - the other is garbage, rendering any core that uses keyboard input inoperable (it also breaks any attempt to bind keys in the menu)

There are multiple issues with the underlying code here:

- Whenever RetroArch is run under X11, keyboard events are handled (i.e. `input_keyboard_event()` is called) in `x11_common:x11_check_window()`
- When the udev input driver is used, keyboard events are also handled in the driver itself - leading to duplicate `input_keyboard_event()` calls
- In `x11_common:x11_check_window()`, all keyboard key identification relies on the `x11` input keymap; in the udev driver, all keyboard key identification relies on the `linux` input keymap. The udev driver sets the global keymap to the `linux` one - which means the mapping in `x11_common:x11_check_window()` is entirely wrong (producing garbage input)
- The udev driver is incomplete. It calls `input_keyboard_event()` without valid 'character' (Unicode/UTF-8 representation of the current key) or keyboard modifier (shift/ctrl/etc.) information. This means the udev driver keyboard events do not work correctly - e.g. they cannot be used for text entry in the menu

This PR makes the following changes to the code:

1. `x11_common:x11_check_window()` now uses it's own local `x11`-specific input keymap, ensuring that keys are always identified correctly regardless of the input driver
2. In the udev input driver, calls to `input_keyboard_event()` are suppressed whenever an x11-based context driver is active (i.e. whenever `x11_common:x11_check_window()` is being called)

This fixes keyboard input - but while (1) is required in any case, (2) should be considered a workaround. The 'proper' approach would be to suppress `input_keyboard_event()` calls in `x11_common:x11_check_window()` whenever the udev input driver is active - however, this would require the udev driver to be fleshed out such that the missing 'character' and 'modifier' values can be determined. The 'modifier' is easy enough, but I can find no useable reference material for converting a udev keycode into a localised Unicode/UTF-8 representation. So until we can find someone to implement this, the workaround will have to suffice.

Finally, this PR also fixes a memory leak that occurred in the udev driver on each init/reinit.

## Related Issues

#12980
",True,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/919698258,Add workaround to fix keyboard input when using x11+udev,i30817,3,994986134,2,919698258,0,994986134,2021-09-15T04:54:15Z,"I'm sure you're aware, but this still doesn't fix the permission problem of using the udev driver in x (gnome 3) without being in the ~~sound~~ input group or its equivalent. Just making it clear for other people before they start asking.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/919865368,Add workaround to fix keyboard input when using x11+udev,jdgleaver,3,994986134,3,919865368,0,919698258,2021-09-15T09:42:28Z,"Yes, you are quite correct (although it's the `input` group on most distros). Unfortunately I don't know how to fix that particular issue....",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/927301420,Add workaround to fix keyboard input when using x11+udev,ghost,3,994986134,4,927301420,0,919865368,2021-09-26T12:51:34Z,Permissions can only be fixed with group permissions or adding the uaccess tag to the udev rules. ,False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/12988,"Perhaps the ""freeze stuck"" bug was ""fixed"" using new Nvidia driver 470",Augusto7743,5,996235985,1,996235985,0,0,2021-09-14T16:59:19Z,"I have used Retroarch in Linux for a few months and the more worst issue is when starting in full screen the program is totally stoped at point that not is possible move selection menus or use ALT+TAB for alternate to others programs.
That ""freeze stuck"" will continue for more than 1 minute and after is possible select menus and start a game , but when closing a game again will happen that issue.
I had always tested enabling or disabling several settings and not fix.
Today was updated the Nvidia driver for version 470.63.01 and not happen the issue above , but when enabling threaded video Retroarch will start and happen the ""freeze stuck"" for a delay of few miliseconds. Thus disabling threaded video not happen the ""freeze stuck"".

Have something wrong in threaded video code ?",True,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/922378544,"Perhaps the ""freeze stuck"" bug was ""fixed"" using new Nvidia driver 470",Sanaki,5,996235985,2,922378544,0,996235985,2021-09-18T21:49:10Z,"To be clear, this isn't a generalized Nvidia Linux issue. I've never experienced it, and I'd have been seeing it for years were that the case. I did try enabling threaded video just now and just got the typical double reinit, but that's not abnormal at all. I'm afraid I don't know what to suggest for you, since I've never witnessed the problem in the first place.

Closest issues I've seen were an old driver bug related to vulkan on prime laptops (resolved finally in 460 I believe) and #10408.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/922546949,"Perhaps the ""freeze stuck"" bug was ""fixed"" using new Nvidia driver 470",ghost,5,996235985,3,922546949,0,922378544,2021-09-19T22:28:50Z,Might be unrelated but the statistics don't show on threaded video either.,False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/922629503,"Perhaps the ""freeze stuck"" bug was ""fixed"" using new Nvidia driver 470",Augusto7743,5,996235985,4,922629503,0,922546949,2021-09-20T04:25:12Z,"Using Linux Ubuntu nvidia driver 460 and Retroarch previous versions had that ""freeze stuck"" bug and with current version driver 460 and Retroarch current version not more ""freeze stuck"" , but disabling thread video start more fast and enabling have a little delay and in previous versions even disabling thread video had the ""freeze stuck"".
Search in the issue list you will see some users saying about that ""freeze stuck"" bug.
My topic here was to say a information thus if the bug return in next versions the information above is a clue to fix.",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/923188200,"Perhaps the ""freeze stuck"" bug was ""fixed"" using new Nvidia driver 470",gouchi,5,996235985,5,923188200,0,922629503,2021-09-20T18:50:24Z,"Hi,

I can't reproduce your issue I can enable threaded video and I have no freeze.

Can you be more precise how to to reproduce your issue step by step ?

1. Enable threaded video
2. Launch game ? Move in the menu ?

Moreover which DM are you using ? display server Xorg or Wayland ?

Which RA version are you using ? From which package ?

Thank  you.",False,0,MEMBER
https://api.github.com/repos/libretro/RetroArch/issues/comments/923613570,"Perhaps the ""freeze stuck"" bug was ""fixed"" using new Nvidia driver 470",Augusto7743,5,996235985,6,923613570,0,923188200,2021-09-21T04:28:04Z,"Tested in Linux Ubuntu 20.04 xorg and 21.04.3 xorg ... GT 640 drivers 465 and 470.

- Retroarch 1.9.9 and previous versions before 1.9.6 driver 465 in both Ubuntu 20.04 and 21.04.
Starting Retroarch in full screen even without loaded content ""freeze stuck"" at point that also ""frezze stuck"" the OS for more than 1 minute and when closng content again happen ""freeze stuck"".
Windowed mode not any problems.
Any setting enabled or disabled not fix the issue.

- Retroarch 1.9.9 driver 470 in Ubuntu 21.04.
Not more any terrible issues starting in full screen.
The only strange detail is enabling video thread happen the ""freeze stuck"" for 500 miliseconds.

Search in users posts you will see users saying about ""freeze stuck"" happening in Retroarch for several previous versions that never was fixed.",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/12990,Hotkey options for direct save/load states,kimimaru4000,5,996488240,1,996488240,0,0,2021-09-14T22:22:58Z,"# First and foremost consider this:
- Only RetroArch bugs should be filed here. Not core bugs or game bugs
- This is not a forum or a help section, this is strictly developer oriented

## Description

This is a follow-up to https://github.com/libretro/RetroArch/issues/12144. I would like to discuss the possibility of adding hotkeys for direct save and load states into RetroArch. I have added it to my own fork, and you can see what it l looks like in the image below:

![RetroArch_DirectSaveLoadHotkeys_640](https://user-images.githubusercontent.com/1388037/133341224-2574c458-5a0c-4ae2-8bd1-b7258ced7b71.png)

Reasons I want to discuss this feature:

- As mentioned in the other issue, I run a Twitch Plays channel, and separate slots make it much easier to control permissions for individual savestates.
- Some people, including myself, prefer direct states as opposed to changing save slots then saving or loading. Other emulators have this feature as well.
- What I have now has only 6 slots present at all times. It may be better if the number of available slots were user-defined to a certain limit - say 10. There could be a menu option to enable direct saving/loading, and the menu options for each slot could be visible based on this option.
- Implementation-wise, everything is in place for this feature, so it'd be trivial to add. It leverages existing code to set the current save slot to a given number then save or load it.

I am fully willing to work on a PR for this, considering I have already done a large chunk of the work implementing it. I hope to discuss this further with you soon!",True,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/919712718,Hotkey options for direct save/load states,i30817,5,996488240,2,919712718,0,996488240,2021-09-15T05:30:50Z,"Sounds good, the dolphin way is cool.

You probably don't want these set up by default though. RA hotkey menu is a mess and you can't even reset them (this is _problem_ imo), so most position you chose in a keyboard or controller by default would conflict with others, or in the case of the computer emulation cores conflict with text input (1-0 keys particularly but even the F-keys are not free of this).

Speaking personally, i nuke all the hotkeys except the savestates, menu toggle and fps counter, and now that the quit key is not insane that too (though i probably should).

Dolphin uses the shift or ctrl (iirc) keys to override a save or a load state. RA will not be able to do this iirc, so you have even less key real estate here that expected.

I _suppose_ most people will want FKeys to save and 1-5 keys to load but that sounds slightly overwrite or 'load when you wanted to save' dangerous to me.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/919715719,Hotkey options for direct save/load states,i30817,5,996488240,3,919715719,0,919712718,2021-09-15T05:38:40Z,"In short i kind of suggest that if you implement this you also add a reset option. Individual or for all, not sure.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/919748348,Hotkey options for direct save/load states,kimimaru4000,5,996488240,4,919748348,0,919715719,2021-09-15T06:51:09Z,"I agree about keeping them unmapped by default. There are only so many keys/buttons and this is a new feature that users shouldn't expect to have mapped, considering the existing savestate system has been in place for so long.

RetroArch already supports unmapping inputs with the `delete` key on desktop (unsure about consoles and mobile). Go to the action you want on the menu and simply press `delete`, without selecting it to map it. Even if it weren't implemented, that should be a separate issue as it's not directly related to this one.",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/919758434,Hotkey options for direct save/load states,i30817,5,996488240,5,919758434,0,919748348,2021-09-15T07:09:08Z,"Yes, i was confused at first (it's not delete for me but 'a' as in the controller), but i wasn't thinking about only resetting to nil. I was thinking about resetting it to default. Fair enough about it being another issue though.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/921939434,Hotkey options for direct save/load states,kimimaru4000,5,996488240,6,921939434,0,919758434,2021-09-17T16:49:12Z,Sounds good! I will work on a PR with the additional options.,False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/12991,Fix analog inputs on HID devices,gblues,4,996565648,1,996565648,0,0,2021-09-15T01:21:34Z,"# Description

    File this one under ""I'm not sure how this ever worked.""

    I mean, it did (in 1.8.8). I'm not sure what changed, but ultimately what I did was
    a bunch of comparative testing against 1.8.8:

    - I confirmed the packet data was still being read successfully
    - I confirmed that the axis value being passed into pad->get_axis() had
      not changed
    - I confirmed the work done in `gamepad_read_axis_data()` was working the same
      between 1.8.8 and master

    With the only difference between 1.8.8 and current being the return value from
    `gamepad_read_axis_data()`, I just rewrote the method to work properly, and
    also fixed up the default axis mapping.

    I tested this with a sixaxis controller and GCA, configuring the analog-to-digital
    control override to use the right stick.

## Related Issues
#12964 
[Any issues this pull request may be addressing]

## Reviewers
@twinaphex @QuarkTheAwesome 
",True,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/919626531,Fix analog inputs on HID devices,inactive123,4,996565648,2,919626531,0,996565648,2021-09-15T01:29:57Z,Awesome work once again @gblues . I am sure WiiU users will be very happy with this.,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/920556800,Fix analog inputs on HID devices,blancedd,4,996565648,3,920556800,0,919626531,2021-09-16T04:00:24Z,"Thank you so much @gblues , I just tested it and the right analog stick is now working again, just one other thing, PS Home button on the PS3 controller used to work as Home Button (Retroarch Menu) and is still not working, to get to the Retroarch menu I have to assign a Menu Toggle Combo, it was working fine in 1.8.8

Thanks again for the fix",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/920564551,Fix analog inputs on HID devices,gblues,4,996565648,4,920564551,0,920556800,2021-09-16T04:23:42Z,"@blancedd I think that's related to the removal of the ""any pad controls the menu"" feature that was done (intentionally) awhile back. I did confirm that the PS button is properly mapped and is getting read successfully, I think RA just doesn't pay attention to the menu button for anything other than pad 0 (always the gamepad on wiiu).",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/920611844,Fix analog inputs on HID devices,blancedd,4,996565648,5,920611844,0,920564551,2021-09-16T06:19:58Z,"@gblues That's strange because if I launch Retroarch with the Gamepad turned off, pad0 is assign to another controller, if it's assigned to a Pro controller Home Button works, even on the Wii remote, but if I launch Retroarch and immediately disconnect bluetooth controllers and the Gamepad having a PS3 controller connected, pad0 is assigned to a PS3 Controller and the Home Button doesn't work, this is why I thought this was a HID problem

![IMG_20210915_231310920](https://user-images.githubusercontent.com/90412864/133559791-8e577440-f2f1-4721-84d8-b6816888b7b1.jpg)
",False,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/1175,Proposal: a new general purpose Block extension,waylan,84,970498069,1,970498069,0,0,2021-08-13T15:22:39Z,"I haven't solidified the proposal yet, but I am envisioning something like a fenced code block (except its not for code and would use different delimitators) which might support two different block types:

1. Element Block: The user would define the HTML element (tag) and any attributes. This would be simpler to deal with (read, write and parse) that md_in_html as it avoids lots of HTML tags in your Markdown.
2. Templated Block: The user would define the block 'type' and any attributes. So long as a template exists for the 'type', then the content is inserted into the template after being parsed as Markdown.

Therefore, if the user provided `div` (for an element block), the content is parsed as Markdown and then wrapped in a `div` element with any additional attributes being set on the `div`. However, if the user provides a 'type' of `admonition`, then the `admonition` template is used. Presumably the template would expect a set of attributes (including the admonition type), a title and a body and insert those values into the HTML template. Other templates might accept other options.

This would also allow users to use the CSS provided by whichever CSS framework they are using. For example, the MkDocs default theme is using Bootstrap, which provides it own set of [alerts][1]. However, MkDocs doesn't use them, but instead also provides CSS for Rst style admonitions because that is what the admonition extension expects. With a new block extension, a Bootstrap alert template could allow Bootstrap's CSS to be used along with all of Bootstrap's alert features (icons, dismissal, etc) removing the need for the MkDocs theme to also include the Rst based CSS.

A few additional things to note:

I would prefer to not add any new extensions to the core library. So I would expect this to be developed in a separate repo. However, I mention it here because it could effect how we proceed with #1174. Also, I would appreciate any feedback on the idea and/or input on a possible syntax proposal.

[1]: https://getbootstrap.com/docs/5.1/components/alerts/",True,0,MEMBER
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/898558372,Proposal: a new general purpose Block extension,waylan,84,970498069,2,898558372,0,970498069,2021-08-13T15:52:12Z,"My initial proposal suggests that these blocks are different from fenced code blocks, but another option would be to use the fenced code block delimitators and also provide for a 'code' type.  In our implementation, a user could provide their own 'code' template which might allow them to provide their own custom syntax highlighting solution. If we went this way, the user would simply use this extension instead of the `fenced_code` extension, avoiding any conflicts.

I am undecided which way to go on this. Do we overload fenced code blocks, or create a completely new and different fenced block? Similar approaches (overloading fenced code blocks) have been taken by other implementations. For example r-markdown uses fenced code blocks to define the `r` code which is executed with its output being included in the rendered document. I have also seen at least one Markdown-to-reStructuredText bridge which used overloaded fenced code blocks to replicate directives (sorry, I don't recall which one). To my mind, the primary benefit of overloading fenced code blocks is that when a document using the blocks are parsed by other Markdown implementations, the block is simply parsed as a plain code block. In contrast, introducing a completely new syntax could result in some weird output from other implementations. The only reason the existing admonitions extension mostly avoids this is because the content is indented and becomes a code block. But I would prefer to not indent the content of the new block.",False,0,MEMBER
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/898568847,Proposal: a new general purpose Block extension,facelessuser,84,970498069,3,898568847,0,898558372,2021-08-13T16:08:18Z,"In general, when I went through the pain of getting fenced blocks to work under lists and such via SuperFences, I just made it so that users could create custom fences to generate whatever kind of block they wanted. With that said, it still doesn't run inline with normal block processors, so it has some limitations as the content is stored under placeholders like code.

I'd love an approach that uses the normal block processors, and if it is possible, I'd love to see how that would work.

1. The way Python Markdown currently normalizes line breaks and such between blocks is frustrating for code blocks as any code blocks with multiple empty lines always get normalized to one. 
2. Even in Admontions there is still a degree of complexity involved with appending additional blocks as children and accounting for lists and such. I think this is partly due to how Python Markdown consumes blocks.

Anyways, I'm at least interested to see how this may potentially work.",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/898615723,Proposal: a new general purpose Block extension,waylan,84,970498069,4,898615723,0,898568847,2021-08-13T17:33:48Z,"@facelessuser you make some valid points. I have not looked too closely at how you implemented superfences, and was curious how you worked around the problems with the existing block parser. Sounds like you didn't. It may not make sense to even attempt this until after we refactor how blocks are parsed. However, I'm not really interested in tackling that problem right now. Mostly I am simply trying to get my ideas recorded at this point. I haven't given much thought to how it might be implemented.

",False,0,MEMBER
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/898616297,Proposal: a new general purpose Block extension,mitya57,84,970498069,5,898616297,0,898615723,2021-08-13T17:34:55Z,See also Pandoc Markdown's Divs and Spans https://pandoc.org/MANUAL.html#divs-and-spans which have a bit different but similar idea.,False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/898983055,Proposal: a new general purpose Block extension,facelessuser,84,970498069,6,898983055,0,898616297,2021-08-15T01:56:26Z,"> @facelessuser you make some valid points. I have not looked too closely at how you implemented superfences, and was curious how you worked around the problems with the existing block parser. Sounds like you didn't. It may not make sense to even attempt this until after we refactor how blocks are parsed. However, I'm not really interested in tackling that problem right now. Mostly I am simply trying to get my ideas recorded at this point. I haven't given much thought to how it might be implemented.

Yeah, I accomplish everything through the preprocessor still. It's a bit hacky, but it was the only way to avoid the above issues. Anyways, I think this is a good idea, and generally, if/when block parsers are able to handle blocks better, this will be a good addition on top of it.",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/980848674,Proposal: a new general purpose Block extension,alkisg,84,970498069,7,980848674,0,898983055,2021-11-28T06:34:45Z,"As a user, I think this is a wonderful idea!
I'm currently migrating a mediawiki site to git/markdown. For admonitions, the pandoc mediawiki→markdown converter produced `::: warning`, which is the same that markdown-it, docusaurus and some others use. It'll take time to update hundreds of wiki pages to `!!! warning` and indented content that mkdocs uses. Also, if I ever need to switch away from mkdocs in the future, I'll have to convert the content once more.
The `::: class` (and the `::: tag`) ideas are so powerful, that will probably make `!!! admonitions` obsolete if they're implemented! I hope we can see this in production soon! :)",False,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/981762063,Proposal: a new general purpose Block extension,waylan,84,970498069,8,981762063,0,980848674,2021-11-29T15:48:37Z,"Just stumbled upon [MyST][1], a Commonmark parser which is intended as a reStructuredText replacement. I've seen many before, but this is the first one where I like the [directives syntax][2]. It is very similar to what I was trying to accomplish here. See also, their optional [colon_fence][3] extension, which looks similar to (but not the same as) Pandoc's syntax.

Also of interest is their [discussion][4] of various existing proposals and implementations out in the wild and why they chose what they did.

[1]: https://myst-parser.readthedocs.io/en/latest/index.html
[2]: https://myst-parser.readthedocs.io/en/latest/syntax/syntax.html#directives-a-block-level-extension-point
[3]: https://myst-parser.readthedocs.io/en/latest/syntax/optional.html#code-fences-using-colons
[4]: https://myst-parser.readthedocs.io/en/latest/explain/index.html",False,0,MEMBER
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/981791443,Proposal: a new general purpose Block extension,facelessuser,84,970498069,9,981791443,0,981762063,2021-11-29T16:19:24Z,"> Just stumbled upon [MyST](https://myst-parser.readthedocs.io/en/latest/index.html), a Commonmark parser which is intended as a reStructuredText replacement. I've seen many before, but this is the first one where I like the [directives syntax](https://myst-parser.readthedocs.io/en/latest/syntax/syntax.html#directives-a-block-level-extension-point). It is very similar to what I was trying to accomplish here. See also, their optional [colon_fence](https://myst-parser.readthedocs.io/en/latest/syntax/optional.html#code-fences-using-colons) extension, which looks similar to (but not the same as) Pandoc's syntax.

Unfortunately, us doing code this way, without a huge overhaul of the parser to get block handling where we want, may not be possible. And I definitely wouldn't try to use the ` ```{directive} ` format unless the block handling was refactored as the only real way to properly preserve code is using the PreProcessor, and that syntax will conflict with fenced code (at least as things are currently).

But, if you don't need to preserve empty lines and such for code blocks and you just want to handle normal Markdown content, it *may* be possible to cook something up now. I've been considering possibly tinkering with a way to pull this off now that I've had some time to think about it, at least the logic in regards to the handling of the ""fences"". Assuming some sort of prototype could be pulled off, we'd at least have something to work with now.

",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1204715550,Proposal: a new general purpose Block extension,facelessuser,84,970498069,10,1204715550,0,981791443,2022-08-04T03:32:15Z,"So, I actually started to play around with this, and it is in a very early prototype stage. I wanted to make sure I could get it to work in lists and such. I kind of played with the directive syntax some. I'm not sure if anything below, syntax or behavior-wise,  will be the final implementation, but this is currently just exploratory.

The thing I like is that you don't have to do indentations for admonitions and such, and it doesn't break my editor's syntax highlighting :). I guess some common admonitions could be created like `warning` and if people want something different, they could use the generic `admonition` type.  Anyways, this was a simple test:

```markdown
- 
    ::::{admonition} This is really important!
    ---
    type: warning
    ---

    Don't do that, for these reasons:

    - 
        :::{details} Here is a summary
        This is nested!
        :::

    ::::

    :::{html} div
    ---
    attributes: {id: some-id, class: these are classes}
    ---

    Some other content
    :::

```

Results

```html
<ul>
<li>
<div class=""admonition warning"">
<div class=""admonition-title"">This is really important!</div>
<p>Don't do that, for these reasons</p>
<ul>
<li>
<details>
<summary>Here is a summary</summary>
<p>This is nested!</p>
</details>
</li>
</ul>
</div>
<div class=""these are classes"" id=""some-id"">
<p>Some other content</p>
</div>
</li>
</ul>
```

So far the directives are pretty simple objects. They have `on_create` events and `on_end` events.  You can store the content as you accumulate it and then process it once you hit `on_end`, or not store it and let the Markdown parser just parse it as Markdown content.  That's really it.

```py
class DirectiveTemplate:
    """"""Directive template.""""""

    # Set to something if argument should be split.
    # Arguments will be split and white space stripped.
    ARG_DELIM = ''
    NAME = ''
    STORE = False

    def __init__(self, length):
        """"""Intitialize.""""""

        self.store = []
        self.length = length

    def config(self, args, **options):
        """"""Parse configuration.""""""

        self.args = [a.strip() for a in args.split(self.ARG_DELIM)] if args and self.ARG_DELIM else [args]
        self.options = options

    def on_create(self, el):
        """"""On create event.""""""

    def on_end(self, el):
        """"""Perform action on end.""""""
```

Anyways, I figured I share it and see if people had any thoughts.
",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1204726206,Proposal: a new general purpose Block extension,facelessuser,84,970498069,11,1204726206,0,1204715550,2022-08-04T03:55:38Z,"Yeah, it is pretty easy to just derive to create shortcut for Note admonitions and such:

```py
class Admonition(DirectiveTemplate):
    """"""Admonition.""""""

    NAME = 'admonition'

    def on_create(self, parent):
        """"""Create the element.""""""

        el = etree.SubElement(parent, 'div')
        t = self.options.get('type', '').lower()
        title = self.args[0] if self.args and self.args[0] else t.title()
        classes = [c for c in self.options.get('classes', '').split(' ') if c]
        if t != 'admonition':
            classes.insert(0, t)
        classes.insert(0, 'admonition')
        ad_title = etree.SubElement(el, 'div', {'class': 'admonition-title'})
        ad_title.text = title
        el.set('class', ' '.join(classes))
        return el


class Note(Admonition):
    """"""Note.""""""

    NAME = 'note'

    def config(self, args, **options):
        """"""Parse configuration.""""""

        super().config(args, **options)
        self.options['type'] = 'note'
```

And then this:

```markdown
:::{admonition} This is really important!
---
type: warning
---

Don't do that!
:::

:::{note}
Just a note
:::

:::{note} With a title
And some words.
:::
```

Becomes this:

```html
<div class=""admonition warning"">
<div class=""admonition-title"">This is really important!</div>
<p>Don't do that!</p>
</div>
<div class=""admonition note"">
<div class=""admonition-title"">Note</div>
<p>Just a note</p>
</div>
<div class=""admonition note"">
<div class=""admonition-title"">With a title</div>
<p>And some words.</p>
</div>
```
",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1205287772,Proposal: a new general purpose Block extension,waylan,84,970498069,12,1205287772,0,1204726206,2022-08-04T13:51:21Z,"Very cool. Although, when I initially proposed a template block, I meant to actually use a template. Something like the following, which would allow the end user to define any layout they want.

```
<div class=""admonition {{ type }}>
<div class=""admonition-title"">{{ title }}</div>
{{ body }}
</div>
```

Of course, that would ideally end up as part of the etree, which adds additional complications, so I understand why you haven't taken that approach. It's just that requiring users to use the etree API to define their own custom blocks narrows the target audience. Although, I suppose for specific predefined block types like admonitions, using the etree API is probably more performant. However, a wrapper around what you have so far could provide a more general purpose system which uses actual templates. I just wouldn't name what you have ""template.""",False,0,MEMBER
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1205347804,Proposal: a new general purpose Block extension,facelessuser,84,970498069,13,1205347804,0,1205287772,2022-08-04T14:37:21Z,"> However, a wrapper around what you have so far could provide a more general purpose system that uses actual templates. I just wouldn't name what you have ""template.""

Yeah, the idea of templates wasn't really laid out, and I do realize what I have isn't a template. The naming is quite wrong in that regard. I haven't even thought about true templates yet. I'm still working through getting the blocks to not get messed up when passing through lists. There are always list corner cases...always 😢 .

I feel there is an advantage to more advanced, non-template type variants, but I can also see the attraction for actual tempaltes.",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1205570230,Proposal: a new general purpose Block extension,facelessuser,84,970498069,14,1205570230,0,1205347804,2022-08-04T17:39:14Z,"I did get ""templating"" working. But it seems to offer a host of troublesome situations. We have to create a temporary `div` to let Markdown figure out the context and properly wrap things in `<p>` and such, but it doesn't have any intelligence to know which variables need escaping and which will be handled by Markdown. Also, what if you insert the content into something that requires preserving the text (like in a code block). 

It's all kind of a pain. I haven't even bothered to try and figure out all the templating cases, just wanted to see if we could utilize the existing system to convert templates into directives:

```py
TEST = """"""
<div class=""{directive}"">
<div class=""test-title"">{arg0}</div>
{body}
</div>
""""""
```

```markdown
:::{test} A title
Some **content**

More content

    This is code

:::
```

```py
<div class=""test"">
<div class=""test-title"">A title</div>
<p>Some <strong>content</strong></p>
<p>More content</p>
<pre><code>This is code
</code></pre>
</div>
```

So, could it kind of sort of work? Yeah, is there a lot more intelligence that would have to be added? Probably. Is it worth the effort? 🤷🏻 How much motivation do I have to plow through and get a fully working template approach? :shrug:

Knowing that a template approach is _probably_ viable is probably enough for me right now. I think my main concern is making sure the general flow is fairly sound and maybe putting up an experimental branch over at [pymdown-extensions](https://github.com/facelessuser/pymdown-extensions).

I think I have most major list flow issues solved.",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1205584484,Proposal: a new general purpose Block extension,facelessuser,84,970498069,15,1205584484,0,1205570230,2022-08-04T17:53:02Z,"I guess you could maybe make available an `escaped-body`  and a `body` that could dictate what kind of temporary element gets created to store the content. For the rest, you just have to kind of assume the user won't feed in bad content as there is no way to be for sure about context.

If the user is creating a series of elements that require their own different body each with different requirements...too bad 🙃 . I think the template case shouldn't be allowed to be that complicated. If they have a greater need, they shouldn't use the template approach.
",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1205603755,Proposal: a new general purpose Block extension,facelessuser,84,970498069,16,1205603755,0,1205584484,2022-08-04T18:11:19Z,"I guess I should state that currently, templates with nested directives fail...not sure why though. I'll have to dig a bit deeper.",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1205629223,Proposal: a new general purpose Block extension,waylan,84,970498069,17,1205629223,0,1205603755,2022-08-04T18:37:35Z,"I think leaving templates as  something to tackle later is a reasonable approach. My initial proposal was simply trying to present an ideal situation from the user's perspective with no thought to how it would be implemented. I'm sure its possible, but it may not be worth the effort.",False,0,MEMBER
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1205646829,Proposal: a new general purpose Block extension,facelessuser,84,970498069,18,1205646829,0,1205629223,2022-08-04T18:48:01Z,"Yeah, that sounds good. That's probably going to be my approach for now. I think my current issue is the fact I'm swapping out the placeholder with the real template element during the block processor phase...but maybe that kind of operation shouldn't happen until after the block processor phase is over...

I'm certain it s doable, but I think getting a sound base before I burn up my motivation is key 🙂.

Anyways, I'll keep experimenting as I have time and then pair down to what I think is most useful once it seems the obvious issues are resolved.",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1207091938,Proposal: a new general purpose Block extension,facelessuser,84,970498069,19,1207091938,0,1205646829,2022-08-05T23:47:24Z,"I've found something particular about list handling that won't allow:

```
- ::::{admonition} This is really important!
  ---
  type: warning
  class: some-class
  ---
```

It gets all messed up and turns them to `hr` blocks and such. This doesn't happen outside of lists.

I'm going to prototype with `~~~` for now:

```
- ::::{admonition} This is really important!
  ~~~
  type: warning
  class: some-class
  ~~~
```",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1207110905,Proposal: a new general purpose Block extension,facelessuser,84,970498069,20,1207110905,0,1207091938,2022-08-06T00:53:22Z,"I forgot that `~~~` is an alternate code format 🤦🏻 . But it seems I can get away with two (`--`) which is not quite what I'm looking for, but will allow me to finish making sure the logic is okay....Somehow `hr` is getting a hold of it before we see can get it under a list.

This is somewhat surprising as I would expect that `hr` wouldn't touch the content of a list until we've started processing the content as list blocks, but I guess maybe it preprocesses the blocks before lists...",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1207114058,Proposal: a new general purpose Block extension,facelessuser,84,970498069,21,1207114058,0,1207110905,2022-08-06T01:08:25Z,"Yep, `hr` is processed before lists, this is likely to catch `- - -` before lists as I think `---` shouldn't trigger lists. Sigh, well that limits using `---` unless someone has a clever workaround.",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1207114973,Proposal: a new general purpose Block extension,facelessuser,84,970498069,22,1207114973,0,1207114058,2022-08-06T01:12:37Z,If we really wanted to use `---` Python Markdown would need to split up HR handling I think. Handle loose HR `- - -` prior to lists and tight `---` after lists. I think that is the only way. I'll just use `--` for now as it sits safely between list and HR.,False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1207149401,Proposal: a new general purpose Block extension,facelessuser,84,970498069,23,1207149401,0,1207114973,2022-08-06T05:17:25Z,"I have an experimental branch up here: https://github.com/facelessuser/pymdown-extensions/pull/1777

I ended up monkey patching HR so we could use the `---` format. Nothing we are doing is set in stone. Ideally, I'd like Markdown to make the HR change as I don't currently see a reason not to, but worst case, we could always use `--`.

Feel free to try it out.",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1207217271,Proposal: a new general purpose Block extension,facelessuser,84,970498069,24,1207217271,0,1207149401,2022-08-06T13:42:12Z,"Just an overall description of how the current prototype is laid out. I think I'm ready to discuss the syntax.

```
:::{directive-name} arguments
---
option1: value
option2: value
---

content
:::
```

1. Fencing of blocks requires 3 or more `:`. If nesting blocks, the outer block should have a greater length of `:` than the child blocks. Currently, if a closing fence is encountered that is greater than or equal to the starting fence, it is sufficient to close the current fence.
2. `directive-name` is currently the name of whatever directive you are using. It is case insensitive.
3. `arguments` can be one or many arguments, and the given directive would specify required delimiters if required.
4.  The optional frontmatter containing options is YAML-ish bock that comes immediately after the header, or better put, is part of the header when specified. We currently went with YAML-ish to avoid pulling in PyYAML as a requirement. I'm kind of going with simpler is better right now.

    Due to limitations of the Python Markdown parser, it must be a ""tight"" config (no empty new lines). This also means there should be no newline after the initial header line.

    The key value pairs are similar to the `meta` extension (though I haven't yet made them multi-line, was considering this).

    The directive would impose any specific rules that these options require: delimiter split list, etc.
5. `content`: any valid content can be used, even nested directives. There does not have to be a separation between the header and the content, but can be if desired.

## Examples

Note with no content

```
:::{warning} All we need is a title!
:::
```

```
:::{warning} This is important!
Read this notice.
:::
```

```
:::{warning}
Arguments are optional with some directives!
:::
```

```
:::{figure} some/image.png
---
width: 300
---

I'm a figure caption, and you can specify optional settings for your directives as well!
:::
```

```
::::{tip} Here's a secret

:::{note}
You can nest directives as well
:::

::::
```


",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1207474244,Proposal: a new general purpose Block extension,facelessuser,84,970498069,25,1207474244,0,1207217271,2022-08-07T19:52:51Z,"I did end up allowing the other format for options as well.

```
:::{admonition} Title
:class: note

This is a note
:::
```

I had to add some intelligence so it knew how to handle insertion into different kinds of parents: spans, blocks, etc. I also switched to just using PyYAML for option parsing for now.

Anyways, this is all of course assuming we decide to keep the Myst approach, but I think we are modeling the format as well as Python Markdown can. I may hold off and wait and see if I get some feedback on the format and such before plowing forward much more.

It ended up being a surprisingly more complex endeavor than I thought at first, but I think the hard part is over. Even if we completely rework everything, I think generally the flow is working.
",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1208225545,Proposal: a new general purpose Block extension,waylan,84,970498069,26,1208225545,0,1207474244,2022-08-08T14:45:35Z,"> I think I'm ready to discuss the syntax.

I like the general idea here. Overall, it seems like a great start. I will address each item in turn below. Note that the following is all my personal option and preferences. As this is your third-party extension, I am not dictating that you must use my preferences. However, I am sharing them as a means to provide feedback. In the end, I could work with the syntax as you have it now.

> 1. Fencing of blocks requires 3 or more `:`. If nesting blocks, the outer block should have a greater length of `:` than the child blocks. Currently, if a closing fence is encountered that is greater than or equal to the starting fence, it is sufficient to close the current fence.

I'm curious why you chose colons. Personally, they are not my favorite character for this but I don't have any specific reasons why and I don't have any better suggestions.

However, I was surprised by your nesting rule. Yes, nesting should be supported, but why must the nested blocks increase in length? Why not just require that they be different? I realize that the current syntax makes it simpler for a human to read (longer means deeper nesting), but there is no such requirement for fenced code blocks, which this is modeled after. I don't know, maybe we should have followed this pattern when developing the fenced code block syntax years ago. But we didn't and... well, I'm not sure what to think about this.

> * `directive-name` is currently the name of whatever directive you are using. It is case insensitive.

I'm assuming wrapping the `directive-name` in curly braces is to separate it from the arguments. I probably would have just used a space and required that directive names can't contain spaces. But maybe the braces are better.

> * `arguments` can be one or many arguments, and the given directive would specify required delimiters if required.

You have `arguments` plural, So far I only see examples with a single argument. What would it look like with multiple arguments? I see one example (figure) uses a URL while the rest all use a title. I'm wondering it just naming it `title` would be better and `arguments` should be the name of the ""frontmatter."" Of course, that would eliminate the use case for `figure`, but I wonder if perhaps the URL argument would better fit in the frontmatter anyway.

> 4\. The optional frontmatter containing options is YAML-ish bock that comes immediately after the header, or better put, is part of the header when specified.

I'm very torn about this. On the one hand, using YAML is clearly better. On the other hand, that requires a hard dependency, which I prefer to avoid. Also, I don't love the requirement for YAML delimitators (`---`) and would prefer to avoid them altogether. On the other hand, if your are using YAML, then it makes sense for them to exist. Your alternate syntax (`:class: note`) is interesting, but seems non-standard to me. What was your inspiration for it?

In the end I could live with either. However, if I hadn't used the syntax in a while and didn't look it up, I'm more likely to remember the YAML syntax than `:class: note` (I'm likely to forget the opening colon).

> The key value pairs are similar to the `meta` extension (though I haven't yet made them multi-line, was considering this).

Note that I don't personally use or recommend the `meta` extension any more. Instead, I think that the correct approach is something like [waylan/docdata][0]. Of course, that would not be usable here, but I point to is because [MkDocs uses a variation on that][1], Specifically I like how it differentiates between Multimarkdown metadata and YAML metadata. I'm not sure if we want to support both here, but it is prior art. I would hesitate to introduce another new way to define key/value pairs in Markdown.

> 5\. `content`: any valid content can be used, even nested directives. There does not have to be a separation between the header and the content, but can be if desired.

Personally, I would have started out by requiring a blank line to separate the header from the content. That would eliminate the need to require some other delimitator for the frontmatter. But again, I can live with it either way. Personally, I would be inclined to include a blank line whether it was required or not.

> It ended up being a surprisingly more complex endeavor than I thought at first

Doesn't it often. In any event, you made some great progress on this. When I get a change, I'll look over your code.

[0]: https://github.com/waylan/docdata
[1]: https://www.mkdocs.org/user-guide/writing-your-docs/#yaml-style-meta-data",False,0,MEMBER
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1208299769,Proposal: a new general purpose Block extension,facelessuser,84,970498069,27,1208299769,0,1208225545,2022-08-08T15:49:01Z,"> I'm curious why you chose colons. Personally, they are not my favorite character for this but I don't have any specific reasons why and I don't have any better suggestions.

I was simply using Myst as a reference. I am open to suggestions. Myst allows fenced blocks, which we simply can't do as it will conflict with existing fenced block implementations which must be done as preprocessor to preserve multiple newlines, avoid things like `HR` from getting converted, etc. They also allowed for a `:::` variation, we simply copied what they are doing.

With that said, we don't have to do what they do anyways. They modeled something similar to RST. Not that we had we have to do what they do. I am open to specific alternative suggestions though. Coming up with a syntax that everyone will like is hard, so I'm open to other suggestions.

> However, I was surprised by your nesting rule. Yes, nesting should be supported, but why must the nested blocks increase in length? Why not just require that they be different? I realize that the current syntax makes it simpler for a human to read (longer means deeper nesting), but there is no such requirement for fenced code blocks, which this is modeled after. I don't know, maybe we should have followed this pattern when developing the fenced code block syntax years ago. But we didn't and... well, I'm not sure what to think about this.

It doesn't _have_ to. I think I initially had it not have this requirement, but I think it certainly helps visually. I'm open to dropping this requirement.

> You have arguments plural, So far I only see examples with a single argument. What would it look like with multiple arguments? I see one example (figure) uses a URL while the rest all use a title. I'm wondering it just naming it title would be better and arguments should be the name of the ""frontmatter."" Of course, that would eliminate the use case for figure, but I wonder if perhaps the URL argument would better fit in the frontmatter anyway.

The reference allows multiple arguments, you could define a directive to have space delimited arguments:

```
:::{name} arg1 arg2
:::
```

Or delimit them in some other way if arguments require spaces, maybe commas or semicolons. Again, this is all assuming the current modeling against Myst which models its approach against RST (for better or for worst).

> Your alternate syntax (:class: note) is interesting, but seems non-standard to me. What was your inspiration for it?

It's directly modeled after Myst: https://myst-parser.readthedocs.io/en/latest/syntax/roles-and-directives.html#parameterizing-directives

They don't specifically show it's used with the `:::` syntax, but it is implied on that page. It's more how parameters in general are specified, which work for both ` ``` ` format and `:::`.

> Note that I don't personally use or recommend the meta extension any more. Instead, I think that the correct approach is something like [waylan/docdata](https://github.com/waylan/docdata). Of course, that would not be usable here, but I point to is because [MkDocs uses a variation on that](https://www.mkdocs.org/user-guide/writing-your-docs/#yaml-style-meta-data), Specifically I like how it differentiates between Multimarkdown metadata and YAML metadata. I'm not sure if we want to support both here, but it is prior art. I would hesitate to introduce another new way to define key/value pairs in Markdown.

This is a response to before I switched to YAML. I was simply referencing that I originally tried to avoid a YAML dependency, and considered parsing the options in a similar method. I ended up using YAML, but that is not set in stone yet. I can take a look at you links. I haven't yet looked.

> Personally, I would have started out by requiring a blank line to separate the header from the content. That would eliminate the need to require some other delimitator for the frontmatter. But again, I can live with it either way. Personally, I would be inclined to include a blank line whether it was required or not.

This could still happen. If someone has a well-thought-out syntax, I'm interested in evaluating it. The plan was simply to prototype the Myst approach as a starting point. I am open to another syntax.  Right now, nothing I've submitted for discussion is any different than what is offered under Myst.  The only thing we can't do yet is to insert a raw text block without an HTML wrapper element, but I think this could be accomplished. Do we need this? I don't know, but I was working towards creating something as flexible to understand what we *could* do, and then pair back if we felt it necessary.

The syntax was kind of the same. There was one that existed, so I could prototype it, test what was possible, and then decide if we wanted a brand new syntax or to follow an existing approach.

",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1208330902,Proposal: a new general purpose Block extension,facelessuser,84,970498069,28,1208330902,0,1208299769,2022-08-08T16:17:05Z,"Okay, I just checked out the MkDocs link that uses Multi-Markdown type params. I get what you mean. That is actually what I was doing before importing PyYAML, and what the meta extension more or less does.  We could definitely do this.

Assuming we don't want to model an existing syntax like Myst, and just take inspiration from it, we could:

- Use a Multi-Markdown like syntax for headers.
- Require content to be after a newline to separate content from header parameters.

If we are absolutely not using YAML, then we no longer need `---` in the header and we no longer need `:key: value` behavior.

This would of course take YAML off the table. This limits you somewhat if care about data types, but then you also have to sometimes ""cast"" data types for user experiences (user typed 300, but they really just want to assign that as a string to an HTML width attribute).

I'm not sure if we care about multi-line parameters (like preserving new lines in parameters), but the Multi-Markdown approach would prevent such an option as well.
",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1208436970,Proposal: a new general purpose Block extension,facelessuser,84,970498069,29,1208436970,0,1208330902,2022-08-08T18:00:31Z,"Okay, the reference implementation does use increasing levels of colons. It also clearly shows the shorthand parameter format too (`:key: value`): https://myst-parser.readthedocs.io/en/latest/syntax/optional.html#code-fences-using-colons

So, as of right now, we are duplicating their syntax.

So far there have been a number of proposals, so I'll summarize them below:

- Don't use `:::`, but no alternative has been suggested yet. Open to alternate proposals.
- Don't require a different amount of (currently colons) when for nested elements. The reference implementation does this, and I think this would make things harder to read.
- Don't require directive name in `{}`, but is this more confusing?

    ```
    :::name some argument(s)
    :::

- These are kind of related. Don't use YAML, and maybe use something like Multi-Markdown format,
   require a blank new line between the header (which includes the parameters) and the content.

    This would eliminate the need for a YAML dependency, YAML fences `---`, and alternative `:key: value` format.

    ```
    :::{name} some argument(s)
    class: additional
               classes
    some-option: whatever

    content
    :::
    ```",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1208583640,Proposal: a new general purpose Block extension,waylan,84,970498069,30,1208583640,0,1208436970,2022-08-08T20:34:27Z,"Ah, I had missed that this is copying a pre-existing implementation (Myst). Now it makes more sense to me. The one concern I have is that Myst is specifically intended as a ""Markdown for Docutils."" Therefore, it is intended to be a direct replacement for Rest directives. Whereas we are looking for something this is more ""inspired by"" than a direct replacement.

That being the case, I think the `:key:` syntax should be out as that is a direct copy of Rest directive syntax. Presumably it is supported in Myst so that a user could copy a Rest directive to a Markdown document and not need to alter it.

Regarding the YAML vs. MultiMarkdown issue, I prefer YAML. In fact, IIRC MultiMarkdown has more recently been updated and it now uses YAML parsing. I don't see the point in adding support for an old standard in a new location where is has never existed before. YAML also gives us types out-of-the-box, which is better in my opinion (for example, if the user needs a string containing a number, they can wrap in in quotes and we don't need to explicitly build support for that into the parser).  The one thing I don't love about YAML is the delimitators (`---`).  Personally, I would simply require a blank line between the header and the content. Anything before the blank line and the first line would be assumed to be YAML. I suppose you could allow the delimitators optionally for those who want to use them.

> Don't use `:::`, but no alternative has been suggested yet. Open to alternate proposals.
> 
> Don't require a different amount of (currently colons) when for nested elements. The reference implementation does this, and I think this would make things harder to read.
> 
> Don't require directive name in `{}`, but is this more confusing?

I can see both sides of these, but I don't have any better suggestions either. To me they all feel like ""we jut copied Myst"" which in some ways is unsatisfying for the reasons stated above. But, without a better proposal, it is completely understandable.",False,0,MEMBER
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1208603946,Proposal: a new general purpose Block extension,facelessuser,84,970498069,31,1208603946,0,1208583640,2022-08-08T20:59:10Z,"> That being the case, I think the :key: syntax should be out as that is a direct copy of Rest directive syntax. Presumably it is supported in Myst so that a user could copy a Rest directive to a Markdown document and not need to alter it.

Yeah, I'm not a huge fan of all the config lines with `:` either. I barely tolerate block quotes requiring this.

> To me they all feel like ""we jut copied Myst"" which in some ways is unsatisfying for the reasons stated above.

I certainly understand this. It's much easier to implement the guts sometimes than it is to come up with syntax. Copying Myst allowed me to think about how I would approach the guts, but was not necessarily meant to be the final syntax, but I didn't have any great ideas for syntax yet either.

TBH, I don't like having to come up with new syntax, so I procrastinated, hoping the ""committee"" method would turn out something better 🙃.

I don't care about specifically being compatible with Myst or RST. I do feel you need some sort of generic fencing, you need some sort of way to indicate which general block you are defining, and some way to tweak options. I think options should come before content so we can properly setup the target element(s), so I think having the options specified as part of the header is a good idea.

Internally, it needs to be flexible. And I think what I currently have can handle simple things like admonitions, and much more complex block structures if required. It's just figuring out the Markdown syntax that doesn't make people claw their eyes out or throw their keyboard out the window.",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/1176,Add pre-commit hook,voronind,3,973530498,1,973530498,0,0,2021-08-18T10:46:03Z,Can we add [pre-commit](https://pre-commit.com/index.html#new-hooks) hook? There is no Python markdown linter.,True,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/901100316,Add pre-commit hook,facelessuser,3,973530498,2,901100316,0,973530498,2021-08-18T13:07:30Z,"I'm confused about what this is asking. Are you asking that git commit hooks are added to the Python Markdown project to lint its own resources? Or are you asking for a separate project that uses Python Markdown and can be installed as a git hook to lint other Markdown content in other projects?

If it is the latter, you are free to create any project you need using Python Markdown as a dependency, I don't imagine we will be taking on an additional project to provide such functionality. If it is the former, I'm pretty sure we have everything we need to ensure proper project health and don't really need to add pre-commit hooks at this time.

Feel free to clarify if I am still a bit confused as to what is being asked.",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/902159135,Add pre-commit hook,voronind,3,973530498,3,902159135,0,901100316,2021-08-19T18:53:23Z,I mean checking other projects on Markdown file correctness.,False,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/902351247,Add pre-commit hook,waylan,3,973530498,4,902351247,0,902159135,2021-08-20T00:58:10Z,"> I mean checking other projects on Markdown file correctness.

That it out-of-scope for a Markdown parser. Note that a linter enforces best practices which is much more strict than a parser. Therefore, the linter does not need to make use of the same parser as you are using to parse your document. 

Personally, I use and recommend [DavidAnson/markdownlint][1] as a Markdown linter.

[1]: https://github.com/DavidAnson/markdownlint",False,0,MEMBER
https://api.github.com/repos/Python-Markdown/markdown/issues/1177,lxml support,arkadesOrg,14,977266493,1,977266493,0,0,2021-08-23T17:37:49Z,"Some projects already rely on lxml features internally, but still want to make use of the python-markdown package. So it can be important to use the third-party implementation with python-markdown if one wants to deeper integrate with markdown library.

I did outsource the etree import mechanism into markdown/etree module as a try-except block.",True,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/903980165,lxml support,facelessuser,14,977266493,2,903980165,0,977266493,2021-08-23T17:45:08Z,"What about 3rd party plugins interacting with a now unknown implementation? Now they aren't sure if it is an lxml or built-in XML.



",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/903991462,lxml support,arkadesOrg,14,977266493,3,903991462,0,903980165,2021-08-23T18:02:37Z,"True, so the lxml-switch should go into the configuration right?",False,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/904005279,lxml support,facelessuser,14,977266493,4,904005279,0,903991462,2021-08-23T18:21:03Z,"You'll have a mix of 3rd party plugins. Most won't support this. TBH, I am doubtful @waylan will accept this.

What are you hoping to gain by having lxml support baked in?",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/904006255,lxml support,facelessuser,14,977266493,5,904006255,0,904005279,2021-08-23T18:22:26Z,"Also, keep in mind that @waylan  evaluated a number of parsers and such for HTML and may have evaluated lxml and passed on it for one reason or another.",False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/904023746,lxml support,arkadesOrg,14,977266493,6,904023746,0,904006255,2021-08-23T18:50:36Z,"I recognized that the package architecture moved away from the global etree-variable toward a decentralized etree package import. So it became harder to switch parser without changing the python-markdown source.

I am currently working on a template engine using lxml's FunctionNamespace to extend the XPath functionality. So first I parse extended md files into etree, and then run the renderer (which also evaluates extended XPath and dpath on external resources from inside markdown, and also heavily relies on lxml's _getparent_) on it.

IMHO a custom parser configuration would be a nice feature. But I should call the branch experimental-lxml-support though, to make clear that non-standard parsers are not officially supported but possible.

I will try to come up with a reasonable Markdown config mechanism to switch parser optionally away from the python builtin parser.",False,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/904028683,lxml support,waylan,14,977266493,7,904028683,0,904023746,2021-08-23T18:58:45Z,"What value does this offer? We don't output the etree document to the end-user. We only use it internally and then output the rendered string. True, extensions can operate on the etree object and you can get the etree object as output using hacks, but even then, what benefit does lxml's implementation provide? 

If you want to combine the output of Markdown with an existing lxml etree object, then I would suggest running Markdown's output through lxml's parser. As a reminder, Markdown postprocessors take various actions on the rendered string which you will be missing if you make use of our internal etree object directly.",False,0,MEMBER
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/904052244,lxml support,arkadesOrg,14,977266493,8,904052244,0,904028683,2021-08-23T19:19:06Z,"In my case the benefit is to be able to use extended XPath evaluation from within my custom Markdown Extension. I already tried to back-and-forth parse the tree between _xml_ and _lxml_ inside the treeprocessors stage, but its horrible and just does not work, especially if I rely on references to nodes of the previous stage. In my case the best solution is to optionally switch the parser at the earliest stage possible, so the postprocessor won't miss anything but just run on lxml.

Of course I see the advantage of the builtin xml parser, most parties will be fine with lesser dependencies.
But lxml comes with extended XPath plus customizable XPath functions.
Now for example I can have a YAML data block inside Markdown and access it's values from within markdown text through {{ customFunc(/data/value1 + /data/value2) }} placeholder.

PS: thanks for both your quick and detailed answers though",False,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/904074004,lxml support,waylan,14,977266493,9,904074004,0,904052244,2021-08-23T19:53:00Z,"What would you do if we didn't use etree at all? I would suggest exploring that approach. For example, the codehilite extension inserts a placeholder in the etree object and stores the actual HTML in a stash. The placeholder is later swapped out for the stashed HTML in a postprocessor after the etree is rendered to a string. And highlighted code blocks are just plain HTML which would be relatively easy to insert as etree objects.

By the way, I have always been annoyed the lxml's etree object is not compatible with ElementTree. I see this as a bug with lxml and not something we need to accommodate. Therefore, I have always avoiding using it. I don't want to start now if there is any way to avoid it.",False,0,MEMBER
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/904085288,lxml support,arkadesOrg,14,977266493,10,904085288,0,904074004,2021-08-23T20:09:32Z,"The question of what would I do without etree is a bit out of scope. I guess I'd write a Markdown parser with ElementTree and experimental lxml-support in some of those parallel universes.
Anyway I agree that it is not the Python-Markdown-team's job to be compatible with multiple parsers.
But if I use an experimental parser through a parser-config-feature for my lxml-dependent Markdown-Extension, I will be in charge to commit ElementTree compatibility improvements to the lxml project. Basically lxml claims to be compatible with ElementTree, and not vice versa.

I'll implement a optional-parser-feature for Markdown kwargs-config-dict locally and do some further testing on it's compability. I'll let you know about another pull request.

What disadvantages/incompabilities of lxml did you encounter, except the unicode-string-thingy? I remember I did some hackish workaround locally several years ago, to make the codehilite placeholder work with lxml.",False,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/904655293,lxml support,waylan,14,977266493,11,904655293,0,904085288,2021-08-24T13:43:53Z,"> I guess I'd write a Markdown parser with ElementTree and experimental lxml-support

Interesting. Personally, in retrospect, I believe using ElementTree was the wrong choice for Markdown way back when. If I was to start over, I would instead generate an abstract syntax tree. The only reason we leave etree support in is to continue to support the large number of existing third party extensions. However, I'm not interested in expanding etree support.",False,0,MEMBER
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/904668458,lxml support,arkadesOrg,14,977266493,12,904668458,0,904655293,2021-08-24T14:00:07Z,"Interesting. So you'd rather print the XML-tree directly, right?
You want to develop the project away from common interfaces like ET or lxml?
So, hopefully you are not the only Developer to make the decision on this.
I am pretty sure the imagination of the community can follow my constructive
intention of enabling entended lxml functionality with almost no cost.",False,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/904688460,lxml support,waylan,14,977266493,13,904688460,0,904668458,2021-08-24T14:23:02Z,"> So you'd rather print the XML-tree directly, right?

Yes, that is correct.

> You want to develop the project away from common interfaces like ET or lxml?

Yes. Those are terrible HTML libraries IMO. They make sense for XML, but for HTML, they feel like a hack. I've discussed this at length elsewhere so I won't rehash it here.

That said, there are no plans to make any changes at this time because we want to continue supporting the existing library of third party extensions. I expect that if anything changes, it would be that this project gets put into maintenance mode. In other words, we would only consider/commit bug fixes and made no feature additions.

",False,0,MEMBER
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/904979783,lxml support,arkadesOrg,14,977266493,14,904979783,0,904688460,2021-08-24T21:11:15Z,"I see. But someone who uses python to process Markdown will most probably need further transformations beyond bare XHTML output.
Anyways, could you lead me to the public discussion on ET/lxml as HTML libraries? I have to re-evaluate my own targets. Thank you!",False,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/905496223,lxml support,waylan,14,977266493,15,905496223,0,904979783,2021-08-25T13:21:08Z,"> But someone who uses python to process Markdown will most probably need further transformations beyond bare XHTML output.

Then they should be making those transformations after Markdown returns its output, not as part of the Markdown parser itself.

For the reasons stated here as well as in #1179, I am closing this.",False,0,MEMBER
https://api.github.com/repos/Python-Markdown/markdown/issues/1178,[Feature Request] Ignore header in table of contents (toc),j1elo,4,977966256,1,977966256,0,0,2021-08-24T10:50:16Z,"It could be useful, and after seeing the code, almost trivial to add support to skip / ignore / omit some of the document headers, using a header attribute.

I'm thinking of something like this: https://bookdown.org/yihui/rmarkdown-cookbook/toc-unlisted.html

Using the Attribute Lists extension is a great way to allow users fine tune the desired behavior. Right now, the TOC extension allows using just one, [data-toc-label](https://github.com/Python-Markdown/markdown/blob/7cff3bd5af4a3ebea608b9fc7c48327d67147db0/markdown/extensions/toc.py#L292), so I'd propose adding a `data-toc-unlisted` which disables adding the header to the TOC.

Code would be pretty minimal, something like this (but I'm no Python programmer so syntax may be off):

```python
for el in doc.iter():
    ....

    # Check if data-toc-unlisted attribute is present, to skip current element
    if 'data-toc-unlisted' in el.attrib:
        del el.attrib['data-toc-unlisted']  # Not sure if deleting the attr is really needed
        continue                            # This is the key point: to skip the current element altogether

    ...
```

Let me take the chance to say thank you to all maintainers and devs of this project!",True,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/904660759,[Feature Request] Ignore header in table of contents (toc),waylan,4,977966256,2,904660759,0,977966256,2021-08-24T13:50:41Z,"Interesting idea. The existing implementation elsewhere certainly helps.

However, I have to wonder what use case this meets. Seems weird to me to just skip one in a list of headers all from the same level. It would seem more reasonable to me to ignore all headers above and/or below a certain level, which we already support via the `toc_depth` config option.",False,0,MEMBER
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/921682540,[Feature Request] Ignore header in table of contents (toc),iBug,4,977966256,3,921682540,0,904660759,2021-09-17T10:17:31Z,"Ruby Kramdown already ignores headings with class `no_toc` in ToC generation. What about just adopting this setup for ""compatibility"" (so users migrate their documents easier)?",False,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/938594078,[Feature Request] Ignore header in table of contents (toc),j1elo,4,977966256,4,938594078,0,921682540,2021-10-08T12:13:54Z,"> seem more reasonable to me to ignore all headers above and/or below a certain level

That's the most typical way to skip elements in a TOC, yes. But it's a different thing.

Say you have this:

```
# Topic title
## Advanced comments on the topic

# Examples
## Example 1: with Java
## Example 2: with C++
```

Depending on the narrative, it might make perfect sense to have the ""Advanced comments"" as a subheading inside some title... and not having it appear in the TOC. Meanwhile, the ""Examples"" and each of its subsections would make sense in the TOC (so people interested in C++ can jump right into it). This is a typical scenario where excluding specific headers from TOC would be helpful, while the simpler mechanism of excluding higher or lower bounds becomes insufficient.",False,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1979972868,[Feature Request] Ignore header in table of contents (toc),j-davis-2022,4,977966256,5,1979972868,0,938594078,2024-03-06T02:37:01Z,"I'm working on a project where a feature like this would be very useful (at least, with my amateur coding ability).
I'm trying to build a fan wiki, and I noticed wikipedia has a sort of box with basic information to one side (example here: https://en.wikipedia.org/wiki/Cat_Quest). I want to be able to implement something similar purely with markdown, but I haven't found a way to omit the heading of the box that looks consistent with the rest of the page.

The only other option I can think of is to style an element or class to look like the header with CSS, but that might be bad for accessibility, so I'd rather not resort to that. I've edited the library in my personal project to add this functionality, but I think it would be easier in the long run, and for more people, to have it as a part of the code to begin with.",False,0,NONE
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/10248,fix(docker-compose): support Compose V2 `docker compose` command,mcornella,9,1013552472,1,1013552472,0,0,2021-10-01T16:42:34Z,"## Standards checklist:

<!-- Fill with an x the ones that apply. Example: [x] -->

- [x] The PR title is descriptive.
- [x] The PR doesn't replicate another PR which is already open.
- [x] I have read the contribution guide and followed all the instructions.
- [x] The code follows the code style guide detailed in the wiki.
- [x] The code is mine or it's from somewhere with an MIT-compatible license.
- [x] The code is efficient, to the best of my ability, and does not waste computer resources.
- [x] The code is stable and I have tested it myself, to the best of my abilities.

## Changes:

- Tests if `docker compose` runs successfully and uses that to decide whether to use `docker-compose` or `docker compose` in the aliases.

## Other comments:

Fixes #10231
Fixes #10241
",True,0,MEMBER
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/933905065,fix(docker-compose): support Compose V2 `docker compose` command,Frederick888,9,1013552472,2,933905065,0,1013552472,2021-10-04T22:30:35Z,"Sorry I know I should've reported this earlier, but running `docker compose` to check if it's available can block the initialisation for a long time in case of using a remote Docker context.

I've configured a context to connect to a remote Docker host via SSH, and `docker compose` command blocks for ~20s if the Docker host is down. In fact even `docker --help` / `docker --version` block. If there's no good way to work around this, I'm wondering if it's easier to simply allow overriding the auto-detection via an environment variable?",False,0,CONTRIBUTOR
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/934233470,fix(docker-compose): support Compose V2 `docker compose` command,mcornella,9,1013552472,3,934233470,0,933905065,2021-10-05T09:28:21Z,"I consider that a configuration error. I've never done that, but [according to this page](https://blog.mikesir87.io/2019/08/using-ssh-connections-in-docker-contexts/) you could set up the context via an env variable after OMZ has loaded:
```sh
# OR use the DOCKER_CONTEXT env var
DOCKER_CONTEXT=ssh-box docker ps
```

Either way I don't see why a simple `docker compose` command should wait for an external host before displaying the help message 😐",False,0,MEMBER
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/934294754,fix(docker-compose): support Compose V2 `docker compose` command,Frederick888,9,1013552472,4,934294754,0,934233470,2021-10-05T10:50:49Z,"@mcaserta Just guessing, perhaps when there are new subcommands, it needs to check if it's supported by remote Docker host and then decides whether to show the subcommand or not? (But yeah, even this is pretty weird, printing an error message only when such subcommands get called is much simpler.) Anyway, I think this is a bit off-topic here.

And thanks for the info about `DOCKER_CONTEXT`. Instead of setting it after omz (it'll be tricky to apply this environment variable to non-interactive scripts if we do this), I can try applying it to omz initialisation only to switch to the default local context. I'll give it a shot tomorrow on my work machine. But tbh I don't think this is a very clean solution.",False,0,CONTRIBUTOR
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/934296198,fix(docker-compose): support Compose V2 `docker compose` command,mcornella,9,1013552472,5,934296198,0,934294754,2021-10-05T10:53:01Z,"Oh, we could do that in the plugin. Does this work?
```
DOCKER_CONTEXT= docker compose
```",False,0,MEMBER
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/934299013,fix(docker-compose): support Compose V2 `docker compose` command,Frederick888,9,1013552472,6,934299013,0,934296198,2021-10-05T10:56:11Z,"@mcornella It should be `DOCKER_CONTEXT=default docker compose` I think. I used `docker context use ssh-box` make sure the context was applied globally, so here it needs to switch back to the default one temporarily. Not sure if the default context can be deleted or not though...",False,0,CONTRIBUTOR
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/934300673,fix(docker-compose): support Compose V2 `docker compose` command,Frederick888,9,1013552472,7,934300673,0,934299013,2021-10-05T10:58:45Z,"@mcornella Something like
```sh
[[ -n ""$DOCKER_CONTEXT"" ]] && _DOCKER_CONTEXT=""$DOCKER_CONTEXT"" || _DOCKER_CONTEXT=""default""
/usr/bin/env DOCKER_CONTEXT=""$_DOCKER_CONTEXT"" docker compose
unset _DOCKER_CONTEXT
```
?",False,0,CONTRIBUTOR
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/934304211,fix(docker-compose): support Compose V2 `docker compose` command,mcornella,9,1013552472,8,934304211,0,934300673,2021-10-05T11:04:06Z,"You don't need all that, when you set the env variable in the same line you call the command it only applies to that command. So as you said this should work
```sh
DOCKER_CONTEXT=default docker compose
```
Let me know when you test it if it stops taking so long.",False,0,MEMBER
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/934311154,fix(docker-compose): support Compose V2 `docker compose` command,Frederick888,9,1013552472,9,934311154,0,934304211,2021-10-05T11:13:49Z,"@mcornella Yup that works! And I can confirm that the default context cannot be deleted (tested on mac):
```sh
$ docker context rm default
Error: context ""default"": forbidden
```",False,0,CONTRIBUTOR
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/934319413,fix(docker-compose): support Compose V2 `docker compose` command,mcornella,9,1013552472,10,934319413,0,934311154,2021-10-05T11:25:18Z,OK should be fixed in 49bc55f966d91b2a407c883cf1d0f21d0cdd9f4a. Try `omz update`. Thanks for the help!,False,0,MEMBER
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/10260,Recent change to oh-my-zsh.sh makes it so zsh completely fails to load,samvimes42,8,1015253696,1,1015253696,0,0,2021-10-04T14:27:10Z,"Starting with commit 7152a942802b01cb74d7c0b99f3106f8af17439d, when I try to open a terminal instance, zsh completely fails to load because it cannot parse the new f function that was added at the beginning of the file. When I delete the new code added by that commit and the previous one, zsh loads properly.",True,0,NONE
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/933577303,Recent change to oh-my-zsh.sh makes it so zsh completely fails to load,mcornella,8,1015253696,2,933577303,0,1015253696,2021-10-04T15:06:27Z,Which zsh version are you running?,False,0,MEMBER
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/933610418,Recent change to oh-my-zsh.sh makes it so zsh completely fails to load,ThatCooperLewis,8,1015253696,3,933610418,0,933577303,2021-10-04T15:40:53Z,"I am seeing the same issue, here's the full printout when running `zsh`

```
/Users/<user>/.oh-my-zsh/oh-my-zsh.sh:5: defining function based on alias `f'
/Users/<user>/.oh-my-zsh/oh-my-zsh.sh:5: parse error near `()'
```

This is on the latest 568584a master commit.",False,0,NONE
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/933611550,Recent change to oh-my-zsh.sh makes it so zsh completely fails to load,mcornella,8,1015253696,4,933611550,0,933610418,2021-10-04T15:42:14Z,What is f aliased to? `alias f`,False,0,MEMBER
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/933611946,Recent change to oh-my-zsh.sh makes it so zsh completely fails to load,ThatCooperLewis,8,1015253696,5,933611946,0,933611550,2021-10-04T15:42:41Z,@mcornella `f='find . -iname'`,False,0,NONE
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/933613756,Recent change to oh-my-zsh.sh makes it so zsh completely fails to load,ThatCooperLewis,8,1015253696,6,933613756,0,933611946,2021-10-04T15:44:50Z,I can also confirm that reverting to master commit c6c3643 (the commit before 7152a94) resolves this issue,False,0,NONE
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/933615237,Recent change to oh-my-zsh.sh makes it so zsh completely fails to load,samvimes42,8,1015253696,7,933615237,0,933613756,2021-10-04T15:46:38Z,"I see the same error as @ThatCooperLewis. 
Here is my zsh version: `zsh 5.8 (x86_64-ubuntu-linux-gnu)`
Here is my f alias: `f='fasd -f'`
My f alias is from the app fasd.",False,0,NONE
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/933622433,Recent change to oh-my-zsh.sh makes it so zsh completely fails to load,mcornella,8,1015253696,8,933622433,0,933615237,2021-10-04T15:55:30Z,You should be good to go if you still can update with `omz update`. Otherwise manually update by running `$ZSH/tools/upgrade.sh`.,False,0,MEMBER
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/933623731,Recent change to oh-my-zsh.sh makes it so zsh completely fails to load,ThatCooperLewis,8,1015253696,9,933623731,0,933622433,2021-10-04T15:57:07Z,"a54148a fixed it for me, thanks @mcornella !!",False,0,NONE
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/10261,feat(git): add `gupom` and `gupomi` aliases,stevenpitts,8,1015265872,1,1015265872,0,0,2021-10-04T14:37:40Z,"Alias `gupom` to `git pull --rebase origin $(git_main_branch)`.
It is a very common practice for me to rebase off latest remote origin/main once I am finished with a PR, so that the commit history is clean.

## Standards checklist:

<!-- Fill with an x the ones that apply. Example: [x] -->

- [x] The PR title is descriptive.
- [x] The PR doesn't replicate another PR which is already open.
- [x] I have read the contribution guide and followed all the instructions.
- [x] The code follows the code style guide detailed in the wiki.
- [x] The code is mine or it's from somewhere with an MIT-compatible license.
- [x] The code is efficient, to the best of my ability, and does not waste computer resources.
- [x] The code is stable and I have tested it myself, to the best of my abilities.

## Changes:

- Alias `gupom` to `git pull --rebase origin $(git_main_branch)`
- Update README to reflect the new alias

## Other comments:

*Note in this section that I am using `master`/`main`/`$(git_main_branch)` interchangibly in some places, as the PR I am referencing was created before using `git_main_branch` was common practice.*

Also see @hikaru-shindo's PR https://github.com/ohmyzsh/ohmyzsh/pull/8988, which introduces `alias grbom='git rebase origin/master'`.
This is a good suggestion, but it does not cover the full scope of my desires, mainly because it rebases off local origin/master (the version last fetched), not remote origin/master.
I could achieve similar behavior with `gfa && grbom`, but I feel that rebasing off the latest remote master is a common enough practice that a convenient single alias is justified.

CC @hikaru-shindo, @SimenB, @mcornella
",True,0,CONTRIBUTOR
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/966596135,feat(git): add `gupom` and `gupomi` aliases,stevenpitts,8,1015265872,2,966596135,0,1015265872,2021-11-11T20:17:09Z,"@hikaru-shindo @SimenB @mcornella I see a lot of PRs getting ignored on this repo, is there any guide on how I can increase the changes of my PR getting reviewed?
I can't find anything on the contribution guidelines...",False,0,CONTRIBUTOR
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/966898830,feat(git): add `gupom` and `gupomi` aliases,SimenB,8,1015265872,3,966898830,0,966596135,2021-11-12T07:58:51Z,"I'm not a maintainer here, so I can't help you",False,0,CONTRIBUTOR
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/980825049,feat(git): add `gupom` and `gupomi` aliases,stevenpitts,8,1015265872,4,980825049,0,966898830,2021-11-28T02:32:17Z,"@robbyrussell I see you merged https://github.com/ohmyzsh/ohmyzsh/pull/10445 but not this one, could you please let me know what I can do to get this merged?",False,0,CONTRIBUTOR
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1125258955,feat(git): add `gupom` and `gupomi` aliases,jmeridth,8,1015265872,5,1125258955,0,980825049,2022-05-12T17:39:50Z,"@stevenpitts would you be willing to update your PR to also include `gupomi` that aliases to `git pull --rebase=interactive origin $(git_main_branch)` to allow interactive rebasing?  Would be a great compliment to my open PR #10901.  I don't want to steal your thunder on this solution. If not, I can add to my PR.  Cheers.",False,0,CONTRIBUTOR
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1125401069,feat(git): add `gupom` and `gupomi` aliases,stevenpitts,8,1015265872,6,1125401069,0,1125258955,2022-05-12T20:38:19Z,"@jmeridth Absolutely! https://github.com/ohmyzsh/ohmyzsh/pull/10261/commits/fae7e8c6cfa2d263ceb63a2a0897942faac7e343
This PR does seem to be getting ignored, unfortunately :disappointed: ",False,0,CONTRIBUTOR
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1125406184,feat(git): add `gupom` and `gupomi` aliases,jmeridth,8,1015265872,7,1125406184,0,1125401069,2022-05-12T20:45:09Z,@stevenpitts i feel ya. But the maintainers are active just short handed it seems. ,False,0,CONTRIBUTOR
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1136833080,feat(git): add `gupom` and `gupomi` aliases,carlosala,8,1015265872,8,1136833080,0,1125406184,2022-05-25T06:55:23Z,"There are tons of PRs adding aliases for git. That's why we take a long time until git aliases are merged.
By the way, this particular ones look useful using GitHub workflow, so are probably interesting to merge 👌🏻",False,0,MEMBER
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1137372681,feat(git): add `gupom` and `gupomi` aliases,jmeridth,8,1015265872,9,1137372681,0,1136833080,2022-05-25T14:50:21Z,Thank you @carlosala and @mcornella ,False,0,CONTRIBUTOR
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/10265,Add alias for git merge --signoff,MrSkwiggs,4,1016323920,1,1016323920,0,0,2021-10-05T13:21:29Z,"## Standards checklist:
- [x] The PR title is descriptive.
- [x] The PR doesn't replicate another PR which is already open.
- [x] I have read the contribution guide and followed all the instructions.
- [x] The code follows the code style guide detailed in the wiki.
- [x] The code is mine or it's from somewhere with an MIT-compatible license.
- [x] The code is efficient, to the best of my ability, and does not waste computer resources.
- [x] The code is stable and I have tested it myself, to the best of my abilities.

## Changes:
- Added a `gms` alias for `git merge --signoff`",True,0,NONE
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1032306957,Add alias for git merge --signoff,MrSkwiggs,4,1016323920,2,1032306957,0,1016323920,2022-02-08T07:50:27Z,"Hello, is there any update on when this PR could be merged?",False,0,NONE
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1407685606,Add alias for git merge --signoff,MrSkwiggs,4,1016323920,3,1407685606,0,1032306957,2023-01-29T14:57:44Z,@jmeridth Sorry somehow I completely missed your comment. Have done so (and updated the branch as it was _way_ out of date 🤓),False,0,NONE
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1734384322,Add alias for git merge --signoff,adamchainz,4,1016323920,4,1734384322,0,1407685606,2023-09-25T20:02:54Z,I think `--signoff` is too specific to include an alias for. The only project I’ve ever seen using it is Git itself. Also `git commit --signoff` would be much more common.,False,0,CONTRIBUTOR
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1734994022,Add alias for git merge --signoff,carlosala,4,1016323920,5,1734994022,0,1734384322,2023-09-26T07:37:38Z,"Nowadays with the most used git workflows (based on PRs, MRs, or the equivalent in your system) makes not much sense to signoff the commits, even more taking into account that is the merge commit.
Closing then, thanks for the contribution to everyone!",False,0,MEMBER
https://api.github.com/repos/SudhanPlayz/Discord-MusicBot/issues/483,Added Option To Change Bot's Presence From botconfig.js,TechGenius7777,11,1023471270,1,1023471270,0,0,2021-10-12T07:37:15Z,Added Option To Change Bot's Presence From botconfig.js,True,0,CONTRIBUTOR
https://api.github.com/repos/SudhanPlayz/Discord-MusicBot/issues/comments/940748846,Added Option To Change Bot's Presence From botconfig.js,DarrenOfficial,11,1023471270,2,940748846,0,1023471270,2021-10-12T07:40:58Z,Why should we merge this pull request?,False,0,COLLABORATOR
https://api.github.com/repos/SudhanPlayz/Discord-MusicBot/issues/comments/940749307,Added Option To Change Bot's Presence From botconfig.js,TechGenius7777,11,1023471270,3,940749307,0,940748846,2021-10-12T07:41:38Z,Umm why shouldn't?,False,0,CONTRIBUTOR
https://api.github.com/repos/SudhanPlayz/Discord-MusicBot/issues/comments/940749431,Added Option To Change Bot's Presence From botconfig.js,DarrenOfficial,11,1023471270,4,940749431,0,940749307,2021-10-12T07:41:49Z,idk lol,False,0,COLLABORATOR
https://api.github.com/repos/SudhanPlayz/Discord-MusicBot/issues/comments/940749537,Added Option To Change Bot's Presence From botconfig.js,TechGenius7777,11,1023471270,5,940749537,0,940749431,2021-10-12T07:41:58Z,Bruh,False,0,CONTRIBUTOR
https://api.github.com/repos/SudhanPlayz/Discord-MusicBot/issues/comments/940749889,Added Option To Change Bot's Presence From botconfig.js,TechGenius7777,11,1023471270,6,940749889,0,940749537,2021-10-12T07:42:33Z,Just merge it lol,False,0,CONTRIBUTOR
https://api.github.com/repos/SudhanPlayz/Discord-MusicBot/issues/comments/940750189,Added Option To Change Bot's Presence From botconfig.js,DarrenOfficial,11,1023471270,7,940750189,0,940749889,2021-10-12T07:42:58Z,"also, you should remove the comments on the `ready.js` cause welp there's one in the `botconfig.js` thingy",False,0,COLLABORATOR
https://api.github.com/repos/SudhanPlayz/Discord-MusicBot/issues/comments/940750414,Added Option To Change Bot's Presence From botconfig.js,TechGenius7777,11,1023471270,8,940750414,0,940750189,2021-10-12T07:43:18Z,Umm ok,False,0,CONTRIBUTOR
https://api.github.com/repos/SudhanPlayz/Discord-MusicBot/issues/comments/940751192,Added Option To Change Bot's Presence From botconfig.js,DarrenOfficial,11,1023471270,9,940751192,0,940750414,2021-10-12T07:44:28Z,eh good enough,False,0,COLLABORATOR
https://api.github.com/repos/SudhanPlayz/Discord-MusicBot/issues/comments/940751195,Added Option To Change Bot's Presence From botconfig.js,TechGenius7777,11,1023471270,10,940751195,0,940751192,2021-10-12T07:44:29Z,Done,False,0,CONTRIBUTOR
https://api.github.com/repos/SudhanPlayz/Discord-MusicBot/issues/comments/940751226,Added Option To Change Bot's Presence From botconfig.js,AryanTah2005,11,1023471270,11,940751226,0,940751195,2021-10-12T07:44:31Z,seems convenient to me,False,0,CONTRIBUTOR
https://api.github.com/repos/SudhanPlayz/Discord-MusicBot/issues/comments/940751386,Added Option To Change Bot's Presence From botconfig.js,TechGenius7777,11,1023471270,12,940751386,0,940751226,2021-10-12T07:44:47Z,Darren just do it,False,0,CONTRIBUTOR
https://api.github.com/repos/SudhanPlayz/Discord-MusicBot/issues/484,Responsive website,testbot-github,4,1024870091,1,1024870091,0,0,2021-10-13T07:06:04Z,"<!-- Use Discord for questions: https://discord.gg/bRCvFy9 -->

**Is your feature request related to a problem? Please describe.**
Yea, #475 

**Describe the ideal solution**
Make the website fully responsive

**Additional context**
You can make the website better. [DM MathisCool#8659 cuz I have ideas]

+ Add Realtime updater in dashboard [It will update in realtime]
",True,0,NONE
https://api.github.com/repos/SudhanPlayz/Discord-MusicBot/issues/comments/942118153,Responsive website,SudhanPlayz,4,1024870091,2,942118153,0,1024870091,2021-10-13T09:40:49Z,"It will be, just be patient ",False,0,OWNER
https://api.github.com/repos/SudhanPlayz/Discord-MusicBot/issues/comments/942120211,Responsive website,TechGenius7777,4,1024870091,3,942120211,0,942118153,2021-10-13T09:43:29Z,"Agreed, I am trying my best, It will eventually make it more responsive in upcoming updates. Just have some patience.

Regards,
Tech Genius",False,0,CONTRIBUTOR
https://api.github.com/repos/SudhanPlayz/Discord-MusicBot/issues/comments/944891430,Responsive website,testbot-github,4,1024870091,4,944891430,0,942120211,2021-10-16T10:04:11Z,👍,False,0,NONE
https://api.github.com/repos/SudhanPlayz/Discord-MusicBot/issues/comments/944891524,Responsive website,testbot-github,4,1024870091,5,944891524,0,944891430,2021-10-16T10:04:50Z,"> It will be, just be patient

@SudhanPlayz what about **Realtime updater in dashboard [It will update in realtime]**",False,0,NONE
https://api.github.com/repos/SudhanPlayz/Discord-MusicBot/issues/490,bump replit to nodejs16,DarrenOfficial,6,1025819576,1,1025819576,0,0,2021-10-14T00:48:37Z,"Because NodeJS 12 Is deprecated. 
",True,0,COLLABORATOR
https://api.github.com/repos/SudhanPlayz/Discord-MusicBot/issues/comments/942835145,bump replit to nodejs16,SudhanPlayz,6,1025819576,2,942835145,0,1025819576,2021-10-14T00:49:20Z,Plz don't do any commits to master ;-;,False,0,OWNER
https://api.github.com/repos/SudhanPlayz/Discord-MusicBot/issues/comments/942835355,bump replit to nodejs16,SudhanPlayz,6,1025819576,3,942835355,0,942835145,2021-10-14T00:50:00Z,If u commit in master it makes more conflicts when merging v5,False,0,OWNER
https://api.github.com/repos/SudhanPlayz/Discord-MusicBot/issues/comments/942836600,bump replit to nodejs16,DarrenOfficial,6,1025819576,4,942836600,0,942835355,2021-10-14T00:52:53Z,how so?,False,0,COLLABORATOR
https://api.github.com/repos/SudhanPlayz/Discord-MusicBot/issues/comments/942836992,bump replit to nodejs16,DarrenOfficial,6,1025819576,5,942836992,0,942836600,2021-10-14T00:54:07Z,"Wait? are we gonna merge v5 to master, or master to v5?",False,0,COLLABORATOR
https://api.github.com/repos/SudhanPlayz/Discord-MusicBot/issues/comments/942902785,bump replit to nodejs16,AryanTah2005,6,1025819576,6,942902785,0,942836992,2021-10-14T03:04:06Z,LOL,False,0,CONTRIBUTOR
https://api.github.com/repos/SudhanPlayz/Discord-MusicBot/issues/comments/942913446,bump replit to nodejs16,SudhanPlayz,6,1025819576,7,942913446,0,942902785,2021-10-14T03:28:51Z,v5 to master lol,False,0,OWNER
https://api.github.com/repos/SudhanPlayz/Discord-MusicBot/issues/492,MIssing Perm,SpaceLeft,3,1026223510,1,1026223510,0,0,2021-10-14T10:20:37Z,Add Missing Perm For commands embed,True,0,NONE
https://api.github.com/repos/SudhanPlayz/Discord-MusicBot/issues/comments/943379918,MIssing Perm,SudhanPlayz,3,1026223510,2,943379918,0,1026223510,2021-10-14T13:53:00Z,what do you mean?,False,0,OWNER
https://api.github.com/repos/SudhanPlayz/Discord-MusicBot/issues/comments/943392455,MIssing Perm,TechGenius7777,3,1026223510,3,943392455,0,943379918,2021-10-14T14:06:41Z,"> what do you mean?

I was also going to say that",False,0,CONTRIBUTOR
https://api.github.com/repos/SudhanPlayz/Discord-MusicBot/issues/comments/943436392,MIssing Perm,AryanTah2005,3,1026223510,4,943436392,0,943392455,2021-10-14T14:53:17Z,"> what do you mean?

I think he means to say to add a permission handler where you check the bot's permissions in every guild for each command, like if one guild removes SEND_MESSAGES perm, the bot should send `Missing Permission - SEND_MESSAGES`",False,0,CONTRIBUTOR
https://api.github.com/repos/JodaOrg/joda-time/issues/569,2021c time zone data base updates,JigarJoshi,3,1024092388,1,1024092388,0,0,2021-10-12T17:57:28Z,"please cover tzdata 2021c and release joda-time.

http://mm.icann.org/pipermail/tz-announce/2021-October.txt",True,0,NONE
https://api.github.com/repos/JodaOrg/joda-time/issues/comments/944696667,2021c time zone data base updates,JigarJoshi,3,1024092388,2,944696667,0,1024092388,2021-10-15T21:34:18Z,now can you please release up to 2021d,False,0,NONE
https://api.github.com/repos/JodaOrg/joda-time/issues/comments/952026366,2021c time zone data base updates,jodastephen,3,1024092388,3,952026366,0,944696667,2021-10-26T14:57:43Z,2021e (fork) has been merged in.,False,0,MEMBER
https://api.github.com/repos/JodaOrg/joda-time/issues/comments/952537754,2021c time zone data base updates,JigarJoshi,3,1024092388,4,952537754,0,952026366,2021-10-27T04:54:49Z,Thanks!,False,0,NONE
https://api.github.com/repos/JodaOrg/joda-time/issues/578,Refactoring,ullenius,4,1136449590,1,1136449590,0,0,2022-02-13T21:00:37Z,"Minor code refactoring:

* Partially removes commented out code.
* Add missing `@Override` annotations to method signatures.
* Replace `indexOf(String)` with the faster `indexOf(char)`
* Minor refactoring (remove empty statement and superfluous parentheses).",True,0,NONE
https://api.github.com/repos/JodaOrg/joda-time/issues/comments/1038430438,Refactoring,lgtm-com[bot],4,1136449590,2,1038430438,0,1136449590,2022-02-13T21:08:34Z,"This pull request **fixes 4 alerts** when merging cc388040d407dbe2b8c12129b82ff9667948ce46 into e9337f0c0955aed0e3d6866a35ba2db5992080e5 - [view on LGTM.com](https://lgtm.com/projects/g/JodaOrg/joda-time/rev/pr-c9a5d39f3da65b76adb68970509a9ce6b46a5f78)

**fixed alerts:**

* 4 for Spurious Javadoc @param tags",False,0,NONE
https://api.github.com/repos/JodaOrg/joda-time/issues/comments/1079931206,Refactoring,jodastephen,4,1136449590,3,1079931206,0,1038430438,2022-03-27T13:23:15Z,"I've performed the Override change myself. Of the others, I don't want to lose the commented out code. Up to you whether you want to rebase on top of my changes. Thanks",False,0,MEMBER
https://api.github.com/repos/JodaOrg/joda-time/issues/comments/1079970779,Refactoring,ullenius,4,1136449590,4,1079970779,0,1079931206,2022-03-27T17:02:30Z,"Thanks. I've rebased and kept the commented-out code as you wished.

The remaining commits are minuscule.",False,0,NONE
https://api.github.com/repos/JodaOrg/joda-time/issues/comments/1095427446,Refactoring,ullenius,4,1136449590,5,1095427446,0,1079970779,2022-04-11T18:48:02Z,Implemented by https://github.com/JodaOrg/joda-time/commit/75ab8caeaadb6ffcef7726c1bc38ed0ee3b0eb18.,False,0,NONE
https://api.github.com/repos/JodaOrg/joda-time/issues/587,DateTimeZone.getDefault() is prone to race condition,spand,6,1212326115,1,1212326115,0,0,2022-04-22T12:53:19Z,"### Key information
- Joda-Time version: Latest

I am mostly just documenting the problem here since the library is no longer in active development but obviously it would be nice to get fixed.

### Problem description
`DateTimeZone.getDefault()` is specified to check in order:
1. `user.timezone` property
2. `java.util.TimeZone.getDefault()`
3. Use UTC

This is problematic because the `user.timezone` property is not fixed but can change as `java.util.TimeZone.getDefault()` is specified to set the `user.timezone` if it is missing. If `java.util.TimeZone.setDefault()` is called prior to `getDefault()` then it will never be set. In effect this means that `user.timezone` is set (quite unintuitively imo) on two conditions:
1. Provided by the user as -Duser.timezone
2. or picked up from the environment.

I believe and assume that the `DateTimeZone.getDefault()` checks `user.timezone` first because it is assumed to only be set in case 1.

### The Problem

Ok. So what is the problem? You might say
> Just call `java.util.TimeZone.setDefault()`"" and at startup and Joda will use that

That is what we do currently. However, it seems that is not enough. We initially discovered this when adding the NewRelic agent to our production system but have since discovered that when running the jvm even just in debug mode in IDEA then `user.timezone` is set before even before the main method starts executing. In effect having jodatime getting stuck on the environment timezone and never checking `java.util.TimeZone.getDefault()`. I can only assume that the agents has a codepath that triggers `java.util.TimeZone.getDefault()` on startup.

### Proposed solution
Stop checking the user.timezone property. Instead use the following algorithm
1. Check a `org.joda.time.defaulttimezone` property if one really wants to override jodatimes default timezone from the commandline. Technically this is not needed for us but I assume the `user.timezone` check is present to override any prior calls to `java.util.TimeZone.setDefault()`.
2. `java.util.TimeZone.getDefault()` which will then in turn check user.timezone if needed.
3. Use UTC 

This should provide a stable algorithm free of races.

### Test case (In Kotlin. It doesnt happen in plain java)

```kotlin
import java.util.*
import org.joda.time.DateTimeZone

fun main() {
    System.out.println(""user.timezone "" + System.getProperty(""user.timezone""))
    System.out.println(""java.util.TimeZone.getDefault() = "" + TimeZone.getDefault().id)
    System.out.println(""user.timezone "" + System.getProperty(""user.timezone""))
}
```

When run nomally:
```
user.timezone null
java.util.TimeZone.getDefault() = Europe/Paris
user.timezone Europe/Paris

Process finished with exit code 0
```

In debug:
```
Connected to the target VM, address: '127.0.0.1:57990', transport: 'socket'
user.timezone Europe/Paris
java.util.TimeZone.getDefault() = Europe/Paris
user.timezone Europe/Paris
Disconnected from the target VM, address: '127.0.0.1:57990', transport: 'socket'

Process finished with exit code 0
```
",True,0,NONE
https://api.github.com/repos/JodaOrg/joda-time/issues/comments/1127065666,DateTimeZone.getDefault() is prone to race condition,jodastephen,6,1212326115,2,1127065666,0,1212326115,2022-05-15T22:29:03Z,"Thanks for the detailed issue. I've made the change, although there is some risk of breaking users, I think that risk is small.",False,0,MEMBER
https://api.github.com/repos/JodaOrg/joda-time/issues/comments/1227001153,DateTimeZone.getDefault() is prone to race condition,jahar-tyagi,6,1212326115,3,1227001153,0,1127065666,2022-08-25T09:15:55Z,"Does it have any effect on application code? Though it is mentioned in Release note as:  _""In most cases this change will have no effect on application code, as 'user.timezone' will be picked up by 'TimeZone.getDefault()' instead. If you specifically need to stop Joda-Time calling 'TimeZone.getDefault()' then you will need to change to use the new system property 'org.joda.time.DateTimeZone.Timezone'""_

But this is little unclear to me.",False,0,NONE
https://api.github.com/repos/JodaOrg/joda-time/issues/comments/1227035570,DateTimeZone.getDefault() is prone to race condition,jodastephen,6,1212326115,4,1227035570,0,1227001153,2022-08-25T09:48:12Z,"Unless your application is very special/weird, just do nothing and everything will continue to work.

If your application is weird, and want to set the Joda-Time zone specifically, use `org.joda.time.DateTimeZone.Timezone'` on the command line instead of `user.timezone`",False,0,MEMBER
https://api.github.com/repos/JodaOrg/joda-time/issues/comments/1227045276,DateTimeZone.getDefault() is prone to race condition,jahar-tyagi,6,1212326115,5,1227045276,0,1227035570,2022-08-25T09:57:47Z,Thanks for the clarification @jodastephen ,False,0,NONE
https://api.github.com/repos/JodaOrg/joda-time/issues/comments/1249005944,DateTimeZone.getDefault() is prone to race condition,jahar-tyagi,6,1212326115,6,1249005944,0,1227045276,2022-09-16T07:15:36Z,Is it possible that Joda uses the timezone information (tzdata) picked up from the environment or JRE directly using -Duser.timezone or any other config. So that every time we don't have to update tzDB in Joda?,False,0,NONE
https://api.github.com/repos/JodaOrg/joda-time/issues/comments/1264728939,DateTimeZone.getDefault() is prone to race condition,jodastephen,6,1212326115,7,1264728939,0,1249005944,2022-10-02T20:41:12Z,That is not an option available in Joda-Time,False,0,MEMBER
https://api.github.com/repos/JodaOrg/joda-time/issues/642,Add slovak translation to messages_sk.properties,dombalaz,5,1392932643,1,1392932643,0,0,2022-09-30T19:53:51Z,This PR adds slovak translation as described in https://github.com/lichess-org/lila/issues/11634 and https://github.com/lichess-org/lila/issues/11623,True,0,CONTRIBUTOR
https://api.github.com/repos/JodaOrg/joda-time/issues/comments/1263970234,Add slovak translation to messages_sk.properties,hb20007,5,1392932643,2,1263970234,0,1392932643,2022-09-30T20:02:13Z,"@dombalaz I see that your file includes non-ASCII characters like ý. All of the other files in this repository use Unicode encoding for such characters. However, when I downloaded the file I could see that the encoding was UTF-8 so perhaps it is okay. Maybe @jodastephen can comment on this.",False,0,CONTRIBUTOR
https://api.github.com/repos/JodaOrg/joda-time/issues/comments/1263985297,Add slovak translation to messages_sk.properties,dombalaz,5,1392932643,3,1263985297,0,1263970234,2022-09-30T20:19:02Z,"> 

didn't realize that, I made changes so it is aligned with other translations",False,0,CONTRIBUTOR
https://api.github.com/repos/JodaOrg/joda-time/issues/comments/1264253078,Add slovak translation to messages_sk.properties,orim15,5,1392932643,4,1264253078,0,1263985297,2022-10-01T05:43:32Z,I wanted to start working on Slovak translation but then noticed this thread. So I take it there is no need anymore?,False,0,NONE
https://api.github.com/repos/JodaOrg/joda-time/issues/comments/1264262061,Add slovak translation to messages_sk.properties,hb20007,5,1392932643,5,1264262061,0,1264253078,2022-10-01T06:22:03Z,"@orim15 Yes, the Slovak translation is already done :)",False,0,CONTRIBUTOR
https://api.github.com/repos/JodaOrg/joda-time/issues/comments/1264718844,Add slovak translation to messages_sk.properties,jodastephen,5,1392932643,6,1264718844,0,1264262061,2022-10-02T19:46:43Z,Thanks,False,0,MEMBER
https://api.github.com/repos/microsoft/winget-cli/issues/1670,Different package upgrade issues,MikronT,7,1044081450,1,1044081450,0,0,2021-11-03T20:26:15Z,"### Brief description of your issue

3 major issues I faced:

- WinGet can't find files for the upgradable packages
- WinGet detects upgrades for the packages already upgraded
- Can't finish upgrading some of the packages properly

### Steps to reproduce

1. Install any of the packages listed below:

    - Visual Studio Community 2019 16.11.4
    - Resource Hacker (version doesn't matter)
    - AOMEI Partition Assistant (version doesn't matter)
    - Viber 16.3.0.5
    - Java 8 8.0.3010.9
    - Oracle VM VirtualBox 6.1.26
    - PowerToys (Preview) 0.47.0

1. Let these packages upgrade themselves:

    - PowerToys (Preview) (can be also upgraded manually)
    - Oracle VM VirtualBox (can be also upgraded manually)
    - Viber (upgrades itself automatically on start)

1. Try to upgrade them all to the latest version using

    With all the packages listed above, the `upgrade` command syntax doesn't matter

    ```batch
    winget upgrade {packageName}
    winget upgrade {packageId}
    winget upgrade --id {packageId}
    ```

### Expected behavior

- Upgrade packages that can be upgraded
- Finish all the upgrades successfully
- Don't show upgrades for the latest versions of packages

### Actual behavior

WinGet detects packages to upgrade:

```
D:\Computer\Desktop>winget upgrade
Name                         Id                                    Version    Available   Source
------------------------------------------------------------------------------------------------
Visual Studio Community 2019 Microsoft.VisualStudio.2019.Community 16.11.4    16.11.5     winget
Resource Hacker              AngusJohnson.ResourceHacker           Unknown    5.1.8       winget
AOMEI Partition Assistant    AOMEI.PartitionAssistant              Unknown    9.5.0       winget
Viber                        Viber.Viber                           16.3.0.5   16.4.0.7    winget
Java 8                       Oracle.JavaRuntimeEnvironment         8.0.3010.9 8.0.3110.11 winget
Oracle VM VirtualBox         Oracle.VirtualBox                     6.1.26     6.1.28      winget
PowerToys (Preview)          Microsoft.PowerToys                   0.47.0     0.49.1      winget
7 upgrades available.
```

And then produces different types of errors trying to perform upgrades:

1. **Visual Studio Community 2019**

    Can find the upgrade but can't finish the installation.

    ```
    D:\Computer\Desktop>winget upgrade Microsoft.VisualStudio.2019.Community
    Found Visual Studio Community 2019 [Microsoft.VisualStudio.2019.Community] Version 16.11.5
    This application is licensed to you by its owner.
    Microsoft is not responsible for, nor does it grant any licenses to, third-party packages.
    Downloading https://download.visualstudio.microsoft.com/download/pr/5a50b8ac-2c22-47f1-ba60-70d4257a78fa/d662d2f23b4b523f30e24cbd7e5e651c7c6a712f21f48e032f942dc678f08beb/vs_Community.exe
      ██████████████████████████████  1.40 MB / 1.40 MB
    Successfully verified installer hash
    Starting package install...
    Installer failed with exit code: 1
    ```

    A small dialog appears for some seconds, then disappears, and produces error level 1.

    ![image](https://user-images.githubusercontent.com/45333177/140183628-fd84d856-cac5-4544-947f-f11328d334a9.png)

    Log:

    ```
    2021-11-03 21:58:08.433 [CORE] Settings loaded from settings.json
    2021-11-03 21:58:08.433 [CORE] WinGet, version [1.1.12701], activity [{E94BC313-1D82-4025-AA44-4B6A021C5389}]
    2021-11-03 21:58:08.433 [CORE] OS: Windows.Desktop v10.0.19043.1320
    2021-11-03 21:58:08.433 [CORE] Command line Args: winget  upgrade Microsoft.VisualStudio.2019.Community
    2021-11-03 21:58:08.433 [CORE] Package: Microsoft.DesktopAppInstaller v1.16.12701.0
    2021-11-03 21:58:08.433 [CORE] IsCOMCall:0; Caller: winget-cli
    2021-11-03 21:58:08.451 [CLI ] WinGet invoked with arguments: 'upgrade' 'Microsoft.VisualStudio.2019.Community'
    2021-11-03 21:58:08.451 [CLI ] Found subcommand: upgrade
    2021-11-03 21:58:08.451 [CLI ] Leaf command to execute: root:upgrade
    2021-11-03 21:58:08.454 [CLI ] Executing command: upgrade
    2021-11-03 21:58:08.454 [REPO] GetCurrentSourceRefs: Source named 'microsoft.builtin.desktop.frameworks' from origin Default is a tombstone and is dropped.
    2021-11-03 21:58:08.454 [REPO] Default source requested, multiple sources available, creating aggregated source.
    2021-11-03 21:58:08.454 [REPO] Adding to aggregated source: msstore
    2021-11-03 21:58:08.454 [REPO] Source past auto update time [5 mins]; it has been at least 14 mins
    2021-11-03 21:58:08.455 [REPO] Sending http GET request to: https://storeedgefd.dsx.mp.microsoft.com/v9.0/information
    2021-11-03 21:58:08.927 [REPO] Response status: 200
    2021-11-03 21:58:08.927 [REPO] Adding to aggregated source: winget
    2021-11-03 21:58:08.927 [REPO] Source past auto update time [5 mins]; it has been at least 14 mins
    2021-11-03 21:58:09.449 [CORE] Examining extension: PFN = Microsoft.Winget.Source_8wekyb3d8bbwe, ID = IndexDB
    2021-11-03 21:58:09.449 [CORE] Found matching extension.
    2021-11-03 21:58:09.455 [REPO] Remote source data was not newer than existing, no update needed
    2021-11-03 21:58:09.466 [CORE] Examining extension: PFN = Microsoft.Winget.Source_8wekyb3d8bbwe, ID = IndexDB
    2021-11-03 21:58:09.466 [CORE] Found matching extension.
    2021-11-03 21:58:09.541 [REPO] Opening SQLite Index for ImmutableRead at 'C:\Program Files\WindowsApps\Microsoft.Winget.Source_2021.1103.2035.97_neutral__8wekyb3d8bbwe\Public\index.db'
    2021-11-03 21:58:09.541 [SQL ] Opening SQLite connection: 'file:/C:/Program Files/WindowsApps/Microsoft.Winget.Source_2021.1103.2035.97_neutral__8wekyb3d8bbwe/Public/index.db?immutable=1' [1, 40]
    2021-11-03 21:58:09.542 [REPO] Opened SQLite Index with version [1.3], last write [2021-11-03 21:35:28.000]
    2021-11-03 21:58:09.837 [REPO] Creating PredefinedInstalledSource with filter [None]
    2021-11-03 21:58:09.837 [REPO] Creating new SQLite Index [4294967295.4294967295] at ':memory:'
    2021-11-03 21:58:09.837 [SQL ] Opening SQLite connection: ':memory:' [6, 0]
    2021-11-03 21:58:09.883 [REPO] Examining ARP entries for Machine | X64
    2021-11-03 21:58:09.930 [REPO] Examining ARP entries for Machine | X86
    2021-11-03 21:58:09.998 [REPO] Examining ARP entries for User | X64
    2021-11-03 21:58:10.473 [CLI ] Found one app. App id: Microsoft.VisualStudio.2019.Community App name: Visual Studio Community 2019
    2021-11-03 21:58:10.476 [REPO] Downloading manifest
    2021-11-03 21:58:10.476 [CORE] WinINet downloading from url: https://winget.azureedge.net/cache/manifests/m/Microsoft/VisualStudio/2019/Community/16.11.5/eac8-Microsoft.VisualStudio.2019.Community.yaml
    2021-11-03 21:58:11.099 [CORE] Download hash: 0aaae3d901d2841dac2b3c5145f0fe855a4950d819615fce2acf2e83543b8034
    2021-11-03 21:58:11.099 [CORE] Download completed.
    2021-11-03 21:58:11.100 [CLI ] Starting installer selection.
    2021-11-03 21:58:11.100 [CLI ] Completed installer selection.
    2021-11-03 21:58:11.111 [CLI ] Generated temp download path: C:\Users\DARKLI~1\AppData\Local\Temp\WinGet\Microsoft.VisualStudio.2019.Community.16.11.5
    2021-11-03 21:58:11.111 [CORE] Downloading to path: C:\Users\DARKLI~1\AppData\Local\Temp\WinGet\Microsoft.VisualStudio.2019.Community.16.11.5
    2021-11-03 21:58:11.111 [CORE] DeliveryOptimization downloading from url: https://download.visualstudio.microsoft.com/download/pr/5a50b8ac-2c22-47f1-ba60-70d4257a78fa/d662d2f23b4b523f30e24cbd7e5e651c7c6a712f21f48e032f942dc678f08beb/vs_Community.exe
    2021-11-03 21:58:12.123 [CORE] Download completed.
    2021-11-03 21:58:12.262 [CORE] Started applying motw to C:\Users\DARKLI~1\AppData\Local\Temp\WinGet\Microsoft.VisualStudio.2019.Community.16.11.5 with zone: 3
    2021-11-03 21:58:12.265 [CORE] Finished applying motw
    2021-11-03 21:58:12.265 [CLI ] Installer hash verified
    2021-11-03 21:58:12.266 [CORE] Started applying motw to C:\Users\DARKLI~1\AppData\Local\Temp\WinGet\Microsoft.VisualStudio.2019.Community.16.11.5 with zone: 2
    2021-11-03 21:58:12.267 [CORE] Finished applying motw
    2021-11-03 21:58:12.267 [REPO] Creating PredefinedInstalledSource with filter [ARP]
    2021-11-03 21:58:12.267 [REPO] Creating new SQLite Index [4294967295.4294967295] at ':memory:'
    2021-11-03 21:58:12.267 [SQL ] Opening SQLite connection: ':memory:' [6, 0]
    2021-11-03 21:58:12.313 [REPO] Examining ARP entries for Machine | X64
    2021-11-03 21:58:12.354 [REPO] Examining ARP entries for Machine | X86
    2021-11-03 21:58:12.419 [REPO] Examining ARP entries for User | X64
    2021-11-03 21:58:12.690 [CLI ] Installer args: --passive --wait
    2021-11-03 21:58:12.691 [CLI ] Successfully renamed downloaded installer. Path: C:\Users\DARKLI~1\AppData\Local\Temp\WinGet\Microsoft.VisualStudio.2019.Community.16.11.5.exe
    2021-11-03 21:58:12.691 [CLI ] Starting: 'C:\Users\DARKLI~1\AppData\Local\Temp\WinGet\Microsoft.VisualStudio.2019.Community.16.11.5.exe' with arguments '--passive --wait'
    2021-11-03 21:58:26.563 [CLI ] ShellExecute installer failed: 1
    2021-11-03 21:58:26.563 [CLI ] Terminating context: 0x8a150006 at D:\a\_work\1\s\external\pkg\src\AppInstallerCLICore\Workflows\InstallFlow.cpp:23b
    ```

1. **Resource Hacker** & **AOMEI Partition Assistant**

    WinGet upgrades them successfully but the version remains `Unknown` so these packages can be upgraded again and again - a serious issue for automation.

    ```
    D:\Computer\Desktop>winget upgrade AngusJohnson.ResourceHacker
    Found Resource Hacker [AngusJohnson.ResourceHacker] Version 5.1.8
    This application is licensed to you by its owner.
    Microsoft is not responsible for, nor does it grant any licenses to, third-party packages.
    Downloading http://www.angusj.com/resourcehacker/reshacker_setup.exe
      ██████████████████████████████  3.98 MB / 3.98 MB
    Successfully verified installer hash
    Starting package install...
    Successfully installed

    D:\Computer\Desktop>winget upgrade
    Name                         Id                                    Version    Available   Source
    ------------------------------------------------------------------------------------------------
    ...
    Resource Hacker              AngusJohnson.ResourceHacker           Unknown    5.1.8       winget
    AOMEI Partition Assistant    AOMEI.PartitionAssistant              Unknown    9.5.0       winget
    ...
    ```

1. **Viber** & **Oracle VM VirtualBox** & **PowerToys (Preview)**

    Packages are already upgraded to the latest versions. However, WinGet finds their updates but can't actually upgrade them. Some of these packages show up as multiple versions installed but specifying their ids resolves the issue with determining the right one.

    **VirtualBox**

    ```
    D:\Computer\Desktop>winget upgrade Viber.Viber
    No applicable update found.
    
    D:\Computer\Desktop>winget upgrade Viber
    No applicable update found.
    ```

    Log:

    ```
    2021-11-03 21:47:32.559 [CORE] Settings loaded from settings.json
    2021-11-03 21:47:32.559 [CORE] WinGet, version [1.1.12701], activity [{6C62D8D8-02BB-49D4-A01F-A1D433437167}]
    2021-11-03 21:47:32.560 [CORE] OS: Windows.Desktop v10.0.19043.1320
    2021-11-03 21:47:32.560 [CORE] Command line Args: winget  upgrade Viber.Viber
    2021-11-03 21:47:32.560 [CORE] Package: Microsoft.DesktopAppInstaller v1.16.12701.0
    2021-11-03 21:47:32.560 [CORE] IsCOMCall:0; Caller: winget-cli
    2021-11-03 21:47:32.577 [CLI ] WinGet invoked with arguments: 'upgrade' 'Viber.Viber'
    2021-11-03 21:47:32.577 [CLI ] Found subcommand: upgrade
    2021-11-03 21:47:32.577 [CLI ] Leaf command to execute: root:upgrade
    2021-11-03 21:47:32.580 [CLI ] Executing command: upgrade
    2021-11-03 21:47:32.581 [REPO] GetCurrentSourceRefs: Source named 'microsoft.builtin.desktop.frameworks' from origin Default is a tombstone and is dropped.
    2021-11-03 21:47:32.581 [REPO] Default source requested, multiple sources available, creating aggregated source.
    2021-11-03 21:47:32.581 [REPO] Adding to aggregated source: msstore
    2021-11-03 21:47:32.581 [REPO] Sending http GET request to: https://storeedgefd.dsx.mp.microsoft.com/v9.0/information
    2021-11-03 21:47:32.913 [REPO] Response status: 200
    2021-11-03 21:47:32.913 [REPO] Adding to aggregated source: winget
    2021-11-03 21:47:32.931 [CORE] Examining extension: PFN = Microsoft.Winget.Source_8wekyb3d8bbwe, ID = IndexDB
    2021-11-03 21:47:32.931 [CORE] Found matching extension.
    2021-11-03 21:47:32.962 [REPO] Opening SQLite Index for ImmutableRead at 'C:\Program Files\WindowsApps\Microsoft.Winget.Source_2021.1103.2035.97_neutral__8wekyb3d8bbwe\Public\index.db'
    2021-11-03 21:47:32.962 [SQL ] Opening SQLite connection: 'file:/C:/Program Files/WindowsApps/Microsoft.Winget.Source_2021.1103.2035.97_neutral__8wekyb3d8bbwe/Public/index.db?immutable=1' [1, 40]
    2021-11-03 21:47:32.964 [REPO] Opened SQLite Index with version [1.3], last write [2021-11-03 21:35:28.000]
    2021-11-03 21:47:33.213 [REPO] Creating PredefinedInstalledSource with filter [None]
    2021-11-03 21:47:33.213 [REPO] Creating new SQLite Index [4294967295.4294967295] at ':memory:'
    2021-11-03 21:47:33.213 [SQL ] Opening SQLite connection: ':memory:' [6, 0]
    2021-11-03 21:47:33.257 [REPO] Examining ARP entries for Machine | X64
    2021-11-03 21:47:33.299 [REPO] Examining ARP entries for Machine | X86
    2021-11-03 21:47:33.364 [REPO] Examining ARP entries for User | X64
    2021-11-03 21:47:33.847 [CLI ] Found one app. App id: Viber.Viber App name: Viber
    2021-11-03 21:47:33.849 [REPO] Downloading manifest
    2021-11-03 21:47:33.849 [CORE] WinINet downloading from url: https://winget.azureedge.net/cache/manifests/v/Viber/Viber/16.4.0.7/d8b7-Viber.Viber.yaml
    2021-11-03 21:47:34.482 [CORE] Download hash: 7776dbf2b29ed39335b2e3d26f61d803ef5b0958302638a407958a2a3c79d2e5
    2021-11-03 21:47:34.482 [CORE] Download completed.
    2021-11-03 21:47:34.483 [CLI ] Starting installer selection.
    2021-11-03 21:47:34.483 [CLI ] Installer [X86,Msi,User,en-US] not applicable: Installer scope does not matched currently installed scope: User != Machine
    2021-11-03 21:47:34.483 [CLI ] Installer [X86,Exe,User,en-US] not applicable: Installer scope does not matched currently installed scope: User != Machine
    2021-11-03 21:47:34.491 [CLI ] Terminating context: 0x8a15002b at D:\a\_work\1\s\external\pkg\src\AppInstallerCLICore\Workflows\UpdateFlow.cpp:46
    ```

    **VirtualBox**

    ```
    D:\Computer\Desktop>winget upgrade Oracle.VirtualBox
    Multiple installed packages found matching input criteria. Please refine the input.
    Name                        Id
    ------------------------------------------------------------------
    Oracle VM VirtualBox        Oracle.VirtualBox
    Oracle VM VirtualBox 6.1.28 {73A88925-78D8-43C3-9F9F-24D4E5DFCD75}
    
    D:\Computer\Desktop>winget upgrade --id {73A88925-78D8-43C3-9F9F-24D4E5DFCD75}
    No applicable update found.
    
    D:\Computer\Desktop>winget upgrade --id ""{73A88925-78D8-43C3-9F9F-24D4E5DFCD75}""
    No applicable update found.
    
    D:\Computer\Desktop>winget upgrade VirtualBox
    Multiple installed packages found matching input criteria. Please refine the input.
    Name                        Id
    ------------------------------------------------------------------
    Oracle VM VirtualBox        Oracle.VirtualBox
    Oracle VM VirtualBox 6.1.28 {73A88925-78D8-43C3-9F9F-24D4E5DFCD75}
    ```

    **PowerToys**

    ```
    D:\Computer\Desktop>winget upgrade Microsoft.PowerToys
    Multiple installed packages found matching input criteria. Please refine the input.
    Name                Id
    ----------------------------------------------------------
    PowerToys (Preview) Microsoft.PowerToys
    PowerToys (Preview) {E42CA5D6-208C-438D-8751-375F708C104D}
    
    D:\Computer\Desktop>winget upgrade --id {E42CA5D6-208C-438D-8751-375F708C104D}
    No applicable update found.
    ```

1. **Oracle.JavaRuntimeEnvironment**

    JRE can be upgraded, JRE's update checker detects a new version available but WinGet can't start an upgrade process.

    ```
    D:\Computer\Desktop>winget upgrade Oracle.JavaRuntimeEnvironment
    No applicable update found.
    ```

### Environment

```shell
Windows Package Manager v1.1.12701
Copyright (c) Microsoft Corporation. All rights reserved.

Windows: Windows.Desktop v10.0.19043.1320
Package: Microsoft.DesktopAppInstaller v1.16.12701.0


Windows Terminal Preview -> Command Prompt (cmd)
Running as Admin has no impact
```
",True,0,NONE
https://api.github.com/repos/microsoft/winget-cli/issues/comments/961054742,Different package upgrade issues,denelon,7,1044081450,2,961054742,0,1044081450,2021-11-04T14:29:17Z,"@MikronT, Thank you for the detailed report. I believe most of these are duplicates. It's best to report a single problem with a single issue. That way we can focus on a single specific problem and resolve it. We tend to prioritize by sorting issues by the number of 👍. Duplicate issues artificially lower the priority by splitting the votes.

1. Visual Studio Community 2019 may be a new report, but the problem appears to be with the installer. I believe we've seen this error before, but the logs needed would be from the install of Visual Studio.
2. Resource Hacker & AOMEI Partition Assistant don't report the version in Windows Apps & Features, which is why the version is reported as Unknown. In this case, the publisher would need to report a version so the Windows Package Manager could determine if an upgrade is available. 
2. Viber appears to be a mobile application and not Virtual Box. The failure to match might be addressed with changes to the manifest you could submit a ""Help Wanted"" request for the package at https://github.com/microsoft/winget-pkgs
3. VirtualBox is another issue in the installer, and is tracked at https://github.com/microsoft/winget-pkgs
4. We do know that PowerToys is an MSI installer shipped inside of an EXE installer. We have improvements in the 1.1 manifest schema that are in progress to support upgrades when installer types don't match.

* https://github.com/microsoft/winget-pkgs/issues/15504
* #752 
* #1242

I will keep this bug open to see if the community can help with Visual Studio Community 2019, and I'll mark this issue as area external since the majority of the issues are related to installers.

",False,0,CONTRIBUTOR
https://api.github.com/repos/microsoft/winget-cli/issues/comments/961414508,Different package upgrade issues,Masamune3210,7,1044081450,3,961414508,0,961054742,2021-11-04T20:56:47Z,Maybe as a solution to packages not reporting their versions a entry to the manifest could be added to contain the version number? That way when the manifest is created the version could be pulled from the manifest if it's missing. Just throwing ideas out,False,0,NONE
https://api.github.com/repos/microsoft/winget-cli/issues/comments/961487026,Different package upgrade issues,denelon,7,1044081450,4,961487026,0,961414508,2021-11-04T22:41:14Z,We depend on Apps & Features to tell us what is installed on the machine. We don't have another trustworthy mechanism. A user might have done anything between the last event we recorded and when they try to perform an upgrade. We also can't assume the user had the previous latest version installed.,False,0,CONTRIBUTOR
https://api.github.com/repos/microsoft/winget-cli/issues/comments/961982670,Different package upgrade issues,jedieaston,7,1044081450,5,961982670,0,961487026,2021-11-05T15:17:34Z,"Turns out Visual Studio requires a [special command line argument](https://docs.microsoft.com/en-us/visualstudio/install/update-a-network-installation-of-visual-studio?view=vs-2019#deploy-an-update-to-client-machines) to upgrade. 

PRs are open to resolve this for Community (https://github.com/microsoft/winget-pkgs/pull/34094) and Enterprise, I'll try to push them for Professional too today. This should resolve that part of your issue :)",False,0,CONTRIBUTOR
https://api.github.com/repos/microsoft/winget-cli/issues/comments/962262072,Different package upgrade issues,jedieaston,7,1044081450,6,962262072,0,961982670,2021-11-05T22:41:01Z,Looks like all of the PRs have merged. You should be able to upgrade Visual Studio. ,False,0,CONTRIBUTOR
https://api.github.com/repos/microsoft/winget-cli/issues/comments/962432160,Different package upgrade issues,MikronT,7,1044081450,7,962432160,0,962262072,2021-11-06T10:40:36Z,"Thank you all for your replies!

It looks like the bug with upgrading Visual Studio is fixed now. As you stated above, the other problems are outside your area of influence, so this issue has no more purpose to be opened.",False,0,NONE
https://api.github.com/repos/microsoft/winget-cli/issues/comments/1738605964,Different package upgrade issues,arashkarimpourg,7,1044081450,8,1738605964,0,962432160,2023-09-28T07:14:45Z,"I have the same problem with ""AngusJohnson.ResourceHacker""'s wrong version numbers in winget. Is there a workaround for now so I won't see its related errors? Asking since the latest version of this app was back in 2019 and I don't think the developer is even interested in fixing anything related to the app meaning if someone else doesn't fix the issue, most likely it will remain an issue until forever.",False,0,NONE
https://api.github.com/repos/microsoft/winget-cli/issues/1675,winget install OBSProject.OBSStudio = Installer failed with exit code: 6,dxnnie,9,1044777742,1,1044777742,0,0,2021-11-04T13:44:06Z,"### Brief description of your issue

`winget install OBSProject.OBSStudio`
Found OBS Studio [OBSProject.OBSStudio] Version 27.1.3
This application is licensed to you by its owner.
Microsoft is not responsible for, nor does it grant any licences to, third-party packages.
Downloading https://github.com/obsproject/obs-studio/releases/download/27.1.3/OBS-Studio-27.1.3-Full-Installer-x64.exe
  ██████████████████████████████  86.4 MB / 86.4 MB
Successfully verified installer hash
Starting package install...
**Installer failed with exit code: 6**

### Steps to reproduce

Try to install OBS Studio via Winget .

### Expected behavior

Expected normal installation.

### Actual behavior

Installer failed with exit code: 6

### Environment

```shell
winget --info
Windows Package Manager v1.1.12663
Copyright (c) Microsoft Corporation. All rights reserved.

Windows: Windows.Desktop v10.0.22000.282
Package: Microsoft.DesktopAppInstaller v1.16.12663.0

Logs: %LOCALAPPDATA%\Packages\Microsoft.DesktopAppInstaller_8wekyb3d8bbwe\LocalState\DiagOutputDir

Links
---------------------------------------------------------------------------
Privacy Statement   https://aka.ms/winget-privacy
Licence Agreement   https://aka.ms/winget-license
Third Party Notices https://aka.ms/winget-3rdPartyNotice
Homepage            https://aka.ms/winget
Windows Store Terms https://www.microsoft.com/en-us/storedocs/terms-of-sale
```
",True,0,NONE
https://api.github.com/repos/microsoft/winget-cli/issues/comments/961072082,winget install OBSProject.OBSStudio = Installer failed with exit code: 6,denelon,9,1044777742,2,961072082,0,1044777742,2021-11-04T14:37:36Z,"Exit code 6 is coming from the OBS Studio installer. The installer is an EXE (specifically nullsoft), so the error codes aren't standardized as they are in an MSI or a MSIX package. I did a quick search, and didn't see anything telling me what their installer error code 6 refers to. We have added a section on Expected Return Codes in the new 1.1 manifest schema so the error can be mapped to a friendly message for users, but we don't know what the specific error is in this case.",False,0,CONTRIBUTOR
https://api.github.com/repos/microsoft/winget-cli/issues/comments/961152972,winget install OBSProject.OBSStudio = Installer failed with exit code: 6,jedieaston,9,1044777742,3,961152972,0,961072082,2021-11-04T15:26:00Z,"I can't replicate this. Can you try restarting your computer and running it again? I wonder if it's something silly, like a file being locked.",False,0,CONTRIBUTOR
https://api.github.com/repos/microsoft/winget-cli/issues/comments/961196426,winget install OBSProject.OBSStudio = Installer failed with exit code: 6,dxnnie,9,1044777742,4,961196426,0,961152972,2021-11-04T16:14:16Z,"> Exit code 6 is coming from the OBS Studio installer. The installer is an EXE (specifically nullsoft), so the error codes aren't standardized as they are in an MSI or a MSIX package. I did a quick search, and didn't see anything telling me what their installer error code 6 refers to. We have added a section on Expected Return Codes in the new 1.1 manifest schema so the error can be mapped to a friendly message for users, but we don't know what the specific error is in this case.

Thanks for the response! I believe it was indeed a file lock error as @jedieaston mentioned. 

> I can't replicate this. Can you try restarting your computer and running it again? I wonder if it's something silly, like a file being locked.

Thanks for your suggestion, i've rebooted and instalation proceed as usuall.

` winget install OBSProject.OBSStudio`
Found OBS Studio [OBSProject.OBSStudio] Version 27.1.3
This application is licensed to you by its owner.
Microsoft is not responsible for, nor does it grant any licences to, third-party packages.
Downloading https://github.com/obsproject/obs-studio/releases/download/27.1.3/OBS-Studio-27.1.3-Full-Installer-x64.exe
  ██████████████████████████████  86.4 MB / 86.4 MB
Successfully verified installer hash
Starting package install...
Successfully installed",False,0,NONE
https://api.github.com/repos/microsoft/winget-cli/issues/comments/1458746250,winget install OBSProject.OBSStudio = Installer failed with exit code: 6,cjwijtmans,9,1044777742,5,1458746250,0,961196426,2023-03-07T19:52:02Z,i get the same error. i never ran obs studio so idoubt a file is locked.,False,0,NONE
https://api.github.com/repos/microsoft/winget-cli/issues/comments/1551686537,winget install OBSProject.OBSStudio = Installer failed with exit code: 6,No0Vad,9,1044777742,6,1551686537,0,1458746250,2023-05-17T16:09:03Z,"@cjwijtmans Same here just now. But if you run the .exe file winget downloads you'll see what file is causing the error.
In my case the installer did not like that NZXT CAM running 🤷",False,0,NONE
https://api.github.com/repos/microsoft/winget-cli/issues/comments/1582353528,winget install OBSProject.OBSStudio = Installer failed with exit code: 6,AdonNeet,9,1044777742,7,1582353528,0,1551686537,2023-06-08T10:43:39Z,"i have same problem but i dont want to uninstall it, how?
![image](https://github.com/microsoft/winget-cli/assets/95969256/8a53da87-d55f-42d6-82bc-dd47306072ac)

but, i can update it from OBS it self, so how to solve the problem in the winget?

edited: when i see the version it still in 29.0.2, not upgraded
",False,0,NONE
https://api.github.com/repos/microsoft/winget-cli/issues/comments/1582357844,winget install OBSProject.OBSStudio = Installer failed with exit code: 6,No0Vad,9,1044777742,8,1582357844,0,1582353528,2023-06-08T10:47:36Z,"@adonneet If you add `-i` to your command (example: ` winget upgrade --id OBSProject.OBSStudio -i`) it will show the installer and it will tell you which app is blocking.

For me it's always NZXT CAM, closing that app fixes it and opening it again after works.",False,0,NONE
https://api.github.com/repos/microsoft/winget-cli/issues/comments/1582359004,winget install OBSProject.OBSStudio = Installer failed with exit code: 6,AdonNeet,9,1044777742,9,1582359004,0,1582357844,2023-06-08T10:48:39Z,"i see, ok let me check it

edited: so... the problem is from nvidia broadcast :D",False,0,NONE
https://api.github.com/repos/microsoft/winget-cli/issues/comments/1923876796,winget install OBSProject.OBSStudio = Installer failed with exit code: 6,giaco77,9,1044777742,10,1923876796,0,1582359004,2024-02-02T13:56:28Z,"> @AdonNeet If you add `-i` to your command (example: ` winget upgrade --id OBSProject.OBSStudio -i`) it will show the installer and it will tell you which app is blocking.
> 
> For me it's always NZXT CAM, closing that app fixes it and opening it again after works.

the -i parameter actually made my day! Thanks so much! <3",False,0,NONE
https://api.github.com/repos/microsoft/winget-cli/issues/1676,Pass credentials on the command line or prompt once for admin credentials,TWanamaker,4,1045071356,1,1045071356,0,0,2021-11-04T18:27:56Z,"### Description of the new feature / enhancement

I would like to run winget upgrade --all, and walk away from it. Instead, I get multiple requests to enter my admin level credentials which is somewhat annoying.



### Proposed technical implementation details

It would look something like this on the command line.

--user <user_id> --password <user_password> (future --certificate <path_to_private_key>)
or
--credentials userid/userpassword

Another option 

--escalate or --elevate -e
This would ask for the credentials once to avoid passing credentials on the command line.",True,0,NONE
https://api.github.com/repos/microsoft/winget-cli/issues/comments/961428149,Pass credentials on the command line or prompt once for admin credentials,jedieaston,4,1045071356,2,961428149,0,1045071356,2021-11-04T21:13:21Z,"One way a lot of us do it is through something like [`gsudo`](https://github.com/gerardog/gsudo) (`winget install gerardog.gsudo`).

It allows you to run a single command as a administrator, so you can do `gsudo winget upgrade --all` and winget along with all of the processes will be elevated.",False,0,CONTRIBUTOR
https://api.github.com/repos/microsoft/winget-cli/issues/comments/961481918,Pass credentials on the command line or prompt once for admin credentials,TWanamaker,4,1045071356,3,961481918,0,961428149,2021-11-04T22:30:03Z,"That works for me!

Please close or delete this ticket.
",False,0,NONE
https://api.github.com/repos/microsoft/winget-cli/issues/comments/961554023,Pass credentials on the command line or prompt once for admin credentials,jedieaston,4,1045071356,4,961554023,0,961481918,2021-11-05T01:18:37Z,"You can close it, by going to the bottom of this page and clicking ""Close issue"". ",False,0,CONTRIBUTOR
https://api.github.com/repos/microsoft/winget-cli/issues/comments/961948013,Pass credentials on the command line or prompt once for admin credentials,TWanamaker,4,1045071356,5,961948013,0,961554023,2021-11-05T14:37:54Z,No longer needed,False,0,NONE
https://api.github.com/repos/microsoft/winget-cli/issues/1678,Create nuget package for COM API,JohnMcPMS,3,1046058743,1,1046058743,0,0,2021-11-05T17:03:28Z,"### Description of the new feature / enhancement

Create a nuget package to enable easier consumption of the COM API.

### Proposed technical implementation details

Include the winmd, client binary, and appropriate targets file to enable callers to easily integrate.",True,0,MEMBER
https://api.github.com/repos/microsoft/winget-cli/issues/comments/1530133147,Create nuget package for COM API,ChrisGuzak,3,1046058743,2,1530133147,0,1046058743,2023-05-01T19:55:37Z,In email with @JohnMcPMS I learned [the nuget package](https://www.nuget.org/packages/Microsoft.WindowsPackageManager.ComInterop/1.5.863-preview) has been created already. update the docs to mention this!,False,0,MEMBER
https://api.github.com/repos/microsoft/winget-cli/issues/comments/1530135231,Create nuget package for COM API,ChrisGuzak,3,1046058743,3,1530135231,0,1530133147,2023-05-01T19:57:16Z,"I noticed this package is missing a .targets file that would automatically add the reference to the .winmd file, needed to consume the APIs. ",False,0,MEMBER
https://api.github.com/repos/microsoft/winget-cli/issues/comments/1530138351,Create nuget package for COM API,ChrisGuzak,3,1046058743,4,1530138351,0,1530135231,2023-05-01T19:59:43Z,"I also see the package does not include the COM CLSIDs needed to use the API. 
adding a .h file to the nuget package with them would resolve this.

cppwinrt makes this easy...
```cpp
#include <winrt/base.h>
inline constexpr winrt::guid PackageManager{""{C53A4F16-787E-42A4-B304-29EFFB4BF597}""};
```",False,0,MEMBER
https://api.github.com/repos/IntellectualSites/PlotSquared/issues/3345,"Fixes #3344, Wrong iterator algorithm in PlotRangeIterator",buepas,5,1060818896,1,1060818896,0,0,2021-11-23T04:05:40Z,"## Overview
Yeah dunno, its a very small change and I don't know, the issue says everything...

## Description
This PR Fixes #3344 
## Checklist
- [] Make sure you are opening from a topic branch (**/feature/fix/docs/ branch** (right side)) and not your main branch.
- [] Ensure that the pull request title represents the desired changelog entry.
- [X] I tested my changes and approved their functionality.
- [X] I ensured my changes do not break other parts of the code
- [] I read and followed the [contribution guidelines](https://github.com/IntellectualSites/.github/blob/main/CONTRIBUTING.md)",True,0,CONTRIBUTOR
https://api.github.com/repos/IntellectualSites/PlotSquared/issues/comments/976153258,"Fixes #3344, Wrong iterator algorithm in PlotRangeIterator",buepas,5,1060818896,2,976153258,0,1060818896,2021-11-23T04:07:23Z,"also sorry if I didn't meet the standards. If you really want me to fit them for this one-liner, I can surely do that!",False,0,CONTRIBUTOR
https://api.github.com/repos/IntellectualSites/PlotSquared/issues/comments/976233292,"Fixes #3344, Wrong iterator algorithm in PlotRangeIterator",SirYwell,5,1060818896,3,976233292,0,976153258,2021-11-23T07:53:45Z,Looks good. Could you add a test case in `com.plotsquared.core.plot.PlotRangeIteratorTest` to avoid regressions here? That would be very nice.,False,0,MEMBER
https://api.github.com/repos/IntellectualSites/PlotSquared/issues/comments/976581650,"Fixes #3344, Wrong iterator algorithm in PlotRangeIterator",buepas,5,1060818896,4,976581650,0,976233292,2021-11-23T14:03:46Z,"> Looks good. Could you add a test case in `com.plotsquared.core.plot.PlotRangeIteratorTest` to avoid regressions here? That would be very nice.

Sure! When I come home I will do that",False,0,CONTRIBUTOR
https://api.github.com/repos/IntellectualSites/PlotSquared/issues/comments/976964713,"Fixes #3344, Wrong iterator algorithm in PlotRangeIterator",buepas,5,1060818896,5,976964713,0,976581650,2021-11-23T18:15:18Z,"About the unit-tests:

It looks like that junit was upgraded to junit 5, but the imports haven't been updated?

Should this be handled in a different PR?

Edit:
I have written the test, and I converted the imports on my side.",False,0,CONTRIBUTOR
https://api.github.com/repos/IntellectualSites/PlotSquared/issues/comments/976967016,"Fixes #3344, Wrong iterator algorithm in PlotRangeIterator",NotMyFault,5,1060818896,6,976967016,0,976964713,2021-11-23T18:17:22Z,"Some tests are using JUnit 4, newer ones are using JUnit 5. Targeting the newer one is preferable. But no, you can append it to this PR.",False,0,MEMBER
https://api.github.com/repos/IntellectualSites/PlotSquared/issues/3346,Road gets placed one block further down than it should,EscolarProgramming,9,1063167892,1,1063167892,0,0,2021-11-25T05:16:24Z,"### Server Implementation

Paper

### Server Version

1.17.1

### Describe the bug

After updating from PlotSquared 6.1.3 to 6.1.4, the road gets placed one block futher down than it should, when an interaction with the road happens (e.g. plot unmerge). Even ""/debug roadregen"" doesn't help. We haven't changed the road schematic. After downgrading back to 6.1.3, it works as it should.

### To Reproduce

1. Create a merge
2. Unlink or delete it
3. There you go

### Expected behaviour

The road should be generated on the same level than the other ones

### Screenshots / Videos

![Image](https://user-images.githubusercontent.com/6965961/143273493-a411656c-ce27-4795-bda2-c852ed93e807.jpeg)


### Error log (if applicable)

_No response_

### Plot Debugpaste

https://athion.net/ISPaster/paste/view/f6be46aaab1446f6a8392add90ff8924

### PlotSquared Version

6.1.4-Premium

### Checklist

- [X] I have included a Plot debugpaste.
- [X] I am using the newest build from https://www.spigotmc.org/resources/77506/ and the issue still persists.

### Anything else?

_No response_",True,0,NONE
https://api.github.com/repos/IntellectualSites/PlotSquared/issues/comments/980065932,Road gets placed one block further down than it should,NotMyFault,9,1063167892,2,980065932,0,1063167892,2021-11-26T15:41:20Z,"Take a look at your worlds.yml: the plot and road height are 62 blocks, the wall height are 61 blocks.",False,0,MEMBER
https://api.github.com/repos/IntellectualSites/PlotSquared/issues/comments/980289231,Road gets placed one block further down than it should,EscolarProgramming,9,1063167892,3,980289231,0,980065932,2021-11-26T18:48:37Z,"But it's only with version 6.1.4, when we use the exact same files with 6.1.3, it doesn't happen!",False,0,NONE
https://api.github.com/repos/IntellectualSites/PlotSquared/issues/comments/992456703,Road gets placed one block further down than it should,EscolarProgramming,9,1063167892,4,992456703,0,980289231,2021-12-13T13:04:56Z,"Thank you for re-opening this ticket! Should I provide you our PlotSquared and world files, so you can replicate it?",False,0,NONE
https://api.github.com/repos/IntellectualSites/PlotSquared/issues/comments/999591865,Road gets placed one block further down than it should,EscolarProgramming,9,1063167892,5,999591865,0,992456703,2021-12-22T13:51:20Z,"With a little testing we found out the following: Since the 6.1.4 update, PS seems to use the wall height as the street height. If we set the border to height 62, the road is at the correct height, but the border is one block higher than the road.",False,0,NONE
https://api.github.com/repos/IntellectualSites/PlotSquared/issues/comments/1008802275,Road gets placed one block further down than it should,EscolarProgramming,9,1063167892,6,1008802275,0,999591865,2022-01-10T11:54:15Z,"The problem seems to be in #3300. With that pull request, the calculation of the road height has been changed. See here https://github.com/IntellectualSites/PlotSquared/pull/3300/commits/658d5f9326e16e41a7295e23f44e8c0bf7944c5d#diff-cd31969ae49cbf1071b2053db320c9ef683c006623f40305d7704d3b258b64c9",False,0,NONE
https://api.github.com/repos/IntellectualSites/PlotSquared/issues/comments/1008925353,Road gets placed one block further down than it should,NotMyFault,9,1063167892,7,1008925353,0,1008802275,2022-01-10T14:27:23Z,cc @dordsor21 Can you take a look? Works fine based on my prior testing.,False,0,MEMBER
https://api.github.com/repos/IntellectualSites/PlotSquared/issues/comments/1009041170,Road gets placed one block further down than it should,dordsor21,9,1063167892,8,1009041170,0,1008925353,2022-01-10T16:17:41Z,"This is/*was* an issue specifically when the road and wall are at different heights. The PR fixed issues where the schematic was cut off by the number of blocks difference if the schematic height was greater than 1. It technically now takes the lower of the two heights to start schematic creation. Remaking the road schematic will fix this, else I will quickly add a config option to force road schematics to be set from the road height, rather than the lower of road and wall.",False,0,MEMBER
https://api.github.com/repos/IntellectualSites/PlotSquared/issues/comments/1011306069,Road gets placed one block further down than it should,EscolarProgramming,9,1063167892,9,1011306069,0,1009041170,2022-01-12T17:54:40Z,A config option would be very nice! Thanks in advance.,False,0,NONE
https://api.github.com/repos/IntellectualSites/PlotSquared/issues/comments/1011307134,Road gets placed one block further down than it should,PierreSchwang,9,1063167892,10,1011307134,0,1011306069,2022-01-12T17:55:56Z,"> A config option would be very nice! Thanks in advance.

A config option was already added in the pull request",False,0,MEMBER
https://api.github.com/repos/IntellectualSites/PlotSquared/issues/3347,Setowner for normal player,BensaTV,7,1065391798,1,1065391798,0,0,2021-11-28T17:38:53Z,"### What feature do you want to see added?

Please add a permission that allows only changing the owner with /plot setowner on your own plot. Currently there is only an admin permission that allows a player to change the owner of anyones plot. This would take alot of work for me away as my wouldn't have to ask me every single time if I can change the owner of their plot. This also used to be a thing in PlotSquared V3 and even V4 I think.

### Are there any alternatives?

Not really. I could use an outdated version of plotsquared but I don't really see that as an option as I paid for this one and want to avoid Bugs.

### Anything else?

_No response_",True,0,NONE
https://api.github.com/repos/IntellectualSites/PlotSquared/issues/comments/981161101,Setowner for normal player,zOIDAdaJulian,7,1065391798,2,981161101,0,1065391798,2021-11-28T22:08:44Z,"I would also apreciate this feature very much! 😄
Definitely a upvote from my side 👍",False,0,NONE
https://api.github.com/repos/IntellectualSites/PlotSquared/issues/comments/981912950,Setowner for normal player,NotMyFault,7,1065391798,3,981912950,0,981161101,2021-11-29T18:45:11Z,"I'm a bit opposed to the suggested implementation. `Setowner` is intended to be an administrative command, it does not respect the same limits other commands do, and does not fire events you would expect it to do.
An in my opinion better approach would be something like `/plot transfer`, that transfers the plot ownership from one user to another, while respecting economy, grants and possible third party circumstances (e.g. firing separate events; at this time it's not possible to distinguish whether a `setowner` action has been instantiated as administrative or user action), everything setowner does not do.
An optional confirmation, like for plot merging with different owners, should be added as well, considering it's an irreversible action for the actor.
The `setowner` command can be deprecated in favor of `transfer`, which then handles the administrative and the player part.
Adding the player logic to `setowner` is undesired, considering its naming scheme implies a direct operation and is misleading to what it's new part will do. ",False,0,MEMBER
https://api.github.com/repos/IntellectualSites/PlotSquared/issues/comments/981916014,Setowner for normal player,zOIDAdaJulian,7,1065391798,4,981916014,0,981912950,2021-11-29T18:49:36Z,"Yeah of course 👍 Thanks for looking into the request, I really think a command like a transfer command would be a huge innovation for PlotSquared 😁",False,0,NONE
https://api.github.com/repos/IntellectualSites/PlotSquared/issues/comments/985609793,Setowner for normal player,DevJoey,7,1065391798,5,985609793,0,981916014,2021-12-03T15:26:29Z,It would be nice if /plot transfer also respects grant limit and plots.plot.<number> limits to,False,0,NONE
https://api.github.com/repos/IntellectualSites/PlotSquared/issues/comments/1537182119,Setowner for normal player,DueKay,7,1065391798,6,1537182119,0,985609793,2023-05-06T17:01:14Z,"Evening together,

I wanted to ask if there will ever be the possibility for users to hand in their own plots? Whether with /p give or /p transfer
But it would make everything much more pleasant than if you always have to transfer it to someone for the users if they want it.
As already mentioned, the limitation of the plots should be taken into account so that nobody can claim more than they are allowed to. And I also find the possibility that the other user has to accept the transmission of the plot very useful.

Thanks in advance and best regards

Ps. Sry for the probably bad grammar. I used google translator xD


------------------------------------------------------------------------------------------------------


Abend zusammen,

Ich wollte mal nachfragen, ob es irgendwann die Möglichkeit für User geben wird, dass sie selbstständig ihr Plot abgeben können? Egal ob mit /p give oder /p transfer
Aber es würde alles doch wesentlich angenehmer machen, als wenn man es immer für die User an jemanden übertragen muss, wenn diese das gerne möchten.
Wie schon erwähnt sollte die begrenzung der Plots hierfür berücksichtigt sein, dass niemand dadurch mehr in anspruch nehmen kann, als er darf. Und auch die Möglichkeit das der andere User die Übertragung des Plots akzeptieren muss, finde ich sehr sinnvoll.

Danke schonmal und liebe Grüße

Ps. Sry für die wahrscheinlich schlechte Grammatik. Ich hab Google Übersetzer benutzt xD",False,0,NONE
https://api.github.com/repos/IntellectualSites/PlotSquared/issues/comments/1646660762,Setowner for normal player,BensaTV,7,1065391798,7,1646660762,0,1537182119,2023-07-22T19:59:10Z,We really need this.,False,0,NONE
https://api.github.com/repos/IntellectualSites/PlotSquared/issues/comments/1813292084,Setowner for normal player,BensaTV,7,1065391798,8,1813292084,0,1646660762,2023-11-15T21:33:08Z,It's been almost two years. Is there any update to this?,False,0,NONE
https://api.github.com/repos/IntellectualSites/PlotSquared/issues/3352,Failed to parse default flag with key 'use' and value '#doors',SecretlyJealous,4,1069658114,1,1069658114,0,0,2021-12-02T15:08:38Z,"### Server Implementation

Paper

### Server Version

1.17.1

### Describe the bug

In worlds.yml when I set #doors as a use flag it prints an error in console:
```
[15:04:34 WARN]: [PlotSquared/PlotArea] Failed to parse default flag with key 'use' and value '#doors'. Reason: com.plotsquared.core.configuration.caption.TranslatableCaption@6ebec81d. This flag will not be added as a default flag.
[15:04:34 WARN]: com.plotsquared.core.plot.flag.FlagParseException: Failed to parse flag of type 'use'. Value '#doors' was not accepted.
[15:04:34 WARN]:        at PlotSquared-Bukkit-6.1.4-Premium.jar//com.plotsquared.core.plot.flag.types.BlockTypeListFlag.getCategory(BlockTypeListFlag.java:102)
[15:04:34 WARN]:        at PlotSquared-Bukkit-6.1.4-Premium.jar//com.plotsquared.core.plot.flag.types.BlockTypeListFlag.parse(BlockTypeListFlag.java:63)
[15:04:34 WARN]:        at PlotSquared-Bukkit-6.1.4-Premium.jar//com.plotsquared.core.plot.flag.types.BlockTypeListFlag.parse(BlockTypeListFlag.java:42)
[15:04:34 WARN]:        at PlotSquared-Bukkit-6.1.4-Premium.jar//com.plotsquared.core.plot.PlotArea.parseFlags(PlotArea.java:201)
[15:04:34 WARN]:        at PlotSquared-Bukkit-6.1.4-Premium.jar//com.plotsquared.core.plot.PlotArea.loadDefaultConfiguration(PlotArea.java:411)
[15:04:34 WARN]:        at PlotSquared-Bukkit-6.1.4-Premium.jar//com.plotsquared.core.PlotSquared.loadWorld(PlotSquared.java:844)
[15:04:34 WARN]:        at PlotSquared-Bukkit-6.1.4-Premium.jar//com.plotsquared.bukkit.generator.BukkitPlotGenerator.getDefaultPopulators(BukkitPlotGenerator.java:116)
[15:04:34 WARN]:        at net.minecraft.server.MinecraftServer.initWorld(MinecraftServer.java:746)
[15:04:34 WARN]:        at net.minecraft.server.MinecraftServer.loadWorld(MinecraftServer.java:702)
[15:04:34 WARN]:        at net.minecraft.server.dedicated.DedicatedServer.init(DedicatedServer.java:317)
[15:04:34 WARN]:        at net.minecraft.server.MinecraftServer.x(MinecraftServer.java:1220)
[15:04:34 WARN]:        at net.minecraft.server.MinecraftServer.lambda$spin$0(MinecraftServer.java:319)
[15:04:34 WARN]:        at java.base/java.lang.Thread.run(Thread.java:833)
```

### To Reproduce

1. Go to worlds.yml and set the use flag to `#doors`

### Expected behaviour

1. There should be no error printed to console

### Screenshots / Videos

_No response_

### Error log (if applicable)

_No response_

### Plot Debugpaste

https://athion.net/ISPaster/paste/view/591bc8d7600249738145f33d58f874b3

### PlotSquared Version

PlotSquared-Bukkit-6.1.4-Premium

### Checklist

- [X] I have included a Plot debugpaste.
- [X] I am using the newest build from https://www.spigotmc.org/resources/77506/ and the issue still persists.

### Anything else?

_No response_",True,0,NONE
https://api.github.com/repos/IntellectualSites/PlotSquared/issues/comments/985996125,Failed to parse default flag with key 'use' and value '#doors',NotMyFault,4,1069658114,2,985996125,0,1069658114,2021-12-04T09:12:55Z,"I was not able to replicate that. Looking at your log, it doesn't appear on startup either, can you leave some steps to replicate that?",False,0,MEMBER
https://api.github.com/repos/IntellectualSites/PlotSquared/issues/comments/985999908,Failed to parse default flag with key 'use' and value '#doors',SecretlyJealous,4,1069658114,3,985999908,0,985996125,2021-12-04T09:43:11Z,"> I was not able to replicate that. Looking at your log, it doesn't appear on startup either, can you leave some steps to replicate that?

In my worlds.yml I am manually editing the file to add a use flag for minecraft:#doors

```
    flags:
      use: minecraft:#doors
```

![Untitled](https://user-images.githubusercontent.com/10485646/144704955-1fb9097d-374f-40ce-ba9e-50c98c14e2c5.png)

On startup it gives this error in latest.log:
```
[09:39:34 WARN]: [PlotSquared/PlotArea] Failed to parse default flag with key 'use' and value 'minecraft:#doors'. Reason: com.plotsquared.core.configuration.caption.TranslatableCaption@6ebec81d. This flag will not be added as a default flag.
[09:39:34 WARN]: com.plotsquared.core.plot.flag.FlagParseException: Failed to parse flag of type 'use'. Value 'minecraft:#doors' was not accepted.
[09:39:34 WARN]:        at PlotSquared-Bukkit-6.1.4-Premium.jar//com.plotsquared.core.plot.flag.types.BlockTypeListFlag.getCategory(BlockTypeListFlag.java:93)
[09:39:34 WARN]:        at PlotSquared-Bukkit-6.1.4-Premium.jar//com.plotsquared.core.plot.flag.types.BlockTypeListFlag.parse(BlockTypeListFlag.java:63)
[09:39:34 WARN]:        at PlotSquared-Bukkit-6.1.4-Premium.jar//com.plotsquared.core.plot.flag.types.BlockTypeListFlag.parse(BlockTypeListFlag.java:42)
[09:39:34 WARN]:        at PlotSquared-Bukkit-6.1.4-Premium.jar//com.plotsquared.core.plot.PlotArea.parseFlags(PlotArea.java:201)
[09:39:34 WARN]:        at PlotSquared-Bukkit-6.1.4-Premium.jar//com.plotsquared.core.plot.PlotArea.loadDefaultConfiguration(PlotArea.java:411)
[09:39:34 WARN]:        at PlotSquared-Bukkit-6.1.4-Premium.jar//com.plotsquared.core.PlotSquared.loadWorld(PlotSquared.java:844)
[09:39:34 WARN]:        at PlotSquared-Bukkit-6.1.4-Premium.jar//com.plotsquared.bukkit.generator.BukkitPlotGenerator.getDefaultPopulators(BukkitPlotGenerator.java:116)
[09:39:34 WARN]:        at net.minecraft.server.MinecraftServer.initWorld(MinecraftServer.java:746)
[09:39:34 WARN]:        at net.minecraft.server.MinecraftServer.loadWorld(MinecraftServer.java:702)
[09:39:34 WARN]:        at net.minecraft.server.dedicated.DedicatedServer.init(DedicatedServer.java:317)
[09:39:34 WARN]:        at net.minecraft.server.MinecraftServer.x(MinecraftServer.java:1220)
[09:39:34 WARN]:        at net.minecraft.server.MinecraftServer.lambda$spin$0(MinecraftServer.java:319)
[09:39:34 WARN]:        at java.base/java.lang.Thread.run(Thread.java:833)
[09:39:34 INFO]: [P2] Area flags: [use;minecraft:#doors]
[09:39:34 INFO]: [P2] Road flags: []
```

PS Debugpaste: https://athion.net/ISPaster/paste/view/7c2d0bc9180b4dc2ae0eeaa74f99d45a

<blockquote><div><strong><a href=""https://athion.net/ISPaster/paste/view/7c2d0bc9180b4dc2ae0eeaa74f99d45a"">Incendo Paste Viewer</a></strong></div></blockquote>",False,0,NONE
https://api.github.com/repos/IntellectualSites/PlotSquared/issues/comments/986279515,Failed to parse default flag with key 'use' and value '#doors',SirYwell,4,1069658114,4,986279515,0,985999908,2021-12-05T18:39:52Z,"The correct syntax for that would be `#minecraft:doors`. In YAML, you need to add enclosing `'`, otherwise it's interpreted as a comment.",False,0,MEMBER
https://api.github.com/repos/IntellectualSites/PlotSquared/issues/comments/989947325,Failed to parse default flag with key 'use' and value '#doors',SecretlyJealous,4,1069658114,5,989947325,0,986279515,2021-12-09T15:16:51Z,"> The correct syntax for that would be `#minecraft:doors`. In YAML, you need to add enclosing `'`, otherwise it's interpreted as a comment.

I've adjusted it but it still doesn't work unless I've still written it wrong?

    flags:
      use: '#minecraft:doors'

```
[15:14:46 WARN]: [PlotSquared/PlotArea] Failed to parse default flag with key 'use' and value '#minecraft:doors'. Reason: com.plotsquared.core.configuration.caption.TranslatableCaption@6ebec81d. This flag will not be added as a default flag.
[15:14:46 WARN]: com.plotsquared.core.plot.flag.FlagParseException: Failed to parse flag of type 'use'. Value '#minecraft:doors' was not accepted.
[15:14:46 WARN]:        at PlotSquared-Bukkit-6.1.4-Premium.jar//com.plotsquared.core.plot.flag.types.BlockTypeListFlag.getCategory(BlockTypeListFlag.java:102)
[15:14:46 WARN]:        at PlotSquared-Bukkit-6.1.4-Premium.jar//com.plotsquared.core.plot.flag.types.BlockTypeListFlag.parse(BlockTypeListFlag.java:63)
[15:14:46 WARN]:        at PlotSquared-Bukkit-6.1.4-Premium.jar//com.plotsquared.core.plot.flag.types.BlockTypeListFlag.parse(BlockTypeListFlag.java:42)
[15:14:46 WARN]:        at PlotSquared-Bukkit-6.1.4-Premium.jar//com.plotsquared.core.plot.PlotArea.parseFlags(PlotArea.java:201)
[15:14:46 WARN]:        at PlotSquared-Bukkit-6.1.4-Premium.jar//com.plotsquared.core.plot.PlotArea.loadDefaultConfiguration(PlotArea.java:411)
[15:14:46 WARN]:        at PlotSquared-Bukkit-6.1.4-Premium.jar//com.plotsquared.core.PlotSquared.loadWorld(PlotSquared.java:844)
[15:14:46 WARN]:        at PlotSquared-Bukkit-6.1.4-Premium.jar//com.plotsquared.bukkit.generator.BukkitPlotGenerator.getDefaultPopulators(BukkitPlotGenerator.java:116)
[15:14:46 WARN]:        at net.minecraft.server.MinecraftServer.initWorld(MinecraftServer.java:746)
[15:14:46 WARN]:        at net.minecraft.server.MinecraftServer.loadWorld(MinecraftServer.java:702)
[15:14:46 WARN]:        at net.minecraft.server.dedicated.DedicatedServer.init(DedicatedServer.java:317)
[15:14:46 WARN]:        at net.minecraft.server.MinecraftServer.x(MinecraftServer.java:1220)
[15:14:46 WARN]:        at net.minecraft.server.MinecraftServer.lambda$spin$0(MinecraftServer.java:319)
[15:14:46 WARN]:        at java.base/java.lang.Thread.run(Thread.java:833)
[15:14:46 INFO]: [P2] Area flags: [use;#minecraft:doors]
[15:14:46 INFO]: [P2] Road flags: []
```",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/13322,[Feature Request] Sublists based on folder structure,chinagreenelvis,8,1071142982,1,1071142982,0,0,2021-12-04T06:54:32Z,"I keep my ROMs sorted into subdirectories based on region, license, genre, etc. Rather than manually populating RetroArch with tons of custom playlists based on my categorizations, it would be much more convenient (and easier to browse) if the files added to any given playlist from a directory had the option of being sub-listed within that playlist, reflecting the folder structure.
",True,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/986008447,[Feature Request] Sublists based on folder structure,i30817,8,1071142982,2,986008447,0,1071142982,2021-12-04T10:54:48Z,"What would be more convenient yet (if i wasn't convinced it was impossible in general because of lacking metadata and accurate scanning for hacks) would be if you could save metadata searches (from 'explore') as playlists, with some kind of more robust search and more robust metadata (not just 'plain and uninformative genre, company and language').

Then, with a similar mechanism to how you can 'refresh' manual scanner playlists today - thanks to the hard work of jdgleaver - you could do the same when RA updates metadata. First you'd 'update' the manual scan playlists to add or remove games, then you'd update the genre lists which take from those playlists.

If the query language gets 'negative' and better genres and characteristics you could even do things like '2d-beatemup && !contemporary' and other things like that. Unfortunately, game metadata ~~from hobbyists~~ (you know what? In general, all game metadata is poor) is completely and utterly pathetic, mainly because it's complicated to fill and they get into the rut of pretending a 'general genre' actually means anything instead being the pre-history of the web of things. What does 'adventure' actually means, or even 'action-adventure'. What does that tell me about the themes, plot, setting or characters? Nothing. 

RA _could_ make a big feature about allowing filling metadata 'approved' tags from retroarch itself and upload those to their servers then rollback and ip ban the inevitable trolls trying to turn every sega or nintendo games into a +18, but honestly, i think it never will. Not enough incentive when you can just use the flawed and painfully uninformative current external databases.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/986013027,[Feature Request] Sublists based on folder structure,i30817,8,1071142982,3,986013027,0,986008447,2021-12-04T11:33:23Z,"That said your feature is a nice idea but you can kind of do it today with the manual scanner - it can autoupdate as you move games around because it saves the scanned directory. If you _really really_ want it.

I wouldn't have the patience because RA playlists _should_ be organized by console first and foremost because of the core association and of the 'problem' of duplicates with scanning, even with a the manual scanner using filenames (there are many ports and no intro/redump kind of reuse names). So you'd endup with 'gamecube - rpg' and 'ps1 - rpg' or more arbitrarily specific divisions etc.

But i suppose if you already organized your folder structure, you have that patience. 

A warning: neither scanner is perfect, and several games will not scan whatever you do in large collections and have to be added manually or have to have 'invented metadata' added (scummvm core did this but i think they gave up on it, because it was hell for users). 

In the 'automatic' scanner because of bugs, or the serial is fucked from origin, or misleading false positives that look like duplicates (hacks) or if it's one of the systems still using CRCs, misleading crcs because the file used isn't actually readonly. 

In the manual scanner because the name of the game it's searching for is either missing from the database, a hack name or something in a format you forgot to accept, or because of false positives from 'games' you need for the emulator to run, but don't actually want (for instance, mame bioses). The option to accept a ctrlmame dat file to filter is useful then cause because i think the scanner ignores files marked as 'system' files. And if you can make a script to transform xml you can use xslt to 'make your own filters' from the dumper dat file (and any self respectable romset has a a dat file, for instance, i could semi-easily make a 'whdload english only playlist' for puae like this. Again, lack of metadata hurts this feature - i had to string process it from the filename itself instead of setting up something in the menu to say 'scan this dir but exclude all non-english' - but it's only really often used for 'filter MAME bios' for 99%.

Or because if there is no way to associate a 'sane' filename to the the entry and use that as id (the best feature of the manual scanner) you get a bunch of 'agssetup.cfg' entries or similar (agssetup.cfg is a configuration file from a engine with about 1 thousand+ games and as a configuration file, it's not unusual to be edited by users, so the CRC is out too, if you _did_ edit it). To fix that last i think it would be nice if the manual scanner had yet another option to say 'find the files but take the name to match medata from the file parent directory, not the file'.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/986019301,[Feature Request] Sublists based on folder structure,chinagreenelvis,8,1071142982,4,986019301,0,986013027,2021-12-04T12:26:19Z,"A feature for saving explore filters as custom playlists would be nice. In the meantime, allowing playlists to have the option of sublist structures based on the organization of the files themselves would solve my problems entirely since I don't have to wait on a community-driven metadata solution to organize my own ROMs.",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/986101210,[Feature Request] Sublists based on folder structure,i30817,8,1071142982,5,986101210,0,986019301,2021-12-04T22:16:30Z,"The problem here is that this solution was already rejected for the manual scanner, a solution that is frankly superior. I even think, we can just create a empty playlist with a prototype of what the manual scanner wants and the path to your 'sublist' and 'refresh' the playlist to get get what you want, with the gotchas i mentioned.

For instance, this is a empty version of my whdload playlist:

```
{
  ""version"": ""1.5"",
  ""default_core_path"": ""/home/i3/.config/retroarch/cores/puae_libretro.so"",
  ""default_core_name"": ""Commodore - Amiga (PUAE)"",
  ""base_content_directory"": ""/home/i3/Documents/Games"",
  ""label_display_mode"": 0,
  ""right_thumbnail_mode"": 0,
  ""left_thumbnail_mode"": 0,
  ""sort_mode"": 0,
  ""scan_content_dir"": ""/home/i3/Documents/Games/Commodore - Amiga/Amiga WHDLoad"",
  ""scan_file_exts"": ""lha"",
  ""scan_dat_file_path"": ""/home/i3/Documents/Games/Commodore - Amiga/Amiga WHDLoad/games.dat"",
  ""scan_search_recursively"": true,
  ""scan_search_archives"": false,
  ""scan_filter_dat_content"": true,
  ""items"": [
]
}
```

And i'm pretty sure that if i hit 'refresh' in the manage playlist menu it would fill it all again. The name of the playlist file is the name of the playlist in RA since it's not a config item there. And there is a separator to have multiple types of file to scan i don't remember (probably "";"" but it could be ',' or space even).",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/986111653,[Feature Request] Sublists based on folder structure,chinagreenelvis,8,1071142982,6,986111653,0,986101210,2021-12-04T23:20:04Z,"Why would the option for subfolder respect on a manual scan - and the ability to navigate playlists according to that folder structure - be rejected? I would think it would be a desirable _option_ for many users.

The most important thing for me, besides organization, is the navigation. I'm sure I could automate a script to write some manual playlists according to my categories and sub-categories, but the result would be an ugly mess since each playlist would wind up taking up a primary spot in the navigational menu - I would have to scroll through each one for every system, rather than just changing systems and then navigating by region/genre/playercount, etc.

Allowing for subfolder recognition on a scan, again - not by default but as an _option_ - seems like a much more elegant way of addressing the problem, especially since metadata for games is, as you've pointed out, terribly inconsistent and for some systems functionally non-existent and will probably continue to be for many years to come. (Not to mention that the creation of playlists by metadata would probably result in the same navigational problem, which is a lack of heirarchy, and would also take unnecessary time if the user has already gone through the process of organizing by subfolders.)

To make it even better, I can imagine binding a key to switch between the folder heirarchy and the ""all games"" list. This is more or less how I've had it set up in Maximus Arcade for the last ten years (which I may continue using in spite of all of the things I love about RetroArch... the ability to create sublists in a sensible navigation is more or less a dealbreaker for me, I think.)",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/986142905,[Feature Request] Sublists based on folder structure,i30817,8,1071142982,7,986142905,0,986111653,2021-12-05T00:40:08Z,"Ah you want subfolders in the actual playlist not just playlists per directory. I was misunderstanding almost the whole thing myself.

Good luck with your FR then.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/986148972,[Feature Request] Sublists based on folder structure,chinagreenelvis,8,1071142982,8,986148972,0,986142905,2021-12-05T01:38:34Z,Right; an optional subfolder structure within a primary playlist.,False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/2094026001,[Feature Request] Sublists based on folder structure,agluck91,8,1071142982,9,2094026001,0,986148972,2024-05-04T05:26:13Z,Just want to plus one this one,False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/13326,Add option for showing notifications only in menu,sonninnos,8,1071282826,1,1071282826,0,0,2021-12-04T19:53:02Z,"## Description

Simple option addition for hiding all kinds of notifications/widgets when menu is not active.

## Related Issues

Closes #12814
",True,0,COLLABORATOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/986088531,Add option for showing notifications only in menu,jayare5,8,1071282826,2,986088531,0,1071282826,2021-12-04T20:30:38Z,"Hey, this works perfectly!! Thanks so much!!",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/986213223,Add option for showing notifications only in menu,jdgleaver,8,1071282826,3,986213223,0,986088531,2021-12-05T11:33:38Z,"Nice option! But there are a couple of issues here:

- You can't use `config_get_ptr()` or `menu_state_get_ptr()` in `gfx_widgets_frame()` - if you need to check new parameters here, they have to be passed via the `video_frame_info_t` struct
- At present, you're forcing an early return from `runloop_msg_queue_push()` and `runloop_task_msg_queue_push()` if the option is set - but this is a little improper since it means a message sent by a core will be lost if the user opens the quick menu while the message timer would have still been running. More correctly, the message should be pushed in all cases, but just not be displayed if the option is enabled and the menu is not running

Essentially, this should be implemented in a similar fashion to the way that I hide notifications when the menu screensaver is running: https://github.com/libretro/RetroArch/pull/12217",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/986224426,Add option for showing notifications only in menu,sonninnos,8,1071282826,4,986224426,0,986213223,2021-12-05T12:49:00Z,"Whoops & thanks! Now should be more like it.
",False,0,COLLABORATOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/986633084,Add option for showing notifications only in menu,jdgleaver,8,1071282826,5,986633084,0,986224426,2021-12-06T10:17:09Z,"Thanks, that's better :)

But you need a 'notifications hidden' check here as well: https://github.com/libretro/RetroArch/blob/7769ef4f3f5253e852432ba8c85a978173ddb277/gfx/video_driver.c#L3935",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/986689935,Add option for showing notifications only in menu,sonninnos,8,1071282826,6,986689935,0,986633084,2021-12-06T11:30:13Z,"I thought so too at first, but it appears that the earlier `video_driver_msg` nulling effectively blanks those already. Which lead me thinking that perhaps those particular status ones (fps etc) should be visible instead just like statistics, since those won't appear out of thin air.
",False,0,COLLABORATOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/986698302,Add option for showing notifications only in menu,jdgleaver,8,1071282826,7,986698302,0,986689935,2021-12-06T11:43:26Z,"Yes indeed - even without the extra check, those messages won't be displayed. The reason for having the check, however, is that it saves the overheads of pushing a runloop message that can never be seen. These status messages are 'special' in that they are sent every frame, so if we block them while content is running then they will automatically reappear when the quick menu is opened - this is unlike core-generated messages, which are lost forever if they don't get pushed.

> Which lead me thinking that perhaps those particular status ones (fps etc) should be visible instead just like statistics, since those won't appear out of thin air.

I think for this PR, which is a blanket notifications on/off setting, it's fine to hide everything. Individual switches could be added later.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/986708546,Add option for showing notifications only in menu,sonninnos,8,1071282826,8,986708546,0,986698302,2021-12-06T11:59:40Z,"Ach, so it seems, so there we go.
",False,0,COLLABORATOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/986710993,Add option for showing notifications only in menu,jdgleaver,8,1071282826,9,986710993,0,986708546,2021-12-06T12:02:49Z,Excellent - this all looks fine now :),False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/13339,Add Linux GameMode support,realnc,19,1074820966,1,1074820966,0,0,2021-12-08T20:54:20Z,"## Description

This can fix a lot of performance issues, like audio crackling and frame
time spikes. This requires the GameMode package to be installed. See:

https://github.com/FeralInteractive/gamemode

This commit adds a ""Game Mode"" bool option to the ""Power
Management"" and ""Latency"" settings sections, and it can be toggled
on/off without restarting RA.

The actual toggling of game mode happens in a new frontend platform
interface function. Perhaps this will become useful for other platforms
that provide some equivalent of Linux GameMode.

Since the GameMode ABI is fixed, and the API comes as a single,
header-only file with no actual deps, we simply bundle the header
(deps/feralgamemode/gamemode_client.h.) That way, all Linux builds will
have support for GameMode regardless of whether the GameMode development
package is installed or not.

## Reviewers

@jdgleaver @twinaphex",True,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/989192924,Add Linux GameMode support,realnc,19,1074820966,2,989192924,0,1074820966,2021-12-08T21:02:53Z,"I'm not sure how to handle the `gamemode_client.h` dependency. Right now, it's just found with pkg-config and so it will need to be installed on the build bot. However, that header can also be bundled and used unconditionally. In that case, GameMode will simply not work on systems that don't have that software installed (the `gamemode_client.h` functions use `dlopen`.)

Thoughts?",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/989329259,Add Linux GameMode support,RobLoach,19,1074820966,3,989329259,0,989192924,2021-12-09T00:09:29Z,"> I'm not sure how to handle the gamemode_client.h dependency. Right now, it's just found with pkg-config and so it will need to be installed on the build bot. However, that header can also be bundled and used unconditionally. In that case, GameMode will simply not work on systems that don't have that software installed (the gamemode_client.h functions use dlopen.)

I think how it is seems reasonable. I didn't have `libgamemode-dev` installed, and it was building without gamemode enabled. Once libgamemode-dev was installed and re-compiled, it worked. When I removed gamemode from my system, I got a reasonable error:
```
[WARN] GameMode: Failed to enter game mode: dlopen failed - libgamemode.so: cannot open shared object file: No such file or directory.
```",False,0,MEMBER
https://api.github.com/repos/libretro/RetroArch/issues/comments/989337425,Add Linux GameMode support,realnc,19,1074820966,4,989337425,0,989329259,2021-12-09T00:27:10Z,"> I think how it is seems reasonable. I didn't have `libgamemode-dev` installed, and it was building without gamemode enabled. Once libgamemode-dev was installed and re-compiled, it worked. When I removed gamemode from my system, I got a reasonable error:
> 
> ```
> [WARN] GameMode: Failed to enter game mode: dlopen failed - libgamemode.so: cannot open shared object file: No such file or directory.
> ```

The problem is that it's not installed on the build bot. So when people download RA instead of building it themselves, they get a build that doesn't support gamemode.

So there's two choices. Make sure it's installed on the build bot, or bundle the header.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/989346741,Add Linux GameMode support,RobLoach,19,1074820966,5,989346741,0,989337425,2021-12-09T00:47:41Z,"True... Perhaps let the builds and package managers determine whether GameMode is available? If the header isn't there, assume the build doesn't have it seems fine. I could likely get it up and running in Flatpak and Snap.

Majority of Linux people I've talked to don't download the RA build from the buildbot, and likely shouldn't because you should almost never download and run binaries from websites on the Internet 🤷

Alternatively, is it able to static-compile it?",False,0,MEMBER
https://api.github.com/repos/libretro/RetroArch/issues/comments/989373699,Add Linux GameMode support,realnc,19,1074820966,6,989373699,0,989346741,2021-12-09T01:16:16Z,"> Alternatively, is it able to static-compile it?

It's always being statically compiled. All the code in `gamemode_client.h` is inline. If you mean whether the gamemode deamon itself can be ""statically compiled"", then no. It's a process running on the host, usually started by systemd (the process is called `gamemoded`, you can see it running with `ps aux | grep gamemode`).",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/989796382,Add Linux GameMode support,jdgleaver,19,1074820966,7,989796382,0,989373699,2021-12-09T12:12:46Z,"@realnc Thank you, this is excellent :)

For proper correctness, however, the gamemode interface should be accessed inside the unix frontend platform driver - and it seems that the `frontend_unix_set_sustained_performance_mode()` function would be the ideal place for this. We can in fact use all the existing 'sustained performance' code, and just sub in different menu entry text depending upon whether we're running on Android or Linux. I will prepare a little patch to implement this change, and let you review it :)

As for your other points:

- Installing `libgamemode-dev` on the buildbot seems preferable to bundling the header. I can address this once the PR is merged

- I agree that gamemode should ideally be enabled by default for self-builds - but this makes things sticky for users who download a prebuilt version. Most people won't have gamemode installed, so they're all going to get dlopen failures and log spam. We perhaps need a command line flag to set it disabled by default for the buildbot versions...",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/989821262,Add Linux GameMode support,RobLoach,19,1074820966,8,989821262,0,989796382,2021-12-09T12:48:15Z,"> Most people won't have gamemode installed, so they're all going to get dlopen failures and log spam. 

This is why I believe having it disabled by default may be preferable.",False,0,MEMBER
https://api.github.com/repos/libretro/RetroArch/issues/comments/989825803,Add Linux GameMode support,realnc,19,1074820966,9,989825803,0,989821262,2021-12-09T12:54:15Z,"The dlopen failure messages are fine. After all, I constantly get wayland errors with no way to disable them. So nobody really cares about these messages, I'd say. And in the case of gamemode, unlike wayland, you can at least disable it.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/989835984,Add Linux GameMode support,realnc,19,1074820966,10,989835984,0,989825803,2021-12-09T13:07:01Z,"> the `frontend_unix_set_sustained_performance_mode()` function would be the ideal place for this.

Nah, gamemode is also about changing the CPU scheduler, I/O priority, nice level, and running custom scripts the user has provided.

Gamemode is it's own thing and should be treated as its own thing in the source code, IMO. I would never expect to find gamemode related code in that function.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/989874319,Add Linux GameMode support,jdgleaver,19,1074820966,11,989874319,0,989835984,2021-12-09T13:55:09Z,"> Nah, gamemode is also about changing the CPU scheduler, I/O priority, nice level, and running custom scripts the user has provided.
>
> Gamemode is it's own thing and should be treated as its own thing in the source code, IMO. I would never expect to find gamemode related code in that function.

You missed my point. This *has* to go inside the unix frontend platform driver. This means it has to be enabled/disabled via a frontend platform interface function. We already have a 'sustained performance' function available on all platforms. If you don't want to put it in there, then you'll have to add a new frontend platform interface function.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/989906696,Add Linux GameMode support,realnc,19,1074820966,12,989906696,0,989874319,2021-12-09T14:32:38Z,"> You missed my point. This _has_ to go inside the unix frontend platform driver. This means it has to be enabled/disabled via a frontend platform interface function. We already have a 'sustained performance' function available on all platforms. If you don't want to put it in there, then you'll have to add a new frontend platform interface function.

Thanks. That makes sense. I'll add a new interface function for this.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/989976815,Add Linux GameMode support,realnc,19,1074820966,13,989976815,0,989906696,2021-12-09T15:49:48Z,@jdgleaver I reworked the PR and it now uses a new platform interface function.,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/990008987,Add Linux GameMode support,jdgleaver,19,1074820966,14,990008987,0,989976815,2021-12-09T16:24:49Z,"Okay, thanks. A couple of things remain:

- You need to call `frontend_unix_set_linux_gamemode(false)` in `frontend_unix_deinit()` if `HAVE_LINUXGAMEMODE` is set

- Calling the frontend interface function `set_linux_gamemode` is somewhat nonsensical, isn't it? Why would we have a Linux-specific function in the frontend drivers for every platform? This should instead be a generic 'game mode' function, which could potentially be used on other platforms (and as such is very much like the existing 'sustained performance' interface function, as I said before...). In this case, all 'linux' references should be removed from the code, with only the menu entry sublabel (and info text) changing to reflect the host platform. In addition, there is no longer a need to gate any of the code outside the frontend driver file behind `HAVE_LINUXGAMEMODE` ifdefs - you can instead show menu options dynamically based on whether the frontend 'game mode' function is non-NULL",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/990159344,Add Linux GameMode support,realnc,19,1074820966,15,990159344,0,990008987,2021-12-09T19:25:12Z,"I did the changes. One thing though:

> all 'linux' references should be removed from the code, with only the menu entry sublabel (and info text) changing to reflect the host platform.

I don't know how to do that for the sublabel text.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/991143156,Add Linux GameMode support,RobLoach,19,1074820966,16,991143156,0,990159344,2021-12-10T17:07:26Z,"> I don't know how to do that for the sublabel text.

Perhaps remove all mention of ""Linux"" throughout then? It's branded as ""GameMode"", so I think that should be enough.",False,0,MEMBER
https://api.github.com/repos/libretro/RetroArch/issues/comments/991149705,Add Linux GameMode support,realnc,19,1074820966,17,991149705,0,991143156,2021-12-10T17:16:25Z,"> > I don't know how to do that for the sublabel text.
> 
> Perhaps remove all mention of ""Linux"" throughout then? It's branded as ""GameMode"", so I think that should be enough.

It's fixed now. Thanks everyone for all the help.

Also, since the GameMode ABI is fixed (commercial games out there already use it and it's never gonna break,) the header is now bundled. It's header-only with no deps.

So this PR is now ready to merge.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/991152131,Add Linux GameMode support,realnc,19,1074820966,18,991152131,0,991149705,2021-12-10T17:19:40Z,"Oh, the C89 test failed. The header uses `//` comments :P",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/991173930,Add Linux GameMode support,realnc,19,1074820966,19,991173930,0,991152131,2021-12-10T17:51:43Z,"OK, should be all good now for merging. Game mode support is now disabled when building in C89 mode. A system so old that needs C89 mode can't have game mode to begin with, since the game mode software itself requires at least C99.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/991625674,Add Linux GameMode support,jdgleaver,19,1074820966,20,991625674,0,991173930,2021-12-11T12:26:48Z,Excellent - this all looks good now.,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/13341,Fix Xbox one and Xbox series x and s threaded video crashes,Jackmath5,9,1075336417,1,1075336417,0,0,2021-12-09T09:17:46Z,"# First and foremost consider this:
- Only RetroArch bugs should be filed here. Not core bugs or game bugs
- This is not a forum or a help section, this is strictly developer oriented

## Description

Fix up Audio latency glitches and Threaded video crashes on Xbox one and Xbox series x/s

### Expected behavior

Can you fix up threaded video for Xbox one and Xbox series x?

### Actual behavior

When Threaded video is turn on the Retroarch crashed on Xbox one and Xbox series x/s

### Steps to reproduce the bug

1. Fix up threaded video crashes
2. Fix up audio latency
3. [and so on...]

### Bisect Results

[Try to bisect and tell us when this started happening]

### Version/Commit
You can find this information under Information/System Information

- RetroArch: any version

### Environment information

- OS: Xbox one and Xbox series x
- Compiler: [In case you are running local builds]
",True,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/1234946758,Fix Xbox one and Xbox series x and s threaded video crashes,LibretroAdmin,9,1075336417,2,1234946758,0,1075336417,2022-09-02T00:47:08Z,"Audio latency 0-11 is unrealistic, won't fix.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/1237048417,Fix Xbox one and Xbox series x and s threaded video crashes,LibretroAdmin,9,1075336417,3,1237048417,0,1234946758,2022-09-05T13:39:47Z,@TheRhysWyrill do you know what he is referring to with regards to these threaded video crashes? Have they been resolved by now?,False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/1237065535,Fix Xbox one and Xbox series x and s threaded video crashes,TheRhysWyrill,9,1075336417,4,1237065535,0,1237048417,2022-09-05T13:49:58Z,"@LibretroAdmin I believe he's referring to the fact that trying to enable the Threaded Video option results in a black screen hard crash, just tested it with the latest master and can confirm it still happens.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/1585794077,Fix Xbox one and Xbox series x and s threaded video crashes,basharast,9,1075336417,5,1585794077,0,1237065535,2023-06-10T20:02:53Z,"There are many issues related to `Threaded Video` crash:
## First
Those lines [here 781](https://github.com/libretro/RetroArch/blob/8a6f7e6fffce7e9ea5bffcb24a4a797fc9635781/uwp/uwp_main.cpp#L781) and [here 821](https://github.com/libretro/RetroArch/blob/8a6f7e6fffce7e9ea5bffcb24a4a797fc9635781/uwp/uwp_main.cpp#L821) at `uwp_main.cpp`
must be called from UI thread.
but that will fix the crash only.

## Second (After fixing the crash)
There is deadlock (I guess) happening at [this function](https://github.com/libretro/RetroArch/blob/8a6f7e6fffce7e9ea5bffcb24a4a797fc9635781/libretro-common/rthreads/rthreads.c#L501) in `rthreads.c`, 
it will freeze at black screen only..

### Stack call for this

1. [void drivers_init](https://github.com/libretro/RetroArch/blob/8a6f7e6fffce7e9ea5bffcb24a4a797fc9635781/retroarch.c#L783)
2. [bool video_driver_init_internal](https://github.com/libretro/RetroArch/blob/8a6f7e6fffce7e9ea5bffcb24a4a797fc9635781/gfx/video_driver.c#L2848)
3. [bool video_thread_init](https://github.com/libretro/RetroArch/blob/8a6f7e6fffce7e9ea5bffcb24a4a797fc9635781/gfx/video_thread_wrapper.c#L680)
4. [void video_thread_wait_reply](https://github.com/libretro/RetroArch/blob/8a6f7e6fffce7e9ea5bffcb24a4a797fc9635781/gfx/video_thread_wrapper.c#LL76C37-L76C37)
5. [void scond_wait](https://github.com/libretro/RetroArch/blob/8a6f7e6fffce7e9ea5bffcb24a4a797fc9635781/libretro-common/rthreads/rthreads.c#L713)

```c
static void video_thread_wait_reply(thread_video_t *thr, thread_packet_t *pkt)
{
   slock_lock(thr->lock);

   while (pkt->type != thr->reply_cmd)
      scond_wait(thr->cond_cmd, thr->lock); //<--- It will stuck here..

   *pkt               = thr->cmd_data;
   thr->cmd_data.type = CMD_VIDEO_NONE;

   slock_unlock(thr->lock);
}
```

I have no idea how the threaded video works or what exactly this function waits for, so wasn't able to fix this freeze.",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/1682960484,Fix Xbox one and Xbox series x and s threaded video crashes,ghost,9,1075336417,6,1682960484,0,1585794077,2023-08-17T20:49:54Z,"I have found a workaround for this on series x for mupen angle core, im on 1.15.0, (for optimal effect first make sure threaded renderer is enabled in mupen core options then close mupen), what i do is i launch a flycast game, then bring up the retroarch menu, then navigate to retroarch video settings, output, and turn on threaded video, then within the same retroarch session i can launch mupen angle core and it will retain threaded video, i have to do this process on every boot of retroarch if i want threaded video with mupen angle or flycast, im not sure if other hardware cores work but the software cores i tested all crash, mesen, mgba, bsnes, genesisplus",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/1684642533,Fix Xbox one and Xbox series x and s threaded video crashes,greenchili2,9,1075336417,7,1684642533,0,1682960484,2023-08-19T01:26:11Z,"Really?  I tried it and as soon as I switch cores it changes back to off.  Although I do find it interesting that retroarch does not crash if you enable it while in the dreamcast core after a game has been started.
",False,0,CONTRIBUTOR
https://api.github.com/repos/libretro/RetroArch/issues/comments/1684764329,Fix Xbox one and Xbox series x and s threaded video crashes,ghost,9,1075336417,8,1684764329,0,1684642533,2023-08-19T03:57:39Z,"> Really? I tried it and as soon as I switch cores it changes back to off. Although I do find it interesting that retroarch does not crash if you enable it while in the dreamcast core after a game has been started.

i corrected my comment above, i should have mentioned i only tested with mupen angle core, the software cores all crash in my tests with this trick, bsnes, mesen, mgba, genesisplus etc, though i have no other hardware cores to test so i wonder if someone could test this trick on other hardware cores and see if it works",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/1870781776,Fix Xbox one and Xbox series x and s threaded video crashes,ghost,9,1075336417,9,1870781776,0,1684764329,2023-12-28T03:09:15Z,"Hi @basharast , threaded video can be activated without crashing/freezing on xbox series, this can be done by first launching a hardware core like flycast or swanstation then go into retroarch video settings and enable threaded video, do you have an idea what is happening in this context that allows threaded video to be enabled without crashing?",False,0,NONE
https://api.github.com/repos/libretro/RetroArch/issues/comments/1876930354,Fix Xbox one and Xbox series x and s threaded video crashes,basharast,9,1075336417,10,1876930354,0,1870781776,2024-01-04T11:20:15Z,"> Hi @basharast , threaded video can be activated without crashing/freezing on xbox series, this can be done by first launching a hardware core like flycast or swanstation then go into retroarch video settings and enable threaded video, do you have an idea what is happening in this context that allows threaded video to be enabled without crashing?

Hi, sorry this part is beyond my understanding in `C` language, but as for the part that related to UWP as I mentioned above there is minor issue related to UI thread can be easily solved, when this part is fixed it will be easier for some one with better experience in `C` to solve the problem.",False,0,CONTRIBUTOR
https://api.github.com/repos/scikit-learn/scikit-learn/issues/21894,MAINT set testpaths = sklearn for pytest in setup.cfg,ogrisel,3,1072030301,1,1072030301,0,0,2021-12-06T11:17:02Z,"I think this will make the maintenance more robust and avoid running expensive Python code with potentially detrimental side-effects by mistake when pytest is scanning and importing Python files for test collection.

It just happened to myself with a temporary benchmark script I left in the root of the source folder and was causing trouble with high CPU usage on my machine with the VS Code pytest plugin.",True,0,MEMBER
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/986866149,MAINT set testpaths = sklearn for pytest in setup.cfg,ogrisel,3,1072030301,2,986866149,0,1072030301,2021-12-06T15:10:50Z,"Note that while investigating issues with my setup, I also found out that the `--color=yes` option was making the contents of the ""Python Test Log"" output panel very hard to read because the log viewer does not render the ANSI escape code sequences.

I reported the problem upstream under https://github.com/microsoft/vscode-python/issues/18119. The pytest plugin still works though if you do not care about the ""Python Test Log"" view.

If the issue is fixed upstream quickly, we might want to keep that option as is. Otherwise we could also remove it from our `setup.cfg` and add it specifically in the pytest command-lines of the CI scripts instead.",False,0,MEMBER
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/986874161,MAINT set testpaths = sklearn for pytest in setup.cfg,ogrisel,3,1072030301,3,986874161,0,986866149,2021-12-06T15:18:34Z,"> I'm okay with removing it and only running it in CI.

I find it nice to have the colors in the term by default though. So let's wait for a day or two to see how they react for the color problem.",False,0,MEMBER
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/987930667,MAINT set testpaths = sklearn for pytest in setup.cfg,ogrisel,3,1072030301,4,987930667,0,986874161,2021-12-07T13:33:49Z,Let me merge this. It's easy to revert if it has an unintended side effect.,False,0,MEMBER
https://api.github.com/repos/scikit-learn/scikit-learn/issues/21895,GridSearchCV & RandomizedSearchCV has a ranking issue when test scores are same.,AChand20,13,1072030743,1,1072030743,0,0,2021-12-06T11:17:28Z,"### Describe the bug

During best parameter candidate search when two parameter candidates have the same `mean_test_<scorer_name>` then the `rank_test_<scorer_name>` ranks them the same, and if both have rank 1 then the algorithm picks the one that come first.

### Steps/Code to Reproduce

```python
from sklearn import svm, datasets
import pandas as pd
import numpy as np
from sklearn.model_selection import GridSearchCV
iris = datasets.load_iris()
def grid_search(parameters):
    svc = svm.SVC()
    clf = GridSearchCV(svc, parameters,return_train_score=True)
    clf.fit(iris.data, iris.target)
    print(pd.DataFrame(clf.cv_results_)[['param_C','param_kernel','mean_test_score','rank_test_score','mean_train_score']])
    print('best_parameters = ',clf.best_params_,'\n')

params = {'kernel':('linear', 'rbf'), 'C':[1, 10]}
grid_search(params)
params = {'kernel':('rbf', 'linear'), 'C':[10, 1]}
grid_search(params)
```

### Expected Results

Both function calls should return the same output for `clf.best_params_` 
i.e  `best_parameters =  {'C': 1, 'kernel': 'linear'}`  because the difference between the `mean_train_score` and the `mean_test_score` is the least for this parameter candidate.

### Actual Results

![scikit-learn_bug](https://user-images.githubusercontent.com/20677278/144828758-b6b8820a-d595-4194-8cb1-246606b91925.JPG)

### Versions

```

System:
    python: 3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]
executable: C:\Anaconda3\anaconda3\envs\sklearndev\python.exe
   machine: Windows-10-10.0.19043-SP0

Python dependencies:
          pip: 21.2.4
   setuptools: 58.0.4
      sklearn: 1.1.dev0
        numpy: 1.21.2
        scipy: 1.7.1
       Cython: 0.29.24
       pandas: 1.3.4
   matplotlib: 3.5.0
       joblib: 1.1.0
threadpoolctl: 3.0.0

Built with OpenMP: True

threadpoolctl info:
       user_api: blas
   internal_api: mkl
         prefix: mkl_rt
       filepath: C:\Anaconda3\anaconda3\envs\sklearndev\Library\bin\mkl_rt.1.dll
        version: 2021.4-Product
threading_layer: intel
    num_threads: 2

user_api: openmp
   internal_api: openmp
         prefix: vcomp
       filepath: C:\Windows\System32\vcomp140.dll
        version: None
    num_threads: 4
```",True,0,NONE
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/986688612,GridSearchCV & RandomizedSearchCV has a ranking issue when test scores are same.,AChand20,13,1072030743,2,986688612,0,1072030743,2021-12-06T11:28:12Z,I would like to work on this issue if the bug gets confirmed.,False,0,NONE
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/987958262,GridSearchCV & RandomizedSearchCV has a ranking issue when test scores are same.,Nivi09,13,1072030743,3,987958262,0,986688612,2021-12-07T14:07:38Z,"Hello, I would like to work on this issue.",False,0,NONE
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/987999623,GridSearchCV & RandomizedSearchCV has a ranking issue when test scores are same.,thomasjpfan,13,1072030743,4,987999623,0,987958262,2021-12-07T14:53:20Z,"The issue with using `train_score` is that it does not describe the generalized performance of the configuration. Also it is only available if `return_train_score=True`. If we do want to rank parameters with the same mean test performance, then I think using the `fit` time would be better. In this case, when configurations have the same `mean_test_score`, then the configuration that fitted quicker will be ranked higher.

Any change to the ranking will break backward compatibility. It would be best to get opinions from other maintainers before getting started.",False,0,MEMBER
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/988579845,GridSearchCV & RandomizedSearchCV has a ranking issue when test scores are same.,AChand20,13,1072030743,5,988579845,0,987999623,2021-12-08T07:55:53Z,"> The issue with using `train_score` is that it does not describe the generalized performance of the configuration. Also it is only available if `return_train_score=True`. If we do want to rank parameters with the same mean test performance, then I think using the `fit` time would be better. In this case, when configurations have the same `mean_test_score`, then the configuration that fitted quicker will be ranked higher.
> 
> Any change to the ranking will break backward compatibility. It would be best to get opinions from other maintainers before getting started.

But `fit time` is not a consistent variable. It will change the rank every time we run the code (Tested this on the example code above). 
How about we don't change the ranking, instead we return all configurations that have the same `mean_test_score` and are ranked 1. 

So now in my particular example above `clf.best_params_` will return both parameter candidates and the end user will try both and choose the one that performs best for his test data.",False,0,NONE
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/988825731,GridSearchCV & RandomizedSearchCV has a ranking issue when test scores are same.,Nivi09,13,1072030743,6,988825731,0,988579845,2021-12-08T13:43:26Z,"Hello @AChand20 and @thomasjpfan, as AChand20 mentioned, I also thought of the same thing. 

Two approaches, :
1. return all in best_aparams having same mean test score
2. Sort the parameters combination having same mean test score in lexicographical order and return the top most.

I would like to work on this. Please let me know if my approach is correct and if I can start to work on this.",False,0,NONE
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/989988554,GridSearchCV & RandomizedSearchCV has a ranking issue when test scores are same.,thomasjpfan,13,1072030743,7,989988554,0,988825731,2021-12-09T16:02:33Z,"> But fit time is not a consistent variable. It will change the rank every time we run the code (Tested this on the example code above).

Good point. In that case fit time is not the most stable way to rank parameter candidates.

> So now in my particular example above clf.best_params_ will return both parameter candidates 

In the end `*SearchCV` will be refitted on the complete dataset with one parameter configuration. Even if `clf.best_params_` returns a multiple candidates, `*SearchCV` will still need to decide which candidates to use to refit on the complete dataset. 

> Sort the parameters combination having same mean test score in lexicographical order and return the top most.

Having a stable way to pick between candidates with the same rank is a good stop gap solution.
",False,0,MEMBER
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/990824912,GridSearchCV & RandomizedSearchCV has a ranking issue when test scores are same.,Nivi09,13,1072030743,8,990824912,0,989988554,2021-12-10T10:30:23Z,"@thomasjpfan Hi Thomas, Would you please elaborate a bit more on - 'Having a stable way to pick between candidates with the same rank is a good stop gap solution.' ? If you can provide any guidance to me, I will be thankful to you. ",False,0,NONE
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/991039654,GridSearchCV & RandomizedSearchCV has a ranking issue when test scores are same.,thomasjpfan,13,1072030743,9,991039654,0,990824912,2021-12-10T14:55:44Z,"I think you already proposed a solution in https://github.com/scikit-learn/scikit-learn/pull/21925. Please update the opening message in the PR to describe what you mean by ""lexicographical sort"".",False,0,MEMBER
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/991495918,GridSearchCV & RandomizedSearchCV has a ranking issue when test scores are same.,AChand20,13,1072030743,10,991495918,0,991039654,2021-12-11T06:54:57Z,"Then I think we should go for a stable way to pick between candidates as suggested by **@thomasjpfan** , and if ""lexicographical sort"" provides this stability then we should go for it. 
Yes, updating the opening message in PR  #21925 would be helpful.

Moreover if this issue is confirmed as a 'Bug', can someone change the label of this issue from 'Bug: triage' to 'Bug'.",False,0,NONE
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/991625886,GridSearchCV & RandomizedSearchCV has a ranking issue when test scores are same.,Nivi09,13,1072030743,11,991625886,0,991495918,2021-12-11T12:27:38Z,"@AChand20 , @thomasjpfan Have test and implemented the sorting and all local tests have passed. But azurebuild-piplines test has failed as it is asserting on the values that you will get using the previous implementation which we are trying to resolve. So looks like need to change some test output value. Working on that. I will update the detailed approach in PR.",False,0,NONE
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/998627946,GridSearchCV & RandomizedSearchCV has a ranking issue when test scores are same.,Nivi09,13,1072030743,12,998627946,0,991625886,2021-12-21T09:46:34Z,"@AChand20 , @thomasjpfan 

Hello, I have updated the PR. 
Can anyone of you please have a look and provide feedback on the approach and if there is anything that can be improved or modified? 
Thank you in advance.

Regards. ",False,0,NONE
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/998860700,GridSearchCV & RandomizedSearchCV has a ranking issue when test scores are same.,thomasjpfan,13,1072030743,13,998860700,0,998627946,2021-12-21T15:15:11Z,"For future reference, it is best to ping in the PR when you want attention on a PR. This makes the notification link directly to the PR.",False,0,MEMBER
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/1246003536,GridSearchCV & RandomizedSearchCV has a ranking issue when test scores are same.,thomasjpfan,13,1072030743,14,1246003536,0,998860700,2022-09-13T22:14:28Z,"As noted in https://github.com/scikit-learn/scikit-learn/pull/21925#issuecomment-1246002997 and https://github.com/scikit-learn/scikit-learn/pull/21925#issuecomment-1246437958, I think this is more of a documentation issue on how we rank ties. A long term solution would be to have a callable to allow users to specific how they want to rank the results.",False,0,MEMBER
https://api.github.com/repos/scikit-learn/scikit-learn/issues/21897,"CircleCI failure on ""doc"" build",adrinjalali,10,1072239485,1,1072239485,0,0,2021-12-06T14:49:24Z,"Since ""CI Simplier wheel building config [cd build gh] (#21849)"" circleci has been consistently failing around an example which does not take long at all when run locally. It also doesn't fail on `doc-min-dependencies`. Here's an [example CI run](https://app.circleci.com/pipelines/github/scikit-learn/scikit-learn/20896/workflows/6f731efa-bb1f-439f-8f1d-01c62e483829/jobs/165939) with the following log.

Luckily this is not blocking our PR CIs since we don't build the full documentation there.

ping @glemaitre @lesteve and @thomasjpfan 

<details>

```
generating gallery for auto_examples/neighbors... [  7%] plot_regression.py
generating gallery for auto_examples/neighbors... [ 15%] plot_lof_outlier_detection.py
generating gallery for auto_examples/neighbors... [ 23%] plot_nearest_centroid.py
generating gallery for auto_examples/neighbors... [ 30%] plot_digits_kde_sampling.py
generating gallery for auto_examples/neighbors... [ 38%] plot_classification.py
generating gallery for auto_examples/neighbors... [ 46%] plot_caching_nearest_neighbors.py
generating gallery for auto_examples/neighbors... [ 53%] plot_nca_illustration.py
generating gallery for auto_examples/neighbors... [ 61%] plot_nca_dim_reduction.py
generating gallery for auto_examples/neighbors... [ 69%] plot_lof_novelty_detection.py
generating gallery for auto_examples/neighbors... [ 76%] plot_nca_classification.py
generating gallery for auto_examples/neighbors... [ 84%] plot_species_kde.py
generating gallery for auto_examples/neighbors... [ 92%] plot_kde_1d.py
generating gallery for auto_examples/neighbors... [100%] approximate_nearest_neighbors.py

generating gallery for auto_examples/neural_networks... [ 25%] plot_mnist_filters.py
make: *** [Makefile:48: html] Killed

Too long with no output (exceeded 10m0s): context deadline exceeded
```

</details>",True,0,MEMBER
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/986862136,"CircleCI failure on ""doc"" build",glemaitre,10,1072239485,2,986862136,0,1072239485,2021-12-06T15:07:03Z,I tried to reproduce locally with the same environment on a linux machine and building the full documentation and everything went fine. I will try to send a build and connect via ssh to the machine on CircleCI but this is a rather complicated issue.,False,0,MEMBER
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/986947447,"CircleCI failure on ""doc"" build",thomasjpfan,10,1072239485,3,986947447,0,986862136,2021-12-06T16:37:43Z,"Copying my response from https://github.com/scikit-learn/scikit-learn/pull/21859:

> From past experience with circleci + doc building, it usually comes down to memory issues. I recall doing experiments on `fetch_openml` + mnist that it takes quite a bit of memory to load: https://github.com/scikit-learn/scikit-learn/issues/19774 and the circleci instance only has 4gb.",False,0,MEMBER
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/988101582,"CircleCI failure on ""doc"" build",adrinjalali,10,1072239485,4,988101582,0,986947447,2021-12-07T16:51:39Z,"Two things that come in mind:

We switched the mnist to use the one which has 70k samples instead of 62k. We could create a small mnist dataset on openml with 20k samples, which should be enough for our examples and use that one.

What happened to moving doc build to azure? I can't find the PR, was @jjerphan working on it? Not sure.",False,0,MEMBER
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/988107349,"CircleCI failure on ""doc"" build",jjerphan,10,1072239485,5,988107349,0,988101582,2021-12-07T16:59:17Z,"> What happened to moving doc build to azure? I can't find the PR, was @jjerphan working on it? Not sure.

@adrinjalali: are you referring to https://github.com/scikit-learn/scikit-learn/pull/21721 (which was superseded by https://github.com/scikit-learn/scikit-learn/pull/21715)?",False,0,MEMBER
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/988122515,"CircleCI failure on ""doc"" build",adrinjalali,10,1072239485,6,988122515,0,988107349,2021-12-07T17:19:42Z,"No, the idea was to build the docs on azure, and then use circleci only to store the artifacts. Or maybe the idea was to build them on GitHub actions, not sure. But either way, it would make us not use circleci for such long builds anymore.",False,0,MEMBER
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/988128769,"CircleCI failure on ""doc"" build",jjerphan,10,1072239485,7,988128769,0,988122515,2021-12-07T17:28:09Z,"I see, apart from simple hotfixes I have not worked actively on the CI lately.

The two PR I worked on for the CI are https://github.com/scikit-learn/scikit-learn/pull/21744 and https://github.com/scikit-learn/scikit-learn/pull/21174.",False,0,MEMBER
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/988315151,"CircleCI failure on ""doc"" build",thomasjpfan,10,1072239485,8,988315151,0,988128769,2021-12-07T22:44:17Z,I will prioritize working on moving doc building away from circleci this week with my plan outlined in https://github.com/scikit-learn/scikit-learn/issues/21068.,False,0,MEMBER
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/989019918,"CircleCI failure on ""doc"" build",lesteve,10,1072239485,9,989019918,0,988315151,2021-12-08T17:28:00Z,"I opened #21922 as a potential quick fix (it considerably reduces memory usage for mnist dataset by using `as_frame=False`).

 By the way the last build on master of the doc is green https://app.circleci.com/pipelines/github/scikit-learn/scikit-learn/20979/workflows/f4efceec-734e-4c10-88d9-9add8d632379/jobs/166261 whereas it has been consistently red for some time :man_shrugging: ...",False,0,MEMBER
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/989025429,"CircleCI failure on ""doc"" build",glemaitre,10,1072239485,10,989025429,0,989019918,2021-12-08T17:34:46Z,"> I opened #21922 as a potential quick fix (it considerably reduces memory usage for mnist dataset by using as_frame=False).

By how much? Is it that we have fewer copies going in the ARFF reader?",False,0,MEMBER
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/989679658,"CircleCI failure on ""doc"" build",lesteve,10,1072239485,11,989679658,0,989025429,2021-12-09T09:44:26Z,"> By how much? Is it that we have fewer copies going in the ARFF reader?

I sprinkled comments in different issues ... more details are here: https://github.com/scikit-learn/scikit-learn/issues/19774#issuecomment-988995348",False,0,MEMBER
https://api.github.com/repos/scikit-learn/scikit-learn/issues/21898,Link airspeed benchmarks page in the scikit-learn webpage,lorentzenchr,5,1072260206,1,1072260206,0,0,2021-12-06T15:07:34Z,"### Describe the issue linked to the documentation

Link the site https://scikit-learn.org/scikit-learn-benchmarks/ and https://github.com/scikit-learn/scikit-learn-benchmarks in the homepage https://scikit-learn.org.

Follow-up on #17026",True,0,MEMBER
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/989930197,Link airspeed benchmarks page in the scikit-learn webpage,ogrisel,5,1072260206,2,989930197,0,1072260206,2021-12-09T14:58:24Z,"We could also find a way to generate a new (static) badge for the README.rst.

```
[![asv](http://img.shields.io/badge/benchmarked%20by-asv-blue.svg?style=flat)](https://scikit-learn.org/scikit-learn-benchmarks/ )
```

that should render as: [![asv](http://img.shields.io/badge/benchmarked%20by-asv-blue.svg?style=flat)](https://scikit-learn.org/scikit-learn-benchmarks/ )

EDIT: actually the syntax above is for markdown. It would need to be adapted to use the reStructuredText syntax instead for our README.rst file.",False,0,MEMBER
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/991761118,Link airspeed benchmarks page in the scikit-learn webpage,ojeda-e,5,1072260206,3,991761118,0,989930197,2021-12-11T19:37:11Z,Can I help with this? @ogrisel ,False,0,CONTRIBUTOR
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/992673275,Link airspeed benchmarks page in the scikit-learn webpage,lorentzenchr,5,1072260206,4,992673275,0,991761118,2021-12-13T16:52:58Z,"#21956 put the link in form of a badge to the README in github.

Question: Shall we also put the link somewhere on the website?",False,0,MEMBER
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/992680467,Link airspeed benchmarks page in the scikit-learn webpage,ogrisel,5,1072260206,5,992680467,0,992673275,2021-12-13T17:01:26Z,"> Question: Shall we also put the link somewhere on the website?

+1 for adding a link to `doc/developers/contributing.rst`  in the intro paragraph of the section named [Monitoring Performance](https://scikit-learn.org/dev/developers/contributing.html#monitoring-performance).",False,0,MEMBER
https://api.github.com/repos/scikit-learn/scikit-learn/issues/comments/1001109213,Link airspeed benchmarks page in the scikit-learn webpage,ohadmich,5,1072260206,6,1001109213,0,992680467,2021-12-26T05:37:48Z,take,False,0,CONTRIBUTOR
https://api.github.com/repos/JuliaLang/julia/issues/43480, release-1.7: set VERSION to 1.7.1,KristofferC,12,1084099579,1,1084099579,0,0,2021-12-19T13:34:35Z,,True,0,MEMBER
https://api.github.com/repos/JuliaLang/julia/issues/comments/997566317, release-1.7: set VERSION to 1.7.1,vtjnash,12,1084099579,2,997566317,0,1084099579,2021-12-20T03:37:51Z,"@nanosoldier `runtests(""shootout"", vs=""#v1.7.0"")`",False,0,MEMBER
https://api.github.com/repos/JuliaLang/julia/issues/comments/997567092, release-1.7: set VERSION to 1.7.1,vtjnash,12,1084099579,3,997567092,0,997566317,2021-12-20T03:40:40Z,"@nanosoldier `runbenchmarks(""shootout"", vs=""#v1.7.0"")`",False,0,MEMBER
https://api.github.com/repos/JuliaLang/julia/issues/comments/997568540, release-1.7: set VERSION to 1.7.1,nanosoldier,12,1084099579,4,997568540,0,997567092,2021-12-20T03:45:47Z,"Something went wrong when running [your job](https://github.com/JuliaLang/julia/pull/43480#issuecomment-997567092):
```
CompositeException(Any[TaskFailedException(Task (failed) @0x00007fff608a7c70)])
```
",False,0,COLLABORATOR
https://api.github.com/repos/JuliaLang/julia/issues/comments/997573224, release-1.7: set VERSION to 1.7.1,nanosoldier,12,1084099579,5,997573224,0,997568540,2021-12-20T04:02:08Z,"Something went wrong when running [your job](https://github.com/JuliaLang/julia/pull/43480#issuecomment-997566317):
```
NanosoldierError: failed to run tests: MethodError: no method matching read_pkgs(::String)
Closest candidates are:
  read_pkgs() at /storage/pkgeval/depot/packages/PkgEval/a8wK1/src/registry.jl:39
  read_pkgs(!Matched::Vector{String}; registry) at /storage/pkgeval/depot/packages/PkgEval/a8wK1/src/registry.jl:39
```
Logs and partial data can be found [here](https://github.com/JuliaCI/NanosoldierReports/blob/master/pkgeval/by_hash/b36816a_vs_3bf9d17/report.md)
cc @maleadt",False,0,COLLABORATOR
https://api.github.com/repos/JuliaLang/julia/issues/comments/997574164, release-1.7: set VERSION to 1.7.1,vtjnash,12,1084099579,6,997574164,0,997573224,2021-12-20T04:04:00Z,"@nanosoldier `runbenchmarks(""shootout"", vs=""#v1.7.0"")`",False,0,MEMBER
https://api.github.com/repos/JuliaLang/julia/issues/comments/997574395, release-1.7: set VERSION to 1.7.1,nanosoldier,12,1084099579,7,997574395,0,997574164,2021-12-20T04:04:27Z,"Something went wrong when running [your job](https://github.com/JuliaLang/julia/pull/43480#issuecomment-997574164):
```
CompositeException(Any[TaskFailedException(Task (failed) @0x00007fff91d0c940)])
```
",False,0,COLLABORATOR
https://api.github.com/repos/JuliaLang/julia/issues/comments/997576975, release-1.7: set VERSION to 1.7.1,vtjnash,12,1084099579,8,997576975,0,997574395,2021-12-20T04:09:12Z,"@nanosoldier `runbenchmarks(""shootout"", vs=""#v1.7.0"")`",False,0,MEMBER
https://api.github.com/repos/JuliaLang/julia/issues/comments/997584811, release-1.7: set VERSION to 1.7.1,nanosoldier,12,1084099579,9,997584811,0,997576975,2021-12-20T04:24:52Z,[Your benchmark job](https://github.com/JuliaLang/julia/pull/43480#issuecomment-997576975) has completed - no performance regressions were detected. A full report can be found [here](https://github.com/JuliaCI/NanosoldierReports/blob/master/benchmark/by_hash/bae2d8d_vs_3bf9d17/report.md).,False,0,COLLABORATOR
https://api.github.com/repos/JuliaLang/julia/issues/comments/997773009, release-1.7: set VERSION to 1.7.1,KristofferC,12,1084099579,10,997773009,0,997584811,2021-12-20T10:01:05Z,"@nanosoldier `runbenchmarks(ALL, vs=""#v1.7.0"")`",False,0,MEMBER
https://api.github.com/repos/JuliaLang/julia/issues/comments/998045154, release-1.7: set VERSION to 1.7.1,nanosoldier,12,1084099579,11,998045154,0,997773009,2021-12-20T15:49:18Z,"[Your benchmark job](https://github.com/JuliaLang/julia/pull/43480#issuecomment-997772637) has completed, but no benchmarks were actually executed. Perhaps your tag predicate contains misspelled tags? cc @",False,0,COLLABORATOR
https://api.github.com/repos/JuliaLang/julia/issues/comments/998334916, release-1.7: set VERSION to 1.7.1,nanosoldier,12,1084099579,12,998334916,0,998045154,2021-12-20T23:06:41Z,"Something went wrong when running [your job](https://github.com/JuliaLang/julia/pull/43480#issuecomment-997773009):
```
NanosoldierError: error when preparing/pushing to report repo: failed process: Process(setenv(`git push`; dir=""/data/nanosoldier/workdir/NanosoldierReports""), ProcessExited(1)) [1]

```
Unfortunately, the logs could not be uploaded.
",False,0,COLLABORATOR
https://api.github.com/repos/JuliaLang/julia/issues/comments/998372759, release-1.7: set VERSION to 1.7.1,vtjnash,12,1084099579,13,998372759,0,998334916,2021-12-21T00:36:38Z,https://github.com/JuliaCI/NanosoldierReports/blob/master/benchmark/by_hash/bae2d8d_vs_3bf9d17/report.md,False,0,MEMBER
https://api.github.com/repos/JuliaLang/julia/issues/43481,Mark stack as non-executable,nalimilan,7,1084127628,1,1084127628,0,0,2021-12-19T15:45:14Z,"The linker is unable to detect that executable stack is not required and so marks libjulia.so as requiring it
Pass `-Wl,-z,noexecstack` to ensure that the stack is marked as not executable.
This improves security and allows Julia to run on systems where SELinux has been configured to disallow executable stacks.

AFAIK no change is needed on OSes other than Linux as they do not allow executable stacks by default.

Tests will fail until https://github.com/JuliaLinearAlgebra/libblastrampoline/pull/51 is merged and libblatrampoline is updated, as libblastrampoline.so is also affected by the same problem.",True,0,MEMBER
https://api.github.com/repos/JuliaLang/julia/issues/comments/997712806,Mark stack as non-executable,inkydragon,7,1084127628,2,997712806,0,1084127628,2021-12-20T08:41:25Z,"By default, many dependencies are built by directly downloading the compiled binaries of BinaryBuilder.jl.
> When compiled the first time, the build will automatically download pre-built external dependencies. 
>
> —— [julia/build.md at master · JuliaLang/julia](https://github.com/JuliaLang/julia/blob/master/doc/src/devdocs/build/build.md#building-julia)

For example: All dependencies in the [`deps\checksums`](https://github.com/JuliaLang/julia/tree/master/deps/checksums) folder

Should we update the BinaryBuilder build settings for julia-related dependencies?
e.g: [SuiteSparse · JuliaPackaging/Yggdrasil](https://github.com/JuliaPackaging/Yggdrasil/blob/master/S/SuiteSparse/SuiteSparse/build_tarballs.jl#L20-L26)

Is this link parameter necessary as a default setting for the global build of BinaryBuilder?",False,0,MEMBER
https://api.github.com/repos/JuliaLang/julia/issues/comments/997804847,Mark stack as non-executable,nalimilan,7,1084127628,3,997804847,0,997712806,2021-12-20T10:40:11Z,"No it shouldn't be needed in general, it's only for some libraries (here libjulia.so and libblastrampoline.so) for which the linker wasn't able to detect that they don't need an executable stack.",False,0,MEMBER
https://api.github.com/repos/JuliaLang/julia/issues/comments/1046039735,Mark stack as non-executable,ViralBShah,7,1084127628,4,1046039735,0,997804847,2022-02-19T15:10:25Z,The LBT PR referred to is merged and pulled in here. Just wondering if the next step is to revive this.,False,0,MEMBER
https://api.github.com/repos/JuliaLang/julia/issues/comments/1046057220,Mark stack as non-executable,nalimilan,7,1084127628,5,1046057220,0,1046039735,2022-02-19T16:42:58Z,"Julia is still using an old libblastrampoline AFAICT, while we need at least version 4.

@staticfloat Is there any reason not to update it?",False,0,MEMBER
https://api.github.com/repos/JuliaLang/julia/issues/comments/1046117321,Mark stack as non-executable,ViralBShah,7,1084127628,6,1046117321,0,1046057220,2022-02-19T22:38:40Z,We are on version 5 of LBT. blastrampoline.version was behind and that was just fixed in https://github.com/JuliaLang/julia/pull/44258,False,0,MEMBER
https://api.github.com/repos/JuliaLang/julia/issues/comments/1046575290,Mark stack as non-executable,nalimilan,7,1084127628,7,1046575290,0,1046117321,2022-02-21T08:05:08Z,"OK, should be good to merge now.",False,0,MEMBER
https://api.github.com/repos/JuliaLang/julia/issues/comments/1046932236,Mark stack as non-executable,ViralBShah,7,1084127628,8,1046932236,0,1046575290,2022-02-21T14:22:13Z,"I don't have much experience with this linker flag, but it seems that tests are passing everywhere. Maybe good to see if @staticfloat and/or @giordano can take a look.",False,0,MEMBER
https://api.github.com/repos/JuliaLang/julia/issues/43482,better way to reverse a reverse iterator?,StephenVavasis,3,1084133637,1,1084133637,0,0,2021-12-19T16:11:13Z,"According to the documentation, if `itr` is an iterator and `r = reverse(itr)`, then the original iterator `itr` is obtained via `r.itr`.  This API (of retrieving `itr` by querying the field `.itr`) is not very Julian and also limits the possible implementations available to a package-writer.   Could I suggest instead that the original iterator `itr` be obtained via `reverse(r)`? ",True,0,CONTRIBUTOR
https://api.github.com/repos/JuliaLang/julia/issues/comments/997451730,better way to reverse a reverse iterator?,mcabbott,3,1084133637,2,997451730,0,1084133637,2021-12-19T19:59:05Z,"Doesn't this already work?
```
julia> Iterators.Reverse(1:3)
Base.Iterators.Reverse{UnitRange{Int64}}(1:3)

julia> Iterators.reverse(ans)
1:3
```
I think that line in the documentation of `Iterators.reverse` is a hint on how to write implementations, maybe it should be removed. What this function returns may not have a field `.itr` at all, so that certainly isn't the recommended way to un-do it:
```
julia> Iterators.reverse(1:3)
3:-1:1

julia> Iterators.reverse(x for x in 1:3)
Base.Generator{StepRange{Int64, Int64}, typeof(identity)}(identity, 3:-1:1)
```",False,0,CONTRIBUTOR
https://api.github.com/repos/JuliaLang/julia/issues/comments/999608643,better way to reverse a reverse iterator?,stevengj,3,1084133637,3,999608643,0,997451730,2021-12-22T14:15:42Z,"> I think that line in the documentation of Iterators.reverse is a hint on how to write implementations, maybe it should be removed.

Yes, it was intended as documentation for people writing methods for `iterate(foo::Iterators.Reverse{Foo})` (as is explicit in the text ""To implement these methods, …"").",False,0,MEMBER
https://api.github.com/repos/JuliaLang/julia/issues/comments/999609709,better way to reverse a reverse iterator?,stevengj,3,1084133637,4,999609709,0,999608643,2021-12-22T14:17:18Z,The docs should be clarified (#43522).,False,0,MEMBER
https://api.github.com/repos/JuliaLang/julia/issues/43485,New multithreading segfault in RayTracingWeekend.jl,claforte,15,1084188772,1,1084188772,0,0,2021-12-19T20:52:17Z,"For full context, see https://discourse.julialang.org/t/ray-tracing-in-a-week-end-julia-vs-simd-optimized-c/72958/60

versioninfo():
```
Julia Version 1.6.1
Commit 6aaedecc44 (2021-04-23 05:59 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: AMD Ryzen 7 3700X 8-Core Processor
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-11.0.1 (ORCJIT, znver2)
Environment:
  JULIA_DEPOT_PATH = ~/.julia/depot
```

Reproduction steps:
1. `git clone https://github.com/claforte/RayTracingWeekend.jl`
2. `cd RayTracingWeekend.jl/`
2. `git checkout claforte/threads_crash1`
3. `cd src/proto`
4. Start Julia with some threads, e.g. 
   `julia --project=. --threads=8 repro_crash.jl`

I commented out the call to @threads, so you can first verify that it runs normally. (And if you open it in vscode or juno and run through each line, you'll see that the last line produces a small raytraced image, like this:

![image](https://user-images.githubusercontent.com/5090329/146690268-4cf70364-418a-46fe-8b60-4384ffd2a1dc.png)

5. To trigger the crash, uncomment the `Thread.@threads` in `src/RayTracingWeekend.jl`, i.e. replace:
```
#Threads.@threads # claforte: uncomment for CRASH?!
	for i in 1:image_height
```
by 
```
Threads.@threads for i in 1:image_height
```
6. Re-run step 4. I consistently get this kind of segmentation fault:

```
claforte@ub-claforte:~/.julia/depot/dev/RayTracingWeekend/src/proto$ julia --project=. --threads=8 repro_crash.jl 

signal (11): Segmentation fault
in expression starting at /home/claforte/.julia/depot/dev/RayTracingWeekend/src/proto/repro_crash.jl:6
jl_lookup_generic_ at /buildworker/worker/package_linux64/build/src/gf.c:2347 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2415
wait at ./task.jl:322 [inlined]
threading_run at ./threadingconstructs.jl:34
macro expansion at ./threadingconstructs.jl:93 [inlined]
render at /home/claforte/.julia/depot/dev/RayTracingWeekend/src/RayTracingWeekend.jl:331
unknown function (ip: 0x7ff85b9985f7)
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2237 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2419
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1703 [inlined]
do_call at /buildworker/worker/package_linux64/build/src/interpreter.c:115
eval_value at /buildworker/worker/package_linux64/build/src/interpreter.c:204
eval_stmt_value at /buildworker/worker/package_linux64/build/src/interpreter.c:155 [inlined]
eval_body at /buildworker/worker/package_linux64/build/src/interpreter.c:562
jl_interpret_toplevel_thunk at /buildworker/worker/package_linux64/build/src/interpreter.c:670
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:877
jl_toplevel_eval_flex at /buildworker/worker/package_linux64/build/src/toplevel.c:825
jl_toplevel_eval_in at /buildworker/worker/package_linux64/build/src/toplevel.c:929
eval at ./boot.jl:360 [inlined]
include_string at ./loading.jl:1094
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2237 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2419
_include at ./loading.jl:1148
include at ./Base.jl:386
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2237 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2419
exec_options at ./client.jl:285
_start at ./client.jl:485
jfptr__start_34289.clone_1 at /home/claforte/.julia/lib/julia/sys.so (unknown line)
_jl_invoke at /buildworker/worker/package_linux64/build/src/gf.c:2237 [inlined]
jl_apply_generic at /buildworker/worker/package_linux64/build/src/gf.c:2419
jl_apply at /buildworker/worker/package_linux64/build/src/julia.h:1703 [inlined]
true_main at /buildworker/worker/package_linux64/build/src/jlapi.c:560
repl_entrypoint at /buildworker/worker/package_linux64/build/src/jlapi.c:702
main at julia (unknown line)
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4007d8)
Allocations: 12282419 (Pool: 12278054; Big: 4365); GC: 5
Segmentation fault (core dumped)
```",True,0,NONE
https://api.github.com/repos/JuliaLang/julia/issues/comments/997461292,New multithreading segfault in RayTracingWeekend.jl,claforte,15,1084188772,2,997461292,0,1084188772,2021-12-19T21:06:21Z,"I verified that the problem is somehow tied to my recent splitting of classes/functions from one monolithic file (src/old_proto.jl) into:
1. reusable stuff that went in `src/RayTracingWeekend.jl`
2. tests, e.g. `src/proto/repro_crash.jl`

If I run the old code (that defines classes/functions and runs tests along the way) `src/old_proto.jl` with the same environment (or with the `RayTracingWeekend` environment), it still works fine.",False,0,NONE
https://api.github.com/repos/JuliaLang/julia/issues/comments/997462294,New multithreading segfault in RayTracingWeekend.jl,paulmelis,15,1084188772,3,997462294,0,997461292,2021-12-19T21:14:47Z,Might be caused by accessing the image array from multiple threads simultaneously? ,False,0,CONTRIBUTOR
https://api.github.com/repos/JuliaLang/julia/issues/comments/997462928,New multithreading segfault in RayTracingWeekend.jl,claforte,15,1084188772,4,997462928,0,997462294,2021-12-19T21:19:17Z,"I captured a `rr` trace after applying the zen_workaround.py: https://s3.amazonaws.com/julialang-dumps/reports/2021-12-19T21-16-29-claforte.tar.zst

I thought that'd be a lot harder! :-) Kudos to whoever spent the time automating that process!",False,0,NONE
https://api.github.com/repos/JuliaLang/julia/issues/comments/997463178,New multithreading segfault in RayTracingWeekend.jl,claforte,15,1084188772,5,997463178,0,997462928,2021-12-19T21:20:48Z,"> Might be caused by accessing the image array from multiple threads simultaneously?

Maybe, but then, why does it work when everything is the one big old_proto.jl file?
BTW, I suspected that it might have to do with my resetting the RNG seed across each thread (`reseed!()`) but that didn't seem to matter.",False,0,NONE
https://api.github.com/repos/JuliaLang/julia/issues/comments/997472691,New multithreading segfault in RayTracingWeekend.jl,claforte,15,1084188772,6,997472691,0,997463178,2021-12-19T22:26:14Z,"As an extra experiment (in case I messed up when I extracted the functions), I cut-and-pasted the entire body of `RayTracingWeekend.jl` (except the module/export) at the start of `repro_crash.jl`, and removed the `using RaytracingWeekend` statement there. The crash doesn't occur then. So it's clearly specific to the separation of the code between files.",False,0,NONE
https://api.github.com/repos/JuliaLang/julia/issues/comments/997482866,New multithreading segfault in RayTracingWeekend.jl,claforte,15,1084188772,7,997482866,0,997472691,2021-12-19T23:30:42Z,"I pinpointed in part the reason for the multithreading crash... see branch `claforte/threads_crash2`:

I:
    - cut-and-pasted whole source code from RayTracingWeekend.jl
      - crash doesn't occur then
    - Commented out redefinitions that make no difference on the crash
    - **The problems seems related to the initialization of `TRNG` and its use in related functions, and my aggressive use of @inline...**
    - search for `claforte CRASH` for my debugging notes",False,0,NONE
https://api.github.com/repos/JuliaLang/julia/issues/comments/997497583,New multithreading segfault in RayTracingWeekend.jl,claforte,15,1084188772,8,997497583,0,997482866,2021-12-20T00:41:18Z,"I found a work-around. Instead of:
```
# Instantiate 1 RNG (Random Number Generator) per thread, for performance
# Fix the random seeds, to make it easier to benchmark changes.
# Work-around segmentation fault caused by nthreads() returning 1 during precompilation. 
const TRNG = [Xoroshiro128Plus(i) for i = 1:Threads.nthreads()] 
```

... which somehow seems to only allocate 1 item in TRNG, I initialize it to 128 elements...

```
# Assume <=128 threads
const TRNG = [Xoroshiro128Plus(i) for i = 1:128] 
```

I vaguely remember that there's a way to prevent the precompilation from being applied on some global variables? If so could that offer a cleaner approach?",False,0,NONE
https://api.github.com/repos/JuliaLang/julia/issues/comments/997501726,New multithreading segfault in RayTracingWeekend.jl,vchuravy,15,1084188772,9,997501726,0,997497583,2021-12-20T00:55:39Z,You should initialize the TRNG from within your `__init__` method.,False,0,MEMBER
https://api.github.com/repos/JuliaLang/julia/issues/comments/997518826,New multithreading segfault in RayTracingWeekend.jl,claforte,15,1084188772,10,997518826,0,997501726,2021-12-20T01:35:59Z,"Thanks... unfortunately I couldn't figure out a way to initialize it from `__init__` and still get the benefit of @inline for functions that depend on it, etc. So for now, pre-allocating 256 RNGs seems like the practical work-around...",False,0,NONE
https://api.github.com/repos/JuliaLang/julia/issues/comments/997547204,New multithreading segfault in RayTracingWeekend.jl,vchuravy,15,1084188772,11,997547204,0,997518826,2021-12-20T02:50:15Z,"I am not sure I understand?

I would allocate an empty const array as a global. Then within init resize it, to the current number of threads and initialize it.",False,0,MEMBER
https://api.github.com/repos/JuliaLang/julia/issues/comments/997896711,New multithreading segfault in RayTracingWeekend.jl,claforte,15,1084188772,12,997896711,0,997547204,2021-12-20T12:51:16Z,"Thanks, I'll try that! However, IMHO there should be better ""guard rails"" or at least documentation to prevent this kind of segmentation fault. In this case, this was a toy program so it wasn't particularly hard to debug and work-around... but imagine if this were a 1000-files system... Surely there's a reasonably simple way to prevent others from bumping into the same problem?

1. e.g. make a mention in https://docs.julialang.org/en/v1/manual/multi-threading/ that nthreads isn't reliable during pre-compilation. Or better yet, include a safe and fast example of per-thread RNG initialization. (Since that's what lead me to this problem...)
2. or during pre-compilation, if there's an easy way (?) to identify that nthreads is used in an allocation, print a warning?",False,0,NONE
https://api.github.com/repos/JuliaLang/julia/issues/comments/997903045,New multithreading segfault in RayTracingWeekend.jl,KristofferC,15,1084188772,13,997903045,0,997896711,2021-12-20T13:01:26Z,"There are guard rails. You just sawed them off: https://github.com/claforte/RayTracingWeekend.jl/blob/6b53e5433cc6591992bfebf9f078c6c2e1b955e7/src/RayTracingWeekend.jl#L52.

Run with `--check-bounds=yes` to force the guard rails back and then you see the error.",False,0,MEMBER
https://api.github.com/repos/JuliaLang/julia/issues/comments/998138757,New multithreading segfault in RayTracingWeekend.jl,claforte,15,1084188772,14,998138757,0,997903045,2021-12-20T17:41:10Z,"OK, point taken. So I guess my take-away is, whenever there's a seg fault, turn off all optimizations and run again. Thanks for pointing it out!",False,0,NONE
https://api.github.com/repos/JuliaLang/julia/issues/comments/998140425,New multithreading segfault in RayTracingWeekend.jl,claforte,15,1084188772,15,998140425,0,998138757,2021-12-20T17:43:54Z,BTW I recommend someone adds this kind of suggestion at the top of this page: https://docs.julialang.org/en/v1/devdocs/backtraces/,False,0,NONE
https://api.github.com/repos/JuliaLang/julia/issues/comments/998231285,New multithreading segfault in RayTracingWeekend.jl,vchuravy,15,1084188772,16,998231285,0,998140425,2021-12-20T20:04:34Z,"> I recommend someone

Always happy to take PRs :)",False,0,MEMBER
https://api.github.com/repos/doitsujin/dxvk/issues/2401,Warframe random VK_ERROR_DEVICE_LOST crashes,Monsterovich,5,1081544311,1,1081544311,0,0,2021-12-15T21:48:21Z,"The game crashes more frequently on open world locations. The crash happens every ~30 min, sometimes rarer.

### Software information
The game runs just fine even on medium/high settings (I have 60-70 fps on open world maps). I tried it on low settings to avoid issues and, unfortunately, it crashes too.
I've never had issues in Warframe on an Intel GPU (Intel HD Graphics 620), but it's a much slower GPU, though. It's barely playable.

I've run many Unreal Engine 4 games on my current GPU, never got a VK_ERROR_DEVICE_LOST crash.

### System information
- GPU: NVIDIA GeForce GTX 960
- Driver: 470.86
- Wine version: wine-7.0-rc1 (Staging)
- DXVK version: 1.9.2

### Apitrace file(s)


### Log files
- d3d9.log: The game doesn't use d3d9.
- d3d11.log: [Warframe.x64_d3d11.log](https://github.com/doitsujin/dxvk/files/7722889/Warframe.x64_d3d11.log)
- dxgi.log: [Warframe.x64_dxgi.log](https://github.com/doitsujin/dxvk/files/7722891/Warframe.x64_dxgi.log)

Looks like NVidia driver issue? Thoughts?",True,0,NONE
https://api.github.com/repos/doitsujin/dxvk/issues/comments/998283436,Warframe random VK_ERROR_DEVICE_LOST crashes,Monsterovich,5,1081544311,2,998283436,0,1081544311,2021-12-20T21:28:23Z,I've bought an extra memory stick (+16GB) and the crashes are gone. Why is that? ,False,0,NONE
https://api.github.com/repos/doitsujin/dxvk/issues/comments/1152970438,Warframe random VK_ERROR_DEVICE_LOST crashes,Blisto91,5,1081544311,3,1152970438,0,998283436,2022-06-11T17:36:29Z,"@Monsterovich I sadly can't say why it stopped crashing for you.
Has this been true since then?",False,0,CONTRIBUTOR
https://api.github.com/repos/doitsujin/dxvk/issues/comments/1152970773,Warframe random VK_ERROR_DEVICE_LOST crashes,Monsterovich,5,1081544311,4,1152970773,0,1152970438,2022-06-11T17:39:05Z,"> I sadly can't say why it stopped crashing for you.
> Has this been true since then?

Yes. I also have replaced by GPU with RTX 3060 ti.",False,0,NONE
https://api.github.com/repos/doitsujin/dxvk/issues/comments/1152970986,Warframe random VK_ERROR_DEVICE_LOST crashes,Monsterovich,5,1081544311,5,1152970986,0,1152970773,2022-06-11T17:40:36Z,"Crashes are probably caused in situations with low amount of video memory, although I don't know why increasing the amount of RAM fixed it. Probably because of the dual channel memory mode.",False,0,NONE
https://api.github.com/repos/doitsujin/dxvk/issues/comments/1152971468,Warframe random VK_ERROR_DEVICE_LOST crashes,Blisto91,5,1081544311,6,1152971468,0,1152970986,2022-06-11T17:44:41Z,"> Yes. I also have replaced by GPU with RTX 3060 ti.

Nice! gz :grin: 

Would you be fine with the issue being closed then? If you run into anymore issues you are ofc welcome to open a new one.",False,0,CONTRIBUTOR
https://api.github.com/repos/doitsujin/dxvk/issues/2402,"i can't get 1.92 to load in Skyrim, with Nvidia Drivers 471.41(derp coppied the wrong dll)",XDbored1,6,1081795744,1,1081795744,0,0,2021-12-16T05:46:23Z,"i can't get 1.92 to load in Skyrim, with Nvidia Drivers 471.41, and i was wondering if the new version needed newer drivers or something if so what version? does it need a specific newer version of Vulkan?

i can't find anywhere to ask about this so i am posting it as a issue for now",True,0,NONE
https://api.github.com/repos/doitsujin/dxvk/issues/comments/995507231,"i can't get 1.92 to load in Skyrim, with Nvidia Drivers 471.41(derp coppied the wrong dll)",XDbored1,6,1081795744,2,995507231,0,1081795744,2021-12-16T07:21:51Z,"1.92 is still not loading with driver version, 497.9, vulkan 1.2.182
1.91 still loads",False,0,NONE
https://api.github.com/repos/doitsujin/dxvk/issues/comments/995853694,"i can't get 1.92 to load in Skyrim, with Nvidia Drivers 471.41(derp coppied the wrong dll)",K0bin,6,1081795744,3,995853694,0,995507231,2021-12-16T14:12:30Z,Are you talking about classic Skyrim or Skyrim Special Edition? Please post logs.,False,0,COLLABORATOR
https://api.github.com/repos/doitsujin/dxvk/issues/comments/995855843,"i can't get 1.92 to load in Skyrim, with Nvidia Drivers 471.41(derp coppied the wrong dll)",XDbored1,6,1081795744,4,995855843,0,995853694,2021-12-16T14:15:02Z,Classic Skyrim and pretty sure there were no logs for 1.9.2 i could post 1.9.1 logs but i don't think those would be useful,False,0,NONE
https://api.github.com/repos/doitsujin/dxvk/issues/comments/995856481,"i can't get 1.92 to load in Skyrim, with Nvidia Drivers 471.41(derp coppied the wrong dll)",XDbored1,6,1081795744,5,995856481,0,995855843,2021-12-16T14:15:48Z,"wait i just saw it 32bit vs 64bit did i fuck and copy the wrong dll? probably
",False,0,NONE
https://api.github.com/repos/doitsujin/dxvk/issues/comments/995858081,"i can't get 1.92 to load in Skyrim, with Nvidia Drivers 471.41(derp coppied the wrong dll)",K0bin,6,1081795744,6,995858081,0,995856481,2021-12-16T14:17:34Z,"You need to copy over the 32bit d3d9.dll right next to the exe of the game. If there are no logs, the game isn't even loading DXVK. I'm closing this for now because this is almost certainly a setup issue. Feel free to reopen if there's an actual bug.",False,0,COLLABORATOR
https://api.github.com/repos/doitsujin/dxvk/issues/comments/995859047,"i can't get 1.92 to load in Skyrim, with Nvidia Drivers 471.41(derp coppied the wrong dll)",XDbored1,6,1081795744,7,995859047,0,995858081,2021-12-16T14:18:43Z,yeah that was it i still can't find the logs but its working,False,0,NONE
https://api.github.com/repos/doitsujin/dxvk/issues/2404,Devil May Cry HD Collection Fails To Launch Re: DXVK Update,shklein,6,1083643400,1,1083643400,0,0,2021-12-17T22:00:39Z,"I am testing Devil May Cry HD Collection (631510) on Proton - Experimental (experimental-6.3-20211215) and the game is crashing on launch. On the current Proton version (6.3-8) the game launches but runs into issues elsewhere. In testing a fix for these issues, we found that the version of DXVK currently in Experimental is causing the launch to fail. I ran a bisect to determine the ""bad"" commit:
---------------------------------------------------------------------------------------------- 
5b725205efd6f69cf9500a4fdfb5ca21c1a862bf is the first bad commit
commit 5b725205efd6f69cf9500a4fdfb5ca21c1a862bf
Author: Philip Rebohle philip.rebohle@tu-dortmund.de
Date: Wed Nov 3 16:07:46 2021 +0100

[dxvk] Introduce DxvkFramebufferInfo

Stores all info that is currently held by the DxvkFramebuffer class,
but is not heap-allocated and will not create an actual framebuffer
object.
--------------------------------------------------------------------------------------------

### Software information
Devil May Cry HD Collection (631510)

### System information
Ubuntu 20.04
- GPU: NVIDIA GeForce RTX 3060 Laptop GPU
- Driver: nvidia-driver-470
- Proton: experimental-6.3-20211215
- DXVK version: 0c2551f8 Merge commit 'v1.9.2-33-g1fd037c'

[dmcLauncher_d3d11.log](https://github.com/doitsujin/dxvk/files/7737325/dmcLauncher_d3d11.log)
[dmcLauncher_dxgi.log](https://github.com/doitsujin/dxvk/files/7737326/dmcLauncher_dxgi.log)

",True,0,NONE
https://api.github.com/repos/doitsujin/dxvk/issues/comments/997226676,Devil May Cry HD Collection Fails To Launch Re: DXVK Update,doitsujin,6,1083643400,2,997226676,0,1083643400,2021-12-18T16:28:47Z,can we please have an apitrace or something?,False,0,OWNER
https://api.github.com/repos/doitsujin/dxvk/issues/comments/998075995,Devil May Cry HD Collection Fails To Launch Re: DXVK Update,shklein,6,1083643400,3,998075995,0,997226676,2021-12-20T16:21:28Z,"Site is refusing my uploads for .zip and .gz. Trace can be downloaded here: 
https://www.codeweavers.com/xfer/sklein/dmcLauncher.trace.gz",False,0,NONE
https://api.github.com/repos/doitsujin/dxvk/issues/comments/998174729,Devil May Cry HD Collection Fails To Launch Re: DXVK Update,K0bin,6,1083643400,4,998174729,0,998075995,2021-12-20T18:35:05Z,That says it requires a password.,False,0,COLLABORATOR
https://api.github.com/repos/doitsujin/dxvk/issues/comments/998179978,Devil May Cry HD Collection Fails To Launch Re: DXVK Update,shklein,6,1083643400,5,998179978,0,998174729,2021-12-20T18:43:31Z,"Apologies - I didn't set it up to do that, not sure why. Please try going here: https://www.codeweavers.com/xfer/sklein/DMC/ and using key ""dmctrace"".",False,0,NONE
https://api.github.com/repos/doitsujin/dxvk/issues/comments/998327428,Devil May Cry HD Collection Fails To Launch Re: DXVK Update,doitsujin,6,1083643400,6,998327428,0,998179978,2021-12-20T22:49:24Z,"Thanks; does https://github.com/doitsujin/dxvk/commit/3bfad1e70e73e9098c2540d73d93ebbec728655f fix the issue?

I can reproduce a crash with your trace, the aforementioned commit seems to resolve it.",False,0,OWNER
https://api.github.com/repos/doitsujin/dxvk/issues/comments/998934318,Devil May Cry HD Collection Fails To Launch Re: DXVK Update,shklein,6,1083643400,7,998934318,0,998327428,2021-12-21T16:46:54Z,"Yes, it does.",False,0,NONE
https://api.github.com/repos/doitsujin/dxvk/issues/2405,[util] Don't call GetCurrentThreadId() on every spin,imaami,4,1083947035,1,1083947035,0,0,2021-12-18T21:13:35Z,Signed-off-by: Juuso Alasuutari <juuso.alasuutari@gmail.com>,True,0,NONE
https://api.github.com/repos/doitsujin/dxvk/issues/comments/997366813,[util] Don't call GetCurrentThreadId() on every spin,imaami,4,1083947035,2,997366813,0,1083947035,2021-12-19T10:24:14Z,Updated to restore compliance with C++11's Lockable requirement should it become an issue in the future. Thanks to @DadSchoorse for pointing this out and @openglfreak for suggesting a fix on Discord.,False,0,NONE
https://api.github.com/repos/doitsujin/dxvk/issues/comments/998409688,[util] Don't call GetCurrentThreadId() on every spin,doitsujin,4,1083947035,3,998409688,0,997366813,2021-12-21T02:08:21Z,does this lead to any tangible improvements anywhere?,False,0,OWNER
https://api.github.com/repos/doitsujin/dxvk/issues/comments/998964865,[util] Don't call GetCurrentThreadId() on every spin,imaami,4,1083947035,4,998964865,0,998409688,2021-12-21T17:29:35Z,"> does this lead to any tangible improvements anywhere?

I'd be surprised if it did. On the other hand there's no reason I can think of why `GetCurrentThreadId()` should be called on every loop. @Guy1524 said on Discord that he checked and found out the call doesn't get inlined by MingGW, so there's at least a nano-optimization there.",False,0,NONE
https://api.github.com/repos/doitsujin/dxvk/issues/comments/999960500,[util] Don't call GetCurrentThreadId() on every spin,doitsujin,4,1083947035,5,999960500,0,998964865,2021-12-23T00:35:58Z,"Yeah, don't really see the point to be honest other than making the implementation unnecessarily clunky. We're literally just spinning faster, in a way this is even the opposite of what we actually want (hence the `_mm_pause` in `spin`).",False,0,OWNER
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/164,The website is crashed,Michael18811380328,9,1167844591,1,1167844591,0,0,2022-03-14T03:37:57Z,The main page (https://lgbt-cn.org/) is crashed,True,0,MEMBER
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1070078999,The website is crashed,KevinZonda,9,1167844591,2,1070078999,0,1167844591,2022-03-17T03:08:07Z,"@kecrily 
",False,0,MEMBER
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1075903068,The website is crashed,CberYellowstone,9,1167844591,3,1075903068,0,1070078999,2022-03-23T04:29:08Z,"I misread the letter C at first glance, haha",False,0,NONE
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1077272253,The website is crashed,Michael18811380328,9,1167844591,4,1077272253,0,1075903068,2022-03-24T06:14:05Z,I find the domain name resolution error (lgbt-cn.org),False,0,MEMBER
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1077274324,The website is crashed,Michael18811380328,9,1167844591,5,1077274324,0,1077272253,2022-03-24T06:15:35Z,ping: cannot resolve https://lgbt-cn.org/: Unknown host,False,0,MEMBER
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1156297091,The website is crashed,ghost,9,1167844591,6,1156297091,0,1077274324,2022-06-15T10:28:40Z,I think this is because the domain name registration has expired.,False,0,NONE
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1156303553,The website is crashed,KevinZonda,9,1167844591,7,1156303553,0,1156297091,2022-06-15T10:35:22Z,hv no idea how to take back,False,0,MEMBER
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1167560711,The website is crashed,nishidashabia,9,1167844591,8,1167560711,0,1156303553,2022-06-27T16:15:54Z,dick in his ass?,False,0,NONE
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1168174980,The website is crashed,KevinZonda,9,1167844591,9,1168174980,0,1167560711,2022-06-28T03:26:42Z,"> dick in his ass?

Seriously?",False,0,MEMBER
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1172929715,The website is crashed,KevinZonda,9,1167844591,10,1172929715,0,1168174980,2022-07-02T17:09:25Z,fall back to GH,False,0,MEMBER
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/183,fuck your freedom,fhtfc,3,1290215934,1,1290215934,0,0,2022-06-30T14:25:31Z,"最近几天LGBT运动在全球范围突然莫名其妙的就热起来了
有没有发现一个奇怪的现象，该项目构建者头像大部分都是二次元，这些只是巧合吗？。
中国尊重人权，中国不歧视LGBT，歧视的是各种主义，和打着这些主义旗号兴风作浪的群体。
像是女权、环保、动保、素食，甚至LGBT这些概念都是经不起推敲的，允许你们拥有自己的自由，允许你们存在，但不允许你们兴风作浪，望好自为之。",True,0,NONE
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1171415469,fuck your freedom,KevinZonda,3,1290215934,2,1171415469,0,1290215934,2022-06-30T16:16:04Z,Oh seriously?,False,0,MEMBER
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1171775059,fuck your freedom,gxres042,3,1290215934,3,1171775059,0,1171415469,2022-06-30T23:43:16Z,"> 最近几天LGBT运动在全球范围突然莫名其妙的就热起来了 有没有发现一个奇怪的现象，该项目构建者头像大部分都是二次元，这些只是巧合吗？。 中国尊重人权，中国不歧视LGBT，歧视的是各种主义，和打着这些主义旗号兴风作浪的群体。 像是女权、环保、动保、素食，甚至LGBT这些概念都是经不起推敲的，允许你们拥有自己的自由，允许你们存在，但不允许你们兴风作浪，望好自为之。

在你发布你自己的言论之前，我希望你能好好想想一些因素。

是的，大多数贡献者的头像都是二次元头像，但我真心不建议以一概全。我们都是支持 LGBT 的一份子，并且您说的 “不歧视 LGBT“ 已经存在有反例。如果后续出现与您言论相关的问题的话，后果由您一人承担。

我们用什么头像有我们自己的自由，我们有什么想法有我们自己的自由，与您无关。

如果您还是坚持您的狭隘想法的话，我给的建议是别来搜索，眼不见心不烦，谢谢。",False,0,MEMBER
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1171775373,fuck your freedom,gxres042,3,1290215934,4,1171775373,0,1171775059,2022-06-30T23:44:04Z,"另，您不配用 ""Fuck"" 这个单词。请检查其是否适用于您的身上。",False,0,MEMBER
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/185,域名是否出现问题？,Nofated095,3,1291929426,1,1291929426,0,0,2022-07-02T01:12:42Z,"如题 我在访问<https://lgbt-cn.org/>时发现目前此域名可能已经被恶意注册变成了黄色网站并且GitHub Pages的页面也会跳转到色情页面
我认为这很讽刺 🏳️‍🌈LGBT的官网居然跳转色情网站？是不是太....
希望可以及时更改或者撤出官网",True,0,NONE
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1172841591,域名是否出现问题？,KevinZonda,3,1291929426,2,1172841591,0,1291929426,2022-07-02T05:58:56Z,没续费，被人买了:(,False,0,MEMBER
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1172913291,域名是否出现问题？,Nofated095,3,1291929426,3,1172913291,0,1172841591,2022-07-02T15:06:24Z,"也许可以通过 Vercel 或多种方式来继续宣传 LGBTQIA-CN 项目
也可以利用类似于 Docusaurus 和 VuePress 做出更具有阅读性的文档、网页
萝卜青菜，各有所爱，只是一些小建议
总之，~~先把主页的域名撤掉吧~~",False,0,NONE
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1172929642,域名是否出现问题？,KevinZonda,3,1291929426,4,1172929642,0,1172913291,2022-07-02T17:09:09Z,"> 也许可以通过 Vercel 或多种方式来继续宣传 LGBTQIA-CN 项目 也可以利用类似于 Docusaurus 和 VuePress 做出更具有阅读性的文档、网页 萝卜青菜，各有所爱，只是一些小建议 总之，~先把主页的域名撤掉吧~

try again",False,0,MEMBER
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/187,一些跨性别者，让我怀疑了我是否站在了正确的立场上,Nofated095,25,1299934235,1,1299934235,0,0,2022-07-10T14:25:27Z,"如题，我之前写过一篇关于跨性别者保护的一篇文章，里面提到了一些关于保护他们利益和生活的一些具体措施。
# 但是
# 我现在怀疑我是否站在了正确的立场上
# 我不知道为他们而付出的努力有没有意义
## 我在 Twitter 上关注了一些 MtF，我本想关注关注他们的生活情况，好家伙，我可以用“色情无处不在”来形容 MtF 们，相当一大部分吃激素并且是性转的跨性别者几乎天天都在发有关于色情的推，甚至出现了很多 MtF 援交的情况。
## 我现在很难以接受这样的情况，我感觉对跨性别者保护到最后居然形成了一个色情群体，都拿着国家物资去干援交。
## 我现在很是怀疑之前我是否应该为他们而不断努力，我感觉自己的努力完全就是助长了性跨的色情。
### 如果性跨们都是这样的话，我虽然仍然支持平权，但我将坚决收回我的文章，并且将支持反跨，我的努力都被拿去做色情事业，我感觉所有努力全TM打了水漂
### 上述问题存在于 MtF 社区，当然不是每一个人，但是是目前我认为急需解决的问题",True,0,NONE
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1179739037,一些跨性别者，让我怀疑了我是否站在了正确的立场上,Nofated095,25,1299934235,2,1179739037,0,1299934235,2022-07-10T14:26:13Z,写的有一些激进，但是确实是我当时的想法,False,0,NONE
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1179740864,一些跨性别者，让我怀疑了我是否站在了正确的立场上,gxres042,25,1299934235,3,1179740864,0,1179739037,2022-07-10T14:37:36Z,"并不是所有的 MtF 都会是这样子，就比如，和你居住在同一个城市的一位 MtF（因隐私问题我不在这里讲）。
但，说实在，会有这么一群 MtF 拿着公共资源搞这种 sexy 行为我是确实没想到，虽然 Twitter 上见到这种内容其实也挺正常的吧......
根据你所提供的信息进行分析，如果他们只是纯粹想要交配的话，那应该还能理解一下；如果真的是想当那些 sexy 的角色的话，真的没有 MtF 的必要了。",False,0,MEMBER
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1179740921,一些跨性别者，让我怀疑了我是否站在了正确的立场上,Nofated095,25,1299934235,4,1179740921,0,1179740864,2022-07-10T14:38:03Z,"# 我说句难听的
# 某 些 MTF 根 本 就 不 需 要 什 么 保 护 吧
# 一个个恨不得将来就是上海名媛
# ~~也许一个15岁的臭傻逼关注平权本身就是一件傻逼事情，我就是个傻逼~~",False,0,NONE
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1179741593,一些跨性别者，让我怀疑了我是否站在了正确的立场上,Nofated095,25,1299934235,5,1179741593,0,1179740921,2022-07-10T14:42:19Z,我愿意支持那些能够从性转中获取精神慰藉的人们，但不代表我支持他们去做爱,False,0,NONE
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1179743436,一些跨性别者，让我怀疑了我是否站在了正确的立场上,LeeZhihan,25,1299934235,6,1179743436,0,1179741593,2022-07-10T14:54:38Z,"> 都拿着国家物资去干援交。

順女，LES，我覺得你不適合來海外的社群，你適合用微博，拿著華爲用微博。",False,0,NONE
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1179743720,一些跨性别者，让我怀疑了我是否站在了正确的立场上,kecrily,25,1299934235,7,1179743720,0,1179743436,2022-07-10T14:56:12Z,"Did you know that some people need to do things they don't necessarily like to earn the money they need to do SRS or take medication?

> 我愿意支持那些能够从性转中获取精神慰藉的人们，但不代表我支持他们去做爱

In addition sex is a basic human right",False,0,CONTRIBUTOR
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1179747422,一些跨性别者，让我怀疑了我是否站在了正确的立场上,Nofated095,25,1299934235,8,1179747422,0,1179743720,2022-07-10T15:18:47Z,"> > 都拿着国家物资去干援交。
> 
> 順女，LES，我覺得你不適合來海外的社群，你適合用微博，拿著華爲用微博。

我说的有一些部分是错误的，但是我反对说保护了她们，转手就通过一些形式挥霍这些保护，“援交”这个词可能用的不太准确，反正我认为是其中一种浪费的形式，但就算没有，也有很多其他被浪费了。

谢谢，我相信不用证明狗都不用微博和华为的结论。
![image](https://user-images.githubusercontent.com/49985975/178150998-5dd85a01-731a-4ab5-aeac-b8b708c2c541.png)
",False,0,NONE
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1179748123,一些跨性别者，让我怀疑了我是否站在了正确的立场上,Nofated095,25,1299934235,9,1179748123,0,1179747422,2022-07-10T15:22:58Z,"> Did you know that some people need to do things they don't necessarily like to earn the money they need to do SRS or take medication?
> 
> > 我愿意支持那些能够从性转中获取精神慰藉的人们，但不代表我支持他们去做爱
> 
> In addition sex is a basic human right

我清楚你说的情况，和我文章中所说的一样，确实说因为保护不够落地而导致很多证明和药物都开不了、买不了。
我说的色情方面存在一定的问题，但是在性跨中的的确确有存在浪费资源和保护的情况，~~我认为色情只是其中一种形式~~

我支持'sex is a basic human right'，对不起，可能从色情角度出发来说我的观点是错误的。",False,0,NONE
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1179748578,一些跨性别者，让我怀疑了我是否站在了正确的立场上,Nofated095,25,1299934235,10,1179748578,0,1179748123,2022-07-10T15:25:43Z,"再解释一下
>我在 Twitter 上关注了一些 MtF，我本想关注关注他们的生活情况，好家伙，我可以用“色情无处不在”来形容 MtF 们，相当一大部分吃激素并且是性转的跨性别者几乎天天都在发有关于色情的推，甚至出现了很多 MtF 援交的情况。
我现在很难以接受这样的情况，我感觉对跨性别者保护到最后居然形成了一个色情群体，都拿着国家物资去干援交。
我现在很是怀疑之前我是否应该为他们而不断努力，我感觉自己的努力完全就是助长了性跨的色情。
如果性跨们都是这样的话，我虽然仍然支持平权，但我将坚决收回我的文章，并且将支持反跨，我的努力都被拿去做色情事业，我感觉所有努力全TM打了水漂

这一部分，从色情角度出发来看是存在问题的，但是我要表达的是存在 MtF 挥霍保护和资源的问题",False,0,NONE
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1179748878,一些跨性别者，让我怀疑了我是否站在了正确的立场上,LeeZhihan,25,1299934235,11,1179748878,0,1179748578,2022-07-10T15:27:34Z,"> > > 都拿着国家物资去干援交。
> > 
> > 
> > 順女，LES，我覺得你不適合來海外的社群，你適合用微博，拿著華爲用微博。
> 
> 我说的有一些部分是错误的，但是我反对说保护了她们，转手就通过一些形式挥霍这些保护，“援交”这个词可能用的不太准确，反正我认为是其中一种浪费的形式，但就算没有，也有很多其他被浪费了。
> 
> 谢谢，我相信不用证明狗都不用微博和华为的结论。 ![image](https://user-images.githubusercontent.com/49985975/178150998-5dd85a01-731a-4ab5-aeac-b8b708c2c541.png)

MBA 2012 真沒必要秀了…

十五歲還是好好迎接初三吧",False,0,NONE
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1179749225,一些跨性别者，让我怀疑了我是否站在了正确的立场上,Nofated095,25,1299934235,12,1179749225,0,1179748878,2022-07-10T15:29:25Z,"> MBA 2012

谢谢，并不说在秀，只是说一下狗都不用微博和华为
#184 中的签署和文章都是在中考结束后进行的。",False,0,NONE
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1179749576,一些跨性别者，让我怀疑了我是否站在了正确的立场上,LeeZhihan,25,1299934235,13,1179749576,0,1179749225,2022-07-10T15:31:47Z,"> > MBA 2012
> 
> 谢谢，并不说在秀，只是说一下狗都不用微博和华为 #184 中的签署和文章都是在中考结束后进行的。

既然這樣，相信你也有時間聊聊吧

我很好奇你對於 MtF 的看法，你認爲，她們應該是怎麽樣的？

你認爲我們，我們 LES，又應該是如何的？",False,0,NONE
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1179750993,一些跨性别者，让我怀疑了我是否站在了正确的立场上,Nofated095,25,1299934235,14,1179750993,0,1179749576,2022-07-10T15:40:11Z,"> > > MBA 2012
> > 
> > 
> > 谢谢，并不说在秀，只是说一下狗都不用微博和华为 #184 中的签署和文章都是在中考结束后进行的。
> 
> 既然這樣，相信你也有時間聊聊吧
> 
> 我很好奇你對於 MtF 的看法，你認爲，她們應該是怎麽樣的？
> 
> 你認爲我們，我們 LES，又應該是如何的？

谢谢你愿意给我聊
（对不起对于LES群体不是很有了解，可能说不了什么

我是希望国内的MtF可以通过多种途径的保护，从而获得真正跨过去的性别的所有权利，可以和我们正常的共享一切我们都享有的社会福利和资源。

迫于国内的环境，通过援交来获取检查的资金和药品购买，从援交的性质上我是无法接受的，但是我明白她们的目的是好的。

我的愿望是MtF们能像我们一样参与到积极的社会生活中，因为社会主义核心价值观在那里摆着，积极融入他才能获得更多公正待遇。

我认识和上述特征比较像的 MtF 们，她们平时和普通人一样可以去上街购物，我也很开心把她们当普通女孩子看待，我很高兴他们能从跨中获得精神慰藉。",False,0,NONE
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1179751417,一些跨性别者，让我怀疑了我是否站在了正确的立场上,Nofated095,25,1299934235,15,1179751417,0,1179750993,2022-07-10T15:42:33Z,"> > > MBA 2012
> > 
> > 
> > 谢谢，并不说在秀，只是说一下狗都不用微博和华为 #184 中的签署和文章都是在中考结束后进行的。
> 
> 既然這樣，相信你也有時間聊聊吧
> 
> 我很好奇你對於 MtF 的看法，你認爲，她們應該是怎麽樣的？
> 
> 你認爲我們，我們 LES，又應該是如何的？

简单去看了一下 LES 的概念，大概有了一个理解

我觉得和 MtF 一样吧，我觉得在限度之内的sex是我完全能接受的，同样，尽管sex是human's right，我不支持发生为了纯粹金钱和利益的性关系，或者其他浪费社会资源和保护的行为。
如果 LES 和我做朋友，我也可以很容易接受。如果她们生活有困难，我也愿意帮助她们。",False,0,NONE
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1179751899,一些跨性别者，让我怀疑了我是否站在了正确的立场上,LeeZhihan,25,1299934235,16,1179751899,0,1179751417,2022-07-10T15:45:05Z,"> > > > MBA 2012
> > > 
> > > 
> > > 谢谢，并不说在秀，只是说一下狗都不用微博和华为 #184 中的签署和文章都是在中考结束后进行的。
> > 
> > 
> > 既然這樣，相信你也有時間聊聊吧
> > 我很好奇你對於 MtF 的看法，你認爲，她們應該是怎麽樣的？
> > 你認爲我們，我們 LES，又應該是如何的？
> 
> 简单去看了一下 LES 的概念，大概有了一个理解
> 
> 我觉得和 MtF 一样吧，我觉得在限度之内的sex是我完全能接受的，同样，我不支持发生为了纯粹金钱和利益的性关系，尽管这是human's right
> 
> 如果 LES 和我做朋友，我也可以很容易接受。如果她们生活有困难，我也愿意帮助她们。

粗略看了下，可惜時間有些晚了 —— 明天是東城區期末考試的最後一天，放學後回復你。

晚安。",False,0,NONE
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1179752020,一些跨性别者，让我怀疑了我是否站在了正确的立场上,Nofated095,25,1299934235,17,1179752020,0,1179751899,2022-07-10T15:45:44Z,"> > > > > MBA 2012
> > > > 
> > > > 
> > > > 谢谢，并不说在秀，只是说一下狗都不用微博和华为 #184 中的签署和文章都是在中考结束后进行的。
> > > 
> > > 
> > > 既然這樣，相信你也有時間聊聊吧
> > > 我很好奇你對於 MtF 的看法，你認爲，她們應該是怎麽樣的？
> > > 你認爲我們，我們 LES，又應該是如何的？
> > 
> > 
> > 简单去看了一下 LES 的概念，大概有了一个理解
> > 我觉得和 MtF 一样吧，我觉得在限度之内的sex是我完全能接受的，同样，我不支持发生为了纯粹金钱和利益的性关系，尽管这是human's right
> > 如果 LES 和我做朋友，我也可以很容易接受。如果她们生活有困难，我也愿意帮助她们。
> 
> 粗略看了下，可惜時間有些晚了 —— 明天是東城區期末考試的最後一天，放學後回復你。
> 
> 晚安。

谢谢，我也是北京东城区的。晚安",False,0,NONE
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1179950164,一些跨性别者，让我怀疑了我是否站在了正确的立场上,Nofated095,25,1299934235,18,1179950164,0,1179752020,2022-07-11T04:21:13Z,"![image](https://user-images.githubusercontent.com/49985975/178187746-0616e53a-6d9d-489f-9cdc-c0cf36efe181.jpg)
![Uploading image.jpg…]()
",False,0,NONE
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1193134526,一些跨性别者，让我怀疑了我是否站在了正确的立场上,Nofated095,25,1299934235,19,1193134526,0,1179950164,2022-07-23T14:29:55Z,"我为我所有说过的话，以及不成熟的言论，以及咄咄逼人的态度，沉重地道歉，并对伤害到的 MtF 们抱歉。对不起，我撤回我说过的所有话。
我的行为看上去可能非常撒比，希望各位你们可以原谅，当然也许你们不会原谅。
再一次沉重地道歉，出现的损失是无法挽回的，我会尽量用自己的行为弥补",False,0,NONE
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1193137639,一些跨性别者，让我怀疑了我是否站在了正确的立场上,Nofated095,25,1299934235,20,1193137639,0,1193134526,2022-07-23T14:51:16Z,"我重新表明一下立场：
支持 LGBT-CN，支持发展。
只是**以建议形式来建议各位跨性者（尤其是在中国大陆的）可以更加注意自己的行为是否符合中国的法律**
违反价值观没什么问题，但毕竟~~得益于~~中国的法律体系，最好还是安分守己一点吧（",False,0,NONE
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1193138189,一些跨性别者，让我怀疑了我是否站在了正确的立场上,Nofated095,25,1299934235,21,1193138189,0,1193137639,2022-07-23T14:55:27Z,如果可以的话，我希望可以重新签署。。。,False,0,NONE
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1193138321,一些跨性别者，让我怀疑了我是否站在了正确的立场上,gxres042,25,1299934235,22,1193138321,0,1193138189,2022-07-23T14:56:36Z,"Maybe their behaviour is the reason that many people hate LGBTQIA.

I agree to keep following the law of Chinese Mainland, I will always disagree the people who said like ""fuck your freedom"" that have no any effective evidence.

Thanks for you to support LGBT-CN again.",False,0,MEMBER
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1193138628,一些跨性别者，让我怀疑了我是否站在了正确的立场上,gxres042,25,1299934235,23,1193138628,0,1193138321,2022-07-23T14:58:47Z,"> 如果可以的话，我希望可以重新签署。。。

You can try to sign your name again, I will approve the change if not any problems.",False,0,MEMBER
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1193138759,一些跨性别者，让我怀疑了我是否站在了正确的立场上,alex3236,25,1299934235,24,1193138759,0,1193138628,2022-07-23T14:59:42Z,"> Maybe their behaviour is the reason that many people hate LGBTQIA.
> 
> I agree to keep following the law of Chinese Mainland, I will always disagree the people who said like ""fuck your freedom"" that have no any effective evidence.
> 
> Thanks for you to support LGBT-CN again.

Can't agree with you more",False,0,CONTRIBUTOR
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1193138991,一些跨性别者，让我怀疑了我是否站在了正确的立场上,alex3236,25,1299934235,25,1193138991,0,1193138759,2022-07-23T15:01:18Z,In fact I think this kind of topic should be discussed in Discussions not Issues as it has nothing to do with the repo itself. 🤔 ,False,0,CONTRIBUTOR
https://api.github.com/repos/LGBT-CN/LGBTQIA-In-China/issues/comments/1193139050,一些跨性别者，让我怀疑了我是否站在了正确的立场上,Nofated095,25,1299934235,26,1193139050,0,1193138991,2022-07-23T15:01:44Z,"> In fact I think this kind of topic should be discussed in Discussions not Issues as it has nothing to do with the repo itself. thinking

Good idea.",False,0,NONE
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/1031,2.35.2 issue,szmabcd,5,1088686880,1,1088686880,0,0,2021-12-26T02:30:15Z,"2.35.2 open issue

![QQ截图20211226102832](https://user-images.githubusercontent.com/38176269/147397425-0182f8de-f45c-4b87-9664-3d6bfa5a4346.png)
",True,0,NONE
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1001270868,2.35.2 issue,NickeManarin,5,1088686880,2,1001270868,0,1088686880,2021-12-27T00:59:33Z,"You should download the .NET 6 Desktop Runtime.

![image](https://user-images.githubusercontent.com/14798947/147424342-00a9f637-9ea7-4780-b411-72e79f552ddd.png)

Did you download that one?
",False,0,OWNER
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1001286165,2.35.2 issue,szmabcd,5,1088686880,3,1001286165,0,1001270868,2021-12-27T01:51:01Z,"------------------&nbsp;原始邮件&nbsp;------------------
发件人:                                                                                                                        ""NickeManarin/ScreenToGif""                                                                                    ***@***.***&gt;;
发送时间:&nbsp;2021年12月27日(星期一) 上午8:59
***@***.***&gt;;
***@***.******@***.***&gt;;
主题:&nbsp;Re: [NickeManarin/ScreenToGif] 2.35.2 issue (Issue #1031)





 
You should download the .NET 6 Desktop Runtime.
 

 
Did you download that one?
 
—
Reply to this email directly, view it on GitHub, or unsubscribe.
Triage notifications on the go with GitHub Mobile for iOS or Android. 
You are receiving this because you authored the thread.Message ID: ***@***.***&gt;",False,0,NONE
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1001610924,2.35.2 issue,NickeManarin,5,1088686880,4,1001610924,0,1001286165,2021-12-27T15:09:45Z,"Hi, your answer is broken.",False,0,OWNER
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1008305225,2.35.2 issue,szmabcd,5,1088686880,5,1008305225,0,1001610924,2022-01-09T14:11:00Z,"screentogif如何录制全屏，thanks!




------------------&nbsp;原始邮件&nbsp;------------------
发件人:                                                                                                                        ""NickeManarin/ScreenToGif""                                                                                    ***@***.***&gt;;
发送时间:&nbsp;2021年12月27日(星期一) 晚上11:09
***@***.***&gt;;
***@***.******@***.***&gt;;
主题:&nbsp;Re: [NickeManarin/ScreenToGif] 2.35.2 issue (Issue #1031)





 
Hi, your answer is broken.
 
—
Reply to this email directly, view it on GitHub, or unsubscribe.
Triage notifications on the go with GitHub Mobile for iOS or Android. 
You are receiving this because you authored the thread.Message ID: ***@***.***&gt;",False,0,NONE
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1043807473,2.35.2 issue,szmabcd,5,1088686880,6,1043807473,0,1008305225,2022-02-18T03:11:32Z,"hi，


&nbsp; &nbsp; 有两个问题请改进下，谢谢！
&nbsp; &nbsp; 1、录像看起来很模糊

&nbsp; &nbsp; &nbsp;


&nbsp; &nbsp; 2、制作gif动画时请支持多尺寸图片

&nbsp; &nbsp; &nbsp;&nbsp;




------------------&nbsp;原始邮件&nbsp;------------------
发件人:                                                                                                                        ""NickeManarin/ScreenToGif""                                                                                    ***@***.***&gt;;
发送时间:&nbsp;2022年1月31日(星期一) 中午12:01
***@***.***&gt;;
***@***.******@***.***&gt;;
主题:&nbsp;Re: [NickeManarin/ScreenToGif] 2.35.2 issue (Issue #1031)





 
Closed #1031.
 
—
Reply to this email directly, view it on GitHub, or unsubscribe.
Triage notifications on the go with GitHub Mobile for iOS or Android. 
You are receiving this because you authored the thread.Message ID: ***@***.***&gt;",False,0,NONE
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/1032,[Bug] Program do NOT launch on arm64,gxj8885718,14,1089077480,1,1089077480,0,0,2021-12-27T08:49:43Z,"**Describe the bug**
either github release nor windows store edition, can't open screentogif.
runtime installed.
just process, no windows

**Desktop (please complete the following information):**
 - system:windows 10 21H2
 - device:huawei matebook e 2019
 - architecture:arm64
 - screentogif version:2.35.2

![image](https://user-images.githubusercontent.com/6293425/147453823-2f1e15d3-25ad-4fcc-935c-e4dfe71caa89.png)
",True,0,NONE
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1001444494,[Bug] Program do NOT launch on arm64,gxj8885718,14,1089077480,2,1001444494,0,1089077480,2021-12-27T08:59:55Z,PS: 2.34.1 works fine. ,False,0,NONE
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1001557659,[Bug] Program do NOT launch on arm64,NickeManarin,14,1089077480,3,1001557659,0,1001444494,2021-12-27T13:00:31Z,"Hi, any error in the event viewer?

![image](https://user-images.githubusercontent.com/14798947/147474092-c5cdf6d8-dea2-4468-9a01-a410faf09146.png)
",False,0,OWNER
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1001579591,[Bug] Program do NOT launch on arm64,gxj8885718,14,1089077480,4,1001579591,0,1001557659,2021-12-27T13:52:05Z,"just clear all logs and start screentogif,then refresh windws log, nope, it's empty, nothing logged.
![image](https://user-images.githubusercontent.com/6293425/147478044-c7c1cd70-05ee-415a-a3a4-3114ddd564d8.png)
",False,0,NONE
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1001580376,[Bug] Program do NOT launch on arm64,gxj8885718,14,1089077480,5,1001580376,0,1001579591,2021-12-27T13:54:31Z,"<img width=""863"" alt=""image"" src=""https://user-images.githubusercontent.com/6293425/147478203-cfd2b1dd-fbd9-4c11-86a5-192535c86384.png"">
",False,0,NONE
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1001580893,[Bug] Program do NOT launch on arm64,gxj8885718,14,1089077480,6,1001580893,0,1001580376,2021-12-27T13:56:00Z,"![image](https://user-images.githubusercontent.com/6293425/147478322-084c3903-53b8-4bd6-a754-2b37adbe49dc.png)
runtime installed",False,0,NONE
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1001585351,[Bug] Program do NOT launch on arm64,NickeManarin,14,1089077480,7,1001585351,0,1001580893,2021-12-27T14:07:03Z,"Thanks.
In the folder where the app is installed, are there any logs?

It's usually inside a folder, like ScreenToGif (install folder) > ScreenToGif > Logs.
Or inside Users > User > Documents > ScreenToGif.",False,0,OWNER
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1002024323,[Bug] Program do NOT launch on arm64,gxj8885718,14,1089077480,8,1002024323,0,1001585351,2021-12-28T11:07:29Z,"Here's the log(under /users/username/documents/screentogif
-------------------------------------------------------
► Title - 
	On dispacher unhandled exception - Unknown
▬ Message - 
	试图加载格式不正确的程序。 (0x8007000B)
○ Type - 
	System.BadImageFormatException
♦ [Version] Date/Hour - 
	[2.35.2] 12/28/2021 19:04:00
▲ Source - 
	PresentationCore
▼ TargetSite - 
	Void RenderOptions_ForceSoftwareRenderingModeForProcess(Boolean)
► Fuslog - 
	
♠ StackTrace - 
   at MS.Win32.PresentationCore.UnsafeNativeMethods.MilCoreApi.RenderOptions_ForceSoftwareRenderingModeForProcess(Boolean fForce)
   at System.Windows.Media.RenderOptions.set_ProcessRenderMode(RenderMode value)
   at ScreenToGif.App.App_Startup(Object sender, StartupEventArgs e) in C:\Users\nicke\source\repos\ScreenToGif\ScreenToGif\App.xaml.cs:line 156
   at System.Windows.Application.OnStartup(StartupEventArgs e)
   at System.Windows.Application.<.ctor>b__1_0(Object unused)
   at System.Windows.Threading.ExceptionWrapper.InternalRealCall(Delegate callback, Object args, Int32 numArgs)
   at System.Windows.Threading.ExceptionWrapper.TryCatchWhen(Object source, Delegate callback, Object args, Int32 numArgs, Delegate catchHandler)

----------------------------------

► Title - 
	Error while displaying the error.
▬ Message - 
	Add value to collection of type 'System.Windows.Controls.UIElementCollection' threw an exception.
○ Type - 
	System.Windows.Markup.XamlParseException
♦ [Version] Date/Hour - 
	[2.35.2] 12/28/2021 19:04:00
▲ Source - 
	PresentationFramework
▼ TargetSite - 
	Void RewrapException(System.Exception, System.Xaml.IXamlLineInfo, System.Uri)
♠ StackTrace - 
   at System.Windows.Markup.XamlReader.RewrapException(Exception e, IXamlLineInfo lineInfo, Uri baseUri)
   at System.Windows.Markup.WpfXamlLoader.Load(XamlReader xamlReader, IXamlObjectWriterFactory writerFactory, Boolean skipJournaledProperties, Object rootObject, XamlObjectWriterSettings settings, Uri baseUri)
   at System.Windows.Markup.WpfXamlLoader.LoadBaml(XamlReader xamlReader, Boolean skipJournaledProperties, Object rootObject, XamlAccessLevel accessLevel, Uri baseUri)
   at System.Windows.Markup.XamlReader.LoadBaml(Stream stream, ParserContext parserContext, Object parent, Boolean closeStream)
   at System.Windows.Application.LoadComponent(Object component, Uri resourceLocator)
   at ScreenToGif.Windows.Other.ExceptionDialog.InitializeComponent() in C:\Users\nicke\source\repos\ScreenToGif\ScreenToGif\Windows\Other\ExceptionDialog.xaml:line 1
   at ScreenToGif.Windows.Other.ExceptionDialog..ctor(Exception exception) in C:\Users\nicke\source\repos\ScreenToGif\ScreenToGif\Windows\Other\ExceptionDialog.xaml.cs:line 21
   at ScreenToGif.Windows.Other.ExceptionDialog.Ok(Exception exception, String title, String instruction, String observation, Boolean bugWith4055002) in C:\Users\nicke\source\repos\ScreenToGif\ScreenToGif\Windows\Other\ExceptionDialog.xaml.cs:line 101
   at ScreenToGif.App.<>c__DisplayClass21_0.<ShowException>b__0() in C:\Users\nicke\source\repos\ScreenToGif\ScreenToGif\App.xaml.cs:line 433
   at System.Windows.Threading.Dispatcher.Invoke(Action callback, DispatcherPriority priority, CancellationToken cancellationToken, TimeSpan timeout)
   at System.Windows.Threading.Dispatcher.Invoke(Action callback)
   at ScreenToGif.App.ShowException(Exception exception) in C:\Users\nicke\source\repos\ScreenToGif\ScreenToGif\App.xaml.cs:line 428
   at ScreenToGif.App.App_DispatcherUnhandledException(Object sender, DispatcherUnhandledExceptionEventArgs e) in C:\Users\nicke\source\repos\ScreenToGif\ScreenToGif\App.xaml.cs:line 238

▬▬ Message - 
	试图加载格式不正确的程序。 (0x8007000B)
○○ Type - 
	System.BadImageFormatException
▲▲ Source - 
	PresentationCore
▼▼ TargetSite - 
	Void .ctor(System.Windows.Media.MediaContext)
♠♠ StackTrace - 
   at System.Windows.Media.MediaContextNotificationWindow..ctor(MediaContext ownerMediaContext)
   at System.Windows.Media.MediaContext..ctor(Dispatcher dispatcher)
   at System.Windows.Media.MediaContext.From(Dispatcher dispatcher)
   at System.Windows.Media.Visual.VerifyAPIReadWrite()
   at System.Windows.Media.VisualCollection.Add(Visual visual)
   at System.Windows.Controls.UIElementCollection.AddInternal(UIElement element)
   at System.Windows.Controls.UIElementCollection.Add(UIElement element)
   at System.Windows.Controls.UIElementCollection.System.Collections.IList.Add(Object value)
   at System.Xaml.Schema.XamlTypeInvoker.AddToCollection(Object instance, Object item)
   at MS.Internal.Xaml.Runtime.ClrObjectRuntime.Add(Object collection, XamlType collectionType, Object value, XamlType valueXamlType)

----------------------------------

",False,0,NONE
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1002039636,[Bug] Program do NOT launch on arm64,gxj8885718,14,1089077480,9,1002039636,0,1002024323,2021-12-28T11:30:33Z,"have tried 3 versions of screentogif
2.35.2 arm64 failed
2.35.2 x86 failed
2.35.0 arm64 failed
2.35.0 x86 failed
2.34.1 x86 worked

so the problem could be both .NET 6 or project restructuring.",False,0,NONE
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1002044147,[Bug] Program do NOT launch on arm64,NickeManarin,14,1089077480,10,1002044147,0,1002039636,2021-12-28T11:38:37Z,"The logs tell me that at least one DLL from a different assembly is trying to get loaded, which causes the error (bad image).",False,0,OWNER
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1002076900,[Bug] Program do NOT launch on arm64,gxj8885718,14,1089077480,11,1002076900,0,1002044147,2021-12-28T12:32:05Z,"clean install Windows 10 Pro 21H2 , nothing modified. All drivers from stock system image. no strange software installed.",False,0,NONE
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1002789916,[Bug] Program do NOT launch on arm64,NickeManarin,14,1089077480,12,1002789916,0,1002076900,2021-12-29T21:54:45Z,"Hi @gxj8885718, can you try this one?
It's working in here.

[ScreenToGif.zip](https://github.com/NickeManarin/ScreenToGif/files/7790761/ScreenToGif.zip)
",False,0,OWNER
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1002950623,[Bug] Program do NOT launch on arm64,gxj8885718,14,1089077480,13,1002950623,0,1002789916,2021-12-30T09:46:18Z,"> Hi @gxj8885718, can you try this one? It's working in here.
> 
> [ScreenToGif.zip](https://github.com/NickeManarin/ScreenToGif/files/7790761/ScreenToGif.zip)

Wonderful!! it works!! Great job!",False,0,NONE
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1003056815,[Bug] Program do NOT launch on arm64,NickeManarin,14,1089077480,14,1003056815,0,1002950623,2021-12-30T14:38:08Z,Thank you!,False,0,OWNER
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1003056950,[Bug] Program do NOT launch on arm64,NickeManarin,14,1089077480,15,1003056950,0,1003056815,2021-12-30T14:38:31Z,Version 2.35.3 should be working then.,False,0,OWNER
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/1034,Autosave recording/screenshot to clipboard,VandenboschVincent,5,1089252692,1,1089252692,0,0,2021-12-27T13:42:50Z,"Is there a possibility to save everything to clipboard instead of opening editor?
Following flow:
1. Select area
2. Start
3. Stop

After clicking stop the recording is automatically saved in clipboard as a gif.",True,0,NONE
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1002215594,Autosave recording/screenshot to clipboard,NickeManarin,5,1089252692,2,1002215594,0,1089252692,2021-12-28T17:46:08Z,"It's not properly possible to save a gif to the clipboard.
You can set the path of the gif and some apps may be able to load the gif automatically when you paste it, but different from storing an image to the clipboard.

About the other aspect of your feature request, that's on my plans for the next year. :)",False,0,OWNER
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1046334998,Autosave recording/screenshot to clipboard,circletmate,5,1089252692,3,1046334998,0,1002215594,2022-02-20T22:30:42Z,"hello, I used screentogif for a while, I liked this application, it seems to me that the function described in this issue is very lacking, because I rarely want to save a file to disk. I hope you have time this year to implement this feature. thanks in advance ",False,0,NONE
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1159763727,Autosave recording/screenshot to clipboard,HyperLife1119,5,1089252692,4,1159763727,0,1046334998,2022-06-19T15:57:29Z,I have the same need.,False,0,NONE
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1635593342,Autosave recording/screenshot to clipboard,Markus87,5,1089252692,5,1635593342,0,1159763727,2023-07-14T09:41:33Z,"@NickeManarin I think png can handle animation as well, could that be posted to the clipboard?",False,0,NONE
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1959912535,Autosave recording/screenshot to clipboard,glenncarr,5,1089252692,6,1959912535,0,1635593342,2024-02-22T17:20:51Z,Would love to have this ability as well,False,0,NONE
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/1035,[Bug] 2.35.2 ScreenToGif (.stg) saving error,tony,16,1089551804,1,1089551804,0,0,2021-12-28T01:32:38Z,"**Describe the bug**
Saving project files has an error after 2.35 update.

Normal encoding of video (e.g. .webm, .mp4) works as anticipated.

**To Reproduce**
Steps to reproduce the behavior:
1. Create a recording
2. Save As
3. Project
4. Default (.stg)
5. Click Save

""Could not find file 'DriveLetter:\Users\username\APpData\Local\Temp\ScreenToGif\Recording\<date>\Project.json'.""

**Expected behavior**
Should save project files at it did before

**Screenshots**
If applicable, add screenshots to help explain your problem.

![image](https://user-images.githubusercontent.com/26336/147518018-3750aaa3-385d-4a3c-8347-b5ffd3afd02a.png)

Temp directory
![image](https://user-images.githubusercontent.com/26336/147518198-a79ef362-dd1b-49c0-b7c5-494418c7ce84.png)
![image](https://user-images.githubusercontent.com/26336/147518215-c966c359-1cdb-40d1-bfc2-91c3ef2f917c.png)


**Desktop (please complete the following information):**
 - OS: Win 11
 - Version 2.35.2
 

**Additional context**
- 2.34 worked
- Fails with both No compression
- Fails with .zip and .stg
- The directory for `Recording/<datetime>` exists and it has images and `Encode <>` folders, but no `Project.json`
- I've only tried 2.35.2, not 2.35.0 or 2.35.1",True,0,CONTRIBUTOR
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1001825646,[Bug] 2.35.2 ScreenToGif (.stg) saving error,NickeManarin,16,1089551804,2,1001825646,0,1089551804,2021-12-28T01:42:52Z,"Hi, just tested in here and it worked normally.

Before trying to export as a project, what steps did you take?",False,0,OWNER
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1001826203,[Bug] 2.35.2 ScreenToGif (.stg) saving error,tony,16,1089551804,3,1001826203,0,1001825646,2021-12-28T01:45:35Z,"@NickeManarin It was my first attempt after upgrade

I'm not recreating it now either...

Perhaps it's overcome by evens on my system?  Can I close? (I can recreate/reopen if I bump into again?)

P.S. Thank you for checking into this!  I hope things are going well!",False,0,CONTRIBUTOR
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1001826488,[Bug] 2.35.2 ScreenToGif (.stg) saving error,NickeManarin,16,1089551804,4,1001826488,0,1001826203,2021-12-28T01:47:12Z,"Any anti-virus triggering some false positive and removing the file?
Usually that file is only removed by discarding the whole project, manually or via the cleaning task.

Yes, you can close it and if it ever appears again, you can just reopen this ticket.

Thank you for the detailed feedback! Have a nice day.",False,0,OWNER
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1001826878,[Bug] 2.35.2 ScreenToGif (.stg) saving error,tony,16,1089551804,5,1001826878,0,1001826488,2021-12-28T01:49:02Z,"No antivirus that I can see

I am not sure why it happened 🤷 

If I get it happening again I will try to get a more complete recreation

Have a good evening. I will donate again some time also. I am no longer on Patreon (due to leaving the platform, not dissatisfaction with you or ScreenToGif)",False,0,CONTRIBUTOR
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1001827692,[Bug] 2.35.2 ScreenToGif (.stg) saving error,tony,16,1089551804,6,1001827692,0,1001826878,2021-12-28T01:51:30Z,"Actually, nevermind it happened again",False,0,CONTRIBUTOR
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1001827723,[Bug] 2.35.2 ScreenToGif (.stg) saving error,tony,16,1089551804,7,1001827723,0,1001827692,2021-12-28T01:51:35Z,😆 ,False,0,CONTRIBUTOR
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1001827799,[Bug] 2.35.2 ScreenToGif (.stg) saving error,NickeManarin,16,1089551804,8,1001827799,0,1001827723,2021-12-28T01:51:58Z,😅,False,0,OWNER
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1001828110,[Bug] 2.35.2 ScreenToGif (.stg) saving error,NickeManarin,16,1089551804,9,1001828110,0,1001827799,2021-12-28T01:53:37Z,"Ok, let's check, were did you get the app from? Github/Website, Store, chocolatey?
",False,0,OWNER
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1001828130,[Bug] 2.35.2 ScreenToGif (.stg) saving error,tony,16,1089551804,10,1001828130,0,1001828110,2021-12-28T01:53:41Z,"Is there a way I can collect a debug report?  

FIle: `C:\Users\username\Documents\ScreenToGif`
My filename is like `?yyyy-MM-dd HH-mm-ss? - PR 1993- master @ 712eabc`",False,0,CONTRIBUTOR
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1001828156,[Bug] 2.35.2 ScreenToGif (.stg) saving error,tony,16,1089551804,11,1001828156,0,1001828130,2021-12-28T01:53:49Z,via Updater.,False,0,CONTRIBUTOR
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1001828292,[Bug] 2.35.2 ScreenToGif (.stg) saving error,tony,16,1089551804,12,1001828292,0,1001828156,2021-12-28T01:54:19Z,"Before that from the website, .msi file.  

2.34

Then I upgraded via the updater",False,0,CONTRIBUTOR
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1001828365,[Bug] 2.35.2 ScreenToGif (.stg) saving error,NickeManarin,16,1089551804,13,1001828365,0,1001828292,2021-12-28T01:54:37Z,"If some error was triggered, it would be located at AppDirectory / ScreenToGif / Logs",False,0,OWNER
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1001828388,[Bug] 2.35.2 ScreenToGif (.stg) saving error,tony,16,1089551804,14,1001828388,0,1001828365,2021-12-28T01:54:42Z,Do you skype or telegram? I can screenshare with you,False,0,CONTRIBUTOR
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1001828626,[Bug] 2.35.2 ScreenToGif (.stg) saving error,NickeManarin,16,1089551804,15,1001828626,0,1001828388,2021-12-28T01:55:45Z,"Yes, that or discord.",False,0,OWNER
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1001843691,[Bug] 2.35.2 ScreenToGif (.stg) saving error,NickeManarin,16,1089551804,16,1001843691,0,1001828626,2021-12-28T03:01:51Z,"Thanks for the help.
A new version should be available tomorrow.",False,0,OWNER
https://api.github.com/repos/NickeManarin/ScreenToGif/issues/comments/1001843878,[Bug] 2.35.2 ScreenToGif (.stg) saving error,tony,16,1089551804,17,1001843878,0,1001843691,2021-12-28T03:02:40Z,Thank you for looking into this on short notice. Looking forward to it,False,0,CONTRIBUTOR
https://api.github.com/repos/electron/rebuild/issues/975,chore(deps): bump detect-libc from 1.0.3 to 2.0.0,dependabot[bot],4,1126635342,1,1126635342,0,0,2022-02-08T00:02:45Z,"Bumps [detect-libc](https://github.com/lovell/detect-libc) from 1.0.3 to 2.0.0.
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/lovell/detect-libc/commit/19e2c00f8f6fc50cefb83c3fd3d774cf8f0e4918""><code>19e2c00</code></a> Release v2.0.0</li>
<li><a href=""https://github.com/lovell/detect-libc/commit/0b7ef0bed5d80dd5da07f95b24711de31936adaa""><code>0b7ef0b</code></a> Ensure only 1 process spawned for older Node.js versions</li>
<li><a href=""https://github.com/lovell/detect-libc/commit/fc57adf8c3a841f208cb03f769e506ed73bf3ab3""><code>fc57adf</code></a> Drop CLI, use its logic for integration tests only</li>
<li><a href=""https://github.com/lovell/detect-libc/commit/46b45b0c709d8c8c6b5af7907a563657975b8493""><code>46b45b0</code></a> Provide async and sync API, require Node.js &gt;= 8</li>
<li>See full diff in <a href=""https://github.com/lovell/detect-libc/compare/v1.0.3...v2.0.0"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=detect-libc&package-manager=npm_and_yarn&previous-version=1.0.3&new-version=2.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",True,0,CONTRIBUTOR
https://api.github.com/repos/electron/rebuild/issues/comments/1038799621,chore(deps): bump detect-libc from 1.0.3 to 2.0.0,malept,4,1126635342,2,1038799621,0,1126635342,2022-02-14T08:34:45Z,Requires https://github.com/lovell/detect-libc/pull/15 to finish upgrading,False,0,MEMBER
https://api.github.com/repos/electron/rebuild/issues/comments/1039699910,chore(deps): bump detect-libc from 1.0.3 to 2.0.0,dependabot[bot],4,1126635342,3,1039699910,0,1038799621,2022-02-15T00:02:18Z,"A newer version of detect-libc exists, but since this PR has been edited by someone other than Dependabot I haven't updated it. You'll get a PR for the updated version as normal once this PR is merged.",False,0,CONTRIBUTOR
https://api.github.com/repos/electron/rebuild/issues/comments/1039740316,chore(deps): bump detect-libc from 1.0.3 to 2.0.0,codecov-commenter,4,1126635342,4,1039740316,0,1039699910,2022-02-15T01:04:50Z,"# [Codecov](https://codecov.io/gh/electron/electron-rebuild/pull/975?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron) Report
> Merging [#975](https://codecov.io/gh/electron/electron-rebuild/pull/975?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron) (6c3774a) into [master](https://codecov.io/gh/electron/electron-rebuild/commit/d0f1797939c7b710eb82f92917d70c9442f0815c?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron) (d0f1797) will **not change** coverage.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/electron/electron-rebuild/pull/975/graphs/tree.svg?width=650&height=150&src=pr&token=7F5sGXgudh&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron)](https://codecov.io/gh/electron/electron-rebuild/pull/975?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron)

```diff
@@           Coverage Diff           @@
##           master     #975   +/-   ##
=======================================
  Coverage   76.38%   76.38%           
=======================================
  Files          19       19           
  Lines         686      686           
  Branches      131      131           
=======================================
  Hits          524      524           
  Misses        118      118           
  Partials       44       44           
```


| [Impacted Files](https://codecov.io/gh/electron/electron-rebuild/pull/975?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron) | Coverage Δ | |
|---|---|---|
| [src/module-type/node-gyp.ts](https://codecov.io/gh/electron/electron-rebuild/pull/975/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron#diff-c3JjL21vZHVsZS10eXBlL25vZGUtZ3lwLnRz) | `84.61% <100.00%> (ø)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/electron/electron-rebuild/pull/975?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/electron/electron-rebuild/pull/975?src=pr&el=footer&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron). Last update [d0f1797...6c3774a](https://codecov.io/gh/electron/electron-rebuild/pull/975?src=pr&el=lastupdated&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron).
",False,0,NONE
https://api.github.com/repos/electron/rebuild/issues/comments/1179320985,chore(deps): bump detect-libc from 1.0.3 to 2.0.0,electron-bot,4,1126635342,5,1179320985,0,1039740316,2022-07-08T20:02:26Z,":tada: This PR is included in version 3.2.8 :tada:

The release is available on:
- [npm package (@latest dist-tag)](https://www.npmjs.com/package/electron-rebuild)
- [GitHub release](https://github.com/electron/electron-rebuild/releases/tag/v3.2.8)

Your **[semantic-release](https://github.com/semantic-release/semantic-release)** bot :package::rocket:",False,0,NONE
https://api.github.com/repos/electron/rebuild/issues/989,feat: add support for force-build-from-source argument,gribnoysup,8,1155049735,1,1155049735,0,0,2022-03-01T08:49:37Z,"This patch adds support for the `--build-from-source` option of the `prebuild-install` package similar to the `--tag-prefix` flag from the same tool that is already supported. Sometimes it is helpful to be able to force rebuild for native modules when the electron application is packaged, but currently the `--force` flag just makes sure that `prebuild-install` is activated, and this tool will prioritize downloading a prebuilt binary if it exists. It might make sense to make `--force` implicitly activate this flag, but to avoid breaking change to the package I added it as a separate flag (but happy to change to whatever the maintainers would prefer)",True,0,NONE
https://api.github.com/repos/electron/rebuild/issues/comments/1140270246,feat: add support for force-build-from-source argument,codecov-commenter,8,1155049735,2,1140270246,0,1155049735,2022-05-28T13:58:22Z,"## [Codecov](https://app.codecov.io/gh/electron/rebuild/pull/989?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron) Report
> Merging [#989](https://app.codecov.io/gh/electron/rebuild/pull/989?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron) (7af98bb) into [main](https://app.codecov.io/gh/electron/rebuild/commit/29365ad904a8713567c4a7beb745d32df7f229e1?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron) (29365ad) will **decrease** coverage by `0.33%`.
> The diff coverage is `79.62%`.

```diff
@@            Coverage Diff             @@
##             main     #989      +/-   ##
==========================================
- Coverage   76.44%   76.12%   -0.33%     
==========================================
  Files          19       20       +1     
  Lines         692      691       -1     
  Branches      134      131       -3     
==========================================
- Hits          529      526       -3     
  Misses        118      118              
- Partials       45       47       +2     
```


| [Impacted Files](https://app.codecov.io/gh/electron/rebuild/pull/989?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron) | Coverage Δ | |
|---|---|---|
| [src/clang-fetcher.ts](https://app.codecov.io/gh/electron/rebuild/pull/989?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron#diff-c3JjL2NsYW5nLWZldGNoZXIudHM=) | `81.42% <ø> (+0.34%)` | :arrow_up: |
| [src/types.ts](https://app.codecov.io/gh/electron/rebuild/pull/989?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron#diff-c3JjL3R5cGVzLnRz) | `100.00% <ø> (ø)` | |
| [src/module-type/node-gyp/node-gyp.ts](https://app.codecov.io/gh/electron/rebuild/pull/989?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron#diff-c3JjL21vZHVsZS10eXBlL25vZGUtZ3lwL25vZGUtZ3lwLnRz) | `83.87% <75.00%> (ø)` | |
| [src/module-type/node-gyp/worker.ts](https://app.codecov.io/gh/electron/rebuild/pull/989?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron#diff-c3JjL21vZHVsZS10eXBlL25vZGUtZ3lwL3dvcmtlci50cw==) | `76.19% <76.19%> (ø)` | |
| [src/module-rebuilder.ts](https://app.codecov.io/gh/electron/rebuild/pull/989?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron#diff-c3JjL21vZHVsZS1yZWJ1aWxkZXIudHM=) | `91.52% <100.00%> (ø)` | |
| [src/module-type/prebuild-install.ts](https://app.codecov.io/gh/electron/rebuild/pull/989?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron#diff-c3JjL21vZHVsZS10eXBlL3ByZWJ1aWxkLWluc3RhbGwudHM=) | `90.00% <100.00%> (ø)` | |
| [src/rebuild.ts](https://app.codecov.io/gh/electron/rebuild/pull/989?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron#diff-c3JjL3JlYnVpbGQudHM=) | `72.82% <100.00%> (+0.29%)` | :arrow_up: |
| [src/sysroot-fetcher.ts](https://app.codecov.io/gh/electron/rebuild/pull/989?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron#diff-c3JjL3N5c3Jvb3QtZmV0Y2hlci50cw==) | `83.87% <100.00%> (-0.51%)` | :arrow_down: |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron)
",False,0,NONE
https://api.github.com/repos/electron/rebuild/issues/comments/1140273516,feat: add support for force-build-from-source argument,gribnoysup,8,1155049735,3,1140273516,0,1140270246,2022-05-28T14:17:45Z,Renamed and added a test,False,0,NONE
https://api.github.com/repos/electron/rebuild/issues/comments/1276784631,feat: add support for force-build-from-source argument,mmaietta,8,1155049735,4,1276784631,0,1140273516,2022-10-12T22:08:55Z,"Hey folks, I'd like to bump up this PR. @malept can you please take a look? It seems the requested changes were made.

Context: I'm looking to migrate the electron-builder package to use electron-rebuild directly (as opposed to the Go-library that handles it), and one of the requirements for us is to have `forceBuildFromSource` for us to cleanly transition",False,0,CONTRIBUTOR
https://api.github.com/repos/electron/rebuild/issues/comments/1277233128,feat: add support for force-build-from-source argument,gribnoysup,8,1155049735,5,1277233128,0,1276784631,2022-10-13T08:27:10Z,"@mmaietta not sure if this is of any help, but if you're looking for a temporary workaround while this is being approved what we ended up doing in our case is [passing a completely fake tag prefix](https://github.com/mongodb-js/compass/blob/0cccd1949f03aa264a5e94254ae66ca80add2858/packages/hadron-build/commands/release.js#L297-L302) which ensures that prebuilt version cannot be found and forces the build from source to happen",False,0,NONE
https://api.github.com/repos/electron/rebuild/issues/comments/1284252221,feat: add support for force-build-from-source argument,mmaietta,8,1155049735,6,1284252221,0,1277233128,2022-10-19T16:07:42Z,"Thanks @gribnoysup ! I'll use that for an alpha release of the npm package `electron-builder`. However, I don't think it should be the long-term implementation I use, so I'll still need this PR merged/released before I can proceed with a ""prod"" RC",False,0,CONTRIBUTOR
https://api.github.com/repos/electron/rebuild/issues/comments/1325368389,feat: add support for force-build-from-source argument,mmaietta,8,1155049735,7,1325368389,0,1284252221,2022-11-23T16:46:07Z,"@malept if no objections, can you please merge when you have a chance? 🙂 ",False,0,CONTRIBUTOR
https://api.github.com/repos/electron/rebuild/issues/comments/1573215513,feat: add support for force-build-from-source argument,gaodeng,8,1155049735,8,1573215513,0,1325368389,2023-06-02T06:20:58Z,"Hi @malept , just wanted to remind you of the pending  pull request. Many users are waiting for this important update.",False,0,NONE
https://api.github.com/repos/electron/rebuild/issues/comments/1575082186,feat: add support for force-build-from-source argument,gribnoysup,8,1155049735,9,1575082186,0,1573215513,2023-06-03T17:24:51Z,Rebased on main to resolve conflicts,False,0,NONE
https://api.github.com/repos/electron/rebuild/issues/1005,error rebuild electron 18.0.0 on Windows,songzhj,8,1205453556,1,1205453556,0,0,2022-04-15T10:04:12Z,"On Mac, `electron-rebuild -v 18.0.0` is OK.
On Windows, `electron-rebuild -v 17.0.0` will success, but `electron-rebuild -v 18.0.0` will get errors:

```
Building module: tutor-mupdf-addon, Completed: 0

c:\users\feixiang\.electron-gyp\18.0.0\include\node\v8-traced-handle.h(240): error C2061: 语法错误: 标识符“TracedGlobal<`templ
ate-type-parameter-1'>” [D:\code\tutor-mupdf-addon\build\tutor-mupdf-addon.vcxproj]
  c:\users\feixiang\.electron-gyp\18.0.0\include\node\v8-traced-handle.h(335): note: 参见对正在编译的 类 模板 实例化 ""v8::TracedGloba
  l<T>"" 的引用
c:\users\feixiang\.electron-gyp\18.0.0\include\node\v8-traced-handle.h(240): error C2334: “:”的前面有意外标记；跳过明 显的函数体 [D:\code
\tutor-mupdf-addon\build\tutor-mupdf-addon.vcxproj]
c:\users\feixiang\.electron-gyp\18.0.0\include\node\v8-traced-handle.h(22): fatal error C1075: “{”: 未找到匹配令牌 [D:\code\tu
tor-mupdf-addon\build\tutor-mupdf-addon.vcxproj]
× Rebuild Failed


An unhandled error occurred inside electron-rebuild
node-gyp failed to rebuild 'D:\code\tutor-mupdf-addon'.
For more information, rerun with the DEBUG environment variable set to ""electron-rebuild"".


Error: `C:\Program Files\Microsoft Visual Studio\2022\Community\Msbuild\Current\Bin\MSBuild.exe` failed with exit code: 1






Error: node-gyp failed to rebuild 'D:\code\tutor-mupdf-addon'.
For more information, rerun with the DEBUG environment variable set to ""electron-rebuild"".


Error: `C:\Program Files\Microsoft Visual Studio\2022\Community\Msbuild\Current\Bin\MSBuild.exe` failed with exit code: 1




    at NodeGyp.rebuildModule (D:\Code\tutor-mupdf-addon\node_modules\electron-rebuild\lib\src\module-type\node-gyp.js:117:19)
    at processTicksAndRejections (node:internal/process/task_queues:96:5)
    at async ModuleRebuilder.rebuildNodeGypModule (D:\Code\tutor-mupdf-addon\node_modules\electron-rebuild\lib\src\module-rebuilder.js:94:9)
    at async ModuleRebuilder.rebuild (D:\Code\tutor-mupdf-addon\node_modules\electron-rebuild\lib\src\module-rebuilder.js:124:14)
    at async Rebuilder.rebuildModuleAt (D:\Code\tutor-mupdf-addon\node_modules\electron-rebuild\lib\src\rebuild.js:145:13)
    at async Rebuilder.rebuild (D:\Code\tutor-mupdf-addon\node_modules\electron-rebuild\lib\src\rebuild.js:108:17)
    at async D:\Code\tutor-mupdf-addon\node_modules\electron-rebuild\lib\src\cli.js:154:9
error Command failed with exit code 4294967295.
```

Why and how to resolve it ?",True,0,NONE
https://api.github.com/repos/electron/rebuild/issues/comments/1100588196,error rebuild electron 18.0.0 on Windows,retsimx,8,1205453556,2,1100588196,0,1205453556,2022-04-16T06:45:47Z,+1,False,0,NONE
https://api.github.com/repos/electron/rebuild/issues/comments/1109846495,error rebuild electron 18.0.0 on Windows,kryops,8,1205453556,3,1109846495,0,1100588196,2022-04-26T14:10:15Z,"We had the same problem in a build using Node 14 and Visual Studio 2017 (MSBuild 15). Builds using Node 16 and Visual Studio 2022 (MSBuild 17) do not seem to be affected.

In our concrete case, we worked around the problem by updating our native dependency to a version that has prebuilt binaries for Electron 18.",False,0,NONE
https://api.github.com/repos/electron/rebuild/issues/comments/1115941571,error rebuild electron 18.0.0 on Windows,Ciberusps,8,1205453556,4,1115941571,0,1109846495,2022-05-03T10:16:50Z,"Same trouble
- with electron@16 works fine
- with electron@18 rebuild broken

```
c:\users\ciber\.electron-gyp\18.0.1\include\node\v8-traced-handle.h(240): error C2061: syntax error: identifier 'Tr
acedGlobal<`template-type-parameter-1'>' [F:\FireSave\release\app\node_modules\greenworks\build\greenworks-win64.vc
xproj]
  c:\users\ciber\.electron-gyp\18.0.1\include\node\v8-traced-handle.h(335): note: see reference to class template i
  nstantiation 'v8::TracedGlobal<T>' being compiled
c:\users\ciber\.electron-gyp\18.0.1\include\node\v8-traced-handle.h(240): error C2334: unexpected token(s) precedin
g ':'; skipping apparent function body [F:\FireSave\release\app\node_modules\greenworks\build\greenworks-win64.vcxp
roj]
c:\users\ciber\.electron-gyp\18.0.1\include\node\v8-traced-handle.h(22): fatal error C1075: '{': no matching token
found [F:\FireSave\release\app\node_modules\greenworks\build\greenworks-win64.vcxproj]
```",False,0,NONE
https://api.github.com/repos/electron/rebuild/issues/comments/1116732898,error rebuild electron 18.0.0 on Windows,jurkog,8,1205453556,5,1116732898,0,1115941571,2022-05-03T22:50:35Z,+1,False,0,NONE
https://api.github.com/repos/electron/rebuild/issues/comments/1147350333,error rebuild electron 18.0.0 on Windows,Ciberusps,8,1205453556,6,1147350333,0,1116732898,2022-06-06T11:33:24Z,"Looks like it works now, dont know what changed, anybody still experience issue?",False,0,NONE
https://api.github.com/repos/electron/rebuild/issues/comments/1150070367,error rebuild electron 18.0.0 on Windows,kryops,8,1205453556,7,1150070367,0,1147350333,2022-06-08T15:28:31Z,"Might have been fixed by https://github.com/electron/electron/pull/34109

I will try tomorrow and see if I can still reproduce it in my project.",False,0,NONE
https://api.github.com/repos/electron/rebuild/issues/comments/1150851853,error rebuild electron 18.0.0 on Windows,kryops,8,1205453556,8,1150851853,0,1150070367,2022-06-09T08:52:14Z,Works again for me too 🚀 ,False,0,NONE
https://api.github.com/repos/electron/rebuild/issues/comments/1173306000,error rebuild electron 18.0.0 on Windows,Joey-Coder,8,1205453556,9,1173306000,0,1150851853,2022-07-04T03:44:46Z,"I try to `electron-rebuild -v 18.0.0 -f -w better-sqlite3` with VS2017, But it throw some c++ compile error.

But it is work in VS2019, so I guess it maybe relate with VS version",False,0,NONE
https://api.github.com/repos/electron/rebuild/issues/1022,fix: add std=c++17 flag for e20+,VerteDinde,4,1296220281,1,1296220281,0,0,2022-07-06T18:35:21Z,"Addresses e/e issue [34209](https://github.com/electron/electron/issues/34209) while 20.0.0-beta.1 is in beta.

This PR adds a compile flag for `-std=c++17` when using Electron 20 or higher.",True,0,MEMBER
https://api.github.com/repos/electron/rebuild/issues/comments/1176548023,fix: add std=c++17 flag for e20+,malept,4,1296220281,2,1176548023,0,1296220281,2022-07-06T18:36:31Z,Is this a `chore:` or a `fix:`?,False,0,MEMBER
https://api.github.com/repos/electron/rebuild/issues/comments/1176557497,fix: add std=c++17 flag for e20+,codecov-commenter,4,1296220281,3,1176557497,0,1176548023,2022-07-06T18:46:41Z,"# [Codecov](https://codecov.io/gh/electron/electron-rebuild/pull/1022?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron) Report
> Merging [#1022](https://codecov.io/gh/electron/electron-rebuild/pull/1022?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron) (979361d) into [master](https://codecov.io/gh/electron/electron-rebuild/commit/20107a83a30ca8a5d764684e2586b300393d8e86?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron) (20107a8) will **decrease** coverage by `0.37%`.
> The diff coverage is `33.33%`.

```diff
@@            Coverage Diff             @@
##           master    #1022      +/-   ##
==========================================
- Coverage   76.38%   76.01%   -0.38%     
==========================================
  Files          19       19              
  Lines         686      692       +6     
  Branches      131      133       +2     
==========================================
+ Hits          524      526       +2     
- Misses        118      120       +2     
- Partials       44       46       +2     
```


| [Impacted Files](https://codecov.io/gh/electron/electron-rebuild/pull/1022?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron) | Coverage Δ | |
|---|---|---|
| [src/module-type/node-gyp.ts](https://codecov.io/gh/electron/electron-rebuild/pull/1022/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron#diff-c3JjL21vZHVsZS10eXBlL25vZGUtZ3lwLnRz) | `82.50% <0.00%> (-2.12%)` | :arrow_down: |
| [src/clang-fetcher.ts](https://codecov.io/gh/electron/electron-rebuild/pull/1022/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron#diff-c3JjL2NsYW5nLWZldGNoZXIudHM=) | `79.72% <50.00%> (-1.70%)` | :arrow_down: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/electron/electron-rebuild/pull/1022?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/electron/electron-rebuild/pull/1022?src=pr&el=footer&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron). Last update [20107a8...979361d](https://codecov.io/gh/electron/electron-rebuild/pull/1022?src=pr&el=lastupdated&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=electron).
",False,0,NONE
https://api.github.com/repos/electron/rebuild/issues/comments/1176560977,fix: add std=c++17 flag for e20+,VerteDinde,4,1296220281,4,1176560977,0,1176557497,2022-07-06T18:50:38Z,@malept Looks like we don't have any unit tests for clang-fetcher - I'll see if I can add some,False,0,MEMBER
https://api.github.com/repos/electron/rebuild/issues/comments/1201539000,fix: add std=c++17 flag for e20+,electron-bot,4,1296220281,5,1201539000,0,1176560977,2022-08-01T18:07:52Z,":tada: This PR is included in version 3.2.9 :tada:

The release is available on:
- [npm package (@latest dist-tag)](https://www.npmjs.com/package/electron-rebuild)
- [GitHub release](https://github.com/electron/electron-rebuild/releases/tag/v3.2.9)

Your **[semantic-release](https://github.com/semantic-release/semantic-release)** bot :package::rocket:",False,0,NONE
https://api.github.com/repos/restsharp/RestSharp/issues/1682,AddUrlSegment accepts object values but internally casts to strings causing exception,Guerra24,6,1095674395,1,1095674395,0,0,2022-01-06T20:35:35Z,"This change https://github.com/restsharp/RestSharp/commit/8e96bba46d7d2101319529ea68782a39aaa3bfa8#diff-5df1c2c9f9f84319d21c361a0a336251f7698927e2f1c0b0adab575fa407c6e6 simply [casts object values](https://github.com/restsharp/RestSharp/blob/5830af48cf85b8eaadf89d83fbc3bf46106f5873/src/RestSharp/Ensure.cs#L25) into strings, this is causing issues since the [public api accepts object values](https://github.com/restsharp/RestSharp/blob/8e96bba46d7d2101319529ea68782a39aaa3bfa8/src/RestSharp/Request/RestRequestExtensions.cs#L97).",True,0,NONE
https://api.github.com/repos/restsharp/RestSharp/issues/comments/1006939451,AddUrlSegment accepts object values but internally casts to strings causing exception,alexeyzimarev,6,1095674395,2,1006939451,0,1095674395,2022-01-06T21:14:19Z,"It would also be nice if you actually follow the contribution guidelines and provide stack trace and exception details.

But, I see what happens. Will try to fix it tomorrow.",False,0,MEMBER
https://api.github.com/repos/restsharp/RestSharp/issues/comments/1006950118,AddUrlSegment accepts object values but internally casts to strings causing exception,Guerra24,6,1095674395,3,1006950118,0,1006939451,2022-01-06T21:32:51Z,"First of all thanks for the quick fix!

> It would also be nice if you actually follow the contribution guidelines and provide stack trace and exception details.

Sorry about that. I thought pointing out the source of the issue and why it was an *issue* was descriptive enough. Will keep that in mind for next time.",False,0,NONE
https://api.github.com/repos/restsharp/RestSharp/issues/comments/1006951839,AddUrlSegment accepts object values but internally casts to strings causing exception,alexeyzimarev,6,1095674395,4,1006951839,0,1006950118,2022-01-06T21:35:44Z,"You're right. I got it right after looking into the links you provided. I usually scan the issue content, and when it has no stack trace, it looks incomplete to me :)",False,0,MEMBER
https://api.github.com/repos/restsharp/RestSharp/issues/comments/1006953251,AddUrlSegment accepts object values but internally casts to strings causing exception,alexeyzimarev,6,1095674395,5,1006953251,0,1006951839,2022-01-06T21:38:10Z,"Btw I made constructors for all parameter types (except the abstract one) more explicit. The old `AddParameter` has to, of course, accept `object?` but then I try converting those values to string, not cast them.

Also, `AddParameter` overload that doesn't accept the parameter type enum, as well as all `AddXXXParameter` now have explicit `string` or `string?` where it's appropriate (not files and body parameters).",False,0,MEMBER
https://api.github.com/repos/restsharp/RestSharp/issues/comments/1006954460,AddUrlSegment accepts object values but internally casts to strings causing exception,alexeyzimarev,6,1095674395,6,1006954460,0,1006953251,2022-01-06T21:40:26Z,"It will break some existing code of course... I understand that you got this error when passing something like a number or a boolean. Not sure how to fix it better. Maybe I need to return the overload that accepts `object`? It might lead to boxing though, need to check.",False,0,MEMBER
https://api.github.com/repos/restsharp/RestSharp/issues/comments/1006962231,AddUrlSegment accepts object values but internally casts to strings causing exception,alexeyzimarev,6,1095674395,7,1006962231,0,1006954460,2022-01-06T21:54:30Z,"Made this, and it clearly shows the boxing issue. Not such a big issue though.
![image](https://user-images.githubusercontent.com/2821205/148457527-6a070232-6653-4c0b-a887-5920afea5c82.png)
",False,0,MEMBER
https://api.github.com/repos/restsharp/RestSharp/issues/1684,RestResponse does not contain Content-Disposition header,nesc58,4,1096304247,1,1096304247,0,0,2022-01-07T13:10:36Z,"## Expected Behavior
Headers should contain all headers e.g. also ""Content-Disposition"" header.

## Actual Behavior
No Content-Disposition header is available.

Some ""Content"" related header values are mapped to the RestResponse object but not all headers.
https://github.com/restsharp/RestSharp/blob/dev/src/RestSharp/Response/RestResponse.cs#L111


This behavior is not listed in the migration guide. 
Should I really implement this by my own?


## Specifications

  - Version: 107.0.1
  - Platform: Windows - .net 5.0
  - Subsystem:",True,0,NONE
https://api.github.com/repos/restsharp/RestSharp/issues/comments/1007400829,RestResponse does not contain Content-Disposition header,alexeyzimarev,4,1096304247,2,1007400829,0,1096304247,2022-01-07T13:19:03Z,Could you clarify if the content-disposition header is missing in the request or you just want to have it in the response?,False,0,MEMBER
https://api.github.com/repos/restsharp/RestSharp/issues/comments/1007430911,RestResponse does not contain Content-Disposition header,nesc58,4,1096304247,3,1007430911,0,1007400829,2022-01-07T14:04:20Z,"I just want it in the response.
The behavior of the 106.* and before was: All response headers are present in the rest response.

Here is some ""pseudo code"" using wiremock.net:
```
var server = WireMockServer.Start();
server.Given(Request.Create()
        .UsingGet()
        .WithPath(""/file""))
    .RespondWith(Response.Create()
        .WithStatusCode(HttpStatusCode.OK)
        .WithHeader(""Content-Type"", ""application/pdf"")
        .WithHeader(""Content-Disposition"", ""attachment; filename=r1_name2; filename*=UTF-8''r1_name2""));

var client = new RestClient($""http://localhost:{server.Ports.FirstOrDefault()}"");
var response = await client.ExecuteGetAsync(new RestRequest(""/file""));
```

In the case of version 107.0.1 response.Headers does not contain any content related headers. 

The old versions contains all headers e.g. Content-Type, Content-Length and also the Content-Disposition. These are also mapped to the response.ContentType properties but are still present in the response.Headers collection.

I am sure that this is not an error of RestSharp because the `HttpResponseMessage` also have a separate Content header section. I don't know what's the correct way to fix this. Adding an additional property for ContentDisposition would solve actual my problem. But what is with all other available headers in the HttpContentHeaders class?
Maybe something like `.SetHeaders(httpResponse.Headers.Concat(httpResponse.Content.Headers))` could be used in RestSharp.",False,0,NONE
https://api.github.com/repos/restsharp/RestSharp/issues/comments/1007514345,RestResponse does not contain Content-Disposition header,alexeyzimarev,4,1096304247,4,1007514345,0,1007430911,2022-01-07T15:49:29Z,"Check the last preview. `RestResponse.ContentHeaders` are there in a separate property. Is it a problem to have them separated? I don't really care, thought it might be useful.

I also added a property that contains the full `HttpResponseMessage`, which, basically, gives you access to everything.",False,0,MEMBER
https://api.github.com/repos/restsharp/RestSharp/issues/comments/1008139695,RestResponse does not contain Content-Disposition header,alexeyzimarev,4,1096304247,5,1008139695,0,1007514345,2022-01-08T20:26:47Z,107.0.2-alpha.5 has all the necessary fixes.,False,0,MEMBER
https://api.github.com/repos/restsharp/RestSharp/issues/1685,Memory leak in RestClient.ExecuteInternal,DanWatkins,4,1096605843,1,1096605843,0,0,2022-01-07T19:27:25Z,"There appears to be a small memory leak in `RestClient.ExecuteInternal` caused by  the following code:

```
var timeoutCts = new CancellationTokenSource(request.Timeout > 0 ? request.Timeout : int.MaxValue);
var cts        = CancellationTokenSource.CreateLinkedTokenSource(timeoutCts.Token, cancellationToken);
```

`CancellationTokenSource` does not have a finalizer, so my understanding is it needs to be explicitly disposed. I have made a custom build of RestSharp that adds using statements as shown below. This change fixes the leak.

```
using var timeoutCts = new CancellationTokenSource(request.Timeout > 0 ? request.Timeout : int.MaxValue);
using var cts        = CancellationTokenSource.CreateLinkedTokenSource(timeoutCts.Token, cancellationToken);
```

My application is making a high volume of requests, so this leak causes the system to run out of memory in about 2 hours.

## Expected Behavior

No leaked memory

<!-- If this issue is a feature request remove text below -->
## Actual Behavior

Leaked memory

## Steps to Reproduce the Problem

  1. Execute a request using RestClient
  2. Profile using dotMemory by JetBrains

## Specifications

  - Version: 107.0.0-preview.17
  - Platform: Windows 10, Ubuntu 20.04 (.NET 6)",True,0,NONE
https://api.github.com/repos/restsharp/RestSharp/issues/comments/1007782799,Memory leak in RestClient.ExecuteInternal,alexeyzimarev,4,1096605843,2,1007782799,0,1096605843,2022-01-07T22:18:59Z,Thanks. I will look at it.,False,0,MEMBER
https://api.github.com/repos/restsharp/RestSharp/issues/comments/1007784774,Memory leak in RestClient.ExecuteInternal,alexeyzimarev,4,1096605843,3,1007784774,0,1007782799,2022-01-07T22:21:41Z,Check 107.0.2-alpha.0.4 if it fixes the issue.,False,0,MEMBER
https://api.github.com/repos/restsharp/RestSharp/issues/comments/1007818069,Memory leak in RestClient.ExecuteInternal,DanWatkins,4,1096605843,4,1007818069,0,1007784774,2022-01-07T23:28:02Z,Thanks for the fast fix. Unfortunately I seem to be stuck on 107.0.0-preview.17 due to the encoding changes in 107.0.0-preview.18. I commented on #1687.,False,0,NONE
https://api.github.com/repos/restsharp/RestSharp/issues/comments/1008139477,Memory leak in RestClient.ExecuteInternal,alexeyzimarev,4,1096605843,5,1008139477,0,1007818069,2022-01-08T20:26:19Z,"Closing as the fix is implemented, will be released in the next stable version.",False,0,MEMBER
https://api.github.com/repos/restsharp/RestSharp/issues/1686,v107 and x-www-form-urlencoded,mabi,7,1096638991,1,1096638991,0,0,2022-01-07T20:16:49Z,"In v107 sending parameters as name=value x-www-form-urlencoded using
request.AddParameter(""name"", ""value"");
as stated in usage.md no longer works.
What is the correct way?",True,0,NONE
https://api.github.com/repos/restsharp/RestSharp/issues/comments/1007711189,v107 and x-www-form-urlencoded,alexeyzimarev,7,1096638991,2,1007711189,0,1096638991,2022-01-07T20:18:39Z,Could you please check the exact version you're using? It should be multipart form in the latest version.,False,0,MEMBER
https://api.github.com/repos/restsharp/RestSharp/issues/comments/1007713381,v107 and x-www-form-urlencoded,mabi,7,1096638991,3,1007713381,0,1007711189,2022-01-07T20:21:43Z,"Version=""107.0.1""
the issue is that body is no longer just name=value",False,0,NONE
https://api.github.com/repos/restsharp/RestSharp/issues/comments/1007719070,v107 and x-www-form-urlencoded,alexeyzimarev,7,1096638991,4,1007719070,0,1007713381,2022-01-07T20:28:54Z,I don't understand what you need. Do you want to post as url encoded form or as multipart form data?,False,0,MEMBER
https://api.github.com/repos/restsharp/RestSharp/issues/comments/1007763937,v107 and x-www-form-urlencoded,mabi,7,1096638991,5,1007763937,0,1007719070,2022-01-07T21:48:47Z,"urlencoded form,
Content-Type: application/x-www-form-urlencoded",False,0,NONE
https://api.github.com/repos/restsharp/RestSharp/issues/comments/1008065961,v107 and x-www-form-urlencoded,alexeyzimarev,7,1096638991,6,1008065961,0,1007763937,2022-01-08T17:06:39Z,@mabi the latest preview should work for you.,False,0,MEMBER
https://api.github.com/repos/restsharp/RestSharp/issues/comments/1008076932,v107 and x-www-form-urlencoded,mabi,7,1096638991,7,1008076932,0,1008065961,2022-01-08T17:46:09Z,"tested OK with version 107.0.2-alpha.0.5 more testing on monday.
Thank you @alexeyzimarev ",False,0,NONE
https://api.github.com/repos/restsharp/RestSharp/issues/comments/1008280318,v107 and x-www-form-urlencoded,alexeyzimarev,7,1096638991,8,1008280318,0,1008076932,2022-01-09T11:32:59Z,"Released in 107.0.2, if you still get an issue, please reopen.",False,0,MEMBER
https://api.github.com/repos/nexe/nexe/issues/945,Virus detected on exe startup,Default-01,6,1063979247,1,1063979247,0,0,2021-11-26T00:14:29Z,"When i try to run my exe my windows warns me that the file could damage mu computer. How can i prevent this from showing?

Like can i change the exe file so that other users dont get this warning when they download the exe",True,0,NONE
https://api.github.com/repos/nexe/nexe/issues/comments/980239276,Virus detected on exe startup,Stanley-GF,6,1063979247,2,980239276,0,1063979247,2021-11-26T18:05:55Z,You can fix by signing your exe ;),False,0,NONE
https://api.github.com/repos/nexe/nexe/issues/comments/980361625,Virus detected on exe startup,Default-01,6,1063979247,3,980361625,0,980239276,2021-11-26T19:45:16Z,how can i do that?,False,0,NONE
https://api.github.com/repos/nexe/nexe/issues/comments/981335989,Virus detected on exe startup,Default-01,6,1063979247,4,981335989,0,980361625,2021-11-29T06:49:22Z,Anyone that can help me?,False,0,NONE
https://api.github.com/repos/nexe/nexe/issues/comments/1038722595,Virus detected on exe startup,nytamin,6,1063979247,5,1038722595,0,981335989,2022-02-14T07:03:49Z,"A bit late to the party, but this thread sums it up pretty well: https://stackoverflow.com/questions/252226/signing-a-windows-exe-file",False,0,NONE
https://api.github.com/repos/nexe/nexe/issues/comments/1084586643,Virus detected on exe startup,calebboyd,6,1063979247,6,1084586643,0,1038722595,2022-03-31T13:35:38Z,"The base binaries are intentionally unsigned. If shipping an executable to an end user, it will need to be signed to avoid false positives, from the OS or AV software.",False,0,MEMBER
https://api.github.com/repos/nexe/nexe/issues/comments/1231605963,Virus detected on exe startup,emcodem,6,1063979247,7,1231605963,0,1084586643,2022-08-30T12:35:04Z,"Signing exe files can afaik only be done by paying a yearly fee which automatically implies that i cannot distribute free software that is signed. Does nexe really target only to be used in commercial software? 
",False,0,NONE
https://api.github.com/repos/nexe/nexe/issues/948,Nexe generates corrupted linux binaries,GoldenretriverYT,3,1077844466,1,1077844466,0,0,2021-12-12T16:09:59Z,"Hello,
I have tried to compile my NodeJS script with Nexe. (I am using 4.0.0-beta.19). These are my commands:
```
nexe ./poopweb.js --build --target windows-x86  --output ./../builds/poopweb-windows-x86.exe   && ^
nexe ./poopweb.js --build --target windows-x64  --output ./../builds/poopweb-windows-x64.exe   && ^
nexe ./poopweb.js --build --target linux-x86    --output ./../builds/poopweb-linux-x86         && ^
nexe ./poopweb.js --build --target linux-x64    --output ./../builds/poopweb-linux-x64         && ^
```

The windows builds work completely fine, but when running the the linux builds on my VPS, I am getting this error:
`-bash: ./poopweb-linux-x64: cannot execute binary file: Exec format error`

I am currently using NodeJS v16.13.0.",True,0,NONE
https://api.github.com/repos/nexe/nexe/issues/comments/1012537375,Nexe generates corrupted linux binaries,T1MOXA,3,1077844466,2,1012537375,0,1077844466,2022-01-13T21:40:39Z,"It seems that when building under windows, the windows version is always assembled. Since if you rename the file `out` to `out.exe` and run it, then it will open successfully.",False,0,NONE
https://api.github.com/repos/nexe/nexe/issues/comments/1055311482,Nexe generates corrupted linux binaries,SanderDeWaal1992,3,1077844466,3,1055311482,0,1012537375,2022-03-01T11:07:11Z,"I just popped into this problem. Is there a workaround? 

Is the only option to build the Linux binaries on Linux and Windows binaries on Windows or is there a more convenient option?",False,0,NONE
https://api.github.com/repos/nexe/nexe/issues/comments/1055431272,Nexe generates corrupted linux binaries,SanderDeWaal1992,3,1077844466,4,1055431272,0,1055311482,2022-03-01T13:13:51Z,"This is actually not so much a bug as is described in the Readme:
`If the [build](https://github.com/nexe/nexe/tree/master#build-boolean) flag is set, the platform portion of the target is ignored.`

So to answer my own question: yes; building Linux binaries on Linux and Windows binaries on Windows is the only option. I will now choose to create two node build outputs (1 for Linux, 1 for Windows) and then place those artifacts on a central server (you can target your own artifacts machine using the remote property).

To my opinion it would be nice if Nexe gives a warning if the platform property is different than current platform if the build flag is given as now it took me quite some time.",False,0,NONE
https://api.github.com/repos/nexe/nexe/issues/954,MODULE_NOT_FOUND,kasp1,3,1105086488,1,1105086488,0,0,2022-01-16T15:46:24Z,"Hey there!

When I compile the following simple app with nexe and run it on my dev machine, everything seems to work fine, even if I move the `.exe` out of the project directory it seems to work. But if I move it to another windows machine without the development environment, I get the following error:

```
> .\test.exe

node:internal/event_target:777
  process.nextTick(() => { throw err; });
                           ^
Error: Cannot find module 'C:\Users\Administrator\Desktop\node_modules\hasha\thread.js'
    at Function.Module._resolveFilename (node:internal/modules/cjs/loader:933:15)
    at Function.Module._load (node:internal/modules/cjs/loader:778:27)
    at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:81:12)
    at MessagePort.<anonymous> (node:internal/main/worker_thread:187:24)
    at MessagePort.[nodejs.internal.kHybridDispatch] (node:internal/event_target:562:20)
    at MessagePort.exports.emitMessage (node:internal/per_context/messageport:23:28) {
  code: 'MODULE_NOT_FOUND',
  requireStack: []
}
```

index.js:

```js
const hasha = require('hasha')

async function calculateHash(file) {
  console.log(await hasha.fromFile(file, { algorithm: 'sha1', }))
}

calculateHash('test.exe')
```

package.json:

```json
{
  ""name"": ""test"",
  ""version"": ""1.0.0"",
  ""description"": """",
  ""main"": ""index.js"",
  ""scripts"": {
    ""test"": ""echo \""Error: no test specified\"" && exit 1""
  },
  ""author"": """",
  ""license"": ""ISC"",
  ""dependencies"": {
    ""hasha"": ""^5.2.2""
  }
}
``` 

build command:

```
nexe -o test.exe -t windows --build --verbose
```

What am I missing? Thank you for any hints. :-)",True,0,NONE
https://api.github.com/repos/nexe/nexe/issues/comments/1022889142,MODULE_NOT_FOUND,please-rewrite,3,1105086488,2,1022889142,0,1105086488,2022-01-27T06:28:37Z,"You either need to have your `node_modules` next to your app, or you need to bring them in as a resource:
`nexe -o test.exe -r ""./node_modules/**/*"" -t windows --build --verbose`
",False,0,NONE
https://api.github.com/repos/nexe/nexe/issues/comments/1023194115,MODULE_NOT_FOUND,calebboyd,3,1105086488,3,1023194115,0,1022889142,2022-01-27T13:14:50Z,It looks like this is related to `worker_threads`. I'll track it along with #680. Since the worker threads are accessed from library code the workarounds probably won't work. And the issue is with nexe's lack of support for them. ,False,0,MEMBER
https://api.github.com/repos/nexe/nexe/issues/comments/1858906512,MODULE_NOT_FOUND,kimboslice99,3,1105086488,4,1858906512,0,1023194115,2023-12-16T18:55:08Z,"Same issue here, resources are included with -r yet it complains theyre not there if the exe is moved out of development folder",False,0,NONE
https://api.github.com/repos/nexe/nexe/issues/956,exe is runnable within project folder but got Cannot find module 'app-builder' when running outside,zh3ngyuan,5,1110844837,1,1110844837,0,0,2022-01-21T19:51:18Z,"I include the compile function in my js file which wants to be compiled to exe:
```javascript
// DataAnalyzerGenerator.js
...
   compile({
        input: ""./main.temp.js"",
        output: ""./DataAnalyzer.exe"",
        targets: [""win32-x86-10.13.0""]
    }).then(() => {
        console.log(""DataAnalyzer.exe generated!"");
        cleanUpAndExit();
    }).catch((e) => {
        console.log(e);
        exitHelper();
    })
...
```

And after compiling it into exe with command `nexe DataAnalyzerGenerator.js -t win32-x86-10.13.0 -o DataAnalyzerGenerator.exe` and running it in the current project folder, there is no error. But if I move it outside of the current project folder I got:
```
C:\Users\yuanz\Downloads\DataAnalyzerGenerator_v2.0.0>DataAnalyzerGenerator.exe
internal/modules/cjs/loader.js:582
    throw err;
    ^

Error: Cannot find module 'app-builder'
    at Function.Module._resolveFilename (internal/modules/cjs/loader.js:580:15)
    at Function.Module._load (internal/modules/cjs/loader.js:506:25)
    at Module.require (internal/modules/cjs/loader.js:636:17)
    at require (internal/modules/cjs/helpers.js:20:18)
    at Object.<anonymous> (C:\Users\yuanz\Downloads\DataAnalyzerGenerator_v2.0.0\node_modules\nexe\lib\nexe.js:13:23)
    at Module._compile (internal/modules/cjs/loader.js:688:30)
    at Object.Module._extensions..js (internal/modules/cjs/loader.js:699:10)
    at Module.load (internal/modules/cjs/loader.js:598:32)
    at tryModuleLoad (internal/modules/cjs/loader.js:537:12)
    at Function.Module._load (internal/modules/cjs/loader.js:529:3)
``` 

I suspect it is due to the module `app-builder` is not bundled into the exe. Any steps I missed?

nexe version:
```
➜ nexe -v
4.0.0-beta.19
```

### Current workaround
I have to manually copy `node_modules/app-builder` to the exe file folder in order to make it working",True,0,NONE
https://api.github.com/repos/nexe/nexe/issues/comments/1022923749,exe is runnable within project folder but got Cannot find module 'app-builder' when running outside,please-rewrite,5,1110844837,2,1022923749,0,1110844837,2022-01-27T07:32:18Z,look at `resources` in the documentation.,False,0,NONE
https://api.github.com/repos/nexe/nexe/issues/comments/1023188525,exe is runnable within project folder but got Cannot find module 'app-builder' when running outside,calebboyd,5,1110844837,3,1023188525,0,1022923749,2022-01-27T13:09:00Z,@ALexander4295502 Can you run your app outside the project folder with the `DEBUG=nexe:require` environment variable set?. Or even better if you can provide a small reproduction/example repo?,False,0,MEMBER
https://api.github.com/repos/nexe/nexe/issues/comments/1023706059,exe is runnable within project folder but got Cannot find module 'app-builder' when running outside,zh3ngyuan,5,1110844837,4,1023706059,0,1023188525,2022-01-27T22:37:49Z,"> look at `resources` in the documentation.

`app-builder` is not used in my app anywhere except `nexe#compile` which I think is rely on that. In that case, it doesn't make too much sense for me to include it as an additional resource for my app. Also I am not sure if it can be picked up correctly when running `nexe#compile`",False,0,NONE
https://api.github.com/repos/nexe/nexe/issues/comments/1023707927,exe is runnable within project folder but got Cannot find module 'app-builder' when running outside,calebboyd,5,1110844837,5,1023707927,0,1023706059,2022-01-27T22:40:58Z,"Yeah, That's super odd! If you use the debug flag we may be able to track down why that's being included!
",False,0,MEMBER
https://api.github.com/repos/nexe/nexe/issues/comments/1023712700,exe is runnable within project folder but got Cannot find module 'app-builder' when running outside,zh3ngyuan,5,1110844837,6,1023712700,0,1023707927,2022-01-27T22:49:43Z,"> @ALexander4295502 Can you run your app outside the project folder with the `DEBUG=nexe:require` environment variable set?. Or even better if you can provide a small reproduction/example repo?

Hi @calebboyd, sorry but I am not sure if you mean add this env var when I run my app in windows. here is what I got:
```
C:\Users\yuanz\Downloads\>DEBUG=nexe:require DataAnalyzerGenerator.exe
'DEBUG' is not recognized as an internal or external command,
operable program or batch file.
```

Here is the gist for `DataAnalyzerGenerator.js`: https://gist.github.com/ALexander4295502/4e0247250dc372417d9cb52f2988bb84

The only difference is everytime before I use nexe to make this js file into exe I will replace 
```js
const encodedJSFileContent = ""BASE64"";
```
with the actual js file content encoded in base64, but I don't think it can make any difference here. ",False,0,NONE
https://api.github.com/repos/spring-projects/spring-framework/issues/27920,Revisit AOT constructor and factory method resolution,snicoll,8,1099272983,1,1099272983,0,0,2022-01-11T15:06:19Z,"We currently resolve the constructor or factory method to use to instantiate a bean using the package private `ConstructorResolver` class. When processing a `BeanFactory` at build-time, we need to retain that information (without instantiating the bean) so that we lower reflection and processing at runtime.

Right now, `ConstructorResolver`:

* Detect and instantiate the `Constructor` to use.
* Detect the factory method to use and set some additional metadata in the bean definition
* Instantiate the bean using the state of the bean definition

Rather than returning `BeanWrapper` we could return an object that provides the metadata that we need and wrap the instantiation call for the regular runtime behavior. However, the difference between constructor and factory method is annoying as I'd rather have a consistent API for both. 

It is also unknown how we'd store the resolved arguments or if we'd need to.",True,0,MEMBER
https://api.github.com/repos/spring-projects/spring-framework/issues/comments/1062772303,Revisit AOT constructor and factory method resolution,snicoll,8,1099272983,2,1062772303,0,1099272983,2022-03-09T10:24:48Z,FTR we have a very hackish/temporary version in the meantime in `DefaultBeanRegistrationContributionProvider`.,False,0,MEMBER
https://api.github.com/repos/spring-projects/spring-framework/issues/comments/1124861847,Revisit AOT constructor and factory method resolution,jhoeller,8,1099272983,3,1124861847,0,1062772303,2022-05-12T11:10:46Z,"On a related note, after #28414, the `ConstructorOrFactoryMethodResolver` class re-implementing constructor resolution at this point refers to the `@Autowired` annotation directly, creating a package cycle between `beans.factory.aot` and `beans.factory.annotation`. This should be resolved along the proposed reusable constructor resolution algorithm here.",False,0,CONTRIBUTOR
https://api.github.com/repos/spring-projects/spring-framework/issues/comments/1242030233,Revisit AOT constructor and factory method resolution,snicoll,8,1099272983,4,1242030233,0,1124861847,2022-09-09T14:16:01Z,"Juergen and I brainstormed about this one today and we're thinking about an API that would provide a richer model to account, namely, for generic constructor argument values.

Given a `BeanDefinition`, the resolver would return:

1. The `Executable` to use
2. A view over the arguments that have been ""pre-converted"" if necessary. This includes `TypeStringValue` that exposes a raw `String` value with an optional type that should be taken into account to determine the constructor anyway. There are other cases where the input value doesn't strictly match the parameter type, including for indexed constructor arguments.
3. Potentially a way to determine that an argument has to be autowired.

Based on this model we could generate code so that a  `ConstructorArgumentValue` is already in the expected type. If a generic constructor argument has been resolved, it becomes indexed rather so that code instantiation is as straightforward as possible.

A further refinement is the case where all the arguments are known upfront, avoiding the use of `AutowiredArguments` altogether.

There is such an example of such a generic argument in #29087.

",False,0,MEMBER
https://api.github.com/repos/spring-projects/spring-framework/issues/comments/1246638857,Revisit AOT constructor and factory method resolution,snicoll,8,1099272983,5,1246638857,0,1242030233,2022-09-14T11:39:34Z,Regarding 2. I should add some sort of SPI for this would be very much welcome as this could be reused transparently for `PropertyValues`. The conversion for the expected type can happen and it could handle `TypeStringValue` transparently as well.,False,0,MEMBER
https://api.github.com/repos/spring-projects/spring-framework/issues/comments/1268450961,Revisit AOT constructor and factory method resolution,jhoeller,8,1099272983,6,1268450961,0,1246638857,2022-10-05T13:35:24Z,"I'm narrowing the scope of this ticket for our immediate purposes in 6.0, namely merging AOT constructor and factory method resolution into `ConstructorResolver` in the `beans.factory.support` package. This moves related code into the same class, unifies candidate determination for constructors and factory methods, and gets rid of the package cycle around the hard-coded `Autowired` annotation check (which is implicitly coming from `AutowiredAnnotationBeanPostProcessor` via the `determineCandidateConstructors` SPI now). The API entry point for AOT pre-resolution purposes is in `RegisteredBean` now.

Follow-up work might happen before GA still or afterwards in the 6.0.x line, ideally without affecting applications or the rest of the portfolio.",False,0,CONTRIBUTOR
https://api.github.com/repos/spring-projects/spring-framework/issues/comments/1272267271,Revisit AOT constructor and factory method resolution,snicoll,8,1099272983,7,1272267271,0,1268450961,2022-10-08T08:37:01Z,@jhoeller I didn't see a follow-up issue for the argument resolution that is quite important for XML-based scenarios. I've created another issue.,False,0,MEMBER
https://api.github.com/repos/spring-projects/spring-framework/issues/comments/1296768657,Revisit AOT constructor and factory method resolution,CynanX,8,1099272983,8,1296768657,0,1272267271,2022-10-31T08:39:56Z,"HI, do you have a link to the follow up issue, please so I can follow it?

With the latest snapshots I still see the issue as I raised under https://github.com/spring-projects/spring-framework/issues/29052 when trying to compile as native.",False,0,NONE
https://api.github.com/repos/spring-projects/spring-framework/issues/comments/1296832070,Revisit AOT constructor and factory method resolution,snicoll,8,1099272983,9,1296832070,0,1296768657,2022-10-31T09:36:22Z,Alright. Please create a separate issue and share a small sample we can use to reproduce. ,False,0,MEMBER
https://api.github.com/repos/spring-projects/spring-framework/issues/27925,NamedParameterUtils has broken square brackets handling,artembilan,3,1100498424,1,1100498424,0,0,2022-01-12T15:49:11Z,"This is a simple unit test which passes with the `5.3.x` but fails with the current `6.0` milestones:

```java
	@Test
	void namedParamMapReference() {
		String insert = ""insert into foos (id) values (:headers[id])"";
		class Foo {

			final Map<String, Object> headers = new HashMap<>();

			public Foo() {
				this.headers.put(""id"", UUID.randomUUID());
			}

			public Map<String, Object> getHeaders() {
				return this.headers;
			}

		}

		Foo foo = new Foo();

		Object[] params =
				NamedParameterUtils.buildValueArray(NamedParameterUtils.parseSqlStatement(insert),
						new BeanPropertySqlParameterSource(foo), null);

		assertThat(params[0]).isEqualTo(foo.getHeaders().get(""id""));
	}
```

The point is that we may have a reference for the value from nested `Map` property.

The typical use case is messaging, for example with Spring Integration, where a `Message<?>` in the request is used as a source for parameter values.

We even advertise this in the docs: https://docs.spring.io/spring-integration/docs/current/reference/html/jdbc.html#jdbc-outbound-channel-adapter.

I suspect that the cause for breaking change is this fix: https://github.com/spring-projects/spring-framework/commit/64b6beed5b135344b6f0d15bc50bf4c08c2ab9bb. Or the previous one: https://github.com/spring-projects/spring-framework/commit/86eda279c82b79c7888558e7a2524db44c7ee108.

Thanks",True,0,MEMBER
https://api.github.com/repos/spring-projects/spring-framework/issues/comments/1014261249,NamedParameterUtils has broken square brackets handling,quaff,3,1100498424,2,1014261249,0,1100498424,2022-01-17T08:32:20Z,parameterName is changed from `headers[id]` to `headers` after commit https://github.com/spring-projects/spring-framework/commit/64b6beed5b135344b6f0d15bc50bf4c08c2ab9bb,False,0,CONTRIBUTOR
https://api.github.com/repos/spring-projects/spring-framework/issues/comments/1274357754,NamedParameterUtils has broken square brackets handling,rstoyanchev,3,1100498424,3,1274357754,0,1014261249,2022-10-11T09:04:29Z,Maybe consider #17773 as well for potential improvement to the parsing algorithm.,False,0,CONTRIBUTOR
https://api.github.com/repos/spring-projects/spring-framework/issues/comments/1282973136,NamedParameterUtils has broken square brackets handling,jhoeller,3,1100498424,4,1282973136,0,1274357754,2022-10-18T20:35:33Z,"With some custom treatment, we can restore the original intent of #27716 as well as preserve square brackets for index/key expressions. Finally making it into RC2...",False,0,CONTRIBUTOR
https://api.github.com/repos/spring-projects/spring-framework/issues/27927,fix:Spring fails to determine XML is XSD-based if DOCTYPE appears in a comment,shooye,3,1100552741,1,1100552741,0,0,2022-01-12T16:37:21Z,"It solves the problem that `XmlValidationModeDetector` cannot determine whether XML is based on XSD due to improper parsing of comments spanning multiple lines in the original XML configuration file.

Fixes #27915 ",True,0,NONE
https://api.github.com/repos/spring-projects/spring-framework/issues/comments/1011236783,fix:Spring fails to determine XML is XSD-based if DOCTYPE appears in a comment,pivotal-cla,3,1100552741,2,1011236783,0,1100552741,2022-01-12T16:37:23Z,"@shooye Please sign the [Contributor License Agreement](https://cla.pivotal.io/sign/spring?repositoryId=spring-projects/spring-framework&pullRequestId=27927)!

[Click here](https://cla.pivotal.io/sync/spring?repositoryId=spring-projects/spring-framework&pullRequestId=27927) to manually synchronize the status of this Pull Request.

See the [FAQ](https://cla.pivotal.io/about) for frequently asked questions.",False,0,NONE
https://api.github.com/repos/spring-projects/spring-framework/issues/comments/1011239040,fix:Spring fails to determine XML is XSD-based if DOCTYPE appears in a comment,pivotal-cla,3,1100552741,3,1011239040,0,1011236783,2022-01-12T16:39:40Z,@shooye Thank you for signing the [Contributor License Agreement](https://cla.pivotal.io/sign/spring?repositoryId=spring-projects/spring-framework&pullRequestId=27927)!,False,0,NONE
https://api.github.com/repos/spring-projects/spring-framework/issues/comments/1012252218,fix:Spring fails to determine XML is XSD-based if DOCTYPE appears in a comment,sbrannen,3,1100552741,4,1012252218,0,1011239040,2022-01-13T15:38:08Z,"Hi @shooye,

We really appreciate all the effort you put in to provide a fix!

In the end, we decided to go with a simpler solution that relies on recursion in order to reuse the existing comment parsing logic. If you're interested in checking it out, you'll find it in https://github.com/spring-projects/spring-framework/commit/4b1b25496bfd72c288c3af07c741183d0d90567a#diff-d2b71d5dbef74357add917ba7662a8f3d376fe9e965f82cd08407587b55bf833.

In light of that, I am closing this PR.

Thanks again for reporting this set of bugs.",False,0,MEMBER
https://api.github.com/repos/spring-projects/spring-framework/issues/27930,Provide a context URL aware ResourceTransformer,michael-o,3,1102067921,1,1102067921,0,0,2022-01-13T17:23:32Z,"I use `<mvc:resources />` to host Asciidoctor-generated HTML content in few webapps. Those webapps are deployed to different contexts on an Apache Tomcat 8.5 instance. The documentation must be able to reference the entire URL for documentation purpose. Since this is statically generated, I cannot inject the webapp context URL, for obvious reasons. Those HTML files contain a `{contextUrl}` placeholder and with the following snippet the interpolation happens.

```java
import java.io.IOException;
import java.nio.charset.Charset;
import java.nio.charset.StandardCharsets;

import javax.servlet.http.HttpServletRequest;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.core.io.Resource;
import org.springframework.util.FileCopyUtils;
import org.springframework.util.StringUtils;
import org.springframework.web.servlet.resource.ResourceTransformer;
import org.springframework.web.servlet.resource.ResourceTransformerChain;
import org.springframework.web.servlet.resource.TransformedResource;
import org.springframework.web.servlet.support.ServletUriComponentsBuilder;

public class ContextUrlResourceTransformer implements ResourceTransformer {

	private static final Logger logger = LoggerFactory
			.getLogger(ContextUrlResourceTransformer.class);

	private static final Charset DEFAULT_CHARSET = StandardCharsets.UTF_8;

	private final Collection<String> extensions;

	public ContextUrlResourceTransformer() {
		this.extensions = new HashSet<>();
		extensions.add(""html"");
		extensions.add(""yaml"");
	}

	@Override
	public Resource transform(HttpServletRequest request, Resource resource,
			ResourceTransformerChain transformerChain) throws IOException {

		resource = transformerChain.transform(request, resource);

		String filename = resource.getFilename();
		if (!extensions.contains(StringUtils.getFilenameExtension(filename))) {
			return resource;
		}

		logger.trace(""Transforming: {}"", resource);

		byte[] bytes = FileCopyUtils.copyToByteArray(resource.getInputStream());
		String content = new String(bytes, DEFAULT_CHARSET);

		if (!content.contains(""{contextUrl}"")) {
			logger.trace(""No {contextUrl} placeholders found."");
			return resource;
		}

		ServletUriComponentsBuilder builder = ServletUriComponentsBuilder.fromContextPath(request);

		String contextUrl = builder.build().toUriString();
		content = content.replace(""{contextUrl}"", contextUrl);

		return new TransformedResource(resource, content.getBytes(DEFAULT_CHARSET));
	}
````

followed by:
```xml
	<mvc:resources mapping=""/**"" location=""/"" cache-period=""86400"">
		<mvc:resource-chain resource-cache=""true"">
			<mvc:transformers>
				<beans:bean
					class=""...ContextUrlResourceTransformer"" />
			</mvc:transformers>
		</mvc:resource-chain>
	</mvc:resources>
```

This is conceptually similar to the `CssLinkResourceTransformer`, but for suited for general text formats. Please add such a resource tranformer upstream, I guess many would require something like this. Feel free to reuse and modify my code for upstream.

I am on Spring Framework 5.3.14.",True,0,NONE
https://api.github.com/repos/spring-projects/spring-framework/issues/comments/1015251647,Provide a context URL aware ResourceTransformer,bclozel,3,1102067921,2,1015251647,0,1102067921,2022-01-18T10:02:08Z,"Hello @michael-o 

While conceptually similar to `CssLinkResourceTransformer`, this is a rather different use case. CSS resource transformation is well defined and targets a common use case for web applications.

What you're describing here and in #27931 sound like the following use case: hosting static HTML files and partially implementing templating engine features. For this, we'd rather advise our community to use a proper templating engine or a processor in the static html generator that supports this case.

We're happy to support custom implementations through this infrastructure, but I don't think we're going to officially support this implementation in Spring Framework. I'm declining this issue and #27931 as a result, I hope you'll understand our position. Thanks for your contribution!",False,0,MEMBER
https://api.github.com/repos/spring-projects/spring-framework/issues/comments/1015267354,Provide a context URL aware ResourceTransformer,michael-o,3,1102067921,3,1015267354,0,1015251647,2022-01-18T10:19:31Z,"@bclozel I do understand your position, but a static site generator won't solve a runtime problem for me and a template engine is overkill for such a case. Sad, then I will keep those private. I am still surprised that I am the only one requiring this.",False,0,NONE
https://api.github.com/repos/spring-projects/spring-framework/issues/comments/1015323842,Provide a context URL aware ResourceTransformer,bclozel,3,1102067921,4,1015323842,0,1015267354,2022-01-18T11:31:25Z,"We can always reconsider if we get more demand for this. Note that manually dealing with substitutions in HTML content exposes you to the usual templating engine challenges: encoding, malicious injection, etc.",False,0,MEMBER
https://api.github.com/repos/ipython/ipython/issues/13450,Show suggestions in error messages in Python 3.10,tirkarthi,4,1101234440,1,1101234440,0,0,2022-01-13T05:45:04Z,Fixes #13445 ,True,0,CONTRIBUTOR
https://api.github.com/repos/ipython/ipython/issues/comments/1015149476,Show suggestions in error messages in Python 3.10,Carreau,4,1101234440,2,1015149476,0,1101234440,2022-01-18T07:49:54Z,"Hum , I think we might be able to get something better with 

```python
def structured_traceback(...):
    from difflib import get_close_matches
    get_close_matches(value.name, dir(value.obj)
```

And re-implemented the match logic (even if slightly different). That way we can properly highlight tokens.",False,0,MEMBER
https://api.github.com/repos/ipython/ipython/issues/comments/1015669345,Show suggestions in error messages in Python 3.10,aroberge,4,1101234440,3,1015669345,0,1015149476,2022-01-18T17:56:52Z,I believe that the suggestion to use difflib would only work for AttributeError cases but not for NameError (where the misspelled name can be found in the local or global scope).,False,0,NONE
https://api.github.com/repos/ipython/ipython/issues/comments/1015809630,Show suggestions in error messages in Python 3.10,aroberge,4,1101234440,4,1015809630,0,1015669345,2022-01-18T20:31:04Z,"Furthermore, `difflib` gives different results from those given by cPython.
```python
>>> import math
>>> math.Pi
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
AttributeError: module 'math' has no attribute 'Pi'. Did you mean: 'pi'?
>>> from difflib import get_close_matches
>>> get_close_matches('Pi', dir(math))
[]
```",False,0,NONE
https://api.github.com/repos/ipython/ipython/issues/comments/1018229287,Show suggestions in error messages in Python 3.10,tirkarthi,4,1101234440,5,1018229287,0,1015809630,2022-01-21T06:50:00Z,"CPython has done several tweaks to get better results. IMO, it's better to use the suggestions from the compiler itself to avoid any discrepancy and to avoid reimplementing/maintaining the algorithm.

https://github.com/python/cpython/pull/25412
https://github.com/python/cpython/pull/25443
https://github.com/python/cpython/pull/25460
https://github.com/python/cpython/pull/25584
https://github.com/python/cpython/pull/25776",False,0,CONTRIBUTOR
https://api.github.com/repos/ipython/ipython/issues/13451,how to disable auto suggestion in Version 8,2sn,8,1101241014,1,1101241014,0,0,2022-01-13T05:56:14Z,"<!-- This is the repository for IPython command line, if you can try to make sure this question/bug/feature belong here and not on one of the Jupyter repositories. 

If it's a generic Python/Jupyter question, try other forums or discourse.jupyter.org.

If you are unsure, it's ok to post here, though, there are few maintainer so you might not get a fast response. 

-->
I find the new auto suggestion mode *very* distracting. making ipython basically unusable.

How can I disable this?
(I would appreciate if you did not enable new features to the UI by default in the future)

From the documation or a grep of *.py files of IPython I could not find how to do it.

I tried in my ipython config file
```
c = get_config()
...
c.enable_auto_suggest = False
```
but with no success.

It would be good if you could add a clear documentation on how to disable it in a prominent place.",True,0,NONE
https://api.github.com/repos/ipython/ipython/issues/comments/1011932044,how to disable auto suggestion in Version 8,2sn,8,1101241014,2,1011932044,0,1101241014,2022-01-13T09:02:53Z,"apparently I can comment out the line 
```
auto_suggest=AutoSuggestFromHistory(),
```
in `interactiveshell.py` but is there a parameter for it?
",False,0,NONE
https://api.github.com/repos/ipython/ipython/issues/comments/1014526360,how to disable auto suggestion in Version 8,asteppke,8,1101241014,3,1014526360,0,1011932044,2022-01-17T13:17:51Z,"The autosuggestions are generated from the prompt-toolkit package. They don't seem to be configurable at the moment from the ipython side. To disable this snippet works fine in an interactive prompt:

````python
import IPython
terminal = IPython.get_ipython()
terminal.pt_app.auto_suggest = None
````
While I personally I find it great, especially in a REPL context, a configuration option would be a good idea. 
",False,0,CONTRIBUTOR
https://api.github.com/repos/ipython/ipython/issues/comments/1030915182,how to disable auto suggestion in Version 8,MarkMoretto,8,1101241014,4,1030915182,0,1014526360,2022-02-06T21:11:10Z,Can autosuggest be an opt-in thing?   I really would hate to have to keep disabling it instead of being productive.,False,0,NONE
https://api.github.com/repos/ipython/ipython/issues/comments/1030915768,how to disable auto suggestion in Version 8,2sn,8,1101241014,5,1030915768,0,1030915182,2022-02-06T21:14:45Z,There is the code from @asteppke which you could be put in startup file (I have not tested myself).,False,0,NONE
https://api.github.com/repos/ipython/ipython/issues/comments/1030916642,how to disable auto suggestion in Version 8,2sn,8,1101241014,6,1030916642,0,1030915768,2022-02-06T21:19:10Z,"I install current IPython 8.1 development from git
```shell
pip3 install -U git+https://github.com/ipython/ipython.git

```
and in my IPython config file I set
```python
c = get_config()
c.TerminalInteractiveShell.autosuggestions_provider = None
```
",False,0,NONE
https://api.github.com/repos/ipython/ipython/issues/comments/1030924573,how to disable auto suggestion in Version 8,MarkMoretto,8,1101241014,7,1030924573,0,1030916642,2022-02-06T22:07:56Z,"@2sn You're a God among men.  Where do you want to meet up so I can give you a big ol' bear hug? lol

Such a pain.  Every time I create a new venv and install IPython, I get nervous that this exact thing is going to happen. ",False,0,NONE
https://api.github.com/repos/ipython/ipython/issues/comments/1102278847,how to disable auto suggestion in Version 8,s3dev,8,1101241014,8,1102278847,0,1030924573,2022-04-19T08:25:14Z,I can confirm the startup file patch by @asteppke works excellently - AND - the method-based auto suggest for packages still works.  :-),False,0,NONE
https://api.github.com/repos/ipython/ipython/issues/comments/1242305164,how to disable auto suggestion in Version 8,CameronBieganek,8,1101241014,9,1242305164,0,1102278847,2022-09-09T18:03:24Z,"Should this issue be closed? I'm on IPython 8.2.0, and the following config code provided by @2sn works correctly:

> ```python
> c = get_config()
> c.TerminalInteractiveShell.autosuggestions_provider = None
> ```

Looks like #13475 is the PR that fixed this.",False,0,NONE
https://api.github.com/repos/ipython/ipython/issues/13457,IPython-8 warns about virtualenv created by pyenv,verdimrc,7,1103129008,1,1103129008,0,0,2022-01-14T06:56:40Z,"Hi, is there a way to disable the virtualenv warning?

I use pyenv, and every time IPython-8.0 starts from a virtual environment that's based on pyenv's miniconda, it shows this warning:

```bash
# Activate virtualenv via 'pyenv activate my_project_env' or 'pyenv activate my_base_python_env/envs/my_project_env'.
...

# Then, start ipython (installed in that virtual env).
$ ipython
/Users/xxx/.pyenv/versions/rubix-mds/lib/python3.9/site-packages/IPython/core/interactiveshell.py:802: UserWarning: Attempting to work in a virtualenv. If you encounter problems, please install IPython inside the virtualenv.
  warn(
Python 3.9.7 (default, Sep 16 2021, 08:50:36) 
Type 'copyright', 'credits' or 'license' for more information
IPython 8.0.0 -- An enhanced Interactive Python. Type '?' for help.

In [1]: import sys
   ...: 
   ...: sys.executable
Out[1]: '/Users/xxx/.pyenv/versions/rubix-mds/bin/python'

In [2]: import os
   ...: 
   ...: os.environ[""VIRTUAL_ENV""]
Out[2]: '/Users/xxx/.pyenv/versions/miniconda3-latest/envs/rubix-mds'
```

This only happens for virtualenv based on another pyenv's miniconda3-latest. No warning shown with virtualenv based on another pyenv's ""python version"".

```bash
$HOME
`-- versions
    |-- miniconda3-latest
    |   `-- envs
    |       `-- rubix-mds
    `-- rubix-mds -> $HOME/.pyenv/versions/miniconda3-latest/envs/rubix-mds
```

I'd like to know if there's a way to silent this particular warning?

Thank you.",True,0,NONE
https://api.github.com/repos/ipython/ipython/issues/comments/1012913078,IPython-8 warns about virtualenv created by pyenv,Carreau,7,1103129008,2,1012913078,0,1103129008,2022-01-14T08:32:45Z,"Hum, I would have to try, but see if you can use `warnings.filterwarnings` in one of the [startup files](https://ipython.readthedocs.io/en/stable/interactive/tutorial.html?highlight=startup#startup-files).

I'f not we can add a flag/config option to silence it.",False,0,MEMBER
https://api.github.com/repos/ipython/ipython/issues/comments/1030150044,IPython-8 warns about virtualenv created by pyenv,luca-drf,7,1103129008,3,1030150044,0,1012913078,2022-02-04T16:32:56Z,I have the same problem as @verdimrc. Note that the IPython that is executed is actually installed in the virtualenv. I started noticing this problem with IPython 7.28.0.,False,0,NONE
https://api.github.com/repos/ipython/ipython/issues/comments/1103752156,IPython-8 warns about virtualenv created by pyenv,cbrnr,7,1103129008,4,1103752156,0,1030150044,2022-04-20T10:08:19Z,"+1 for a config option to silence this warning. I'm using IPython via pipx, precisely because I didn't want to install it in every venv.

Edit: I added the following lines to `~/.ipython/profile_default/startup/00-startup.py`, but the warning still shows up:

```python
from warnings import filterwarnings

filterwarnings(""ignore"", ""Attempting to work in a virtualenv"")
```

Besides, this would make `filterwarnings` available in the global namespace, so I'd prefer a config option to hide the warning.",False,0,CONTRIBUTOR
https://api.github.com/repos/ipython/ipython/issues/comments/1184448949,IPython-8 warns about virtualenv created by pyenv,MrMino,7,1103129008,5,1184448949,0,1103752156,2022-07-14T13:27:24Z,"If you get this warning then you are _not_ running IPython from the active virtualenv.

Lots of people get confused by this, when they don't realize that their shells cache `PATH` resolution. Right after you install IPython in the virtualenv, the command `ipython` may still point to the installation from outside of your venv.

I have doubts whether adding an option to suppress this warning, thereby adding another moving part to the whole setup, will actually help.",False,0,MEMBER
https://api.github.com/repos/ipython/ipython/issues/comments/1184456258,IPython-8 warns about virtualenv created by pyenv,cbrnr,7,1103129008,6,1184456258,0,1184448949,2022-07-14T13:34:02Z,"I don't want to install IPython in every venv, that's why I run the one from my main env. Because this applies to many projects I'm using, I'd appreciate an option to disable the warning.",False,0,CONTRIBUTOR
https://api.github.com/repos/ipython/ipython/issues/comments/1184637680,IPython-8 warns about virtualenv created by pyenv,MrMino,7,1103129008,7,1184637680,0,1184456258,2022-07-14T16:18:38Z,"I'm not sure how healthy it is to do that, but I guess we can add it for that usecase.

I would still like to advise people against doing it this way. There be dragons.",False,0,MEMBER
https://api.github.com/repos/ipython/ipython/issues/comments/1184730487,IPython-8 warns about virtualenv created by pyenv,cbrnr,7,1103129008,8,1184730487,0,1184637680,2022-07-14T17:45:41Z,"Of course, the default is still to issue the warning. But people can silence it if they want.",False,0,CONTRIBUTOR
https://api.github.com/repos/ipython/ipython/issues/13461,Light editing of 8.0 what's new,jasongrout,3,1104158786,1,1104158786,0,0,2022-01-14T21:58:55Z,"I made a bunch of small editing changes to the what's new notes for 8.0, editing for grammar, spelling, light changes on phrasing, etc.

Thanks again to everyone who worked on this release!",True,0,MEMBER
https://api.github.com/repos/ipython/ipython/issues/comments/1014609497,Light editing of 8.0 what's new,Carreau,3,1104158786,2,1014609497,0,1104158786,2022-01-17T14:34:48Z,"much appreciated, hope all is well at your new Job.",False,0,MEMBER
https://api.github.com/repos/ipython/ipython/issues/comments/1035537180,Light editing of 8.0 what's new,collares,3,1104158786,3,1035537180,0,1014609497,2022-02-10T21:28:15Z,"This PR removed the ""IPython 8.0 is still in alpha/beta stage"" phrase from the ""What's New"" page, but it wasn't backported to the 8.0.x branch. Would someone confirm that 8.0.1 is a stable release? This is relevant for distributions/users [such as SageMath](https://trac.sagemath.org/ticket/33170#comment:4).",False,0,NONE
https://api.github.com/repos/ipython/ipython/issues/comments/1035560431,Light editing of 8.0 what's new,Carreau,3,1104158786,4,1035560431,0,1035537180,2022-02-10T21:52:53Z,"Yes it's stable. Anything released on pypy, or properly tagged in the repo can be considered stable.
Even master have the `.dev` suffix. 
I'm going to try to make a 8.1 soon as 8.0/8.0.1 still have a couple of things to iron out, at least on the terminal interface. 
If it's for the kernel, then yes, you can move to 8.0.1.",False,0,MEMBER
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/2011,Duplicate no silenced errors,kkmuffme,3,1034795867,1,1034795867,0,0,2021-10-25T07:52:03Z,"You haev a custom rule WordPress.PHP.NoSilencedErrors.Discouraged, but there already is a generic rule Generic.PHP.NoSilencedErrors.Forbidden

I think the custom rule can be removed.",True,0,NONE
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/950676182,Duplicate no silenced errors,dingo-d,3,1034795867,2,950676182,0,1034795867,2021-10-25T08:45:42Z,"Hi @kkmuffme, not sure if you've checked both sniffs, but the WP one differs from the Generic one because it has a list of allowed functions that can be silenced.

The doc block explains it in more details

```php
/**
 * PHP native function whitelist.
 *
 * Errors caused by calls to any of these native PHP functions
 * are allowed to be silenced as file system permissions and such
 * can cause E_WARNINGs to be thrown which cannot be prevented via
 * error checking.
 *
 * Note: only calls to global functions - in contrast to class methods -
 * are taken into account.
 *
 * Only functions for which the PHP manual annotates that an
 * error will be thrown on failure are accepted into this list.
 *
 * @since 1.1.0
 *
 * @var array <string function name> => <bool true>
 */
```",False,0,MEMBER
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/950702496,Duplicate no silenced errors,kkmuffme,3,1034795867,3,950702496,0,950676182,2021-10-25T09:12:27Z,"Thanks, I think we should get an error there though and those shouldn't be silenced. e.g. if permissions are wrong, we should get a notice and not have it silenced.",False,0,NONE
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/950739429,Duplicate no silenced errors,jrfnl,3,1034795867,4,950739429,0,950702496,2021-10-25T09:52:50Z,"> I think we should get an error there though and those shouldn't be silenced. e.g. if permissions are wrong, we should get a notice and not have it silenced.

@kkmuffme Please read the information available about the custom properties so you actually know what you are talking about: https://github.com/WordPress/WordPress-Coding-Standards/wiki/Customizable-sniff-properties#error-silencing-use-build-in-function-whitelist and https://github.com/WordPress/WordPress-Coding-Standards/wiki/Customizable-sniff-properties#error-silencing-custom-function-whitelist

The short of it is that if you use the `WordPress-Core` ruleset, the build-in list will be used, but if you use the `WordPress-Extra` ruleset, it won't be used.

You can change it from a warning to an error yourself in your custom ruleset:
```xml
<rule ref=""WordPress.PHP.NoSilencedErrors"">
    <type>error</type>
</rule>
```",False,0,MEMBER
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/2013,Improve/clarify the error message for the WordPress.Arrays.ArrayKeySpacingRestrictions.NoSpacesAroundArrayKeys sniff ,pbiron,8,1042701050,1,1042701050,0,0,2021-11-02T18:48:30Z,"## Is your feature request related to a problem?
<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->

Suppose I have the following code:

```
$variable                         = 'foo';
$my_array[""a_string_{$variable}""] = 'bar';
```

This results in the following error message:

> ERROR | Array keys must be surrounded by spaces unless they contain a string or an integer.
>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|   (WordPress.Arrays.ArrayKeySpacingRestrictions.NoSpacesAroundArrayKeys)

Which is not technically correct, since the array key is a string...it just contains an interpolation.

## Describe the solution you'd like
<!--
A clear and concise description of what you want to happen.

Any (sniff) feature request/suggestion should be accompanied by code samples of what should be detected.
And preferably also code samples of code which shouldn't be flagged.
-->

The error message would be more correct if it were something like:

> ERROR | Array keys must be surrounded by spaces unless they contain an uninterpolated string or an integer.
>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|   (WordPress.Arrays.ArrayKeySpacingRestrictions.NoSpacesAroundArrayKeys)
",True,0,NONE
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/958222437,Improve/clarify the error message for the WordPress.Arrays.ArrayKeySpacingRestrictions.NoSpacesAroundArrayKeys sniff ,jrfnl,8,1042701050,2,958222437,0,1042701050,2021-11-02T21:58:39Z,"@pbiron What about using ""unless they contain a **plain** string or an integer"" ? Want to send in a PR ?",False,0,MEMBER
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/958256124,Improve/clarify the error message for the WordPress.Arrays.ArrayKeySpacingRestrictions.NoSpacesAroundArrayKeys sniff ,pbiron,8,1042701050,3,958256124,0,958222437,2021-11-02T22:14:18Z,"Yeah, `uninterpolated string` is probably too ""technical"" :-)  But `plain string` is not clear either.  Let me think about it (and read the PHP manual to see how it describes uninterpolated strings) and see if I can come up with better wording.

And then I do a PR.

thanx.",False,0,NONE
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/961153773,Improve/clarify the error message for the WordPress.Arrays.ArrayKeySpacingRestrictions.NoSpacesAroundArrayKeys sniff ,GaryJones,8,1042701050,4,961153773,0,958256124,2021-11-04T15:26:53Z,"""...single-quotable string..."" ?",False,0,MEMBER
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/961159213,Improve/clarify the error message for the WordPress.Arrays.ArrayKeySpacingRestrictions.NoSpacesAroundArrayKeys sniff ,pbiron,8,1042701050,5,961159213,0,961153773,2021-11-04T15:32:36Z,How about `an integer or string without embedded variables`?,False,0,NONE
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/961190773,Improve/clarify the error message for the WordPress.Arrays.ArrayKeySpacingRestrictions.NoSpacesAroundArrayKeys sniff ,jrfnl,8,1042701050,6,961190773,0,961159213,2021-11-04T16:07:58Z,"> ""...single-quotable string..."" ?

A double quoted string without interpolated variables is also fine.  `$a[""mc'donald""]`. This may give the wrong impression that single quotes are required.

> How about `an integer or string without embedded variables`?

Not sure how well that would read as integers cannot contain embedded variables.

Also, it's not just about _embedded_ or interpolated variables. The rule also applies to concatenated keys or keys created via a calculation: `$a[ 'a' . $text ]` or `$a[  1 + $i ]`


The [manual](https://developer.wordpress.org/coding-standards/wordpress-coding-standards/php/#space-usage) describes it like so:

> When referring to array items, only include a space around the index if it is a variable...

But the sniff was put in place largely as it is now and has been around since 2014, so we may also want to improve the text in the coding standards manual.",False,0,MEMBER
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/961205352,Improve/clarify the error message for the WordPress.Arrays.ArrayKeySpacingRestrictions.NoSpacesAroundArrayKeys sniff ,pbiron,8,1042701050,7,961205352,0,961190773,2021-11-04T16:23:58Z,"> Also, it's not just about _embedded_ or interpolated variables. The rule also applies to concatenated keys or keys created via a calculation: `$a[ 'a' . $text ]` or `$a[ 1 + $i ]`

Ah...that I didn't know.  Just as an FYI: I opened this issue after getting the error in a plugin I'm writing that uses WPCS (i.e., not part of a core patch).

> The [manual](https://developer.wordpress.org/coding-standards/wordpress-coding-standards/php/#space-usage) describes it like so:
> 
> > When referring to array items, only include a space around the index if it is a variable...
> 
> But the sniff was put in place largely as it is now and has been around since 2014, so we may also want to improve the text in the coding standards manual.

That sounds like a good idea.  At the very least, interpolated/concatenated strings and calculated ints should be added to the manual as `incorrect` examples.

This is probably out-of-scope (for this issue at least), but how much work would be involved to add links to the relevant section of the manual in error messages?  A substantial amount I suspect.  Just a thought.",False,0,NONE
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/1374672749,Improve/clarify the error message for the WordPress.Arrays.ArrayKeySpacingRestrictions.NoSpacesAroundArrayKeys sniff ,jrfnl,8,1042701050,8,1374672749,0,961205352,2023-01-08T00:45:34Z,"Has anyone come up with better phrasing in the mean time ? Now would be the time to address this. If not, I suggest we close this issue.",False,0,MEMBER
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/1678370022,Improve/clarify the error message for the WordPress.Arrays.ArrayKeySpacingRestrictions.NoSpacesAroundArrayKeys sniff ,jrfnl,8,1042701050,9,1678370022,0,1374672749,2023-08-15T03:19:41Z,Closing for lack of response.,False,0,MEMBER
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/2017,Calling file_exists should count as sanitized input,kkmuffme,9,1067096052,1,1067096052,0,0,2021-11-30T11:03:13Z,"```
if ( !empty( $_POST['hello'] ) && file_exists( $_POST['hello'] ) ) {
    $hello = $_POST['hello'];
}
```

Atm it's reported as `WordPress.Security.ValidatedSanitizedInput`

Same for is_file, is_dir, is_link

EDIT:
same also for:

```
require_once( $_POST['hello'] );
require_once( $_POST['hello'] . '/world.php' );
require_once( '/foo/' . $_POST['hello'] . '/world.php' );
```
 and the same for `require`, `include` and `include_once` too, since there is no attack vector a ""regular"" sanitization with sanitize_text_field would solve/improve security.",True,0,NONE
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/982549580,Calling file_exists should count as sanitized input,jrfnl,9,1067096052,2,982549580,0,1067096052,2021-11-30T11:30:49Z,"@kkmuffme Maybe we have different ideas of sanitization, but this code sample - to me - is a clear security risk....",False,0,MEMBER
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/982549941,Calling file_exists should count as sanitized input,dingo-d,9,1067096052,3,982549941,0,982549580,2021-11-30T11:31:18Z,How is checking if file exists a valid sanitization? 🤔 ,False,0,MEMBER
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/982555018,Calling file_exists should count as sanitized input,kkmuffme,9,1067096052,4,982555018,0,982549941,2021-11-30T11:38:40Z,"Thanks for the quick feedback. 

>to me - is a clear security risk....

Could you please explain the attack vector you have in mind?

The only one I can think of:
You would have to have a file on your server that has an SQL injection as file name.
Since we don't create files willy nilly, but sanitize names before creating them, this won't be an issue.",False,0,NONE
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/982589374,Calling file_exists should count as sanitized input,jrfnl,9,1067096052,5,982589374,0,982555018,2021-11-30T12:27:16Z,"> Could you please explain the attack vector you have in mind?

Well, a file name is generally later used to include or read the file. While the above code doesn't do that, it does assign the unsanitized value to a variable which will not be flagged anymore as unsanitized.
So any variations of the below would be accepted and could then end up being included and/or displayed:
```
.env
wp-config.php.bak
../../../.htpasswd
site.sql

... etc
```


",False,0,MEMBER
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/982596992,Calling file_exists should count as sanitized input,kkmuffme,9,1067096052,6,982596992,0,982589374,2021-11-30T12:37:25Z,"Correct, but this is not what `WordPress.Security.ValidatedSanitizedInput` checks/reports for currently either.

Using `sanitize_text_field( wp_unslash( $_POST['hello'] ) )` will give you exactly the same thing, as my code with file_exists.

Using your example:
```
// $_POST['hello'] = '../../../.htpasswd'
echo sanitize_text_field( wp_unslash( $_POST['hello'] ) );
```

you will also get:

```
.env
wp-config.php.bak
../../../.htpasswd
site.sql
... etc
```

But this is not reported by `WordPress.Security.ValidatedSanitizedInput` bc it counts as sanitized - but for attack vector, this is as unsanitized as my file_exists code",False,0,NONE
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/982653763,Calling file_exists should count as sanitized input,swissspidy,9,1067096052,7,982653763,0,982596992,2021-11-30T13:49:38Z,"That's because `WordPress.Security.ValidatedSanitizedInput` does not know whether your `$_POST['hello']` variable is supposed to be a file path or something else.

When dealing with file paths like in your examples I highly recommend using `sanitize_file_name()` and `validate_file()`. Everything else is a potential security risk.

When you use those functions, `WordPress.Security.ValidatedSanitizedInput` will recognize them and treat your input as sanitized. As you can see from this list:

https://github.com/WordPress/WordPress-Coding-Standards/blob/9e89040631985ec1493e6efb551c75e0383edf6c/WordPress/Sniff.php#L180-L234",False,0,MEMBER
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/983395032,Calling file_exists should count as sanitized input,kkmuffme,9,1067096052,8,983395032,0,982653763,2021-12-01T08:14:41Z,"1)
>That's because WordPress.Security.ValidatedSanitizedInput does not know whether your $_POST['hello'] variable is supposed to be a file path or something else.

That's a great idea to extend it though: store the type that is validated (e.g. text, filename, url) and report an error if it's used for something else (e.g. if I use something I sanitized as text field in e.g. touch(), file_get_contents(),...)

b) this also leads to another suggestion from your text: only allow `sanitize_file_name()` or `validate_file()` on `$_FILES` superglobal

2) 
>Everything else is a potential security risk.

True, when we CREATE new files. Not true, when we check EXISTING files.

e.g. there is no risk here whatsoever (and this should not be reported):

```
require_once( $_POST['hello'] );
require_once( $_POST['hello'] . '/world.php' );
require_once( '/foo/' . $_POST['hello'] . '/world.php' );
// same with require/include/include_once
```

In a similar vein, let's take a look at my original suggestion too:

```
if ( !empty( $_POST['hello'] ) && file_exists( $_POST['hello'] ) ) {
    $hello = $_POST['hello'];
}
``` 

a) if file exists returns true, we know that the file exists.
b) we also know, that if a file exists, it has been created with a sanitized name (e.g. via `sanitize_file_name()`)

Therefore, we know that if a variable which contains a file path which exists, is sanitized.
Therefore file_exists is a sufficient check for sanitization, no matter for what the variable is used (since sanitize file name is at least as strict as other sanitize functions like sanitize name or url sanitizing)

I'd appreciate if you point out any attack vectors you guys see. Since currently I only see dogmatic replies without actually examining the issue.

",False,0,NONE
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/983439284,Calling file_exists should count as sanitized input,swissspidy,9,1067096052,9,983439284,0,983395032,2021-12-01T09:13:19Z,"> we also know, that if a file exists, it has been created with a sanitized name (e.g. via `sanitize_file_name()`)

That is not true. `$_POST['hello'] = '../../../.htpasswd'; file_exists( $_POST['hello'] )` would also return `true`, but clearly the input has not been sanitized.

Doing something like `require_once( $_POST['hello'] )` without proper input sanitization allows an attacker to include arbitrary files on your server. Such a vulnerability is called Local File Inclusion and is often just the starting point of a malicious attack.

Articles like https://outpost24.com/blog/from-local-file-inclusion-to-remote-code-execution-part-1 might explain it a bit better.

Aside: If the `allow_url_include` PHP setting is on, this would even allow including arbitrary files _from a remote server_!

```php
$_POST['hello'] = 'http://some-attacker-website/path/to/malicious/file';
require_once( $_POST['hello'] )
```

That is clearly a security risk.",False,0,MEMBER
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/983503171,Calling file_exists should count as sanitized input,kkmuffme,9,1067096052,10,983503171,0,983439284,2021-12-01T10:30:50Z,"You're right (directories/is_dir would be safe though?)

Local file inclusion: valid point.

Should I open a separate ticket for the suggestion of:
only allow sanitize_file_name() or validate_file() on $_FILES superglobal
",False,0,NONE
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/2021,"Fatal error: Uncaught TypeError: vsprintf(): Argument #2 ($values) must be of type array, string given in ~/.composer/vendor/squizlabs/php_codesniffer/src/Files/File.php:1056",goodevilgenius,5,1074544095,1,1074544095,0,0,2021-12-08T15:38:49Z,"## Bug Description

1. Ran `phpcs --standard=WordPress /path/to/file.php`
2. Saw exception

## Minimal Code Snippet

The issue happens when running this command:
```bash
phpcs --standard=WordPress /path/to/file.php
```

... over a file containing this code:
```php
function foo
{

}
```

## Error Code

Expected exactly one space between closing parenthesis and opening control structure; ""T_WHITESPACE"" found.

## Custom ruleset

None

## Environment

| Question               | Answer
| ------------------------| -------
| PHP version             | 8.0.13
| PHP_CodeSniffer version | 3.6.1
| WPCS version            | `stable` branch
| WPCS install type       | `git clone`


## Additional Context (optional)

Stacktrace:

```
Fatal error: Uncaught TypeError: vsprintf(): Argument #2 ($values) must be of type array, string given in ~/.composer/vendor/squizlabs/php_codesniffer/src/Files/File.php:1056
Stack trace:
#0 ~/.composer/vendor/squizlabs/php_codesniffer/src/Files/File.php(1056): vsprintf('Expected exactl...', '\n')
#1 ~/.composer/vendor/squizlabs/php_codesniffer/src/Files/File.php(672): PHP_CodeSniffer\Files\File->addMessage(true, 'Expected exactl...', 15, 1, 'ExtraSpaceAfter...', '\n', 5, true)
#2 ~/.composer/vendor/squizlabs/php_codesniffer/src/Files/File.php(780): PHP_CodeSniffer\Files\File->addError('Expected exactl...', 57, 'ExtraSpaceAfter...', '\n', 0, true)
#3 ~/.local/share/wpcs/WordPress/Sniffs/WhiteSpace/ControlStructureSpacingSniff.php(396): PHP_CodeSniffer\Files\File->addFixableError('Expected exactl...', 57, 'ExtraSpaceAfter...', '\n')
#4 ~/.local/share/wpcs/WordPress/Sniff.php(910): WordPressCS\WordPress\Sniffs\WhiteSpace\ControlStructureSpacingSniff->process_token(57)
#5 ~/.composer/vendor/squizlabs/php_codesniffer/src/Files/File.php(498): WordPressCS\WordPress\Sniff->process(Object(PHP_CodeSniffer\Files\LocalFile), 57)
#6 ~/.composer/vendor/squizlabs/php_codesniffer/src/Files/LocalFile.php(92): PHP_CodeSniffer\Files\File->process()
#7 ~/.composer/vendor/squizlabs/php_codesniffer/src/Runner.php(631): PHP_CodeSniffer\Files\LocalFile->process()
#8 ~/.composer/vendor/squizlabs/php_codesniffer/src/Runner.php(434): PHP_CodeSniffer\Runner->processFile(Object(PHP_CodeSniffer\Files\LocalFile))
#9 ~/.composer/vendor/squizlabs/php_codesniffer/src/Runner.php(114): PHP_CodeSniffer\Runner->run()
#10 ~/.composer/vendor/squizlabs/php_codesniffer/bin/phpcs(18): PHP_CodeSniffer\Runner->runPHPCS()
#11 {main}
  thrown in ~/.composer/vendor/squizlabs/php_codesniffer/src/Files/File.php on line 1056
```

This diff fixes the issue:

```diff
diff --git a/WordPress/Sniffs/WhiteSpace/ControlStructureSpacingSniff.php b/WordPress/Sniffs/WhiteSpace/ControlStructureSpacingSniff.php
index 5f7b9a3c..293d78c7 100644
--- a/WordPress/Sniffs/WhiteSpace/ControlStructureSpacingSniff.php
+++ b/WordPress/Sniffs/WhiteSpace/ControlStructureSpacingSniff.php
@@ -392,7 +392,7 @@ class ControlStructureSpacingSniff extends Sniff {
 					$error,
 					$stackPtr,
 					'ExtraSpaceAfterCloseParenthesis',
-					$this->tokens[ ( $parenthesisCloser + 1 ) ]['content']
+					$this->tokens[ ( $parenthesisCloser + 1 ) ]
 				);
 
 				if ( true === $fix ) {
```

## Tested Against `develop` branch?
- [ ] I have verified the issue still exists in the `develop` branch of WPCS.
    * I did not. I tried, but got a completely different error: ""Referenced sniff PHPCSUtils does not exist",True,0,NONE
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/988944928,"Fatal error: Uncaught TypeError: vsprintf(): Argument #2 ($values) must be of type array, string given in ~/.composer/vendor/squizlabs/php_codesniffer/src/Files/File.php:1056",jrfnl,5,1074544095,2,988944928,0,1074544095,2021-12-08T16:01:26Z,"This was already fixed in #1935. The fix will be included in the next release.

Also see #1967

P.s.: do not use your ""fix"" as it is not the right way to fix this.",False,0,MEMBER
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/988983357,"Fatal error: Uncaught TypeError: vsprintf(): Argument #2 ($values) must be of type array, string given in ~/.composer/vendor/squizlabs/php_codesniffer/src/Files/File.php:1056",goodevilgenius,5,1074544095,3,988983357,0,988944928,2021-12-08T16:44:47Z,"@jrfnl Thanks. I couldn't find the previous issue.

I'll just cherry-pick that commit into my local branch, since I couldn't get develop to work.",False,0,NONE
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/1183514080,"Fatal error: Uncaught TypeError: vsprintf(): Argument #2 ($values) must be of type array, string given in ~/.composer/vendor/squizlabs/php_codesniffer/src/Files/File.php:1056",Mte90,5,1074544095,4,1183514080,0,988983357,2022-07-13T17:53:01Z,I am facing the same error but the latest release is 2.3.0 of may 2020...,False,0,NONE
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/1235895052,"Fatal error: Uncaught TypeError: vsprintf(): Argument #2 ($values) must be of type array, string given in ~/.composer/vendor/squizlabs/php_codesniffer/src/Files/File.php:1056",bgoewert,5,1074544095,5,1235895052,0,1183514080,2022-09-02T21:03:26Z,"Still seeing this same issue using the latest release (v2.3.0 May 2020).
@jrfnl Any update on that next release?

__Edit:__ Looks like it's working fine on gh actions, so nvm? It was not working for me locally.

```
PHP Fatal error:  Uncaught TypeError: vsprintf(): Argument #2 ($values) must be of type array, string given in /redacted/vendor/squizlabs/php_codesniffer/src/Files/File.php:1056
Stack trace:
#0 /redacted/vendor/squizlabs/php_codesniffer/src/Files/File.php(1056): vsprintf()
#1 /redacted/vendor/squizlabs/php_codesniffer/src/Files/File.php(672): PHP_CodeSniffer\Files\File->addMessage()
#2 /redacted/vendor/squizlabs/php_codesniffer/src/Files/File.php(780): PHP_CodeSniffer\Files\File->addError()
#3 /redacted/vendor/wp-coding-standards/wpcs/WordPress/Sniffs/WhiteSpace/ControlStructureSpacingSniff.php(205): PHP_CodeSniffer\Files\File->addFixableError()
#4 /redacted/vendor/wp-coding-standards/wpcs/WordPress/Sniff.php(910): WordPressCS\WordPress\Sniffs\WhiteSpace\ControlStructureSpacingSniff->process_token()
#5 /redacted/vendor/squizlabs/php_codesniffer/src/Files/File.php(498): WordPressCS\WordPress\Sniff->process()
#6 /redacted/vendor/squizlabs/php_codesniffer/src/Files/LocalFile.php(92): PHP_CodeSniffer\Files\File->process()
#7 /redacted/vendor/squizlabs/php_codesniffer/src/Runner.php(628): PHP_CodeSniffer\Files\LocalFile->process()
#8 /redacted/vendor/squizlabs/php_codesniffer/src/Runner.php(500): PHP_CodeSniffer\Runner->processFile()
#9 /redacted/vendor/squizlabs/php_codesniffer/src/Runner.php(114): PHP_CodeSniffer\Runner->run()
#10 /redacted/vendor/squizlabs/php_codesniffer/bin/phpcs(18): PHP_CodeSniffer\Runner->runPHPCS()
#11 /redacted/vendor/bin/phpcs(117): include('...')
#12 {main}
  thrown in /redacted/vendor/squizlabs/php_codesniffer/src/Files/File.php on line 1056
```",False,0,NONE
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/1287799868,"Fatal error: Uncaught TypeError: vsprintf(): Argument #2 ($values) must be of type array, string given in ~/.composer/vendor/squizlabs/php_codesniffer/src/Files/File.php:1056",ZachWatkins,5,1074544095,6,1287799868,0,1235895052,2022-10-22T13:54:44Z,"I am also experiencing this issue locally.
PHP: 8.1.7
squizlabs/php_codesniffer 3.7.1
wp-coding-standards/wpcs: 2.3.0

This is using my project's .phpcs.xml.dist file which I copied from a wpvip repository (below).

If I run phpcs and specify any non-WordPress standard it works correctly and outputs a report to the terminal. Example: `./vendor/bin/phpcs --standard=Zend functions.php`

`<?xml version=""1.0""?>
<ruleset name=""Template-Genesis-Theme"">

	<description>Defines PHPCS configuration that applies for this repository. Based on the Gutenberg repository.</description>

	<!-- Define code to exclude from scans -->
	<exclude-pattern>vendor/*</exclude-pattern>
	<exclude-pattern>config/*</exclude-pattern>
	<exclude-pattern>assets/*</exclude-pattern>
	<exclude-pattern>languages/*</exclude-pattern>

	<config name=""testVersion"" value=""5.6-""/>
	<config name=""text_domain"" value=""template-genesis-theme""/>

	<rule ref=""WordPress-Core""/>
	<rule ref=""WordPress-Docs""/>
	<rule ref=""WordPress.WP.I18n""/>


	<!-- Do not require docblocks for unit tests -->
	<rule ref=""Squiz.Commenting.FunctionComment.Missing"">
		<exclude-pattern>phpunit/*</exclude-pattern>
	</rule>
	<rule ref=""Squiz.Commenting.FileComment.Missing"">
		<exclude-pattern>phpunit/*</exclude-pattern>
	</rule>
	<rule ref=""Squiz.Commenting.ClassComment.Missing"">
		<exclude-pattern>phpunit/*</exclude-pattern>
	</rule>
	<rule ref=""Squiz.Commenting.ClassComment.SpacingAfter"">
		<exclude-pattern>phpunit/*</exclude-pattern>
	</rule>
	<rule ref=""Squiz.Commenting.FunctionComment.MissingParamTag"">
		<exclude-pattern>phpunit/*</exclude-pattern>
	</rule>
	<rule ref=""Generic.Commenting.DocComment.Empty"">
    	<exclude-pattern>phpunit/*</exclude-pattern>
    </rule>
	<rule ref=""Generic.Commenting.DocComment.MissingShort"">
		<exclude-pattern>phpunit/*</exclude-pattern>
	</rule>
	<rule ref=""Squiz.Commenting.VariableComment.Missing"">
		<exclude-pattern>phpunit/*</exclude-pattern>
	</rule>
	<rule ref=""Squiz.Commenting.FunctionCommentThrowTag.Missing"">
		<exclude-pattern>phpunit/*</exclude-pattern>
	</rule>

	<!-- Use the standard VIP Go Ruleset -->
	<rule ref=""WordPress-VIP-Go""/>

</ruleset>
`",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/9405,"Fix ""Illegal mix of collations"" in MultiTableDeleteExecutor - Take 2",mlocati,5,1107934880,1,1107934880,0,0,2022-01-19T10:37:47Z,"
When database tables use a collation that's not the default database one, MultiTableDeleteExecutor fails with this error:

```
In AbstractMySQLDriver.php line 128:
                                                                                                                                                    
  [Doctrine\DBAL\Exception\DriverException]                                                                                                         
  An exception occurred while executing 'DELETE FROM MessengerTaskProcesses WHERE (id) IN (SELECT id FROM MessengerProcesses_id_tmp)':              
                                                                                                                                                    
  SQLSTATE[HY000]: General error: 1267 Illegal mix of collations (utf8mb4_unicode_ci,IMPLICIT) and (utf8mb4_general_ci,IMPLICIT) for operation '='
```

This issue should be fixed by using the configured charset/collation.

Let's first add a test that detects the issue: I'll then update this PR to fix it.

PS: Supersedes #9370",True,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/1016321759,"Fix ""Illegal mix of collations"" in MultiTableDeleteExecutor - Take 2",mlocati,5,1107934880,2,1016321759,0,1107934880,2022-01-19T10:53:25Z,"Tests are failing because setup-php can't configure PHP 7.1, but the MySQL tests are passing and they shouldn't, at least they don't pass on my local PC:

```
$ ./vendor/bin/phpunit --stop-on-error

PHPUnit 9.5.11 by Sebastian Bergmann and contributors.

Using DB driver Doctrine\DBAL\Driver\PDO\MySQL\Driver
.............................................................   61 / 3602 (  1%)
.............................................................  122 / 3602 (  3%)
.............................................................  183 / 3602 (  5%)
.............................................................  244 / 3602 (  6%)
..............SS.............................................  305 / 3602 (  8%)
.............................................................  366 / 3602 ( 10%)
...........E

Time: 00:11.159, Memory: 74.00 MB

There was 1 error:

1) Doctrine\Tests\ORM\Functional\AdvancedDqlQueryWithCollationTest::testDeleteAs
Exception: [Doctrine\DBAL\Exception\DriverException] An exception occurred while executing a query: SQLSTATE[HY000]: General error: 1267 Illegal mix of collations (utf8_roman_ci,IMPLICIT) and (utf8_general_ci,IMPLICIT) for operation '='

With queries:
12. SQL: 'DROP TEMPORARY TABLE productroman_features_id_tmp' Params:
11. SQL: 'DELETE FROM productroman_colors WHERE (sku) IN (SELECT sku FROM productroman_features_id_tmp)' Params:
10. SQL: 'INSERT INTO productroman_features_id_tmp (sku) SELECT t0.sku FROM productroman_colors t0 INNER JOIN productroman_features p0_ ON t0.sku = p0_.sku' Params:
9. SQL: 'CREATE TEMPORARY TABLE productroman_features_id_tmp (sku VARCHAR(255) NOT NULL)' Params:
8. SQL: '""COMMIT""' Params:
7. SQL: 'INSERT INTO productroman_colors (sku, colorName, quantity) VALUES (?, ?, ?)' Params: 'P03', 'Blue', 123
6. SQL: 'INSERT INTO productroman_features (sku, discr) VALUES (?, ?)' Params: 'P03', 'color'
5. SQL: 'INSERT INTO productroman_colors (sku, colorName, quantity) VALUES (?, ?, ?)' Params: 'P02', 'Green', 12
4. SQL: 'INSERT INTO productroman_features (sku, discr) VALUES (?, ?)' Params: 'P02', 'color'
3. SQL: 'INSERT INTO productroman_colors (sku, colorName, quantity) VALUES (?, ?, ?)' Params: 'P01', 'Red', 1
2. SQL: 'INSERT INTO productroman_features (sku, discr) VALUES (?, ?)' Params: 'P01', 'color'
1. SQL: '""START TRANSACTION""' Params:

Trace:
/path/to/vendor/doctrine/dbal/src/Connection.php:1767
/path/to/vendor/doctrine/dbal/src/Connection.php:1706
/path/to/vendor/doctrine/dbal/src/Connection.php:1147
/path/to/lib/Doctrine/ORM/Query/Exec/MultiTableDeleteExecutor.php:121
/path/to/lib/Doctrine/ORM/Query.php:325
/path/to/lib/Doctrine/ORM/AbstractQuery.php:1181
/path/to/lib/Doctrine/ORM/AbstractQuery.php:1135
/path/to/lib/Doctrine/ORM/AbstractQuery.php:871
/path/to/tests/Doctrine/Tests/ORM/Functional/AdvancedDqlQueryWithCollationTest.php:54
/path/to/vendor/phpunit/phpunit/src/Framework/TestCase.php:1545
/path/to/vendor/phpunit/phpunit/src/Framework/TestCase.php:1151
/path/to/vendor/phpunit/phpunit/src/Framework/TestResult.php:726
/path/to/vendor/phpunit/phpunit/src/Framework/TestCase.php:903
/path/to/vendor/phpunit/phpunit/src/Framework/TestSuite.php:678
/path/to/vendor/phpunit/phpunit/src/Framework/TestSuite.php:678
/path/to/vendor/phpunit/phpunit/src/Framework/TestSuite.php:678
/path/to/vendor/phpunit/phpunit/src/TextUI/TestRunner.php:670
/path/to/vendor/phpunit/phpunit/src/TextUI/Command.php:143
/path/to/vendor/phpunit/phpunit/src/TextUI/Command.php:96
phpvfscomposer:///path/to/vendor/phpunit/phpunit/phpunit:97
/path/to/vendor/bin/phpunit:105


/path/to/tests/Doctrine/Tests/OrmFunctionalTestCase.php:858
phpvfscomposer:///path/to/vendor/phpunit/phpunit/phpunit:97

Caused by
Doctrine\DBAL\Exception\DriverException: An exception occurred while executing a query: SQLSTATE[HY000]: General error: 1267 Illegal mix of collations (utf8_roman_ci,IMPLICIT) and (utf8_general_ci,IMPLICIT) for operation '='

/path/to/vendor/doctrine/dbal/src/Driver/API/MySQL/ExceptionConverter.php:119
/path/to/vendor/doctrine/dbal/src/Connection.php:1767
/path/to/vendor/doctrine/dbal/src/Connection.php:1706
/path/to/vendor/doctrine/dbal/src/Connection.php:1147
/path/to/lib/Doctrine/ORM/Query/Exec/MultiTableDeleteExecutor.php:121
/path/to/lib/Doctrine/ORM/Query.php:325
/path/to/lib/Doctrine/ORM/AbstractQuery.php:1181
/path/to/lib/Doctrine/ORM/AbstractQuery.php:1135
/path/to/lib/Doctrine/ORM/AbstractQuery.php:871
/path/to/tests/Doctrine/Tests/ORM/Functional/AdvancedDqlQueryWithCollationTest.php:54
phpvfscomposer:///path/to/vendor/phpunit/phpunit/phpunit:97
```

Any idea why they pass in the GitHub Actions?",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/1016459968,"Fix ""Illegal mix of collations"" in MultiTableDeleteExecutor - Take 2",mlocati,5,1107934880,3,1016459968,0,1016321759,2022-01-19T13:21:09Z,"> Tests are failing because setup-php can't configure PHP 7.1

I updated this PR with [a minor change](https://github.com/doctrine/orm/pull/9405/commits/bf43c1f25c2f5e3a2241a3bdfee5856ca6fda395), and now setup-php installed PHP 7.1, so tests are passing (but they shouldn't)",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/1024107856,"Fix ""Illegal mix of collations"" in MultiTableDeleteExecutor - Take 2",beberlei,5,1107934880,4,1024107856,0,1016459968,2022-01-28T11:04:00Z,I ust realized the commit from https://github.com/doctrine/orm/pull/9370 is not in this PR here,False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/1024237825,"Fix ""Illegal mix of collations"" in MultiTableDeleteExecutor - Take 2",mlocati,5,1107934880,5,1024237825,0,1024107856,2022-01-28T13:43:25Z,"> I ust realized the commit from #9370 is not in this PR here

Nope, I first want to have tests failing (and that's why this PR is still in the Draft state).

They fail on my local machine, but not in GitHub Actions.",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/1024285113,"Fix ""Illegal mix of collations"" in MultiTableDeleteExecutor - Take 2",mlocati,5,1107934880,6,1024285113,0,1024237825,2022-01-28T14:38:55Z,"Nope, tests keep failing on my PC (`Exception: [Doctrine\DBAL\Exception\DriverException] An exception occurred while executing a query: SQLSTATE[HY000]: General error: 1267 Illegal mix of collations (utf8_roman_ci,IMPLICIT) and
 (utf8_general_ci,IMPLICIT) for operation '='`), but succeeding in GitHub Actions,
Maybe people at MySQL changed/fixed something between MySQL 5.7.24 (the one I'm using) and MySQL 5.7.37 (the one used in GitHub Actions).
",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/9408,Virtual columns will always have schema changes when checked with `orm:schema-tool:update`,villermen,10,1108501728,1,1108501728,0,0,2022-01-19T19:59:51Z,"### Bug Report

|    Q        |   A
|------------ | ------
| BC Break    | no
| Version     | 2.11.0

#### Summary

A virtual column defined via the new capabilities of v2.11 will always have changes when checked with the `orm:schema-tool:update` console command.

#### How to reproduce

Consider the following mapping on a MySQL 8 database:

```php
#[Entity]
class Website
{
    #[Column(
        type: 'string',
        insertable: false,
        updatable: false,
        columnDefinition: ""VARCHAR(255) GENERATED ALWAYS AS ('foo') VIRTUAL"",
        generated: 'ALWAYS'
    )]
    private ?string $url = null;
} 
```

Running `orm:schema-tool:update --dump-sql --force` consecutively will always yield the change:

```mysql
ALTER TABLE website CHANGE url url VARCHAR(255) GENERATED ALWAYS AS ('foo') VIRTUAL;
```

#### Expected behavior

Expected behavior is to either compare the column definition from the database with the schema, or ignore it completely and only check column existence when it has a custom definition. Both situations would lead to the changes being generated only once.
",True,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/1016888119,Virtual columns will always have schema changes when checked with `orm:schema-tool:update`,beberlei,10,1108501728,2,1016888119,0,1108501728,2022-01-19T21:34:44Z,"What version of DBAL are you using? Older versions will always cause a change with `columnDefinition`, DBAL 3.3 I believe is the first version that checks this differently.",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/1017875966,Virtual columns will always have schema changes when checked with `orm:schema-tool:update`,villermen,10,1108501728,3,1017875966,0,1016888119,2022-01-20T20:05:39Z,I'm currently on v2.13.7 so that might explain it. I'll try (force-)updating it to check if it happens in the latest version.,False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/1018311352,Virtual columns will always have schema changes when checked with `orm:schema-tool:update`,villermen,10,1108501728,4,1018311352,0,1017875966,2022-01-21T09:02:38Z,"@beberlei I've managed to update to doctrine/dbal 3.3.0. The result for the ""website"" example is still the same. In addition, another column manually defined as `ENUM` that previously existed now exposes the same behavior:

```php
#[Entity]
class Website
{
    #[Column(
        type: 'string',
        insertable: false,
        updatable: false,
        columnDefinition: ""VARCHAR(255) GENERATED ALWAYS AS ('foo') VIRTUAL"",
        generated: 'ALWAYS'
    )]
    private ?string $url = null;

    #[Column(type: 'string', nullable: true, columnDefinition: ""ENUM('preparing', 'pending', 'approved', 'rejected') DEFAULT NULL"")]
    private ?string $status = null;
} 
```

`orm:schema-tool:update --dump-sql --force && orm:schema-tool:update --dump-sql --force`

```mysql
ALTER TABLE website CHANGE url url VARCHAR(255) GENERATED ALWAYS AS ('foo') VIRTUAL, CHANGE status status ENUM('foo', 'bar') DEFAULT NULL;
```",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/1018341159,Virtual columns will always have schema changes when checked with `orm:schema-tool:update`,derrabus,10,1108501728,5,1018341159,0,1018311352,2022-01-21T09:39:57Z,This sounds like the kind of problem @bcremer tried to tackle with #9410.,False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/1018352203,Virtual columns will always have schema changes when checked with `orm:schema-tool:update`,bcremer,10,1108501728,6,1018352203,0,1018341159,2022-01-21T09:55:45Z,@villermen For your `$status` column try setting `length=0`. That fixed the schema diff for us.,False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/1018373159,Virtual columns will always have schema changes when checked with `orm:schema-tool:update`,villermen,10,1108501728,7,1018373159,0,1018352203,2022-01-21T10:21:33Z,"Adding `length: 0` to the attribute on `$status` indeed removed it from the schema diff.  That doesn't make much sense to me, but I can work with that =)",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/1018499775,Virtual columns will always have schema changes when checked with `orm:schema-tool:update`,bcremer,10,1108501728,8,1018499775,0,1018373159,2022-01-21T13:21:02Z,"@villermen 
I would advice to step into `\Doctrine\DBAL\Schema\Comparator::diffColumn`  to find out what property of the column is different.

In case of the `enum` you will observe that the `length` property is different so it can be adjusted in the Entity accordingly.
That might help you to find the different property in your generated column case.

On a related note:
It would be super helpful to have a debug/verbose mode for the `\Doctrine\DBAL\Schema\Comparator` that logs what parts of the table/column is different. One should create a PR for that :disguised_face: ",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/1019164307,Virtual columns will always have schema changes when checked with `orm:schema-tool:update`,villermen,10,1108501728,9,1019164307,0,1018499775,2022-01-22T10:26:15Z,"@bcremer Thanks for the pointer!

Looks like it triggered completely unrelated to `columnDefinition`. Instead it's due to a difference in the `notnull` property. And fair enough, the column is generated as nullable when using the definition `VARCHAR(255) GENERATED ALWAYS AS ('foo') VIRTUAL` so it's completely right too!

I've fixed it by changing `columnDefinition` (and the database schema) to:

```mysql
VARCHAR(255) GENERATED ALWAYS AS ('foo') VIRTUAL NOT NULL
```

to bring it in line with the `Column` attribute, which is not null by default. I could've also fixed it by changing the attribute to `nullable: true`, but that made less sense considering the column is never `NULL`.

Having to figure it out like this is pretty cumbersome, so I'm all in favor of the debug/verbose mode suggested by @bcremer. But this issue is definitely invalid because it has nothing to do with the column being virtual.

Thanks for your help!",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/1025467177,Virtual columns will always have schema changes when checked with `orm:schema-tool:update`,bcremer,10,1108501728,10,1025467177,0,1019164307,2022-01-31T08:00:24Z,"Unfortunately the new https://github.com/doctrine/dbal/releases/tag/3.3.1 release and https://github.com/doctrine/dbal/pull/5220 makes it impossible to use `columnDefinition` to validate enum types that are mapped to varchars like described in https://www.doctrine-project.org/projects/doctrine-orm/en/2.11/cookbook/mysql-enums.html#solution-1-mapping-to-varchars.

",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/1025594858,Virtual columns will always have schema changes when checked with `orm:schema-tool:update`,derrabus,10,1108501728,11,1025594858,0,1025467177,2022-01-31T10:33:50Z,@bcremer: doctrine/dbal#5223,False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/5191,Schema diff generates duplicative ALTER statements with custom columnDefinition,pps1,8,1109078270,1,1109078270,0,0,2022-01-19T22:07:07Z,"### Bug Report

<!-- Fill in the relevant information below to help triage your issue. -->

|    Q        |   A
|------------ | ------
| BC Break    | n/a
| Version     | 2.11.0
| MySQL     | 8.0.27
| DBAL     | 3.3.0
| Migrations     | 3.4.0

#### Summary

I need to add an auto-incremented integer column that is not the primary key to a MySQL InnoDB table. My entity is defined as follows:
```
/**
 * @ORM\Entity(repositoryClass=AddressRepository::class)
 * @ORM\Table(
 *   uniqueConstraints={@ORM\UniqueConstraint(name=""id_int"",columns={""id_int""})}
 * )
 */
class Address
{
    //{...}
	
    /**
     * @ORM\Column(
     *     type=""integer"",
     *     nullable=false,
     *     unique=true,
     *     options={""unsigned""=true},
     *     columnDefinition=""int unsigned NOT NULL AUTO_INCREMENT UNIQUE""
     * )
     */
    private ?int $idInt = null;
	
    //{...}
}
```

Running `doctrine:schema:diff` (Symfony 5.4 binding) results in the correct migration:
```
final class Version20220119220248 extends AbstractMigration
{
    public function up(Schema $schema): void
    {
        $this->addSql('ALTER TABLE address ADD id_int int unsigned NOT NULL AUTO_INCREMENT UNIQUE');
    }
}
```

Executing the migration yields the correct schema:
```
mysql> show create table address \G;
--------------
show create table address
--------------

*************************** 1. row ***************************
       Table: address
Create Table: CREATE TABLE `address` (
  `id` char(36) COLLATE utf8mb4_unicode_ci NOT NULL COMMENT '(DC2Type:guid)',
  `id_int` int unsigned NOT NULL AUTO_INCREMENT,
//{...}
  PRIMARY KEY (`id`),
  UNIQUE KEY `id_int` (`id_int`),
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
```

#### Current behavior

The problem comes when running `doctrine:migrations:diff` again. Without any changes to the field definitions, diff yields the following migration:
```
final class Version20220119220422 extends AbstractMigration
{
    public function up(Schema $schema): void
    {
        $this->addSql('ALTER TABLE address CHANGE id_int id_int int unsigned NOT NULL AUTO_INCREMENT UNIQUE');
    }
}
```

#### How to reproduce

1) Create an auto_incremented integer that is a non-primary key on an entity
2) Run Schema Diff
3) Migrate up
4) Run Schema Diff again

#### Expected behavior

Running Schema Diff again should not create a duplicative migration statement.

",True,0,NONE
https://api.github.com/repos/doctrine/dbal/issues/comments/1017290620,Schema diff generates duplicative ALTER statements with custom columnDefinition,beberlei,8,1109078270,2,1017290620,0,1109078270,2022-01-20T09:43:58Z,"As Schema diffing is a DBAL feature, i am transfering the issue.

With DBAL 3.3 this should be covered by our new comparison code, but maybe there is a problem somewhere that casues this, your column definition case is really complicated.",False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/comments/1017718163,Schema diff generates duplicative ALTER statements with custom columnDefinition,morozov,8,1109078270,3,1017718163,0,1017290620,2022-01-20T17:00:53Z,"@pps1 what version of Doctrine Migrations are you using? Up until 3.4.0 (https://github.com/doctrine/migrations/issues/1227, released a week ago), it used the old schema comparison API that is prone to the issues of comparing schemas like yours. What version of Migrations are you using.

In order for it to be considered a DBAL issue, please reproduce it by using only the DBAL API.",False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/comments/1017832041,Schema diff generates duplicative ALTER statements with custom columnDefinition,pps1,8,1109078270,4,1017832041,0,1017718163,2022-01-20T19:06:39Z,@morozov thanks for your feedback. We're using `doctrine/migrations 3.4.0` and as you can see are having the issue even with the latest version. I'll work on reproducing it with the DBAL API and will report back.,False,0,NONE
https://api.github.com/repos/doctrine/dbal/issues/comments/1017875736,Schema diff generates duplicative ALTER statements with custom columnDefinition,beberlei,8,1109078270,5,1017875736,0,1017832041,2022-01-20T20:05:19Z,"Maybe when you pass in a column definitoin, since that is used in its given order, but the database returns that slightly different, then it always missmatches?",False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/comments/1017899996,Schema diff generates duplicative ALTER statements with custom columnDefinition,pps1,8,1109078270,6,1017899996,0,1017875736,2022-01-20T20:26:32Z,"I believe I'm able to reproduce this behavior using the DBAL API. 

Here's the `Doctrine\DBAL\Schema\Schema` for the current, or `FROM` schema:

```
Doctrine\DBAL\Schema\Schema Object
(
    [namespaces:Doctrine\DBAL\Schema\Schema:private] => Array
        (
        )

    [_tables:protected] => Array
        (
            [app.address] => Doctrine\DBAL\Schema\Table Object
                (
                    [_columns:protected] => Array
                        (
                            //{...}

                            [id_int] => Doctrine\DBAL\Schema\Column Object
                                (
                                    [_type:protected] => Doctrine\DBAL\Types\IntegerType Object
                                        (
                                        )

                                    [_length:protected] =>
                                    [_precision:protected] => 10
                                    [_scale:protected] => 0
                                    [_unsigned:protected] => 1
                                    [_fixed:protected] =>
                                    [_notnull:protected] => 1
                                    [_default:protected] =>
                                    [_autoincrement:protected] => 1
                                    [_platformOptions:protected] => Array
                                        (
                                        )

                                    [_columnDefinition:protected] =>
                                    [_comment:protected] =>
                                    [_customSchemaOptions:protected] => Array
                                        (
                                        )

                                    [_name:protected] => id_int
                                    [_namespace:protected] =>
                                    [_quoted:protected] =>
                                )

                        )

                    [_indexes:protected] => Array
                        (
                            [id_int] => Doctrine\DBAL\Schema\Index Object
                                (
                                    [_columns:protected] => Array
                                        (
                                            [id_int] => Doctrine\DBAL\Schema\Identifier Object
                                                (
                                                    [_name:protected] => id_int
                                                    [_namespace:protected] =>
                                                    [_quoted:protected] =>
                                                )

                                        )

                                    [_isUnique:protected] => 1
                                    [_isPrimary:protected] =>
                                    [_flags:protected] => Array
                                        (
                                        )

                                    [options:Doctrine\DBAL\Schema\Index:private] => Array
                                        (
                                            [lengths] => Array
                                                (
                                                    [0] =>
                                                )

                                        )

                                    [_name:protected] => id_int
                                    [_namespace:protected] =>
                                    [_quoted:protected] =>
                                )

                            [primary] => Doctrine\DBAL\Schema\Index Object
                                (
                                    [_columns:protected] => Array
                                        (
                                            [id] => Doctrine\DBAL\Schema\Identifier Object
                                                (
                                                    [_name:protected] => id
                                                    [_namespace:protected] =>
                                                    [_quoted:protected] =>
                                                )

                                        )

                                    [_isUnique:protected] => 1
                                    [_isPrimary:protected] => 1
                                    [_flags:protected] => Array
                                        (
                                        )

                                    [options:Doctrine\DBAL\Schema\Index:private] => Array
                                        (
                                            [lengths] => Array
                                                (
                                                    [0] =>
                                                )

                                        )

                                    [_name:protected] => PRIMARY
                                    [_namespace:protected] =>
                                    [_quoted:protected] =>
                                )
                        )

                    [_primaryKeyName:protected] => primary
                    [uniqueConstraints:protected] => Array
                        (
                        )

                    [_fkConstraints:protected] => Array
                        (
                        )

                    [_options:protected] => Array
                        (
                            [create_options] => Array
                                (
                                )

                            [engine] => InnoDB
                            [collation] => utf8mb4_unicode_ci
                            [charset] => utf8mb4
                            [comment] =>
                        )

                    [_schemaConfig:protected] => Doctrine\DBAL\Schema\SchemaConfig Object
                        (
                            [hasExplicitForeignKeyIndexes:protected] =>
                            [maxIdentifierLength:protected] => 63
                            [name:protected] => app
                            [defaultTableOptions:protected] => Array
                                (
                                    [collate] => utf8mb4_unicode_ci
                                    [charset] => utf8mb4
                                )

                        )

                    [implicitIndexes:Doctrine\DBAL\Schema\Table:private] => Array
                        (
                        )

                    [_name:protected] => address
                    [_namespace:protected] =>
                    [_quoted:protected] =>
                )

        	//{...}

        )

    [_sequences:protected] => Array
        (
        )

    [_schemaConfig:protected] => Doctrine\DBAL\Schema\SchemaConfig Object
        (
            [hasExplicitForeignKeyIndexes:protected] =>
            [maxIdentifierLength:protected] => 63
            [name:protected] => app
            [defaultTableOptions:protected] => Array
                (
                    [collate] => utf8mb4_unicode_ci
                    [charset] => utf8mb4
                )

        )

    [_name:protected] => app
    [_namespace:protected] =>
    [_quoted:protected] =>
)
```

And here is the computed `Doctrine\DBAL\Schema\Schema` Object for the `NEW` schema:
```
Doctrine\DBAL\Schema\Schema Object
(
    [namespaces:Doctrine\DBAL\Schema\Schema:private] => Array
        (
        )

    [_tables:protected] => Array
        (
            [app.address] => Doctrine\DBAL\Schema\Table Object
                (
                    [_columns:protected] => Array
                        (
                            //{...}

                            [id_int] => Doctrine\DBAL\Schema\Column Object
                                (
                                    [_type:protected] => Doctrine\DBAL\Types\IntegerType Object
                                        (
                                        )

                                    [_length:protected] =>
                                    [_precision:protected] => 10
                                    [_scale:protected] => 0
                                    [_unsigned:protected] => 1
                                    [_fixed:protected] =>
                                    [_notnull:protected] => 1
                                    [_default:protected] =>
                                    [_autoincrement:protected] =>
                                    [_platformOptions:protected] => Array
                                        (
                                            [version] =>
                                        )

                                    [_columnDefinition:protected] => int unsigned NOT NULL AUTO_INCREMENT UNIQUE
                                    [_comment:protected] =>
                                    [_customSchemaOptions:protected] => Array
                                        (
                                        )

                                    [_name:protected] => id_int
                                    [_namespace:protected] =>
                                    [_quoted:protected] =>
                                )

                        )

                    [_indexes:protected] => Array
                        (
                            [primary] => Doctrine\DBAL\Schema\Index Object
                                (
                                    [_columns:protected] => Array
                                        (
                                            [id] => Doctrine\DBAL\Schema\Identifier Object
                                                (
                                                    [_name:protected] => id
                                                    [_namespace:protected] =>
                                                    [_quoted:protected] =>
                                                )

                                        )

                                    [_isUnique:protected] => 1
                                    [_isPrimary:protected] => 1
                                    [_flags:protected] => Array
                                        (
                                        )

                                    [options:Doctrine\DBAL\Schema\Index:private] => Array
                                        (
                                        )

                                    [_name:protected] => primary
                                    [_namespace:protected] =>
                                    [_quoted:protected] =>
                                )

                            [id_int] => Doctrine\DBAL\Schema\Index Object
                                (
                                    [_columns:protected] => Array
                                        (
                                            [id_int] => Doctrine\DBAL\Schema\Identifier Object
                                                (
                                                    [_name:protected] => id_int
                                                    [_namespace:protected] =>
                                                    [_quoted:protected] =>
                                                )

                                        )

                                    [_isUnique:protected] => 1
                                    [_isPrimary:protected] =>
                                    [_flags:protected] => Array
                                        (
                                        )

                                    [options:Doctrine\DBAL\Schema\Index:private] => Array
                                        (
                                        )

                                    [_name:protected] => id_int
                                    [_namespace:protected] =>
                                    [_quoted:protected] =>
                                )

                        )

                    [_primaryKeyName:protected] => primary
                    [uniqueConstraints:protected] => Array
                        (
                        )

                    [_fkConstraints:protected] => Array
                        (
                        )

                    [_options:protected] => Array
                        (
                            [create_options] => Array
                                (
                                )

                            [collate] => utf8mb4_unicode_ci
                            [charset] => utf8mb4
                        )

                    [_schemaConfig:protected] => Doctrine\DBAL\Schema\SchemaConfig Object
                        (
                            [hasExplicitForeignKeyIndexes:protected] =>
                            [maxIdentifierLength:protected] => 63
                            [name:protected] => app
                            [defaultTableOptions:protected] => Array
                                (
                                    [collate] => utf8mb4_unicode_ci
                                    [charset] => utf8mb4
                                )

                        )

                    [implicitIndexes:Doctrine\DBAL\Schema\Table:private] => Array
                        (
                        )

                    [_name:protected] => address
                    [_namespace:protected] =>
                    [_quoted:protected] =>
                )

        )

    [_sequences:protected] => Array
        (
        )

    [_schemaConfig:protected] => Doctrine\DBAL\Schema\SchemaConfig Object
        (
            [hasExplicitForeignKeyIndexes:protected] =>
            [maxIdentifierLength:protected] => 63
            [name:protected] => app
            [defaultTableOptions:protected] => Array
                (
                    [collate] => utf8mb4_unicode_ci
                    [charset] => utf8mb4
                )

        )

    [_name:protected] => app
    [_namespace:protected] =>
    [_quoted:protected] =>
)
```

Could the mismatch on ` [_autoincrement:protected]` be the cause?


 ",False,0,NONE
https://api.github.com/repos/doctrine/dbal/issues/comments/1021299038,Schema diff generates duplicative ALTER statements with custom columnDefinition,pps1,8,1109078270,7,1021299038,0,1017899996,2022-01-25T15:20:46Z,@morozov is the above diff helpful? Can I help produce additional artifacts?,False,0,NONE
https://api.github.com/repos/doctrine/dbal/issues/comments/1021470091,Schema diff generates duplicative ALTER statements with custom columnDefinition,morozov,8,1109078270,8,1021470091,0,1021299038,2022-01-25T18:11:07Z,@pps1 could you reproduce your issue as a code snippet? E.g. like https://github.com/doctrine/dbal/issues/2663#issuecomment-905763017 or https://github.com/doctrine/dbal/issues/2566#issuecomment-905906599.,False,0,MEMBER
https://api.github.com/repos/doctrine/dbal/issues/comments/1189670876,Schema diff generates duplicative ALTER statements with custom columnDefinition,github-actions[bot],8,1109078270,9,1189670876,0,1021470091,2022-07-20T00:20:27Z,This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.,False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/9411,convertToDatabaseValue in \Doctrine\ORM\UnitOfWork::getSingleIdentifierValue(),e-kemal,3,1109341078,1,1109341078,0,0,2022-01-20T14:04:19Z,"getSingleIdentifierValue() must return a scalar value, but it doesn't. Because of this, queries with entities in parameters do not work. This occurs on platforms where the string representation of the identifier differs from the representation in the database (for example, MySQL + symfony/uid).",True,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/1017547109,convertToDatabaseValue in \Doctrine\ORM\UnitOfWork::getSingleIdentifierValue(),derrabus,3,1109341078,2,1017547109,0,1109341078,2022-01-20T14:17:45Z,Please provide a test that covers your change.,False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/1017580082,convertToDatabaseValue in \Doctrine\ORM\UnitOfWork::getSingleIdentifierValue(),derrabus,3,1109341078,3,1017580082,0,1017547109,2022-01-20T14:43:09Z,Looks like your change breaks quite some existing tests.,False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/1020138123,convertToDatabaseValue in \Doctrine\ORM\UnitOfWork::getSingleIdentifierValue(),e-kemal,3,1109341078,4,1020138123,0,1017580082,2022-01-24T14:08:11Z,"I have added a test that reproduces my issue. My edit to UnitOfWork::getSingleIdentifierValue() fixes the issue. But, judging by the failed tests, I do not quite correctly understand the internal structure of the ORM. In particular, I was confused by the line
```       * @return mixed A scalar value.```
That's why I decided that getSingleIdentifierValue should return a DatabaseValue.
However, it will not work to do the conversion in the external code, since there is no information about the type of the field there (moreover, it is not known which field will be used). Maybe you need to add a separate method for this?",False,0,NONE
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/9718,Found a Diamond / graphite vein but it doesnt get registered on the minimap ore vein detection system,MathiasDeWeerdt,3,1131112111,1,1131112111,0,0,2022-02-10T22:18:23Z,"### Your GTNH Discord Username

Single Core#0827

### Your Pack Version

2.1.1.2QF2

### Your Server

private server

### Type of Server

_No response_

### Your Expectation

I found a Diamond / graphite vein but it doesn't get registered on the minimap ore vein detection system. I expect it to show up like all the other veins.

### The Reality

It doesnt register / discover the vein.

### Your Proposal

Make it register / discover the vein.

### Final Checklist

- [X] I have searched this issue tracker and there is nothing similar already. Posting on a closed issue saying the bug still exists will prompt us to investigate and reopen it once we confirm your report.
- [ ] I can reproduce this problem consistently by follow the exact steps I described above, or this does not need reproducing, e.g. recipe loophole.
- [ ] I have asked other people and they confirm they also have this problem by follow the exact steps I described above, or this does not need reproducing, e.g. recipe loophole.",True,0,NONE
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/1035602726,Found a Diamond / graphite vein but it doesnt get registered on the minimap ore vein detection system,bombcar,3,1131112111,2,1035602726,0,1131112111,2022-02-10T22:37:13Z,"Are you near spawn? If so, set 

`B:recacheVeins=false` to true and restart, see if that fixes it.

If not, it's probably a known issue with graphite for some reason.",False,0,MEMBER
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/1036440825,Found a Diamond / graphite vein but it doesnt get registered on the minimap ore vein detection system,BritishCynic,3,1131112111,3,1036440825,0,1035602726,2022-02-11T17:25:09Z,Have had this happen with Apatite away from spawn.,False,0,NONE
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/1036511257,Found a Diamond / graphite vein but it doesnt get registered on the minimap ore vein detection system,bombcar,3,1131112111,4,1036511257,0,1036440825,2022-02-11T18:45:44Z,"Was it an old/new chunk? If you want to experiment, and it's far from base, calculate and *backup* and remove the appropriate region file (when you're not there of course) and then go back and see if it now finds it. Sometimes old-scanning just doesn't work at all.

https://dinnerbone.com/minecraft/tools/coordinates/",False,0,MEMBER
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/9719,Create Toxic Everglades quest,riking,4,1131156931,1,1131156931,0,0,2022-02-10T22:43:54Z,"### Your GTNH Discord Username

Riking#6902

### Your Pack Version

2.1.2.0

### Your Proposal

Add a LuV-tier quest to build the Toxic Everglades portal parts.

### Your Goal

Draw players who see Everglades ores to (1) instructions on making the portal, which is satisfied by directing them to the Containment Frame item, and (2) realizing what tier the dimension is available at, which is satisfied by placing it in the quest book.

### Your Vision

=== Toxic Everglades Portal ===

The Toxic Everglades are a dimension with many useful ores and maybe a few environmental hazards. Create the portal and check it out.

Retrieval Task: Containment Frame #2783 x10
Retrieval Task: Alkalus Disk [Activated] #9741 x1

Requirements: LuV Assembler #1722

### Final Checklist

- [X] I have searched this issue tracker and there is nothing similar already. Posting on a closed issue saying *I like this feature please reconsider adding it* will prompt us to investigate and reopen it once we confirm your report.
- [X] I believe there is nothing similar in the pack already, or the existing solution isn't good enough.
- [X] I understand this change request may not attract enough attention and thus not be implemented.
- [X] I understand this change request may be rejected due to other community members thinking it's inappropriate.
- [X] I believe this feature would make the pack better.",True,0,NONE
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/1035610257,Create Toxic Everglades quest,draknyte1,4,1131156931,2,1035610257,0,1131156931,2022-02-10T22:47:23Z,@bombcar delegate to whomever is the new quest goblin. ,False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/1035699487,Create Toxic Everglades quest,Pxx500,4,1131156931,3,1035699487,0,1035610257,2022-02-11T01:19:35Z,"![image](https://user-images.githubusercontent.com/81298696/153523682-5a71040c-4be5-4cb1-ae5a-5eae3ac2bd59.png)
Hmm...",False,0,MEMBER
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/1035699988,Create Toxic Everglades quest,Pxx500,4,1131156931,4,1035699988,0,1035699487,2022-02-11T01:20:46Z,"> Requirements: LuV Assembler

![image](https://user-images.githubusercontent.com/81298696/153523773-03fd546c-edc9-4b0e-bed2-330289de4c74.png)
Yes",False,0,MEMBER
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/1036585883,Create Toxic Everglades quest,Dream-Master,4,1131156931,5,1036585883,0,1035699988,2022-02-11T20:18:21Z,"yes quest is in ZPM chapter and need zpm voltage
",False,0,MEMBER
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/9723,Pollution scrubber does not work (singleblock),madmacf,7,1132862079,1,1132862079,0,0,2022-02-11T17:01:56Z,"### Your GTNH Discord Username

_No response_

### Your Pack Version

2.1.1.0

### Your Server

Single player

### Type of Server

_No response_

### Your Expectation

Pollution scrubbers doesn't work.

### The Reality

The scrubber never starts. Added T1 filter in left slot. Turbine in left slots. Both normal turbines and gt++ ones.
Tried adding power on all sides. Tried directly to a transformer. Pollution above 300000 in chunk.
It's the singleblock HV one.
Smacked it with the soft mallet. 
Nothing works.
It looks whatever item is placed in lower right corner, and can't be removed again. 
Seems buggy.
![error](https://user-images.githubusercontent.com/22689175/153635269-dde7425e-8e45-49eb-be20-0c2af8cdb98f.jpg)



### Your Proposal

Fix it :-)

### Final Checklist

- [X] I have searched this issue tracker and there is nothing similar already. Posting on a closed issue saying the bug still exists will prompt us to investigate and reopen it once we confirm your report.
- [X] I can reproduce this problem consistently by follow the exact steps I described above, or this does not need reproducing, e.g. recipe loophole.
- [X] I have asked other people and they confirm they also have this problem by follow the exact steps I described above, or this does not need reproducing, e.g. recipe loophole.",True,0,NONE
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/1036423620,Pollution scrubber does not work (singleblock),bombcar,7,1132862079,2,1036423620,0,1132862079,2022-02-11T17:06:58Z,2.1.1.0 has pollution off - did you turn pollution back on?,False,0,MEMBER
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/1036426823,Pollution scrubber does not work (singleblock),draknyte1,7,1132862079,3,1036426823,0,1036423620,2022-02-11T17:09:42Z,Update your game. ,False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/1036439258,Pollution scrubber does not work (singleblock),madmacf,7,1132862079,4,1036439258,0,1036426823,2022-02-11T17:23:18Z,"> 2.1.1.0 has pollution off - did you turn pollution back on?

It's an old world I started playing again. Never turned it off or on.
It's the newest version. 2.1.1.0 It's updated. Do you mean it's a setting in af config file? Which one?
Please help.",False,0,NONE
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/1036440262,Pollution scrubber does not work (singleblock),draknyte1,7,1132862079,5,1036440262,0,1036439258,2022-02-11T17:24:26Z,2.1.1.0 is not the latest and did not have pollution enabled. ,False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/1036451720,Pollution scrubber does not work (singleblock),madmacf,7,1132862079,6,1036451720,0,1036440262,2022-02-11T17:37:43Z,"Sorry. Wrote the wrong version. I'm on 2.1.2.0. Newest from curseforge.
Turned the pollution off. Never turned it on myself.",False,0,NONE
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/1036511745,Pollution scrubber does not work (singleblock),bombcar,7,1132862079,7,1036511745,0,1036451720,2022-02-11T18:46:28Z,"2.1.2.0 has known issues with the GT++ scrubbers, but if you turned pollution back off, the scrubbers won't run at all.",False,0,MEMBER
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/1036514421,Pollution scrubber does not work (singleblock),draknyte1,7,1132862079,8,1036514421,0,1036511745,2022-02-11T18:49:58Z,"I fixed scrubbers, I was sure that made it into 2.1.2.0. 🤷🏻‍♀️ ",False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/9724,Early Smelting Changes [Suggestion],BritishCynic,9,1132887052,1,1132887052,0,0,2022-02-11T17:24:20Z,"### Your GTNH Discord Username

BritishCynic#9193

### Your Pack Version

2.1.2.2

### Your Proposal

I like realism having a valid place in modding, and as GTNH is under no illusions about being more time-consuming in general, I have a proposal to make early-game smelting more meaningful without being *too* obnoxious.

First off, this mainly concerns the following early game metals: Tin, Gold, Copper, Bronze, Iron and Steel. Each of these, left to right, has an increasingly high melting point, and I propose the following to have that actually mean something. Tin would be smeltable with a standard furnace given its low melting point. A three-tiered Furnace Multiblock system would then come into play: The Brick Furnace Multiblock would be as it exists now, only now it would open up Gold, Copper and Bronze smelting. The Bronze Furnace Multiblock would now have a reason to be constructed, and this would open up Iron smelting. Lastly, the Iron Furnace multiblock would open up Steel smelting. Each tier can also smelt each previous Tier's metals, so Bronze can do Gold, Copper, Bronze and Iron, while the Iron one can do Copper, Bronze, Iron and Steel.

Oh, and have them use the same ""use random full-dust chance generation rather than always giving tiny dusts"" logic as further on in the pack. This would mean removing said recipes from the Bronze and Steel Steam Furnaces, and then having them Furnace-smeltable at LV; Steam furnaces can still do Tin. TC would also need to be amended so that it can only melt down ingots rather than dusts or ores of the affected metals.

### Your Goal

To annoy people, but to also make them thankful of the steps the pack makes you take to make smelting easier and less time-consuming.

### Your Vision

For me, this would have the pack very early on make a statement of intent that it's going to make the player jump through hoops, and I personally think this adds more realism and a little bit more of a challenge in the early game

### Final Checklist

- [X] I have searched this issue tracker and there is nothing similar already. Posting on a closed issue saying *I like this change please reconsider adding it* will prompt us to investigate and reopen it once we confirm your report.
- [X] I understand this change request may not attract enough attention and thus not be implemented.
- [X] I understand this change request may be rejected due to other community members think it's inappropriate.
- [X] I believe this feature would make the pack better.",True,0,NONE
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/1036558987,Early Smelting Changes [Suggestion],Dream-Master,9,1132887052,2,1036558987,0,1132887052,2022-02-11T19:45:53Z,"If you ask me vanilla furce shouldn't make ingots or nuggets. We need some low level Furnaces with 2 slots where you can smelt metal, add a brick form to it to make ingots or nuggest.",False,0,MEMBER
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/1036574557,Early Smelting Changes [Suggestion],BritishCynic,9,1132887052,3,1036574557,0,1036558987,2022-02-11T20:02:14Z,I like this. Clay precursors to the existing TC/GT molds.,False,0,NONE
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/1036586687,Early Smelting Changes [Suggestion],Dream-Master,9,1132887052,4,1036586687,0,1036574557,2022-02-11T20:19:38Z,I guess the community will kill me if we change furnace behavior but sure we can make some plan to realise it.,False,0,MEMBER
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/1056671172,Early Smelting Changes [Suggestion],MadRatSRP,9,1132887052,5,1056671172,0,1036586687,2022-03-02T09:29:05Z,"I didnt read TS's comment in full yet, but what i would like to see in modpack before steam age is a multiblock furnace which would have multiple slots for fuel and items (from 3 to 6 for example), will be able to save the heat for some time when all the fuel is gone and will be needed to be fired up (not by flint and steel because its steam age thing) but by something else. I think that this is up to user does them want to rush up to steam age or to spend time in stone age.

Also the balance of metals in stone age is sometimes differs strangely. For example, in TC bronze is x1.5 times more effective than iron, but in GT bronze instruments are worse than iron ones. But at the same time iron spawns in many veins and for making bronze you need to find tin which sometimes takes lots of time. So in conclusion, it takes more time to make bronze than iron, but in GT it doesnt make sense :D",False,0,NONE
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/1141907642,Early Smelting Changes [Suggestion],github-actions[bot],9,1132887052,6,1141907642,0,1056671172,2022-05-31T09:39:05Z,This issue is stale because it has been open 90 days with no activity. Remove stale label or comment or this will be closed in 3 days,False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/1142398793,Early Smelting Changes [Suggestion],BritishCynic,9,1132887052,7,1142398793,0,1141907642,2022-05-31T17:10:53Z,"Any thoughts on this? Or is this just too evil for GTNH?

On Tue, 31 May 2022 at 10:39, github-actions[bot] ***@***.***>
wrote:

> This issue is stale because it has been open 90 days with no activity.
> Remove stale label or comment or this will be closed in 3 days
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/GTNewHorizons/GT-New-Horizons-Modpack/issues/9724#issuecomment-1141907642>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ADETUFXOMEE7LEJQL5FQA7LVMXM4JANCNFSM5OE4BZRQ>
> .
> You are receiving this because you authored the thread.Message ID:
> ***@***.***>
>


-- 
""I had a handle on life, but then it broke""
",False,0,NONE
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/1142783122,Early Smelting Changes [Suggestion],Elisis,9,1132887052,8,1142783122,0,1142398793,2022-05-31T23:55:52Z,If you want TFC just play TFC,False,0,MEMBER
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/1231092604,Early Smelting Changes [Suggestion],github-actions[bot],9,1132887052,9,1231092604,0,1142783122,2022-08-30T03:18:37Z,This issue is stale because it has been open 90 days with no activity. Remove stale label or comment or this will be closed in 3 days,False,0,CONTRIBUTOR
https://api.github.com/repos/GTNewHorizons/GT-New-Horizons-Modpack/issues/comments/1328656567,Early Smelting Changes [Suggestion],github-actions[bot],9,1132887052,10,1328656567,0,1231092604,2022-11-28T07:32:17Z,This issue is stale because it has been open 90 days with no activity. Remove stale label or comment or this will be closed in 3 days,False,0,CONTRIBUTOR
https://api.github.com/repos/truecharts/charts/issues/1875,"Home-Assistant > failed to provision volume with StorageClass ""ix-storage-class-home-assistant"": error generating accessibility requirements: no available topology found",Dremor,5,1128917085,1,1128917085,0,0,2022-02-09T19:03:19Z,"I tried to deploy Home-Assistant, but the deployment seem to be stuck.

Scale version: TrueNAS-SCALE-22.02-RC.2 as well as latest nightly
App version: 2022.2.2_12.0.41

The logs are the following:

```
2022-02-09 17:05:38 waiting for a volume to be created, either by external provisioner ""zfs.csi.openebs.io"" or manually created by system administrator
2022-02-09 17:05:38 waiting for a volume to be created, either by external provisioner ""zfs.csi.openebs.io"" or manually created by system administrator
2022-02-09 17:06:15 External provisioner is provisioning volume for claim ""ix-home-assistant/db-home-assistant-postgresql-0""
2022-02-09 17:06:15 External provisioner is provisioning volume for claim ""ix-home-assistant/home-assistant-config""
2022-02-09 17:06:15 failed to provision volume with StorageClass ""ix-storage-class-home-assistant"": error generating accessibility requirements: no available topology found
2022-02-09 17:06:15 failed to provision volume with StorageClass ""ix-storage-class-home-assistant"": error generating accessibility requirements: no available topology found
0/1 nodes are available: 1 pod has unbound immediate PersistentVolumeClaims.
0/1 nodes are available: 1 pod has unbound immediate PersistentVolumeClaims.
```

Any idea of where this could come from ?",True,0,NONE
https://api.github.com/repos/truecharts/charts/issues/comments/1034099974,"Home-Assistant > failed to provision volume with StorageClass ""ix-storage-class-home-assistant"": error generating accessibility requirements: no available topology found",stavros-k,5,1128917085,2,1034099974,0,1128917085,2022-02-09T19:07:37Z,"Probably all apps would have the same problem.
If that's the case, you should file a ticket to iX Systems, as this seems to be a problem with your host system.",False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1034138721,"Home-Assistant > failed to provision volume with StorageClass ""ix-storage-class-home-assistant"": error generating accessibility requirements: no available topology found",Dremor,5,1128917085,3,1034138721,0,1034099974,2022-02-09T19:56:12Z,"Possible. What other chart uses PVCs, so I can try to deploy it to test.",False,0,NONE
https://api.github.com/repos/truecharts/charts/issues/comments/1034139964,"Home-Assistant > failed to provision volume with StorageClass ""ix-storage-class-home-assistant"": error generating accessibility requirements: no available topology found",stavros-k,5,1128917085,4,1034139964,0,1034138721,2022-02-09T19:57:37Z,99% of truecharts apps ;),False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1034146739,"Home-Assistant > failed to provision volume with StorageClass ""ix-storage-class-home-assistant"": error generating accessibility requirements: no available topology found",Dremor,5,1128917085,5,1034146739,0,1034139964,2022-02-09T20:06:12Z,"Indeed, tried some apps (Odoo, Recipes), all of them show the same Symptoms. I'll log a bug report to iX-Systems tomorrow. Closing this issue, will reopen if there is something on the Truecharts side.",False,0,NONE
https://api.github.com/repos/truecharts/charts/issues/comments/1034489416,"Home-Assistant > failed to provision volume with StorageClass ""ix-storage-class-home-assistant"": error generating accessibility requirements: no available topology found",Ornias1993,5,1128917085,6,1034489416,0,1034146739,2022-02-10T04:47:14Z,"No reopening permitted.
There is simply nothing we can do here for sure.",False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/1878,chore(gitea): remove dups from configmap,stavros-k,8,1130620450,1,1130620450,0,0,2022-02-10T18:23:57Z,"**Description**
<!--
Please include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.
-->
Fixes #

**Type of change**

- [ ] Feature/App addition
- [ ] Bugfix
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [x] Refactor of current code

**How Has This Been Tested?**
<!--
Please describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration
-->

**Notes:**
<!-- Please enter any other relevant information here -->

**Checklist:**

- [x] My code follows the style guidelines of this project
- [x] I have performed a self-review of my own code
- [ ] I have commented my code, particularly in hard-to-understand areas
- [ ] I have made corresponding changes to the documentation
- [x] My changes generate no new warnings
- [ ] I have added tests to this description that prove my fix is effective or that my feature works
- [ ] I increased versions for any altered app according to semantic versioning
",True,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1035906772,chore(gitea): remove dups from configmap,stavros-k,8,1130620450,2,1035906772,0,1130620450,2022-02-11T06:02:52Z,"Upstream issue is fixed, waiting for the new image, 
We can leave this open to test it once it's releases.

Also this PR ""should"" fix the Chart linting the CI is mentioning.",False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1037076291,chore(gitea): remove dups from configmap,Ornias1993,8,1130620450,3,1037076291,0,1035906772,2022-02-12T09:03:16Z,Coukd you fix the CI seperately?,False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1037195922,chore(gitea): remove dups from configmap,stavros-k,8,1130620450,4,1037195922,0,1037076291,2022-02-12T12:20:14Z,"> Coukd you fix the CI seperately?

Splitted PR's and this PR is actually just a clean up on the configmap.
As there are no issues on the appini path, just an upstream bug that we wait for themt o release new image",False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1037228474,chore(gitea): remove dups from configmap,Ornias1993,8,1130620450,5,1037228474,0,1037195922,2022-02-12T13:38:45Z,Can you specify why deleting those is a good thing?,False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1037228540,chore(gitea): remove dups from configmap,Ornias1993,8,1130620450,6,1037228540,0,1037228474,2022-02-12T13:39:04Z,"(also rebase would be nice and shit)
",False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1037234117,chore(gitea): remove dups from configmap,stavros-k,8,1130620450,7,1037234117,0,1037228540,2022-02-12T14:01:50Z,"> Can you specify why deleting those is a good thing?

They are declared twice 4 lines above ;)
Nothing is changing just cleanup.",False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1037235384,chore(gitea): remove dups from configmap,Ornias1993,8,1130620450,8,1037235384,0,1037234117,2022-02-12T14:07:08Z,Shoot.,False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1563658267,chore(gitea): remove dups from configmap,truecharts-admin,8,1130620450,9,1563658267,0,1037235384,2023-05-26T00:21:29Z,This PR is locked to prevent necro-posting on closed PRs. Please create a issue or contact staff on discord if you want to further discuss this,False,0,COLLABORATOR
https://api.github.com/repos/truecharts/charts/issues/1880,[Traefik] error validating data: apiVersion not set - when enabling ingressclass,PylotLight,5,1132576171,1,1132576171,0,0,2022-02-11T13:09:02Z,"<!--
MIND YOUR TITLE:
- ""App in a deploying state"" is NOT the title/description of your actual bug.
- ""Appname not working"" is NOT the title/description of your actual bug.
- Don't refer to a version, bugs are always for latest version
-->

***SCALE version***
TrueNAS-SCALE-22.02-RC.2

***App Version***
traefik - 2.6.0_10.0.55

***Application Events***
![image](https://user-images.githubusercontent.com/7006124/153595203-2897aafe-1079-4260-9055-e579beab5b2e.png)

***Application Logs***
![image](https://user-images.githubusercontent.com/7006124/153595567-b3579c06-e5d4-46b5-9e7c-b7d7c956652c.png)

***Application Configuration***
![image](https://user-images.githubusercontent.com/7006124/153596048-bce33d9e-36e8-42ea-a557-76b843317070.png)

**Describe the bug**
Get the error when enabling ingressclass on the app and clicking save.

**To Reproduce**
Steps to reproduce the behavior:
1. Go to App Configuration
2. Click on ingressclass and enable and save it.
3. See error


**Expected behavior**
Ingress is enabled for traefik

**Screenshots**
![image](https://user-images.githubusercontent.com/7006124/153596903-90d71b33-68e8-4ebb-8068-b7702730603b.png)


**Additional context**
Nothing too complicated configured already.
",True,0,NONE
https://api.github.com/repos/truecharts/charts/issues/comments/1036221546,[Traefik] error validating data: apiVersion not set - when enabling ingressclass,Ornias1993,5,1132576171,2,1036221546,0,1132576171,2022-02-11T13:37:16Z,IngressClass never has been supported or working.,False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1036221745,[Traefik] error validating data: apiVersion not set - when enabling ingressclass,Ornias1993,5,1132576171,3,1036221745,0,1036221546,2022-02-11T13:37:29Z,This is why I requested you to actually file a support ticket first.,False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1060528815,[Traefik] error validating data: apiVersion not set - when enabling ingressclass,Ornias1993,5,1132576171,4,1060528815,0,1036221745,2022-03-07T11:05:14Z,@all-contributors please add @PylotLight   for bugs,False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1060529156,[Traefik] error validating data: apiVersion not set - when enabling ingressclass,allcontributors[bot],5,1132576171,5,1060529156,0,1060528815,2022-03-07T11:05:22Z,"@Ornias1993 

I've put up [a pull request](https://github.com/truecharts/apps/pull/2065) to add @PylotLight! :tada:",False,0,CONTRIBUTOR
https://api.github.com/repos/truecharts/charts/issues/comments/1415936301,[Traefik] error validating data: apiVersion not set - when enabling ingressclass,truecharts-admin,5,1132576171,6,1415936301,0,1060529156,2023-02-03T14:20:31Z,This issue is locked to prevent necro-posting on closed issues. Please create a new issue or contact staff on discord of the problem persists,False,0,COLLABORATOR
https://api.github.com/repos/truecharts/charts/issues/1881,feat(Photoview): Add photoview,stavros-k,3,1132864562,1,1132864562,0,0,2022-02-11T17:04:05Z,"**Description**
<!--
Please include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.
-->
Fixes #293

**Type of change**

- [x] Feature/App addition
- [ ] Bugfix
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] Refactor of current code

**How Has This Been Tested?**
<!--
Please describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration
-->

**Notes:**
<!-- Please enter any other relevant information here -->

**Checklist:**

- [x] My code follows the style guidelines of this project
- [x] I have performed a self-review of my own code
- [ ] I have commented my code, particularly in hard-to-understand areas
- [x] I have made corresponding changes to the documentation
- [ ] My changes generate no new warnings
- [ ] I have added tests to this description that prove my fix is effective or that my feature works
- [x] I increased versions for any altered app according to semantic versioning
",True,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1036445106,feat(Photoview): Add photoview,stavros-k,3,1132864562,2,1036445106,0,1132864562,2022-02-11T17:30:06Z,"TODO: Update image to our mirror once published.

Waiting: https://github.com/photoview/photoview/issues/648 (CI Passes, but there is errors)",False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1038061990,feat(Photoview): Add photoview,Ornias1993,3,1132864562,3,1038061990,0,1036445106,2022-02-13T12:09:10Z,needs rebase,False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1562088834,feat(Photoview): Add photoview,truecharts-admin,3,1132864562,4,1562088834,0,1038061990,2023-05-25T00:21:09Z,This PR is locked to prevent necro-posting on closed PRs. Please create a issue or contact staff on discord if you want to further discuss this,False,0,COLLABORATOR
https://api.github.com/repos/chalk/chalk/issues/523,Outdated package.json since 4.1.1,alopix,3,1042480816,1,1042480816,0,0,2021-11-02T15:05:06Z,"4.1.1 was supposed to add ESM support and require NodeJS 12, but looking at the published package contents on NPM, this does not show up in code anymore:

https://www.npmjs.com/package/chalk/v/4.1.1
https://www.npmjs.com/package/chalk/v/4.1.2

See the explore tab or download the files from NPM. If you compare them, they are not the same as checked into this repo.",True,0,NONE
https://api.github.com/repos/chalk/chalk/issues/comments/957797067,Outdated package.json since 4.1.1,sindresorhus,3,1042480816,2,957797067,0,1042480816,2021-11-02T15:15:49Z,"> 4.1.1 was supposed to add ESM support and require NodeJS 12

No it was not. What's in the main branch is supposed to do that, but it's not done yet. What's in the main branch is not necessarily always what's published. This is how most repos on GitHub works.",False,0,MEMBER
https://api.github.com/repos/chalk/chalk/issues/comments/957846531,Outdated package.json since 4.1.1,alopix,3,1042480816,3,957846531,0,957797067,2021-11-02T15:39:00Z,"Actually cross-referenced release dates and main branch to make sure this could have been released yet. Which is how repos on GitHub usually work, but fine, if you have a different strategy.",False,0,NONE
https://api.github.com/repos/chalk/chalk/issues/comments/957900356,Outdated package.json since 4.1.1,Qix-,3,1042480816,4,957900356,0,957846531,2021-11-02T16:14:57Z,"You're mistaken. 4.1.1 was published from branch `meta-tweaks` which is 2 commits diverged from `main`. The common ancestral commit is the 4.1.0 release which sported [this `package.json`](https://github.com/chalk/chalk/blob/4c3df8847256f9f2471f0af74100b21afc12949f/package.json#L10) which clearly targets Node >= 10.0 and is not ESM. 4.1.1 did not change that as can be seen [here](https://github.com/chalk/chalk/blob/89e9e3a5b0601f4eda4c3a92acd887ec836d0175/package.json#L10).

Dates mean nothing, look at the content please. Master/main are always to be considered bleeding edge. I'm not really sure where the confusion is - Chalk doesn't do anything weird or unusual here w.r.t. git repositories.

Nothing actionable and I see this conversation getting less civil moving forward so going to pre-emptively lock.",False,0,MEMBER
https://api.github.com/repos/chalk/chalk/issues/528,Error [ERR_REQUIRE_ESM]: require() of ES Module /home/circleci/project/node_modules/chalk/source/index.js from /home/circleci/project/index.js not supported.,ItzMiracleOwO,3,1071369789,1,1071369789,0,0,2021-12-05T04:30:45Z,https://app.circleci.com/pipelines/github/RadishTeam/RadishBot/33/workflows/905f695c-fd3a-4bba-9e29-bdd1111ed8a7/jobs/66?invite=true#step-105-20,True,0,NONE
https://api.github.com/repos/chalk/chalk/issues/comments/986164887,Error [ERR_REQUIRE_ESM]: require() of ES Module /home/circleci/project/node_modules/chalk/source/index.js from /home/circleci/project/index.js not supported.,ItzMiracleOwO,3,1071369789,2,986164887,0,1071369789,2021-12-05T04:31:15Z,any fixes?,False,0,NONE
https://api.github.com/repos/chalk/chalk/issues/comments/986167236,Error [ERR_REQUIRE_ESM]: require() of ES Module /home/circleci/project/node_modules/chalk/source/index.js from /home/circleci/project/index.js not supported.,sv-22,3,1071369789,3,986167236,0,986164887,2021-12-05T05:01:00Z,having same issue here,False,0,NONE
https://api.github.com/repos/chalk/chalk/issues/comments/986186527,Error [ERR_REQUIRE_ESM]: require() of ES Module /home/circleci/project/node_modules/chalk/source/index.js from /home/circleci/project/index.js not supported.,Qix-,3,1071369789,4,986186527,0,986167236,2021-12-05T08:22:02Z,This is by design. Chalk 5 is ESM only. Please read the release notes.,False,0,MEMBER
https://api.github.com/repos/chalk/chalk/issues/530,Missing audit in the actions workflow,ivanblazevic,3,1094220410,1,1094220410,0,0,2022-01-05T10:49:59Z,"Can you introduce `npm audit` in the actions workflow which would eventually resolve following problem I have because of the chalk lib? 

<img width=""911"" alt=""Screenshot 2022-01-05 at 11 45 22"" src=""https://user-images.githubusercontent.com/2737184/148205074-904cc173-5a8f-4d8c-8e82-b5753fb06419.png"">
",True,0,NONE
https://api.github.com/repos/chalk/chalk/issues/comments/1005965802,Missing audit in the actions workflow,sindresorhus,3,1094220410,2,1005965802,0,1094220410,2022-01-05T18:16:23Z,Chalk does not depend on `ansi-regex` and it has not done it for years. So it sound like the project you're using needs to upgrade Chalk.,False,0,MEMBER
https://api.github.com/repos/chalk/chalk/issues/comments/1013514730,Missing audit in the actions workflow,ivanblazevic,3,1094220410,3,1013514730,0,1005965802,2022-01-14T22:25:15Z,"@sindresorhus would like to upgrade but looks like chalk does not support node 12:
<img width=""907"" alt=""Screenshot 2022-01-14 at 23 24 53"" src=""https://user-images.githubusercontent.com/2737184/149593129-14d32663-3d0c-47df-b96b-45ba7b352ef1.png"">

",False,0,NONE
https://api.github.com/repos/chalk/chalk/issues/comments/1013617765,Missing audit in the actions workflow,sindresorhus,3,1094220410,4,1013617765,0,1013514730,2022-01-15T05:41:18Z,"Chalk supports Node.js 12 fine. The problem is your TypeScript types. Make sure you're using the latest Node.js types and latest TS version.

Also read: https://github.com/chalk/chalk/releases/tag/v5.0.0",False,0,MEMBER
https://api.github.com/repos/chalk/chalk/issues/531,Yarn PnP fails to resolve #ansi-styles,stevenxu-db,4,1094797666,1,1094797666,0,0,2022-01-05T22:32:18Z,"Yarn PnP appears to fail with chalk 5. A routine import of chalk fails with the following message:

```
(node:28002) ExperimentalWarning: --experimental-loader is an experimental feature. This feature could change at any time
(Use `node --trace-warnings ...` to show where the warning was created)
/private/var/folders/4y/p9httzjd7px11pkmsfvlbdym0000gp/T/tmp.i44UjSW8/.pnp.cjs:9361
  return Object.defineProperties(new Error(message), {
                                 ^

Error: chalk tried to access #ansi-styles, but it isn't declared in its dependencies; this makes the require call ambiguous and unsound.

Required package: #ansi-styles (via ""#ansi-styles/package.json"")
Required by: chalk@npm:5.0.0 (via /private/var/folders/4y/p9httzjd7px11pkmsfvlbdym0000gp/T/tmp.i44UjSW8/.yarn/cache/chalk-npm-5.0.0-7be183234e-6eba7c518b.zip/node_modules/chalk/source/index.js)

    at internalTools_makeError (/private/var/folders/4y/p9httzjd7px11pkmsfvlbdym0000gp/T/tmp.i44UjSW8/.pnp.cjs:9361:34)
    at resolveToUnqualified (/private/var/folders/4y/p9httzjd7px11pkmsfvlbdym0000gp/T/tmp.i44UjSW8/.pnp.cjs:10659:21)
    at Object.resolveToUnqualified (/private/var/folders/4y/p9httzjd7px11pkmsfvlbdym0000gp/T/tmp.i44UjSW8/.pnp.cjs:10856:26)
    at resolve$1 (file:///private/var/folders/4y/p9httzjd7px11pkmsfvlbdym0000gp/T/tmp.i44UjSW8/.pnp.loader.mjs:195:31)
    at ESMLoader.resolve (node:internal/modules/esm/loader:422:30)
    at ESMLoader.getModuleJob (node:internal/modules/esm/loader:222:40)
    at ModuleWrap.<anonymous> (node:internal/modules/esm/module_job:76:40)
    at link (node:internal/modules/esm/module_job:75:36)
    at processTicksAndRejections (node:internal/process/task_queues:96:5)
```

The same works fine with node-modules linker. This may be related to `package.json` `imports` introduced in v5: https://github.com/chalk/chalk/blob/4d5c4795ad24c326ae16bfe0c39c826c732716a9/package.json#L10.

Repro steps:

```
tmp=""$(mktemp -d)""
cd ""$tmp""
yarn set version berry
echo '{""type"": ""module""}' > package.json
echo """"""import chalk from 'chalk';
console.log(chalk.blue('hi'));"""""" > index.js
yarn add chalk@^5
yarn node ./index.js # fails

### other test cases follow

yarn config set nodeLinker node-modules
yarn
yarn node ./index.js # works

yarn config set nodeLinker pnp
yarn
yarn node ./index.js # fails

yarn up chalk@^4
yarn
yarn node ./index.js # works
```

Environment:

```
$ yarn -v; node -v; uname -a
1.22.15
v16.13.1
Darwin C02FC0SHMD6R 20.6.0 Darwin Kernel Version 20.6.0: Tue Oct 12 18:33:42 PDT 2021; root:xnu-7195.141.8~1/RELEASE_X86_64 x86_64
```",True,0,NONE
https://api.github.com/repos/chalk/chalk/issues/comments/1006167578,Yarn PnP fails to resolve #ansi-styles,sindresorhus,4,1094797666,2,1006167578,0,1094797666,2022-01-05T23:52:23Z,This is a problem with Yarn PnP and should be reported on the Yarn issue tracker.,False,0,MEMBER
https://api.github.com/repos/chalk/chalk/issues/comments/1146705502,Yarn PnP fails to resolve #ansi-styles,Kurt-von-Laven,4,1094797666,3,1146705502,0,1006167578,2022-06-04T23:55:31Z,"I encountered the same issue and recently discovered that adding the following section to `.yarnrc.yml` works around the matter:

```yaml
packageExtensions:
  chalk@5.0.1:
    dependencies:
      ""#ansi-styles"": npm:ansi-styles@6.1.0
      ""#supports-color"": npm:supports-color@9.2.2
```",False,0,NONE
https://api.github.com/repos/chalk/chalk/issues/comments/1258778969,Yarn PnP fails to resolve #ansi-styles,dobesv,4,1094797666,4,1258778969,0,1146705502,2022-09-26T23:48:46Z,"Steps to reproduce:

```
$ mkdir chalk-err
$ cd chalk-err
$ yarn init
yarn init v1.22.19
question name (chalk-err): 
question version (1.0.0): 
question description: 
question entry point (index.js): 
question repository url: 
question author: 
question license (MIT): 
question private: 
success Saved package.json
Done in 5.67s.
$ yarn set version berry
➤ YN0000: Retrieving https://repo.yarnpkg.com/3.2.3/packages/yarnpkg-cli/bin/yarn.js
➤ YN0000: Saving the new release in .yarn/releases/yarn-3.2.3.cjs
➤ YN0000: Done in 0s 547ms
$ yarn add chalk
➤ YN0000: ┌ Resolution step
➤ YN0000: └ Completed
➤ YN0000: ┌ Fetch step
➤ YN0013: │ chalk@npm:5.0.1 can't be found in the cache and will be fetched from the remote registry
➤ YN0000: └ Completed
➤ YN0000: ┌ Link step
➤ YN0000: │ ESM support for PnP uses the experimental loader API and is therefore experimental
➤ YN0000: └ Completed
➤ YN0000: Done with warnings in 0s 155ms
$ yarn node
Welcome to Node.js v16.17.0.
Type "".help"" for more information.
> import('chalk')
Promise {
  <pending>,
  [Symbol(async_id_symbol)]: 157,
  [Symbol(trigger_async_id_symbol)]: 11
}
> Uncaught:
Error: chalk tried to access #ansi-styles, but it isn't declared in its dependencies; this makes the require call ambiguous and unsound.

Required package: #ansi-styles (via ""#ansi-styles/package.json"")
Required by: chalk@npm:5.0.1 (via /home/ubuntu/chalk-err/.yarn/cache/chalk-npm-5.0.1-6afcb94227-7b45300372.zip/node_modules/chalk/source/index.js)

    at makeError (/home/ubuntu/chalk-err/.pnp.cjs:8466:34)
    at resolveToUnqualified (/home/ubuntu/chalk-err/.pnp.cjs:9385:21)
    at Object.resolveToUnqualified (/home/ubuntu/chalk-err/.pnp.cjs:9529:26)
    at resolve$1 (file:///home/ubuntu/chalk-err/.pnp.loader.mjs:224:31)
    at nextResolve (node:internal/modules/esm/loader:165:28)
    at ESMLoader.resolve (node:internal/modules/esm/loader:844:30)
    at ESMLoader.getModuleJob (node:internal/modules/esm/loader:431:18)
> 

```
",False,0,NONE
https://api.github.com/repos/chalk/chalk/issues/comments/1258814397,Yarn PnP fails to resolve #ansi-styles,Qix-,4,1094797666,5,1258814397,0,1258778969,2022-09-27T00:22:01Z,"We're well aware of the issue - `yarn` lacks proper support for how we structure our package.json.

There's nothing actionable here. Please voice your support for this feature over at the appropriate Yarn repository.",False,0,MEMBER
https://api.github.com/repos/composer/packagist/issues/1254,Support GitLab in README files,pixelbrackets,4,1125046358,1,1125046358,0,0,2022-02-05T22:33:00Z,"Add support for GitLab in README files as well.

- Convert relative links to absolute links,
  pointing to the right repository subdirectory

- Fix path to images sources to embed them directly

Tested manually with [example package pixelbrackets/markdown-mini-page](https://packagist.org/packages/pixelbrackets/markdown-mini-page).

Before: [Missing screenshot](https://user-images.githubusercontent.com/1592995/152661116-5078ed64-aaff-4fb1-b889-85a07970d9a3.png)
After: [Having screenshot](https://user-images.githubusercontent.com/1592995/152661117-bdf5a2b5-f342-43d8-9768-649c1134f495.png)

As suggested in issue #1223 I tried to take a look at BitBucket as well,
but it turns out they generate hashes for all embedded image paths,
which can not be guessed (see https://bitbucket.org/pixelbrackets/composer-test/).

Closes #1223",True,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1030802154,Support GitLab in README files,pixelbrackets,4,1125046358,2,1030802154,0,1125046358,2022-02-06T10:20:23Z,"To support other hosts than GitHub in the README [preparation method](https://github.com/composer/packagist/blob/787bd997f96fcb812efa2b3683acb1770269d5df/src/Package/Updater.php#L608) I changed the method argument `$isGitHub` to a more generic `$host`. Is this okay with you?

The fixtures have GitHub repos only. Therefore my note that I tested the change manually with an example package of my own. Is this good enough to reproduce the feature?",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1030864892,Support GitLab in README files,Seldaek,4,1125046358,3,1030864892,0,1030802154,2022-02-06T16:17:38Z,"Thanks, looks good to me I think.

Regarding bitbucket it seems to me like the hash is simply the commit hash, and it can be replaced by the branch name or HEAD as well e.g. https://bitbucket.org/pixelbrackets/composer-test/raw/HEAD/docs/screenshot.png works fine. So I think you should be able to add bitbucket support if you still want to do that?",False,0,MEMBER
https://api.github.com/repos/composer/packagist/issues/comments/1030865657,Support GitLab in README files,Seldaek,4,1125046358,4,1030865657,0,1030864892,2022-02-06T16:21:59Z,"I'm already merging this for now though, if you wanna do bitbucket please send another PR :)",False,0,MEMBER
https://api.github.com/repos/composer/packagist/issues/comments/1030880608,Support GitLab in README files,pixelbrackets,4,1125046358,5,1030880608,0,1030865657,2022-02-06T17:47:48Z,"> Thanks, looks good to me I think.
> 
> Regarding bitbucket it seems to me like the hash is simply the commit hash, and it can be replaced by the branch name or HEAD as well e.g. https://bitbucket.org/pixelbrackets/composer-test/raw/HEAD/docs/screenshot.png works fine. So I think you should be able to add bitbucket support if you still want to do that?

Hah, thanks for the clue. I'll pick that up in another PR.

Thanks for the feedback and merge. :100: ",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/1266,ukranian propaganda,ghost,16,1160862933,1,1160862933,0,0,2022-03-07T03:41:27Z,"when i use composer installer i see ukranian propaganda in terminal

image: https://i.imgur.com/BeGNgth.png

do the maintainers of this project understand the long, complex history of ukraine and russian issues? do the maintainers understand the propaganda coming from both sides of the issue? do the maintainers understand that this type of messaging causes xenophobia against regular russian citizens who may not even be in favor of putins actions?

i search for PR/issues for this and found nothing, meaning maintainers decided to implement this without any feedback from community whatsoever.",True,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1060263759,ukranian propaganda,cjango,16,1160862933,2,1060263759,0,1160862933,2022-03-07T07:18:25Z,why close it?,False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1060328688,ukranian propaganda,Gemorroj,16,1160862933,3,1060328688,0,1060263759,2022-03-07T08:35:35Z,@cjango because many Europeans are xenophobic and hate Russians.,False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1060623718,ukranian propaganda,ghost,16,1160862933,4,1060623718,0,1060328688,2022-03-07T12:13:45Z,"Reopening so people can discuss. I saw in workflow composer maintainer is introducing this to many aspects of composer and it pissed me off really bad that’s why I closed it before. Makes me wish composer did not have monopoly on PHP package management. 

Tom Butler was right all along. ",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1060664470,ukranian propaganda,Seldaek,16,1160862933,5,1060664470,0,1060623718,2022-03-07T13:04:00Z,"See https://github.com/composer/packagist/commit/86244a3695fcaaac9c5ba4257a4314eae1c6d981#commitcomment-68136538 for some attempt at discussing this. Down the line though I don't think this kind of discussion can lead to consensus, there are too many sides with different information bubbles discussing super-heated topics. The thread on php internals (https://externals.io/message/117187) for example was a mess, and I am not really looking to repeat the same here.

Anyway closing here. It's a single line of output when you run a Composer update, if that really pisses you off so bad you can `grep -v` it away I suppose.",False,0,MEMBER
https://api.github.com/repos/composer/packagist/issues/comments/1061911780,ukranian propaganda,GeoffreyDijkstra,16,1160862933,6,1061911780,0,1060664470,2022-03-08T15:37:59Z,"@Seldaek I don't want to be involved in the discussion if we should show or not show this banner, but by adding the #StandWithUkraine info banner we now get bombarded by our crontab with emails :grin: 

For my company I run a  lot of automated tasks using composer scripts (with -q and -n flags) running in crontab, if there is output a mail get send by crontab, this normally only happend when something went wrong but now  I get a lot of emails only containing this info header. So the question is can we hide this banner in composer?",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1061918821,ukranian propaganda,Seldaek,16,1160862933,7,1061918821,0,1061911780,2022-03-08T15:44:20Z,@GeoffreyDijkstra please open a new issue on Composer with some details (like composer version & co) because it sounds to me like -q should definitely suppress this as it isn't an error.,False,0,MEMBER
https://api.github.com/repos/composer/packagist/issues/comments/1061928648,ukranian propaganda,GeoffreyDijkstra,16,1160862933,8,1061928648,0,1061918821,2022-03-08T15:53:40Z,@Seldaek done https://github.com/composer/composer/issues/10598,False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1071013533,ukranian propaganda,paxperscientiam,16,1160862933,9,1071013533,0,1061928648,2022-03-17T15:58:44Z,"I really appreciate the gesture, @Seldaek. Even if only fleetingly, I hope complicit programmers within the Putin government are given pause.

This is an act of defiance; ignore the detractors who openly, or apathetically support Russia's criminal invasion of Ukraine.",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1075658728,ukranian propaganda,stanfieldr,16,1160862933,10,1075658728,0,1071013533,2022-03-22T21:24:04Z,@ghost These types of people will be the demise of centralized projects. And I look forward to and will be working on alternatives moving forward.,False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1079591305,ukranian propaganda,paxperscientiam,16,1160862933,11,1079591305,0,1075658728,2022-03-26T03:52:33Z,"> @ghost These types of people will be the demise of centralized projects. And I look forward to and will be working on alternatives moving forward.

By all means, make your own project. Most will not miss your juvenile apologia. ",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1079719734,ukranian propaganda,stanfieldr,16,1160862933,12,1079719734,0,1079591305,2022-03-26T15:47:26Z,"Thanks for the inspiration, although the idealist in me wishes Open Source Software was inclusive rather than divisive. Separation of Concerns has been a well accepted belief throughout my career. Politics, calling people names and failing to debate PRs on a technical merit is just disappointing.",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1079760693,ukranian propaganda,paxperscientiam,16,1160862933,13,1079760693,0,1079719734,2022-03-26T19:34:11Z,"Ukraine has been invaded by Russia.

Millions have been displaced by Russian brutality. Millions are refugees departed, millions are refugees in their own land. 

What's rich is how blissfully ignorant you are of your own egomania.

You failed to silence the author with your delusional concerns over the state of free software.

You spend too much time on the Internet; take a break to figure out the source of your desire to silence those who speak for the victims of Putin. 

Long Live Ukraine!",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1079765838,ukranian propaganda,stanfieldr,16,1160862933,14,1079765838,0,1079760693,2022-03-26T20:05:10Z,You guys should consider removing the code of conduct from your README.md if you're not going to follow it,False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1441008691,ukranian propaganda,politsin,16,1160862933,15,1441008691,0,1079765838,2023-02-22T23:41:51Z,"```sh
git clone https://github.com/composer/composer.git --branch 2.6.5  ~/composer-build && \
    composer install  -o -d ~/composer-build && \
    wget https://raw.githubusercontent.com/politsin/snipets/master/patch/composer.patch -q -O ~/composer-build/composer.patch  && \
    cd ~/composer-build && patch -p1 < composer.patch && \
    php -d phar.readonly=0 bin/compile && \
    rm /usr/local/bin/composer && \
    php composer.phar install && \
    php composer.phar update && \
    mv ~/composer-build/composer.phar /usr/local/bin/composer && \
    rm -rf ~/composer-build  && \
    chmod +x /usr/local/bin/composer
```",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1651918013,ukranian propaganda,unix-dude,16,1160862933,16,1651918013,0,1441008691,2023-07-26T14:26:56Z,Really disappointed to see political propaganda in my terminal when using composer after a long time today. what a joke. Will not be funding any projects until they stop trying to be a political organisation that supports Ukranian rebels.,False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1735455918,ukranian propaganda,maslennikov-yv,16,1160862933,17,1735455918,0,1651918013,2023-09-26T12:34:26Z,"@Seldaek 

> I really appreciate the gesture, @Seldaek. Even if only fleetingly, I hope complicit programmers within the Putin government are given pause.
> 
> This is an act of defiance; ignore the detractors who openly, or apathetically support Russia's criminal invasion of Ukraine.

Nazis

> @GeoffreyDijkstra please open a new issue on Composer with some details (like composer version & co) because it sounds to me like -q should definitely suppress this as it isn't an error.

this is a palliative, cleanup!",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/1272,Honestly,garethnic,4,1169650672,1,1169650672,0,0,2022-03-15T13:06:41Z,"Why do we need to see political messaging every time we use composer?

It's okay if devs wanna write blogs about the issue of the day, cater websites to it etc. But why mess with the tools and force this one every single dev around the world that has to use this. 

This adds nothing but a visual distraction.",True,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1068081107,Honestly,Seldaek,4,1169650672,2,1068081107,0,1169650672,2022-03-15T14:54:53Z,"Bombs are also distracting, I guess you can be glad you just have to deal with some colorful text.",False,0,MEMBER
https://api.github.com/repos/composer/packagist/issues/comments/1068089873,Honestly,garethnic,4,1169650672,3,1068089873,0,1068081107,2022-03-15T15:01:54Z,"Ja buddy, virtue signal harder.",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1071003696,Honestly,paxperscientiam,4,1169650672,4,1071003696,0,1068089873,2022-03-17T15:50:33Z,"@garethnic, “Virtue signaling” is the thoughtless squawk for today’s hip, haughty reactionary on-the-go.

As with the context of this discussion, it’s rhetoric deployed to shield oneself from discomfort through (failed) suppression of free expression of complex social issues.

You don't like it? Fork off.",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1071037843,Honestly,garethnic,4,1169650672,5,1071037843,0,1071003696,2022-03-17T16:18:06Z,Yeah @paxperscientiam fuck you too.,False,0,NONE
https://api.github.com/repos/composer/packagist/issues/1277,Do one thing and do it well,stanfieldr,3,1175937111,1,1175937111,0,0,2022-03-21T21:03:06Z,"- Fixes #1266
- Fixes #1268
- Fixes #1271
- Avoids a substantial amount of disagreements found here https://github.com/composer/packagist/commit/86244a3695fcaaac9c5ba4257a4314eae1c6d981#commitcomment-68136538
- Decouples the code",True,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1074713948,Do one thing and do it well,paxperscientiam,3,1175937111,2,1074713948,0,1175937111,2022-03-22T04:29:04Z,"Your commit strips out an important reminder that Russia has invaded Ukraine. The Russian military are killing indiscriminately, millions of people are displaced. 

Code doesn't exist in a vacuum. Anyone might use composer -- even developers in the governments of Ukraine and Russia. 

I recommend rejecting this PR. ",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1074744007,Do one thing and do it well,stanfieldr,3,1175937111,3,1074744007,0,1074713948,2022-03-22T05:32:05Z,"@paxperscientiam If people would like to see political messages in their package manager, they could easily add it as an [event](https://getcomposer.org/doc/articles/scripts.md#command-events). We could substitute any other political statement there and the same would be true. The point is it would be extremely difficult to represent all the political messages out there in the world **well** as #1268 hints at. If enough people are interested in this type of information in their package manager, perhaps a plugin would resolve their issue.",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1074999052,Do one thing and do it well,Seldaek,3,1175937111,4,1074999052,0,1074744007,2022-03-22T10:29:35Z,Thanks but no thanks. Piling up yet another issue/PR on top is not going to make us change our minds.,False,0,MEMBER
https://api.github.com/repos/composer/packagist/issues/1279,The stand with ukraine message makes it feel like malware is being installed.,Quilava1,5,1179107768,1,1179107768,0,0,2022-03-24T07:17:59Z,"When I installed a package and saw the #StandWithUkraine letters, I panicked and quickly closed the terminal, thinking it was installing malware infected dependancies. And it led to a good half hour of searching why it appeared. I was worried my PC at that point had malware installed and was trying to remove it. 
Seeing messages like that on installer is confusing. I think most developers seeing something like that appear on the console will alt+f4 before seeing why the message is there. ",True,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1077344265,The stand with ukraine message makes it feel like malware is being installed.,karol-haltenberger,5,1179107768,2,1077344265,0,1179107768,2022-03-24T08:05:08Z,#1280 ,False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1077380298,The stand with ukraine message makes it feel like malware is being installed.,Seldaek,5,1179107768,3,1077380298,0,1077344265,2022-03-24T08:49:38Z,"Yes.. because if your computer is compromised and running third party code, closing the window is definitely fixing it. Sorry but that sounds like ostrich security practices.

Anyway, we will remove this when we deem it appropriate, thank you.",False,0,MEMBER
https://api.github.com/repos/composer/packagist/issues/comments/1081250517,The stand with ukraine message makes it feel like malware is being installed.,almazdanilov,5,1179107768,4,1081250517,0,1077380298,2022-03-28T23:30:41Z,Now composer is malware itself. Please use clear one https://github.com/open-composer/composer,False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1247815524,The stand with ukraine message makes it feel like malware is being installed.,kryoz,5,1179107768,5,1247815524,0,1081250517,2022-09-15T09:10:20Z,It seems Seldaek has become not only excellent developer but a great political analyst.,False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1441008296,The stand with ukraine message makes it feel like malware is being installed.,politsin,5,1179107768,6,1441008296,0,1247815524,2023-02-22T23:41:13Z,"```sh
git clone https://github.com/composer/composer.git --branch 2.6.5  ~/composer-build && \
    composer install  -o -d ~/composer-build && \
    wget https://raw.githubusercontent.com/politsin/snipets/master/patch/composer.patch -q -O ~/composer-build/composer.patch  && \
    cd ~/composer-build && patch -p1 < composer.patch && \
    php -d phar.readonly=0 bin/compile && \
    rm /usr/local/bin/composer && \
    php composer.phar install && \
    php composer.phar update && \
    mv ~/composer-build/composer.phar /usr/local/bin/composer && \
    rm -rf ~/composer-build  && \
    chmod +x /usr/local/bin/composer
```",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/1284,#StandWithPeace,dschotman,3,1184994229,1,1184994229,0,0,2022-03-29T14:51:53Z,,True,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1212182615,#StandWithPeace,dreipoe,3,1184994229,2,1212182615,0,1184994229,2022-08-11T15:58:31Z,Stop dragging politics into open source projects because they can be forked easily ;),False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1212815414,#StandWithPeace,xabbuh,3,1184994229,3,1212815414,0,1212182615,2022-08-12T07:29:39Z,"Have fun maintaining this ""easily"".",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1216344120,#StandWithPeace,EnderCaster,3,1184994229,4,1216344120,0,1212815414,2022-08-16T09:00:15Z,"> Stop dragging politics into open source projects because they can be forked easily ;)

To view the code, I think he just removed 'politics'",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/1285,Bump guzzlehttp/psr7 from 2.1.0 to 2.2.1,dependabot[bot],3,1185488090,1,1185488090,0,0,2022-03-29T22:18:25Z,"Bumps [guzzlehttp/psr7](https://github.com/guzzle/psr7) from 2.1.0 to 2.2.1.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/guzzle/psr7/releases"">guzzlehttp/psr7's releases</a>.</em></p>
<blockquote>
<h2>2.2.1</h2>
<p>See <a href=""https://github.com/guzzle/psr7/blob/HEAD/CHANGELOG.md"">change log</a> for changes.</p>
<h2>2.2.0</h2>
<p>See <a href=""https://github.com/guzzle/psr7/blob/HEAD/CHANGELOG.md"">change log</a> for changes.</p>
<h2>2.1.2</h2>
<p>See <a href=""https://github.com/guzzle/psr7/blob/HEAD/CHANGELOG.md"">change log</a> for changes.</p>
<h2>2.1.1</h2>
<p>See <a href=""https://github.com/guzzle/psr7/blob/HEAD/CHANGELOG.md"">change log</a> for changes.</p>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/guzzle/psr7/blob/master/CHANGELOG.md"">guzzlehttp/psr7's changelog</a>.</em></p>
<blockquote>
<h2>2.2.1 - 2022-03-20</h2>
<h3>Fixed</h3>
<ul>
<li>Correct header value validation</li>
</ul>
<h2>2.2.0 - 2022-03-20</h2>
<h3>Added</h3>
<ul>
<li>A more compressive list of mime types</li>
<li>Add JsonSerializable to Uri</li>
<li>Missing return types</li>
</ul>
<h3>Fixed</h3>
<ul>
<li>Bug MultipartStream no <code>uri</code> metadata</li>
<li>Bug MultipartStream with filename for <code>data://</code> streams</li>
<li>Fixed new line handling in MultipartStream</li>
<li>Reduced RAM usage when copying streams</li>
<li>Updated parsing in <code>Header::normalize()</code></li>
</ul>
<h2>2.1.1 - 2022-03-20</h2>
<h3>Fixed</h3>
<ul>
<li>Validate header values properly</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/guzzle/psr7/commit/c94a94f120803a18554c1805ef2e539f8285f9a2""><code>c94a94f</code></a> Release 2.2.1 (<a href=""https://github-redirect.dependabot.com/guzzle/psr7/issues/493"">#493</a>)</li>
<li><a href=""https://github.com/guzzle/psr7/commit/8f199b15f06c5b2b101aa87a073f652fca506ba0""><code>8f199b1</code></a> Merge branch '2.1'</li>
<li><a href=""https://github.com/guzzle/psr7/commit/b36d463b214c76ed12b924bae0445f3531bb1686""><code>b36d463</code></a> Release 2.1.2 (<a href=""https://github-redirect.dependabot.com/guzzle/psr7/issues/492"">#492</a>)</li>
<li><a href=""https://github.com/guzzle/psr7/commit/6565c7e0db3231e92dd5ca3bed448b30fbc89eb1""><code>6565c7e</code></a> Release 2.2.0 (<a href=""https://github-redirect.dependabot.com/guzzle/psr7/issues/488"">#488</a>)</li>
<li><a href=""https://github.com/guzzle/psr7/commit/11d949b0042e7e8b92bf006ceb45759e20825c8d""><code>11d949b</code></a> Merge branch '2.1'</li>
<li><a href=""https://github.com/guzzle/psr7/commit/53491b6394cdcb66880063b82c0b16cf082711eb""><code>53491b6</code></a> Release 2.1.1 (<a href=""https://github-redirect.dependabot.com/guzzle/psr7/issues/485"">#485</a>)</li>
<li><a href=""https://github.com/guzzle/psr7/commit/a7b43201ff9001aafcbbff2cb6510172696d6aff""><code>a7b4320</code></a> Upgrade actions and SA tools (<a href=""https://github-redirect.dependabot.com/guzzle/psr7/issues/479"">#479</a>)</li>
<li><a href=""https://github.com/guzzle/psr7/commit/b71e948cfd842d5938c3af7a782ae2820ae09c3c""><code>b71e948</code></a> Dont put the full file body as filename (<a href=""https://github-redirect.dependabot.com/guzzle/psr7/issues/478"">#478</a>)</li>
<li><a href=""https://github.com/guzzle/psr7/commit/d55bd569d52f460409c1bd2322c73a4d1c1f5fef""><code>d55bd56</code></a> Fix parsing in <code>Header::normalize()</code> (<a href=""https://github-redirect.dependabot.com/guzzle/psr7/issues/476"">#476</a>)</li>
<li><a href=""https://github.com/guzzle/psr7/commit/ff7677767bdca41a0659377b939ba43ec59e6953""><code>ff76777</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/guzzle/psr7/issues/453"">#453</a> from guzzle/comprehensive-mime-types</li>
<li>Additional commits viewable in <a href=""https://github.com/guzzle/psr7/compare/2.1.0...2.2.1"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=guzzlehttp/psr7&package-manager=composer&previous-version=2.1.0&new-version=2.2.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/composer/packagist/network/alerts).

</details>",True,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1082424730,Bump guzzlehttp/psr7 from 2.1.0 to 2.2.1,private-packagist[bot],3,1185488090,2,1082424730,0,1185488090,2022-03-29T22:18:30Z,"### composer.lock

#### Package changes
| Package | Operation | From | To | Changes |
|---------|-----------|------|----|--------|
| **composer/composer** | upgrade | 2.3.x-dev b066598 | 2.3.x-dev 02931cd | [diff](https://github.com/composer/composer/compare/b066598...02931cd) |
| doctrine/dbal | upgrade | 3.3.3 | 3.3.4 | [diff](https://github.com/doctrine/dbal/compare/3.3.3...3.3.4) |
| **doctrine/doctrine-bundle** | upgrade | 2.5.7 | 2.6.0 | [diff](https://github.com/doctrine/DoctrineBundle/compare/2.5.7...2.6.0) |
| doctrine/persistence | upgrade | 2.4.0 | 2.4.1 | [diff](https://github.com/doctrine/persistence/compare/2.4.0...2.4.1) |
| guzzlehttp/guzzle | upgrade | 7.4.1 | 7.4.2 | [diff](https://github.com/guzzle/guzzle/compare/7.4.1...7.4.2) |
| guzzlehttp/psr7 | upgrade | 2.1.0 | 2.2.1 | [diff](https://github.com/guzzle/psr7/compare/2.1.0...2.2.1) |
| **laminas/laminas-diagnostics** | upgrade | 1.14.0 | 1.15.0 | [diff](https://github.com/laminas/laminas-diagnostics/compare/1.14.0...1.15.0) |
| **laminas/laminas-feed** | upgrade | 2.16.0 | 2.17.0 | [diff](https://github.com/laminas/laminas-feed/compare/2.16.0...2.17.0) |
| phpdocumentor/type-resolver | upgrade | 1.6.0 | 1.6.1 | [diff](https://github.com/phpDocumentor/TypeResolver/compare/1.6.0...1.6.1) |
| thecodingmachine/safe | upgrade | v2.1.2 | v2.1.3 | [diff](https://github.com/thecodingmachine/safe/compare/v2.1.2...v2.1.3) |
| **twig/twig** | upgrade | v3.3.8 | v3.3.9 | [diff](https://github.com/twigphp/Twig/compare/v3.3.8...v3.3.9) |

#### Dev Package changes
| Package | Operation | From | To | Changes |
|---------|-----------|------|----|--------|
| **phpstan/phpstan** | upgrade | 1.4.10 | 1.5.2 | [diff](https://github.com/phpstan/phpstan/compare/1.4.10...1.5.2) |
| **phpstan/phpstan-doctrine** | upgrade | 1.2.11 | 1.3.0 | [diff](https://github.com/phpstan/phpstan-doctrine/compare/1.2.11...1.3.0) |
| **phpstan/phpstan-symfony** | upgrade | 1.1.7 | 1.1.8 | [diff](https://github.com/phpstan/phpstan-symfony/compare/1.1.7...1.1.8) |




---
[Settings](https://packagist.com/orgs/packagist-conductors/syncs/3683/pull-requests/settings) · [Docs](https://packagist.com/docs/update-review) · Powered by [Private Packagist](https://packagist.com/)
",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1082882092,Bump guzzlehttp/psr7 from 2.1.0 to 2.2.1,private-packagist[bot],3,1185488090,3,1082882092,0,1082424730,2022-03-30T09:59:33Z,"The [composer.lock diff comment](https://github.com/composer/packagist/pull/1285#issuecomment-1082424730) has been updated to reflect new changes in this PR.
",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1082882200,Bump guzzlehttp/psr7 from 2.1.0 to 2.2.1,dependabot[bot],3,1185488090,4,1082882200,0,1082882092,2022-03-30T09:59:38Z,"Looks like guzzlehttp/psr7 is up-to-date now, so this is no longer needed.",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/1304,test phpstan-dba feature branch,staabm,13,1247089616,1,1247089616,0,0,2022-05-24T20:28:09Z,just testing a bleeding edge phpstan dba feature,True,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1136399825,test phpstan-dba feature branch,private-packagist[bot],13,1247089616,2,1136399825,0,1247089616,2022-05-24T20:28:14Z,"### composer.lock
<details>
  <summary>Click to show 192 changes in this composer.lock file</summary>

#### Package changes
| Package | Operation | From | To | Changes |
|---------|-----------|------|----|--------|
  | **algolia/algoliasearch-client-php** | remove | 3.2.0  | -  | - |
  | **babdev/pagerfanta-bundle** | remove | v3.6.1  | -  | - |
  | bacon/bacon-qr-code | remove | 2.0.7  | -  | - |
  | beberlei/assert | remove | v3.3.2  | -  | - |
  | **beelab/recaptcha2-bundle** | remove | v2.6.0  | -  | - |
  | **cebe/markdown** | remove | 1.2.1  | -  | - |
  | composer/ca-bundle | remove | 1.3.1  | -  | - |
  | **composer/composer** | remove | 2.3.x-dev f1f013e  | -  | - |
  | composer/metadata-minifier | remove | 1.0.0  | -  | - |
  | **composer/pcre** | remove | 3.0.0  | -  | - |
  | composer/semver | remove | 3.3.2  | -  | - |
  | composer/spdx-licenses | remove | 1.5.6  | -  | - |
  | composer/xdebug-handler | remove | 3.0.3  | -  | - |
  | dasprid/enum | remove | 1.0.3  | -  | - |
  | **doctrine/annotations** | remove | 1.13.2  | -  | - |
  | doctrine/cache | remove | 2.1.1  | -  | - |
  | doctrine/collections | remove | 1.6.8  | -  | - |
  | **doctrine/common** | remove | 3.2.2  | -  | - |
  | doctrine/dbal | remove | 3.3.4  | -  | - |
  | doctrine/deprecations | remove | v0.5.3  | -  | - |
  | **doctrine/doctrine-bundle** | remove | 2.6.0  | -  | - |
  | doctrine/event-manager | remove | 1.1.1  | -  | - |
  | doctrine/inflector | remove | 2.0.4  | -  | - |
  | doctrine/instantiator | remove | 1.4.1  | -  | - |
  | doctrine/lexer | remove | 1.2.3  | -  | - |
  | **doctrine/orm** | remove | 2.11.2  | -  | - |
  | doctrine/persistence | remove | 2.4.1  | -  | - |
  | doctrine/sql-formatter | remove | 1.1.2  | -  | - |
  | egulias/email-validator | remove | 3.1.2  | -  | - |
  | **endroid/qr-code** | remove | 4.4.7  | -  | - |
  | **ezyang/htmlpurifier** | remove | v4.14.0  | -  | - |
  | friendsofphp/proxy-manager-lts | remove | v1.0.7  | -  | - |
  | google/recaptcha | remove | 1.2.4  | -  | - |
  | **graze/dog-statsd** | remove | 1.0.0  | -  | - |
  | guzzlehttp/guzzle | remove | 7.4.2 [:warning:](# ""A security advisory has been found for this version."") | -  | - |
  | guzzlehttp/promises | remove | 1.5.1  | -  | - |
  | guzzlehttp/psr7 | remove | 2.2.1  | -  | - |
  | justinrainbow/json-schema | remove | 5.2.11  | -  | - |
  | knplabs/knp-menu | remove | v3.3.0  | -  | - |
  | **knplabs/knp-menu-bundle** | remove | v3.2.0  | -  | - |
  | **knpuniversity/oauth2-client-bundle** | remove | v2.10.0  | -  | - |
  | laminas/laminas-code | remove | 4.5.1  | -  | - |
  | **laminas/laminas-diagnostics** | remove | 1.15.0  | -  | - |
  | laminas/laminas-escaper | remove | 2.10.0  | -  | - |
  | **laminas/laminas-feed** | remove | 2.17.0  | -  | - |
  | laminas/laminas-stdlib | remove | 3.7.1  | -  | - |
  | lcobucci/clock | remove | 2.1.0  | -  | - |
  | lcobucci/jwt | remove | 4.1.5  | -  | - |
  | league/oauth2-client | remove | 2.6.1  | -  | - |
  | **league/oauth2-github** | remove | 3.0.0  | -  | - |
  | monolog/monolog | remove | 2.4.0  | -  | - |
  | **nelmio/cors-bundle** | remove | 2.2.0  | -  | - |
  | **nelmio/security-bundle** | remove | v2.12.0  | -  | - |
  | **pagerfanta/core** | remove | v3.6.1  | -  | - |
  | **pagerfanta/doctrine-orm-adapter** | remove | v3.6.1  | -  | - |
  | **pagerfanta/twig** | remove | v3.6.1  | -  | - |
  | paragonie/constant_time_encoding | remove | v2.5.0  | -  | - |
  | phpdocumentor/reflection-common | remove | 2.2.0  | -  | - |
  | **phpdocumentor/reflection-docblock** | remove | 5.3.0  | -  | - |
  | phpdocumentor/type-resolver | remove | 1.6.1  | -  | - |
  | **predis/predis** | remove | v1.1.10  | -  | - |
  | psr/cache | remove | 2.0.0  | -  | - |
  | psr/container | remove | 1.1.2  | -  | - |
  | psr/event-dispatcher | remove | 1.0.0  | -  | - |
  | psr/http-client | remove | 1.0.1  | -  | - |
  | psr/http-factory | remove | 1.0.1  | -  | - |
  | psr/http-message | remove | 1.0.1  | -  | - |
  | psr/link | remove | 1.1.1  | -  | - |
  | psr/log | remove | 2.0.0  | -  | - |
  | psr/simple-cache | remove | 3.0.0  | -  | - |
  | ralouphie/getallheaders | remove | 3.0.3  | -  | - |
  | react/promise | remove | v2.9.0  | -  | - |
  | **scheb/2fa-backup-code** | remove | v6.0.1  | -  | - |
  | **scheb/2fa-bundle** | remove | v6.0.1  | -  | - |
  | **scheb/2fa-totp** | remove | v6.0.1  | -  | - |
  | **scheb/2fa-trusted-device** | remove | v6.0.1  | -  | - |
  | seld/jsonlint | remove | 1.8.3  | -  | - |
  | seld/phar-utils | remove | 1.2.0  | -  | - |
  | **seld/signal-handler** | remove | 1.3.0  | -  | - |
  | **sensio/framework-extra-bundle** | remove | v6.2.6  | -  | - |
  | **snc/redis-bundle** | remove | 3.6.0  | -  | - |
  | spomky-labs/otphp | remove | v10.0.3  | -  | - |
  | **symfony/asset** | remove | v5.4.7  | -  | - |
  | symfony/cache | remove | v5.4.8  | -  | - |
  | symfony/cache-contracts | remove | v2.5.1  | -  | - |
  | symfony/config | remove | v5.4.8  | -  | - |
  | **symfony/console** | remove | v5.4.8  | -  | - |
  | symfony/dependency-injection | remove | v5.4.8  | -  | - |
  | symfony/deprecation-contracts | remove | v3.0.1  | -  | - |
  | symfony/doctrine-bridge | remove | v5.4.8  | -  | - |
  | **symfony/dotenv** | remove | v5.4.5  | -  | - |
  | symfony/error-handler | remove | v5.4.8  | -  | - |
  | symfony/event-dispatcher | remove | v5.4.3  | -  | - |
  | symfony/event-dispatcher-contracts | remove | v3.0.1  | -  | - |
  | **symfony/expression-language** | remove | v5.4.8  | -  | - |
  | symfony/filesystem | remove | v5.4.7  | -  | - |
  | symfony/finder | remove | v5.4.8  | -  | - |
  | **symfony/flex** | remove | v1.18.6  | -  | - |
  | **symfony/form** | remove | v5.4.8  | -  | - |
  | **symfony/framework-bundle** | remove | v5.4.8  | -  | - |
  | **symfony/http-client** | remove | v5.4.8  | -  | - |
  | symfony/http-client-contracts | remove | v2.5.1  | -  | - |
  | symfony/http-foundation | remove | v5.4.8  | -  | - |
  | symfony/http-kernel | remove | v5.4.8  | -  | - |
  | **symfony/intl** | remove | v5.4.8  | -  | - |
  | **symfony/lock** | remove | v5.4.7  | -  | - |
  | **symfony/mailer** | remove | v5.4.8  | -  | - |
  | symfony/mime | remove | v5.4.8  | -  | - |
  | symfony/monolog-bridge | remove | v5.4.3  | -  | - |
  | **symfony/monolog-bundle** | remove | v3.7.1  | -  | - |
  | symfony/options-resolver | remove | v5.4.3  | -  | - |
  | symfony/password-hasher | remove | v5.4.8  | -  | - |
  | symfony/polyfill-intl-grapheme | remove | v1.25.0  | -  | - |
  | symfony/polyfill-intl-icu | remove | v1.25.0  | -  | - |
  | symfony/polyfill-intl-idn | remove | v1.25.0  | -  | - |
  | symfony/polyfill-intl-normalizer | remove | v1.25.0  | -  | - |
  | symfony/polyfill-mbstring | remove | v1.25.0  | -  | - |
  | symfony/polyfill-php72 | remove | v1.25.0  | -  | - |
  | symfony/polyfill-php73 | remove | v1.25.0  | -  | - |
  | symfony/polyfill-php80 | remove | v1.25.0  | -  | - |
  | symfony/polyfill-php81 | remove | v1.25.0  | -  | - |
  | **symfony/process** | remove | v5.4.8  | -  | - |
  | **symfony/property-access** | remove | v5.4.8  | -  | - |
  | **symfony/property-info** | remove | v5.4.7  | -  | - |
  | **symfony/proxy-manager-bridge** | remove | v5.4.6  | -  | - |
  | symfony/routing | remove | v5.4.8  | -  | - |
  | **symfony/security-bundle** | remove | v5.4.8  | -  | - |
  | symfony/security-core | remove | v5.4.8  | -  | - |
  | symfony/security-csrf | remove | v5.4.3  | -  | - |
  | symfony/security-guard | remove | v5.4.3  | -  | - |
  | symfony/security-http | remove | v5.4.8  | -  | - |
  | **symfony/serializer** | remove | v5.4.8  | -  | - |
  | symfony/service-contracts | remove | v2.5.1  | -  | - |
  | symfony/string | remove | v5.4.8  | -  | - |
  | **symfony/translation** | remove | v5.4.8  | -  | - |
  | symfony/translation-contracts | remove | v2.5.1  | -  | - |
  | symfony/twig-bridge | remove | v5.4.8  | -  | - |
  | **symfony/twig-bundle** | remove | v5.4.8  | -  | - |
  | **symfony/validator** | remove | v5.4.8  | -  | - |
  | **symfony/var-dumper** | remove | v5.4.8  | -  | - |
  | symfony/var-exporter | remove | v5.4.8  | -  | - |
  | **symfony/web-link** | remove | v5.4.3  | -  | - |
  | **symfony/yaml** | remove | v5.4.3  | -  | - |
  | **symfonycasts/verify-email-bundle** | remove | v1.10.0  | -  | - |
  | thecodingmachine/safe | remove | v2.1.3  | -  | - |
  | **twig/extra-bundle** | remove | v3.3.8  | -  | - |
  | **twig/string-extra** | remove | v3.3.5  | -  | - |
  | **twig/twig** | remove | v3.3.9  | -  | - |
  | ua-parser/uap-php | remove | v3.9.14  | -  | - |
  | webmozart/assert | remove | 1.10.0  | -  | - |

#### Dev Package changes
| Package | Operation | From | To | Changes |
|---------|-----------|------|----|--------|
  | doctrine/data-fixtures | remove | 1.5.2  | -  | - |
  | **doctrine/doctrine-fixtures-bundle** | remove | 3.4.1  | -  | - |
  | myclabs/deep-copy | remove | 1.11.0  | -  | - |
  | nikic/php-parser | remove | v4.13.2  | -  | - |
  | phar-io/manifest | remove | 2.0.3  | -  | - |
  | phar-io/version | remove | 3.2.1  | -  | - |
  | phpspec/prophecy | remove | v1.15.0  | -  | - |
  | **phpstan/phpstan** | remove | 1.5.2  | -  | - |
  | **phpstan/phpstan-doctrine** | remove | 1.3.0  | -  | - |
  | **phpstan/phpstan-symfony** | remove | 1.1.8  | -  | - |
  | phpunit/php-code-coverage | remove | 9.2.15  | -  | - |
  | phpunit/php-file-iterator | remove | 3.0.6  | -  | - |
  | phpunit/php-invoker | remove | 3.1.1  | -  | - |
  | phpunit/php-text-template | remove | 2.0.4  | -  | - |
  | phpunit/php-timer | remove | 5.0.3  | -  | - |
  | **phpunit/phpunit** | remove | 9.5.19  | -  | - |
  | sebastian/cli-parser | remove | 1.0.1  | -  | - |
  | sebastian/code-unit | remove | 1.0.8  | -  | - |
  | sebastian/code-unit-reverse-lookup | remove | 2.0.3  | -  | - |
  | sebastian/comparator | remove | 4.0.6  | -  | - |
  | sebastian/complexity | remove | 2.0.2  | -  | - |
  | sebastian/diff | remove | 4.0.4  | -  | - |
  | sebastian/environment | remove | 5.1.3  | -  | - |
  | sebastian/exporter | remove | 4.0.4  | -  | - |
  | sebastian/global-state | remove | 5.0.5  | -  | - |
  | sebastian/lines-of-code | remove | 1.0.3  | -  | - |
  | sebastian/object-enumerator | remove | 4.0.4  | -  | - |
  | sebastian/object-reflector | remove | 2.0.4  | -  | - |
  | sebastian/recursion-context | remove | 4.0.4  | -  | - |
  | sebastian/resource-operations | remove | 3.0.3  | -  | - |
  | sebastian/type | remove | 3.0.0  | -  | - |
  | sebastian/version | remove | 3.0.2  | -  | - |
  | **staabm/phpstan-dba** | remove | 0.2.23  | -  | - |
  | **symfony/browser-kit** | remove | v5.4.3  | -  | - |
  | **symfony/css-selector** | remove | v5.4.3  | -  | - |
  | **symfony/debug-bundle** | remove | v5.4.3  | -  | - |
  | symfony/dom-crawler | remove | v5.4.6  | -  | - |
  | **symfony/maker-bundle** | remove | v1.40.1  | -  | - |
  | **symfony/phpunit-bridge** | remove | v5.4.8  | -  | - |
  | **symfony/stopwatch** | remove | v5.4.5  | -  | - |
  | **symfony/web-profiler-bundle** | remove | v5.4.8  | -  | - |
  | theseer/tokenizer | remove | 1.2.1  | -  | - |

</details>




---
[Settings](https://packagist.com/orgs/packagist-conductors/syncs/3683/pull-requests/settings) · [Docs](https://packagist.com/docs/update-review) · Powered by [Private Packagist](https://packagist.com/)
",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1136407247,test phpstan-dba feature branch,private-packagist[bot],13,1247089616,3,1136407247,0,1136399825,2022-05-24T20:37:11Z,"The [composer.lock diff comment](https://github.com/composer/packagist/pull/1304#issuecomment-1136399825) has been updated to reflect new changes in this PR.
",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1136916744,test phpstan-dba feature branch,staabm,13,1247089616,4,1136916744,0,1136407247,2022-05-25T07:58:27Z,"@chr-hertel since I don't want to annoy Jordi again with my question, I send this question to you - would be great if you could spent a few minutes to answer them.

with this PR I am testing a new phpstan-dba feature, which analyzes sql queries that don't use an index.
as you can see from the 'files changed'-tab, we got a few errors here.

could you have a look at these and tell me whether you would consider those a ""false-positive""?
maybe we can figure out, whether/how to read a mysql explain result-set to identify queries which should be optimized by the author.

the current implemenation can be seen in https://github.com/staabm/phpstan-dba/pull/377/files#diff-325c727a8f7834a6b7b42f1b3fbfcaa5c41073e796df7eda0fa5f25a48757eb3R55-R83",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1137191119,test phpstan-dba feature branch,stof,13,1247089616,5,1137191119,0,1136916744,2022-05-25T12:42:00Z,"@staabm looking at the reported issues, they are indeed detecting cases where queries don't use indexes (but then, I'm wondering whether it should always be reported as an error, as having indexes for everything might have drawbacks as it slows down writes, which might not be worth it if a query is used rarely in a CLI command for instance, but that's a separate topic).
The only one that might not be expected is the one reporting a missing index on a derived table (which *cannot* have an index AFAICT)",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1137211609,test phpstan-dba feature branch,private-packagist[bot],13,1247089616,6,1137211609,0,1137191119,2022-05-25T13:03:30Z,"The [composer.lock diff comment](https://github.com/composer/packagist/pull/1304#issuecomment-1136399825) has been updated to reflect new changes in this PR.
",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1137216874,test phpstan-dba feature branch,staabm,13,1247089616,7,1137216874,0,1137211609,2022-05-25T13:08:29Z,"@stof thx for the feedback.

ignoring DERIVED-tables seems like a good measure to prevent false-positives -> I will implement just that.

I got another feedback in https://github.com/staabm/phpstan-dba/pull/377#discussion_r881477205 which made me add a threshold, so we don't report missing indexes/table-scan when tables are small (mysql sometime decides reading the table as is is faster then using an index, when small enough).

",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1137221191,test phpstan-dba feature branch,private-packagist[bot],13,1247089616,8,1137221191,0,1137216874,2022-05-25T13:12:24Z,"The [composer.lock diff comment](https://github.com/composer/packagist/pull/1304#issuecomment-1136399825) has been updated to reflect new changes in this PR.
",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1137225789,test phpstan-dba feature branch,staabm,13,1247089616,9,1137225789,0,1137221191,2022-05-25T13:16:29Z,"just update phpstandba and now we no longer get errors.

it seems the few which were reported previous are related to small tables",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1137231385,test phpstan-dba feature branch,stof,13,1247089616,10,1137231385,0,1137225789,2022-05-25T13:21:16Z,"Well, is the CI running with data in tables or with an empty DB ?",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1137234669,test phpstan-dba feature branch,staabm,13,1247089616,11,1137234669,0,1137231385,2022-05-25T13:24:03Z,"I guess its an empty schema currently

see https://github.com/composer/packagist/blob/6a40c01ac4d1eb48236ae5242bca152c9034266b/.github/workflows/phpstan.yml#L41-L52",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1137724237,test phpstan-dba feature branch,Seldaek,13,1247089616,12,1137724237,0,1137234669,2022-05-25T18:56:00Z,@staabm yeah table size metrics seem to be kinda useless as you're unlikely to have prod data in when running PHPStan. Otherwise great feature even with some amount of false positives IMO.. maybe should be opt-in or at least have an option to opt-out if it is too noisy.,False,0,MEMBER
https://api.github.com/repos/composer/packagist/issues/comments/1137740932,test phpstan-dba feature branch,staabm,13,1247089616,13,1137740932,0,1137724237,2022-05-25T19:04:22Z,"thx for the feedback.

> maybe should be opt-in or at least have an option to opt-out if it is too noisy.

its an opt-in feature and the min-table size arg can be [configured with the RuntimeConfiguration](https://github.com/staabm/phpstan-dba/blob/ad5da7c3d6f31ac4abfecd2fb1023e6907d32261/src/QueryReflection/RuntimeConfiguration.php#L119)

just [added an explicit hint](https://github.com/staabm/phpstan-dba/commit/bec52f41f9807cf6ad34136520efe711277b708e), on how to achieve that scenario",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1138227688,test phpstan-dba feature branch,private-packagist[bot],13,1247089616,14,1138227688,0,1137740932,2022-05-26T07:00:45Z,"The [composer.lock diff comment](https://github.com/composer/packagist/pull/1304#issuecomment-1136399825) has been updated to reflect new changes in this PR.
",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/1307,Outdated versions in package JSON response,tiegz,3,1248670667,1,1248670667,0,0,2022-05-25T20:17:37Z,"Hello, the HTML page for this package https://packagist.org/packages/facturascripts/facturascripts shows a latest version of v2022.08, but the JSON representation only shows versions up to v2021.51: https://repo.packagist.org/p/facturascripts/facturascripts.json

The last-modified header looks outdated from the response, too: `last-modified: Sun, 23 Jan 2022 12:30:16 GMT`",True,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1140957157,Outdated versions in package JSON response,stof,3,1248670667,2,1140957157,0,1248670667,2022-05-30T10:01:56Z,"the `/p/` endpoints are the endpoints for the composer v1 metadata, which are restricted to the deprecation. See https://blog.packagist.com/deprecating-composer-1-support/

If you want to read uptodate metadata in JSON format, use the v2 metadata endpoints, as documented on https://packagist.org/apidoc#get-package-data",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1142247083,Outdated versions in package JSON response,tiegz,3,1248670667,3,1142247083,0,1140957157,2022-05-31T14:57:24Z,"Thanks @stof ! Do you know if the first version returned in that list will be the latest versions? It seems like it, but the docs didn't mention it.",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1142254991,Outdated versions in package JSON response,stof,3,1248670667,4,1142254991,0,1142247083,2022-05-31T15:04:11Z,"The `/p2/` endpoints are the ones used by composer 2. So yes, they contain all available versions (and the `p2` files are re-dumped a few seconds after Packagist knows about the new version thanks to the new format)",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/1309,POST request to security advisories API gets 404 error,GuySartorelli,4,1249323705,1,1249323705,0,0,2022-05-26T09:26:39Z,"A GET request to `https://packagist.org/api/security-advisories/` works exactly as expected, but a POST request gets a 404 error.
It looks like [the API should support POST requests](https://github.com/composer/packagist/blob/6a40c01ac4d1eb48236ae5242bca152c9034266b/src/Controller/ApiController.php#L316), even if it's not documented in [the apidoc](https://packagist.org/apidoc#list-security-advisories).

I want to send a POST request because any GET request with too many packages fails (gets a 502 error, most likely hitting the limit of characters that can be included in get vars). Even a project with a fairly modest number of packages can't currently request advisories for all of its packages in a single request, and I'd rather not spam the API with lots of requests for a single project's package list.",True,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1138346170,POST request to security advisories API gets 404 error,glaubinix,4,1249323705,2,1138346170,0,1249323705,2022-05-26T09:34:18Z,"@GuySartorelli can you show how you trigger the POST request? This should definitely work, see for example `curl -X POST -F 'packages[]=symfony/http-foundation' https://packagist.org/api/security-advisories/`",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1138351355,POST request to security advisories API gets 404 error,GuySartorelli,4,1249323705,3,1138351355,0,1138346170,2022-05-26T09:41:15Z,"Yup. The code I'm using is in composer/composer#10798 - I'll include the relevant parts here for convenience:

```php
use Composer\Factory;

$opts = [
    'retry-auth-failure' => false,
    'http' => [
        'method' => 'POST',
        'header' => array('Content-Type: application/json'),
        'content' => json_encode(['packages' => $packageNames]),
    ],
];

// `$this` in this context is a command
$composer = $this->getComposer(true);
$httpDownloader = Factory::createHttpDownloader($this->getIO(), $composer->getConfig());
$response = $httpDownloader->get('https://packagist.org/api/security-advisories', $opts);
```

Sounds like there's probably something wrong with my code rather than something wrong with packagist though. ",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1138362741,POST request to security advisories API gets 404 error,glaubinix,4,1249323705,4,1138362741,0,1138351355,2022-05-26T09:55:37Z,"Two things:
* You are missing a slash at the end of the URL which causes the 404
* Packagist currently doesn't check and decodes the body content for package names so using application/json won't work

The below code should work:
```
$response = $httpDownloader->get('https://packagist.org/api/security-advisories/', [
    'retry-auth-failure' => false,
    'http' => [
        'method' => 'POST',
        'header' => array('Content-type: application/x-www-form-urlencoded'),
        'content' => http_build_query(['packages' => ['symfony/http-foundation']]),
    ],
]);
```
",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1138364307,POST request to security advisories API gets 404 error,GuySartorelli,4,1249323705,5,1138364307,0,1138362741,2022-05-26T09:57:44Z,Huh. I wouldn't have expected a trailing slash being ommitted would cause a 404... but there ya go haha. Thank you very much!,False,0,NONE
https://api.github.com/repos/composer/packagist/issues/1310,"Security Advisories API requires ""packages"" even if ""updatedSince"" is included in request",GuySartorelli,3,1252276768,1,1252276768,0,0,2022-05-30T06:52:47Z,"## Description
[The documentation](https://packagist.org/apidoc#list-security-advisories) for the security advisories API suggests that `packages` can be omitted if `updatedSince` is passed in - but this isn't the case.
> Either a list of packages as query or request parameter or a timestamp as updatedSince query parameter need to be passed.

But if I send a request that includes `updatedSince` but omits `packages` I get an error as below. I suspect it is the documentation rather than the implementation that is incorrect - I can't think of a use case where getting _all_ updates since a given time would be useful.

## Reproduce
`curl -X POST -F 'updatedSince=1653893419' https://packagist.org/api/security-advisories/`
> {""status"":""error"",""message"":""Missing array of package names as the \u0022packages\u0022 parameter""}
",True,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1140800990,"Security Advisories API requires ""packages"" even if ""updatedSince"" is included in request",stof,3,1252276768,2,1140800990,0,1252276768,2022-05-30T07:29:03Z,Can you send a PR updating the doc ?,False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1140811009,"Security Advisories API requires ""packages"" even if ""updatedSince"" is included in request",GuySartorelli,3,1252276768,3,1140811009,0,1140800990,2022-05-30T07:39:51Z,@stof #1311 ,False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1140881132,"Security Advisories API requires ""packages"" even if ""updatedSince"" is included in request",GuySartorelli,3,1252276768,4,1140881132,0,1140811009,2022-05-30T08:48:36Z,"As pointed out in the PR:
> Sending one of them is enough however, updatedSince is currently expected to be set as query parameter. See https://github.com/composer/packagist/blob/main/src/Controller/ApiController.php#L322

> Query parameters are not limited to GET requests. You can also use them with POST requests e.g. curl -X POST https://packagist.org/api/security-advisories/?updatedSince=TIMESTAMP
",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/1313,Feature Request: Jump to search with `/`,LiamKearn,3,1260725718,1,1260725718,0,0,2022-06-04T12:01:31Z,"Google now almost universally adopted this UX principal. Would be really nice for something with heavy searching like packagist.

If anyone else is interested would be appreciated happy to make a PR.",True,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1146606389,Feature Request: Jump to search with `/`,Seldaek,3,1260725718,2,1146606389,0,1260725718,2022-06-04T13:07:03Z,Not against it if you want to PR it. But tab should work already FYI ,False,0,MEMBER
https://api.github.com/repos/composer/packagist/issues/comments/1146784771,Feature Request: Jump to search with `/`,LiamKearn,3,1260725718,3,1146784771,0,1146606389,2022-06-05T11:07:36Z,"Yeah its the first element on the page that is focusable. That should make it easy but for some reason I always find myself doing: `mod+f -> search ""sign in"" because it is visually before the searchbar -> tab` and it never works 😄. In reality the mental pattern I should have is `mod+r -> tab` but I feel spoilt by the recent influx of websites that support `/` to search (even github right now).",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1189940978,Feature Request: Jump to search with `/`,stof,3,1260725718,4,1189940978,0,1146784771,2022-07-20T07:44:51Z,@Seldaek this should be closed as it has been implemented,False,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/2025,WordPress.WP.CronInterval.ChangeDetected can't handle intervals with parentheses,diedexx,3,1124077150,1,1124077150,0,0,2022-02-04T11:05:26Z,"## Bug Description
<!--
Please provide a clear and concise description of what the bug is.

What did you expect to happen? What actually happened?
-->
The WordPress.WP.CronInterval.ChangeDetected sniff will show a `Detected changing of cron_schedules, but could not detect the interval value.` warning when the interval is surrounded with parentheses.

## Minimal Code Snippet
The issue happens when running this command:
```bash
phpcs ./myfile.php
```
... over a file containing this code:
``` php
// myfile.php
<?php

function add_cron_schedule( $schedules ) {
		$schedules['my-schedule'] = [
			'interval' => ( 15 * MINUTE_IN_SECONDS ), // <-- works without the ""()""
			'display'  => esc_html__( 'Every fifteen minutes' ),
		];

		return $schedules;
}

add_filter( 'cron_schedules', 'add_cron_schedule' );
```

## Error Code
<!--
The error code for the sniff that is (or should be) being triggered (you
can see the sniff error codes by running `phpcs` with the `-s` flag).
e.g. `WordPress.PHP.NoSilencedErrors.Discouraged`

You can leave this section empty if you are reporting a false negative.
-->
N/A

## Custom ruleset
<!--
If the issue cannot be reproduced when using `--standard=WordPress` on the command line,
please post the relevant part of your custom ruleset here.
-->
I used the ruleset of this repository. 

## Environment
<!--
To find out the versions used:
* PHP: run `php -v`.
* PHPCS: run `[vendor/bin/]phpcs --version`
* WPCS: run `composer [global] info` for a Composer install.
-->

| Question               | Answer
| ------------------------| -------
| PHP version             | 7.2.22
| PHP_CodeSniffer version | 3.6.2
| WPCS version            | `develop` (2.3.0)
| WPCS install type       | Composer project local and git clone (haven't tested others)


## Additional Context (optional)
<!-- Add any other context about the problem here. -->
While debugging this I found that the parser does look for parentheses, but only parses the opening and not the closing.
After [this loop](https://github.com/WordPress/WordPress-Coding-Standards/blob/73f3d69b3a200935b80f5fd265bfbee8d642d082/WordPress/Sniffs/WP/CronIntervalSniff.php#L180) the `$value` is `""(15*MINUTE_IN_SECONDS""`

## Tested Against `develop` branch?
- [x] I have verified the issue still exists in the `develop` branch of WPCS.
",True,0,NONE
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/1029907803,WordPress.WP.CronInterval.ChangeDetected can't handle intervals with parentheses,jrfnl,3,1124077150,2,1029907803,0,1124077150,2022-02-04T11:35:33Z,@diedexx Thanks for reporting - see PR #2026,False,0,MEMBER
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/1029939386,WordPress.WP.CronInterval.ChangeDetected can't handle intervals with parentheses,diedexx,3,1124077150,3,1029939386,0,1029907803,2022-02-04T12:22:41Z,Thank you @jrfnl for creating a patch so quickly! ,False,0,NONE
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/1029945762,WordPress.WP.CronInterval.ChangeDetected can't handle intervals with parentheses,jrfnl,3,1124077150,4,1029945762,0,1029939386,2022-02-04T12:32:26Z,"Thanks for testing the patch @diedexx !
FYI: it may still be a while before the patch is released as it will go into WPCS 3.0.0... ",False,0,MEMBER
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/2027,"False positive ""High pagination limit"" when `posts_per_page` is set to a function.",justlevine,6,1124928026,1,1124928026,0,0,2022-02-05T13:14:37Z,"<!--
PLEASE FILL OUT THE TEMPLATE COMPLETELY.
BUG REPORTS WHICH CANNOT BE REPRODUCED BASED ON THE INFORMATION PROVIDED WILL BE CLOSED.
-->

## Bug Description
<!--
Please provide a clear and concise description of what the bug is.

What did you expect to happen? What actually happened?
-->

When setting `posts_per_page` to a function, wpcs logs ""Detected high pagination limit, `posts_per_page` is set to..."" warning.
It should [be treated like `-1`](https://github.com/WordPress/WordPress-Coding-Standards/issues/1638#issuecomment-459141404), and have no error shown.

## Minimal Code Snippet
<!-- Please provide example code that allows us to reproduce the issue. Do NOT paste screenshots of code! -->

The issue happens when running this command:
```bash
phpcs ...
```

... over a file containing this code:
```php
function get_query_args( int $first, int $last, int $default_min = 10 ) : array {
  return array(
    // other query args...
    'posts_per_page' => min( max( $first, $last ), $default_min ), 
  );
}
```

## Error Code
<!--
The error code for the sniff that is (or should be) being triggered (you
can see the sniff error codes by running `phpcs` with the `-s` flag).
e.g. `WordPress.PHP.NoSilencedErrors.Discouraged`

You can leave this section empty if you are reporting a false negative.
-->
`WordPress.WP.PostsPerPage.posts_per_page_posts_per_page`

## Custom ruleset
<!--
If the issue cannot be reproduced when using `--standard=WordPress` on the command line,
please post the relevant part of your custom ruleset here.
-->

## Environment
<!--
To find out the versions used:
* PHP: run `php -v`.
* PHPCS: run `[vendor/bin/]phpcs --version`
* WPCS: run `composer [global] info` for a Composer install.
-->

| Question               | Answer
| ------------------------| -------
| PHP version             | 8.0.15
| PHP_CodeSniffer version | 3.6.2
| WPCS version            | 2.3.0, dev-develop
| WPCS install type       | Composer project local
| IDE (if relevant)       | VSCode on wsl2


## Tested Against `develop` branch?
- [x] I have verified the issue still exists in the `develop` branch of WPCS.
",True,0,NONE
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/1031266463,"False positive ""High pagination limit"" when `posts_per_page` is set to a function.",dingo-d,6,1124928026,2,1031266463,0,1124928026,2022-02-07T09:46:05Z,"This example is a tricky one because PHPCS isn't aware of the context. It doesn't parse your code and tracks what you used and where.

PHPCS cannot know if the `$first`, `$lasst`, and `$default_min` would fall in the 'acceptable' category of the post per page sniff (unless you've defined them).

### EDIT

Looking at [the sniff](https://github.com/WordPress/WordPress-Coding-Standards/blob/develop/WordPress/Sniffs/WP/PostsPerPageSniff.php#L71) it doesn't do any sort of calculations, just compares the values here. And you don't have a value but a statement that does something (in your case returns the lowest value of the expression). 




",False,0,MEMBER
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/1031396818,"False positive ""High pagination limit"" when `posts_per_page` is set to a function.",justlevine,6,1124928026,3,1031396818,0,1031266463,2022-02-07T12:09:01Z,"@dingo-d exactly my point. Since we can't know the context, but see that `posts_per_page` is explicitly set, we should mute the error, same way that `-1` is ignored, even though it might be more than 100.",False,0,NONE
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/1031436993,"False positive ""High pagination limit"" when `posts_per_page` is set to a function.",dingo-d,6,1124928026,4,1031436993,0,1031396818,2022-02-07T12:53:30Z,"You can easily do that either by excluding that sniff in your ruleset

```xml
<rule ref=""WordPress.WP"">
	<exclude name=""WordPress.WP.PostsPerPage.posts_per_page_posts_per_page""/>
</rule>
```

Or ignoring that line with a comment

```php
function get_query_args( int $first, int $last, int $default_min = 10 ) : array {
  return array(
    // other query args...
    'posts_per_page' => min( max( $first, $last ), $default_min ), // phpcs:ignore WordPress.WP.PostsPerPage.posts_per_page_posts_per_page
  );
}
```",False,0,MEMBER
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/1031518000,"False positive ""High pagination limit"" when `posts_per_page` is set to a function.",justlevine,6,1124928026,5,1031518000,0,1031436993,2022-02-07T14:18:35Z,"Thanks, I am aware how to silence the sniff. However, I believe it to be a false positive, which is why I opened the issue.",False,0,NONE
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/1031733694,"False positive ""High pagination limit"" when `posts_per_page` is set to a function.",dingo-d,6,1124928026,6,1031733694,0,1031518000,2022-02-07T17:35:34Z,"This is odd, I'm not getting that error. I tried adding your code example to the unit test file, and I tried sniffing a test file with `WordPress-Extra` ruleset and nothing gets reported.

The value that is picked up in your case is `min( max( $first`, which will return `false` in the callback.

Can you share your ruleset?",False,0,MEMBER
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/1605806386,"False positive ""High pagination limit"" when `posts_per_page` is set to a function.",jrfnl,6,1124928026,7,1605806386,0,1031733694,2023-06-25T01:00:58Z,"I have been able to reproduce the issue and a fix will be included in WPCS 3.0.0.

@dingo-d I believe the reason you couldn't reproduce the issue is because you tested with PHP 7.x, while the behaviour in PHP for [text to number comparisons](https://wiki.php.net/rfc/string_to_number_comparison) has changed in PHP 8.0: https://3v4l.org/nOlYL#veol",False,0,MEMBER
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/2031,Remove deprecation Warning on sanitize_url(),Ipstenu,3,1166684224,1,1166684224,0,0,2022-03-11T17:36:48Z,"## Bug Description

The use of sanitize_url() is still listed as deprecated, however as of WordPress 5.9 it has been **un** deprecated

## Minimal Code Snippet

Use sanitize_url() in a line of code.
ERROR   sanitize_url() has been deprecated since WordPress version 2.8.0. Use esc_url_raw() instead.
                  (WordPress.WP.DeprecatedFunctions.sanitize_urlFound)

This can be fixed by removing it from the deprecation list.

## Tested Against `develop` branch?

I have not tested against develop, but I did check here:

https://github.com/WordPress/WordPress-Coding-Standards/blob/develop/WordPress/Sniffs/WP/DeprecatedFunctionsSniff.php#L412

So it's still on the sniffs :)",True,0,CONTRIBUTOR
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/1065344921,Remove deprecation Warning on sanitize_url(),jrfnl,3,1166684224,2,1065344921,0,1166684224,2022-03-11T17:51:36Z,"@Ipstenu Thanks for reporting this. The deprecation lists haven't been updated for WP 5.9 yet.

",False,0,MEMBER
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/1147267003,Remove deprecation Warning on sanitize_url(),SergeyBiryukov,3,1166684224,3,1147267003,0,1065344921,2022-06-06T09:50:35Z,"As of WordPress 6.1, `sanitize_url()` becomes the recommended function for sanitizing a URL, see [#WP55852](https://core.trac.wordpress.org/ticket/55852) for details.

I think it should be removed from the deprecated functions sniff (as noted above) and added to the list of [sanitizing functions](https://github.com/WordPress/WordPress-Coding-Standards/blob/95a5df2e074f757cc24f87f60b8b276c817e312f/WordPress/Sniff.php#L185).",False,0,MEMBER
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/1147600508,Remove deprecation Warning on sanitize_url(),jrfnl,3,1166684224,4,1147600508,0,1147267003,2022-06-06T15:47:51Z,@SergeyBiryukov It definitely will be removed when we run the deprecated code scanner before releasing the next version.,False,0,MEMBER
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/2032,What does QuotedDynamicPlaceholderGeneration mean?,kkmuffme,3,1168400212,1,1168400212,0,0,2022-03-14T13:44:02Z,"
```
""AND p.post_status IN ('"" . implode( ""', '"", esc_sql( $allowed_status ) ) . ""') "" .
```

I get `QuotedDynamicPlaceholderGeneration`  error (`Dynamic placeholder generation should not have surrounding quotes.`) for this code, but it's unclear what this means.
I checked the code base here, but the code does not make it any clearer for me.

From what I checked in the code, it compares the code within the IN() without quotes, but that makes 0 sense to me/looks like a false positive.",True,0,NONE
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/1066847161,What does QuotedDynamicPlaceholderGeneration mean?,jrfnl,3,1168400212,2,1066847161,0,1168400212,2022-03-14T14:15:34Z,"@kkmuffme The sniff expects you to use proper prepared queries, not what you are doing.

Your snippet _should_ read something like this for a secure query:
```php
$where = $wpdb->prepare(
	sprintf(
		""AND p.post_status IN (%s)"",
		implode( ',', array_fill( 0, count( $allowed_status ), '%s' ) )
	),
	$allowed_status
);
```",False,0,MEMBER
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/1068827679,What does QuotedDynamicPlaceholderGeneration mean?,jrfnl,3,1168400212,3,1068827679,0,1066847161,2022-03-16T07:44:44Z,@kkmuffme Why was this reopened ?,False,0,MEMBER
https://api.github.com/repos/WordPress/WordPress-Coding-Standards/issues/comments/1068827821,What does QuotedDynamicPlaceholderGeneration mean?,kkmuffme,3,1168400212,4,1068827821,0,1068827679,2022-03-16T07:44:57Z,"This doesn't work when there are multiple placeholders (my example given was a bit too simplistic I guess).
In that case one has to additionally merge the args

My actual code:

```
$wpdb->prepare(
         ""SELECT ID AS order_id, postmeta.meta_value AS country_code FROM $wpdb->posts AS posts INNER JOIN $wpdb->postmeta AS postmeta ON posts.ID = postmeta.post_id WHERE posts.post_type = 'shop_order' "" .
         ""AND posts.post_status IN ('"" . implode( ""', '"", esc_sql( $order_status ) ) . ""') "" .
         ""AND DATE ( posts.post_date ) BETWEEN %s AND %s AND postmeta.meta_key = '_billing_country'"",
         $date_from,
         $date_to
      )
```

When implementing this, one has to do:

```
$args = $order_status;
$args[] = $date_from;
$args[] = $date_to;

$wpdb->prepare(
   ""SELECT ID AS order_id, postmeta.meta_value AS country_code FROM $wpdb->posts AS posts INNER JOIN $wpdb->postmeta AS postmeta ON posts.ID = postmeta.post_id WHERE posts.post_type = 'shop_order' "" .
   sprintf( ""AND posts.post_status IN (%s) "", implode( ',', array_fill( 0, count( $order_status ), '%s' ) ) ) .
   ""AND DATE ( posts.post_date ) BETWEEN %s AND %s AND postmeta.meta_key = '_billing_country'"",
   $args
)
```

EDIT: just to document this for people who find this on google",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/1314,Make `/` keypress focus search input,LiamKearn,10,1261020039,1,1261020039,0,0,2022-06-05T10:55:46Z,"#1313.

I feel like this may break stuff. I've done 10 minutes or so of testing, But I don't know packagist very well despite how much I use the public site and having this globally means accounting for a lot of things like this stealing focus from other inputs.

As an example: without the check for inputs as active elements this would break signing in (with a password that had a `/`).

Is there any chance that there could be abnormal keyboard inputs somewhere that don't use the input tag as they should?",True,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1164342844,Make `/` keypress focus search input,Seldaek,10,1261020039,2,1164342844,0,1261020039,2022-06-23T12:25:35Z,"Thanks, seems to work well enough!",False,0,MEMBER
https://api.github.com/repos/composer/packagist/issues/comments/1189023889,Make `/` keypress focus search input,staabm,10,1261020039,3,1189023889,0,1164342844,2022-07-19T13:00:40Z,"not sure if I get it right.. but neither on firefox nightly nor on google chrome canary I get the search field focused, when pressing `/`. thats what this PR tried to implement, right?

the javascript event handler does not get triggered (debugger does not halt)",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1189039789,Make `/` keypress focus search input,LiamKearn,10,1261020039,4,1189039789,0,1189023889,2022-07-19T13:15:13Z,"Does the listener get triggered at all? Does your browser block the JS file or this JS from executing?

Do you get any console errors?

Try run:
```js
document.addEventListener('keydown', function (e) {
	debugger;
}
```
in your console, check the document attached event listeners.

I find it hard to believe this PR wouldn't work. If anything I suspected it would too well 😬
",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1189055912,Make `/` keypress focus search input,Seldaek,10,1261020039,5,1189055912,0,1189039789,2022-07-19T13:29:23Z,"Could be a keyboard layout thing too perhaps, if you need shift or smth to get a `/`? Not sure..",False,0,MEMBER
https://api.github.com/repos/composer/packagist/issues/comments/1189080282,Make `/` keypress focus search input,stof,10,1261020039,6,1189080282,0,1189055912,2022-07-19T13:50:28Z,"I think it should use `event.key` instead of `event.code`, as `event.code` ignores keyboard layout: https://developer.mozilla.org/en-US/docs/Web/API/KeyboardEvent#properties",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1189083097,Make `/` keypress focus search input,Seldaek,10,1261020039,7,1189083097,0,1189080282,2022-07-19T13:52:56Z,"Yes right, I somehow remember double checking event.code was fine when reviewing the PR.. but I guess I misread :D ",False,0,MEMBER
https://api.github.com/repos/composer/packagist/issues/comments/1189086016,Make `/` keypress focus search input,staabm,10,1261020039,8,1189086016,0,1189083097,2022-07-19T13:55:34Z,"firefox nightly:
pressing shift+7 on the german keyboard layout opens the browser-native in-page search toolbar.
~~the keydown handler get not fired at all.~~
I can see a event object like

![grafik](https://user-images.githubusercontent.com/120441/179768379-80da3374-1d22-409a-8b59-0105faa70dc8.png)

-----

on chrome canary:
I can see the handler is getting fired, but the if(e.code) doesn't work, right.
see the event object

![grafik](https://user-images.githubusercontent.com/120441/179767903-8e737c02-d76b-4b73-bb60-ce834eabad0a.png)
",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1189089066,Make `/` keypress focus search input,Seldaek,10,1261020039,9,1189089066,0,1189086016,2022-07-19T13:58:20Z,Yes that confirms it even further. I'll get a fix out later.,False,0,MEMBER
https://api.github.com/repos/composer/packagist/issues/comments/1189157837,Make `/` keypress focus search input,Seldaek,10,1261020039,10,1189157837,0,1189089066,2022-07-19T14:55:02Z,OK fixed in dfb9671d ,False,0,MEMBER
https://api.github.com/repos/composer/packagist/issues/comments/1189472303,Make `/` keypress focus search input,staabm,10,1261020039,11,1189472303,0,1189157837,2022-07-19T19:30:31Z,"fix confirmed, thx!",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/1318,TypeError (strcasecmp) on package scan,mbrodala,6,1283347211,1,1283347211,0,0,2022-06-24T07:02:37Z,"Yesterday I pushed version [0.10.0 of t3g/file-variants](https://github.com/TYPO3GmbH/ext-file-variants/releases/tag/0.10.0).

However, this version does not show up on https://packagist.org/packages/t3g/file-variants. A manual update yields the following error:

![image](https://user-images.githubusercontent.com/5037116/175480620-ca4a1582-a3db-4dca-a98a-3d454950e271.png)

> An unexpected failure occurred [TypeError]: strcasecmp(): Argument #1 ($string1) must be of type string, int given

Currently I cannot see any error in the [Composer manifest](https://github.com/TYPO3GmbH/ext-file-variants/blob/0.10.0/composer.json), only the license gets a warning:

```
$ composer validate
./composer.json is valid, but with a few warnings
See https://getcomposer.org/doc/04-schema.md for details on the schema
# General warnings
- License ""GPL-2.0+"" is a deprecated SPDX license identifier, use ""GPL-2.0-or-later"" instead
```

Any idea what's wrong?",True,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1165303911,TypeError (strcasecmp) on package scan,glaubinix,6,1283347211,2,1165303911,0,1283347211,2022-06-24T07:50:51Z,"The problem seems to be that the composer.json file in the 0.9.0 tag contains an unexpected structure [here](https://github.com/TYPO3GmbH/ext-file-variants/blob/0.9.0/composer.json#L66). This then stops the update process and therefore 0.10.0 is never processed and failing [here](https://github.com/composer/composer/blob/main/src/Composer/Package/Loader/ValidatingArrayLoader.php#L255)

Will get this fixed in Composer.",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1165308708,TypeError (strcasecmp) on package scan,mbrodala,6,1283347211,3,1165308708,0,1165303911,2022-06-24T07:57:13Z,"Good catch, we did indeed fix that with 0.9.1:

https://github.com/TYPO3GmbH/ext-file-variants/commit/e56386262867c62a4cc243b10de0b398e809c9ef

Thanks for having a look at this!",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1165359760,TypeError (strcasecmp) on package scan,mbrodala,6,1283347211,4,1165359760,0,1165308708,2022-06-24T08:58:16Z,Thanks for the better error message. What can we do about the issue at hand? We still cannot see the new tag on Packagist ...,False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1165363483,TypeError (strcasecmp) on package scan,stof,6,1283347211,5,1165363483,0,1165359760,2022-06-24T09:02:20Z,"@mbrodala the PR has been merged in composer/composer. But now, packagist needs to be updated to use the new version and the new code needs to be deployed. Those have not been done yet (the issue got closed by github automatically when merging the PR)",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1165369509,TypeError (strcasecmp) on package scan,Seldaek,6,1283347211,6,1165369509,0,1165363483,2022-06-24T09:08:46Z,"@mbrodala ah sorry I figured if you released a fix in 0.9.1 it wasn't so urgent to fix this in prod. But now I see this is <0.10 so I guess you're still waiting :)

I'll get this deployed soon.",False,0,MEMBER
https://api.github.com/repos/composer/packagist/issues/comments/1165374468,TypeError (strcasecmp) on package scan,mbrodala,6,1283347211,7,1165374468,0,1165369509,2022-06-24T09:14:26Z,"Thanks for the clarification, both of you!",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/1320,[RFC] displaying latest version in search engine view result,94noni,9,1320838818,1,1320838818,0,0,2022-07-28T12:10:44Z,"Hi

I would like to know if it can be useful to display such info on http://packagist.org/ website

here is an example:
<img width=""882"" alt=""Capture d’écran 2022-07-28 à 14 08 27"" src=""https://user-images.githubusercontent.com/1358361/181501501-35ccd14a-a2dd-4d1d-8869-2e7e5495d8e1.png"">

---

We can imagine storing such data in the package when a new version is added to it
And index such data when indexing all data for the search engine",True,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1200146654,[RFC] displaying latest version in search engine view result,Seldaek,9,1320838818,2,1200146654,0,1320838818,2022-07-30T12:11:19Z,What's the value of knowing the last version in a listing though? ,False,0,MEMBER
https://api.github.com/repos/composer/packagist/issues/comments/1237744381,[RFC] displaying latest version in search engine view result,IonBazan,9,1320838818,3,1237744381,0,1200146654,2022-09-06T07:09:21Z,"I think npm provides similar feature:
![image](https://user-images.githubusercontent.com/1985514/188569159-84e11a19-f6ca-4de7-ad2b-00eb9df3164f.png)
![image](https://user-images.githubusercontent.com/1985514/188569204-17f9b934-aae7-4130-839d-0f11aaf5a154.png)

Not sure if it provides much value here but I think the last publish date would be helpful here to decide which package is still actively maintained without going to the details page.",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1237765458,[RFC] displaying latest version in search engine view result,94noni,9,1320838818,4,1237765458,0,1237744381,2022-09-06T07:30:57Z,"@Seldaek @IonBazan thx for stopping here

> What's the value of knowing the last version in a listing though?

mostly yes to know how a package evolve, some projects has little deps tho knowing a packages have new versions is good
also yes with the date, both could be good (mimic the npm page)

it was just an idea I got this summer tho wanted to write it down, if you think it is not that relevant, could be closed for now, thanks",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1245886177,[RFC] displaying latest version in search engine view result,chr-hertel,9,1320838818,5,1245886177,0,1237765458,2022-09-13T19:51:50Z,"I would argue that the search results should give info that helps a developer to choose if a package is worth investigating or not - the detail view will be used anyways btw.
I can see how stars and downloads help with that, but i don't think the version number is really relevant.
the only thing i can see is that it would be worth providing an info about stability of a package, like is there a stable version or not for example",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1246919397,[RFC] displaying latest version in search engine view result,Seldaek,9,1320838818,6,1246919397,0,1245886177,2022-09-14T15:13:31Z,"I can see some value in the last release date to see if something's been ""dead"" for years, although in some cases I'd argue stuff is just stable and working and doesn't need work and thus it's fine. For example https://packagist.org/packages/seld/cli-prompt is almost 2y stale and before that it was almost 3y.. yet it ""just works"".

So even the date needs to be taken with a grain of salt, and newer isn't necessarily better.

The version is even less ""comparable"" between packages IMO, so why show it in a list? 

Overall not so convinced that more info is more value.",False,0,MEMBER
https://api.github.com/repos/composer/packagist/issues/comments/1246960729,[RFC] displaying latest version in search engine view result,chr-hertel,9,1320838818,7,1246960729,0,1246919397,2022-09-14T15:43:26Z,"True and more important for me while evaluation is the list and versions of dependencies, but that's definetly off scope for a list of results.

Filtering for compatibility with specific PHP versions would be interesting though",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1247015074,[RFC] displaying latest version in search engine view result,94noni,9,1320838818,8,1247015074,0,1246960729,2022-09-14T16:26:04Z,"@Seldaek @chr-hertel fair enough, thx for taking time to comment

then we can consider closing? if it does not add much value for majority ppl

or you want to keep open to discus what can be added (not the latest version) but others data

",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1247196303,[RFC] displaying latest version in search engine view result,Seldaek,9,1320838818,9,1247196303,0,1247015074,2022-09-14T19:14:49Z,Yeah I think I'd rather close then. We can always revisit later if there are more compelling arguments,False,0,MEMBER
https://api.github.com/repos/composer/packagist/issues/comments/1962312927,[RFC] displaying latest version in search engine view result,94noni,9,1320838818,10,1962312927,0,1247196303,2024-02-24T09:44:14Z,"PR as discussion draft opened here https://github.com/composer/packagist/pull/1410
Feel free to comment :)",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/1324,Add Gitea webhook for Packagist,toddy15,4,1338249145,1,1338249145,0,0,2022-08-14T13:37:11Z,"Hi,

Gitea recently added support for a Packagist webhook, enabling automatic updates for packages. I've added a section about how to enable it.

Regards,
Tobias
",True,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1218054612,Add Gitea webhook for Packagist,Seldaek,4,1338249145,2,1218054612,0,1338249145,2022-08-17T14:03:27Z,Thanks - I do wonder why they need the packagist.org package URL tho - as what we need to receive in the payload is the canonical repository URL (the gitea one),False,0,MEMBER
https://api.github.com/repos/composer/packagist/issues/comments/1218446369,Add Gitea webhook for Packagist,toddy15,4,1338249145,3,1218446369,0,1218054612,2022-08-17T20:12:02Z,"@Seldaek Thanks for merging -- I thought the payload needs the packagist URL? At least that's how I understood the section about the manual hook setup.

I did create the PR with support for packagist in Gitea, so I'm wondering if it could be simplified. :-)",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1218485477,Add Gitea webhook for Packagist,Seldaek,4,1338249145,4,1218485477,0,1218446369,2022-08-17T21:00:05Z,"Ah yeah sorry I mis-remembered this :) I believe both URLs are supported, either canonical git repo URL or packagist one, but best would be to try it out to ensure that the response you get is positive (HTTP 202) if you use the gitea repo URL. That'd make the setup slightly easier, and has the benefit of updating multiple packages at once if the same git repo gets submitted with different names over time.",False,0,MEMBER
https://api.github.com/repos/composer/packagist/issues/comments/1219905320,Add Gitea webhook for Packagist,toddy15,4,1338249145,5,1219905320,0,1218485477,2022-08-18T20:03:55Z,"@Seldaek Just FYI: I've tested with the canonical ""upstream"" git URL and with the packagist URL. Both work fine, so I guess the implementation in Gitea could be simplified. Thanks for your input.",False,0,CONTRIBUTOR
https://api.github.com/repos/truecharts/charts/issues/2272,fix(common): Add mariadbImage to values.yaml,stavros-k,3,1180049504,1,1180049504,0,0,2022-03-24T20:59:10Z,"**Description**
<!--
Please include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.
-->
⚒️ Fixes  # <!--(issue)-->

**⚙️ Type of change**

- [ ] ⚙️ Feature/App addition
- [x] 🪛 Bugfix
- [ ] ⚠️ Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] 🔃 Refactor of current code

**🧪 How Has This Been Tested?**
<!--
Please describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration
-->

**📃 Notes:**
<!-- Please enter any other relevant information here -->

**✔️ Checklist:**

- [x] ⚖️ My code follows the style guidelines of this project
- [x] 👀 I have performed a self-review of my own code
- [ ] #️⃣ I have commented my code, particularly in hard-to-understand areas
- [ ] 📄 I have made corresponding changes to the documentation
- [x] ⚠️ My changes generate no new warnings
- [ ] 🧪 I have added tests to this description that prove my fix is effective or that my feature works
- [x] ⬆️ I increased versions for any altered app according to semantic versioning
",True,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1078283701,fix(common): Add mariadbImage to values.yaml,stavros-k,3,1180049504,2,1078283701,0,1180049504,2022-03-24T20:59:24Z,@Ornias1993  Can you verify please...,False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1078418384,fix(common): Add mariadbImage to values.yaml,stavros-k,3,1180049504,3,1078418384,0,1078283701,2022-03-24T21:51:43Z,"Merging, as it shouldn't do any harm",False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1552243681,fix(common): Add mariadbImage to values.yaml,truecharts-admin,3,1180049504,4,1552243681,0,1078418384,2023-05-18T00:20:57Z,This PR is locked to prevent necro-posting on closed PRs. Please create a issue or contact staff on discord if you want to further discuss this,False,0,COLLABORATOR
https://api.github.com/repos/truecharts/charts/issues/2273,Cannot disable http to https redirects,Nohac,3,1180065959,1,1180065959,0,0,2022-03-24T21:19:55Z,"### App Name

traefik

### SCALE Version

22.02.0

### App Version

2.6.1_11.0.2

### Application Events

```Shell
.
```


### Application Logs

```Shell
.
```


### Application Configuration

.

### Describe the bug

Currently, all apps seems to be redirected from http to https, this is probably fine for most use cases, however, I'm only going to access apps on LAN or through VPN, so I'm not going to bother getting a certificate etc.

I've tried to change a few settings on the apps themselves, like changing the `(Advanced) Traefik Entrypoint *` to `web` instead of `websecure`, this doesn't work.

There seems to be a setting for traefik under `web Entrypoint Configuration > Show Advanced settings > Redirect to Entrypoin` which is set to `websecure`. However, when I try to remove it, I get a configuration error message when I hit save that only says: `Error: 'nodePort'`.

### To Reproduce

1. Open traefik settings
2. Goto `web Entrypoint Configuration > Show Advanced settings` 
3. Set `Redirect to Entrypoin` to blank
4. Hit save

### Expected Behavior

It should be possible to save the settings changes and redirects from http to https should stop.

### Screenshots

.

### Additional Context

Semirelated issue: https://github.com/truecharts/apps/issues/1939

### I've read and agree with the following

- [X] I've checked all open and closed issues and my issue is not there.",True,0,NONE
https://api.github.com/repos/truecharts/charts/issues/comments/1079894835,Cannot disable http to https redirects,Ornias1993,3,1180065959,2,1079894835,0,1180065959,2022-03-27T09:53:28Z,"We do not actively support http ingress. There is no sane or reasonable reason not to use https in 2022.
Hence this is not a bug.

Even so, we did add a feature to disable our default middlewares that also enforce the redirect. Which has een discussed here before.

Just don't expect any help from us anymore after using that.",False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1079925414,Cannot disable http to https redirects,Nohac,3,1180065959,3,1079925414,0,1079894835,2022-03-27T12:53:03Z,"@Ornias1993 I just gave you a reason and a use case I believe is completely sane, even in 2022 and beyond.
I also tried to disable default middlewares, but that option did seemingly nothing, unfortunately.",False,0,NONE
https://api.github.com/repos/truecharts/charts/issues/comments/1415932359,Cannot disable http to https redirects,truecharts-admin,3,1180065959,4,1415932359,0,1079925414,2023-02-03T14:17:16Z,This issue is locked to prevent necro-posting on closed issues. Please create a new issue or contact staff on discord of the problem persists,False,0,COLLABORATOR
https://api.github.com/repos/truecharts/charts/issues/2275,"fix(common): try to fix ""did not find expected ""-"" indicator",stavros-k,5,1180130058,1,1180130058,0,0,2022-03-24T22:44:53Z,"**Description**
<!--
Please include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.
-->
⚒️ Fixes  # <!--(issue)-->

**⚙️ Type of change**

- [ ] ⚙️ Feature/App addition
- [ ] 🪛 Bugfix
- [ ] ⚠️ Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] 🔃 Refactor of current code

**🧪 How Has This Been Tested?**
<!--
Please describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration
-->

**📃 Notes:**
<!-- Please enter any other relevant information here -->
Tries to fix 
https://github.com/truecharts/apps/runs/5684098791?check_suite_focus=true#step:9:39

**✔️ Checklist:**

- [x] ⚖️ My code follows the style guidelines of this project
- [x] 👀 I have performed a self-review of my own code
- [ ] #️⃣ I have commented my code, particularly in hard-to-understand areas
- [ ] 📄 I have made corresponding changes to the documentation
- [x] ⚠️ My changes generate no new warnings
- [ ] 🧪 I have added tests to this description that prove my fix is effective or that my feature works
- [x] ⬆️ I increased versions for any altered app according to semantic versioning
",True,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1078822176,"fix(common): try to fix ""did not find expected ""-"" indicator",Ornias1993,5,1180130058,2,1078822176,0,1180130058,2022-03-25T09:28:17Z,"Indent is not going to fix this.
Use helm template and helm lint to manually go over rendered output...

Also: common versions in both the App and dependency **have to be** in sync",False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1079004483,"fix(common): try to fix ""did not find expected ""-"" indicator",stavros-k,5,1180130058,3,1079004483,0,1078822176,2022-03-25T12:59:39Z,"Turns out it was something bad with `command`
Splitted it into `command` and `args` to make it more  readable as well.
`helm template` passes locally",False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1079021338,"fix(common): try to fix ""did not find expected ""-"" indicator",stavros-k,5,1180130058,4,1079021338,0,1079004483,2022-03-25T13:20:06Z,"Just for the record. While doing `helm template`, I see this warning
`coalesce.go:175: warning: skipped value for redis.env: Not a table.`
Not sure if it's important, but I can't really pinpoint it",False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1079422987,"fix(common): try to fix ""did not find expected ""-"" indicator",Ornias1993,5,1180130058,5,1079422987,0,1079021338,2022-03-25T20:48:07Z,Feel free to test again :),False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1552243610,"fix(common): try to fix ""did not find expected ""-"" indicator",truecharts-admin,5,1180130058,6,1552243610,0,1079422987,2023-05-18T00:20:49Z,This PR is locked to prevent necro-posting on closed PRs. Please create a issue or contact staff on discord if you want to further discuss this,False,0,COLLABORATOR
https://api.github.com/repos/truecharts/charts/issues/2278,Unmanic unable to scan library.,git4unrealnondev,3,1180248220,1,1180248220,0,0,2022-03-25T01:46:27Z,"### App Name

Unmanic

### SCALE Version

22.02.0

### App Version

0.2.0_2.0.3

### Application Events

```Shell
2022-03-24 20:32:14
Started container unmanic
2022-03-24 20:32:13
Created container unmanic
2022-03-24 20:32:07
Container image ""tccr.io/truecharts/unmanic:v0.2.0@sha256:8803a54504f699d45197b51866e9bdbb1f7bd543e0183aa8c055bfb3dacef04f"" already present on machine
2022-03-24 20:32:06
Started container hostpatch
2022-03-24 20:32:04
Created container hostpatch
2022-03-24 20:31:58
Container image ""ghcr.io/truecharts/alpine:v3.14.2@sha256:4095394abbae907e94b1f2fd2e2de6c4f201a5b9704573243ca8eb16db8cdb7c"" already present on machine
2022-03-24 20:31:56
Started container autopermissions
2022-03-24 20:31:56
Created container autopermissions
2022-03-24 20:31:49
Container image ""ghcr.io/truecharts/alpine:v3.14.2@sha256:4095394abbae907e94b1f2fd2e2de6c4f201a5b9704573243ca8eb16db8cdb7c"" already present on machine
2022-03-24 20:31:49
Add eth0 [172.16.0.162/16] from ix-net
Successfully assigned ix-unmanic/unmanic-755d7d574d-79bws to ix-truenas
2022-03-24 20:31:37
Created pod: unmanic-755d7d574d-79bws
2022-03-24 20:31:37
Scaled up replica set unmanic-755d7d574d to 1
2022-03-24 20:31:30
Liveness probe failed: dial tcp 172.16.0.161:8888: connect: connection refused
2022-03-24 20:31:30
Readiness probe failed: dial tcp 172.16.0.161:8888: connect: connection refused
2022-03-24 20:31:24
Stopping container unmanic
2022-03-24 20:31:24
Deleted pod: unmanic-57968596-vmq88
2022-03-24 20:31:24
Scaled down replica set unmanic-57968596 to 0
2022-03-24 20:07:35
Started container unmanic
2022-03-24 20:07:35
Created container unmanic
2022-03-24 20:07:23
Container image ""tccr.io/truecharts/unmanic:v0.2.0@sha256:8803a54504f699d45197b51866e9bdbb1f7bd543e0183aa8c055bfb3dacef04f"" already present on machine
2022-03-24 20:07:21
Started container hostpatch
2022-03-24 20:07:20
Created container hostpatch
2022-03-24 20:07:07
Container image ""ghcr.io/truecharts/alpine:v3.14.2@sha256:4095394abbae907e94b1f2fd2e2de6c4f201a5b9704573243ca8eb16db8cdb7c"" already present on machine
2022-03-24 20:07:05
Started container autopermissions
2022-03-24 20:07:05
Created container autopermissions
2022-03-24 20:06:53
Container image ""ghcr.io/truecharts/alpine:v3.14.2@sha256:4095394abbae907e94b1f2fd2e2de6c4f201a5b9704573243ca8eb16db8cdb7c"" already present on machine
2022-03-24 20:06:53
Add eth0 [172.16.0.161/16] from ix-net
Successfully assigned ix-unmanic/unmanic-57968596-vmq88 to ix-truenas
2022-03-24 20:06:40
Created pod: unmanic-57968596-vmq88
2022-03-24 20:06:40
Scaled up replica set unmanic-57968596 to 1
2022-03-24 20:06:32
Error: failed to start container ""unmanic"": Error response from daemon: cannot join network of a non running container: cb9158cb96f46bb2349a7482e23a1fada190d53d556963c83cd56f0f18737fb7
2022-03-24 20:06:31
Created container unmanic
2022-03-24 20:06:19
Container image ""tccr.io/truecharts/unmanic:v0.2.0@sha256:8803a54504f699d45197b51866e9bdbb1f7bd543e0183aa8c055bfb3dacef04f"" already present on machine
2022-03-24 20:06:19
Deleted pod: unmanic-64dd9c68fd-b7l54
2022-03-24 20:06:19
Scaled down replica set unmanic-64dd9c68fd to 0
2022-03-24 20:06:18
Started container hostpatch
2022-03-24 20:06:16
Created container hostpatch
2022-03-24 20:06:05
Container image ""ghcr.io/truecharts/alpine:v3.14.2@sha256:4095394abbae907e94b1f2fd2e2de6c4f201a5b9704573243ca8eb16db8cdb7c"" already present on machine
2022-03-24 20:06:04
Started container autopermissions
2022-03-24 20:06:02
Created container autopermissions
2022-03-24 20:05:50
Container image ""ghcr.io/truecharts/alpine:v3.14.2@sha256:4095394abbae907e94b1f2fd2e2de6c4f201a5b9704573243ca8eb16db8cdb7c"" already present on machine
2022-03-24 20:05:50
Add eth0 [172.16.0.160/16] from ix-net
2022-03-24 20:05:35
Created pod: unmanic-64dd9c68fd-b7l54
Successfully assigned ix-unmanic/unmanic-64dd9c68fd-b7l54 to ix-truenas
2022-03-24 20:05:35
Scaled up replica set unmanic-64dd9c68fd to 1
2022-03-24 20:05:29
Liveness probe failed: dial tcp 172.16.0.159:8888: connect: connection refused
2022-03-24 20:05:29
Readiness probe failed: dial tcp 172.16.0.159:8888: connect: connection refused
2022-03-24 20:05:24
Stopping container unmanic
2022-03-24 20:05:24
Deleted pod: unmanic-678468fdd9-qkmw7
2022-03-24 20:05:24
Scaled down replica set unmanic-678468fdd9 to 0
2022-03-24 19:59:13
Started container unmanic
2022-03-24 19:59:13
Created container unmanic
2022-03-24 19:59:04
Successfully pulled image ""tccr.io/truecharts/unmanic:v0.2.0@sha256:8803a54504f699d45197b51866e9bdbb1f7bd543e0183aa8c055bfb3dacef04f"" in 6m11.709430858s
2022-03-24 19:52:53
Pulling image ""tccr.io/truecharts/unmanic:v0.2.0@sha256:8803a54504f699d45197b51866e9bdbb1f7bd543e0183aa8c055bfb3dacef04f""
2022-03-24 19:52:52
Started container hostpatch
2022-03-24 19:52:50
Created container hostpatch
2022-03-24 19:52:43
Container image ""ghcr.io/truecharts/alpine:v3.14.2@sha256:4095394abbae907e94b1f2fd2e2de6c4f201a5b9704573243ca8eb16db8cdb7c"" already present on machine
2022-03-24 19:52:41
Started container autopermissions
2022-03-24 19:52:41
Created container autopermissions
2022-03-24 19:52:34
Container image ""ghcr.io/truecharts/alpine:v3.14.2@sha256:4095394abbae907e94b1f2fd2e2de6c4f201a5b9704573243ca8eb16db8cdb7c"" already present on machine
2022-03-24 19:52:34
Started container lb-port-10157
2022-03-24 19:52:33
Add eth0 [172.16.0.159/16] from ix-net
2022-03-24 19:52:33
Created container lb-port-10157
2022-03-24 19:52:21
Container image ""rancher/klipper-lb:v0.1.2"" already present on machine
2022-03-24 19:52:20
Add eth0 [172.16.0.158/16] from ix-net
Successfully assigned ix-unmanic/unmanic-678468fdd9-qkmw7 to ix-truenas
2022-03-24 19:52:14
Successfully provisioned volume pvc-2844e19f-bea3-40bb-8b9b-55571889fdc4
2022-03-24 19:52:14
Successfully provisioned volume pvc-236ff968-4690-4d2c-95dd-c39aa518e117
0/1 nodes are available: 1 pod has unbound immediate PersistentVolumeClaims.
2022-03-24 19:52:11
waiting for a volume to be created, either by external provisioner ""zfs.csi.openebs.io"" or manually created by system administrator
2022-03-24 19:52:11
waiting for a volume to be created, either by external provisioner ""zfs.csi.openebs.io"" or manually created by system administrator
Successfully assigned ix-unmanic/svclb-unmanic-zpn6s to ix-truenas
2022-03-24 19:52:11
External provisioner is provisioning volume for claim ""ix-unmanic/unmanic-config""
2022-03-24 19:52:11
External provisioner is provisioning volume for claim ""ix-unmanic/unmanic-remote""
0/1 nodes are available: 1 pod has unbound immediate PersistentVolumeClaims.
2022-03-24 19:52:11
Created pod: svclb-unmanic-zpn6s
2022-03-24 19:52:11
Created pod: unmanic-678468fdd9-qkmw7
```


### Application Logs

```Shell
2022-03-25T01:32:14.488700306Z [s6-init] making user provided files available at /var/run/s6/etc...exited 0.
2022-03-25T01:32:14.550947569Z [s6-init] ensuring user provided files have correct perms...exited 0.
2022-03-25T01:32:14.552940344Z [fix-attrs.d] applying ownership & permissions fixes...
2022-03-25T01:32:14.554105585Z [fix-attrs.d] done.
2022-03-25T01:32:14.555239503Z [cont-init.d] executing container initialization scripts...
2022-03-25T01:32:14.557410900Z [cont-init.d] 01-envfile: executing... 
2022-03-25T01:32:14.567260697Z [cont-init.d] 01-envfile: exited 0.
2022-03-25T01:32:14.569197996Z [cont-init.d] 01-migrations: executing... 
2022-03-25T01:32:14.571155506Z [migrations] started
2022-03-25T01:32:14.571214259Z [migrations] no migrations found
2022-03-25T01:32:14.571954564Z [cont-init.d] 01-migrations: exited 0.
2022-03-25T01:32:14.574068656Z [cont-init.d] 02-tamper-check: executing... 
2022-03-25T01:32:14.599236690Z [cont-init.d] 02-tamper-check: exited 0.
2022-03-25T01:32:14.601260199Z [cont-init.d] 10-adduser: executing... 
2022-03-25T01:32:15.331534197Z 
2022-03-25T01:32:15.331606503Z -------------------------------------
2022-03-25T01:32:15.331625446Z           _         ()
2022-03-25T01:32:15.331641146Z          | |  ___   _    __
2022-03-25T01:32:15.331656430Z          | | / __| | |  /  \
2022-03-25T01:32:15.331689386Z          | | \__ \ | | | () |
2022-03-25T01:32:15.331707129Z          |_| |___/ |_|  \__/
2022-03-25T01:32:15.331722773Z 
2022-03-25T01:32:15.331738042Z 
2022-03-25T01:32:15.331753417Z Brought to you by linuxserver.io
2022-03-25T01:32:15.331768535Z -------------------------------------
2022-03-25T01:32:15.331792900Z 
2022-03-25T01:32:15.331809401Z To support LSIO projects visit:
2022-03-25T01:32:15.331824843Z https://www.linuxserver.io/donate/
2022-03-25T01:32:15.331840127Z -------------------------------------
2022-03-25T01:32:15.331855308Z GID/UID
2022-03-25T01:32:15.331878678Z -------------------------------------
2022-03-25T01:32:15.336971391Z 
2022-03-25T01:32:15.337008882Z User uid:    1000
2022-03-25T01:32:15.337026141Z User gid:    1000
2022-03-25T01:32:15.337041600Z -------------------------------------
2022-03-25T01:32:15.337057130Z 
2022-03-25T01:32:15.345449385Z [cont-init.d] 10-adduser: exited 0.
2022-03-25T01:32:15.346730135Z [cont-init.d] 20-config: executing... 
2022-03-25T01:32:15.351750674Z **** (permissions_config) Setting run user uid=1000(abc) gid=1000(abc)  ****
2022-03-25T01:32:15.368053077Z usermod: no changes
2022-03-25T01:32:15.368101768Z **** (permissions_config) Setting permissions ****
2022-03-25T01:32:15.373219769Z **** (permissions_config) Adding run user to video group ****
2022-03-25T01:32:15.375783856Z [cont-init.d] 20-config: exited 0.
2022-03-25T01:32:15.377252635Z [cont-init.d] 30-patch-nvidia: executing... 
2022-03-25T01:32:15.382591993Z [cont-init.d] 30-patch-nvidia: exited 0.
2022-03-25T01:32:15.383599100Z [cont-init.d] 60-custom-setup-script: executing... 
2022-03-25T01:32:15.389166706Z [cont-init.d] 60-custom-setup-script: exited 0.
2022-03-25T01:32:15.390572346Z [cont-init.d] 90-custom-folders: executing... 
2022-03-25T01:32:15.397991782Z [cont-init.d] 90-custom-folders: exited 0.
2022-03-25T01:32:15.399251957Z [cont-init.d] 99-custom-scripts: executing... 
2022-03-25T01:32:15.410475379Z [custom-init] no custom files found exiting...
2022-03-25T01:32:15.410766419Z [cont-init.d] 99-custom-scripts: exited 0.
2022-03-25T01:32:15.411491991Z [cont-init.d] done.
2022-03-25T01:32:15.412487270Z [services.d] starting services
2022-03-25T01:32:15.419504375Z [services.d] done.
2022-03-25T01:32:16.030981305Z 2022-03-24T20:32:16:INFO:Unmanic.UnmanicLogger - Debug logging disabled
2022-03-25T01:32:16.031039440Z 2022-03-24T20:32:16:INFO:Unmanic.UnmanicLogger - Initialising file logger. All further logs should output to the 'unmanic.log' file
```


### Application Configuration

![Screenshot_20220324_204357](https://user-images.githubusercontent.com/30579641/160037731-4ab73549-b47d-4ca0-b79a-b9d812000569.png)
![Screenshot_20220324_204352](https://user-images.githubusercontent.com/30579641/160037732-4e4f0ee3-cac7-4b9d-b956-c79c7d848a82.png)
![Screenshot_20220324_204343](https://user-images.githubusercontent.com/30579641/160037735-a9b8e99b-258b-4663-8c09-84e8e751cc18.png)
![Screenshot_20220324_204337](https://user-images.githubusercontent.com/30579641/160037736-65d085e8-0c29-441e-b02c-9b0d18d75d3e.png)
![Screenshot_20220324_204327](https://user-images.githubusercontent.com/30579641/160037737-9bdab290-7246-423d-b0de-79f5a36cbea6.png)
![Screenshot_20220324_204320](https://user-images.githubusercontent.com/30579641/160037740-7552365a-b327-4620-96c7-abe3f8200b79.png)


### Describe the bug

Currently unmanic is unable to scan files inside of the /library.
I have confirmed that unmanic can see the files and is being owned by abc. EX:
drwxr-xr-x  3 abc abc  6 Mar 17 23:10 FILENAME
id
uid=0(root) gid=0(root) groups=0(root),568,1000(abc)

Additionally the remote link functionality does not work.

### To Reproduce

Add library folder as hostpath to the application library section.
Start unmanic.
Click on scan library.
Nothing happens

For the remote link.
Go to settings -> link -> add remote link.
Add the remote device.
remote device workers do not show in main tab.

### Expected Behavior

Unmanic should get a list of files for it to check.


For the remote link.
Unmanic should show idle remote worker tabs in main window.

### Screenshots

![Uploading Screenshot_20220324_204725.png…]()


### Additional Context

I know i should make separate issues but im lazy, sorry.
The /library folder shows folders and files as it should but unmanic doesn't scan them.

### I've read and agree with the following

- [X] I've checked all open and closed issues and my issue is not there.",True,0,NONE
https://api.github.com/repos/truecharts/charts/issues/comments/1079035415,Unmanic unable to scan library.,stavros-k,3,1180248220,2,1079035415,0,1180248220,2022-03-25T13:35:54Z,"If the files are owned by the correct user `1000` (`abc` ), and unmanic can see the files. It's most likely an unmanic's problem.
Keep in mind that unmanic did a major update some days ago, adding a ton of features and a big refactor of it's code base.

With that said, check you configured it to scan the files. either manual or automatically.

Anyway it's on my todo list to check that the app is ok after this major update.
But it's on the lower end of my priority
",False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1079118103,Unmanic unable to scan library.,stavros-k,3,1180248220,3,1079118103,0,1079035415,2022-03-25T15:03:51Z,"Also, if remote machine is added, means it's connected. If the workers does not show up. It's again an unmanic's problem

Just tried the app, my library scanned fine. Our side is working as it should. 

If there is a proven **bug** on our side, please re-open a ticket.
If you need help setting the app itself use discord channel #software-general",False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1415932522,Unmanic unable to scan library.,truecharts-admin,3,1180248220,4,1415932522,0,1079118103,2023-02-03T14:17:25Z,This issue is locked to prevent necro-posting on closed issues. Please create a new issue or contact staff on discord of the problem persists,False,0,COLLABORATOR
https://api.github.com/repos/helium/HIP/issues/374,HIP45 Amendments,lthiery,4,1165403044,1,1165403044,0,0,2022-03-10T15:53:34Z,This is a draft PR for discussions on fleshing out details of HIP45.,True,0,MEMBER
https://api.github.com/repos/helium/HIP/issues/comments/1064722888,HIP45 Amendments,buzzware,4,1165403044,2,1064722888,0,1165403044,2022-03-11T02:58:29Z,"Some quick ideas 

1) Define a standard for community hotspot votes :
• if regional, only hotspots in the region or wallets with hotspots in the region count
• 1 vote per hotspot, but maximum 100 votes per wallet
• only hotspots and wallets created at least 4 weeks before the committee recommendation or HIP creation count 
2) define a standard for quasi ""unanimous"". Unanimous outcomes can be used to exit the process and save everybody time, effort and angst eg.
• more than 20 wallets voted
• more than 20 hotspot votes
• the vote is >=90% one way or the other
3) define a standard for lack of interest in an open community vote eg.
  • less than 10 wallets voting
4) After committee recommendation, at least 7 days notice for a town Hall meeting between 7am and 9pm in the affected region's average timezone.
5) At the end of the town Hall meeting, a hotspot vote  is taken in the region. 
6) If near unanimous then the process ends with that outcome , but the author is free to make changes deemed significant enough and resubmit for 1 more vote in 7 days time.
7) If not unanimous and enough interest, then the 4 week discussion period begins.
8) Formal dissent comments must begin with ""Formal Dissent"" to be counted.
",False,0,NONE
https://api.github.com/repos/helium/HIP/issues/comments/1064732622,HIP45 Amendments,lthiery,4,1165403044,3,1064732622,0,1064722888,2022-03-11T03:18:50Z,"@buzzware I've invited you to be a collaborator on this fork. If you have the time to edit the PR itself with your ideas that'd help things move as fast as possible. You've done a great job here providing some initial suggestions of some ""magical numbers"" and I realize how much work that takes. However, it'll be easier to work on things if you actually draft it into the HIP format.",False,0,MEMBER
https://api.github.com/repos/helium/HIP/issues/comments/1069188524,HIP45 Amendments,buzzware,4,1165403044,4,1069188524,0,1064732622,2022-03-16T14:26:08Z,"> @buzzware I've invited you to be a collaborator on this fork. If you have the time to edit the PR itself with your ideas that'd help things move as fast as possible. 

@lthiery 
I don't have time sorry. If I have any ideas I'll drop them in here like above.",False,0,NONE
https://api.github.com/repos/helium/HIP/issues/comments/1145344779,HIP45 Amendments,jamiew,4,1165403044,5,1145344779,0,1069188524,2022-06-02T21:10:40Z,Marking this one stale; if I don't hear of any updates I'll close to help keep the repository moving. Please note it can be re-opened at any time. Thanks!,False,0,CONTRIBUTOR
https://api.github.com/repos/helium/HIP/issues/376,HIP 57: PoC Rewards Establishment Period,edakturk14,6,1173445086,1,1173445086,0,0,2022-03-18T10:43:28Z,"# HIP 57: PoC Rewards Establishment Period

- Author(s): [@Scottsigel](https://github.com/Scottsigel), [@starwatcher](https://github.com/mrpatrick1991), [@jthiller](https://github.com/jthiller)
- Start Date: 2022-03-16
- Category: Technical
- Original HIP PR: https://github.com/helium/HIP/pull/375
- Tracking Issue: https://github.com/helium/HIP/issues/376 (this)
- Status: In Discussion

# Summary
[summary]: #summary

In order to combat PoC rewards gaming, the process of ‘spoofing’ or ‘gaming’ a Hotspot to earn disproportionate rewards must be economically unsound. Among a range of solutions, the existing denylist and HIP-40 offer a means to remove Hotspots that don’t provide legitimate coverage. However, there is sufficient time after onboarding a Hotspot where it remains economically viable to spoof a location and game PoC rewards before a Hotspot in question can be confidently identified and added to a denylist.

If approved, this proposal would introduce a Hotspot ‘establishment period’ such that the network can better learn about a Hotspot’s deployment immediately following a location assertion. This period would be defined initially as 15 days and 10 successful witnesses, as set by a chain variable. A Hotspot’s PoC rewards and witnesses of its beacons would be throttled to 10% of what would be its normal earnings until both of these conditions are met. Data rewards would be unaffected. As the network improves its ability to understand a Hotspot’s location or as reliance on denylists are reduced, these chain variables could be adjusted. 

# Rendered View

https://github.com/helium/HIP/blob/main/0057-poc-rewards-establishment-period.md
",True,0,CONTRIBUTOR
https://api.github.com/repos/helium/HIP/issues/comments/1079646667,HIP 57: PoC Rewards Establishment Period,mkultr44,6,1173445086,2,1079646667,0,1173445086,2022-03-26T09:15:13Z,"For people with really good locations and coverage, the very things you want to incentivise, that would increase the ROI by about 50% though......",False,0,NONE
https://api.github.com/repos/helium/HIP/issues/comments/1086941761,HIP 57: PoC Rewards Establishment Period,alphaqt,6,1173445086,3,1086941761,0,1079646667,2022-04-03T20:20:33Z,"This seems like a bandaid.  The real problem is that there is no method currently to actually validate the location of a Hotspot.  The companies that manufacture Helium Miners should start including a GPS receiver to accurately record a hotspots true location to keep people from asserting a location different than the physical hotspot.  Once there are enough hotspots with GPS coordinates, the remaining hotspots could be easily located via triangulation of the beacons.  We need to move away from bandaids and towards solutions that elevate the Miner network to one that is impervious to scamming.",False,0,NONE
https://api.github.com/repos/helium/HIP/issues/comments/1088233164,HIP 57: PoC Rewards Establishment Period,mkultr44,6,1173445086,4,1088233164,0,1086941761,2022-04-05T03:36:24Z,"you can spoof gps too, wouldn't change anything",False,0,NONE
https://api.github.com/repos/helium/HIP/issues/comments/1088283224,HIP 57: PoC Rewards Establishment Period,wolfenhawke,6,1173445086,5,1088283224,0,1088233164,2022-04-05T05:28:03Z,"I think the way to increase the reliability of this is to use time. With time we know which hotspots are not on a deny list, are true, and even what their average behavior is like. When a new miner comes online, a time and witness window can be used _along with this historic information_ to validate what is being seen. 
Someone being honest for 15 days then being dishonest? The algorithm can see when the change occurs that the new witness pattern is an anomaly. Someone self witnessing with a bunch in the basement? History wouldn't have the bunch in the basement. 
Then the gaming is looking for those nests where maybe a spoofer was able to get many in the network and looking like normal -- but even then, it will show up because once legitimate units reach the area suddenly a whole nest is not being witnessed like they should be.
Time as in average of continuous operation is like integrating over a long period - it provides an interesting additional dimension of information. ",False,0,NONE
https://api.github.com/repos/helium/HIP/issues/comments/1236202179,HIP 57: PoC Rewards Establishment Period,HansaFL,6,1173445086,6,1236202179,0,1088283224,2022-09-03T21:39:26Z,"This is a good idea, but it needs ""teeth"". Proper validation using other methods will be needed to prove Hotspot locations.",False,0,NONE
https://api.github.com/repos/helium/HIP/issues/comments/1320316413,HIP 57: PoC Rewards Establishment Period,vincenzospaghetti,6,1173445086,7,1320316413,0,1236202179,2022-11-18T17:26:00Z,"This HIP has been stale for some time. We are moving to close it, as there as been no more discussion in the community Discord. If you would like to reopen this HIP, please submit a new PR with changes. Thanks for your contribution to the Helium Community! ",False,0,CONTRIBUTOR
https://api.github.com/repos/helium/HIP/issues/378,HIP draft - LoRaWAN Committee Terms of Reference,vudutech,22,1176322857,1,1176322857,0,0,2022-03-22T06:25:41Z,"# LoRaWAN Committee

- Author(s): [@leogaggl](https://github.com/leogaggl), [@tonysmith55](https://github.com/tonysmith55), [@buzzware](https://github.com/buzzware), [@jamesmeikle](https://github.com/jamesmeikle)
- Start Date: 2022-03-09
- Category: governance
- Original HIP PR: <!-- leave this empty; maintainer will fill in ID of this pull request -->
- Tracking Issue: <!-- leave this empty; maintainer will create a discussion issue -->

# Summary
[summary]: #summary

The proposed change of frequency plan for Australia highlighted some major deficiencies on how the DEWI LoRaWAN committee is currently selected, operated and how the process can be improved for all impacted by the committee decisions.

This HIP suggests improvements in the following areas:
1. Selection of members and defining their roles
2. Declaration of conflict of interest
3. Governance procedures, such as reporting
4. Creation of sub groups to perform specific tasks or assignments to assist the committee decisions
5. Ethics guidelines
6. Process of including the affected regions in the decision-making process
7. Failures and consequences.

# Motivation
[motivation]: #motivation

Currently there are no publicly available Terms of Reference (TOR) for the DEWI LoRaWAN committee. This can place burden on the committee and the community creating an absence of clarity for both that has led to undesirable results.

Given the accelerated growth of the community, the number of diverse groups (such as makers, operators, and consumers) the number of diverse cultures (worldwide) that are asked to contribute time, financials (blood, sweat and tears) either directly or indirectly we believe it is now time to enact a governance framework that values all contributors to the community and continues to strengthen the resilience of it as it grows. 

This proposed change should be seen as a positive for the existing committee, as due to their effort thus far the community has grown to the size and complexity that requires more formal governance.

# Stakeholders
[stakeholders]: #stakeholders

There are two (2) stakeholder groups with this HIP:
 - DEWI LoRaWAN Committee
    - A clear governance structure will support the DEWI LoRaWAN committee to ensure strong, objective, sustainable and inclusive growth, without bias and conflict.
 - Wider Helium Ecosystem
    - Without a clear articulated governance structure decisions made will inadvertedly create unintended consequences. Such decisions, without adequate consultation, have the potential to create critical user issues and harm growth, which is the reason why selection and governance of this committee are so crucial.

We have started reaching out to people
 - Github repository feedback
 - Helium Community HIP Discord channel
 - Other relevant Helium Community Discord channels.

# Detailed Explanation
[detailed-explanation]: #detailed-explanation

The improvements are to be achieved by the development of a publically accessible Terms of Reference (TOR) that establishes the governance of the comittee, the following details provide a minimine guidence for what must be part of the TOR. 

## Guiding principles of the committee
The committee has a responsibility to:
 - operate in a transparent, timely and accountable manner at all times
 - communicate clearly and regularly with stakeholders and the DEWI as appropriate
 - adopt existing LoRa Alliance standards where applicable
 - act in conformance with the relevant regulatory bodies in each region
 - report to wider Helium Community via publicly accessible meeting minutes and / or communiques on meeting outcomes
 - endeavour to reach consensus within the committee, taking into account the views of all members.

The committee’s recommendations must:
 - not be inconsistent with LoRa Alliance standards and directives by regional regulators
 - be based on the best available scientific information, evidence based policy and encourage best practice in the Helium ecosystem
 - balance the technical implications and impacts of changes with the practicalities of operators, makers and consumers in the wider Helium ecosystem
 - be clear, logical and verifiable
 - demonstrate that the views of affected stakeholder groups have been considered
 - aim to reduce unnecessary, ineffective or duplicative regulation.

## Membership
Committee membership is critical to the transparency and capability of the committee for effective and independent in decision making.

The committee must consist of at least:
 - an independent chair (not connected to either DEWI or Helium Inc)
 - three LoRaWAN and/or RF engineering experts, to ensure appropriate technical expertise is maintained
 - one person with a practical understanding of the operational, technical and logistical facets
 - one standards development/regulation specialist.

A quorum must be established to proceed with the committee meeting.

 The committee should engage other external experts and participants invited by the chair as required and determined by the agenda.
 The committee has the opportunity to establish sub groups (may be topic or region specific) to provide advice the committee.

## Eligibility requirements and declarations of personal interests (conflicts of interest)
Each member is required to make a declaration confirming they met the eligibility requirements upon their appointment to the committee. Members must continue to comply with eligibility requirements.

During the operation of the committee, members are to declare to the chair all known actual or potential conflicts of interest as soon as they become aware of the conflict. Each meeting should contain a standard agenda item to allow for actual and perceived acknowledgement.

The initial declaration of eligibility made to the DEWI prior to joining the committee and subsequent statements of personal interest will be deemed to be a ‘standing statement’ for all meetings of the committee.

At each meeting, members are to advise of any new actual or potential conflicts of interest arising in respect of issues on the meeting agenda. These should be recorded in the minutes of the meeting, along with the course of action taken in relation to managing the conflict of interest. Where a conflict of interest is declared by a member on a particular agenda item, the chair is to consider the nature and extent of the conflict and adopt one of
the following courses of action:
 - allow the member to participate in discussion and in decision-making on the matter
 - allow the member to be involved in discussions on the matter but not be involved in making a decision in relation to the matter
 - exclude the member from participation in any discussion or decision-making on the matter
 - direct the member to leave the meeting during deliberation on the matter.

The use of external experts is also subject to conflict of interest considerations. Each potential external expert must declare any potential conflict of interest or any possible perception of bias that could prevent him or her from participating in the review of a particular issue/standard. If this declaration raises concerns about whether the external expert should participate in the review, the chair may nominate an alternative expert.

## Technical Advisory Committee Operational Guidelines
### Committee roles and responsibilities
The committee structure has been designed to balance the skills, interests and expertise of its members so that the group may offer sound advice to DEWI.

Role of individual members:
 - participate in meetings, engage in quality debate to give professional, independent and advice to the Chair 
 - Represent the consensus view of the community
 -	Understand the strategic impacts and outcomes of initiatives being considered
 - remaining fundamentally committed to the improvement of the Helium ecosystem
 - operating in a transparent, timely and accountable manner
 - ensuring all technical issues, new research and scientific knowledge submitted by stakeholders relating to technical matters have been properly considered by the committee and independent expert advice sought as necessary
 - contributing to the development of clear timelines and work plans for the committee
 - ensuring all interested stakeholders have the opportunity to provide review input
 - clearly analysing the benefits and costs of the proposed options for affected stakeholders in a balanced and objective manner.

Role of the independent chair:
 - chair meetings, including:
   - advising the committee about meeting protocols
   - Ensure actions from each meeting are discussed and managed to their conclusion
   - reminding committee members that they are bound by confidentiality provisions
   - managing declarations of conflict of interest
   - facilitate constructive processes that allow for continuous improvement DEWI and the Helium ecosystem overall
   - ensure work of the committee is conducted efficiently and that recommendations are presented to DEWI within agreed timelines
   - ensure committee members act in accordance with the guiding principles of the terms of reference in all aspects of operations
 - ensure the committee undertakes appropriate record keeping of decisions and actions
 - provide final approval of committee meeting papers and recommendations
 - provide progress updates and reporting to DEWI.
 - report to wider Helium community via meeting minutes and / or communiques on meeting outcomes

## Reporting arrangements
The committee, through the chair, will report to DEWI. In addition to their final recommendations the committee will provide a report that outlines their consultation process, issues raised by stakeholders and their deliberations in reaching their recommendations to DEWI.

The information shall be published on DEWI's website or Github repository. This information published will include information outlining the issues for consideration, the consultation timelines and updates on progress of the review. Submissions (unless clearly marked ‘IN CONFIDENCE’) and draft and final recommendations
will also be published on these pages.


# Drawbacks
[drawbacks]: #drawbacks

None.

The Helium ecosystem needs a governance framework to meet the fast growth that has occurred and allow continued positive growth for the community.

# Rationale and Alternatives
[alternatives]: #rationale-and-alternatives

- Why is this design the best in the space of possible designs?

No other proposals are currently available. Widest possible community feedback will be sought to consider in this proposal.

Best practice governance provides strong platform for growth, sustainability and resilience.

- What is the impact of not doing this?

Poor decision making and unnecessary disruption of the ecosystem due to such decisions. Regional disruptions and potential disconnect. Reduction of confidence in the Helium network.  If so by whom? Likely loss or reduction of network growth and adoption for all stakeholders.

# Unresolved Questions
[unresolved]: #unresolved-questions

- How does this governance proposal for the LoRaWAN committee fit in with an overall DEWI governance structure? 

- Do any decisions made by the LoRaWAN committee prior to the approval of this HIP need to be reviewed? Details of existing documentation has been sought?

- Does cyber security have enough representation within the committees?

What related issues do you consider out of scope for this HIP that could be addressed in the future independently of the solution that comes out of this HIP?

-Issue escalation procedure with Alliance
-Positive mental health of members (including reduction of burnout)
-Risk management.

-[TODO] add some more. 

# Deployment Impact
[deployment-impact]: #deployment-impact

There is no deployment impact. This HIP purely describes proper governance and procedures in the decision making process.

It will create a proper governance structure ensuring that decisions are made with proper consideration of all stakeholders and ensures that conflicts of interest have to be declared.

Documentation on this process should be made available via Helium Docs.

There are no backwards compatibility issues. The only potential issue is how to deal with decisions made prior to this change in governance.

# Success Metrics
[success-metrics]: #success-metrics

What metrics can be used to measure the success of this design?

- Faith of current Helium investors in regions
- Engagement by community in future decisions
- Alignment to best practice and possibility to lead by example
- Greater network uptake and usage aligned to improved committee process and outcomes.",True,0,NONE
https://api.github.com/repos/helium/HIP/issues/comments/1078456287,HIP draft - LoRaWAN Committee Terms of Reference,jaytheblader,22,1176322857,2,1078456287,0,1176322857,2022-03-24T22:50:35Z,"Nice work, I believe implementation of this proposal will go a long way to strengthen the process within the Helium LoRaWan committee.",False,0,NONE
https://api.github.com/repos/helium/HIP/issues/comments/1078479964,HIP draft - LoRaWAN Committee Terms of Reference,ajcrom,22,1176322857,3,1078479964,0,1078456287,2022-03-24T23:29:12Z,"Great document and on behalf of the wider Helium community , thanks for the work to put this together . 

HIP45 certainly exposed some gaps - but these are the necessary learnings and the evolution of a growing , inclusive , transparent , global ecosystem . 

Definitely a step in the right direction . ",False,0,NONE
https://api.github.com/repos/helium/HIP/issues/comments/1078556669,HIP draft - LoRaWAN Committee Terms of Reference,buzzware,22,1176322857,4,1078556669,0,1078479964,2022-03-25T01:09:27Z,"Good work, it looks pretty thorough but it would be good to get feedback from people who do this kind of thing (not me).
One thing I suggest considering is representation from Europe and Asia Pacific regions, and representation of the Helium community ie those who have a significant following and respect from the Helium community via social media, blogs, podcasts etc.",False,0,NONE
https://api.github.com/repos/helium/HIP/issues/comments/1078655630,HIP draft - LoRaWAN Committee Terms of Reference,jamesmeikle,22,1176322857,5,1078655630,0,1078556669,2022-03-25T04:58:37Z,"Referencing a summary of why do we need this post: https://github.com/dewi-alliance/hplans/pull/28#issuecomment-1072949457

Thanks those that have provided feedback , read, commented here on and on other communities.

Any community that is this complex with so many moving parts needs the use of a documented TOR(s) and associated governance to survive a lengthy amount of time these days. There is likely some governance occurring but it is undocumented and thus not transparent to the community ,leading to some rather undesirable conversations. Good to hear the focus is being put on governance and also of the interest by a Helium representative to look at this HIP.",False,0,CONTRIBUTOR
https://api.github.com/repos/helium/HIP/issues/comments/1078874024,HIP draft - LoRaWAN Committee Terms of Reference,ehrisbok,22,1176322857,6,1078874024,0,1078655630,2022-03-25T10:20:19Z,This proposal is sorely needed. No governance & TOR leaves Helium open to to either poor decisions or accusations of conflicts of interest (real or imagined). Glad someone has put forth a well thought out document that promotes open & transparent governance. Which is critical for the Helium community  ,False,0,NONE
https://api.github.com/repos/helium/HIP/issues/comments/1079033502,HIP draft - LoRaWAN Committee Terms of Reference,Australian-Hnt-collectors,22,1176322857,7,1079033502,0,1078874024,2022-03-25T13:33:47Z,Great work to those involved it is well due that governance is sorted out for any discussion and promote some transparency without the cloak and dagger back room deals being done for a single group when the biggest percent of Australian companies currently using IOT is on the most suitable network ,False,0,NONE
https://api.github.com/repos/helium/HIP/issues/comments/1079918338,HIP draft - LoRaWAN Committee Terms of Reference,shawaj,22,1176322857,8,1079918338,0,1079033502,2022-03-27T12:14:36Z,"Great work.

I think having the stakeholders clearly defined and clearly declaring their interests and motivations is very important.

There is no fundamental reason for commercial applications and considerations to be taken into account with these matters but they need to be clearly defined and any potential conflict of interest readily identified.

By no means do I want to jump on the conspiracy theory bandwagon but like all things the optics are the important thing with that. If someone appears to have a conflict of interest people will always assume, rightly or wrongly, that they are biased",False,0,CONTRIBUTOR
https://api.github.com/repos/helium/HIP/issues/comments/1079919019,HIP draft - LoRaWAN Committee Terms of Reference,shawaj,22,1176322857,9,1079919019,0,1079918338,2022-03-27T12:18:17Z,"@vudutech one thing I'd like to see here though, representation from manufacturers.

They are important stakeholders in the ecosystem and are often not thought about.

In a wider way, I'm thinking perhaps a ""manufacturers association"" or something similar makes sense. Similar to how Formula 1 have a constructors and drivers association (just catching up on the qualifying hence my thought!)",False,0,CONTRIBUTOR
https://api.github.com/repos/helium/HIP/issues/comments/1080032238,HIP draft - LoRaWAN Committee Terms of Reference,leogaggl,22,1176322857,10,1080032238,0,1079919019,2022-03-27T22:27:23Z,"Thanks for the input @shawaj - greatly appreciated!

> ...representation from manufacturers.
> 
> They are important stakeholders in the ecosystem and are often not thought about.

This did come up in our discussions when starting this HIP! @tonysmith55 in particular did bring up the way standards bodies are often governed with formal input from all stakeholder groups.

We tried initially to keep it simple and broad (as there was some concern from our community call about too many regulations ""hindering fast innovation""):

_**""demonstrate that the views of affected stakeholder groups have been considered""**_

But I do agree with you that considering all stakeholder groups and allowing input is very important. A lot of this can also be avoided by transparency and good communication. 

> 
> In a wider way, I'm thinking perhaps a ""manufacturers association"" or something similar makes sense. Similar to how Formula 1 have a constructors and drivers association (just catching up on the qualifying hence my thought!)

I do think this is a good idea. However, it is probably outside of the scope of this HIP. It would make the inclusion process easier if there is a clear stakeholder group defined.

Would you be interested in helping us create a listing of stakeholder groups that should be considered? You mention manufacturers. Gateway manufacturers? Device manufacturers? Software vendors?

If you have any suggestions in terms of wording please do submit an issue or a PR on the repo https://github.com/leogaggl/HIP/blob/main/00XX-lorawan-committee.md

[On a more humorous note: I doubt Lewis Hamilton would argue that F1 should be taken as a model of transparency and great decisions ;-)]
",False,0,CONTRIBUTOR
https://api.github.com/repos/helium/HIP/issues/comments/1080086543,HIP draft - LoRaWAN Committee Terms of Reference,fahimshariff,22,1176322857,11,1080086543,0,1080032238,2022-03-28T01:25:59Z,Great work we really need better governance and transparency . ,False,0,NONE
https://api.github.com/repos/helium/HIP/issues/comments/1080098974,HIP draft - LoRaWAN Committee Terms of Reference,jaytheblader,22,1176322857,12,1080098974,0,1080086543,2022-03-28T01:54:46Z,"Thanks @shawaj for your input and support around this HIP, I believe it will if implemented form the basis to similar HIPs that help to address governance issues Helium / DeWi has in some other areas. You are absolutely correct in my opinion that a representative of the gateway manufacturers be considered as a committee position as long as any conflict of interest that could arise on occasion follows due process to allow the committee to be unbiased.",False,0,NONE
https://api.github.com/repos/helium/HIP/issues/comments/1086388424,HIP draft - LoRaWAN Committee Terms of Reference,Buckshot22,22,1176322857,13,1086388424,0,1080098974,2022-04-01T22:36:13Z,"Fantastic work guys, if there is anything I can do to help, please let me know. What has been presented so far is very comprehensive and should be a significant improvement to the current process.
",False,0,NONE
https://api.github.com/repos/helium/HIP/issues/comments/1145345722,HIP draft - LoRaWAN Committee Terms of Reference,jamiew,22,1176322857,14,1145345722,0,1086388424,2022-06-02T21:11:58Z,"Hi @vudutech  @leogaggl, @tonysmith55, @buzzware, @jamesmeikle – would y'all be able to write this as an actual HIP file that can be merged into the repo, per convention? 

I've also written a rough guide to doing this using the github.com web interface: https://jamiedubs.com/blog/how-to-submit-helium-manufacturer-application/",False,0,CONTRIBUTOR
https://api.github.com/repos/helium/HIP/issues/comments/1145419559,HIP draft - LoRaWAN Committee Terms of Reference,leogaggl,22,1176322857,15,1145419559,0,1145345722,2022-06-02T22:56:58Z,"Hi @jamiew,

Do you mean this file: https://github.com/leogaggl/HIP/blob/main/00XX-lorawan-committee.md? 

It was forked from HIP repo and based on the template.

Cheers,
Leo",False,0,CONTRIBUTOR
https://api.github.com/repos/helium/HIP/issues/comments/1145497860,HIP draft - LoRaWAN Committee Terms of Reference,jamiew,22,1176322857,16,1145497860,0,1145419559,2022-06-03T01:19:07Z,"@leogaggl yes, thank you, I was thrown off the scent by having the full post in the PR body too (which is also convenient). Un-stale'ing and will review tomorrow for merger. Please forgive the delay!",False,0,CONTRIBUTOR
https://api.github.com/repos/helium/HIP/issues/comments/1145497977,HIP draft - LoRaWAN Committee Terms of Reference,jamiew,22,1176322857,17,1145497977,0,1145497860,2022-06-03T01:19:27Z,"is it safe to assume it's actually Ready For Review? it's technically still listed as draft, which means don't merge",False,0,CONTRIBUTOR
https://api.github.com/repos/helium/HIP/issues/comments/1146746412,HIP draft - LoRaWAN Committee Terms of Reference,leogaggl,22,1176322857,18,1146746412,0,1145497977,2022-06-05T05:41:28Z,"I would be ready from our perspective to fix the issues around the Committee. So you can definitely take it out of the draft.

It really depends on how @Scottsigel and @edakturk14 want to take this forward. To me, it would make more sense as part of a wider governance HIP which also contains the fixes that @Scottsigel and the Australian community flagged as necessary on HIP-45 during the Town Hall session.

",False,0,CONTRIBUTOR
https://api.github.com/repos/helium/HIP/issues/comments/1249565171,HIP draft - LoRaWAN Committee Terms of Reference,vincenzospaghetti,22,1176322857,19,1249565171,0,1146746412,2022-09-16T16:32:54Z,"Following up to @leogaggl 's last comment. The Foundation, including myself, will be proposing a larger governance structure and processes. All of this will be taken into consideration and we'll engage the community shortly on our proposal. ",False,0,CONTRIBUTOR
https://api.github.com/repos/helium/HIP/issues/comments/1268622223,HIP draft - LoRaWAN Committee Terms of Reference,hiptron,22,1176322857,20,1268622223,0,1249565171,2022-10-05T15:55:26Z,"@leogaggl is this replaced by the governance pieces of https://github.com/helium/HIP/pull/480 ? Per @vincenzospaghetti note they are working on a new governance HIP as well, but we could merge this, merge that one, and merge a new one and discuss each independently. So sorry this one has taken so long to be addressed properly 

- @jamiew + @vincenzospaghetti + HIP Triage Call",False,0,COLLABORATOR
https://api.github.com/repos/helium/HIP/issues/comments/1269021368,HIP draft - LoRaWAN Committee Terms of Reference,leogaggl,22,1176322857,21,1269021368,0,1268622223,2022-10-05T21:54:23Z,"This particular piece of work was related to HIP-45 which was quietly dropped by the foundation with little fanfare it seems.

I would agree that this can probably be closed and seen as another perfect example of a governance failure. I am happy to see some work done by yourself and @vincenzospaghetti - but unless the Helium Foundation Board steps up and treats this seriously I am afraid it seems little and very late. 
",False,0,CONTRIBUTOR
https://api.github.com/repos/helium/HIP/issues/comments/1269110551,HIP draft - LoRaWAN Committee Terms of Reference,jamiew,22,1176322857,22,1269110551,0,1269021368,2022-10-05T23:39:56Z,"@leogaggl was the outcome from this and HIP45 something you don’t agree with, or is it about the process of getting there? 

I think everyone would welcome community participation from you and others in organizing committees like what you had proposed here, and would consider the outputs seriously",False,0,CONTRIBUTOR
https://api.github.com/repos/helium/HIP/issues/comments/1269142334,HIP draft - LoRaWAN Committee Terms of Reference,leogaggl,22,1176322857,23,1269142334,0,1269110551,2022-10-06T00:24:34Z,"> @leogaggl was the outcome from this and HIP45 something you don’t agree with, or is it about the process of getting there?

Hey @jamiew - I was referring to the process in this context here. We had a whole process leading to a town hall meeting where Scott promised that the governance process will be addressed and no decision will be made without the affected community.

Instead there was radio silence for over six months, the whole process discarded rather than fixed and then there was some ""announcement"" blaming the LoRa Alliance (which has actually stated previously that it does not take a position in those matters - as it is determined by the local authorities and the choice is up to the operator). 

You might as well not bother with governance and just let Nova Labs do what they like to do. And don't pretend the Helium Foundation is actually in charge of anything. 

",False,0,CONTRIBUTOR
https://api.github.com/repos/helium/HIP/issues/381,HIP: PoC Distance Limit,abhay,7,1190760812,1,1190760812,0,0,2022-04-02T23:09:54Z,[rendered](https://github.com/helium/HIP/blob/ak/distance-limit/xxxx-poc-distance-limit.md),True,0,CONTRIBUTOR
https://api.github.com/repos/helium/HIP/issues/comments/1086893043,HIP: PoC Distance Limit,alphaqt,7,1190760812,2,1086893043,0,1190760812,2022-04-03T15:35:21Z,"Distance limitation is a huge step towards my proposal for ""HIP 100"" Currently the SINR levels in the network are unmanageable.  The distance limitation should be dynamically assigned similar to the Transmit scale based on the the HEX structure and whether neighbor HEXes are empty or populated",False,0,NONE
https://api.github.com/repos/helium/HIP/issues/comments/1086963295,HIP: PoC Distance Limit,abhay,7,1190760812,3,1086963295,0,1086893043,2022-04-03T22:34:27Z,@evandiewald you were going to add that extra commentary here right? ,False,0,CONTRIBUTOR
https://api.github.com/repos/helium/HIP/issues/comments/1086977731,HIP: PoC Distance Limit,evandiewald,7,1190760812,4,1086977731,0,1086963295,2022-04-03T23:54:50Z,@abhay see #383 ,False,0,CONTRIBUTOR
https://api.github.com/repos/helium/HIP/issues/comments/1087798956,HIP: PoC Distance Limit,edakturk14,7,1190760812,5,1087798956,0,1086977731,2022-04-04T17:03:58Z,"This HIP draft has been numbered and merged for discussion as HIP 58. 

Please direct future questions & comments to the new tracking issue: #384 

If you are one of the named authors, please include #384 in future pull requests to have them automatically merged.",False,0,CONTRIBUTOR
https://api.github.com/repos/helium/HIP/issues/comments/1095586013,HIP: PoC Distance Limit,NotBarki,7,1190760812,6,1095586013,0,1087798956,2022-04-11T21:30:26Z,"Hi @abhay,

Could you please clarify something on Discord?

BigBarki#6528

Much appreciated.

",False,0,NONE
https://api.github.com/repos/helium/HIP/issues/comments/1095600586,HIP: PoC Distance Limit,abhay,7,1190760812,7,1095600586,0,1095586013,2022-04-11T21:48:30Z,"> Could you please clarify something on Discord?
> 
> BigBarki#6528

Sure ping me in the channel ",False,0,CONTRIBUTOR
https://api.github.com/repos/helium/HIP/issues/comments/1095647047,HIP: PoC Distance Limit,NotBarki,7,1190760812,8,1095647047,0,1095600586,2022-04-11T22:21:43Z,"> > Could you please clarify something on Discord?
> > BigBarki#6528
> 
> Sure ping me in the channel


Thanks for your quick response Abhay. I can't find you on Discord, is there a possibility that you add me, we'll talk there.",False,0,NONE
https://api.github.com/repos/sveltejs/kit/issues/4580,import json not working in dependency,cmcculloh-kr,3,1197984978,1,1197984978,0,0,2022-04-09T01:07:39Z,"### Describe the bug

If I npm install a dependency that uses `import something from 'something.json'` I get the following error when I try to build:

```
TypeError [ERR_UNKNOWN_FILE_EXTENSION]: Unknown file extension "".json"" for /Users/cmcculloh/Prototypes/backups/for-bug/node_modules/working-json/baz.json
    at new NodeError (node:internal/errors:371:5)
    at Object.getFileProtocolModuleFormat [as file:] (node:internal/modules/esm/get_format:87:11)
    at defaultGetFormat (node:internal/modules/esm/get_format:102:38)
    at defaultLoad (node:internal/modules/esm/load:21:14)
    at ESMLoader.load (node:internal/modules/esm/loader:359:26)
    at ESMLoader.moduleProvider (node:internal/modules/esm/loader:280:58)
    at new ModuleJob (node:internal/modules/esm/module_job:66:26)
    at ESMLoader.#createModuleJob (node:internal/modules/esm/loader:297:17)
    at ESMLoader.getModuleJob (node:internal/modules/esm/loader:261:34)
    at async ModuleWrap.<anonymous> (node:internal/modules/esm/module_job:81:21)
```

### Reproduction

[Here](https://github.com/cmcculloh/for-bug) is an example sveltekit project that reproduces the issue that I made for this bug report.
[Here](https://github.com/cmcculloh/working-json) is the example module I am npm installing that I made for this bug report.

### Logs

```shell
TypeError [ERR_UNKNOWN_FILE_EXTENSION]: Unknown file extension "".json"" for /Users/cmcculloh/Prototypes/backups/for-bug/node_modules/working-json/baz.json
    at new NodeError (node:internal/errors:371:5)
    at Object.getFileProtocolModuleFormat [as file:] (node:internal/modules/esm/get_format:87:11)
    at defaultGetFormat (node:internal/modules/esm/get_format:102:38)
    at defaultLoad (node:internal/modules/esm/load:21:14)
    at ESMLoader.load (node:internal/modules/esm/loader:359:26)
    at ESMLoader.moduleProvider (node:internal/modules/esm/loader:280:58)
    at new ModuleJob (node:internal/modules/esm/module_job:66:26)
    at ESMLoader.#createModuleJob (node:internal/modules/esm/loader:297:17)
    at ESMLoader.getModuleJob (node:internal/modules/esm/loader:261:34)
    at async ModuleWrap.<anonymous> (node:internal/modules/esm/module_job:81:21)
```


### System Info

```shell
System:
    OS: macOS 12.3
    CPU: (12) x64 Intel(R) Core(TM) i7-8850H CPU @ 2.60GHz
    Memory: 135.13 MB / 32.00 GB
    Shell: 5.8 - /bin/zsh
  Binaries:
    Node: 16.14.0 - ~/.nvm/versions/node/v16.14.0/bin/node
    Yarn: 1.22.18 - /usr/local/bin/yarn
    npm: 8.3.1 - ~/.nvm/versions/node/v16.14.0/bin/npm
  Browsers:
    Brave Browser: 100.1.37.109
    Chrome: 100.0.4896.75
    Safari: 15.4
  npmPackages:
    @sveltejs/adapter-auto: next => 1.0.0-next.34 
    @sveltejs/kit: next => 1.0.0-next.310 
    svelte: ^3.44.0 => 3.47.0
```


### Severity

serious, but I can work around it

### Additional Information

My current workaround is to modify the dependency. I change the `.json` file to a `.js` file with `export default` at the beginning. This is sub-optimal, because in the actual project I am using this for the JSON file is 200,000+ lines of json that is generated by a process (so, I'll have to modify the process to instead generate a `.js` file with `export default` at the front, and I'm not 100% sure I can, because I'm not sure who owns the process).",True,0,NONE
https://api.github.com/repos/sveltejs/kit/issues/comments/1093688801,import json not working in dependency,Conduitry,3,1197984978,2,1093688801,0,1197984978,2022-04-09T04:54:53Z,"Importing JSON in ESM is a syntax error unless you're using experimental type assertions - https://nodejs.org/api/esm.html#json-modules

If you have a dependency doing that, that's a bug in that dependency.",False,0,MEMBER
https://api.github.com/repos/sveltejs/kit/issues/comments/1094018497,import json not working in dependency,cmcculloh-kr,3,1197984978,3,1094018497,0,1093688801,2022-04-09T13:23:04Z,"@Conduitry Thanks. Adding that is causing a different error:

```
Prototypes/backups/for-bug % npm run build                                                                                                                                                     (master)for-bug

> for-bug@0.0.1 build
> svelte-kit build

vite v2.9.1 building for production...
✓ 14 modules transformed.
[commonjs] Unexpected token (1:29) in /Users/cmcculloh/Prototypes/backups/for-bug/node_modules/working-json/bar.js
file: /Users/cmcculloh/Prototypes/backups/for-bug/node_modules/working-json/bar.js:1:29
1: import baz from './baz.json' assert { type: 'json' };
                                ^
2: 
3: const Foo = {
/Users/cmcculloh/Prototypes/backups/for-bug/node_modules/rollup/dist/shared/rollup.js:19636
  var err = new SyntaxError(message);
            ^

SyntaxError: Unexpected token (1:29) in /Users/cmcculloh/Prototypes/backups/for-bug/node_modules/working-json/bar.js
    at Parser.pp$4.raise (/Users/cmcculloh/Prototypes/backups/for-bug/node_modules/rollup/dist/shared/rollup.js:19636:13)
    at Parser.pp$9.unexpected (/Users/cmcculloh/Prototypes/backups/for-bug/node_modules/rollup/dist/shared/rollup.js:16932:8)
    at Parser.pp$9.semicolon (/Users/cmcculloh/Prototypes/backups/for-bug/node_modules/rollup/dist/shared/rollup.js:16909:66)
    at Parser.pp$8.parseImport (/Users/cmcculloh/Prototypes/backups/for-bug/node_modules/rollup/dist/shared/rollup.js:17978:8)
    at Parser.pp$8.parseStatement (/Users/cmcculloh/Prototypes/backups/for-bug/node_modules/rollup/dist/shared/rollup.js:17108:49)
    at Parser.pp$8.parseTopLevel (/Users/cmcculloh/Prototypes/backups/for-bug/node_modules/rollup/dist/shared/rollup.js:16989:21)
    at Parser.parse (/Users/cmcculloh/Prototypes/backups/for-bug/node_modules/rollup/dist/shared/rollup.js:16762:15)
    at Function.parse (/Users/cmcculloh/Prototypes/backups/for-bug/node_modules/rollup/dist/shared/rollup.js:16812:35)
    at Graph.contextParse (/Users/cmcculloh/Prototypes/backups/for-bug/node_modules/rollup/dist/shared/rollup.js:22926:38)
    at tryParse (/Users/cmcculloh/Prototypes/backups/for-bug/node_modules/vite/dist/node/chunks/dep-611778e0.js:11062:12) {
  pos: 29,
  loc: {
    column: 29,
    file: '/Users/cmcculloh/Prototypes/backups/for-bug/node_modules/working-json/bar.js',
    line: 1
  },
  raisedAt: 35,
  frame: ""1: import baz from './baz.json' assert { type: 'json' };\n"" +
    '                                ^\n' +
    '2: \n' +
    '3: const Foo = {',
  id: '/Users/cmcculloh/Prototypes/backups/for-bug/node_modules/working-json/bar.js',
  hook: 'transform',
  code: 'PLUGIN_ERROR',
  plugin: 'commonjs',
  watchFiles: [
    '/Users/cmcculloh/Prototypes/backups/for-bug/.svelte-kit/runtime/client/start.js',
    '/Users/cmcculloh/Prototypes/backups/for-bug/.svelte-kit/runtime/components/layout.svelte',
    '/Users/cmcculloh/Prototypes/backups/for-bug/.svelte-kit/runtime/components/error.svelte',
    '/Users/cmcculloh/Prototypes/backups/for-bug/src/routes/index.svelte',
    '/Users/cmcculloh/Prototypes/backups/for-bug/node_modules/svelte/package.json',
    '/Users/cmcculloh/Prototypes/backups/for-bug/node_modules/svelte/store/package.json',
    '/Users/cmcculloh/Prototypes/backups/for-bug/node_modules/svelte/index.mjs',
    '/Users/cmcculloh/Prototypes/backups/for-bug/node_modules/svelte/store/index.mjs',
    '/Users/cmcculloh/Prototypes/backups/for-bug/.svelte-kit/runtime/paths.js',
    '/Users/cmcculloh/Prototypes/backups/for-bug/.svelte-kit/runtime/client/singletons.js',
    '/Users/cmcculloh/Prototypes/backups/for-bug/.svelte-kit/generated/root.svelte',
    '/Users/cmcculloh/Prototypes/backups/for-bug/.svelte-kit/generated/client-manifest.js',
    '/Users/cmcculloh/Prototypes/backups/for-bug/node_modules/svelte/internal/package.json',
    '/Users/cmcculloh/Prototypes/backups/for-bug/node_modules/svelte/internal/index.mjs',
    '/Users/cmcculloh/Prototypes/backups/for-bug/src/lib/foo.ts',
    '/Users/cmcculloh/Prototypes/backups/for-bug/node_modules/vite/package.json',
    '/Users/cmcculloh/Prototypes/backups/for-bug/.svelte-kit/generated/client-matchers.js',
    'vite/preload-helper',
    '/Users/cmcculloh/Prototypes/backups/for-bug/node_modules/working-json/package.json',
    '/Users/cmcculloh/Prototypes/backups/for-bug/node_modules/working-json/bar.js'
  ]
}

Node.js v17.9.0
```

Using `require` instead causes this error:
```

> for-bug@0.0.1 build
> svelte-kit build

vite v2.9.1 building for production...
✓ 15 modules transformed.
.svelte-kit/output/client/_app/manifest.json                    1.14 KiB
.svelte-kit/output/client/_app/layout.svelte-23d0f029.js        0.53 KiB / gzip: 0.35 KiB
.svelte-kit/output/client/_app/pages/index.svelte-2fa0edb9.js   0.60 KiB / gzip: 0.40 KiB
.svelte-kit/output/client/_app/error.svelte-bb9909e1.js         1.56 KiB / gzip: 0.74 KiB
.svelte-kit/output/client/_app/chunks/index-dd45c2ae.js         6.83 KiB / gzip: 2.79 KiB
.svelte-kit/output/client/_app/start-ebce25f7.js                22.59 KiB / gzip: 8.54 KiB
vite v2.9.1 building SSR bundle for production...
✓ 12 modules transformed.
Generated an empty chunk: ""hooks""
.svelte-kit/output/server/manifest.json                        1.09 KiB
.svelte-kit/output/server/index.js                             65.52 KiB
.svelte-kit/output/server/entries/fallbacks/layout.svelte.js   0.24 KiB
.svelte-kit/output/server/entries/fallbacks/error.svelte.js    0.72 KiB
.svelte-kit/output/server/entries/pages/index.svelte.js        0.36 KiB
.svelte-kit/output/server/chunks/index-2dc61825.js             2.29 KiB
.svelte-kit/output/server/chunks/hooks-1c45ba0b.js             0.00 KiB
ReferenceError: require is not defined in ES module scope, you can use import instead
This file is being treated as an ES module because it has a '.js' file extension and '/Users/cmcculloh/Prototypes/backups/for-bug/package.json' contains ""type"": ""module"". To treat it as a CommonJS script, rename it to use the '.cjs' file extension.
    at file:///Users/cmcculloh/Prototypes/backups/for-bug/node_modules/working-json/bar.js:1:13
    at ModuleJob.run (node:internal/modules/esm/module_job:198:25)
    at async Promise.all (index 0)
    at async ESMLoader.import (node:internal/modules/esm/loader:409:24)
    at async Promise.all (index 1)
    at async respond$1 (file:///Users/cmcculloh/Prototypes/backups/for-bug/.svelte-kit/output/server/index.js:1480:13)
    at async resolve (file:///Users/cmcculloh/Prototypes/backups/for-bug/.svelte-kit/output/server/index.js:1859:105)
    at async respond (file:///Users/cmcculloh/Prototypes/backups/for-bug/.svelte-kit/output/server/index.js:1815:22)
    at async visit (file:///Users/cmcculloh/Prototypes/backups/for-bug/node_modules/@sveltejs/kit/dist/chunks/index2.js:1094:20)
> 500 /
    at file:///Users/cmcculloh/Prototypes/backups/for-bug/node_modules/@sveltejs/kit/dist/chunks/index2.js:980:11
    at save (file:///Users/cmcculloh/Prototypes/backups/for-bug/node_modules/@sveltejs/kit/dist/chunks/index2.js:1213:4)
    at visit (file:///Users/cmcculloh/Prototypes/backups/for-bug/node_modules/@sveltejs/kit/dist/chunks/index2.js:1104:3)
    at processTicksAndRejections (node:internal/process/task_queues:96:5)
```

Using `import()` with `await` causes this error:
```

> for-bug@0.0.1 build
> svelte-kit build

vite v2.9.1 building for production...
✓ 16 modules transformed.
rendering chunks (1)...[vite:esbuild-transpile] Transform failed with 1 error:
pages/index.svelte-4273c36b.js:3:12: ERROR: Top-level await is not available in the configured target environment (""chrome87"", ""edge88"", ""es2019"", ""firefox78"", ""safari13.1"")

Top-level await is not available in the configured target environment (""chrome87"", ""edge88"", ""es2019"", ""firefox78"", ""safari13.1"")
1  |  import { S as SvelteComponent, i as init, s as safe_not_equal, e as element, t as text, k as space, c as claim_element, a as children, h as claim_text, d as detach, m as claim_space, g as insert_hydration, J as append_hydration, n as noop } from '../chunks/index-dd45c2ae.js';
2  |  
3  |  const baz = await import('../chunks/baz-2277351f.js');
   |              ^
4  |  
5  |  const Foo = {

> Transform failed with 1 error:
pages/index.svelte-4273c36b.js:3:12: ERROR: Top-level await is not available in the configured target environment (""chrome87"", ""edge88"", ""es2019"", ""firefox78"", ""safari13.1"")
pages/index.svelte-4273c36b.js:3:12: ERROR: Top-level await is not available in the configured target environment (""chrome87"", ""edge88"", ""es2019"", ""firefox78"", ""safari13.1"")
    at failureErrorWithLog (/Users/cmcculloh/Prototypes/backups/for-bug/node_modules/esbuild/lib/main.js:1603:15)
    at /Users/cmcculloh/Prototypes/backups/for-bug/node_modules/esbuild/lib/main.js:1392:29
    at /Users/cmcculloh/Prototypes/backups/for-bug/node_modules/esbuild/lib/main.js:666:9
    at handleIncomingPacket (/Users/cmcculloh/Prototypes/backups/for-bug/node_modules/esbuild/lib/main.js:763:9)
    at Socket.readFromStdout (/Users/cmcculloh/Prototypes/backups/for-bug/node_modules/esbuild/lib/main.js:632:7)
    at Socket.emit (node:events:527:28)
    at addChunk (node:internal/streams/readable:324:12)
    at readableAddChunk (node:internal/streams/readable:297:9)
    at Socket.Readable.push (node:internal/streams/readable:234:10)
    at Pipe.onStreamRead (node:internal/stream_base_commons:190:23)

```

It's fine if you guys don't support it yet. I wanted to get it on your radar, and also note a solution for others that might run into this (none of the other commonly proposed solutions to this have worked). There's a similar-ish errors in Node 16 btw.",False,0,NONE
https://api.github.com/repos/sveltejs/kit/issues/comments/1094111881,import json not working in dependency,cmcculloh-kr,3,1197984978,4,1094111881,0,1094018497,2022-04-09T19:30:04Z,"@Conduitry I should also note that moving `import baz from './baz.json';` out of the module and making it native to the sveltekit project works just fine (which is why I specified that import json isn't working in a dependency, since it works if within the sveltekit project itself).",False,0,NONE
https://api.github.com/repos/sveltejs/kit/issues/4581,Navigation - The NEXT button in the SvelteKit documentation malfunctions,lukaszpolowczyk,14,1198030494,1,1198030494,0,0,2022-04-09T02:03:22Z,"### Describe the bug

Navigation - The NEXT button in the SvelteKit documentation malfunctions.

The https://kit.svelte.dev/docs/service-workers url looks like this - wrong title, wrong NEXT button, wrong PREVIOUS button.
Clicking the back/forward button, NEXT/PREVIOUS, the link in the side panel - none of them set the title or names of the NEXT and PREVIOUS buttons. The links work, but the names of NEXT and PREVIOUS and title are wrong.
The tab title changes.
![Screenshot_2022-04-09 SvelteKit docs(2)](https://user-images.githubusercontent.com/16800535/162552031-e632eaf1-67a5-4ba4-9303-6b258b8be5a8.png)



### Reproduction

Difficult to reproduce.
I was just going through one by one, from https://kit.svelte.dev/docs/introduction to https://kit.svelte.dev/docs/service-workers and then I noticed it.

But when I do it again now in a new tab, the error is gone.

This has happened a few times already, right after the introduction of the search engine and subdivision it happened.

### Logs

_No response_

### System Info

```shell
System:
    OS: Linux 5.10 Arch Linux
    CPU: (4) x64 AMD Athlon(tm) X4 950 Quad Core Processor
    Memory: 3.03 GB / 15.07 GB
    Container: Yes
    Shell: 5.1.8 - /bin/bash
  Binaries:
    Node: 16.3.0 - /usr/bin/node
    Yarn: 1.22.10 - /usr/bin/yarn
    npm: 7.17.0 - /usr/bin/npm
  Browsers:
    Brave Browser: 100.1.37.109
    Firefox: 87.0
```


### Severity

annoyance

### Additional Information

_No response_",True,0,CONTRIBUTOR
https://api.github.com/repos/sveltejs/kit/issues/comments/1094256916,Navigation - The NEXT button in the SvelteKit documentation malfunctions,Mlocik97,14,1198030494,2,1094256916,0,1198030494,2022-04-10T12:02:56Z,"tested in Firefox, can't reproduce. Try to clear cache in browser.",False,0,CONTRIBUTOR
https://api.github.com/repos/sveltejs/kit/issues/comments/1094275367,Navigation - The NEXT button in the SvelteKit documentation malfunctions,bluwy,14,1198030494,3,1094275367,0,1094256916,2022-04-10T13:28:13Z,No issues for me too.,False,0,MEMBER
https://api.github.com/repos/sveltejs/kit/issues/comments/1094298521,Navigation - The NEXT button in the SvelteKit documentation malfunctions,lukaszpolowczyk,14,1198030494,4,1094298521,0,1094275367,2022-04-10T15:35:55Z,"This is really hard to reproduce, but it is happening with a simple review of the documentation. This error has come up several times over the course of several weeks.
MAYBE it would be easier to look at the code and then determine what could be the cause?
If not, then this issue needs to be closed for now. :/",False,0,CONTRIBUTOR
https://api.github.com/repos/sveltejs/kit/issues/comments/1095282840,Navigation - The NEXT button in the SvelteKit documentation malfunctions,Rich-Harris,14,1198030494,5,1095282840,0,1094298521,2022-04-11T16:36:31Z,"I removed the `documentation` label because if this is a bug, it's a bug in SvelteKit, and this is just a particular manifestation of it. It really does need a repro though",False,0,MEMBER
https://api.github.com/repos/sveltejs/kit/issues/comments/1095350892,Navigation - The NEXT button in the SvelteKit documentation malfunctions,lukaszpolowczyk,14,1198030494,6,1095350892,0,1095282840,2022-04-11T17:49:09Z,"@Rich-Harris I have the documentation tab open NOW, and I was able to get this error.


### What I did today
* I opened Firefox
* I clicked on a tab (not to be mistaken with a bookmark) where I had a document open about ""Hooks""
* I navigated as shown under ""Video - full browsing history""
* I saw that the title froze to ""Assets handling""

After that I opened a new tab and tried to reproduce this error - failing!
Maybe it's not only the order, but also e.g. the pace that matters? :O
Rather, I didn't do backward/forward in the browser.

**I have a tab open with the error. Is there anything else I can do with it? Any information to pull from it?**


### Video - behaviour

Title frozen, NEXT frozem, PREVIOUS frozem (except for hiding when it goes to the first page in the documentation).

https://user-images.githubusercontent.com/16800535/162793075-991893ff-75b6-41ae-8323-2a958231073f.mp4

### Video - full browsing history preview


https://user-images.githubusercontent.com/16800535/162797589-d107328a-e46e-43d4-83b1-7a2cd1e01c9b.mp4



### Screen title
![sveltekitbug-tit](https://user-images.githubusercontent.com/16800535/162793580-d98859d3-9e87-4ee4-acc6-eb41c103ec3c.png)

### Screen NEXT and PREVIOUS buttons
![sveltekitbug](https://user-images.githubusercontent.com/16800535/162793582-badaebdb-444a-4f55-92fe-ce533b0036de.png)",False,0,CONTRIBUTOR
https://api.github.com/repos/sveltejs/kit/issues/comments/1095662222,Navigation - The NEXT button in the SvelteKit documentation malfunctions,Rich-Harris,14,1198030494,7,1095662222,0,1095350892,2022-04-11T22:43:41Z,Are you seeing any errors in your console when this happens?,False,0,MEMBER
https://api.github.com/repos/sveltejs/kit/issues/comments/1095663589,Navigation - The NEXT button in the SvelteKit documentation malfunctions,lukaszpolowczyk,14,1198030494,8,1095663589,0,1095662222,2022-04-11T22:46:01Z,"@Rich-Harris No, there are no errors in the console.",False,0,CONTRIBUTOR
https://api.github.com/repos/sveltejs/kit/issues/comments/1095695557,Navigation - The NEXT button in the SvelteKit documentation malfunctions,lukaszpolowczyk,14,1198030494,9,1095695557,0,1095663589,2022-04-11T23:37:01Z,"@Rich-Harris OMG. I looked at my Firefox extensions, and realized I use this one sometimes:
https://addons.mozilla.org/firefox/addon/traduzir-paginas-web/

**It just swaps the text on the page, to the translated version...**
So it's not surprising that some prcise connection between svelte and TextNode gets broken.
:roll_eyes: 

The question is, is it possible and does it even make sense to include this? Probably not?
I can only apologize. I feel silly now. :pray: 

EDIT: Because I use it on many sites, and it practically never breaks pages, (e.g. Github, Twitter, blogs).",False,0,CONTRIBUTOR
https://api.github.com/repos/sveltejs/kit/issues/comments/1096895770,Navigation - The NEXT button in the SvelteKit documentation malfunctions,Mlocik97,14,1198030494,10,1096895770,0,1095695557,2022-04-12T15:45:07Z,"it's impossible to ""fix"" website (that is not broken) so it works correctly with all possible browser extensions (that can break website)... correct solution is that user disable extension on specific website.",False,0,CONTRIBUTOR
https://api.github.com/repos/sveltejs/kit/issues/comments/1096917593,Navigation - The NEXT button in the SvelteKit documentation malfunctions,lukaszpolowczyk,14,1198030494,11,1096917593,0,1096895770,2022-04-12T16:04:26Z,"@Mlocik97 Yes, that's right.
I've made a fork and I'm checking the code for this extension so that it doesn't overwrite the `TextNode`, but replaces it with the text itself.
It already works better when testing but there are still a few things to do.

EDIT: The built-in translator in Google Chrome, causes a similar error.",False,0,CONTRIBUTOR
https://api.github.com/repos/sveltejs/kit/issues/comments/1097470335,Navigation - The NEXT button in the SvelteKit documentation malfunctions,bluwy,14,1198030494,12,1097470335,0,1096917593,2022-04-13T01:54:40Z,Closing as it's caused by a browser extension,False,0,MEMBER
https://api.github.com/repos/sveltejs/kit/issues/comments/1097738028,Navigation - The NEXT button in the SvelteKit documentation malfunctions,bluwy,14,1198030494,13,1097738028,0,1097470335,2022-04-13T08:55:42Z,I didn't notice this was caused by the built-in translator in Chrome too. Perhaps there's more to look into in that case. Re-opening.,False,0,MEMBER
https://api.github.com/repos/sveltejs/kit/issues/comments/1377344584,Navigation - The NEXT button in the SvelteKit documentation malfunctions,dummdidumm,14,1198030494,14,1377344584,0,1097738028,2023-01-10T14:13:13Z,"To highlight (because I didn't see it at a glance previously): This is reproducible by using Chrome's builtin Google Translate on the docs. The headline and the previous/next buttons do not update their text.

My assumption is that this is a Svelte core issue. Google Translate is messing with the text content, so it gets out of sync with Svelte, which no longer is able to upgrade the text nodes (they are different nodes now).",False,0,MEMBER
https://api.github.com/repos/sveltejs/kit/issues/comments/1377350786,Navigation - The NEXT button in the SvelteKit documentation malfunctions,lukaszpolowczyk,14,1198030494,15,1377350786,0,1377344584,2023-01-10T14:18:03Z,"@dummdidumm Yes, it's a SvelteJS problem. I mistakenly thought it was a SvelteKit navigation problem, that's why I started the thread in the SvelteKit repo.
It can be moved or something.",False,0,CONTRIBUTOR
https://api.github.com/repos/sveltejs/kit/issues/4582,"Support named layouts for the error page, e.g., __error@root.svelte, to remove hardwired dependency on __layout.svelte",johndunderhill,10,1198272580,1,1198272580,0,0,2022-04-09T05:52:16Z,"### Describe the problem

Currently, `__error.svelte` is hardwired to `__layout.svelte`.  In several of my projects, I use `__layout.svelte` for non-trivial purposes, including authentication guards, and of course rendering part of the page.  This makes it nearly impossible to use `__error.svelte` to set up a global error page:

- The error page tries to display the shared page layout, which may be undesirable, and may re-trigger the error, or [another error](https://github.com/sveltejs/kit/issues/3068).
- Authentication guards may attempt expensive operations, redirect to a login page, or trigger another error.

I've tried to work around this by saving the error information and redirecting to a normal page to display the error, but the approach is cumbersome and fraught with problems:

- There is no way to detect, in `__layout.svelte`, that the error page is running.  The URL path is the (possibly bad) path of the page that triggered the error.
- There's no good way to get the error information (error, status) to the next page.  Using the session store may work, but may cause [further problems](https://github.com/sveltejs/kit/issues/3732) or interfere with use of the session store for other purposes (such as server-to-client communication).
- It's not clear where or how to redirect out of the error page, and this may lead to [further problems](https://github.com/sveltejs/kit/issues/3051).  

This has been a nightmare.  I couldn't get it to work--I kept running into cascading issues--so I gave up (see Alternatives, below).

### Describe the proposed solution

A simple solution would be to allow the error page to specify a parent layout (just like any other page, with the new named layouts):

`__error@root.svelte`

This could be an empty layout, which would remove dependencies on other parts of the app, making the error page less likely to fail.  Similar to [2694](https://github.com/sveltejs/kit/issues/2694) but adapted for the new [named layouts](https://kit.svelte.dev/docs/layouts#named-layouts).



### Alternatives considered

Using a catch-all path in the route root will capture any unknown page, and this can specify a named layout:

`[...anypath]@root.svelte`

But this will not have access to actual error information, such as the stack trace, in development.

### Importance

would make my life easier

### Additional Information

The new named layouts were a bit hard to understand at first, but they are extremely powerful, and I'm sold on this.  Fixing this would complete the picture, IMHO.  As always, thanks to everyone for your hard work.",True,0,NONE
https://api.github.com/repos/sveltejs/kit/issues/comments/1115111502,"Support named layouts for the error page, e.g., __error@root.svelte, to remove hardwired dependency on __layout.svelte",gyurielf,10,1198272580,2,1115111502,0,1198272580,2022-05-02T16:46:02Z,"I agree with you.
Now I adjust our app structure to named layouts, and ran into the same issue.
",False,0,CONTRIBUTOR
https://api.github.com/repos/sveltejs/kit/issues/comments/1120160222,"Support named layouts for the error page, e.g., __error@root.svelte, to remove hardwired dependency on __layout.svelte",x4fingers,10,1198272580,3,1120160222,0,1115111502,2022-05-07T07:59:53Z,Same problem here. I think this feature should be developed soon.,False,0,NONE
https://api.github.com/repos/sveltejs/kit/issues/comments/1126817336,"Support named layouts for the error page, e.g., __error@root.svelte, to remove hardwired dependency on __layout.svelte",blujedis,10,1198272580,4,1126817336,0,1120160222,2022-05-14T21:58:54Z,"Popping in to say I'm glad the nightmare I'm currently enduring is being addressed ha ha. 

For what it's worth to me it feels as thought the best solution would be to just have say `--layout-full.svelte` where it has maybe basic font family etc. but is essentially 100% height and width then you could just do `__error@full.svelte`.",False,0,NONE
https://api.github.com/repos/sveltejs/kit/issues/comments/1126869491,"Support named layouts for the error page, e.g., __error@root.svelte, to remove hardwired dependency on __layout.svelte",vhscom,10,1198272580,5,1126869491,0,1126817336,2022-05-15T06:20:13Z,"For anyone lost in the weeds, there's a decent workaround for handling full-screen error page layouts [documented here](https://github.com/sveltejs/kit/issues/2694#issuecomment-991893665) with example implementation [here](https://github.com/vhscom/svelte-headlessui-starter/blob/de79e1cf9773ea1edce52f97b29570776712bae8/src/hooks/index.ts#L5-L21). It's a fairly non-invasive procedure. Not perfect but not too shabby while a suitable long-term solution is considered.",False,0,NONE
https://api.github.com/repos/sveltejs/kit/issues/comments/1141078613,"Support named layouts for the error page, e.g., __error@root.svelte, to remove hardwired dependency on __layout.svelte",icalvin102,10,1198272580,6,1141078613,0,1126869491,2022-05-30T12:09:30Z,"Sadly `__error.svelte` also seems to ignore the the inheritance chain of named layouts. 
For example with `__layout-base.svelte` and `__layout@base.svelte` only `__layout@base.svelte` will be loaded in case of an error and `__layout-base.svelte` is ignored.

This causes issues when the extending layout or error page relies on things that are initialized in the base layout.

This is a big inconsistency and layout inheritance should work the same way it does for page components IMO.",False,0,CONTRIBUTOR
https://api.github.com/repos/sveltejs/kit/issues/comments/1150234982,"Support named layouts for the error page, e.g., __error@root.svelte, to remove hardwired dependency on __layout.svelte",avarun42,10,1198272580,7,1150234982,0,1141078613,2022-06-08T18:10:15Z,"If you use nested layouts at all at the root-level, error pages are completely broken right now pretty much. You end up having to import the same things in the error that should've already been imported by the parent layouts of the base layout.",False,0,CONTRIBUTOR
https://api.github.com/repos/sveltejs/kit/issues/comments/1186037317,"Support named layouts for the error page, e.g., __error@root.svelte, to remove hardwired dependency on __layout.svelte",MadeByMike,10,1198272580,8,1186037317,0,1150234982,2022-07-16T00:26:49Z,"I think there is a easier work-around than vhscom mentions above:

```js
<script>
  import { page } from '$app/stores'
</script>
{#if $page.error}
<div class=""your-error-layout"">
  <slot></slot>
</div>
{:else}
<div class=""your-normal-layout"">
 <slot></slot>
</div>
{/if}
```

I end up with issues using the other method since it modifies the Request stream.",False,0,NONE
https://api.github.com/repos/sveltejs/kit/issues/comments/1229198771,"Support named layouts for the error page, e.g., __error@root.svelte, to remove hardwired dependency on __layout.svelte",Rich-Harris,10,1198272580,9,1229198771,0,1186037317,2022-08-27T14:06:12Z,"I think it's possible that we'll want to add `+error@whatever.svelte` in the future, but in the meantime note that you can now achieve this by putting your app inside a route `(group)` that your `+error.svelte` sits outside of:

```bash
src/routes/
├ (main)
│ ├ foo/
│ ├ bar/
│ ├ etc/
│ ├ +layout.svelte # can safely throw errors in here
│ └ +page.svelte
├ +error.svelte   
└ +layout.svelte   # optional
```",False,0,MEMBER
https://api.github.com/repos/sveltejs/kit/issues/comments/1319197163,"Support named layouts for the error page, e.g., __error@root.svelte, to remove hardwired dependency on __layout.svelte",netfl0,10,1198272580,10,1319197163,0,1229198771,2022-11-17T21:02:26Z,"> 

It appears that the ""named layouts"" feature is gone? 

https://kit.svelte.dev/docs/layouts#named-layouts - I now get a 404

I thought that was one of the slickest features pre ""+layout"" svelte-kit.

",False,0,NONE
https://api.github.com/repos/sveltejs/kit/issues/comments/1319277908,"Support named layouts for the error page, e.g., __error@root.svelte, to remove hardwired dependency on __layout.svelte",madeleineostoja,10,1198272580,11,1319277908,0,1319197163,2022-11-17T22:14:50Z,"Named layouts have been replaced by layout groups, which is a much more powerful and flexible concept. This issue is still open because (afaik) you can't apply certain features of layout groups, namely bailing from the current group with `@...`, to error pages",False,0,NONE
https://api.github.com/repos/sveltejs/kit/issues/4585,Cannot run `npm ci --prod` with adapter-node,angryziber,14,1198986956,1,1198986956,0,0,2022-04-10T11:05:39Z,"### Describe the bug

adapter-node says that `npm ci --prod` should be used to run the build.
However, this command fails

### Reproduction

`npm ci --prod`

### Logs

```shell
> guidest@0.0.1 prepare
> svelte-kit sync

sh: svelte-kit: not found
npm ERR! code 127
npm ERR! path /app
npm ERR! command failed
npm ERR! command sh -c svelte-kit sync

npm ERR! A complete log of this run can be found in:
npm ERR!     /root/.npm/_logs/2022-04-10T11_03_37_215Z-debug.log
The command '/bin/sh -c npm ci --prod' returned a non-zero code: 127
```


### System Info

```
Docker image node:16-alpine
```


### Severity

serious, but I can work around it

### Additional Information

Workaround: `sed -i '/prepare/d' package.json && npm ci --prod`",True,0,NONE
https://api.github.com/repos/sveltejs/kit/issues/comments/1094477325,Cannot run `npm ci --prod` with adapter-node,Conduitry,14,1198986956,2,1094477325,0,1198986956,2022-04-11T02:21:45Z,"I think making the `prepare` script in the template instead be `svelte-kit sync || echo` might work. It looks like the `||` syntax works in Windows cmd.exe as well, and `echo` should be (effectively) a no-op in Unix and Windows. If there's something more elegant than that, I'd love to hear about it. The first thing I tried was `true` and that unfortunately doesn't work in Windows.",False,0,MEMBER
https://api.github.com/repos/sveltejs/kit/issues/comments/1094626946,Cannot run `npm ci --prod` with adapter-node,mrkishi,14,1198986956,3,1094626946,0,1094477325,2022-04-11T07:03:42Z,"Since we're mostly interested in the install behavior (since `build` implicitly runs `sync`), what about running `sync` from `@sveltejs/kit`'s `postinstall` instead?

ps. powershell's `echo` requires an argument, so it'd need to be at least `echo ''`.",False,0,MEMBER
https://api.github.com/repos/sveltejs/kit/issues/comments/1094839555,Cannot run `npm ci --prod` with adapter-node,Conduitry,14,1198986956,4,1094839555,0,1094626946,2022-04-11T09:54:20Z,"I tried this from powershell and the script was still run with cmd.exe. I don't know whether there's some configuration that would have made that work differently.

Having it be in Kit's postinstall would be another option, and that would have been my fallback solution if I couldn't find a cross-platform thing to do in the prepare script, but I imagine it would be more moving pieces.",False,0,MEMBER
https://api.github.com/repos/sveltejs/kit/issues/comments/1095011391,Cannot run `npm ci --prod` with adapter-node,dominikg,14,1198986956,5,1095011391,0,1094839555,2022-04-11T12:51:13Z,"When exactly should sync run. 

Using the prepare lifecycle seems inappropriate for it given it is called during multiple different phases and run in the background since npm@7 . There may be differences in behavior between package managers too, 

https://docs.npmjs.com/cli/v8/using-npm/scripts#life-cycle-scripts

Using postinstall is less invasive than prepare, but is relying on pre/post hooks, which may not be executed. ( due to --ignore-scripts cli flag, pnpm onlyBuiltDependencies option etc).

So if something relies on sync being run before it needs to check that (validate expected files to exist / hash matching) anyways.

",False,0,MEMBER
https://api.github.com/repos/sveltejs/kit/issues/comments/1095125040,Cannot run `npm ci --prod` with adapter-node,mrkishi,14,1198986956,6,1095125040,0,1095011391,2022-04-11T14:29:42Z,"@Conduitry I don't know what's the configuration or combination of shell and package manager required to trigger it, but this is what I get on `pwsh` v7.2.2:

```
F:\projects\svelte\repros\my-app (succeeded in 8ms)
❯ pnpm install --prod --frozen-lockfile
Lockfile is up-to-date, resolution step is skipped
Already up-to-date

devDependencies: skipped

> my-app@0.0.1 prepare F:\projects\svelte\repros\my-app
> svelte-kit sync || echo

svelte-kit: The term 'svelte-kit' is not recognized as a name of a cmdlet, function, script file, or executable program.
Check the spelling of the name, or if a path was included, verify that the path is correct and try again.

cmdlet Write-Output at command pipeline position 1
Supply values for the following parameters:
InputObject:
```

@dominikg `sync` is already run on `dev`/`build`/`package`. The reason for doing it on `prepare` was to get it to run right after installation so that you wouldn't get errors about the missing generated `tsconfig.json` until first build, so I don't think it'd be too bad for it to be skippable.",False,0,MEMBER
https://api.github.com/repos/sveltejs/kit/issues/comments/1095136335,Cannot run `npm ci --prod` with adapter-node,Conduitry,14,1198986956,7,1095136335,0,1095125040,2022-04-11T14:38:57Z,"I agree that erring on the side of not running `sync` is probably preferable.

Having a `postinstall` in `@sveltejs/kit` would also get run when installing dependencies in a checkout of _this_ repo, so we'd need to make sure we made that a no-op in that case. I'm not sure what the CWD is when `postinstall` is run in various cases.

We would potentially need to worry about making `postinstall` a no-op when installing this repo's dependencies, on finding the directory containing `svelte.config.js` when `postinstall` is run as part of installing Kit to a user's app, and on running `svelte-kit sync` with the appropriate CWD.",False,0,MEMBER
https://api.github.com/repos/sveltejs/kit/issues/comments/1095201096,Cannot run `npm ci --prod` with adapter-node,mrkishi,14,1198986956,8,1095201096,0,1095136335,2022-04-11T15:30:43Z,"In theory `cwd` is at the root of the current project, so checking for `svelte.config.js` would indeed be a simple option... In practice, I'm seeing different behavior on `pnpm` (though perhaps because I was testing with a `.tar.gz` instead of a published package).

We do have access to `INIT_CWD` however, and that seems to behave consistently between the big three.",False,0,MEMBER
https://api.github.com/repos/sveltejs/kit/issues/comments/1114037858,Cannot run `npm ci --prod` with adapter-node,johann-taberlet,14,1198986956,9,1114037858,0,1095201096,2022-04-30T19:03:19Z,I'm hitting the same issue. Is there a solution to this ?,False,0,NONE
https://api.github.com/repos/sveltejs/kit/issues/comments/1114038507,Cannot run `npm ci --prod` with adapter-node,dominikg,14,1198986956,10,1114038507,0,1114037858,2022-04-30T19:07:57Z,"As a workaround, remove the `prepare` script from `package.json`. This can lead to errors after updating sveltekit until after you executed `svelte-kit sync`. 

It is automatically called by `svelte-kit dev` and `svelte-kit build` so the worst thing that should happen are some red squigglies in your IDE",False,0,MEMBER
https://api.github.com/repos/sveltejs/kit/issues/comments/1177567995,Cannot run `npm ci --prod` with adapter-node,benmccann,14,1198986956,11,1177567995,0,1114038507,2022-07-07T12:54:28Z,Is `sync` automatically called by `build`? I didn't think it was...,False,0,MEMBER
https://api.github.com/repos/sveltejs/kit/issues/comments/1177695710,Cannot run `npm ci --prod` with adapter-node,Rich-Harris,14,1198986956,12,1177695710,0,1177567995,2022-07-07T14:22:29Z,it is https://github.com/sveltejs/kit/blob/43504ba3ff04313f50fc21a2fe0bcdd774d3dc01/packages/kit/src/vite/index.js#L140,False,0,MEMBER
https://api.github.com/repos/sveltejs/kit/issues/comments/1179187603,Cannot run `npm ci --prod` with adapter-node,benmccann,14,1198986956,13,1179187603,0,1177695710,2022-07-08T16:49:45Z,"Vite tries to read the `tsconfig.json` upfront in order to bundle the config file. I looked at making Vite bundle the config file only if it's `.ts`, but it's not that simple because it uses the `esbuild` output to figure out what the config file dependencies are and I believe watch them to tell if the config file needs to be reloaded. So maybe easier to try to do something just on our side...

I was going to say I'm not sure how `postinstall` would help anything, but I guess it would because `@sveltejs/kit` wouldn't get installed with `npm ci --prod` since it's a `devDependency`. So yeah, that seems like the best solution to me",False,0,MEMBER
https://api.github.com/repos/sveltejs/kit/issues/comments/1200494914,Cannot run `npm ci --prod` with adapter-node,dominikg,14,1198986956,14,1200494914,0,1179187603,2022-07-31T20:32:09Z,"The latest version of @sveltejs/kit now uses a postinstall hook to run sync instead of prepare and `create-svelte` no longer adds a `prepare` script to new applications.

Please check it out and confirm that it fixes this issue you had ",False,0,MEMBER
https://api.github.com/repos/sveltejs/kit/issues/comments/1200495601,Cannot run `npm ci --prod` with adapter-node,Conduitry,14,1198986956,15,1200495601,0,1200494914,2022-07-31T20:36:48Z,"I'm going to go ahead and close this, because it looks good to me now. On a fresh template, `npm install && rm -rf node_modules && npm ci --prod` works fine. Same thing with the equivalent pnpm commands.",False,0,MEMBER
https://api.github.com/repos/LukeSmithxyz/based.cooking/issues/736,No search?,francisdbillones,3,1149933569,1,1149933569,0,0,2022-02-25T01:11:25Z,"Search is the one crucial feature that this site is missing IMO. I understand that you can just CTRL + F, but a search bar is more accessible to everyone, and it would allow searching against the content in each recipe as well, using regular old string matching and some simple document processing techniques such as TF/IDF. Since there's no backend this can easily be done on the client side.",True,0,NONE
https://api.github.com/repos/LukeSmithxyz/based.cooking/issues/comments/1057576443,No search?,tfasano1,3,1149933569,2,1057576443,0,1149933569,2022-03-03T01:44:06Z,"I suggest implementing this and making a pull request, even if it never gets merged other people can choose to use it for their own mirror of based.cooking. Just asking for a feature will usually be a waste of everyone's time.",False,0,CONTRIBUTOR
https://api.github.com/repos/LukeSmithxyz/based.cooking/issues/comments/1089004265,No search?,v0iden,3,1149933569,3,1089004265,0,1057576443,2022-04-05T16:37:58Z,"I agree. Search would be nice. I have no idea how to implement that, though. Would contribute if I could. ",False,0,NONE
https://api.github.com/repos/LukeSmithxyz/based.cooking/issues/comments/1089376254,No search?,tfasano1,3,1149933569,4,1089376254,0,1089004265,2022-04-05T21:27:58Z,"I found this if anyone wants to frankenstein something together: 
https://github.com/akrylysov/simplefts.git",False,0,CONTRIBUTOR
https://api.github.com/repos/LukeSmithxyz/based.cooking/issues/748,Let's revive the project!,v0iden,3,1193482894,1,1193482894,0,0,2022-04-05T17:08:05Z,I think it's a shame that this project died. It had such potential. It's ironic how the simplicity actually made things more complicated in the end. ,True,0,NONE
https://api.github.com/repos/LukeSmithxyz/based.cooking/issues/comments/1098200785,Let's revive the project!,pokemonsta433,3,1193482894,2,1098200785,0,1193482894,2022-04-13T15:36:51Z,"I think the ultimate way to do something like this is an object-oriented app. Have ingredients list be a list of ingredient objects that have a quantity, type, and prep (so ""2 small tomatoes, diced"" becomes {food=tomato; quantity=2; prep=diced; notes=small}) and then you could use this information to create grocery lists (and add ingredients from multiple recipes together), searches, etc. Also if it's an app we can just have the html database be much larger and you just set your custom css and display preferences etc. I plan to make this at *some* point.

But what's the issue with the project as-is? I haven't been following it too closely but the site seems pretty useable",False,0,NONE
https://api.github.com/repos/LukeSmithxyz/based.cooking/issues/comments/1098210837,Let's revive the project!,pokemonsta433,3,1193482894,3,1098210837,0,1098200785,2022-04-13T15:46:28Z,"sry not sure if this was clear enough, but like my idea is that you would basically download recipes (or recipe packs, which might be not even a bad idea) like you would a package with yay. And then you can just query the database of recipes the same way you do any database. That way you can only download/keep recipes you like, so you have a much easier-to-use recipe list  (""like a my-saved recipes"") locally, and we can do vim-like navigation in-app (n for next step in the instructions list, +/- to change text-size, j/k do exactly what you'd expect, etc.). And again the rendering locally means you can do your own ricing for whatever display you want to use (and maybe some way to send to pdf for printing, but that's for not-me to write)",False,0,NONE
https://api.github.com/repos/LukeSmithxyz/based.cooking/issues/comments/1098243572,Let's revive the project!,v0iden,3,1193482894,4,1098243572,0,1098210837,2022-04-13T16:18:26Z,"the project hasn't been updated with new recipes in many months, despite countless pull requests. from what I understand is this because building the website takes a long time for Luke with the current setup. I would def prefer this to stay as a website, I see no point in making it even more niece than it already is. I support the object-oriented part though, I think better machine readability is important regardless.",False,0,NONE
https://api.github.com/repos/LukeSmithxyz/based.cooking/issues/755,Add sardine cakes,tfasano1,3,1206241855,1,1206241855,0,0,2022-04-17T00:05:01Z,,True,0,CONTRIBUTOR
https://api.github.com/repos/LukeSmithxyz/based.cooking/issues/comments/1100864475,Add sardine cakes,LukeSmithxyz,3,1206241855,2,1100864475,0,1206241855,2022-04-17T12:18:22Z,"That image is pretty puny and low quality as to make it unclear what's even in it. Supply a higher res/quality one, otherwise just delete it. Also a missing comma in the json file.",False,0,OWNER
https://api.github.com/repos/LukeSmithxyz/based.cooking/issues/comments/1100908269,Add sardine cakes,LukeSmithxyz,3,1206241855,3,1100908269,0,1100864475,2022-04-17T16:11:37Z,This image still looks like it's been purposefully reduced in quality.,False,0,OWNER
https://api.github.com/repos/LukeSmithxyz/based.cooking/issues/comments/1100924847,Add sardine cakes,tfasano1,3,1206241855,4,1100924847,0,1100908269,2022-04-17T18:02:07Z,"> This image still looks like it's been purposefully reduced in quality.

The next time I make them I'll shoot a pic on my potato flip phone.",False,0,CONTRIBUTOR
https://api.github.com/repos/LukeSmithxyz/based.cooking/issues/759,Multilingual Mode - Hugo,lisbonjoker,3,1208168791,1,1208168791,0,0,2022-04-19T10:46:34Z,"Like my previous suggestion - https://github.com/LukeSmithxyz/based.cooking/issues/666
Introducing localization to based.cooking to be of used to all around the world!

Info: https://gohugo.io/content-management/multilingual/",True,0,CONTRIBUTOR
https://api.github.com/repos/LukeSmithxyz/based.cooking/issues/comments/1157182345,Multilingual Mode - Hugo,ermitxyz,3,1208168791,2,1157182345,0,1208168791,2022-06-16T03:10:59Z,"I was about to suggest just that.
When I show this page to my mother and sister they really like the idea but did't understand english that well and it was a little inconvinient because we don't want to use google translate (this is sadly a common practice).

It would be good for people that don't understand english good enough and also for independence of google services!",False,0,NONE
https://api.github.com/repos/LukeSmithxyz/based.cooking/issues/comments/1168854193,Multilingual Mode - Hugo,LukeSmithxyz,3,1208168791,3,1168854193,0,1157182345,2022-06-28T15:12:46Z,"I can't myself manage this. If you PR stuff that works though, I'll consider it. Just don't expect me to do this myself, especially for languages I don't know.

There are some other metadata issues I think should be Hugoized, like prep time and stuff before adding a whole nother version of the site.",False,0,OWNER
https://api.github.com/repos/LukeSmithxyz/based.cooking/issues/comments/1169907626,Multilingual Mode - Hugo,lisbonjoker,3,1208168791,4,1169907626,0,1168854193,2022-06-29T12:15:16Z,"Will work on it then, I'll handle Portuguese language. ",False,0,CONTRIBUTOR
https://api.github.com/repos/vuetifyjs/vuetify/issues/14972,Fix(VMenu): wrong item highlighted,kglazier,4,1210146025,1,1210146025,0,0,2022-04-20T19:54:48Z,"<!--
MAKE SURE TO READ THE CONTRIBUTING GUIDE BEFORE CREATING A PR
https://vuetifyjs.com/getting-started/contributing

Testing and markup sections can be removed for documentation changes
-->

<!-- Provide a general summary of your changes in the Title above -->
<!-- Keep the title short and descriptive, as it will be used as a commit message -->

<!-- We use conventional-changelog-angular for all commit structures -->
<!-- https://vuetifyjs.com/getting-started/contributing#commit-guidelines-w-commitizen -->


## Description
Fix Wrong item highlighted when using prepend-item slot on v-select. Exclude prepend items from the list of options by returning only valid selection options for highlight.  Don't highlight option when deselecting.
<!-- Describe your changes in detail -->
<!-- Note any issues that are resolved by this PR -->
<!-- e.g. resolves #4213 or fixes #2312 -->

## Motivation and Context
resolves #14489 
<!-- Why is this change required? What problem does it solve? -->
<!-- If it fixes an open issue, please link to the issue here. -->

## How Has This Been Tested?
Manually tested using the playground.vue code below.  This code is taken from the vuetify select component page
https://vuetifyjs.com/en/components/selects/#append-and-prepend-item
<!-- All PR's should implement unit tests if possible -->
<!-- Please describe how you tested your changes. -->
<!-- Have you created new tests or updated existing ones? -->
<!-- e.g. unit | visually | e2e | none -->

## Markup:
<!-- Information on how to setup your local development environment can be found here: -->
<!-- https://vuetifyjs.com/getting-started/contributing#setup-dev-environment -->

<!-- Paste markup for testing your change --->
<details>

```vue
<template>
  <div>
    <v-row justify=""space-around"">
      <v-switch
        v-model=""dense""
        label=""Dense""
      ></v-switch>
      <v-switch
        v-model=""selectable""
        label=""Selectable""
      ></v-switch>
      <v-switch
        v-model=""activatable""
        label=""Activatable""
      ></v-switch>
      <v-switch
        v-model=""hoverable""
        label=""Hoverable""
      ></v-switch>
      <v-switch
        v-model=""shaped""
        label=""Shaped""
      ></v-switch>
      <v-switch
        v-model=""rounded""
        label=""Rounded""
      ></v-switch>
      <v-switch
        v-model=""openOnClick""
        label=""Open on any item click""
      ></v-switch>
      <v-col cols=""12"">
        <v-select
          v-model=""selectedColor""
          :items=""selectedColors""
          :disabled=""!selectable""
          label=""Selected checkbox color""
        ></v-select>
      </v-col>
      <v-col cols=""12"">
        <v-select
          v-model=""color""
          :items=""selectedColors""
          :disabled=""!activatable""
          label=""Active node color""
        ></v-select>
      </v-col>
    </v-row>

    <v-treeview
      :items=""items""
      :dense=""dense""
      :selectable=""selectable""
      :activatable=""activatable""
      :hoverable=""hoverable""
      :open-on-click=""openOnClick""
      :selected-color=""selectedColor""
      :color=""color""
      :shaped=""shaped""
      :rounded=""rounded""
    ></v-treeview>
  </div>
</template>

<script>
  export default {
    data: () => ({
      items: [
        {
          id: 1,
          name: 'Applications :',
          children: [
            { id: 2, name: 'Calendar : app' },
            { id: 3, name: 'Chrome : app' },
            { id: 4, name: 'Webstorm : app' },
          ],
        },
        {
          id: 5,
          name: 'Documents :',
          children: [
            {
              id: 6,
              name: 'vuetify :',
              children: [
                {
                  id: 7,
                  name: 'src :',
                  children: [
                    { id: 8, name: 'index : ts' },
                    { id: 9, name: 'bootstrap : ts' },
                  ],
                },
              ],
            },
            {
              id: 10,
              name: 'material2 :',
              children: [
                {
                  id: 11,
                  name: 'src :',
                  children: [
                    { id: 12, name: 'v-btn : ts' },
                    { id: 13, name: 'v-card : ts' },
                    { id: 14, name: 'v-window : ts' },
                  ],
                },
              ],
            },
          ],
        },
        {
          id: 15,
          name: 'Downloads :',
          children: [
            { id: 16, name: 'October : pdf' },
            { id: 17, name: 'November : pdf' },
            { id: 18, name: 'Tutorial : html' },
          ],
        },
        {
          id: 19,
          name: 'Videos :',
          children: [
            {
              id: 20,
              name: 'Tutorials :',
              children: [
                { id: 21, name: 'Basic layouts : mp4' },
                { id: 22, name: 'Advanced techniques : mp4' },
                { id: 23, name: 'All about app : dir' },
              ],
            },
            { id: 24, name: 'Intro : mov' },
            { id: 25, name: 'Conference introduction : avi' },
          ],
        },
      ],
      dense: false,
      selectable: false,
      activatable: false,
      hoverable: false,
      openOnClick: false,
      shaped: false,
      rounded: false,
      color: 'primary',
      selectedColor: 'accent',
      selectedColors: [
        'accent',
        'teal',
        'red',
        'success',
        'warning lighten-2',
      ],
    }),
  }
</script>

```
</details>

## Types of changes
<!-- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->
- [x] Bug fix (non-breaking change which fixes an issue)
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] Improvement/refactoring (non-breaking change that doesn't add any features but makes things better)

## Checklist:
<!-- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!-- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [x] The PR title is no longer than 64 characters.
- [x] The PR is submitted to the correct branch (`master` for bug fixes and documentation updates, `dev` for new features and backwards compatible changes and `next` for non-backwards compatible changes).
- [x] My code follows the code style of this project.
- [x] I've added relevant changes to the documentation (applies to new features and breaking changes in core library)
",True,0,NONE
https://api.github.com/repos/vuetifyjs/vuetify/issues/comments/1113605059,Fix(VMenu): wrong item highlighted,kglazier,4,1210146025,2,1113605059,0,1210146025,2022-04-29T18:33:10Z,Retested with keyboard and with mouse on both treeview and regular menu.,False,0,NONE
https://api.github.com/repos/vuetifyjs/vuetify/issues/comments/1238448488,Fix(VMenu): wrong item highlighted,joel-wenzel,4,1210146025,3,1238448488,0,1113605059,2022-09-06T17:22:43Z,Was this PR still waiting on changes?,False,0,CONTRIBUTOR
https://api.github.com/repos/vuetifyjs/vuetify/issues/comments/1238477512,Fix(VMenu): wrong item highlighted,kglazier,4,1210146025,4,1238477512,0,1238448488,2022-09-06T17:54:25Z,No more changes have been requested. I requested another review.,False,0,NONE
https://api.github.com/repos/vuetifyjs/vuetify/issues/comments/1243760358,Fix(VMenu): wrong item highlighted,joel-wenzel,4,1210146025,5,1243760358,0,1238477512,2022-09-12T13:40:01Z,@KaelWD Do you have time to take another look at the changes?,False,0,CONTRIBUTOR
https://api.github.com/repos/vuetifyjs/vuetify/issues/14983,[Bug Report][3.0.0-beta.0] v-footer: fixed attribute doesn't seem to work,Shujee,3,1213454450,1,1213454450,0,0,2022-04-23T21:04:07Z,"### Environment
**Vuetify Version:** 3.0.0-beta.0
**Vue Version:** 3.2.13
**Browsers:** Edge 100.0.1185.44
**OS:** Windows 10

### Steps to reproduce
Just place a `v-footer` with `fixed` attribute in a default Vuetify 3 beta based project in any view, or even `v-app` itself. The footer doesn't stick to the bottom of the browser window and is placed in a weird location.

### Expected Behavior
When using `fixed`, `v-footer` should stick to bottom of the window, covering from left to right.

### Actual Behavior
`v-footer` is placed in regular flow (probably) and is as wide as its content.

### Reproduction Link
<a href=""https://codepen.io/shujee/pen/JjMzJeK"" target=""_blank"">https://codepen.io/shujee/pen/JjMzJeK</a>


<!-- generated by vuetify-issue-helper. DO NOT REMOVE -->",True,0,NONE
https://api.github.com/repos/vuetifyjs/vuetify/issues/comments/1107782072,[Bug Report][3.0.0-beta.0] v-footer: fixed attribute doesn't seem to work,Rhilip,3,1213454450,2,1107782072,0,1213454450,2022-04-24T07:44:41Z,Also the `app` atribute in `v-footer` is not work.,False,0,NONE
https://api.github.com/repos/vuetifyjs/vuetify/issues/comments/1108093154,[Bug Report][3.0.0-beta.0] v-footer: fixed attribute doesn't seem to work,iamKyun,3,1213454450,3,1108093154,0,1107782072,2022-04-25T05:26:50Z,"
> Also the `app` atribute in `v-footer` is not work.

Seems also the `inset` atribute ",False,0,NONE
https://api.github.com/repos/vuetifyjs/vuetify/issues/comments/1175266569,[Bug Report][3.0.0-beta.0] v-footer: fixed attribute doesn't seem to work,johnleider,3,1213454450,4,1175266569,0,1108093154,2022-07-05T16:42:14Z,"Here are some examples of how to do this now: https://codepen.io/johnjleider/pen/vYRNMGw

fixed by [893ff06](https://github.com/vuetifyjs/vuetify/commit/893ff065c674082cf115b06f6e225f3de9f78f6f)",False,0,MEMBER
https://api.github.com/repos/vuetifyjs/vuetify/issues/14986,Update globals.ts,nopeless,7,1213607968,1,1213607968,0,0,2022-04-24T10:04:06Z,"globals.ts:3 Uncaught TypeError: Cannot read properties of undefined (reading 'DEBUG')

<!--
MAKE SURE TO READ THE CONTRIBUTING GUIDE BEFORE CREATING A PR
https://vuetifyjs.com/getting-started/contributing

Testing and markup sections can be removed for documentation changes
-->

<!-- Provide a general summary of your changes in the Title above -->
<!-- Keep the title short and descriptive, as it will be used as a commit message -->

<!-- We use conventional-changelog-angular for all commit structures -->
<!-- https://vuetifyjs.com/getting-started/contributing#commit-guidelines-w-commitizen -->


## Description
<!-- Describe your changes in detail -->
<!-- Note any issues that are resolved by this PR -->
<!-- e.g. resolves #4213 or fixes #2312 -->

## Motivation and Context
<!-- Why is this change required? What problem does it solve? -->
<!-- If it fixes an open issue, please link to the issue here. -->

## How Has This Been Tested?
<!-- All PR's should implement unit tests if possible -->
<!-- Please describe how you tested your changes. -->
<!-- Have you created new tests or updated existing ones? -->
<!-- e.g. unit | visually | e2e | none -->

## Markup:
<!-- Information on how to setup your local development environment can be found here: -->
<!-- https://vuetifyjs.com/getting-started/contributing#setup-dev-environment -->

<!-- Paste markup for testing your change --->
<details>

```vue
// Paste your FULL Playground.vue here
```
</details>

## Types of changes
<!-- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->
- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] Improvement/refactoring (non-breaking change that doesn't add any features but makes things better)

## Checklist:
<!-- Go over all the following points, and put an `x` in all the boxes that apply. -->
<!-- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->
- [ ] The PR title is no longer than 64 characters.
- [ ] The PR is submitted to the correct branch (`master` for bug fixes and documentation updates, `dev` for new features and backwards compatible changes and `next` for non-backwards compatible changes).
- [ ] My code follows the code style of this project.
- [ ] I've added relevant changes to the documentation (applies to new features and breaking changes in core library)
",True,0,NONE
https://api.github.com/repos/vuetifyjs/vuetify/issues/comments/1119844354,Update globals.ts,nopeless,7,1213607968,2,1119844354,0,1213607968,2022-05-06T17:39:18Z,Can I have a response ,False,0,NONE
https://api.github.com/repos/vuetifyjs/vuetify/issues/comments/1121346495,Update globals.ts,KaelWD,7,1213607968,3,1121346495,0,1119844354,2022-05-09T16:57:33Z,process.env is always defined in node,False,0,MEMBER
https://api.github.com/repos/vuetifyjs/vuetify/issues/comments/1124513011,Update globals.ts,nopeless,7,1213607968,4,1124513011,0,1121346495,2022-05-12T04:16:56Z,"Well this error pops up in a browser
do you need a reproduction @KaelWD ",False,0,NONE
https://api.github.com/repos/vuetifyjs/vuetify/issues/comments/1134952165,Update globals.ts,nopeless,7,1213607968,5,1134952165,0,1124513011,2022-05-23T17:33:10Z,"I looked into the issue again and I found out this issue is reproducable. Please correct me if I'm doing something wrong.

https://stackblitz.com/edit/nuxt-starter-z12gzz?file=package.json,app.vue,nuxt.config.ts",False,0,NONE
https://api.github.com/repos/vuetifyjs/vuetify/issues/comments/1134952351,Update globals.ts,nopeless,7,1213607968,6,1134952351,0,1134952165,2022-05-23T17:33:23Z,@KaelWD ,False,0,NONE
https://api.github.com/repos/vuetifyjs/vuetify/issues/comments/1134966539,Update globals.ts,KaelWD,7,1213607968,7,1134966539,0,1134952351,2022-05-23T17:48:54Z,"Yeah nice, nuxt are defining `process` in the browser without any of the actual properties: https://nuxtjs.org/pt/docs/concepts/context-helpers#process-helpers
Turns out those two are unused anyway, I've just removed them instead. ",False,0,MEMBER
https://api.github.com/repos/vuetifyjs/vuetify/issues/comments/1135363701,Update globals.ts,nopeless,7,1213607968,8,1135363701,0,1134966539,2022-05-24T03:31:55Z,so the issue is resolved in the next release candidate? @KaelWD ,False,0,NONE
https://api.github.com/repos/vuetifyjs/vuetify/issues/14987,fix(VDataTable): add class to root element when show-select,keyhan-va,4,1213629139,1,1213629139,0,0,2022-04-24T11:36:22Z,"## Description
add v-data-table--selectable class to VDataTable when show-select props are true

## Motivation and Context
By adding this class, it is possible to create custom tables when there is a show-select prop

## How Has This Been Tested?
add v-data-table--selectable class to VDataTable when show-select props are true 
an updated existing test


<!-- Paste markup for testing your change --->
<details>

```vue
// Paste your FULL Playground.vue here
<template>
  <v-data-table
    v-model=""selected""
    :headers=""headers""
    :items=""desserts""
    :single-select=""singleSelect""
    item-key=""name""
    show-select
    class=""elevation-1""
  >
    <template v-slot:top>
      <v-switch
        v-model=""singleSelect""
        label=""Single select""
        class=""pa-3""
      ></v-switch>
    </template>
  </v-data-table>
</template>

<script>
  export default {
    data () {
      return {
        singleSelect: false,
        selected: [],
        headers: [
          {
            text: 'Dessert (100g serving)',
            align: 'start',
            sortable: false,
            value: 'name',
          },
          { text: 'Calories', value: 'calories' },
          { text: 'Fat (g)', value: 'fat' },
          { text: 'Carbs (g)', value: 'carbs' },
          { text: 'Protein (g)', value: 'protein' },
          { text: 'Iron (%)', value: 'iron' },
        ],
        desserts: [
          {
            name: 'Frozen Yogurt',
            calories: 159,
            fat: 6.0,
            carbs: 24,
            protein: 4.0,
            iron: '1%',
          },
          {
            name: 'Ice cream sandwich',
            calories: 237,
            fat: 9.0,
            carbs: 37,
            protein: 4.3,
            iron: '1%',
          },
          {
            name: 'Eclair',
            calories: 262,
            fat: 16.0,
            carbs: 23,
            protein: 6.0,
            iron: '7%',
          },
          {
            name: 'Cupcake',
            calories: 305,
            fat: 3.7,
            carbs: 67,
            protein: 4.3,
            iron: '8%',
          },
          {
            name: 'Gingerbread',
            calories: 356,
            fat: 16.0,
            carbs: 49,
            protein: 3.9,
            iron: '16%',
          },
          {
            name: 'Jelly bean',
            calories: 375,
            fat: 0.0,
            carbs: 94,
            protein: 0.0,
            iron: '0%',
          },
          {
            name: 'Lollipop',
            calories: 392,
            fat: 0.2,
            carbs: 98,
            protein: 0,
            iron: '2%',
          },
          {
            name: 'Honeycomb',
            calories: 408,
            fat: 3.2,
            carbs: 87,
            protein: 6.5,
            iron: '45%',
          },
          {
            name: 'Donut',
            calories: 452,
            fat: 25.0,
            carbs: 51,
            protein: 4.9,
            iron: '22%',
          },
          {
            name: 'KitKat',
            calories: 518,
            fat: 26.0,
            carbs: 65,
            protein: 7,
            iron: '6%',
          },
        ],
      }
    },
  }
</script>

```
</details>

## Types of changes
<!-- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->
- [ ] Bug fix (non-breaking change which fixes an issue)
- [x] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] Improvement/refactoring (non-breaking change that doesn't add any features but makes things better)

## Checklist:
- [x] The PR title is no longer than 64 characters.
- [x] The PR is submitted to the correct branch (`master` for bug fixes and documentation updates, `dev` for new features and backwards compatible changes and `next` for non-backwards compatible changes).
- [x] My code follows the code style of this project.
- [x] I've added relevant changes to the documentation (applies to new features and breaking changes in core library)
",True,0,NONE
https://api.github.com/repos/vuetifyjs/vuetify/issues/comments/1108745729,fix(VDataTable): add class to root element when show-select,johnleider,4,1213629139,2,1108745729,0,1213629139,2022-04-25T15:48:18Z,@nekosaur are we considering features for v2.x?,False,0,MEMBER
https://api.github.com/repos/vuetifyjs/vuetify/issues/comments/1120399380,fix(VDataTable): add class to root element when show-select,keyhan-va,4,1213629139,3,1120399380,0,1108745729,2022-05-08T11:19:44Z,@johnleider we need this feature in production v2.x,False,0,NONE
https://api.github.com/repos/vuetifyjs/vuetify/issues/comments/1120405388,fix(VDataTable): add class to root element when show-select,nekosaur,4,1213629139,4,1120405388,0,1120399380,2022-05-08T12:00:32Z,"What's stopping you from doing this?

```html
<v-data-table
  show-select
  class=""v-data-table--selectable""
/>
```",False,0,MEMBER
https://api.github.com/repos/vuetifyjs/vuetify/issues/comments/1122344694,fix(VDataTable): add class to root element when show-select,keyhan-va,4,1213629139,5,1122344694,0,1120405388,2022-05-10T12:46:00Z,"@nekosaur 
On production, we have a product that used a lot of tables, we need to this class put in them.
According to It's not clear that; which one is able to select or not,
So we added this class. Adding this class to the data table  can be improved
",False,0,NONE
https://api.github.com/repos/sherlock-project/sherlock/issues/1313,how i install this process ,M-warrior,5,1212344352,1,1212344352,0,0,2022-04-22T13:10:56Z,"<!--

######################################################################
  WARNING!
  IGNORING THE FOLLOWING TEMPLATE WILL RESULT IN ISSUE CLOSED AS INCOMPLETE.
######################################################################

-->

## Checklist
<!--
Put x into all boxes (like this [x]) once you have completed what they say.
Make sure complete everything in the checklist.
-->
- [x] I'm asking a question regarding Sherlock
- [x] My question is not a tech support question.

**We are not your tech support**. 
If you have questions related to `pip`, `git`, or something that is not related to Sherlock, please ask them on [Stack Overflow](https://stackoverflow.com/) or [r/learnpython](https://www.reddit.com/r/learnpython/)


## Question

ASK YOUR QUESTION HERE
",True,0,NONE
https://api.github.com/repos/sherlock-project/sherlock/issues/comments/1106501257,how i install this process ,M-warrior,5,1212344352,2,1106501257,0,1212344352,2022-04-22T13:12:11Z,can you give me the direct download link?,False,0,NONE
https://api.github.com/repos/sherlock-project/sherlock/issues/comments/1107134857,how i install this process ,Jhonatanbb,5,1212344352,3,1107134857,0,1106501257,2022-04-23T01:11:49Z,#1254 ,False,0,NONE
https://api.github.com/repos/sherlock-project/sherlock/issues/comments/1120153866,how i install this process ,SethFalco,5,1212344352,4,1120153866,0,1107134857,2022-05-07T07:18:35Z,"Read here please:
https://github.com/sherlock-project/sherlock/discussions/1254#discussioncomment-2704932",False,0,CONTRIBUTOR
https://api.github.com/repos/sherlock-project/sherlock/issues/comments/1120341383,how i install this process ,jamieu187,5,1212344352,5,1120341383,0,1120153866,2022-05-08T03:18:44Z,"Omg I am sorry I dont know what the he'll I am doing on here

On Sat, May 7, 2022, 2:19 AM Seth Falco ***@***.***> wrote:

> Read here please:
> #1254 (comment)
> <https://github.com/sherlock-project/sherlock/discussions/1254#discussioncomment-2704932>
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/sherlock-project/sherlock/issues/1313#issuecomment-1120153866>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ASFMM7UOUYFH3RNQI2JISKDVIYKQ3ANCNFSM5UCJBXGQ>
> .
> You are receiving this because you are subscribed to this thread.Message
> ID: ***@***.***>
>
",False,0,NONE
https://api.github.com/repos/sherlock-project/sherlock/issues/comments/1120341445,how i install this process ,jamieu187,5,1212344352,6,1120341445,0,1120341383,2022-05-08T03:19:29Z,"Anything will help thank you

On Sat, May 7, 2022, 10:18 PM Jamie Ussia ***@***.***> wrote:

> Omg I am sorry I dont know what the he'll I am doing on here
>
> On Sat, May 7, 2022, 2:19 AM Seth Falco ***@***.***> wrote:
>
>> Read here please:
>> #1254 (comment)
>> <https://github.com/sherlock-project/sherlock/discussions/1254#discussioncomment-2704932>
>>
>> —
>> Reply to this email directly, view it on GitHub
>> <https://github.com/sherlock-project/sherlock/issues/1313#issuecomment-1120153866>,
>> or unsubscribe
>> <https://github.com/notifications/unsubscribe-auth/ASFMM7UOUYFH3RNQI2JISKDVIYKQ3ANCNFSM5UCJBXGQ>
>> .
>> You are receiving this because you are subscribed to this thread.Message
>> ID: ***@***.***>
>>
>
",False,0,NONE
https://api.github.com/repos/sherlock-project/sherlock/issues/1331,Code error line 196 21 & 20.,chuckcarne,7,1225627893,1,1225627893,0,0,2022-05-04T16:48:45Z,"Yo i tried to run the stuff normally it worked before and it gave me this error:


raceback (most recent call last):
  File ""/usr/lib/python3.10/runpy.py"", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File ""/usr/lib/python3.10/runpy.py"", line 86, in _run_code
    exec(code, run_globals)
  File ""/home/Clinets/sherlock/sherlock/__main__.py"", line 21, in <module>
    import sherlock
  File ""/home/charles/sherlock/sherlock/sherlock.py"", line 20, in <module>
    from requests_futures.sessions import FuturesSession
ModuleNotFoundError: No module named 'requests_futures'
",True,0,NONE
https://api.github.com/repos/sherlock-project/sherlock/issues/comments/1119185962,Code error line 196 21 & 20.,bslisowski,7,1225627893,2,1119185962,0,1225627893,2022-05-06T01:34:18Z,pip install requests-futures,False,0,NONE
https://api.github.com/repos/sherlock-project/sherlock/issues/comments/1119187536,Code error line 196 21 & 20.,chuckcarne,7,1225627893,3,1119187536,0,1119185962,2022-05-06T01:38:56Z,"got this code now 

pip install requests-futures
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: requests-futures in /home/charles/.local/lib/python3.10/site-packages (1.0.0)
Requirement already satisfied: requests>=1.2.0 in /usr/lib/python3/dist-packages (from requests-futures) (2.25.1)
",False,0,NONE
https://api.github.com/repos/sherlock-project/sherlock/issues/comments/1119191100,Code error line 196 21 & 20.,bslisowski,7,1225627893,4,1119191100,0,1119187536,2022-05-06T01:50:07Z,"try installing sherlock again
",False,0,NONE
https://api.github.com/repos/sherlock-project/sherlock/issues/comments/1119194240,Code error line 196 21 & 20.,chuckcarne,7,1225627893,5,1119194240,0,1119191100,2022-05-06T01:59:34Z,1 step ahead didn't work,False,0,NONE
https://api.github.com/repos/sherlock-project/sherlock/issues/comments/1120291199,Code error line 196 21 & 20.,ghost,7,1225627893,6,1120291199,0,1119194240,2022-05-07T21:11:05Z,"> got this code now
> 
> pip install requests-futures Defaulting to user installation because normal site-packages is not writeable Requirement already satisfied: requests-futures in /home/charles/.local/lib/python3.10/site-packages (1.0.0) Requirement already satisfied: requests>=1.2.0 in /usr/lib/python3/dist-packages (from requests-futures) (2.25.1)

You may have multiple versions of Python installed. Use python3 -m pip and then pip, see which one works. If you are on Windows, use python instead of python3.",False,0,NONE
https://api.github.com/repos/sherlock-project/sherlock/issues/comments/1176544633,Code error line 196 21 & 20.,rudrakshkarpe,7,1225627893,7,1176544633,0,1120291199,2022-07-06T18:32:17Z," ## You can try creating a ```virtual environment``` and try running ``` sherlock ```
 ---
 ### FOR LINUX/MAC
---
-  installing venv 
```sudo apt-get install python3.6-venv```
- creating virtual env
```python3 -m venv env```
- activating virtual env
```source env/bin/activate ```
---
### FOR WINDOWS
---
- installing venv
``` py -m pip install --user virtualenv ```
- creating virtual env
```py -m venv env```
- activating virtual env
```.\env\Scripts\activate```",False,0,NONE
https://api.github.com/repos/sherlock-project/sherlock/issues/comments/1176555920,Code error line 196 21 & 20.,chuckcarne,7,1225627893,8,1176555920,0,1176544633,2022-07-06T18:44:50Z,"it's alright the parrot os security one works fine.

On Wed, Jul 6, 2022 at 12:32 PM Rudraksh Karpe ***@***.***>
wrote:

> You can try creating a virtual environment and try running sherlock
> ------------------------------
> FOR LINUX/MAC
> ------------------------------
>
>    - installing venv
>    sudo apt-get install python3.6-venv
>    - creating virtual env
>    python3 -m venv env
>    - activating virtual env
>    source env/bin/activate
>
> ------------------------------
> FOR WINDOWS
> ------------------------------
>
>    - installing venv
>    py -m pip install --user virtualenv
>    - creating virtual env
>    py -m venv env
>    - activating virtual env
>    .\env\Scripts\activate
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/sherlock-project/sherlock/issues/1331#issuecomment-1176544633>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AXCPEZRO4JSHR2XD2MMEXNTVSXGL5ANCNFSM5VCRZ36A>
> .
> You are receiving this because you authored the thread.Message ID:
> ***@***.***>
>
",False,0,NONE
https://api.github.com/repos/sherlock-project/sherlock/issues/1367,add xlsx file option by using --xlsx parameter ,aristosgi,7,1264792351,1,1264792351,0,0,2022-06-08T13:54:18Z,"Complete issue #1366

In this pull request i modified the following files:

1) requirments.txt i added pandas to requirments
2) Sherlock.py i added parses .xlsx and create a method to export the result as xlxs file if the user use the --xlsx parameter
3).gitignore add *.xlxs in order not to add result files into github",True,0,CONTRIBUTOR
https://api.github.com/repos/sherlock-project/sherlock/issues/comments/1153103121,add xlsx file option by using --xlsx parameter ,TheYahya,7,1264792351,2,1153103121,0,1264792351,2022-06-12T08:35:50Z,"Hey @aristosgi,
Nice idea, I get this error thought when trying to run this:
![Screen Shot 2022-06-12 at 11 34 58](https://user-images.githubusercontent.com/15307244/173224729-5a306da5-4390-45ed-8923-05736b142d3f.png)

",False,0,MEMBER
https://api.github.com/repos/sherlock-project/sherlock/issues/comments/1153112971,add xlsx file option by using --xlsx parameter ,aristosgi,7,1264792351,3,1153112971,0,1153103121,2022-06-12T09:28:39Z,"On my computer with out problem

<img width=""1141"" alt=""image"" src=""https://user-images.githubusercontent.com/72870283/173226940-103e467a-8352-496c-8df4-d07e59688d27.png"">


<img width=""841"" alt=""image"" src=""https://user-images.githubusercontent.com/72870283/173226814-47a78634-9cf1-4579-8178-8fdedd218bdc.png"">

I use python3 i dont know if this is our problem.
",False,0,CONTRIBUTOR
https://api.github.com/repos/sherlock-project/sherlock/issues/comments/1153117367,add xlsx file option by using --xlsx parameter ,TheYahya,7,1264792351,4,1153117367,0,1153112971,2022-06-12T09:49:28Z,Are you sure that the `requirements.txt` is updated?,False,0,MEMBER
https://api.github.com/repos/sherlock-project/sherlock/issues/comments/1153117926,add xlsx file option by using --xlsx parameter ,aristosgi,7,1264792351,5,1153117926,0,1153117367,2022-06-12T09:52:44Z,I have added pandas.The last commit was fail i didnt do anything.,False,0,CONTRIBUTOR
https://api.github.com/repos/sherlock-project/sherlock/issues/comments/1157523764,add xlsx file option by using --xlsx parameter ,aristosgi,7,1264792351,6,1157523764,0,1153117926,2022-06-16T10:56:26Z,"@TheYahya Hello , i just added openpyxl to requirments.txt . I think that this was your problem.This works on my pc with  python3. If the problem remains let me know.Thanks for your time.",False,0,CONTRIBUTOR
https://api.github.com/repos/sherlock-project/sherlock/issues/comments/1158174179,add xlsx file option by using --xlsx parameter ,TheYahya,7,1264792351,7,1158174179,0,1157523764,2022-06-16T21:59:40Z,"Hey @aristosgi, This is my python version `Python 3.9.12`
Make sure that an venv or isolated environment like docker and check it's work for you with same `requirements.txt`.
 
I know that it's hard to debug without being able to reproduce the bug. but I can't merge this until I'm not able to run it!

![Screen Shot 2022-06-17 at 00 58 05](https://user-images.githubusercontent.com/15307244/174177113-05aee683-d1fc-41ff-a73e-f4c342ccdf93.png)
",False,0,MEMBER
https://api.github.com/repos/sherlock-project/sherlock/issues/comments/1158969331,add xlsx file option by using --xlsx parameter ,aristosgi,7,1264792351,8,1158969331,0,1158174179,2022-06-17T15:11:40Z,"Hello @TheYahya ,

I managed to isolate the requirments and find out whats wrong.The openpyxl was a lower version.I change it and i tested it on a isolated environment and worked fine.

Thanks for your help and your time.",False,0,CONTRIBUTOR
https://api.github.com/repos/sherlock-project/sherlock/issues/1371,Important ,MR-EHAB11,5,1269755152,1,1269755152,0,0,2022-06-13T17:42:15Z,"<!--

######################################################################
  WARNING!
  IGNORING THE FOLLOWING TEMPLATE WILL RESULT IN ISSUE CLOSED AS INCOMPLETE
######################################################################

-->


## Checklist
<!--
Put x into all boxes (like this [x]) once you have completed what they say.
Make sure complete everything in the checklist.
-->

- [x] I'm reporting a bug in Sherlock's functionality
- [x] The bug I'm reporting is not a false positive or a false negative
- [x] I've verified that I'm running the latest version of Sherlock
- [x] I've checked for similar bug reports including closed ones
- [x] I've checked for pull requests that attempt to fix this bug

## Description
<!--
Provide a detailed description of the bug that you have found in Sherlock.
Provide the version of Sherlock you are running.
-->

WRITE DESCRIPTION HERE
",True,0,NONE
https://api.github.com/repos/sherlock-project/sherlock/issues/comments/1173594957,Important ,0xdavidel,5,1269755152,2,1173594957,0,1269755152,2022-07-04T09:40:41Z,"Dummy issue, you can delete this.",False,0,CONTRIBUTOR
https://api.github.com/repos/sherlock-project/sherlock/issues/comments/1175842083,Important ,pablodz,5,1269755152,3,1175842083,0,1173594957,2022-07-06T06:44:07Z,???,False,0,NONE
https://api.github.com/repos/sherlock-project/sherlock/issues/comments/1182194526,Important ,MR-EHAB11,5,1269755152,4,1182194526,0,1175842083,2022-07-12T18:23:25Z,"> ???

I am sorry for what...? asked...",False,0,NONE
https://api.github.com/repos/sherlock-project/sherlock/issues/comments/1182195455,Important ,MR-EHAB11,5,1269755152,5,1182195455,0,1182194526,2022-07-12T18:23:49Z,"> Dummy issue, you can delete this.

Why......?",False,0,NONE
https://api.github.com/repos/sherlock-project/sherlock/issues/comments/1183439447,Important ,0xdavidel,5,1269755152,6,1183439447,0,1182195455,2022-07-13T16:34:01Z,"Because you didnt add any content, your issue still has the ""WRITE DESCRIPTION HERE""",False,0,CONTRIBUTOR
https://api.github.com/repos/TryGhost/Ghost/issues/14635,"""Unknown SSL profile"" for self-host using MySQL with SSL after mysql2 package update (v4.38+)",stefann42,8,1222266778,1,1222266778,0,0,2022-05-01T19:52:28Z,"### Issue Summary

Prior to this change https://github.com/TryGhost/Ghost/commit/bf6f607f424106c1973b09dd47f62c1b972b2ae6 self-hosters who connect to MySQL 5.7 using SSL were able to use this config as as discussed at https://forum.ghost.org/t/configure-mysql-over-tls-ssl/2297/8

```
“database”: {
  “client”: “mysql”,
  “connection”: {
    “host”: “127.0.0.1”,
    “user”: “user”,
    “password”: “pass”,
    “database”: “ghostdb”,
    “ssl”: {
      “rejectUnauthorized”: “true”,
      “secureProtocol”: “TLSv1_2_method”
    }
  }
}
```

Upgrading past v4.37 breaks Ghost (node app cannot start) with the error 
`Unknown SSL profile ""{ 'rejectUnauthorized':'true', 'secureProtocol':'TLSv1_2_method'}""`

We need to understand what's the correct SSL config for mysql2 library. This is possibly an issue for downstream dependencies.

Relevant code from downstream dependencies:

- How mysql2 parses config
https://github.com/sidorares/node-mysql2/blob/d74558b605162156b813248a024f7559785de6fb/lib/connection_config.js#L119
- And make sure you use a version of knex dependency that includes this fix https://github.com/knex/knex/issues/4628

### Steps to Reproduce

1. Install self-host v4.38 of later
2. Try to use SSL config documented at https://forum.ghost.org/t/configure-mysql-over-tls-ssl/2297/8

### Ghost Version

>=4.38

### Node.js Version

14.x

### How did you install Ghost?

Using instructions at https://ghost.org/docs/hosting/

### Database type

MySQL 5.7

### Browser & OS version

_No response_

### Relevant log / error output

```shell
DatabaseError: Unknown SSL profile '{ 'rejectUnauthorized': 'true', 'secureProtocol': 'TLSv1_2_method' }'
at DatabaseStateManager.getState (/var/lib/ghost/versions/4.44.0/core/server/data/db/state-manager.js:64:32)
at DatabaseError.KnexMigrateError (/var/lib/ghost/versions/4.44.0/node_modules/knex-migrator/lib/errors.js:7:26)
at new DatabaseError (/var/lib/ghost/versions/4.44.0/node_modules/knex-migrator/lib/errors.js:55:26)
at /var/lib/ghost/versions/4.44.0/node_modules/knex-migrator/lib/database.js:57:19
at async DatabaseStateManager.getState (/var/lib/ghost/versions/4.44.0/core/server/data/db/state-manager.js:40:13)
at async DatabaseStateManager.makeReady (/var/lib/ghost/versions/4.44.0/core/server/data/db/state-manager.js:73:25)
at async initDatabase (/var/lib/ghost/versions/4.44.0/core/boot.js:69:5)
at async bootGhost (/var/lib/ghost/versions/4.44.0/core/boot.js:412:9)

TypeError: Unknown SSL profile '{ 'rejectUnauthorized': 'true', 'secureProtocol': 'TLSv1_2_method' }'
at Function.getSSLProfile (/var/lib/ghost/versions/4.44.0/node_modules/mysql2/lib/connection_config.js:229:13)
at new ConnectionConfig (/var/lib/ghost/versions/4.44.0/node_modules/mysql2/lib/connection_config.js:119:28)
at Object.exports.createConnection (/var/lib/ghost/versions/4.44.0/node_modules/mysql2/index.js:10:35)
at /var/lib/ghost/versions/4.44.0/node_modules/knex-migrator/node_modules/knex/lib/dialects/mysql/index.js:62:38
at new Promise (<anonymous>)
at Client_MySQL2.acquireRawConnection (/var/lib/ghost/versions/4.44.0/node_modules/knex-migrator/node_modules/knex/lib/dialects/mysql/index.js:61:12)
at create (/var/lib/ghost/versions/4.44.0/node_modules/knex-migrator/node_modules/knex/lib/client.js:252:39)""
```


### Code of Conduct

- [X] I agree to be friendly and polite to people in this repository",True,0,NONE
https://api.github.com/repos/TryGhost/Ghost/issues/comments/1115231134,"""Unknown SSL profile"" for self-host using MySQL with SSL after mysql2 package update (v4.38+)",daniellockyer,8,1222266778,2,1115231134,0,1222266778,2022-05-02T18:37:08Z,"@stefann42 I can't seem to reproduce it from your config example. If I replace the smart quotes with double quotes, it functions as expected (ie. it errors because I don't provide the CA certificate). Both our `mysql2` and `knex` dependencies are on the latest version, so I don't think we're missing anything there.

Can you have a look again and check the config you see breaking your site? Also note [the SSL docs](https://ghost.org/docs/config/#ssl-1)",False,0,MEMBER
https://api.github.com/repos/TryGhost/Ghost/issues/comments/1115231494,"""Unknown SSL profile"" for self-host using MySQL with SSL after mysql2 package update (v4.38+)",github-actions[bot],8,1222266778,3,1115231494,0,1115231134,2022-05-02T18:37:31Z,"Note from our bot: The `needs info` label has been added to this issue. Updating your original issue with more details is great, but won't notify us, so please make sure you leave a comment so that we can see when you've updated us.",False,0,CONTRIBUTOR
https://api.github.com/repos/TryGhost/Ghost/issues/comments/1116669184,"""Unknown SSL profile"" for self-host using MySQL with SSL after mysql2 package update (v4.38+)",stefann42,8,1222266778,4,1116669184,0,1115231494,2022-05-03T21:19:42Z,"Looks like we were using an outdated information, thanks for the pointer to Ghost's SSL docs. That said, serializing the CA public cert as a config parameter is awfully complicated. Do you happen to have a sample config for when you're Ok to ignore SSL cert validation? Unfortunately the [node-mysql2 docs](https://github.com/sidorares/node-mysql2/tree/master/documentation) have a placeholder where the ""SSL"" examples are supposed to go.",False,0,NONE
https://api.github.com/repos/TryGhost/Ghost/issues/comments/1116695416,"""Unknown SSL profile"" for self-host using MySQL with SSL after mysql2 package update (v4.38+)",stefann42,8,1222266778,5,1116695416,0,1116669184,2022-05-03T21:49:27Z,"Nevermind, after some trial and error this seems to work `{ 'rejectUnauthorized': 'false' }`
This issue can be closed, but it would be useful if you could add this bit to the [SSL docs](https://ghost.org/docs/config/#ssl-1)",False,0,NONE
https://api.github.com/repos/TryGhost/Ghost/issues/comments/1134605102,"""Unknown SSL profile"" for self-host using MySQL with SSL after mysql2 package update (v4.38+)",ErisDS,8,1222266778,6,1134605102,0,1116695416,2022-05-23T12:21:00Z,"Hey, I realise this was annoying to figure out but it seems the upshot is, mysql2 is _really_ picky about configuration, and was throwing an error because of the `'secureProtocol': 'TLSv1_2_method'` part of your config.

If you are using SSL but are ok to skip certificate validation, you only need `ssl: { 'rejectUnauthorized': 'false' }` in your config.

I'm a little dubious about updating our own docs to cover this, as I'm not clear on what the use case would be for requiring an SSL config but not validating the cert 😬 

Going to close as there is no bug - but convo can continue and if we decide we do want to update docs that's very quick! ",False,0,MEMBER
https://api.github.com/repos/TryGhost/Ghost/issues/comments/1136540253,"""Unknown SSL profile"" for self-host using MySQL with SSL after mysql2 package update (v4.38+)",stefann42,8,1222266778,7,1136540253,0,1134605102,2022-05-24T23:50:33Z,@ErisDS There are many cases where it's warranted to use SSL but not validate the cert. Local development for example or if you must encrypt traffic but it's too costly/time consuming to maintain valid certificates for your own infrastructure. Sometimes you just need to get something up and running quickly. IMHO the purpose of documentation is to be helpful not judgmental. Right now self-host docs cover a narrow set of use cases (deploying db on AWS RDBMS). To be helpful give developers the information and trust that they know what they're doing if choose to do something. I opened this issue because we wasted two full days with this issue and we don't want other people to have the same experience. ,False,0,NONE
https://api.github.com/repos/TryGhost/Ghost/issues/comments/1142237697,"""Unknown SSL profile"" for self-host using MySQL with SSL after mysql2 package update (v4.38+)",berayb,8,1222266778,8,1142237697,0,1136540253,2022-05-31T14:49:20Z,"Hi @ErisDS, having the same problem. Fresh installation, trying to connect Azure MySQL managed service (v8).

Please see my config below:

`  ""database"": {
    ""client"": ""mysql"",
    ""connection"": {
      ""host"": ""asd-mysql-blog.mysql.database.azure.com"",
      ""user"": ""asd@asd-mysql-blog"",
      ""password"": ""!!cdY*asd"",
      ""database"": ""asd_blog"",
      ""ssl"": {
        ""rejectUnauthorized"": true,
        ""secureProtocol"": ""TLSv1_2_method""
      }
    }
`    

    I get: 
    
    `
    node:events:505
      throw er; // Unhandled 'error' event
      Error: read ECONNRESET
    at TLSWrap.onStreamRead (node:internal/stream_base_commons:217:20)
    Emitted 'error' event on Connection instance at:
    at Connection._notifyError (/var/www/ghost/versions/5.1.1/node_modules/mysql2/lib/connection.js:236:12)
    at Connection._handleFatalError (/var/www/ghost/versions/5.1.1/node_modules/mysql2/lib/connection.js:167:10)
    at Connection._handleNetworkError (/var/www/ghost/versions/5.1.1/node_modules/mysql2/lib/connection.js:180:10)
    at TLSSocket.<anonymous> (/var/www/ghost/versions/5.1.1/node_modules/mysql2/lib/connection.js:350:14)
    at TLSSocket.emit (node:events:527:28)
    at TLSSocket._tlsError (node:_tls_wrap:906:8)
    at TLSSocket.emit (node:events:527:28)
    at emitErrorNT (node:internal/streams/destroy:157:8)
    at emitErrorCloseNT (node:internal/streams/destroy:122:3)
    at processTicksAndRejections (node:internal/process/task_queues:83:21) {
    errno: -104,
    code: 'ECONNRESET',
    syscall: 'read',
    fatal: true
    }

`",False,0,NONE
https://api.github.com/repos/TryGhost/Ghost/issues/comments/1196606457,"""Unknown SSL profile"" for self-host using MySQL with SSL after mysql2 package update (v4.38+)",ErisDS,8,1222266778,9,1196606457,0,1142237697,2022-07-27T11:27:54Z,"@berayb that's a different issue, posted here: https://github.com/TryGhost/Ghost/issues/14990",False,0,MEMBER
https://api.github.com/repos/TryGhost/Ghost/issues/14640,Email stats don't work with Mailgun EU domain,ceecko,4,1222761258,1,1222761258,0,0,2022-05-02T11:14:33Z,"### Issue Summary

Email stats are updated only for the first fetched page of stats from Mailgun due to a missing EU domain in the code.
This is resolved in https://github.com/TryGhost/Publishing/pull/73

Opening a ticket here just in case the PR gets missed.

### Steps to Reproduce

1. Send a lot of emails through EU Mailgun account
2. Wait until email stats are updated

They will be updated only partially - only the first 300 events are fetched.

### Ghost Version

4.46.0

### Node.js Version

14

### How did you install Ghost?

cli

### Database type

MySQL 5.7

### Browser & OS version

_No response_

### Relevant log / error output

```shell
[2022-05-02 11:13:01] INFO Worker for job ""email-analytics-fetch-latest"" online
2022-05-02T11:13:01.652Z ghost:jobs:email-analytics:fetch-latest Starting email analytics fetch of latest events
2022-05-02T11:13:01.664Z ghost:services:email-analytics getLastSeenEventTimestamp: finished in 8ms
2022-05-02T11:13:01.664Z @tryghost/email-analytics-service:services:email-analytics fetchLatest: starting
2022-05-02T11:13:01.665Z @tryghost/email-analytics-provider-mailgun:email-analytics-provider-mailgun _fetchPages: starting fetching first events page
2022-05-02T11:13:01.928Z @tryghost/email-analytics-provider-mailgun:email-analytics-provider-mailgun _fetchPages: finished fetching first page with 300 events
2022-05-02T11:13:03.503Z @tryghost/email-analytics-provider-mailgun:email-analytics-provider-mailgun _fetchPages: starting fetching next page https://api.eu.mailgun.net/v3/example.com/events/xxxxxxx
2022-05-02T11:13:03.553Z @tryghost/email-analytics-provider-mailgun:email-analytics-provider-mailgun _fetchPages: finished fetching next page with 0 events
2022-05-02T11:13:03.553Z @tryghost/email-analytics-service:services:email-analytics fetchLatest: finished in 1889ms. Fetched 300 events
2022-05-02T11:13:03.553Z ghost:jobs:email-analytics:fetch-latest Finished fetching 300 analytics events in 1901ms
2022-05-02T11:13:03.553Z ghost:jobs:email-analytics:fetch-latest Starting email analytics aggregation for 1 emails
2022-05-02T11:13:04.847Z ghost:jobs:email-analytics:fetch-latest Finished aggregating email analytics in 1294ms
[2022-05-02 11:13:04] INFO Worker for job email-analytics-fetch-latest sent a message: Fetched 300 events and aggregated stats for 1 emails in 3195ms
[2022-05-02 11:13:04] INFO Worker for job email-analytics-fetch-latest sent a message: done
```
```


### Code of Conduct

- [X] I agree to be friendly and polite to people in this repository",True,0,CONTRIBUTOR
https://api.github.com/repos/TryGhost/Ghost/issues/comments/1114757199,Email stats don't work with Mailgun EU domain,ErisDS,4,1222761258,2,1114757199,0,1222761258,2022-05-02T11:44:36Z,"Hey @ceecko nice catch, thanks for the great bug report and PR - I've dropped a review there. ",False,0,MEMBER
https://api.github.com/repos/TryGhost/Ghost/issues/comments/1114903313,Email stats don't work with Mailgun EU domain,ceecko,4,1222761258,3,1114903313,0,1114757199,2022-05-02T13:47:03Z,@ErisDS should be resolved in the PR,False,0,CONTRIBUTOR
https://api.github.com/repos/TryGhost/Ghost/issues/comments/1124579280,Email stats don't work with Mailgun EU domain,ceecko,4,1222761258,4,1124579280,0,1114903313,2022-05-12T06:27:44Z,@ErisDS when do you expect this could get into a release?,False,0,CONTRIBUTOR
https://api.github.com/repos/TryGhost/Ghost/issues/comments/1125175065,Email stats don't work with Mailgun EU domain,matthanley,4,1222761258,5,1125175065,0,1124579280,2022-05-12T16:06:25Z,"Hey @ceecko 👋🏼 This is now bumped in main and the [4.x branch](https://github.com/TryGhost/Ghost/commit/43badac286dbf042af3f141791ae68491a70b350), so it'll go out in 5.0 when it's released as well as the next 4.x release. Thanks!",False,0,CONTRIBUTOR
https://api.github.com/repos/TryGhost/Ghost/issues/14659,✨Image Backups API endpoint,ronaldlangeveld,3,1224225495,1,1224225495,0,0,2022-05-03T15:05:26Z,"👋 Hi, first time contributor here.

I've been using Ghost for years and one small feature I've always felt was missing, is an image exporter on self-hosted installations, that could potentially compliment the JSON Content exporter. Of course, one could just ssh onto a server and manually zip + download via sftp or something, but it feels like extra steps to achieve something that one would expect to be in the settings.

I challenged myself to build it, as it would be a great way to familiarise myself with the Ghost codebase and as a gateway to perhaps get more involved in open-source.

Last week I dived right in and have a working alpha prototype up and running, that's ready for PR. 


- [X] There's a clear use-case for this code change, explained below
- [x] Commit message has a short title & references relevant issues (I hope I did)
- [X] The build will pass (run yarn test:all and yarn lint)


I added an Export button in the Admin client as well under Labs -> Alpha features. 
Added PR for that here https://github.com/TryGhost/Admin/pull/2362

<img width=""1800"" alt=""Screenshot 2022-05-03 at 16 53 50"" src=""https://user-images.githubusercontent.com/19263291/166482025-1bba0439-7b9a-4f4e-a537-cc699feaaad2.png"">


A next iteration of this would be perhaps to make it a multithreaded task, to avoid it timing out when it's a big archive. 
I only tested it with around 50mb worths photo content, on an M1 Pro. Most cloud servers aren't that powerful and production entities will have much more content to compress.
And then finally, perhaps an uploader that does the reverse. ",True,0,MEMBER
https://api.github.com/repos/TryGhost/Ghost/issues/comments/1116531844,✨Image Backups API endpoint,ErisDS,3,1224225495,2,1116531844,0,1224225495,2022-05-03T20:06:07Z,"Hey there @ronaldlangeveld 👋 I really appreciate your time, effort & enterprise with getting stuck in here.

I think you've touched on the main reason why this feature doesn't exist already: the image folder could be infinite in size and we have to make absolutely certain that a backups endpoint couldn't take a site offline as that rather defeats the object 😬 

This means that the code to do this needs to be infallible and non-blocking. We'd probably need to generate the backup in a job & provide a download link in an email, rather than doing this inside an HTTP request. There are talks of restructuring the main importer this way too & it is also how the members importer was built.

There was an extensive discussion of implementing a backup feature into Ghost-CLI here: https://github.com/TryGhost/Ghost-CLI/issues/468 although it died. This discussed the performance benefits and complexities of shelling out to tar on the server.

As a last note, there are additional files that would be needed inside of a backup or archive as Ghost now has folders with media & files as well as a few json/yaml files dotted around, although it depends slightly on what the definition of the backup is.

I don't say any of this to discourage you or dismiss your work and I completely agree it'd be great to have an official and single-step method for generating a ghost backup, however, there's a lot to think about here and I don't want you to spend more time going in a direction that we wouldn't merge.

Hope this gives you some food for thought 😄 ",False,0,MEMBER
https://api.github.com/repos/TryGhost/Ghost/issues/comments/1116661422,✨Image Backups API endpoint,ronaldlangeveld,3,1224225495,3,1116661422,0,1116531844,2022-05-03T21:10:50Z,"Hi @ErisDS 

Thank you so much for the detailed feedback, much appreciated. 😊

While building it, I did have a gut feeling (that my curiosity ignored 😅) that there's probably informed reasons by the team for not having a feature like this already - and you've summed it up perfectly.

Was fun building a prototype regardless. 😊",False,0,MEMBER
https://api.github.com/repos/TryGhost/Ghost/issues/comments/1117724908,✨Image Backups API endpoint,ErisDS,3,1224225495,4,1117724908,0,1116661422,2022-05-04T19:20:04Z,"If this was something we could do in a blocking HTTP request then this implementation would be spot on 👌 would just be asking for a test 😬  

I'll close this for now. If you get inspiration to build something non-blocking by all means open a fresh PR and I'll take a 👀 ",False,0,MEMBER
https://api.github.com/repos/TryGhost/Ghost/issues/14660,Migrated previous email sending settings to newsletters,matthanley,4,1224350588,1,1224350588,0,0,2022-05-03T16:50:34Z,"refs https://github.com/TryGhost/Team/issues/1581

- The original migration to create the default newsletter omitted the from address and reply-to settings
- `sender_reply_to` and `members_reply_address` are both enums with the same values and copy straight across
- `members_from_address` had a default value of 'noreply' as the fallback, which is remapped to NULL in the newsletters table
- We apply the change to all newsletters (there should only be one outside of alpha) which haven't already been reconfigured",True,0,CONTRIBUTOR
https://api.github.com/repos/TryGhost/Ghost/issues/comments/1116324895,Migrated previous email sending settings to newsletters,github-actions[bot],4,1224350588,2,1116324895,0,1224350588,2022-05-03T16:50:48Z,"It looks like this PR contains a migration 👀
Here's the checklist for reviewing migrations:

### General requirements

- [x]  Satisfies idempotency requirement (both `up()` and `down()`)
- [x]  Does not reference models
- [x]  Filename is in the correct format
- [x]  Targets the next minor version
- [x]  All code paths have appropriate log messages
- [x]  Uses the correct utils
- [x]  Contains a minimal changeset
- [x]  Does not mix DDL/DML operations


### Data changes

- [x]  Mass updates/inserts are batched appropriately
- [x]  Does not loop over large tables/datasets
- [x]  Defends against missing or invalid data
- [ ]  ~For settings updates: follows the appropriate guidelines~",False,0,CONTRIBUTOR
https://api.github.com/repos/TryGhost/Ghost/issues/comments/1116326805,Migrated previous email sending settings to newsletters,codecov[bot],4,1224350588,3,1116326805,0,1116324895,2022-05-03T16:52:59Z,"# [Codecov](https://codecov.io/gh/TryGhost/Ghost/pull/14660?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=TryGhost) Report
> Merging [#14660](https://codecov.io/gh/TryGhost/Ghost/pull/14660?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=TryGhost) (96f6d01) into [4.x](https://codecov.io/gh/TryGhost/Ghost/commit/85577aca64e5b228fe77d2dbcec437048ac54448?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=TryGhost) (85577ac) will **increase** coverage by `0.04%`.
> The diff coverage is `n/a`.

```diff
@@            Coverage Diff             @@
##              4.x   #14660      +/-   ##
==========================================
+ Coverage   59.80%   59.85%   +0.04%     
==========================================
  Files         580      580              
  Lines       48003    47998       -5     
  Branches     4214     4217       +3     
==========================================
+ Hits        28710    28727      +17     
+ Misses      19252    19230      -22     
  Partials       41       41              
```


| [Impacted Files](https://codecov.io/gh/TryGhost/Ghost/pull/14660?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=TryGhost) | Coverage Δ | |
|---|---|---|
| [core/server/services/members/config.js](https://codecov.io/gh/TryGhost/Ghost/pull/14660/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=TryGhost#diff-Y29yZS9zZXJ2ZXIvc2VydmljZXMvbWVtYmVycy9jb25maWcuanM=) | `56.36% <0.00%> (+8.80%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/TryGhost/Ghost/pull/14660?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=TryGhost).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=TryGhost)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/TryGhost/Ghost/pull/14660?src=pr&el=footer&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=TryGhost). Last update [85577ac...96f6d01](https://codecov.io/gh/TryGhost/Ghost/pull/14660?src=pr&el=lastupdated&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=TryGhost). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=TryGhost).
",False,0,NONE
https://api.github.com/repos/TryGhost/Ghost/issues/comments/1117075884,Migrated previous email sending settings to newsletters,SimonBackx,4,1224350588,4,1117075884,0,1116326805,2022-05-04T08:56:49Z,I'm not sure if we should release this without changing `core/server/services/members/config.js` too. Because we'll have a 'hidden' logic to fallback to a value that they can't change. ,False,0,CONTRIBUTOR
https://api.github.com/repos/TryGhost/Ghost/issues/comments/1117105480,Migrated previous email sending settings to newsletters,matthanley,4,1224350588,5,1117105480,0,1117075884,2022-05-04T09:30:33Z,The additional change to remove the hidden fallback is here: https://github.com/TryGhost/Ghost/pull/14665,False,0,CONTRIBUTOR
https://api.github.com/repos/Python-Markdown/markdown/issues/1239,Unescape characters on markdeep diagrams,ipocentro87,3,1183767961,1,1183767961,0,0,2022-03-28T17:37:05Z,"Hi everyone, I am writing a markdeep extension for python-markdown in order to be able to draw diagrams with markdeep support.
However, I had some issues in rendering arrows, since they are escaped. This is the result of an arrow described in markdeep.
```
<markdeep><diagram>
-------&gt;
</diagram></markdeep>
```
Which is not properly handled when the page is loaded. Do you know how I can disable escaping in this scenario?

Thank you very much in advance!",True,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1081024668,Unescape characters on markdeep diagrams,ipocentro87,3,1183767961,2,1081024668,0,1183767961,2022-03-28T18:59:51Z,"I managed to make it work in a dirty way: I include the diagram in a HTML comment, and then I decomment right before printing the html. This prevents the parser to substitute > and other markdown tags (like emphasis, italic, etc.):
```
<markdeep><diagram>
<!-- MARKDEEP_DIAGRAM
--------->
MARKDEEP_DIAGRAM --> 
</diagram></markdeep>
```
Again, it's a bit dirty but makes the job. Is there any better idea?",False,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1081085244,Unescape characters on markdeep diagrams,waylan,3,1183767961,3,1081085244,0,1081024668,2022-03-28T20:04:59Z,Sorry but I'm not familiar with Markdeep and I'm not sure I understand what you are trying to do. What is the raw Markdown source you are trying to parse? How is it being parsed incorrectly? And what would you like to happen instead?,False,0,MEMBER
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1118596621,Unescape characters on markdeep diagrams,waylan,3,1183767961,4,1118596621,0,1081085244,2022-05-05T14:04:19Z,"I'm closing this due to the lack of information. If the requested information is provided, we can consider reopening this issue.",False,0,MEMBER
https://api.github.com/repos/Python-Markdown/markdown/issues/1241,extensions: copy config dict on each highlighted block,gertvdijk,6,1190330594,1,1190330594,0,0,2022-04-01T22:28:02Z,"This fixes a bug where any subsequent highlighted block with codehilite would result in the omission of the style setting, falling back to default.

Fixes #1240",True,0,CONTRIBUTOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1086587551,extensions: copy config dict on each highlighted block,mitya57,6,1190330594,2,1086587551,0,1190330594,2022-04-02T08:25:27Z,Can you please add a test for multiple highlighted blocks?,False,0,COLLABORATOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1086919231,extensions: copy config dict on each highlighted block,gertvdijk,6,1190330594,3,1086919231,0,1086587551,2022-04-03T18:03:41Z,@mitya57 Added them to the now amended commit. 😃 ,False,0,CONTRIBUTOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1086949742,extensions: copy config dict on each highlighted block,gertvdijk,6,1190330594,4,1086949742,0,1086919231,2022-04-03T21:08:34Z,"[CI error](https://github.com/Python-Markdown/markdown/runs/5807792601?check_suite_focus=true) appears unrelated to my change. 😕 

> 43 files checked.
> ERROR: 5 files with dead links found!",False,0,CONTRIBUTOR
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1087595746,extensions: copy config dict on each highlighted block,waylan,6,1190330594,5,1087595746,0,1086949742,2022-04-04T14:00:26Z,"The reason why we `pop` the setting is because we also pass the rest of the config items on to Pygments (see the very next line). As each of Pygmants' lexers/formatters have a different set of options they accept, we just pass all unknown keywords on. However, there is no need to pass the style on as we have already defined that. The only reason we don't get an error is because Pygments just ignores any unknown keywords passed to its lexers and formatters. Still, it would be best to not pass it on to avoid any weird conflicts in the future. 

Perhaps we should be making a copy of the config for each code block and then we can pop the setting off of the copy.

As an aside, we have the `pygments_style` setting for historical reasons (it existed before we accepted all Pygments options). If we were starting fresh today we would not define a special option for it and users could just use `style`  which would get passed it on with the rest of the Pygments' keyword options. Actually, a user could avoid this bug by using `style` now (without this fix). That said, we should still fix the bug. Although, we might want to deprecate the `pygments_style` option as it is duplicative and unnecessary.",False,0,MEMBER
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1087605662,extensions: copy config dict on each highlighted block,waylan,6,1190330594,6,1087605662,0,1087595746,2022-04-04T14:08:32Z,"> [CI error](https://github.com/Python-Markdown/markdown/runs/5807792601?check_suite_focus=true) appears unrelated to my change. 😕
> 
> > 43 files checked.
> > ERROR: 5 files with dead links found!

Yes, I see that. I have opened a separate issue for that in #1243. You can ignore that failure here.",False,0,MEMBER
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1100151045,extensions: copy config dict on each highlighted block,gertvdijk,6,1190330594,7,1100151045,0,1087605662,2022-04-15T14:43:58Z,"@waylan Thanks for the explanation! 😃 
It took a bit longer to get back to this, but I've pushed an amendment.",False,0,CONTRIBUTOR
https://api.github.com/repos/Python-Markdown/markdown/issues/1244,"autolink for non-HTTP URIs, and other non-tag content, produces invalid XML",nxg,3,1198733592,1,1198733592,0,0,2022-04-09T18:15:46Z,"Consider the following:

    import markdown
    
    md = '''
    Here are some elements:
    
      * url <http://example.org>
      * repo url <ssh://example.org>, which is a non-HTTP URL
      * and <urn:foo> is something else
      * ssh url2 <ssh:me@example.org>, handled as an email address
      * misc element <em>boo!</em>
    '''
    
    converter = markdown.Markdown()
    print(converter.convert(md))

This renders as

    <p>Here are some elements:</p>
    <ul>
    <li>url <a href=""http://example.org"">http://example.org</a></li>
    <li>repo url <ssh://example.org>, which is a non-HTTP URL</li>
    <li>and <urn:foo> is something else</li>
    <li>ssh url2 <a href=""&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#115;&#115;&#104;&#58;&#109;&#101;&#64;&#101;&#120;&#97;&#109;&#112;&#108;&#101;&#46;&#111;&#114;&#103;"">&#115;&#115;&#104;&#58;&#109;&#101;&#64;&#101;&#120;&#97;&#109;&#112;&#108;&#101;&#46;&#111;&#114;&#103;</a>, handled as an email address</li>
    <li>misc element <em>boo!</em></li>
    </ul>

I think items number 2 and 3 are incorrect, (a) because the behaviour doesn't match two significant Markdown specs, and (b) because they are both invalid XML (yes, `<urn:foo>` looks like an XML element with a namespace prefix; let's not go there...).

The autolink feature in the [Daring Fireball spec](https://daringfireball.net/projects/markdown/syntax#autolink) is ‘for URLs and email addresses’ (though the only URL in that example is an HTTP URL).  The [corresponding section in the CommonMark spec](https://spec.commonmark.org/0.30/#autolinks) says that the autolink should happen for an absolute URI.  So the second case should be turned into `<a href='ssh://example.org'>ssh://example.org</a>`.

What appears to be happening, instead, is that this is being interpreted as literal HTML.  The [relevant section of Gruber's spec](https://daringfireball.net/projects/markdown/syntax#html) is rather vague, but the [corresponding part of the CommonMark spec](https://spec.commonmark.org/0.30/#raw-html) says that this should happen only to ‘[t]ext between < and > that looks like an HTML tag’, which of course `<ssh://example.org>` doesn't (CommonMark: ‘A tag name consists of an ASCII letter followed by zero or more ASCII letters, digits, or hyphens (-)’).

Independently of any spec, however, having `<ssh://example.org>` appear in the output means that that output is syntactically invalid, and I feel this shouldn't happen for any input, however insane.

**Suggestion**:

  * When `<starttag>` consists of something other than `[a-zA-Z][a-zA-Z0-9-]*`, then it is either a URI, in which case it should be turned into an `<a>` element, or it is not, in which case it should be included literally in the output, as if the content were instead enclosed in backticks.

This would imply that item 3 should render as `<code>urn:foo</code>`.",True,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1094103020,"autolink for non-HTTP URIs, and other non-tag content, produces invalid XML",waylan,3,1198733592,2,1094103020,0,1198733592,2022-04-09T18:32:29Z,"First of all, Python-Markdown is NOT a Commonmark implementation, so I will ignore all references to that spec.

> The autolink feature in the [Daring Fireball spec](https://daringfireball.net/projects/markdown/syntax#autolink) is ‘for URLs and email addresses’ (though the only URL in that example is an HTTP URL).

And in fact, according to [Babelmark][1], Markdown.pl only recognizes HTTP URLs. Seems to me we are mostly inline with the reference implementation.

> Independently of any spec, however, having `<ssh://example.org>` appear in the output means that that output is syntactically invalid, and I feel this shouldn't happen for any input, however insane.

This seems to be the motivation behind your report. However, I have a different view. We cannot be responsible for invalid input. That is the responsibility of the document author. In fact, we do not validate any raw HTML for this reason. Any contact wrapped in angle brackets which is not recognized as a auto link is just treated as raw HTML Everything between (and including) the angle brackets is passed thorough unaltered in any way. I have no intention of changing that.

That said, if there are some additional forms of URLs would should clearly be recognized as auto links which are not currently, then I would be willing to review a PR. However, if those URLs are not also recognized by the reference implementation, then they it would be better for support to be provided through a third party extension.

Speaking of third party extensions, you can always modify any part of the parser with an extension. If you want to avoid invalid output, then you are always free to use an extension to do that. Although, I would think a post processor would be better suited to the task. Simply pass the output from Python-Markdown into some HTML tidy library and then use the output of that on your HTML templates (or whatever you are going with it).

[1]: https://johnmacfarlane.net/babelmark2/?normalize=1&text=Here+are+some+elements%3A%0A%0A*+url+%3Chttp%3A%2F%2Fexample.org%3E%0A*+repo+url+%3Cssh%3A%2F%2Fexample.org%3E%2C+which+is+a+non-HTTP+URL%0A*+and+%3Curn%3Afoo%3E+is+something+else%0A*+ssh+url2+%3Cssh%3Ame%40example.org%3E%2C+handled+as+an+email+address%0A*+misc+element+%3Cem%3Eboo!%3C%2Fem%3E",False,0,MEMBER
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1094275453,"autolink for non-HTTP URIs, and other non-tag content, produces invalid XML",nxg,3,1198733592,3,1094275453,0,1094103020,2022-04-10T13:28:43Z,"Thanks for looking at this.

> First of all, Python-Markdown is NOT a Commonmark implementation, so I will ignore all references to that spec.

And the wonderful thing about Markdown implementations is that there are so many to choose from!  I only mentioned Commonmark because it was one that came to mind, and it seemed useful to mention some spec on top of Gruber's original.  I didn't intend to suggest that python-markdown was, or should be, specifically a Commonmark implementation.

>And in fact, according to [Babelmark](https://johnmacfarlane.net/babelmark2/?normalize=1&text=Here+are+some+elements%3A%0A%0A*+url+%3Chttp%3A%2F%2Fexample.org%3E%0A*+repo+url+%3Cssh%3A%2F%2Fexample.org%3E%2C+which+is+a+non-HTTP+URL%0A*+and+%3Curn%3Afoo%3E+is+something+else%0A*+ssh+url2+%3Cssh%3Ame%40example.org%3E%2C+handled+as+an+email+address%0A*+misc+element+%3Cem%3Eboo!%3C%2Fem%3E), Markdown.pl only recognizes HTTP URLs. Seems to me we are mostly inline with the reference implementation.

True, but I notice that, if we look at the other parsers in that useful list, which produce a result, it's only Markdown.pl and python-markdown that don't do at least _something_ with `<ssh://example.org>`, and instead pass it through verbatim.  Some turn it into a `<a>` link, others give up and escape the `<` with `&lt;` – either of those seems a reasonable strategy.

>> Independently of any spec, however, having <ssh://example.org> appear in the output means that that output is syntactically invalid, and I feel this shouldn't happen for any input, however insane.

> This seems to be the motivation behind your report.

That is indeed the motivation.  I want to consume what python-markdown produces, so I naturally have an interest in it being consumable.

> However, I have a different view. We cannot be responsible for invalid input. That is the responsibility of the document author. In fact, we do not validate any raw HTML for this reason. Any contact wrapped in angle brackets which is not recognized as a auto link is just treated as raw HTML Everything between (and including) the angle brackets is passed thorough unaltered in any way. 

That's an interesting point of view.  Myself, I feel that if there's a ‘spirit of Markdown’, it's that _the user is never wrong_, and there is no such thing as ‘invalid input’, only input which the processor doesn't recognise, where the user therefore fails to communicate their intention.  A Markdown processor is a fairly heuristic tool, and should always have sensible defaults.

That is, Markdown is a DWIM application, and I think we can say, with some degree of confidence, that if the user types `<ssh://example.org>` then their intention was something _other_ than creating inline HTML.  All I'm suggesting is that if python-markdown spots something like that, which is not a mailto, and which is clearly not intended as inline HTML, that it has a third strategy.

> That said, if there are some additional forms of URLs would should clearly be recognized as auto links which are not currently, then I would be willing to review a PR. However, if those URLs are not also recognized by the reference implementation, then they it would be better for support to be provided through a third party extension.

I think it would be reasonable to regard essentially _any_ URL inside angle brackets as an autolink candidate -- there's nothing special about HTTP and FTP from Markdown's point of view.  That would pass a DWI(probably)M test, for me.  In the case of `ssh://example.org` I don't think there's much useful that could happen if that appears in a web page, but if that turned into an `<a>` link, then I as a user would not feel surprised or cheated. 

Thus, in `inlinepatterns.py`, change `AUTOLINK_RE` to

    AUTOLINK_RE = r'<([a-zA-Z]+://[^<>]*)>'

Additionally, and whether or not you though the above was a good idea (ie, I can see at least some sort of case for restricting autolink to HTTP/FTP), there might be milage in something like

    # According to <https://www.w3.org/TR/REC-xml/#NT-Name>,
    # an element start tag is
    #
    #    '<' Name (S Attribute)* S? '>'
    # where
    # [4]   	NameStartChar	   ::=   	"":"" | [A-Z] | ""_"" | [a-z] | [#xC0-#xD6] | [#xD8-#xF6] | [#xF8-#x2FF] | [#x370-#x37D] | [#x37F-#x1FFF] | [#x200C-#x200D] | [#x2070-#x218F] | [#x2C00-#x2FEF] | [#x3001-#xD7FF] | [#xF900-#xFDCF] | [#xFDF0-#xFFFD] | [#x10000-#xEFFFF]
    # [4a]   	NameChar	   ::=   	NameStartChar | ""-"" | ""."" | [0-9] | #xB7 | [#x0300-#x036F] | [#x203F-#x2040]
    #
    # but we don't have to be so general, if what we're aiming to spot is (the complement of) HTML element names.
    # So match an element-start-tag or end-tag
    # which has something other than [a-z]+ for the element name
    NONHTML_RE = re.compile('(<\/?[a-zA-Z][a-zA-Z0-9.-]*[^ a-zA-Z0-9.-]([^ <>]*)?>)')

That (along with a suitable `NonhtmlInlineProcessor` class) would identify those `<something...>` which are obviously not intended to be inline HTML, and could escape the leading `<` (or put the content in `<code>...</code>`, if one wanted to be fancy).

> Although, I would think a post processor would be better suited to the task. Simply pass the output from Python-Markdown into some HTML tidy library and then use the output of that on your HTML templates (or whatever you are going with it).

Indeed, but element `<ssh://example.org>` manages to confuse lxml's HTMLParser (and I can't say I really blame it, but a bug report is heading their way...).  There's ‘tag soup’ and there's ‘what...!’.",False,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1094353574,"autolink for non-HTTP URIs, and other non-tag content, produces invalid XML",waylan,3,1198733592,4,1094353574,0,1094275453,2022-04-10T19:28:32Z,"Let me restate that everything in angle brackets is considered to be raw HTML unless it is clearly an auto link. That is how the reference implementation works and that is how Python-Markdown will always work by default. If you want to alter that behavior, then you can do so in a third party extension.

However, if you want to explore expanding auto links, then that may be worth considering. However, as with everything else in Markdown, I don't think we want to be super strict and encode the entire requirements of some spec. Something simple like `AUTOLINK_RE = r'<([a-zA-Z]+://[^<>]*)>'` is probably the right direction. My only concern is whether that could be to general and match things it shouldn't. A good set of tests would likely address any such concern. Therefore, a PR with such and change and a full set of tests would be given serious consideration. However, anything more complex can be handled by a third party extension.",False,0,MEMBER
https://api.github.com/repos/Python-Markdown/markdown/issues/1246,Extension md_in_html does not recognize tags with hyphens,igordsm,4,1218080423,1,1218080423,0,0,2022-04-28T01:57:34Z,"Web components are custom HTML components that are required to have `-` in their names. This breaks current HTML handling since these elements are not considered. IMHO they should be treated the same as `<div>` (""block"" elements, if I'm not mistaken).

The following was tested in current `main` with the extension `md_in_html` active. 

**input**
```
<a-b>

asdf

</a-b>
```


**output**:
```
<p><a-b></p>
<p>asdf</p>
<p></a-b></p>
```

**expected**:
```
<a-b>
<p>asdf</p>
</a-b>
```


I went through the code and might know how to add this, but I would like the maintainers' input before proceeding. ",True,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1113630639,Extension md_in_html does not recognize tags with hyphens,waylan,4,1218080423,2,1113630639,0,1218080423,2022-04-29T18:59:08Z,"> Web components are custom HTML components that are required to have `-` in their names.

Can you point us to a spec for this?",False,0,MEMBER
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1113740665,Extension md_in_html does not recognize tags with hyphens,igordsm,4,1218080423,3,1113740665,0,1113630639,2022-04-29T21:17:04Z,"The resource I use the most is MDN: https://developer.mozilla.org/en-US/docs/Web/Web_Components/Using_custom_elements 

The actual specification of valid names is at https://html.spec.whatwg.org/#valid-custom-element-name",False,0,NONE
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1114953986,Extension md_in_html does not recognize tags with hyphens,waylan,4,1218080423,4,1114953986,0,1113740665,2022-05-02T14:21:56Z,"Thank you for the links. There are two things I need to mention here.

First of all, the way Python-Markdown handles raw HTML is to define a [list of known block-level tags][0]. Any content within those block-level tags gets special treatment. Anything outside those known block-level tags is just treated as regular Markdown content, including inline raw HTML elements, which explains the behavior of the sample provided above.

Second, I will note that to use custom elements, the HTML spec requires you to register the elements with the browser first. Without registering them, then the browser would have no knowledge of how to handle them. In fact, a custom element could be an inline element or a block-level element.

Given the above, I think that the logical way to support custom elements in Python-Markdown is to require the user to ""register"" the elements. That is, if you have a custom element which should be treated as a block-level element, you need to inform the Markdown class about it. This would probably make a good candidate for a third party extension (extension to register custom elements), although you can do this without an extension as demonstrated below.

```python
>>> src = '''
... <a-b>
...
... asdf
...
... </a-b>
... '''
>>> md = markdown.Markdown()
>>> md.block_level_elements.append('a-b')
>>> md.convert(src)
'<a-b>\n\nasdf\n\n</a-b>'
```

That said, this does not currently work correctly with the md_in_html extension. Specifically, the extension fails to allow Markdown parsing within the element.

```python
>>> md = markdown.Markdown(extensions=['md_in_html'])
>>> md.block_level_elements.append('a-b')
>>> md.convert(src)
'<a-b>\n\nasdf\n\n</a-b>'
```

This would appear to be because the extension compiles its lists of element types when the class instance is created and therefore does not see the changes made to the `Markdown` class latter (see [relevant code here][1]). Ideally, the extension would build its list of element types after all extensions are loaded. I'm open to a PR which makes this change only. However, I do not see any need to add explicit support for custom elements specifically.

[0]: https://github.com/Python-Markdown/markdown/blob/master/markdown/core.py#L75-L86
[1]: https://github.com/Python-Markdown/markdown/blob/master/markdown/extensions/md_in_html.py#L31-L45",False,0,MEMBER
https://api.github.com/repos/Python-Markdown/markdown/issues/comments/1120561870,Extension md_in_html does not recognize tags with hyphens,igordsm,4,1218080423,5,1120561870,0,1114953986,2022-05-09T02:12:57Z,Thanks for the detailed feedback @waylan . I'll try and make a PR with the changes you outlined above this week. ,False,0,NONE
https://api.github.com/repos/kubernetes/website/issues/33834,"kubeadm: apply changes around ""master"" taint for 1.25",neolit123,8,1242217533,1,1242217533,0,0,2022-05-19T19:14:31Z,"The ""master"" taint is no longer applied on control plane
nodes by kubeadm 1.25.

Remove mentions of the taint from the documentation:
- implementation details
- create a kubeadm cluster
- known labels / taints
- TS guide

xref https://github.com/kubernetes/kubeadm/issues/2200
",True,0,MEMBER
https://api.github.com/repos/kubernetes/website/issues/comments/1132105566,"kubeadm: apply changes around ""master"" taint for 1.25",neolit123,8,1242217533,2,1132105566,0,1242217533,2022-05-19T19:14:51Z,"/kind cleanup
/sig cluster-lifecycle
/priority important-soon
(1.25 release)",False,0,MEMBER
https://api.github.com/repos/kubernetes/website/issues/comments/1132113546,"kubeadm: apply changes around ""master"" taint for 1.25",neolit123,8,1242217533,3,1132113546,0,1132105566,2022-05-19T19:23:29Z,"/cc @pacoxu 
PTAL for tech LGTM. thanks!

also logged https://github.com/kubernetes/website/issues/33835 to update the API ref docs.",False,0,MEMBER
https://api.github.com/repos/kubernetes/website/issues/comments/1132414884,"kubeadm: apply changes around ""master"" taint for 1.25",k8s-ci-robot,8,1242217533,4,1132414884,0,1132113546,2022-05-20T03:18:04Z,LGTM label has been added.  <details>Git tree hash: c07a19a2e9c89952c6c43d968e89f4c9fb44c611</details>,False,0,CONTRIBUTOR
https://api.github.com/repos/kubernetes/website/issues/comments/1132419174,"kubeadm: apply changes around ""master"" taint for 1.25",pacoxu,8,1242217533,5,1132419174,0,1132414884,2022-05-20T03:25:33Z,/assign @sftim,False,0,MEMBER
https://api.github.com/repos/kubernetes/website/issues/comments/1134664127,"kubeadm: apply changes around ""master"" taint for 1.25",sftim,8,1242217533,6,1134664127,0,1132419174,2022-05-23T13:14:15Z,"/remove-priority important-soon

We use milestones to track priority for PRs that target releases.

/unassign
I'm happy for anyone to review this for SIG Docs",False,0,CONTRIBUTOR
https://api.github.com/repos/kubernetes/website/issues/comments/1165081169,"kubeadm: apply changes around ""master"" taint for 1.25",reylejano,8,1242217533,7,1165081169,0,1134664127,2022-06-24T01:36:52Z,"/milestone 1.25
/approve",False,0,MEMBER
https://api.github.com/repos/kubernetes/website/issues/comments/1165081465,"kubeadm: apply changes around ""master"" taint for 1.25",k8s-ci-robot,8,1242217533,8,1165081465,0,1165081169,2022-06-24T01:37:23Z,"[APPROVALNOTIFIER] This PR is **APPROVED**

This pull-request has been approved by: *<a href=""https://github.com/kubernetes/website/pull/33834#pullrequestreview-979470491"" title=""LGTM"">pacoxu</a>*, *<a href=""https://github.com/kubernetes/website/pull/33834#issuecomment-1165081169"" title=""Approved"">reylejano</a>*

The full list of commands accepted by this bot can be found [here](https://go.k8s.io/bot-commands?repo=kubernetes%2Fwebsite).

The pull request process is described [here](https://git.k8s.io/community/contributors/guide/owners.md#the-code-review-process)

<details >
Needs approval from an approver in each of these files:

- ~~[content/en/OWNERS](https://github.com/kubernetes/website/blob/dev-1.25/content/en/OWNERS)~~ [reylejano]

Approvers can indicate their approval by writing `/approve` in a comment
Approvers can cancel approval by writing `/approve cancel` in a comment
</details>
<!-- META={""approvers"":[]} -->",False,0,CONTRIBUTOR
https://api.github.com/repos/kubernetes/website/issues/comments/1218480227,"kubeadm: apply changes around ""master"" taint for 1.25",netlify[bot],8,1242217533,9,1218480227,0,1165081465,2022-08-17T20:53:29Z,"### <span aria-hidden=""true"">👷</span> Deploy Preview for *kubernetes-io-vnext-staging* processing.


|  Name | Link |
|---------------------------------|------------------------|
|<span aria-hidden=""true"">🔨</span> Latest commit | ed9ea9c4f26bf225d3359d86b519db29d22cc9d7 |
|<span aria-hidden=""true"">🔍</span> Latest deploy log | https://app.netlify.com/sites/kubernetes-io-vnext-staging/deploys/6286971802afec000887f518 |",False,0,NONE
https://api.github.com/repos/kubernetes/website/issues/33835,"kubeadm API reference docs still mention ""master"" taint",neolit123,3,1242222547,1,1242222547,0,0,2022-05-19T19:19:59Z,"**This is a Bug Report**

<!-- Thanks for filing an issue! Before submitting, please fill in the following information. -->
<!-- See https://kubernetes.io/docs/contribute/start/ for guidance on writing an actionable issue description. -->

<!--Required Information-->
**Problem:**

while cleaning up mentions of the legacy ""master"" taint in kubeadm docs:
https://github.com/kubernetes/website/pull/33834

saw the following:
```
~/go/src/k8s.io/website/content/en/docs$ grep ""node-role.kubernetes.io/master"" * -rnI
reference/config-api/kubeadm-config.v1beta2.md:1280:<code>'node-role.kubernetes.io/master=&quot;&quot;'</code>. If you don't want to taint your control-plane node,
reference/config-api/kubeadm-config.v1beta3.md:1267:<code>taints: [&quot;node-role.kubernetes.io/master:&quot;&quot;]</code>.
```

it seems the generated reference API docs for kubeadm still include the ""master"" taint.

**Proposed Solution:**

cleanup mentions of the old taint from kubeadm's API reference docs at k8s.io.

perhaps these need to be synced with:
https://github.com/kubernetes/kubernetes/blob/master/cmd/kubeadm/app/apis/kubeadm/v1beta2/doc.go
https://github.com/kubernetes/kubernetes/blob/master/cmd/kubeadm/app/apis/kubeadm/v1beta3/doc.go

for dev-1.25 and main at k/website

we removed the old taint from there before 1.24 was released.

**Page to Update:**

https://kubernetes.io/docs/reference/config-api/kubeadm-config.v1beta2/
https://kubernetes.io/docs/reference/config-api/kubeadm-config.v1beta3/

<!--Optional Information (remove the comment tags around information you would like to include)-->
<!--Kubernetes Version:-->

<!--Additional Information:-->
",True,0,MEMBER
https://api.github.com/repos/kubernetes/website/issues/comments/1132110588,"kubeadm API reference docs still mention ""master"" taint",k8s-ci-robot,3,1242222547,2,1132110588,0,1242222547,2022-05-19T19:20:07Z,"@neolit123: This issue is currently awaiting triage.

SIG Docs takes a lead on issue triage for this website, but any Kubernetes member can accept issues by applying the `triage/accepted` label.

The `triage/accepted` label can be added by org members by writing `/triage accepted` in a comment.


<details>

Instructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.
</details>",False,0,CONTRIBUTOR
https://api.github.com/repos/kubernetes/website/issues/comments/1132110884,"kubeadm API reference docs still mention ""master"" taint",neolit123,3,1242222547,3,1132110884,0,1132110588,2022-05-19T19:20:33Z,"/sig cluster-lifecycle
/priority important-soon
/kind cleanup",False,0,MEMBER
https://api.github.com/repos/kubernetes/website/issues/comments/1132111134,"kubeadm API reference docs still mention ""master"" taint",neolit123,3,1242222547,4,1132111134,0,1132110884,2022-05-19T19:20:53Z,cc @tengqm ,False,0,MEMBER
https://api.github.com/repos/kubernetes/website/issues/33836,Update topology-manager.md,prb112,5,1242283358,1,1242283358,0,0,2022-05-19T20:21:45Z,"Fixes a spelling mistake with co-ordinate, thank you, Paul",True,0,CONTRIBUTOR
https://api.github.com/repos/kubernetes/website/issues/comments/1132173163,Update topology-manager.md,shannonxtreme,5,1242283358,2,1132173163,0,1242283358,2022-05-19T20:27:04Z,"TIL that they're both the same but the hyphen isn't considered fashionable anymore https://grammarist.com/spelling/co-ordinate-vs-coordinate/ and apparently it used to be spelled coördinate!

/lgtm",False,0,CONTRIBUTOR
https://api.github.com/repos/kubernetes/website/issues/comments/1132173408,Update topology-manager.md,k8s-ci-robot,5,1242283358,3,1132173408,0,1132173163,2022-05-19T20:27:21Z,LGTM label has been added.  <details>Git tree hash: a1a01415bb1d4ce4dd91dcda56d61c757399415b</details>,False,0,CONTRIBUTOR
https://api.github.com/repos/kubernetes/website/issues/comments/1133587078,Update topology-manager.md,netlify[bot],5,1242283358,4,1133587078,0,1132173408,2022-05-21T09:23:37Z,"### <span aria-hidden=""true"">✅</span> Deploy Preview for *kubernetes-io-main-staging* ready!


|  Name | Link |
|---------------------------------|------------------------|
|<span aria-hidden=""true"">🔨</span> Latest commit | 3bff833b59355302d983614961e8f9447c605dbb |
|<span aria-hidden=""true"">🔍</span> Latest deploy log | https://app.netlify.com/sites/kubernetes-io-main-staging/deploys/6286a6daf1b78300086e4b2f |
|<span aria-hidden=""true"">😎</span> Deploy Preview | https://deploy-preview-33836--kubernetes-io-main-staging.netlify.app |
|<span aria-hidden=""true"">📱</span> Preview on mobile | <details><summary> Toggle QR Code... </summary><br /><br />![QR Code](https://app.netlify.com/qr-code/eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1cmwiOiJodHRwczovL2RlcGxveS1wcmV2aWV3LTMzODM2LS1rdWJlcm5ldGVzLWlvLW1haW4tc3RhZ2luZy5uZXRsaWZ5LmFwcCJ9.My3z54KHrgwIIQ-9rxvl2tgZYwGbUqCh2xU2yvRLtCY)<br /><br />_Use your smartphone camera to open QR code link._</details> |
---

_To edit notification comments on pull requests, go to your [Netlify site settings](https://app.netlify.com/sites/kubernetes-io-main-staging/settings/deploys#deploy-notifications)._",False,0,NONE
https://api.github.com/repos/kubernetes/website/issues/comments/1133604801,Update topology-manager.md,sftim,5,1242283358,5,1133604801,0,1133587078,2022-05-21T11:37:38Z,"/approve
/kind cleanup
",False,0,CONTRIBUTOR
https://api.github.com/repos/kubernetes/website/issues/comments/1133604854,Update topology-manager.md,k8s-ci-robot,5,1242283358,6,1133604854,0,1133604801,2022-05-21T11:38:02Z,"[APPROVALNOTIFIER] This PR is **APPROVED**

This pull-request has been approved by: *<a href=""https://github.com/kubernetes/website/pull/33836#issuecomment-1133604801"" title=""Approved"">sftim</a>*

The full list of commands accepted by this bot can be found [here](https://go.k8s.io/bot-commands?repo=kubernetes%2Fwebsite).

The pull request process is described [here](https://git.k8s.io/community/contributors/guide/owners.md#the-code-review-process)

<details >
Needs approval from an approver in each of these files:

- ~~[content/en/OWNERS](https://github.com/kubernetes/website/blob/main/content/en/OWNERS)~~ [sftim]

Approvers can indicate their approval by writing `/approve` in a comment
Approvers can cancel approval by writing `/approve cancel` in a comment
</details>
<!-- META={""approvers"":[]} -->",False,0,CONTRIBUTOR
https://api.github.com/repos/kubernetes/website/issues/33837,[ja] updated configure-liveness-readiness-startup-probes.md,Arhell,5,1242360914,1,1242360914,0,0,2022-05-19T21:43:26Z,"en PR https://github.com/kubernetes/website/pull/32221/files
/assign @atoato88
/assign @nasa9084",True,0,MEMBER
https://api.github.com/repos/kubernetes/website/issues/comments/1133587337,[ja] updated configure-liveness-readiness-startup-probes.md,netlify[bot],5,1242360914,2,1133587337,0,1242360914,2022-05-21T09:25:31Z,"### <span aria-hidden=""true"">✅</span> Pull request preview available for checking
Built [without sensitive environment variables](https://docs.netlify.com/configure-builds/environment-variables/#sensitive-variable-policy)

|  Name | Link |
|---------------------------------|------------------------|
|<span aria-hidden=""true"">🔨</span> Latest commit | 533a2197fabaf829c9e4e3ab6dd71f1e60928c00 |
|<span aria-hidden=""true"">🔍</span> Latest deploy log | https://app.netlify.com/sites/kubernetes-io-main-staging/deploys/628980f943c90d0008275951 |
|<span aria-hidden=""true"">😎</span> Deploy Preview | https://deploy-preview-33837--kubernetes-io-main-staging.netlify.app |
|<span aria-hidden=""true"">📱</span> Preview on mobile | <details><summary> Toggle QR Code... </summary><br /><br />![QR Code](https://app.netlify.com/qr-code/eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1cmwiOiJodHRwczovL2RlcGxveS1wcmV2aWV3LTMzODM3LS1rdWJlcm5ldGVzLWlvLW1haW4tc3RhZ2luZy5uZXRsaWZ5LmFwcCJ9.Uyk5ILrd8QBfmLaSRXM1H_efgjUSvTPIwlAYNXBCW3Y)<br /><br />_Use your smartphone camera to open QR code link._</details> |
---

_To edit notification comments on pull requests, go to your [Netlify site settings](https://app.netlify.com/sites/kubernetes-io-main-staging/settings/deploys#deploy-notifications)._",False,0,NONE
https://api.github.com/repos/kubernetes/website/issues/comments/1133804025,[ja] updated configure-liveness-readiness-startup-probes.md,atoato88,5,1242360914,3,1133804025,0,1133587337,2022-05-22T02:21:41Z,/lgtm,False,0,CONTRIBUTOR
https://api.github.com/repos/kubernetes/website/issues/comments/1133804069,[ja] updated configure-liveness-readiness-startup-probes.md,k8s-ci-robot,5,1242360914,4,1133804069,0,1133804025,2022-05-22T02:21:56Z,LGTM label has been added.  <details>Git tree hash: 35199444160508859beeb4bd940737df4899aeee</details>,False,0,CONTRIBUTOR
https://api.github.com/repos/kubernetes/website/issues/comments/1134191445,[ja] updated configure-liveness-readiness-startup-probes.md,nasa9084,5,1242360914,5,1134191445,0,1133804069,2022-05-23T05:16:15Z,/approve,False,0,MEMBER
https://api.github.com/repos/kubernetes/website/issues/comments/1134191700,[ja] updated configure-liveness-readiness-startup-probes.md,k8s-ci-robot,5,1242360914,6,1134191700,0,1134191445,2022-05-23T05:16:39Z,"[APPROVALNOTIFIER] This PR is **APPROVED**

This pull-request has been approved by: *<a href=""https://github.com/kubernetes/website/pull/33837#issuecomment-1134191445"" title=""Approved"">nasa9084</a>*

The full list of commands accepted by this bot can be found [here](https://go.k8s.io/bot-commands?repo=kubernetes%2Fwebsite).

The pull request process is described [here](https://git.k8s.io/community/contributors/guide/owners.md#the-code-review-process)

<details >
Needs approval from an approver in each of these files:

- ~~[content/ja/OWNERS](https://github.com/kubernetes/website/blob/main/content/ja/OWNERS)~~ [nasa9084]

Approvers can indicate their approval by writing `/approve` in a comment
Approvers can cancel approval by writing `/approve cancel` in a comment
</details>
<!-- META={""approvers"":[]} -->",False,0,CONTRIBUTOR
https://api.github.com/repos/encode/uvicorn/issues/1488,Import application before running the event loop,Kludex,3,1236343221,1,1236343221,0,0,2022-05-15T17:10:43Z,"- Replaces #1110
- Solves #346",True,0,MEMBER
https://api.github.com/repos/encode/uvicorn/issues/comments/1159580180,Import application before running the event loop,graingert,3,1236343221,2,1159580180,0,1236343221,2022-06-18T23:14:43Z,how does this interact with reload?,False,0,MEMBER
https://api.github.com/repos/encode/uvicorn/issues/comments/1159646372,Import application before running the event loop,Kludex,3,1236343221,3,1159646372,0,1159580180,2022-06-19T07:56:14Z,"@graingert With the simple application:
```python
import anyio


async def example():
    await anyio.sleep(0)
    print(""All good!"")


anyio.run(example)


async def app(scope, receive, send):
    pass
```
Running `uvicorn` with `reload`:

```bash
(uvicorn3.8.12) ➜  uvicorn git:(feat/import-app-before-event-loop) ✗ uvicorn main:app --reload --port 8005
INFO:     Will watch for changes in these directories: ['/Users/marcelotryle/Development/encode/uvicorn']
INFO:     Uvicorn running on http://127.0.0.1:8005 (Press CTRL+C to quit)
INFO:     Started reloader process [6724] using watchgod
All good!
INFO:     Started server process [6738]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
WARNING:  WatchGodReload detected file change in '['/Users/marcelotryle/Development/encode/uvicorn/main.py']'. Reloading...
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [6738]
All good!
INFO:     Started server process [6774]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
```",False,0,MEMBER
https://api.github.com/repos/encode/uvicorn/issues/comments/1160802645,Import application before running the event loop,Kludex,3,1236343221,4,1160802645,0,1159646372,2022-06-20T20:01:01Z,"I'm not able to reproduce the issue that motivated this PR.

I'm going to close this. If someone wants to try to reproduce, and come back with the proof again, we take a decision then. ",False,0,MEMBER
https://api.github.com/repos/encode/uvicorn/issues/1489,Refactor uvicorn logger setup,Kludex,13,1236349167,1,1236349167,0,0,2022-05-15T17:37:14Z,"- Closes #562

## Changes

- Add `uvicorn.http` and `uvicorn.websockets` loggers.
- Replace `uvicorn.error` by `uvicorn.server` logger.

## Missing

- [ ] Docs update.
- [ ] Check  with `UvicornWorker`.",True,0,MEMBER
https://api.github.com/repos/encode/uvicorn/issues/comments/1160829782,Refactor uvicorn logger setup,Kludex,13,1236349167,2,1160829782,0,1236349167,2022-06-20T20:37:40Z,"> Did I get that right?

You did.

> Do you think it might help to add some docs explaining what all the Uvicorn loggers do? Maybe on the [server behavior page](https://www.uvicorn.org/server-behavior/), cross-referencing it with the [logging settings section](https://www.uvicorn.org/settings/#logging)? I'm happy to update the docs in a separate PR if that makes more sense.

I'd be happy to receive help. You can use this branch if you want, so we can merge the functionality with the docs together (I'm not possessive with my branches 👀 ).

But do we agree with those changes? I'm not sure about it myself... @br3ndonland @euri10 opinions?",False,0,MEMBER
https://api.github.com/repos/encode/uvicorn/issues/comments/1160958984,Refactor uvicorn logger setup,br3ndonland,13,1236349167,3,1160958984,0,1160829782,2022-06-20T23:42:47Z,"Ok cool! I will get some docs pushed up here soon.

And definitely open to suggestions on the descriptions and such. I will defer to @euri10 for the direction we want to go overall.",False,0,CONTRIBUTOR
https://api.github.com/repos/encode/uvicorn/issues/comments/1161955896,Refactor uvicorn logger setup,euri10,13,1236349167,4,1161955896,0,1160958984,2022-06-21T16:03:07Z,"well I'd be in favor of NOT changing the name `uvicorn.error`

Not because I think the name is not confusing, it is.

But because it mimics what gunicorn does with gunicorn.error` and dozens of users, not to say hundreds or even thousands, are on a daily basis using, seeing this same exact name, so really I don't get the fuss on this (last commit on https://github.com/benoitc/gunicorn/blob/master/examples/logging.conf is 20 feb 2014) : people literally use this name for almost ten years now....

I don't think we gain anything in changing something that people are most likely used to now for a long time.

This said, I won't oppose it should people feel strongly about it, but to me there's almost no gain in changing, so I'll let you choose :)
",False,0,MEMBER
https://api.github.com/repos/encode/uvicorn/issues/comments/1161965435,Refactor uvicorn logger setup,Kludex,13,1236349167,5,1161965435,0,1161955896,2022-06-21T16:11:30Z,I'm totally fine with not changing it. :),False,0,MEMBER
https://api.github.com/repos/encode/uvicorn/issues/comments/1162135181,Refactor uvicorn logger setup,Kludex,13,1236349167,6,1162135181,0,1161965435,2022-06-21T18:10:04Z,"Let's not do this then. I've closed #562. If someone has a good argument, and/or strategy to achieve it, feel free to comment on the issue.",False,0,MEMBER
https://api.github.com/repos/encode/uvicorn/issues/comments/1163628488,Refactor uvicorn logger setup,br3ndonland,13,1236349167,7,1163628488,0,1162135181,2022-06-22T21:34:58Z,That sounds good. I'm also fine with keeping the current logger name.,False,0,CONTRIBUTOR
https://api.github.com/repos/encode/uvicorn/issues/comments/1164271284,Refactor uvicorn logger setup,doncatnip,13,1236349167,8,1164271284,0,1163628488,2022-06-23T11:02:24Z,"> This said, I won't oppose it should people feel strongly about it, but to me there's almost no gain in changing, so I'll let you choose :)

I don't feel very strongly about it, as I don't work with uvicorn anymore - but I do find the reasoning to keep the current scheme questionable at best. Gunicorn using a very confusing and in fact problem-inducing (i.e. log monitoring) naming scheme is not a good reason to propagate that anti-pattern further. I also wonder if the extend of the confusion can be compared. Uvicorn greets the user with ""[gunicorn.error] Application startup complete"" for example.",False,0,NONE
https://api.github.com/repos/encode/uvicorn/issues/comments/1164404456,Refactor uvicorn logger setup,alexsantos,13,1236349167,9,1164404456,0,1164271284,2022-06-23T13:23:49Z,"For me as a newcomer it was really confusing to see a server starting and greeting me with a bunch of errors saying things like
 `INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)`.
For me, stderr has been always to log errors and not informational messages. For instance, starting uvicorn like this:
`uvicorn main:app 2>error.log 1>out.log`
will result in a file error.log with the start information.
I'm using Google Cloud Run and Cloud Functions and this might trigger alerts that aren't real errors.",False,0,NONE
https://api.github.com/repos/encode/uvicorn/issues/comments/1293234536,Refactor uvicorn logger setup,Kludex,13,1236349167,10,1293234536,0,1164404456,2022-10-27T09:18:14Z,"I've changed my mind. I'm strong about this change now. I'm reopening this PR.

I'll update the documentation.",False,0,MEMBER
https://api.github.com/repos/encode/uvicorn/issues/comments/1364715010,Refactor uvicorn logger setup,Kludex,13,1236349167,11,1364715010,0,1293234536,2022-12-25T17:40:50Z,"I'm closing this as stale.

If someone wants to help me, and take this, I'd appreciate.",False,0,MEMBER
https://api.github.com/repos/encode/uvicorn/issues/comments/1366132754,Refactor uvicorn logger setup,zanieb,13,1236349167,12,1366132754,0,1364715010,2022-12-27T19:43:03Z,I'd consider taking a poke at this; what critical parts remain?,False,0,NONE
https://api.github.com/repos/encode/uvicorn/issues/comments/1366159024,Refactor uvicorn logger setup,Kludex,13,1236349167,13,1366159024,0,1366132754,2022-12-27T20:27:10Z,"I think the ""missing"" section on the description. :eyes:",False,0,MEMBER
https://api.github.com/repos/encode/uvicorn/issues/comments/2078552326,Refactor uvicorn logger setup,ltbd78,13,1236349167,14,2078552326,0,1366159024,2024-04-26T03:04:37Z,"Would push for this change, as I dug into a rabbit hole of confusion seeing the logger named as `uvicorn.error`

Like a user said earlier, what if if we rename `uvicorn.access` to`uvicorn.client` and `uvicorn.error` to `uvicorn.client`?",False,0,NONE
https://api.github.com/repos/encode/uvicorn/issues/1490,Replaced watchgod with watchfiles,timkofu,3,1237396259,1,1237396259,0,0,2022-05-16T16:21:58Z,"As it's [deprecated](https://pypi.org/project/watchgod/).

> The package under the name watchgod will not be further developed and will only receive critical security fixes.",True,0,CONTRIBUTOR
https://api.github.com/repos/encode/uvicorn/issues/comments/1127877396,Replaced watchgod with watchfiles,Kludex,3,1237396259,2,1127877396,0,1237396259,2022-05-16T16:22:54Z,https://github.com/encode/uvicorn/pull/1437,False,0,MEMBER
https://api.github.com/repos/encode/uvicorn/issues/comments/1127878467,Replaced watchgod with watchfiles,timkofu,3,1237396259,3,1127878467,0,1127877396,2022-05-16T16:23:56Z,"Ah, alright.",False,0,CONTRIBUTOR
https://api.github.com/repos/encode/uvicorn/issues/comments/1127933920,Replaced watchgod with watchfiles,Kludex,3,1237396259,4,1127933920,0,1127878467,2022-05-16T17:20:29Z,"Thanks for the PR @timkofu 😁

But as you see, that's already in progress 🙏",False,0,MEMBER
https://api.github.com/repos/encode/uvicorn/issues/1497,Server lifecycle,bwhmather,6,1239808896,1,1239808896,0,0,2022-05-18T11:20:31Z,"Adds `close`, `wait_closed` and `start_serving` methods that match the semantics of `asyncio.Server`.
Adds `sockets` argument constructor in order to enable new methods to be used with existing bindings.

This makes it easier to use uvicorn as part of a larger application, by making it possible to block until a service has started, and easier to shut down cleanly.



For background, we use `uvicorn` extensively and are very happy with its behaviour in production, but have had a lot of difficulty with server lifecycle when trying to use it as part of our test suite.  In particular:
 1. It's not currently possible to block until the service has started without polling.
 2. Shutting a background server down and blocking until completion requires keeping a reference to both the server and an `asyncio.Task` wrapping `serve`.
 3. Waiting for the main loop to poll while shutting down currently dominates our test run time.
 4. Signal handler installation interferes with signal handlers from other instances, and with test shutdown.

It also took a fair bit of digging in the source code to figure out that calling `Server.shutdown` from outside does not do what one might expect.

I'd like to propose a few changes, the first of which I have attempted in this PR, which I think will resolve the issues we've encountered:

 1. Add `close`, `wait_closed` and `start_serving` methods that match the semantics of `asyncio.Server` (resolves issues 1 and 2).
 2. Use an `asyncio.Event` to make it so that `close` can pre-empt the polling loops (resolves issue 3).
 3. Add a `register_event_handlers` keyword argument to `serve` which can be used to disable registering of event handlers (resolves issue 4).
 4. Make any methods which would result in breakage if called from outside the class private.

If you are happy with this approach then I would be glad to work on 2, 3 and 4 as follow ups.

Resolves:
  - https://github.com/encode/uvicorn/issues/1301, with behaviour matching what @tomchristie suggests.
  - https://github.com/encode/uvicorn/issues/1375, although with a different API.
  - https://github.com/encode/uvicorn/issues/742",True,0,NONE
https://api.github.com/repos/encode/uvicorn/issues/comments/1168613627,Server lifecycle,florimondmanca,6,1239808896,2,1168613627,0,1239808896,2022-06-28T11:43:25Z,"As far as I can see, this PR introduces public API changes to `Server`, which means ideally there should be some documentation changes. Eg. does it affect the ""Running programmatically"" section? (Note there were some recent changes: #1525.)

The reason is, right now my main question to assess these changes would be: how would you use the introduced changes to solve 1) and 2) _in your situation_? What's your current programmatic usage of Uvicorn like, and what does it become with these changes?

There are several ways we could go about ""Manage server lifecycle programmatically"".

For example another way would be taking inspiration from structured concurrency, and promoting an async context manager usage. It would do the equivalent of `start_serving()` on aenter, and `.shutdown()` on aclose (but without exposing those internals):

```python
async with Server(...):
    # Server has started (no need to poll)
    ...

# Server has shut down
```

We'd allow users to use this instead of having to write an equivalent of our `run_server()` test utility, which the current ""expose methods"" proposal would require.

Non-block usage would be possible with `AsyncExitStack`:

```python
from contextlib import AsyncExittack

exit_stack = AsyncExitStack()

await exit_stack.enter_async_context(Server(...))  # Starts up
...
await exit_stack.aclose()  # Shuts down
```

Also, I'm not sure what the use case for a `.close()` or `.wait_closed()` couple of methods would be. Could you also illustrate how you'd expect to use those in your setup?",False,0,MEMBER
https://api.github.com/repos/encode/uvicorn/issues/comments/1168681837,Server lifecycle,bwhmather,6,1239808896,3,1168681837,0,1168613627,2022-06-28T12:51:10Z,"Hi @florimondmanca - Regarding our situation:  Our test fixtures currently look a bit like this:

```python
@pytest.fixture
async def server() -> AsyncIterator[str]:
    host = ""127.0.0.1""
    port = choose_port(host)

    app = create_app()

    # Uvicorn will always try to override the log config with something.
    # These settings should cause this to be a no-op.
    log_config = {""version"": 1, ""disable_existing_loggers"": False, ""incremental"": True}

    uvicorn_config = uvicorn.config.Config(
        app, host=host, port=port, reload=False, workers=1, log_config=log_config
    )

    server = uvicorn.server.Server(uvicorn_config)

    # TODO uvicorn unconditionally overrides signal handlers if called from
    # the main thread.  This completely breaks `oaknorth_processes`' soft
    # shutdown mechanism if we don't do something about it.  A proper fix is
    # needed upstream.
    server.install_signal_handlers = lambda: None  # type: ignore

    task = asyncio.create_task(server.serve())

    while not server.started:
        await asyncio.sleep(0.01)

    yield f""http://{host}:{port}""

    server.should_exit = True
    try:
        await asyncio.wait_for(task, 1.0)
    except asyncio.exceptions.TimeoutError:
        logger.exception(""Could not shutdown server cleanly"")     
```
It all works most of the time, but it's brittle (for example, if the server fails to start it will block forever) and the polling, both in the fixture and the `shutdown` method) makes it either slow or inneficient.  It has also taken us a couple of years of patching and rewriting as we encounter bugs to get it shaken down even this far.


Regarding the choice of interface:  I picked this exact set of methods because it matches the interface of `asyncio.Server` in the standard library (https://docs.python.org/3/library/asyncio-eventloop.html?highlight=wait_closed#asyncio.Server).  Give that it supports my use case (as well as pretty much everything I could think of doing including blocking and non-blocking mode, triggering shutdown from inside a request handler, signal handler, or from another thread, waiting for startup and shutdown)  I thought it best not to try to be too clever.

Strongly agree on making server a context manager, but I would prefer to do what the stdlib does and implement `__aenter__` and `__aexit__` as conveneince wrappers.  Given that, I think it makes more makes sense to leave them out of this PR.



Going back to our situation:  in the ideal case, I would like for our test fixtures to look something like this:

```python
@pytest.fixture
async def server() -> AsyncIterator[str]:
    host = ""127.0.0.1""
    port = choose_port(host)

    app = create_app()

    uvicorn_config = uvicorn.config.Config(
        app,
        host=host,
        port=port,
        reload=False,
        workers=1,
        register_signal_handlers=False,
        log_config=None,
    )

    async with uvicorn.server.Server(uvicorn_config):
        yield f""http://{host}:{port}""
```

With only this PR merged, we could go to something like this:
```python
@pytest.fixture
async def server() -> AsyncIterator[str]:
    host = ""127.0.0.1""
    port = choose_port(host)

    app = create_app()

    # Uvicorn will always try to override the log config with something.
    # These settings should cause this to be a no-op.
    log_config = {""version"": 1, ""disable_existing_loggers"": False, ""incremental"": True}

    uvicorn_config = uvicorn.config.Config(
        app, host=host, port=port, reload=False, workers=1, log_config=log_config
    )

    server = uvicorn.server.Server(uvicorn_config)

    await server.start_serving()
    
    yield f""http://{host}:{port}""

    server.close()
    await server.wait_closed()
```    
which would already be a substantial improvement.",False,0,NONE
https://api.github.com/repos/encode/uvicorn/issues/comments/1168806336,Server lifecycle,florimondmanca,6,1239808896,4,1168806336,0,1168681837,2022-06-28T14:33:29Z,"@bwhmather Thanks.

I think I understand the idea of having aenter/aexit be straight-up calls to other public methods, basically making the async context manager usage a shorthand more than anything else.

My comment on documentation still holds, I believe. I think the idea of a publicly documented way to run a server programmatically has been around for a while. It'd be great if we could clear that out with a fully documented and refined solution. Please note the current documentation: https://www.uvicorn.org/#config-and-server-instances

For reference, we use a Uvicorn server in the HTTPX test suite, and what we do is run Uvicorn in a thread instead. Looks like this:

```python
class TestServer(Server):
    def install_signal_handlers(self) -> None:
        pass

def serve_in_thread(server: Server):
    thread = threading.Thread(target=server.run)
    thread.start()
    try:
        while not server.started:
            time.sleep(1e-3)
        yield server
    finally:
        server.should_exit = True
        thread.join()

@pytest.fixture(scope=""session"")
def server():
    config = Config(app=app, lifespan=""off"", loop=""asyncio"")
    server = TestServer(config=config)
    yield from serve_in_thread(server)
```

I believe it suffers from some of the same limitations, esp. regarding hanging on startup failures, as well as asyncio/threading interactions. I'm curious what we'd have to change in HTTPX to use the methods proposed here.",False,0,MEMBER
https://api.github.com/repos/encode/uvicorn/issues/comments/1169925755,Server lifecycle,bwhmather,6,1239808896,5,1169925755,0,1168806336,2022-06-29T12:34:54Z,"> For reference, we use a Uvicorn server in the HTTPX test suite, and what we do is run Uvicorn in a thread instead. Looks like this:

Yup, that looks very familiar!  We were doing the same, but then tried to apply technique to a different project which expected to be create the app with already created resources which referenced the main thread event loop.

Regarding docs:  Sorry, yes, of course.

Regarding #1301:  You are right.  This doesn't actually resolve it.  I think I misread the `if self.should_exit` check after `self.startup`, but this was inherited from before and doesn't fix `_shutdown` not being called.  Best fixed as a follow up.",False,0,NONE
https://api.github.com/repos/encode/uvicorn/issues/comments/1169940287,Server lifecycle,bwhmather,6,1239808896,6,1169940287,0,1169925755,2022-06-29T12:50:09Z,"One other thing that is concerning me on re-reading this PR is the question of what to do about exceptions?  Should they be re-raised by `wait_closed()`, or simply swallowed?

[asyncio.Server](https://github.com/python/cpython/blob/f882d33778ee2625ab32d90e28edb6878fb8af93/Lib/asyncio/base_events.py#L274) appears to opt for swallowing any errors.",False,0,NONE
https://api.github.com/repos/encode/uvicorn/issues/comments/1456630072,Server lifecycle,adriangb,6,1239808896,7,1456630072,0,1169940287,2023-03-06T17:48:20Z,This seems like a great idea. I’m in favor of promoting and developing better APIs to run Uvicorn programmatically ,False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/10793,"composer scripts, process timeouts while debugging",staabm,4,1245113152,1,1245113152,0,0,2022-05-23T12:45:35Z,"In some of our projects we use composer scripts like
```
		""phpunit"": [
			""phpunit -c tests/default/config/phpunit.xml"",
			""phpunit -c tests/rules/config/phpunit.xml"",
			""phpunit -c tests/stringify/config/phpunit.xml"",
			""phpunit -c tests/defaultFetchAssoc/config/phpunit.xml"",
			""phpunit -c tests/defaultFetchNumeric/config/phpunit.xml""
		]
```

when debugging tests with xdebug this leads sometimes to timeouts:

```
$ composer phpunit
> @putenv DBA_REFLECTOR=pdo-mysql
> @putenv DBA_MODE=replay
> phpunit -c tests/default/config/phpunit.xml
PHPUnit 9.5.20 #StandWithUkraine

...............................................................  63 / 241 ( 26%)
............................................................... 126 / 241 ( 52%)
............................................................... 189 / 241 ( 78%)
....................................................            241 / 241 (100%)

Time: 00:00.072, Memory: 90.00 MB

OK (241 tests, 241 assertions)
> phpunit -c tests/rules/config/phpunit.xml
PHPUnit 9.5.20 #StandWithUkraine

.SESESThe following exception is caused by a process timeout
Check https://getcomposer.org/doc/06-config.md#process-timeout for details

In Process.php line 1204:

  The process ""phpunit -c tests/rules/config/phpunit.xml"" exceeded the timeout of 300 seconds.
```

couldn't/shouldn't composer use a unlimited/rather long timeout when running with xdebug?",True,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1135894244,"composer scripts, process timeouts while debugging",Seldaek,4,1245113152,2,1135894244,0,1245113152,2022-05-24T13:01:28Z,"The cause and a possible solution are here https://getcomposer.org/doc/06-config.md#process-timeout - that said, I am wondering if we shouldn't allow longer/unlimited execution time for scripts running via the exec/run-script commands. These are totally different use cases than the internal git processes we use which we don't want to get stuck forever. That'd remove the need for this disableProcessTimeout hack.",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1136089141,"composer scripts, process timeouts while debugging",Seldaek,4,1245113152,3,1136089141,0,1135894244,2022-05-24T15:39:52Z,"I think we could add a `script-timeout` config setting which would default to 0 and be used as timeout for those processes. It looks like it'll require a few changes to ProcessExecutor tho, so not sure if it is really reasonable or if you should just use the `disableProcessTimeout` workaround from the docs.",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1164373337,"composer scripts, process timeouts while debugging",Seldaek,4,1245113152,4,1164373337,0,1136089141,2022-06-23T12:54:37Z,"Yeah I don't see a way to do this clean, so rather close sorry.",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1164375202,"composer scripts, process timeouts while debugging",staabm,4,1245113152,5,1164375202,0,1164373337,2022-06-23T12:56:24Z,thx for considering!,False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/10796,[Help Wanted] Increasing test coverage of Command classes,Seldaek,25,1246145167,1,1246145167,0,0,2022-05-24T08:04:32Z,"As you can see on this image, Command classes have very poor coverage currently (16% of lines covered in total):

<img src=""https://user-images.githubusercontent.com/183678/169980310-62da227b-44ff-4a45-988f-054970436f51.png"" width=200>

**Edit: To see latest guidelines on what to work on see https://github.com/composer/composer/issues/10796#issuecomment-1277340969**

Here some examples of how to write sane integration tests for most commands: 

https://github.com/composer/composer/blob/176d25851d1f99345c652a6ecbc7c3787071218d/tests/Composer/Test/Command/RunScriptCommandTest.php#L92-L113

https://github.com/composer/composer/blob/176d25851d1f99345c652a6ecbc7c3787071218d/tests/Composer/Test/Command/ConfigCommandTest.php#L23-L52

https://github.com/composer/composer/blob/70f2dd6eddd5916f70b3d73dd3170a3d2d3a7681/tests/Composer/Test/Command/BumpCommandTest.php#L28-L47

If you feel like helping, PRs are very much welcome, I don't think we absolutely need 100% coverage but having the most common use cases covered would already be very valuable. Please target the `main` branch if you want to contribute some, and feel free to announce it here if you start some larger chunk of work to avoid duplicating efforts.",True,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1179593554,[Help Wanted] Increasing test coverage of Command classes,theoboldalex,25,1246145167,2,1179593554,0,1246145167,2022-07-09T19:17:43Z,@Seldaek I'd love to take on some of this work. I have opened a first PR here #10932 and will start to work my way through the commands.,False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1179594771,[Help Wanted] Increasing test coverage of Command classes,Seldaek,25,1246145167,3,1179594771,0,1179593554,2022-07-09T19:28:27Z,"@theoboldalex great, thanks! Maybe wait until I get a chance to review the first one to make sure you don't run off and do more of them with the wrong assumptions. I'll try to get to it soon.

Also note the listing above is a bit outdated as I tried to work on this here and there when touching commands the last few months. But there is still plenty to be done :) ",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1217552884,[Help Wanted] Increasing test coverage of Command classes,ralflang,25,1246145167,4,1217552884,0,1179594771,2022-08-17T07:15:38Z,"No promises but I may make the occassional PR every now and then.
Might be a good learning exercise. I have been playing around with the Command, Plugin, Capable ... parts of the codebase last month.

",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1221246207,[Help Wanted] Increasing test coverage of Command classes,Seldaek,25,1246145167,5,1221246207,0,1217552884,2022-08-20T06:56:02Z,"Update, we're at 36% (up from 16!) already now:

<img width=""400"" alt=""image"" src=""https://user-images.githubusercontent.com/183678/185733135-3854c0b4-dd49-435f-ac6e-626655a36c82.png"">
",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1264150734,[Help Wanted] Increasing test coverage of Command classes,tomekpryjma,25,1246145167,6,1264150734,0,1221246207,2022-10-01T00:21:55Z,I'd like to help out with this now and again - is there a way to see the current coverage?,False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1275855328,[Help Wanted] Increasing test coverage of Command classes,Seldaek,25,1246145167,7,1275855328,0,1264150734,2022-10-12T09:20:30Z,"@tomekpryjma nope sorry, gotta run the tests with `--coverage-html foo` yourself then check in `foo/index.html` for the output.",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1277340969,[Help Wanted] Increasing test coverage of Command classes,Seldaek,25,1246145167,8,1277340969,0,1275855328,2022-10-13T09:45:33Z,"Now at 41%! Here are the classes still needing the most effort IMO:

- [ ] BaseDependencyCommand.php (needs to be tested via why/why-not commands)
- [ ] CheckPlatformReqsCommand.php (WIP https://github.com/composer/composer/pull/11079)
- [x] FundCommand.php
- [x] HomeCommand.php (WIP https://github.com/composer/composer/pull/11254 probably only can test with the --show flag enabled)
- [ ] InstallCommand.php
- [x] SuggestsCommand.php (WIP https://github.com/composer/composer/pull/11162)
- [x] ValidateCommand.php
- [x] RemoveCommand.php
- [ ] UpdateCommand.php with --interactive flag (needs to run the command [in interactive mode](https://github.com/symfony/symfony/blob/3a4166e4e99d437a368ff05edd883a56499ec279/src/Symfony/Component/Console/Tester/ApplicationTester.php#L43) to test the uncovered bits, and use `$applicationTester->setInputs()` to configure/fake the user inputs)
- [ ] InitCommand.php & PackageDiscoveryTrait.php (needs to run the command [in interactive mode](https://github.com/symfony/symfony/blob/3a4166e4e99d437a368ff05edd883a56499ec279/src/Symfony/Component/Console/Tester/ApplicationTester.php#L43) to test the uncovered bits, and use `$applicationTester->setInputs()` to configure/fake the user inputs)
- [ ] ShowCommand.php (tested quite a bit but still only 40% covered as it is a large one)
- [ ] GlobalCommand.php (might be tricky to test as it requires some internal knowledge)
 
These need an install to be run to actual get a working vendor dir, using packages with type `metapackage` helps making them installable without actual source:

- [ ] StatusCommand.php
- [x] ReinstallCommand.php
",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1288774783,[Help Wanted] Increasing test coverage of Command classes,giulio-Joshi,25,1246145167,9,1288774783,0,1277340969,2022-10-24T10:07:03Z,Is this issue still relevant?,False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1290158655,[Help Wanted] Increasing test coverage of Command classes,Seldaek,25,1246145167,10,1290158655,0,1288774783,2022-10-25T08:09:57Z,"@giulio-Joshi yes for sure, not much happened since my last comment above yours.",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1290168176,[Help Wanted] Increasing test coverage of Command classes,giulio-Joshi,25,1246145167,11,1290168176,0,1290158655,2022-10-25T08:17:47Z,"Thanks for your answer.
 I was planning on adding some more tests in the area, but paused the activity since my related PR had no feedback.
I was wondering if there was something wrong about it.",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1290210497,[Help Wanted] Increasing test coverage of Command classes,Seldaek,25,1246145167,12,1290210497,0,1290168176,2022-10-25T08:51:04Z,"No it's just been 8 days, I'll get to it :)",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1294826938,[Help Wanted] Increasing test coverage of Command classes,yesdevnull,25,1246145167,13,1294826938,0,1290210497,2022-10-28T10:28:08Z,"Putting my hand up to work on tests for `SuggestsCommand`. Will submit a PR with my progress in the next ~24 hours, I currently have 100% for that command but I want to finesse the tests so they're not just chasing coverage.

PR created here: #11162.",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1500969678,[Help Wanted] Increasing test coverage of Command classes,siims-biz,25,1246145167,14,1500969678,0,1294826938,2023-04-08T20:14:27Z,Do you still need help in getting parts of Composer tested?,False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/1500972732,[Help Wanted] Increasing test coverage of Command classes,Seldaek,25,1246145167,15,1500972732,0,1500969678,2023-04-08T20:33:26Z,@siims-biz yes the list in https://github.com/composer/composer/issues/10796#issuecomment-1277340969 above is still more or less accurate ,False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1501095725,[Help Wanted] Increasing test coverage of Command classes,siims-biz,25,1246145167,16,1501095725,0,1500972732,2023-04-09T10:25:56Z,@Seldaek What kind of skill/talent/tools are required/useful to contribute with testing?,False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/1501112005,[Help Wanted] Increasing test coverage of Command classes,Seldaek,25,1246145167,17,1501112005,0,1501095725,2023-04-09T11:58:53Z,"@siims-biz knowledge of PHPUnit, some knowledge of composer (from user perspective good, internals better), the easy ones have been covered already though so if you aren't super familiar with all this I would say maybe rather find something else to work on, but up to you :)",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1508158624,[Help Wanted] Increasing test coverage of Command classes,stof,25,1246145167,18,1508158624,0,1501112005,2023-04-14T08:47:13Z,Now at 52%,False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1585077284,[Help Wanted] Increasing test coverage of Command classes,theoboldalex,25,1246145167,19,1585077284,0,1508158624,2023-06-09T20:10:33Z,I'm going to make a start on testing `ReinstallCommand` tonight and will try to pick up `StatusCommand` after that if time permits.,False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1603945467,[Help Wanted] Increasing test coverage of Command classes,Seldaek,25,1246145167,20,1603945467,0,1585077284,2023-06-23T08:47:03Z,"54.4% now, thanks everyone involved so far!

<img width=""599"" alt=""image"" src=""https://github.com/composer/composer/assets/183678/f4f514f9-557d-409b-9666-51d368ab69eb"">

Here are the classes still needing the most effort, but overall we are really in a much better spot now I would say with the most critical commands pretty well covered:

- [x] BaseDependencyCommand.php (needs to be tested via why/why-not commands)
- [ ] UpdateCommand.php with --interactive flag (needs to run the command [in interactive mode](https://github.com/symfony/symfony/blob/3a4166e4e99d437a368ff05edd883a56499ec279/src/Symfony/Component/Console/Tester/ApplicationTester.php#L43) to test the uncovered bits, and use `$applicationTester->setInputs()` to configure/fake the user inputs)
- [x] InitCommand.php & PackageDiscoveryTrait.php (needs to run the command [in interactive mode](https://github.com/symfony/symfony/blob/3a4166e4e99d437a368ff05edd883a56499ec279/src/Symfony/Component/Console/Tester/ApplicationTester.php#L43) to test the uncovered bits, and use `$applicationTester->setInputs()` to configure/fake the user inputs)
- [x] ShowCommand.php (tested quite a bit but still only 40% covered as it is a large one)
- [ ] GlobalCommand.php (might be tricky to test as it requires some internal knowledge)
 
These need an install to be run to actual get a working vendor dir, using packages with type `metapackage` helps making them installable without actual source:

- [ ] StatusCommand.php

",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1625691877,[Help Wanted] Increasing test coverage of Command classes,rad8329,25,1246145167,21,1625691877,0,1603945467,2023-07-07T16:58:50Z,Will take test cases for commands `why` and `why-not`,False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1648999602,[Help Wanted] Increasing test coverage of Command classes,rad8329,25,1246145167,22,1648999602,0,1625691877,2023-07-25T03:26:09Z,"Hi @Seldaek, I'd love to continue working on the above checklist, but I'm still waiting for [Tests for base dependency command #11547](https://github.com/composer/composer/pull/11547) feedback, once I've received first feedback I could replicate that same approach in my upcoming PRs, thanks",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1685168555,[Help Wanted] Increasing test coverage of Command classes,rad8329,25,1246145167,23,1685168555,0,1648999602,2023-08-20T03:55:02Z,"Will try to complete `show` command test coverage, currently it is 55%",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1697483088,[Help Wanted] Increasing test coverage of Command classes,stof,25,1246145167,24,1697483088,0,1685168555,2023-08-29T13:48:42Z,"@Seldaek this should be re-opened. The PR #11547 contributed to this by adding more tests, but we are still not done yet.",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1697490679,[Help Wanted] Increasing test coverage of Command classes,stof,25,1246145167,25,1697490679,0,1697483088,2023-08-29T13:53:10Z,"now at 58.11%:
![image](https://github.com/composer/composer/assets/439401/db01ff58-488b-432a-b4c9-7a31223f4509)
",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1749086183,[Help Wanted] Increasing test coverage of Command classes,greew,25,1246145167,26,1749086183,0,1697490679,2023-10-05T15:01:11Z,FYI - I'm writing a lot of test for ShowCommand :),False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/10798,Add audit command to check for security issues,GuySartorelli,23,1246293810,1,1246293810,0,0,2022-05-24T09:53:41Z,"Closes #10329

## Description
Adds an audit command which checks for security vulnerability advisories for installed packages using [the API on packagist.org](https://packagist.org/apidoc#list-security-advisories).

Also adds optional auditing (on by default) to the following commands:
- `create-project`
- `update`
- `install`
- `require`
- `remove`

### Table output (default)
![audit-output-table](https://user-images.githubusercontent.com/36352093/171149069-32cf27c1-3695-4b5a-a42d-8f1964f2b41b.png)

### Plain output
![audit-output-plain](https://user-images.githubusercontent.com/36352093/171149111-5a209074-8bb7-453f-bc28-3f2ce0f77fa1.png)

## Things the audit command does not do:
- Confirm the packages in `vendor` dir match what `composer.lock` says they should be
- If composer.lock is missing, check for advisories based on the constraints in the `composer.json` file

## Out of scope, but would be a good future enhancement
- A new `--no-insecure` (or `--allow-insecure`) flag could be added to `update` and `require`. This could use `Auditor` to take versions with advisories out of the version candidate pool, so that you can't accidentally update to or require an insecure version of a package.
- new config in composer.json where you can declare specific advisories which should be ignored by the audit (e.g. the advisory doesn't apply for your project and you don't want audit to keep failing because of it). Would likely need to include the advisory ID in audit output for this to be feasible.

## Things I'm unsure about
- I don't know how to resolve the PHPStan failures - some seem overly strict so I'm hesitant to just blindly follow them.
- Is there a clean way to test the different formats are working as expected in a unit test?",True,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1135689190,Add audit command to check for security issues,stof,23,1246293810,2,1135689190,0,1246293810,2022-05-24T09:56:49Z,"> I also got the 502 error when trying the query in the browser. This seems to be caused by too many packages in a single request; if I significantly reduce the number of packages in the query, it returns an appropriate response. This is a major blocker for this functionality being implemented, so if someone knows a way around this, please let me know.

Well, one thing you could do is splitting the list of packages into batches (the batch size should be chosen based on the supported size for the Packagist API) and send multiple requests. Thanks to the parallelization support in Composer 2+, you can even send those requests in parallel.",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1135703548,Add audit command to check for security issues,GuySartorelli,23,1246293810,3,1135703548,0,1135689190,2022-05-24T10:05:36Z,"That's a good idea - I couldn't find any information about what the limit actually is but I'll have another look, and failing that I can always do some trial and error to find it. Bonus points for anyone who can point me in the right direction or who already knows what the limit is.

Edit: apparently [the API supports POST requests](https://github.com/composer/packagist/blob/6a40c01ac4d1eb48236ae5242bca152c9034266b/src/Controller/ApiController.php#L316) - I'll experiment a bit and see if I can get that to work, cause it's likely POST requests have a much higher limit. ",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1135869458,Add audit command to check for security issues,Seldaek,23,1246293810,4,1135869458,0,1135703548,2022-05-24T12:40:03Z,"Yes IMO putting the package list in the POST body will fix this as this is AFAIK not size limited at all, unlike URL length which has limits in various places. ",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1138340951,Add audit command to check for security issues,GuySartorelli,23,1246293810,5,1138340951,0,1135869458,2022-05-26T09:27:33Z,"Currently blocked because the packagist API returns a 404 error on POST requests. I've created an issue for it under composer/packagist#1309

Edit: It does if I do things correctly. :P Not blocked anymore.",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1138376092,Add audit command to check for security issues,GuySartorelli,23,1246293810,6,1138376092,0,1138340951,2022-05-26T10:12:36Z,"The basic functionality is working now - any review on the `AuditCommand` or `Auditor`, updates to existing commands, and related documentation would be useful at this stage.

I'm especially eager for feedback on the UX - I'm aware that the current output is probably not ideal, but I'm not sure how it should look. The parent issue references `yarn audit` which formats the output as a table - should we look at doing something like that? If so can someone point me in the right direction for how to format such an output?",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1138407847,Add audit command to check for security issues,GuySartorelli,23,1246293810,7,1138407847,0,1138376092,2022-05-26T10:55:15Z,It looks like there's some PHPStan issues as well - to be honest I don't understand what I need to do to resolve those. A lot of the errors are saying the new command doesn't define some options... but it doesn't need those options.,False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1140850861,Add audit command to check for security issues,GuySartorelli,23,1246293810,8,1140850861,0,1138407847,2022-05-30T08:20:01Z,"I've resolved some of the PHPStan issues. The ones that I think are false alarms I've tried to add to the baseline, but it doesn't seem to have taken. There are a couple of PHPStan issues there as well which are unrelated to this PR.",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1146049306,Add audit command to check for security issues,GuySartorelli,23,1246293810,9,1146049306,0,1140850861,2022-06-03T14:58:37Z,This is now ready to be reviewed.,False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1146272483,Add audit command to check for security issues,Seldaek,23,1246293810,10,1146272483,0,1146049306,2022-06-03T19:00:19Z,"Thanks - sorry I've had a rough few weeks here so lagging behind on many things and it may take me a bit longer to get to this, but regarding phpstan if you're still having issues just ignore them that's no biggie for now.",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1146454331,Add audit command to check for security issues,GuySartorelli,23,1246293810,11,1146454331,0,1146272483,2022-06-03T23:38:40Z,"@Seldaek No worries, there's no rush. 

@herndlm interesting! I didn't think I could add a return type there because it wouldn't match the signature of the symfony command class's configure method - but you're right, other commands here have added it. I'll make that change. 
https://github.com/symfony/console/blob/c9646197ef43b0e2ff44af61e7f0571526fd4170/Command/Command.php#L198",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1149699194,Add audit command to check for security issues,GuySartorelli,23,1246293810,12,1149699194,0,1146454331,2022-06-08T09:45:06Z,Requested changes have been made.,False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1152782931,Add audit command to check for security issues,ktomk,23,1246293810,13,1152782931,0,1149699194,2022-06-10T22:39:46Z,"For the output format could JSON Text be another variant? I've seen there is a table, so perhaps some very straight forward JSON Array of JSON Objects could be nice to pass along to further (automated) processing. ",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1152806097,Add audit command to check for security issues,GuySartorelli,23,1246293810,14,1152806097,0,1152782931,2022-06-10T23:54:27Z,@ktomk At this stage I'd just be keen to see the feature merged - that sounds like an enhancement that can be added after the fact quite easily if there is real world use for it. I'd be quite happy for someone to create a follow-up PR with that format if there is a need for it but it's not something I want to add to this PR right now. ,False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1153322262,Add audit command to check for security issues,GuySartorelli,23,1246293810,15,1153322262,0,1152806097,2022-06-12T23:30:23Z,"Requested changes have been made.
Edit: Oops looks like I broke some tests... will fix those now.",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1153323345,Add audit command to check for security issues,GuySartorelli,23,1246293810,16,1153323345,0,1153322262,2022-06-12T23:38:18Z,Tests fixed - there is one failure there but I think it's unrelated to this PR.,False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1163137715,Add audit command to check for security issues,Seldaek,23,1246293810,17,1163137715,0,1153323345,2022-06-22T14:00:31Z,Thanks! Merged as d93239ddd9e6c18a2f7db3cdf94213dd892fa950 and fixed up some remaining issues in 611b21589 🥳 ,False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1163626227,Add audit command to check for security issues,GuySartorelli,23,1246293810,18,1163626227,0,1163137715,2022-06-22T21:31:48Z,"Awesome, thank you!
Should I create an issue to track/remind about moving `Auditor` into its own repository post-stable, or do you have an alternative to-do list somewhere with that on it?",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1163978059,Add audit command to check for security issues,Seldaek,23,1246293810,19,1163978059,0,1163626227,2022-06-23T05:50:22Z,"The more I think of it the more I think we can't really extract this, as it'll probably need to be integrated deeper into the Repository code than it is now. 

I think the better way would be to publish a packagist.org API client library really, that would be completely separate from Composer, and would not require Package objects or anything to function.",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1164013486,Add audit command to check for security issues,GuySartorelli,23,1246293810,20,1164013486,0,1163978059,2022-06-23T06:41:15Z,That's fair. I'd be happy to help develop such a library with as much or as little guidance as you want to provide. While I could implement such a library in some arbitrary repo it makes sense to me that there would be such a repository under the composer organisation which people can just add to their dependencies when and as they need it. ,False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1164114835,Add audit command to check for security issues,stof,23,1246293810,21,1164114835,0,1164013486,2022-06-23T08:31:39Z,You mean something like https://packagist.org/packages/knplabs/packagist-api ?,False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1164230571,Add audit command to check for security issues,Seldaek,23,1246293810,22,1164230571,0,1164114835,2022-06-23T10:15:52Z,"Ah yes there's that, then maybe worth sending a PR there porting the Auditor querying bits @GuySartorelli if you feel like it? 

",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1164238617,Add audit command to check for security issues,GuySartorelli,23,1246293810,23,1164238617,0,1164230571,2022-06-23T10:24:30Z,I'll take a look - I wasn't aware of that package. Still doesn't feel as appropriate as having one in GitHub.com/composer but I won't push for that if the appetite for creating it isnt here 😅,False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1193105546,Add audit command to check for security issues,barryvdh,23,1246293810,24,1193105546,0,1164238617,2022-07-23T10:54:22Z,"> For the output format could JSON Text be another variant? I've seen there is a table, so perhaps some very straight forward JSON Array of JSON Objects could be nice to pass along to further (automated) processing.

I created a follow-up PR for the json format here: https://github.com/composer/composer/pull/10965",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/10800,False positive error message for GitLab deploy tokens with username,jakubboucek,5,1248043592,1,1248043592,0,0,2022-05-25T12:45:53Z,"I was followed instruction to use GitLab Deploy Tokens for access to private packages from Composer:
**[GitLab Docs: Composer packages in the Package Registry](https://docs.gitlab.com/ee/user/packages/composer_repository/#:~:text=Using%20a%20deploy%20token)**

Composer is now alert warning on any `composer` command:
```
""~/.composer/auth.json"" does not match the expected JSON schema, this may result in errors and should be resolved:
 - gitlab-token.gitlab.com : Object value found, but a string is required
```

**Token with Username is for installation works very well**, Composer is using `username` field correctly, but it just is screaming error as above. 
Maybe fix invalid JSON schema.

My `~/.composer/auth.json`:

![](https://cdn.jakub-boucek.cz/screenshot/220525-0obvl.png)

Output of `composer diagnose`:
![](https://cdn.jakub-boucek.cz/screenshot/220525-5c32g.png)

",True,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1141594355,False positive error message for GitLab deploy tokens with username,pscheit,5,1248043592,2,1141594355,0,1248043592,2022-05-31T02:06:18Z,"I hit this too, when was the validation added? Cause I cant remember updating my composer version on ci? :/

I use  a personal access token with api level, that did not help as well. Before I couldnt access gitlab private repos without a username as well. Once I added the username of the account that owns the personal access token, it worked.

Happy to help debug",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1141602321,False positive error message for GitLab deploy tokens with username,pscheit,5,1248043592,3,1141602321,0,1141594355,2022-05-31T02:23:28Z,"oh .. maybe i missed the update I did:
https://github.com/composer/composer/commit/8e93566c18b1b8b0de32aff64a2204f19f1105f8
This is definitely the source. I clearly don't know why gitlab does need that username to be passed, but passing it, fixes it.

I can revert to 2.3.2 and leave my composer auth to provide username + token to work around it.",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1141617950,False positive error message for GitLab deploy tokens with username,pscheit,5,1248043592,4,1141617950,0,1141602321,2022-05-31T02:58:24Z,"dang.. i should read main first ;)

https://github.com/composer/composer/commit/bd6403a6bef36fdbefdb287dc7e26286d5e06e5e

But the good thing is now.. i have the composer repo dockerized and up and running for more contributions ;)

composer self-update 556450b15b6c47c55ffa46bd9048b410d56c3983

fixes it. so @jakubboucek it will be fixed in the next release. You can rollback to 2.3.2 or use asnapshot release",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1143374342,False positive error message for GitLab deploy tokens with username,webmozart,5,1248043592,5,1143374342,0,1141617950,2022-06-01T09:44:26Z,"I hit this too and it's breaking our pipelines. :grimacing: 

@Seldaek when do you plan to roll out the fix?

**Edit:** False alert. It's not breaking our builds, we were on the wrong track.",False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/1144087357,False positive error message for GitLab deploy tokens with username,Seldaek,5,1248043592,6,1144087357,0,1143374342,2022-06-01T20:11:38Z,https://github.com/composer/composer/releases/tag/2.3.6 should fix this.,False,0,MEMBER
https://api.github.com/repos/libsdl-org/SDL/issues/5721,"Add CMake configuration files, meant for VC-devel/SDL2.framework",madebr,22,1248884650,1,1248884650,0,0,2022-05-25T23:31:47Z,"This PR adds 2 files that are specifically written for the Visual Studio development release.
(=the `SDL2-devel-2.x.y-VC.zip` files)
These files are meant to be put in the root folder (`SDL2-2.x.y`).


RFC for #5713, for distribution along the Visual Studio devel files.


It also has component support.
It supports the components: `SDL2`, `SDL2main` and `SDL2test`.
For simplicity, these are the latter part of the `SDL2::SDL2`, `SDL2::SDL2main` and `SDL2::SDL2test` targets.


## Description

Visual Studio development releases ship with no CMake configuration files.
Because of this, all CMake based consumers need to write (or steal) a `FindSDL2.cmake` module.
By shipping a SDL2 configuration module along binary releases,
consumers don't need a `FindSDL2.cmake` anymore (if we ship one for all configurations).
They can then simply add`-DSDL2_dir=path/to/extracted/SDL2-2.x.y` or `-DCMAKE_PREFIX_PATH=path/to/extracted/SDL2-2.x.y` to the cmake invocation. Or set the `SDL2_DIR` environment variable.

As an example, consider the following cmake build script:
```cmake
cmake_minimum_required(VERSION 3.22)
project(sdl_test C)
find_package(SDL2 2.0.30 REQUIRED COMPONENTS SDL2 SDL2main SDL2test)
message(STATUS ""Found SDL2 ${SDL2_VERSION}"")
add_executable(sdl_test main.c)
target_link_libraries(sdl_test PRIVATE SDL2::SDL2 SDL2::SDL2main SDL2::SDL2test)
```
It fails when executing CMake as:
```
cmake .. -DCMAKE_PREFIX_PATH=""C:\sdl_releases\SDL2-2.0.9;C:\sdl_releases\SDL2-2.0.14;C:\sdl_releases\SDL2-2.0.22""
```
The message is:
```
CMake Error at CMakeLists.txt:4 (find_package):
  Could not find a configuration file for package ""SDL2"" that is compatible
  with requested version ""2.0.30"".

  The following configuration files were considered but not accepted:

    C:/sdl_releases/SDL2-2.0.9/sdl2-config.cmake, version: 2.0.9
    C:/sdl_releases/SDL2-2.0.14/sdl2-config.cmake, version: 2.0.14
    C:/sdl_releases/SDL2-2.0.22/sdl2-config.cmake, version: 2.0.22
```

Replacing the non-existing version `2.0.30` with e.g. `2.0.15` will let CMake pick the first matching version. In my case `2.0.14`:
```
-- Found SDL2 2.0.14
```


## Existing Issue(s)
This PR addresses the Visual Studio +Macos aspect of #5713.


## Questions/More work needed
- @slouken : You will need to modify your release scripts to include these files
- Is `cmake/vcdist` a good location to store these files? These files are not meant to be used by SDL2's cmake build system.
As long as this location is not added to `CMAKE_MODULE_PATH`, I don't see an issue.
- Would it be useful for the configuration scripts to have `COMPONENT` support?
  `COMPONENT` support would be useful because the Visual Studio (and macos) don't ship a static library.
  By e.g. adding `STATIC`, `SHARED`, `TEST` and `MAIN` components we can easily catch the absence of  the `SDL2::SDL2-static` target. 
  **update**: added `COMPONENT` support.",True,0,CONTRIBUTOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1137966589,"Add CMake configuration files, meant for VC-devel/SDL2.framework",slouken,22,1248884650,2,1137966589,0,1248884650,2022-05-25T23:39:35Z,"How about a new standalone cmake directory for each platform?
e.g.:
cmake is used for building SDL
cmake-VisualC is used for Visual Studio development package
cmake-Xcode is used for Xcode development package
etc.

Then everything in the appropriate directory will get copied into the release development package. Does that make sense?",False,0,COLLABORATOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1137967728,"Add CMake configuration files, meant for VC-devel/SDL2.framework",slouken,22,1248884650,3,1137967728,0,1137966589,2022-05-25T23:40:20Z,"> Would it be useful for the configuration scripts to have COMPONENT support?

Is there a reason not to have it?",False,0,COLLABORATOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1137970170,"Add CMake configuration files, meant for VC-devel/SDL2.framework",slouken,22,1248884650,4,1137970170,0,1137967728,2022-05-25T23:41:59Z,"> How about a new standalone cmake directory for each platform?
> 
> Then everything in the appropriate directory will get copied into the release development package. Does that make sense?

Alternatively we could put them in the subdirectories for the associated projects, e.g.
VisualC/cmake
Xcode/SDL/cmake

But would that confuse people, thinking that the files were needed or used for building SDL?",False,0,COLLABORATOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1137990190,"Add CMake configuration files, meant for VC-devel/SDL2.framework",madebr,22,1248884650,5,1137990190,0,1137970170,2022-05-25T23:55:44Z,"These files are distribution-only files, so perhaps put them in `VisualC/dist`.
Inside the SDL repo, these are text files.
It's only when they are distributed that they become cmake files.
So I wouldn't put them in a folder with `cmake` in its name.
",False,0,CONTRIBUTOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1137992201,"Add CMake configuration files, meant for VC-devel/SDL2.framework",madebr,22,1248884650,6,1137992201,0,1137990190,2022-05-25T23:58:26Z,"> > Would it be useful for the configuration scripts to have COMPONENT support?
> 
> Is there a reason not to have it?

Added complexity.
The current files are small and easily understandable.
But I think in the long run, adding `COMPONENT` support to SDL (and its satellite libraries) might pay off.
I'll look into it.",False,0,CONTRIBUTOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1138014125,"Add CMake configuration files, meant for VC-devel/SDL2.framework",madebr,22,1248884650,7,1138014125,0,1137992201,2022-05-26T00:32:43Z,"By keeping it KISS, I was able to add `COMPONENT` support.
There are still holes when a user has created e.g. a `SDL2::SDL2-static` target before doing `find_package(SDL2)`, but imho then he already shot in his own foot.",False,0,CONTRIBUTOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1138674658,"Add CMake configuration files, meant for VC-devel/SDL2.framework",madebr,22,1248884650,8,1138674658,0,1138014125,2022-05-26T15:02:21Z,"Can somebody with an Apple test the SDL2 framework CMake files?

The `CMake` folder should be added to the `Resources` folder (`SDL2.framework/versions/A/Resources`).

I've attached a little `CMakeLists.txt` script that *should* test it (only tested on MSVC).


Download link: [CMakeLists.txt](https://github.com/libsdl-org/SDL/files/8780684/CMakeLists.txt)


The cmake script needs to be run as:
```
cmake -S /path/to/the/cmake/script -B /some/temporary/build/folder -DCMAKE_PREFIX_PATH=""path1_to_folder_containing_the_framework;path2_to_folder_containing_the_framework;path3_to_folder_containing_the_framework"" -DCMAKE_BUILD_TYPE=Release
cmake --build /some/temporary/build/folder --config Release
```
[The search procedure of `find_package` is documented here.](https://cmake.org/cmake/help/latest/command/find_package.html#config-mode-search-procedure)
You need to add the folder containing the `SDL2.framework` folder to the prefix path, not the path of the framework itself.",False,0,CONTRIBUTOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1138778105,"Add CMake configuration files, meant for VC-devel/SDL2.framework",madebr,22,1248884650,9,1138778105,0,1138674658,2022-05-26T16:50:02Z,"> But would that confuse people, thinking that the files were needed or used for building SDL?

I've, once again, moved the files.
Both the Xcode and VC cmake files are placed in a pkg-support subfolder.
The release scripts can then simply copy all files in there to the root of the VC-devel zip or SDL2.framework.
I think the `pkg-support` folder should make it clear to people that these are support files, not build files.",False,0,CONTRIBUTOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1139188730,"Add CMake configuration files, meant for VC-devel/SDL2.framework",slouken,22,1248884650,10,1139188730,0,1138778105,2022-05-27T01:10:28Z,"> Can somebody with an Apple test the SDL2 framework CMake files?
> 
> The `CMake` folder should be added to the `Resources` folder (`SDL2.framework/versions/A/Resources`).
> 
> I've attached a little `CMakeLists.txt` script that _should_ test it (only tested on MSVC).
> 
> Download link: [CMakeLists.txt](https://github.com/libsdl-org/SDL/files/8780684/CMakeLists.txt)
> 
> The cmake script needs to be run as:
> 
> ```
> cmake -S /path/to/the/cmake/script -B /some/temporary/build/folder -DCMAKE_PREFIX_PATH=""path1_to_folder_containing_the_framework;path2_to_folder_containing_the_framework;path3_to_folder_containing_the_framework"" -DCMAKE_BUILD_TYPE=Release
> cmake --build /some/temporary/build/folder --config Release
> ```
> 
> [The search procedure of `find_package` is documented here.](https://cmake.org/cmake/help/latest/command/find_package.html#config-mode-search-procedure) You need to add the folder containing the `SDL2.framework` folder to the prefix path, not the path of the framework itself.

Testing this now:
```
/Applications/CMake.app/Contents/bin/cmake -S . -B build -DCMAKE_PREFIX_PATH=. -DCMAKE_BUILD_TYPE=Release
-- The C compiler identification is AppleClang 13.1.6.13160021
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
CMake Warning at CMakeLists.txt:22 (find_package):
  Could not find a configuration file for package ""SDL2"" that is compatible
  with requested version ""2.90.0"".

  The following configuration files were considered but not accepted:

    /Users/slouken/Desktop/SDL2.framework/Resources/CMake/sdl2-config.cmake, version: 2.23.0
    /Users/slouken/Desktop/SDL2.framework/Versions/A/Resources/CMake/sdl2-config.cmake, version: 2.23.0
    /Users/slouken/Desktop/SDL2.framework/Versions/Current/Resources/CMake/sdl2-config.cmake, version: 2.23.0
    /usr/local/lib/cmake/SDL2/sdl2-config.cmake, version: 2.23.0



CMake Warning at SDL2.framework/Resources/CMake/sdl2-config.cmake:23 (message):
  SDL2: following component(s) are not available: SDL2test
Call Stack (most recent call first):
  CMakeLists.txt:34 (find_package)


CMake Warning at CMakeLists.txt:34 (find_package):
  Found package configuration file:

    /Users/slouken/Desktop/SDL2.framework/Resources/CMake/sdl2-config.cmake

  but it set SDL2_FOUND to FALSE so package ""SDL2"" is considered to be NOT
  FOUND.


-- Found SDL2 2.23.0
-- Configuring done
CMake Error at CMakeLists.txt:78 (add_executable):
  Target ""sdl_test"" links to target ""SDL2::SDL2test"" but the target was not
  found.  Perhaps a find_package() call is missing for an IMPORTED target, or
  an ALIAS target is missing?


-- Generating done
CMake Generate step failed.  Build files cannot be regenerated correctly.
```",False,0,COLLABORATOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1139192071,"Add CMake configuration files, meant for VC-devel/SDL2.framework",slouken,22,1248884650,11,1139192071,0,1139188730,2022-05-27T01:18:39Z,"If I make SDL2test optional, I get:
```
/Applications/CMake.app/Contents/bin/cmake -S . -B build -DCMAKE_PREFIX_PATH=. -DCMAKE_BUILD_TYPE=Release
CMake Warning at CMakeLists.txt:22 (find_package):
  Could not find a configuration file for package ""SDL2"" that is compatible
  with requested version ""2.90.0"".

  The following configuration files were considered but not accepted:

    /Users/slouken/Desktop/SDL2.framework/Resources/CMake/sdl2-config.cmake, version: 2.23.0
    /Users/slouken/Desktop/SDL2.framework/Versions/A/Resources/CMake/sdl2-config.cmake, version: 2.23.0
    /Users/slouken/Desktop/SDL2.framework/Versions/Current/Resources/CMake/sdl2-config.cmake, version: 2.23.0
    /usr/local/lib/cmake/SDL2/sdl2-config.cmake, version: 2.23.0



CMake Warning at SDL2.framework/Resources/CMake/sdl2-config.cmake:23 (message):
  SDL2: following component(s) are not available: SDL2test
Call Stack (most recent call first):
  CMakeLists.txt:34 (find_package)


CMake Warning at CMakeLists.txt:34 (find_package):
  Found package configuration file:

    /Users/slouken/Desktop/SDL2.framework/Resources/CMake/sdl2-config.cmake

  but it set SDL2_FOUND to FALSE so package ""SDL2"" is considered to be NOT
  FOUND.


-- Found SDL2 2.23.0
-- Configuring done
-- Generating done
-- Build files have been written to: /Users/slouken/Desktop/build
```",False,0,COLLABORATOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1139194431,"Add CMake configuration files, meant for VC-devel/SDL2.framework",slouken,22,1248884650,12,1139194431,0,1139192071,2022-05-27T01:24:52Z,"Building fails to find SDL.h, possibly because SDL2_INCLUDE_DIRS isn't used anywhere?",False,0,COLLABORATOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1139201455,"Add CMake configuration files, meant for VC-devel/SDL2.framework",slouken,22,1248884650,13,1139201455,0,1139194431,2022-05-27T01:43:52Z,The Visual Studio support files worked great.,False,0,COLLABORATOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1139208588,"Add CMake configuration files, meant for VC-devel/SDL2.framework",slouken,22,1248884650,14,1139208588,0,1139201455,2022-05-27T02:01:43Z,"> Building fails to find SDL.h, possibly because SDL2_INCLUDE_DIRS isn't used anywhere?

If I change these lines in sdl2-config.cmake:
```cmake
#set(SDL2_INCLUDE_DIR    ""${CMAKE_CURRENT_LIST_DIR}/../../Headers"")
#set(SDL2_INCLUDE_DIRS   ""${SDL2_INCLUDE_DIR}"")
#set(SDL2_LIBRARY        ""${CMAKE_CURRENT_LIST_DIR}/../../SDL2"")
FIND_PATH(SDL2_INCLUDE_DIR SDL.h)
set(SDL2_INCLUDE_DIRS   ""${SDL2_INCLUDE_DIR}"")
FIND_LIBRARY(SDL2_LIBRARY SDL2)
```

Then CMakeCache.txt gets these variables:
```
./CMakeCache.txt:SDL2_DIR:PATH=/Users/slouken/Desktop/SDL2.framework/Resources/CMake
./CMakeCache.txt:SDL2_INCLUDE_DIR:PATH=/Users/slouken/Desktop/SDL2.framework/Headers
./CMakeCache.txt:SDL2_LIBRARY:FILEPATH=/Users/slouken/Desktop/SDL2.framework
```
But the build still fails because SDL2_INCLUDE_DIR isn't used anywhere.",False,0,COLLABORATOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1139470727,"Add CMake configuration files, meant for VC-devel/SDL2.framework",madebr,22,1248884650,15,1139470727,0,1139208588,2022-05-27T10:02:12Z,"> Building fails to find SDL.h, possibly because SDL2_INCLUDE_DIRS isn't used anywhere?

Yeah, I forgot to use `SDL2_INCLUDE_DIR` in the `SDL2::SDL2` target.

> ```cmake
> FIND_PATH(SDL2_INCLUDE_DIR SDL.h)
> set(SDL2_INCLUDE_DIRS   ""${SDL2_INCLUDE_DIR}"")
> FIND_LIBRARY(SDL2_LIBRARY SDL2)
> ```

We don't want to use cache variables in a cmake configuration file.
`sdl2-config.cmake` will be shipped along a sdl sdk, so it knows the location of the headers. Therefore we simply `set` the variables.

In find modules (e.g. `FindSDL2.cmake`) a ""heavy"" file system search is performed when looking for header + library.
These variables are then cached to speed up subsequent find's (e.g. when re-configuring).",False,0,CONTRIBUTOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1139737217,"Add CMake configuration files, meant for VC-devel/SDL2.framework",slouken,22,1248884650,16,1139737217,0,1139470727,2022-05-27T15:44:17Z,"> ```cmake
> FIND_LIBRARY(SDL2_LIBRARY SDL2)
> ```

There's a difference between FIND_LIBRARY(SDL2_LIBRARY SDL2) and explicitly linking to the SDL2 dynamic library. The former adds SDL2 as a framework and the latter as a dylib. On Apple platforms we want to link to the framework, not the dylib inside it.",False,0,COLLABORATOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1140004500,"Add CMake configuration files, meant for VC-devel/SDL2.framework",madebr,22,1248884650,17,1140004500,0,1139737217,2022-05-27T20:20:09Z,"Thanks, I think I understand frameworks a bit better now.
I changed the behavior to do `-F /path/to/folder/containing/the/framework -I SDL2.framework/Headers` when compiling
and do `-F /path/to/folder/containing/the/framework -framework SDL2` when linking.

Google searches learned me that I need to pass the folder containing the `SDL2.framework` folder to `-F`, not the path of the framework itself. Is that correct?",False,0,CONTRIBUTOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1140062724,"Add CMake configuration files, meant for VC-devel/SDL2.framework",slouken,22,1248884650,18,1140062724,0,1140004500,2022-05-27T21:49:25Z,"That's working much better! I had to fix the include path, and then it worked great.

I also removed the other variables, since we need the Framework setup on Apple platforms. I did that as a separate commit though, in case we really need them and you want to drop it.",False,0,COLLABORATOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1140068497,"Add CMake configuration files, meant for VC-devel/SDL2.framework",madebr,22,1248884650,19,1140068497,0,1140062724,2022-05-27T22:01:28Z,"It makes sense to remove the (now unused) variables.
In modern CMake, people should not rely on variables but think in targets.",False,0,CONTRIBUTOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1140071932,"Add CMake configuration files, meant for VC-devel/SDL2.framework",slouken,22,1248884650,20,1140071932,0,1140068497,2022-05-27T22:09:07Z,Should we add some documentation to pkg-support on how to use the new CMake support?,False,0,COLLABORATOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1140079134,"Add CMake configuration files, meant for VC-devel/SDL2.framework",madebr,22,1248884650,21,1140079134,0,1140071932,2022-05-27T22:26:11Z,"Perhaps add a short example to its `ReadMe.txt`?

Something along the lines of:
> SDL2.framework can be used in CMake projects using the following pattern:
> ```
> find_package(SDL2 REQUIRED COMPONENTS SDL2)
> 
> target_link_libraries(your_awesome_game PRIVATE SDL2::SDL2)
> ```
> If SDL2.framework is installed in a non-standard location,
> please refer to [1] for ways to configure CMake.
> 
> [1] https://cmake.org/cmake/help/latest/command/find_package.html#config-mode-search-procedure

My native language is not English, so you might want to rephrase things.",False,0,CONTRIBUTOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1140122298,"Add CMake configuration files, meant for VC-devel/SDL2.framework",ericoporto,22,1248884650,22,1140122298,0,1140079134,2022-05-28T00:49:55Z,"hey, I don't understand much of the MacOS Framework stuff, but just to check, if I make my game executable target using set_target_properties(mygame PROPERTIES MACOSX_BUNDLE TRUE ...), where in `...` is all my bundle information stuff, the resulting app will include the SDL2 framework inside of it, and have rpath or something correctly link to it?

Just checking because I am really used to `${SDL2_LIBRARY}` and static linking and it looks like maybe this is not a thing that is going to be supported.",False,0,CONTRIBUTOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1140133181,"Add CMake configuration files, meant for VC-devel/SDL2.framework",slouken,22,1248884650,23,1140133181,0,1140122298,2022-05-28T01:44:55Z,"> Just checking because I am really used to `${SDL2_LIBRARY}` and static linking and it looks like maybe this is not a thing that is going to be supported.

This is just the CMake support bundled with the official release framework. We're not changing SDL if you're building it yourself.",False,0,COLLABORATOR
https://api.github.com/repos/libsdl-org/SDL/issues/5722,Cannot open the same controller multiple times on linux,hwjsnc,7,1249619017,1,1249619017,0,0,2022-05-26T14:06:27Z,"In SDL2 version 2.0.20 and before, it was possible to open the same controller multiple times from different processes such that all of them receive the controller input events simultaneously.

Since version 2.0.22 this is not possible anymore: Once the controller has been opened by one program, it cannot be opened by another until the first one closes it again. In the interim time, the corresponding /dev/input/event* /dev/input/js* files are gone.",True,0,NONE
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1139406344,Cannot open the same controller multiple times on linux,hwjsnc,7,1249619017,2,1139406344,0,1249619017,2022-05-27T08:38:57Z,`git bisect` led me to commit 0cb39ed4685473928b01682f875f7bb086fbe465.,False,0,NONE
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1139748983,Cannot open the same controller multiple times on linux,slouken,7,1249619017,3,1139748983,0,1139406344,2022-05-27T15:59:06Z,"I'm pretty sure what happened here is that libusb didn't use to be available, and now it is. In order for libusb to function, it takes exclusive control over the USB devices, which doesn't play nice with other users on the system.

@madebr, the autotools version of this defaults libusb off, except on platforms like *BSD, where it's necessary. Is there a way to do something similar here with CMake?",False,0,COLLABORATOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1139749773,Cannot open the same controller multiple times on linux,slouken,7,1249619017,4,1139749773,0,1139748983,2022-05-27T16:00:11Z,"Here's the relevant autotools snippet:
```sh
    AC_ARG_ENABLE(hidapi-libusb,
[AS_HELP_STRING([--enable-hidapi-libusb], [use libusb for low level joystick drivers [default=maybe]])],
                  , enable_hidapi_libusb=maybe)

    if test x$enable_hidapi = xyes; then
        case ""$host"" in
            # libusb does not support iOS
            *-ios-* )
                enable_hidapi_libusb=no
                ;;
            # On the other hand, *BSD specifically uses libusb only
            *-*-*bsd* )
                enable_hidapi_libusb=yes
                require_hidapi_libusb=yes
                ;;
           *-*-os2* )
                enable_hidapi_libusb=yes
                ;;
        esac

        hidapi_support=yes
        if test x$enable_hidapi_libusb = xyes; then
            PKG_CHECK_MODULES([LIBUSB], [libusb-1.0], have_libusb=yes, have_libusb=no)
            save_CPPFLAGS=""$CPPFLAGS""
            CPPFLAGS=""$save_CPPFLAGS $LIBUSB_CFLAGS""
            AC_CHECK_HEADER(libusb.h, have_libusb_h=yes, have_libusb_h=no)
            CPPFLAGS=""$save_CPPFLAGS""
            if test x$have_libusb_h = xno && test x$require_hidapi_libusb = xyes; then
                hidapi_support=no
            fi
        fi
```",False,0,COLLABORATOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1194715637,Cannot open the same controller multiple times on linux,slouken,7,1249619017,5,1194715637,0,1139749773,2022-07-25T22:30:50Z,"@madebr, can you please fix this for the 2.24.0 release?",False,0,COLLABORATOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1195451491,Cannot open the same controller multiple times on linux,madebr,7,1249619017,6,1195451491,0,1194715637,2022-07-26T13:00:08Z,"@hwjsnc 
Can you test #5962?
On Linux, it disables libusb by default.",False,0,CONTRIBUTOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1202281666,Cannot open the same controller multiple times on linux,hwjsnc,7,1249619017,7,1202281666,0,1195451491,2022-08-02T10:04:25Z,"Thanks for that fix. Unfortunately I can't test it at the moment because SDL doesn't compile for me for unrelated reasons (including versions which previously did). I'll try to figure out what's going on and test the patch, but it will likely take at least a few days.",False,0,NONE
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1207406740,Cannot open the same controller multiple times on linux,hwjsnc,7,1249619017,8,1207406740,0,1202281666,2022-08-07T13:16:42Z,I can now confirm the patch works for me. Thanks again!,False,0,NONE
https://api.github.com/repos/libsdl-org/SDL/issues/5723,Infinite Loop in devices without native Atomic support,fjtrujy,10,1249653194,1,1249653194,0,0,2022-05-26T14:32:30Z,"Hello guys,
I'm starting a Playstation 2 port of SDL, so far I have made some progress already, however running the tests I have noticed an infinite loop.

Having in mind that PS2 doesn't have native atomic support, we have the following scenario:

1. Function `SDL_CreateMutex` calling `SDL_Malloc` https://github.com/libsdl-org/SDL/blob/main/src/thread/generic/SDL_sysmutex.c#L43
2. Function `SDL_malloc` calling `SDL_AtomicIncRef` https://github.com/libsdl-org/SDL/blob/main/src/stdlib/SDL_malloc.c#L5390
3. `#define SDL_AtomicIncRef(a)    SDL_AtomicAdd(a, 1)` https://github.com/libsdl-org/SDL/blob/main/include/SDL_atomic.h#L321
4. Function `SDL_AtomicAdd` calling `SDL_AtomicCAS` https://github.com/libsdl-org/SDL/blob/main/src/atomic/SDL_atomic.c#L257
5. Function `SDL_AtomicCAS` calling `enterLock` https://github.com/libsdl-org/SDL/blob/main/src/atomic/SDL_atomic.c#L145
6. Function `enterLock` calling `SDL_AtomicLock` https://github.com/libsdl-org/SDL/blob/main/src/atomic/SDL_atomic.c#L114
7. Function `SDL_AtomicLock` calling `SDL_AtomicTryLock` https://github.com/libsdl-org/SDL/blob/main/src/atomic/SDL_spinlock.c#L165
8. Function `SDL_AtomicTryLock` calling `SDL_CreateMutex` https://github.com/libsdl-org/SDL/blob/main/src/atomic/SDL_spinlock.c#L63 


What is your suggestion to follow?

I was thinking of implementing my own ""atomic"" support, by disabling interruptions, then performing the operation, and finally, enabling interruption backs.
https://github.com/libsdl-org/SDL/blob/main/src/atomic/SDL_atomic.c#L236",True,0,CONTRIBUTOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1138644345,Infinite Loop in devices without native Atomic support,fjtrujy,10,1249653194,2,1138644345,0,1249653194,2022-05-26T14:33:15Z,Pinging @sharkwouter because I have already notified him.,False,0,CONTRIBUTOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1138678566,Infinite Loop in devices without native Atomic support,sezero,10,1249653194,3,1138678566,0,1138644345,2022-05-26T15:06:15Z,"> Having in mind that PS2 doesn't have native atomic support, 

Is this a limitation of MIPS cpu in PS2? (forgive my ignorance on the topic.)",False,0,CONTRIBUTOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1138762517,Infinite Loop in devices without native Atomic support,icculus,10,1249653194,4,1138762517,0,1138678566,2022-05-26T16:34:05Z,"There's only one CPU core; can we just implement the atomics with standard operations?

(I'm not sure the ramifications of _actually_ doing that, but if there's nowhere the CPU could race...)",False,0,COLLABORATOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1138769524,Infinite Loop in devices without native Atomic support,fjtrujy,10,1249653194,5,1138769524,0,1138762517,2022-05-26T16:42:35Z,"> > Having in mind that PS2 doesn't have native atomic support,
> 
> Is this a limitation of MIPS cpu in PS2? (forgive my ignorance on the topic.)

Yes is a limitation in that CPU, I suppose that legacy CPUs could have that limitation",False,0,CONTRIBUTOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1138782720,Infinite Loop in devices without native Atomic support,fjtrujy,10,1249653194,6,1138782720,0,1138769524,2022-05-26T16:52:31Z,"> There's only one CPU core; can we just implement the atomics with standard operations?
> 
> (I'm not sure the ramifications of _actually_ doing that, but if there's nowhere the CPU could race...)

This is exactly what I was suggesting, we have just a single CPU, however, we could have several threads, and then you can't assure an atomic operation unless you disable the interruptions, then the interruption to change thread won't be triggered and you can perform the operation safely, once the operation is done, you enable back the interruptions",False,0,CONTRIBUTOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1138947553,Infinite Loop in devices without native Atomic support,icculus,10,1249653194,7,1138947553,0,1138782720,2022-05-26T19:47:23Z,"
> This is exactly what I was suggesting, we have just a single CPU, however, we could have several threads, and then you can't assure an atomic operation unless you disable the interruptions, then the interruption to change thread won't be triggered and you can perform the operation safely, once the operation is done, you enable back the interruptions

Ah, I missed this part in your original post, sorry to make you repeat yourself. This seems like the correct approach.",False,0,COLLABORATOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1138984850,Infinite Loop in devices without native Atomic support,cgutman,10,1249653194,8,1138984850,0,1138947553,2022-05-26T20:19:14Z,"> Having in mind that PS2 doesn't have native atomic support

Are you sure? According to Wikipedia, it's a MIPS III CPU and LL/SC instructions were introduced in MIPS II.

LL/SC can be used to implement `SDL_AtomicCAS()` which can then be used as the base atomic primitive for all the other `SDL_Atomic` ops.

Edit: Nevermind, saw https://lore.kernel.org/linux-mips/cover.1567326213.git.noring@nocrew.org/

> 1. The R5900 is the main processor that runs the kernel[1]. It implements
   the 64-bit MIPS III instruction set **except LL, SC, LLD and SCD**

:(",False,0,COLLABORATOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1139005957,Infinite Loop in devices without native Atomic support,fjtrujy,10,1249653194,9,1139005957,0,1138984850,2022-05-26T20:33:35Z,"> > Having in mind that PS2 doesn't have native atomic support
> 
> Are you sure? According to Wikipedia, it's a MIPS III CPU and LL/SC instructions were introduced in MIPS II.
> 
> LL/SC can be used to implement `SDL_AtomicCAS()` which can then be used as the base atomic primitive for all the other `SDL_Atomic` ops.
> 
> Edit: Nevermind, saw https://lore.kernel.org/linux-mips/cover.1567326213.git.noring@nocrew.org/
> 
> > 1. The R5900 is the main processor that runs the kernel[1]. It implements
> >    the 64-bit MIPS III instruction set **except LL, SC, LLD and SCD**
> 
> :(

Exactly :( the R5900 is a custom MIPS processor almost MIPS III with some MIPS IV instructions",False,0,CONTRIBUTOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1151481006,Infinite Loop in devices without native Atomic support,icculus,10,1249653194,10,1151481006,0,1139005957,2022-06-09T18:48:46Z,"Are we good to close this issue, since there's a plan in place?",False,0,COLLABORATOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1151484452,Infinite Loop in devices without native Atomic support,fjtrujy,10,1249653194,11,1151484452,0,1151481006,2022-06-09T18:53:01Z,"I have a PR pending to be done with a solution over there.

I didn’t created yet because I wanted to double-check that everything was working fine (testing using your available tests).

I want to create a initial PS2 port just implementing Threads, Atomics, FileSystem, Mutex and Semaphores. Then I will create other PRs adding more drivers.

So If you don’t mind keep this open and I will link this issue to the PR.",False,0,CONTRIBUTOR
https://api.github.com/repos/libsdl-org/SDL/issues/5724,build: Compile with large inode number support where possible,smcv,5,1249743298,1,1249743298,0,0,2022-05-26T15:49:55Z,"On filesystems with large inode numbers, such as overlayfs, attempting
to stat() a file on a 32-bit system using legacy syscalls can fail
with EOVERFLOW. If we opt-in to more modern ""large file support""
syscalls, then source code references to functions like stat() are
transparently replaced with ABIs that support large file sizes and
inode numbers, such as stat64().

This cannot safely be done globally by Linux distributions, because
some libraries expose types like `off_t` or `struct stat` in their
ABI, meaning that enabling large file support would be an incompatible
change that would cause crashes. However, SDL appears to be careful to
avoid these types in header files, so it should be OK to enable this.

---

This is the sort of potentially breaking change that should happen early in a release cycle, so that it can be reverted if it turns out to have broken the ABI. It's probably a good idea to put SDL through something like https://github.com/lvc/abi-compliance-checker before and after this change.",True,0,CONTRIBUTOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1138726127,build: Compile with large inode number support where possible,smcv,5,1249743298,2,1138726127,0,1249743298,2022-05-26T15:53:50Z,See also https://github.com/libsdl-org/SDL_ttf/pull/222.,False,0,CONTRIBUTOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1160680776,build: Compile with large inode number support where possible,sezero,5,1249743298,3,1160680776,0,1138726127,2022-06-20T17:13:05Z,"After this cmake-3.0 compatibility is broken. Error message from my cmake-3.9.6:
```
-- Looking for __GLIBC__
-- Looking for __GLIBC__ - found
CMake Error at CMakeLists.txt:62 (add_compile_definitions):
  Unknown CMake command ""add_compile_definitions"".


-- Configuring incomplete, errors occurred!
```

What mininum cmake version is required for that `add_compile_definitions` thing?
Or, an alternative to it, `add_definitions` maybe? 

CC: @madebr ",False,0,CONTRIBUTOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1160686822,build: Compile with large inode number support where possible,madebr,5,1249743298,4,1160686822,0,1160680776,2022-06-20T17:21:07Z,"`add_compile_definitions` is 3.12+, `add_definitions` is in 3.0.
You need to change the line to `add_definitions(-D_FILE_OFFSET_BITS=64)` for that.",False,0,CONTRIBUTOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1160687623,build: Compile with large inode number support where possible,sezero,5,1249743298,5,1160687623,0,1160686822,2022-06-20T17:22:13Z,"Well, you guys should choose the solution :)",False,0,CONTRIBUTOR
https://api.github.com/repos/libsdl-org/SDL/issues/comments/1160703059,build: Compile with large inode number support where possible,madebr,5,1249743298,6,1160703059,0,1160687623,2022-06-20T17:44:20Z,Fixed in d460000b4586ff1a10cf2f7cb4e922db3efb9400,False,0,CONTRIBUTOR
https://api.github.com/repos/fw876/helloworld/issues/899,新添加的Hysteria协议无法启动,xcf13363175,4,1264557580,1,1264557580,0,0,2022-06-08T10:52:15Z,"新添加的Hysteria协议无法启动，协议wechat，端口123XX，passwall和v2rayN可以连接。
2022-06-08 17:22:51: -----------end------------
2022-06-08 17:22:50: Main node:hysteria 1.0.4 Started!
2022-06-08 17:22:50: ----------start------------

日志显示启动，但是实际未运行，无法连接节点。ps. 甚至在服务器节点中都ping不同服务器。",True,0,NONE
https://api.github.com/repos/fw876/helloworld/issues/comments/1149800811,新添加的Hysteria协议无法启动,hcym,4,1264557580,2,1149800811,0,1264557580,2022-06-08T11:34:26Z,我的能用，就是不能用ipv6，pass那边就能用ipv6,False,0,NONE
https://api.github.com/repos/fw876/helloworld/issues/comments/1149810668,新添加的Hysteria协议无法启动,1715173329,4,1264557580,3,1149810668,0,1149800811,2022-06-08T11:45:57Z,用户配置问题，开启允许不安全连接后解决。,False,0,COLLABORATOR
https://api.github.com/repos/fw876/helloworld/issues/comments/1149816620,新添加的Hysteria协议无法启动,xcf13363175,4,1264557580,4,1149816620,0,1149810668,2022-06-08T11:53:05Z,谢谢天灵巨佬,False,0,NONE
https://api.github.com/repos/fw876/helloworld/issues/comments/1242641884,新添加的Hysteria协议无法启动,hunter8605,4,1264557580,5,1242641884,0,1149816620,2022-09-10T06:13:45Z,"> 用户配置问题，开启允许不安全连接后解决。

我遇到同样的问题了，开启这个允许不安全连接还是不行",False,0,NONE
https://api.github.com/repos/fw876/helloworld/issues/902, sagernet-core 无法与xray-core 共存？,xiangfeidexiaohuo,4,1265613108,1,1265613108,0,0,2022-06-09T05:29:17Z," * check_conflicts_for: The following packages conflict with sagernet-core:
 * check_conflicts_for: 	xray-core * 
 * opkg_install_cmd: Cannot install package luci-app-ssr-plus.
 * check_conflicts_for: The following packages conflict with sagernet-core:
 * check_conflicts_for: 	xray-core * 
 * opkg_install_cmd: Cannot install package sagernet-core.



也就是说，固件内置ssrp编译进去，如果还要内置其他带xray的插件，就无法共存？
",True,0,NONE
https://api.github.com/repos/fw876/helloworld/issues/comments/1150749520, sagernet-core 无法与xray-core 共存？,wekingchen,4,1265613108,2,1150749520,0,1265613108,2022-06-09T07:04:28Z,我也遇到同样的问题，ssrp本身没有带xray-core了，但其他插件有用到，就编译不过,False,0,NONE
https://api.github.com/repos/fw876/helloworld/issues/comments/1150777254, sagernet-core 无法与xray-core 共存？,ShoukakuChuuCC,4,1265613108,3,1150777254,0,1150749520,2022-06-09T07:35:57Z,是的，暂时不能和xray-core共存,False,0,NONE
https://api.github.com/repos/fw876/helloworld/issues/comments/1150882489, sagernet-core 无法与xray-core 共存？,1715173329,4,1265613108,4,1150882489,0,1150777254,2022-06-09T09:21:14Z,不能。,False,0,COLLABORATOR
https://api.github.com/repos/fw876/helloworld/issues/comments/1152153981, sagernet-core 无法与xray-core 共存？,ghost,4,1265613108,5,1152153981,0,1150882489,2022-06-10T09:15:47Z,不能共存，只好放弃SSR了。,False,0,NONE
https://api.github.com/repos/fw876/helloworld/issues/903,更新后 xray Vless协议节点，无法链接,ghost,3,1266071237,1,1266071237,0,0,2022-06-09T12:40:08Z,,True,0,NONE
https://api.github.com/repos/fw876/helloworld/issues/comments/1151361338,更新后 xray Vless协议节点，无法链接,1715173329,3,1266071237,2,1151361338,0,1266071237,2022-06-09T16:42:39Z,UUIDv5?,False,0,COLLABORATOR
https://api.github.com/repos/fw876/helloworld/issues/comments/1151810405,更新后 xray Vless协议节点，无法链接,ghost,3,1266071237,3,1151810405,0,1151361338,2022-06-10T01:33:21Z,passwall/passwall2，旧版helloworld均可以的。,False,0,NONE
https://api.github.com/repos/fw876/helloworld/issues/comments/1151886225,更新后 xray Vless协议节点，无法链接,1715173329,3,1266071237,4,1151886225,0,1151810405,2022-06-10T03:20:32Z,贴出你的配置。,False,0,COLLABORATOR
https://api.github.com/repos/fw876/helloworld/issues/904,6月9日的更新后 UDP无法正常代理,ShoukakuChuuCC,13,1266081784,1,1266081784,0,0,2022-06-09T12:48:51Z,"节点类型shadowsocks，加密协议ss2022 edition
6月8日最后一个commit则正常",True,0,NONE
https://api.github.com/repos/fw876/helloworld/issues/comments/1151355366,6月9日的更新后 UDP无法正常代理,1715173329,13,1266081784,2,1151355366,0,1266081784,2022-06-09T16:35:37Z,贴一下你的配置。,False,0,COLLABORATOR
https://api.github.com/repos/fw876/helloworld/issues/comments/1151706971,6月9日的更新后 UDP无法正常代理,ShoukakuChuuCC,13,1266081784,3,1151706971,0,1151355366,2022-06-09T23:22:51Z,"![image](https://user-images.githubusercontent.com/38343280/172961041-88a19970-5068-417d-98fb-92b0858f03db.png)
![image](https://user-images.githubusercontent.com/38343280/172961058-9d343a1b-24e2-419c-aea5-eb91387e1672.png)
",False,0,NONE
https://api.github.com/repos/fw876/helloworld/issues/comments/1151760817,6月9日的更新后 UDP无法正常代理,ShoukakuChuuCC,13,1266081784,4,1151760817,0,1151706971,2022-06-10T00:50:30Z,"服务端Xray v1.5.7
SSRP-高级设置-数据包编码-xudp",False,0,NONE
https://api.github.com/repos/fw876/helloworld/issues/comments/1151890332,6月9日的更新后 UDP无法正常代理,1715173329,13,1266081784,5,1151890332,0,1151760817,2022-06-10T03:27:47Z,"https://github.com/SagerNet/v2ray-core/suites/6860170564/artifacts/265087919
试试此版本的 v2ray 核心。
",False,0,COLLABORATOR
https://api.github.com/repos/fw876/helloworld/issues/comments/1152134043,6月9日的更新后 UDP无法正常代理,ShoukakuChuuCC,13,1266081784,6,1152134043,0,1151890332,2022-06-10T08:53:31Z,是把服务端核心换成SagerNet？SSRP的数据包编码需不需要也改成v2ray的,False,0,NONE
https://api.github.com/repos/fw876/helloworld/issues/comments/1152214148,6月9日的更新后 UDP无法正常代理,ShoukakuChuuCC,13,1266081784,7,1152214148,0,1152134043,2022-06-10T10:24:31Z,服务端核心换成SagerNet的v2ray-core v5.0.14后，直接连不上代理了，v2ray日志提示cipher: message authentication failed，双端密码都是正确对应的，服务端换成xray后就正常了，v2ray和xray用的config都是一样的配置,False,0,NONE
https://api.github.com/repos/fw876/helloworld/issues/comments/1152215462,6月9日的更新后 UDP无法正常代理,1715173329,13,1266081784,8,1152215462,0,1152214148,2022-06-10T10:26:11Z,"> 是把服务端核心换成SagerNet？SSRP的数据包编码需不需要也改成v2ray的

是需要更新一下客户端，ss 不使用此数据包编码。
SagerNet 的 v2ray-core 请直接下载 Actions 编译文件，不要用 Release 版本，通常不是最新。",False,0,COLLABORATOR
https://api.github.com/repos/fw876/helloworld/issues/comments/1152516189,6月9日的更新后 UDP无法正常代理,kennyleo,13,1266081784,9,1152516189,0,1152215462,2022-06-10T16:05:03Z,同样的问题，SagerNet后udp就不通,False,0,NONE
https://api.github.com/repos/fw876/helloworld/issues/comments/1152707074,6月9日的更新后 UDP无法正常代理,1715173329,13,1266081784,10,1152707074,0,1152516189,2022-06-10T20:18:30Z,udp 问题正在与上游作者沟通，如有 udp 需求可以先取消 ssrp 的 sn 依赖并手动选择 xray。,False,0,COLLABORATOR
https://api.github.com/repos/fw876/helloworld/issues/comments/1153510471,6月9日的更新后 UDP无法正常代理,tmptr,13,1266081784,11,1153510471,0,1152707074,2022-06-13T06:09:29Z,"



> udp 问题正在与上游作者沟通，如有 udp 需求可以先取消 ssrp 的 sn 依赖并手动选择 xray。

Also could you please chat with upstreamer about the full-cone nat issue that connect to xray server? Thank you.
",False,0,NONE
https://api.github.com/repos/fw876/helloworld/issues/comments/1154873410,6月9日的更新后 UDP无法正常代理,foxjie,13,1266081784,12,1154873410,0,1153510471,2022-06-14T08:25:19Z,是的，我这里也发现用SagerNet核心以后，xray节点无法full-cone了，请问现在应该怎样获取到full-core？使用非vless节点么？,False,0,NONE
https://api.github.com/repos/fw876/helloworld/issues/comments/1162579929,6月9日的更新后 UDP无法正常代理,minlang112,13,1266081784,13,1162579929,0,1154873410,2022-06-22T03:00:27Z,"嗯，换SagerNet之后系统日志就会大量报这种东西↓

Wed Jun 22 00:24:48 2022 kern.notice kernel: [215484.767642]  IN= OUT= SRC=100.90.33.139 DST=119.xxx.xxx.xxx LEN=132 TOS=0x00 PREC=0x20 TTL=63 ID=13082 PROTO=UDP SPT=32729 DPT=161 LEN=112
Wed Jun 22 00:25:19 2022 kern.notice kernel: [215515.419797] nf_ct_snmp: dropping packet: parser failed
Wed Jun 22 00:25:19 2022 kern.notice kernel: [215515.419797]  IN= OUT= SRC=100.90.33.139 DST=119.xxx.xxx.xxx LEN=48 TOS=0x00 PREC=0x20 TTL=63 ID=16514 PROTO=UDP SPT=32729 DPT=161 LEN=28
Wed Jun 22 00:31:59 2022 kern.notice kernel: [215916.066174] nf_ct_snmp: dropping packet: parser failed
Wed Jun 22 00:31:59 2022 kern.notice kernel: [215916.066174]  IN= OUT= SRC=100.90.33.139 DST=119.xxx.xxx.xxx LEN=132 TOS=0x00 PREC=0x20 TTL=63 ID=1560 PROTO=UDP SPT=32729 DPT=161 LEN=112
Wed Jun 22 00:38:40 2022 kern.notice kernel: [216317.101160] nf_ct_snmp: dropping packet: parser failed
Wed Jun 22 00:38:40 2022 kern.notice kernel: [216317.101160]  IN= OUT= SRC=100.90.33.139 DST=119.xxx.xxx.xxx LEN=132 TOS=0x00 PREC=0x20 TTL=63 ID=53979 PROTO=UDP SPT=32729 DPT=161 LEN=112
Wed Jun 22 00:38:58 2022 kern.notice kernel: [216334.516450] nf_ct_snmp: dropping packet: parser failed
Wed Jun 22 00:38:58 2022 kern.notice kernel: [216334.516450]  IN= OUT= SRC=100.90.33.139 DST=119.xxx.xxx.xxx LEN=132 TOS=0x00 PREC=0x20 TTL=63 ID=56404 PROTO=UDP SPT=32729 DPT=161 LEN=112",False,0,NONE
https://api.github.com/repos/fw876/helloworld/issues/comments/1166252969,6月9日的更新后 UDP无法正常代理,predators46,13,1266081784,14,1166252969,0,1162579929,2022-06-25T10:38:52Z,you are using shadowsocks looks like shadowsocks doesn't support udp this is a problem in shadowsocks,False,0,NONE
https://api.github.com/repos/composer/composer/issues/10888,"Argument 2 passed to Composer\Pcre\Preg::isMatch() must be of the type string, null given",bartlangelaan,3,1276783204,1,1276783204,0,0,2022-06-20T11:28:10Z,"In the CI (not on my machine) during a `composer create-project`, this error occurs:

```
    Exception trace:
      at /app/.global/composer/composer/vendor/composer/pcre/src/Preg.php:233
     Composer\Pcre\Preg::isMatch() at /app/.global/composer/composer/vendor/composer/composer/src/Composer/Downloader/GitDownloader.php:475
     Composer\Downloader\GitDownloader->updateToCommit() at /app/.global/composer/composer/vendor/composer/composer/src/Composer/Downloader/GitDownloader.php:138
     Composer\Downloader\GitDownloader->doInstall() at /app/.global/composer/composer/vendor/composer/composer/src/Composer/Downloader/VcsDownloader.php:137
     Composer\Downloader\VcsDownloader->install() at /app/.global/composer/composer/vendor/composer/composer/src/Composer/Downloader/DownloadManager.php:279
     Composer\Downloader\DownloadManager->install() at /app/.global/composer/composer/vendor/composer/composer/src/Composer/Installer/LibraryInstaller.php:282
     Composer\Installer\LibraryInstaller->installCode() at /app/.global/composer/composer/vendor/composer/composer/src/Composer/Installer/LibraryInstaller.php:155
     Composer\Installer\LibraryInstaller->install() at /app/.global/composer/composer/vendor/composer/composer/src/Composer/Installer/InstallationManager.php:528
```

I think this is related to https://github.com/composer/pcre/commit/2e56743e50b72279aeb01ed2c9fcbf9f9d7a92d6, #10662 and 0708eb45e5801ef2682f2af8635237eb5f025ddb.

Looking at the code, I could see how this could possibly go wrong:

https://github.com/composer/composer/blob/10cd375cf85dede2ff417ceab517ef9a0dc55407/src/Composer/Downloader/GitDownloader.php#L455-L458
https://github.com/composer/composer/blob/10cd375cf85dede2ff417ceab517ef9a0dc55407/src/Composer/Downloader/GitDownloader.php#L472-L477

So, it seems like the `$branches` var is used while it is null.
However, it's hard for me to check if adding a `&& $branches` to the outer if-statement is enough to fix this issue, because this error only happens in the CI for me. But it seems like a good thing to do anyway.",True,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/1162713000,"Argument 2 passed to Composer\Pcre\Preg::isMatch() must be of the type string, null given",Seldaek,3,1276783204,2,1162713000,0,1276783204,2022-06-22T06:47:38Z,"Do you not have git installed on CI, or why is it failing to execute `git branch -r`? Or maybe you cache vendor dir but not the .git dirs within?

I mean we need to fix this regardless, but I am curious how you reach this code path.",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1250255728,"Argument 2 passed to Composer\Pcre\Preg::isMatch() must be of the type string, null given",brunoborghi,3,1276783204,3,1250255728,0,1162713000,2022-09-18T12:04:43Z,"Interesting...

@Seldaek, on CI after run `composer install`, before generating autoload files, this error occurs:

> `[TypeError]
  Argument 2 passed to Composer\Pcre\Preg::matchAll() must be of the type str
  ing, null given, called in phar:///.../composer.phar/vendor/composer/class-map-generator/src/PhpFil
  eParser.php on line 55`

Trace:

`Exception trace:
  at phar:///.../composer.phar/vendor/composer/pcre/src/Preg.php:67
 Composer\Pcre\Preg::matchAll() at phar:///.../composer.phar/vendor/composer/class-map-generator/src/PhpFileParser.php:55
 Composer\ClassMapGenerator\PhpFileParser::findClasses() at phar:///.../composer.phar/vendor/composer/class-map-generator/src/ClassMapGenerator.php:176
 Composer\ClassMapGenerator\ClassMapGenerator->scanPaths() at phar:///.../composer.phar/src/Composer/Autoload/AutoloadGenerator.php:314
 Composer\Autoload\AutoloadGenerator->dump() at phar:///.../composer.phar/src/Composer/Installer.php:343
 Composer\Installer->run() at phar:///.../composer.phar/src/Composer/Command/UpdateCommand.php:240
 Composer\Command\UpdateCommand->execute() at phar:///.../composer.phar/vendor/symfony/console/Command/Command.php:298
 Symfony\Component\Console\Command\Command->run() at phar:///.../composer.phar/vendor/symfony/console/Application.php:1028
 Symfony\Component\Console\Application->doRunCommand() at phar:///.../composer.phar/vendor/symfony/console/Application.php:299
 Symfony\Component\Console\Application->doRun() at phar:///.../composer.phar/src/Composer/Console/Application.php:370
 Composer\Console\Application->doRun() at phar:///.../composer.phar/vendor/symfony/console/Application.php:171
 Symfony\Component\Console\Application->run() at phar:///.../composer.phar/src/Composer/Console/Application.php:138
 Composer\Console\Application->run() at phar:///.../composer.phar/bin/composer:88
 require() at /.../composer.phar:29`

I'm using version **2.4.2**. Could it have something to do with this error?
On my computer it works normally.",False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/1275819825,"Argument 2 passed to Composer\Pcre\Preg::isMatch() must be of the type string, null given",Seldaek,3,1276783204,4,1275819825,0,1250255728,2022-10-12T08:53:28Z,"@brunoborghi that is an unrelated issue, but I wonder how that is possible at all. The $contents / arg #2 here https://github.com/composer/class-map-generator/blob/main/src/PhpFileParser.php#L55 should always be a string as php_strip_whitespace can only return a string, and as per https://3v4l.org/r4kMa it seems to be the case even for non-existent paths.

It doesn't make sense to me how it'd be null.",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/10890,[Feture request] post-require-cmd script,hubertnnn,8,1278625839,1,1278625839,0,0,2022-06-21T15:32:07Z,"Currently composer has a `post-install-cmd` hook that is run after a package is installed.
This is nice for autoconfiguration tools like eg. `symfony/flex`, but is a bit problematic.

The issue is that this hook runs both after I installed manually a new package (`composer require`) 
and after a deployment script will install all packages based on `composer.lock` (`composer install`).

The effect is that `symfony/flex` is running unattended during deployment to production and either causing issues with deployment itself (flex is very often causing breaking changes on their servers, breaking all deployments) or messing with files that should be just copied from the repository and/or generated by the deployment process.

Would be nice to have separate hooks for `composer install` and `composer require`, 
so I could still benefit from autoconfiguration during installing new packages, 
but at the same time to prevent flex from running during deployments.",True,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/1162327214,[Feture request] post-require-cmd script,Seldaek,8,1278625839,2,1162327214,0,1278625839,2022-06-21T20:41:00Z,"I believe flex should not do changes on prod as long as you deploy/commit symfony.lock as well as composer.json (is that correct understanding @nicolas-grekas ?)

",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1162380038,[Feture request] post-require-cmd script,nicolas-grekas,8,1278625839,3,1162380038,0,1162327214,2022-06-21T21:20:57Z,"It doesn't as long as one commits the symfony.lock file. Did you commit that file @hubertnnn? If not, that's the issue. Otherwise, I've not idea what you're referring too...",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1176310732,[Feture request] post-require-cmd script,hubertnnn,8,1278625839,4,1176310732,0,1162380038,2022-07-06T14:43:37Z,"It is committed. So far i tried to understand why its trying to mess with files only on the production server while behaving correctly in development, test and even staging servers but I could not get any reproducible behavior.

But this issue is not about `flex`. Flex was just an example of situation where I would like to have different scripts tied to `composer install` vs `composer require/update`",False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/1176360089,[Feture request] post-require-cmd script,stof,8,1278625839,5,1176360089,0,1176310732,2022-07-06T15:25:08Z,The `post-install-cmd` script is executed only after installing from lock. `post-update-cmd` is executed after `composer update` or after an install without lock file (which is converted to an update),False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1177601164,[Feture request] post-require-cmd script,hubertnnn,8,1278625839,6,1177601164,0,1176360089,2022-07-07T13:18:35Z,"@stof 
I know, that is why I suggested `post-require-cmd`.
This way you would have granular control over scripts executed during all 3 commonly used commands:
- `composer install`  = `post-install-cmd` = install from existing composer.lock
- `composer update` = `post-update-cmd` = update all/some existing packages
- `composer require X` = `post-require-cmd` = install something new

The first 2 already exist, the third one is undocumented and if I am correct executes `post-install-cmd`",False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/1180100564,[Feture request] post-require-cmd script,stof,8,1278625839,7,1180100564,0,1177601164,2022-07-11T08:16:37Z,"If you don't pass the `--no-update` flag to `composer require`, it will execute `post-update-cmd` due to running a partial update.",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1181771080,[Feture request] post-require-cmd script,Seldaek,8,1278625839,8,1181771080,0,1180100564,2022-07-12T13:37:03Z,@hubertnnn I'm still not sure what you are looking for? That we document the fact that the require command runs post-update-cmd scripts? ,False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1375018675,[Feture request] post-require-cmd script,github-actions[bot],8,1278625839,9,1375018675,0,1181771080,2023-01-09T02:02:27Z,This issue has been automatically marked Stale and will be closed in 15 days if no further activity happens.,False,0,NONE
https://api.github.com/repos/composer/composer/issues/10891,"composer install/update checks requirements even from ""require-dev"" stuff",6562680,5,1278686210,1,1278686210,0,0,2022-06-21T16:20:39Z,"We have `laravel/horizon` in composer.json at ""require-dev"" section

This web-admin for redis requires php-pcntl thats available only on linux

I dont want to install these package on my windows machine, and in case cant run `composer install` cus of package requires it.

It wont be installed but require some.

ps. i know that ""Timmy"" in laravel team creates something... something. Actually i dont want to remove ""this"" from our composer, but wanna skip. I couldnt.",True,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/1162010914,"composer install/update checks requirements even from ""require-dev"" stuff",stof,5,1278686210,2,1162010914,0,1278686210,2022-06-21T16:53:19Z,"you can use the `platform` config to force composer to consider that `ext-pcntl` is available (but then, make sure that the package does not actually require that extension for real but instead handles properly the case where the extension is not there, in which case you might as well send them a PR to move it from `require` to `suggests`)",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1162013078,"composer install/update checks requirements even from ""require-dev"" stuff",stof,5,1278686210,3,1162013078,0,1162010914,2022-06-21T16:55:21Z,"And checking the dev requirements of the root package is expected, because the dependency resolution always takes them into account

We don't want to generate a different lock file with different versions of packages depending on whether you run `composer update` or `composer update --no-dev` (`--no-dev` impacts only the installation step, not the dependency resolution step). Early version of composers were doing that, and it created tons of weird cases.",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1162175519,"composer install/update checks requirements even from ""require-dev"" stuff",6562680,5,1278686210,4,1162175519,0,1162013078,2022-06-21T18:40:45Z,"thanks.
i've understood that dev dependencies wont be installed if our package is a dependency for other.
if we install using composer.json - it installs both and requires flag to skip.",False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/1162192550,"composer install/update checks requirements even from ""require-dev"" stuff",stof,5,1278686210,5,1162192550,0,1162175519,2022-06-21T18:53:00Z,"When you package is the root package, the behavior is indeed different that when using it as a dependency. That's totally expected (that's the difference between `require-dev` and `require`)",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1356980169,"composer install/update checks requirements even from ""require-dev"" stuff",github-actions[bot],5,1278686210,6,1356980169,0,1162192550,2022-12-19T01:58:06Z,This issue has been automatically marked Stale and will be closed in 15 days if no further activity happens.,False,0,NONE
https://api.github.com/repos/composer/composer/issues/10893,Audit command docs: Remove currently restriction,naderman,4,1280235122,1,1280235122,0,0,2022-06-22T14:23:13Z,"- No reason to state that the audit command ""currently"" only checks packagist.org. It should stay that way, if we need to add more sources, we can add them to packagist.org.",True,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1163186310,Audit command docs: Remove currently restriction,stof,4,1280235122,2,1163186310,0,1280235122,2022-06-22T14:35:58Z,"I think this ""currently"" is more related to ""it does not check custom repositories yet"". packagist.org will never list advisories for packages that are not on packagist.org AFAICT.",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1163195274,Audit command docs: Remove currently restriction,naderman,4,1280235122,3,1163195274,0,1163186310,2022-06-22T14:42:48Z,"@stof I think it can do so, but whether that's a good idea is unclear I suppose - cc @glaubinix",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1163269225,Audit command docs: Remove currently restriction,glaubinix,4,1280235122,4,1163269225,0,1163195274,2022-06-22T15:33:43Z,"The API already returns advisories for packages that are not hosted on packagist.org if they are part of the GitHub or FriendsOfPHP advisory database. I think for now the currently is fine, might explain to users why it doesn't work for them at the moment if their setup doesn't allow connections to packagist.org and letting them know that this is something that will/might change in the future",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1164269022,Audit command docs: Remove currently restriction,Seldaek,4,1280235122,5,1164269022,0,1163269225,2022-06-23T10:59:57Z,"Merging, we can always update if/when it changes.",False,0,MEMBER
https://api.github.com/repos/microsoft/vscode/issues/152833,Proposal TerminalExitStatus.reason,jeanp413,7,1279619515,1,1279619515,0,0,2022-06-22T06:30:22Z,"<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->

This PR fixes https://github.com/microsoft/vscode/issues/130231

Implements API proposal `TerminalExitStatus.reason` to address issue #130231
Added `Shutdown`(main motivation for #130231) and `Unknown`(i.e. any other reasons) reasons

Side note, after working on this, I would say that firing `vscode.window.onDidCloseTerminal` on shutdown is more of a bug than a feature, if some extension terminal logic is required to execute on shutdown then using `context.subscriptions` would be preferred I think but changing `onDidCloseTerminal` behavior would be a breaking change :thinking: 

cc @Tyriar ",True,0,CONTRIBUTOR
https://api.github.com/repos/microsoft/vscode/issues/comments/1165220944,Proposal TerminalExitStatus.reason,akosyakov,7,1279619515,2,1165220944,0,1279619515,2022-06-24T05:47:10Z,@Tyriar Does proposed change make sense to you? We would really appreciate such API like stable though to unblock our customers. 🙏 ,False,0,CONTRIBUTOR
https://api.github.com/repos/microsoft/vscode/issues/comments/1173665611,Proposal TerminalExitStatus.reason,akosyakov,7,1279619515,3,1173665611,0,1165220944,2022-07-04T10:46:11Z,@Tyriar thank you! Is API sync internal or we can follow it somehow as well? ,False,0,CONTRIBUTOR
https://api.github.com/repos/microsoft/vscode/issues/comments/1174495527,Proposal TerminalExitStatus.reason,meganrogge,7,1279619515,4,1174495527,0,1173665611,2022-07-05T01:16:10Z,@akosyakov it is internal and we will post a summary after that happens ,False,0,CONTRIBUTOR
https://api.github.com/repos/microsoft/vscode/issues/comments/1177783580,Proposal TerminalExitStatus.reason,meganrogge,7,1279619515,5,1177783580,0,1174495527,2022-07-07T15:22:06Z,Discussed at the API sync and we think the shape looks good. Just the one question above,False,0,CONTRIBUTOR
https://api.github.com/repos/microsoft/vscode/issues/comments/1179133163,Proposal TerminalExitStatus.reason,jeanp413,7,1279619515,6,1179133163,0,1177783580,2022-07-08T15:45:37Z,"I forgot to ask this, how long does it take for a proposal API to become stable? I just realized that even if this is merged we won't be able to use it in our extension and publish it to the marketplace :sweat_smile: ",False,0,CONTRIBUTOR
https://api.github.com/repos/microsoft/vscode/issues/comments/1179145572,Proposal TerminalExitStatus.reason,Tyriar,7,1279619515,7,1179145572,0,1179133163,2022-07-08T15:59:05Z,"It needs to stay proposed for at least a month, this one's not complex so 1 month seems right",False,0,MEMBER
https://api.github.com/repos/microsoft/vscode/issues/comments/1180044968,Proposal TerminalExitStatus.reason,akosyakov,7,1279619515,8,1180044968,0,1179145572,2022-07-11T07:10:26Z,"> Discussed at the API sync and we think the shape looks good. Just the one question above

@Tyriar @meganrogge Thank you a lot 🙏  Is it good to land? I believe @jeanp413 addressed the feedback.

",False,0,CONTRIBUTOR
https://api.github.com/repos/microsoft/vscode/issues/152836,The mimes are not split by line separators when dnd from file explorer,jdneo,8,1279691392,1,1279691392,0,0,2022-06-22T07:28:46Z,"Version: 1.69.0-insider (user setup)
Commit: f361c5b71d6676cfc6de97cdb1cc40b08bf7d994
Date: 2022-06-22T05:17:09.661Z
Electron: 18.3.4
Chromium: 100.0.4896.160
Node.js: 16.13.2
V8: 10.0.139.17-electron.0
OS: Windows_NT x64 10.0.19044

This is a follow up of https://github.com/microsoft/vscode/issues/152031

Steps to Reproduce:

1. Clone the dnd sample: https://github.com/microsoft/vscode-extension-samples/tree/main/tree-view-sample
2. Add `'text/uri-list'` to the `dropMimeTypes` of  `TestViewDragAndDrop`
3. Add some logs in `handleDrop(...)`:
```
sources.forEach((value, key) => {
    console.log(`${key} : ${value.value}`);
});
```
4. Launch the extension
5. Drag multiple files to the dnd sample view, the uris in the data transfer are not split by line separators.

// cc @alexr00 
",True,0,MEMBER
https://api.github.com/repos/microsoft/vscode/issues/comments/1162919781,The mimes are not split by line separators when dnd from file explorer,alexr00,8,1279691392,2,1162919781,0,1279691392,2022-06-22T10:21:35Z,"> Drag multiple files to the dnd sample view

Are you dragging from the VS Code file explorer view, or your operating system's file explorer?",False,0,MEMBER
https://api.github.com/repos/microsoft/vscode/issues/comments/1163815420,The mimes are not split by line separators when dnd from file explorer,jdneo,8,1279691392,3,1163815420,0,1162919781,2022-06-23T01:09:31Z,"Sorry forgot to mention, it's from VS Code file explorer",False,0,MEMBER
https://api.github.com/repos/microsoft/vscode/issues/comments/1164900785,The mimes are not split by line separators when dnd from file explorer,mjbvz,8,1279691392,4,1164900785,0,1163815420,2022-06-23T21:33:08Z,"@jdneo Can you check the actual value, not just the value printed by console.log?

I debugged this and oddly while `console.log` just prints:

```
text/uri-list : file:///Users/matb/projects/san/b.md
```

The actual value of `value.value` is:

```
file:///Users/matb/projects/san/b.md
file:///Users/matb/projects/san/index.js
file:///Users/matb/projects/san/package-lock.json
file:///Users/matb/projects/san/package.json
```

In this case each file name is separated by a `\r\n` pair",False,0,CONTRIBUTOR
https://api.github.com/repos/microsoft/vscode/issues/comments/1165051691,The mimes are not split by line separators when dnd from file explorer,jdneo,8,1279691392,5,1165051691,0,1164900785,2022-06-24T00:50:24Z,"Tested in:

Version: 1.69.0-insider (user setup)
Commit: 668c538b8d2fec1258ed786ae212124d6d68023c
Date: 2022-06-23T05:16:43.681Z
Electron: 18.3.4
Chromium: 100.0.4896.160
Node.js: 16.13.2
V8: 10.0.139.17-electron.0
OS: Windows_NT x64 10.0.22000

It's still stored in one line:

https://user-images.githubusercontent.com/6193897/175438263-37876d70-23cc-4c37-86a4-5d313816d26a.mp4

Is there anything I missed?",False,0,MEMBER
https://api.github.com/repos/microsoft/vscode/issues/comments/1165769540,The mimes are not split by line separators when dnd from file explorer,mjbvz,8,1279691392,6,1165769540,0,1165051691,2022-06-24T17:10:19Z,"Thanks.  Only happens on windows for me. Taking a look now
",False,0,CONTRIBUTOR
https://api.github.com/repos/microsoft/vscode/issues/comments/1165836220,The mimes are not split by line separators when dnd from file explorer,mjbvz,8,1279691392,7,1165836220,0,1165769540,2022-06-24T18:38:37Z,"I don't see us setting `text/uri-list` anywhere and suspect chrome is generating it automatically. See  ` Drag-and-drop processing model` in https://www.w3.org/TR/2011/WD-html5-20110113/dnd.html for how this may happen

Also we are possibly hitting https://bugs.chromium.org/p/chromium/issues/detail?id=239745",False,0,CONTRIBUTOR
https://api.github.com/repos/microsoft/vscode/issues/comments/1167014096,The mimes are not split by line separators when dnd from file explorer,alexr00,8,1279691392,8,1167014096,0,1165836220,2022-06-27T07:59:08Z,"> Also we are possibly hitting https://bugs.chromium.org/p/chromium/issues/detail?id=239745

Nice find. I couldn't find us setting `text/uri-list` anywhere either.",False,0,MEMBER
https://api.github.com/repos/microsoft/vscode/issues/comments/1172110437,The mimes are not split by line separators when dnd from file explorer,aeschli,8,1279691392,9,1172110437,0,1167014096,2022-07-01T08:58:02Z,"Verified on Windows and Linux in 1.69.0-insider (user setup) Commit: 0b3574dcef8f35fec4ee4f83dc958c1f16ef6fce, 022-07-01T05:17:04.343Z
",False,0,CONTRIBUTOR
https://api.github.com/repos/microsoft/vscode/issues/152837,[regression] Incorrect cursor position after nested completion using $0 placeholder,HighCommander4,9,1279700430,1,1279700430,0,0,2022-06-22T07:35:46Z,"**Notes**

 * This is a regression introduced in vscode 1.67 (also affects 1.68 and insiders)
 * The reproduction steps require a language server that produces completion items using the `$0` placeholder. The example steps use clangd

**Steps to reproduce**

(See also screen recordings below)

 1. Install the [clangd](clangd.llvm.org/) C++ language server
 2. Start with the following C++ source file:

```c++
void moo(int, int);

int main() {
  
}
```

 3. On line 4, type `mo` and invoke completion.
 4. Accept the completion item for `moo`.
 5. Type `decl` and invoke completion
 6. Accept the completion item for `decltype(expression)`

**Expected results**

The cursor ends up at column 26, i.e. just before the closing `)` of the inserted `decltype(expression)`.

This is what happens with vscode 1.66:

![good](https://user-images.githubusercontent.com/1751085/174970031-eeb27897-4185-45c9-95d7-41be065674bb.gif)

**Actual results**

The cursor ends up at column 27, i.e. just after the closing `)` of the inserted `decltype(expression)`

This is what happens with vscode 1.67 and later:

![bad](https://user-images.githubusercontent.com/1751085/174970161-6f4c8fc0-cb3d-48fa-be71-a6451bb6af17.gif)

**Analysis**

The bug seems to hinge on the second completion item containing a `$0` placeholder -- in this case, the item's `insertText` is `decltype(${0:expression})`. If this is changed to `decltype(${1:expression})`, the bug goes away.

The interpretation of the `$0` placeholder is explained in the LSP spec here: https://microsoft.github.io/language-server-protocol/specifications/lsp/3.17/specification/#insertTextFormat

Originally reported at https://github.com/clangd/clangd/issues/1190.",True,0,NONE
https://api.github.com/repos/microsoft/vscode/issues/comments/1163167653,[regression] Incorrect cursor position after nested completion using $0 placeholder,jrieken,9,1279700430,2,1163167653,0,1279700430,2022-06-22T14:22:13Z,"> Install the [clangd](https://github.com/microsoft/vscode/issues/clangd.llvm.org/) C++ language server

:cough: :cough: minimal steps

> a `$0` placeholder -- in this case, the item's insertText is `decltype(${0:expression})`. If this is changed to decltype(${1:expression}), the bug goes away.


`$0` is not a placeholder but the final tabstop, e.g it shouldn't be `${0:foobar}`but a number >= 1 when you looking for placeholder semantics (doesn't end snippet mode, does repeat placeholder value). Unsure how/if/why that worked before and when that changed but your workaround seems like the correct way of doing it and it is unlikely that we'll support the final tabstop to be a placeholder. 
",False,0,MEMBER
https://api.github.com/repos/microsoft/vscode/issues/comments/1163415150,[regression] Incorrect cursor position after nested completion using $0 placeholder,HighCommander4,9,1279700430,3,1163415150,0,1163167653,2022-06-22T17:29:50Z,"> > Install the [clangd](https://github.com/microsoft/vscode/issues/clangd.llvm.org/) C++ language server
> 
> :cough: :cough: minimal steps

What could I have done to provide more minimal reproduction steps in this case? The only thing that comes to mind is writing a custom language server for the purpose of demonstrating the bug, which doesn't seem like a reasonable bar.

> > a `$0` placeholder -- in this case, the item's insertText is `decltype(${0:expression})`. If this is changed to decltype(${1:expression}), the bug goes away.
> 
> `$0` is not a placeholder but the final tabstop, e.g it shouldn't be `${0:foobar}`but a number >= 1 when you looking for placeholder semantics (doesn't end snippet mode, does repeat placeholder value). Unsure how/if/why that worked before and when that changed but your workaround seems like the correct way of doing it and it is unlikely that we'll support the final tabstop to be a placeholder.

Thanks, I didn't realize `$0` cannot be used as a placeholder (nor, evidently, did the clangd developers who originally wrote this logic). I guess the way to implement the desired semantics (having a placeholder + having the tab keep you inside the parentheses) would be to use `decltype(${1:expression}$0)` then?",False,0,NONE
https://api.github.com/repos/microsoft/vscode/issues/comments/1165321898,[regression] Incorrect cursor position after nested completion using $0 placeholder,HighCommander4,9,1279700430,4,1165321898,0,1163415150,2022-06-24T08:13:35Z,"> I guess the way to implement the desired semantics (having a placeholder + having the tab keep you inside the parentheses) would be to use `decltype(${1:expression}$0)` then?

I guess that's a bit silly, since after you've finished typing the `expression`, your cursor is already where the `$0` is and pressing `<tab>` to stay in the same place is pointless.

I think the preferred behaviour would be the one `decltype(${0:expression})` had with vscode <= 1.66: after you type the `expression`, if you're inside a nested completion, a `<tab>` takes you directly to the next tab stop of the enclosing completion. Is there a way to achieve this behaviour in vscode >= 1.67?",False,0,NONE
https://api.github.com/repos/microsoft/vscode/issues/comments/1167029701,[regression] Incorrect cursor position after nested completion using $0 placeholder,kadircet,9,1279700430,5,1167029701,0,1165321898,2022-06-27T08:14:18Z,"> $0 is not a placeholder but the final tabstop

reading the spec:
```
Tab stops
With tab stops, you can make the editor cursor move inside a snippet. Use $1, $2 to specify cursor locations. The number is the order in which tab stops will be visited, whereas $0 denotes the final cursor position. Multiple tab stops are linked and updated in sync.

Placeholders
Placeholders are tab stops with values, like ${1:foo}. The placeholder text will be inserted and selected such that it can be easily changed. Placeholders can be nested, like ${1:another ${2:placeholder}}.
```

I don't see why `$0` can't be a placeholder while other tabstops can be. I guess `$0` isn't even a tabstop?
It would be great to reflect that in the LSP docs as well, the wording you used are actually more common in the spec (`$0` defines the final tab stop, it defaults to the end of the snippet.) which doesn't exclude the possibility of it being a placeholder.

I can see how this might've been the decision made, but as @HighCommander4 pointed out, this behavior actually helped language servers (well, at least clangd) to implement some functionality. It'd be great to hear that there'll still be a way to support these without requiring extra tabs.",False,0,NONE
https://api.github.com/repos/microsoft/vscode/issues/comments/1247974469,[regression] Incorrect cursor position after nested completion using $0 placeholder,VSCodeTriageBot,9,1279700430,6,1247974469,0,1167029701,2022-09-15T11:29:13Z,"Hey @jrieken, this issue might need further attention.

@HighCommander4, you can help us out by closing this issue if the problem no longer exists, or adding more information.",False,0,COLLABORATOR
https://api.github.com/repos/microsoft/vscode/issues/comments/1248443499,[regression] Incorrect cursor position after nested completion using $0 placeholder,HighCommander4,9,1279700430,7,1248443499,0,1247974469,2022-09-15T18:17:37Z,"While we have worked around this in clangd for now, it would be nice to consider the behaviour change described in [this comment](https://github.com/microsoft/vscode/issues/152837#issuecomment-1165321898):

> I think the preferred behaviour would be the one `decltype(${0:expression})` had with vscode <= 1.66: after you type the `expression`, if you're inside a nested completion, a `<tab>` takes you directly to the next tab stop of the enclosing completion. Is there a way to achieve this behaviour in vscode >= 1.67?

Or alternatively to update the LSP docs as described in [this comment](https://github.com/microsoft/vscode/issues/152837#issuecomment-1167029701) to clarify that $0 cannot be a placeholder.",False,0,NONE
https://api.github.com/repos/microsoft/vscode/issues/comments/1337173185,[regression] Incorrect cursor position after nested completion using $0 placeholder,VSCodeTriageBot,9,1279700430,8,1337173185,0,1248443499,2022-12-05T11:25:20Z,"Hey @jrieken, this issue might need further attention.

@HighCommander4, you can help us out by closing this issue if the problem no longer exists, or adding more information.",False,0,COLLABORATOR
https://api.github.com/repos/microsoft/vscode/issues/comments/1351051344,[regression] Incorrect cursor position after nested completion using $0 placeholder,VSCodeTriageBot,9,1279700430,9,1351051344,0,1337173185,2022-12-14T11:26:27Z,"This issue has been closed automatically because it needs more information and has not had recent activity. See also our [issue reporting](https://aka.ms/vscodeissuereporting) guidelines.

Happy Coding!",False,0,COLLABORATOR
https://api.github.com/repos/microsoft/vscode/issues/comments/1351746962,[regression] Incorrect cursor position after nested completion using $0 placeholder,HighCommander4,9,1279700430,10,1351746962,0,1351051344,2022-12-14T16:40:46Z,"> @HighCommander4, you can help us out by closing this issue if the problem no longer exists, or adding more information.

It's not clear what ""more information"" was being asked for here.

The current status of the bug is as I summarized in [this previous comment](https://github.com/microsoft/vscode/issues/152837#issuecomment-1248443499). I believe it remains valid.",False,0,NONE
https://api.github.com/repos/microsoft/vscode/issues/152839,error D:\vscode-main\node_modules\@vscode\sqlite3: Command failed.,bfzx,4,1279715936,1,1279715936,0,0,2022-06-22T07:47:47Z,"- VS Code Version: vscode-main
- OS Version:Windows 10
error D:\vscode-main\node_modules\@vscode\sqlite3: Command failed.
Exit code: 1
Command: node-gyp rebuild
Arguments:
Directory: D:\vscode-main\node_modules\@vscode\sqlite3
Output:
D:\vscode-main\node_modules\@vscode\sqlite3>if not defined npm_config_node_gyp (node ""D:\nodejs\node_modules\npm\bin\node-gyp-bin\\..\..\node_modules\node-gyp\bin\node-gyp.js"" rebuild )  else (node """" rebuild )
gyp info it worked if it ends with ok
gyp info using node-gyp@9.0.0
gyp info using node@16.15.1 | win32 | ia32
gyp info find Python using Python version 3.8.6 found at ""C:\Program Files\python\python.exe""
gyp info find VS using VS2017 (15.9.28307.2019) found at:
gyp info find VS ""C:\Program Files (x86)\Microsoft Visual Studio\2017\BuildTools""
gyp info find VS run with --verbose for detailed information
gyp info spawn C:\Program Files\python\python.exe
gyp info spawn args [
gyp info spawn args   'D:\\nodejs\\node_modules\\npm\\node_modules\\node-gyp\\gyp\\gyp_main.py',
gyp info spawn args   'binding.gyp',
gyp info spawn args   '-f',
gyp info spawn args   'msvs',
gyp info spawn args   '-I',
gyp info spawn args   'D:\\vscode-main\\node_modules\\@vscode\\sqlite3\\build\\config.gypi',
gyp info spawn args   '-I',
gyp info spawn args   'D:\\nodejs\\node_modules\\npm\\node_modules\\node-gyp\\addon.gypi',
gyp info spawn args   '-I',
gyp info spawn args   'C:\\Users\\DELL\\AppData\\Local\\node-gyp\\Cache\\18.3.4\\include\\node\\common.gypi',
gyp info spawn args   '-Dlibrary=shared_library',
gyp info spawn args   '-Dvisibility=default',
gyp info spawn args   '-Dnode_root_dir=C:\\Users\\DELL\\AppData\\Local\\node-gyp\\Cache\\18.3.4',
gyp info spawn args   '-Dnode_gyp_dir=D:\\nodejs\\node_modules\\npm\\node_modules\\node-gyp',
gyp info spawn args   '-Dnode_lib_file=C:\\\\Users\\\\DELL\\\\AppData\\\\Local\\\\node-gyp\\\\Cache\\\\18.3.4\\\\<(target_arch)\\\\node.lib',
gyp info spawn args   '-Dmodule_root_dir=D:\\vscode-main\\node_modules\\@vscode\\sqlite3',
gyp info spawn args   '-Dnode_engine=v8',
gyp info spawn args   '--depth=.',
gyp info spawn args   '--no-parallel',
gyp info spawn args   '--generator-output',
gyp info spawn args   'D:\\vscode-main\\node_modules\\@vscode\\sqlite3\\build',
gyp info spawn args   '-Goutput_dir=.'
gyp info spawn args ]
gyp info spawn C:\Program Files (x86)\Microsoft Visual Studio\2017\BuildTools\MSBuild\15.0\Bin\MSBuild.exe
gyp info spawn args [
gyp info spawn args   'build/binding.sln',
gyp info spawn args   '/clp:Verbosity=minimal',
gyp info spawn args   '/nologo',
gyp info spawn args   '/p:Configuration=Release;Platform=Win32'
gyp info spawn args ]
�ڴ˽��������һ������һ����Ŀ����Ҫ���ò������ɣ������ӡ�/m�����ء�
  unpack_sqlite_dep
  'C:\Program' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���
  ���������ļ���
C:\Program Files (x86)\Microsoft Visual Studio\2017\BuildTools\Common7\IDE\VC\VCTargets\Microsoft.CppCommon.targets(209,5): error MSB6006: ��cmd.exe�����˳�������Ϊ 1�� [D:\vscode-main\node_modules\@vscode\sqlite3\build\deps\action_before_build.vcxproj]
  nothing.c
  win_delay_load_hook.cc
  nothing.vcxproj -> D:\vscode-main\node_modules\@vscode\sqlite3\build\Release\\nothing.lib
gyp ERR! build error
gyp ERR! stack Error: `C:\Program Files (x86)\Microsoft Visual Studio\2017\BuildTools\MSBuild\15.0\Bin\MSBuild.exe` failed with exit code: 1
gyp ERR! stack     at ChildProcess.onExit (D:\nodejs\node_modules\npm\node_modules\node-gyp\lib\build.js:194:23)
gyp ERR! stack     at ChildProcess.emit (node:events:527:28)
gyp ERR! stack     at Process.ChildProcess._handle.onexit (node:internal/child_process:291:12)
gyp ERR! System Windows_NT 10.0.19044
gyp ERR! command ""D:\\nodejs\\node.exe"" ""D:\\nodejs\\node_modules\\npm\\node_modules\\node-gyp\\bin\\node-gyp.js"" ""rebuild""
gyp ERR! cwd D:\vscode-main\node_modules\@vscode\sqlite3",True,0,NONE
https://api.github.com/repos/microsoft/vscode/issues/comments/1166715218,error D:\vscode-main\node_modules\@vscode\sqlite3: Command failed.,zhuhe25,4,1279715936,2,1166715218,0,1279715936,2022-06-27T01:19:00Z,"I have the same problem, I've been successful before",False,0,NONE
https://api.github.com/repos/microsoft/vscode/issues/comments/1180227174,error D:\vscode-main\node_modules\@vscode\sqlite3: Command failed.,roma160,4,1279715936,3,1180227174,0,1166715218,2022-07-11T10:28:31Z,"Recently encountered SIMILAR (not the same error):
```bash
error C:\buff\vscode_compile_error\node_modules\@vscode\sqlite3: Command failed.
Exit code: 1
Command: node-gyp rebuild
Arguments:
Directory: C:\buff\vscode_compile_error\node_modules\@vscode\sqlite3
Output:
C:\buff\vscode_compile_error\node_modules\@vscode\sqlite3>if not defined npm_config_node_gyp (node ""C:\Program Files\nodejs\node_modules\npm\bin\node-gyp-bin\\..\..\node_modules\node-gyp\bin\node-gyp.js"" rebuild )  else (node """" rebuild )
gyp info it worked if it ends with ok
gyp info using node-gyp@9.0.0
gyp info using node@16.16.0 | win32 | x64
gyp info find Python using Python version 3.9.7 found at ""C:\Program Files\Python\Python39\python.exe""
gyp info find VS using VS2019 (16.11.31729.503) found at:
gyp info find VS ""C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional""
gyp info find VS run with --verbose for detailed information
gyp info spawn C:\Program Files\Python\Python39\python.exe
gyp info spawn args [
gyp info spawn args   'C:\\Program Files\\nodejs\\node_modules\\npm\\node_modules\\node-gyp\\gyp\\gyp_main.py',
gyp info spawn args   'binding.gyp',
gyp info spawn args   '-f',
gyp info spawn args   'msvs',
gyp info spawn args   '-I',
gyp info spawn args   'C:\\buff\\vscode_compile_error\\node_modules\\@vscode\\sqlite3\\build\\config.gypi',
gyp info spawn args   '-I',
gyp info spawn args   'C:\\Program Files\\nodejs\\node_modules\\npm\\node_modules\\node-gyp\\addon.gypi',
gyp info spawn args   '-I',
gyp info spawn args   'C:\\Users\\<my_username>\\AppData\\Local\\node-gyp\\Cache\\18.3.5\\include\\node\\common.gypi',
gyp info spawn args   '-Dlibrary=shared_library',
gyp info spawn args   '-Dvisibility=default',
gyp info spawn args   '-Dnode_root_dir=C:\\Users\\<my_username>\\AppData\\Local\\node-gyp\\Cache\\18.3.5',
gyp info spawn args   '-Dnode_gyp_dir=C:\\Program Files\\nodejs\\node_modules\\npm\\node_modules\\node-gyp',
gyp info spawn args   '-Dnode_lib_file=C:\\\\Users\\\\<my_username>\\\\AppData\\\\Local\\\\node-gyp\\\\Cache\\\\18.3.5\\\\<(target_arch)\\\\node.lib',
gyp info spawn args   '-Dmodule_root_dir=C:\\buff\\vscode_compile_error\\node_modules\\@vscode\\sqlite3',
gyp info spawn args   '-Dnode_engine=v8',
gyp info spawn args   '--depth=.',
gyp info spawn args   '--no-parallel',
gyp info spawn args   '--generator-output',
gyp info spawn args   'C:\\buff\\vscode_compile_error\\node_modules\\@vscode\\sqlite3\\build',
gyp info spawn args   '-Goutput_dir=.'
gyp info spawn args ]
gyp info spawn C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\MSBuild\Current\Bin\MSBuild.exe
gyp info spawn args [
gyp info spawn args   'build/binding.sln',
gyp info spawn args   '/clp:Verbosity=minimal',
gyp info spawn args   '/nologo',
gyp info spawn args   '/p:Configuration=Release;Platform=x64'
gyp info spawn args ]
Building the projects in this solution one at a time. To enable parallel build, please add the ""-m"" switch.
  unpack_sqlite_dep
  'C:\Program' is not recognized as an internal or external command,
  operable program or batch file.
C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\MSBuild\Microsoft\VC\v160\Microsoft.CppCommon.targets(241,5): error MSB8066: Custom build for '..\..\deps\sqlite-autoconf-3360000.tar.gz' exited with code 1. [C:\buff\vscode_compile_error\node_modules\@vscode\sqlite3\build\deps\action_before_build.vcxproj]
  nothing.c
  win_delay_load_hook.cc
  nothing.vcxproj -> C:\buff\vscode_compile_error\node_modules\@vscode\sqlite3\build\Release\\nothing.lib
gyp ERR! build error
gyp ERR! stack Error: `C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\MSBuild\Current\Bin\MSBuild.exe` failed with exit code: 1
gyp ERR! stack     at ChildProcess.onExit (C:\Program Files\nodejs\node_modules\npm\node_modules\node-gyp\lib\build.js:194:23)
gyp ERR! stack     at ChildProcess.emit (node:events:527:28)
gyp ERR! stack     at Process.ChildProcess._handle.onexit (node:internal/child_process:291:12)
gyp ERR! System Windows_NT 10.0.22000
gyp ERR! command ""C:\\Program Files\\nodejs\\node.exe"" ""C:\\Program Files\\nodejs\\node_modules\\npm\\node_modules\\node-gyp\\bin\\node-gyp.js"" ""rebuild""
gyp ERR! cwd C:\buff\vscode_compile_error\node_modules\@vscode\sqlite3
```

Take special attention to this line: `'C:\Program' is not recognized as an internal or external command,`

As I have Python and some other things installed to the folder `C:\Program Files\`, other programs often fail to interpret this path.

### Things I've done for fixing
I just created python venv inside the root of the project:
```bash
python -m venv ./.venv
# This command will depend on your platform
./.venv/Scripts/activate
```
And then restarted the build process by running `yarn`. Everything compiled successfully.",False,0,NONE
https://api.github.com/repos/microsoft/vscode/issues/comments/1220815984,error D:\vscode-main\node_modules\@vscode\sqlite3: Command failed.,FuPeiJiang,4,1279715936,4,1220815984,0,1180227174,2022-08-19T15:37:22Z,"> 'C:\Program' is not recognized as an internal or external command,

it'll work if you change `deps/sqlite3.gyp` line 65:
```
'<!(node -p ""process.env.PYTHON"")'
```
to
```
'""<!(node -p ""process.env.PYTHON"")""'
```

https://github.com/FuPeiJiang/npm--vscode-sqlite3/commit/4c2fa86d458a9df9cc04975d853e74379729f988

but since yarn resets files, your changes are gone
> Yarn will completely replace the contents of your node_modules with freshly unpackaged modules.

https://yarnpkg.com/package/patch-package#:~:text=Yarn%20will%20completely%20replace%20the%20contents%20of%20your%20node_modules%20with%20freshly%20unpackaged%20modules.

so test with this:
https://github.com/FuPeiJiang/vscode/tree/vscode-sqlite3

the reason I made a separate repo: https://github.com/FuPeiJiang/npm--vscode-sqlite3
is because https://www.npmjs.com/package/@vscode/sqlite3 doesn't have a repo, so nowhere to contribute changes
why was https://www.npmjs.com/package/sqlite3 forked ?
for performance ? I see that dependency: ` ""@mapbox/node-pre-gyp"": ""^1.0.0"",` is removed

note that sqlite3 was updated from `./extract.py` to `./extract.js`
https://github.com/TryGhost/node-sqlite3/pull/1570
so my ""fix"" is totally useless if we merge with sqlite3, but again, no repo",False,0,NONE
https://api.github.com/repos/microsoft/vscode/issues/comments/1340326887,error D:\vscode-main\node_modules\@vscode\sqlite3: Command failed.,deepak1556,4,1279715936,5,1340326887,0,1220815984,2022-12-07T03:34:39Z,"Please try the latest version, this should now be addressed with https://github.com/microsoft/vscode-node-sqlite3/commit/8db96d42be7f7aba506d04018cf6cbdc1bfa3373",False,0,CONTRIBUTOR
https://api.github.com/repos/nestjs/nest-cli/issues/1683,Allow custom suffix when generating unit tests,garritfra,9,1274796320,1,1274796320,0,0,2022-06-17T09:24:15Z,"### Is there an existing issue that is already proposing this?

- [X] I have searched the existing issues

### Is your feature request related to a problem? Please describe it

We've settled with `.test.ts` as a unit-test suffix for all of our projects. While Nest is able to interpret these files, it can only produce `.spec.ts` files when generating a resource, which breaks our convention. It would be nice to be able to specify a custom suffix as a cli option.

### Describe the solution you'd like

There should be a cli flag and config option to specify the suffix to be used, with the default being `spec`.

```sh
nest g res foo --spec-suffix=test
```

`nest-cli.json`:
```json
{
	""generateOptions"": {
		""spec"": true,
		""specSuffix"": ""test""
	}
}
```

(flag and option naming TBD.)

### Teachability, documentation, adoption, migration strategy

_No response_

### What is the motivation / use case for changing the behavior?

Implementing this feature makes it easier to adopt company conventions.",True,0,NONE
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1158745448,Allow custom suffix when generating unit tests,kamilmysliwiec,9,1274796320,2,1158745448,0,1274796320,2022-06-17T10:42:43Z,Would you like to create a PR for this issue?,False,0,MEMBER
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1158747610,Allow custom suffix when generating unit tests,garritfra,9,1274796320,3,1158747610,0,1158745448,2022-06-17T10:45:50Z,@kamilmysliwiec I'll see what I can do.👍,False,0,NONE
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1158828230,Allow custom suffix when generating unit tests,garritfra,9,1274796320,4,1158828230,0,1158747610,2022-06-17T12:35:19Z,"@kamilmysliwiec implementing this takes longer than I anticipated. To prepare for this change, I opened a draft PR in the schematics repo (https://github.com/nestjs/schematics/pull/1077). Let me know if I'm taking a wrong route. Otherwise, I'll gradually finish that PR and then finish the work up here.",False,0,NONE
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1158829004,Allow custom suffix when generating unit tests,kamilmysliwiec,9,1274796320,5,1158829004,0,1158828230,2022-06-17T12:36:25Z,"Thanks @garritfra, let's track this here https://github.com/nestjs/schematics/pull/1077!",False,0,MEMBER
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1462450239,Allow custom suffix when generating unit tests,hrkeni,9,1274796320,6,1462450239,0,1158829004,2023-03-09T17:19:29Z,"@kamilmysliwiec Does this need to be reopened? I don't believe the feature has been implemented and didn't make it into the cli as part of https://github.com/nestjs/schematics/pull/1077 

@garritfra Am I seeing that correctly?",False,0,NONE
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1462462074,Allow custom suffix when generating unit tests,garritfra,9,1274796320,7,1462462074,0,1462450239,2023-03-09T17:26:05Z,"@hrkeni yes, that's correct. I don't have the time to work on it anymore, but it should be a simple change.",False,0,NONE
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1464157083,Allow custom suffix when generating unit tests,hrkeni,9,1274796320,8,1464157083,0,1462462074,2023-03-10T17:49:13Z,I would be happy to work on this.,False,0,NONE
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1484114738,Allow custom suffix when generating unit tests,hrkeni,9,1274796320,9,1484114738,0,1464157083,2023-03-26T14:33:50Z,@kamilmysliwiec Please reopen this issue and review PRs or let me know if I should open another issue here. Thank you.,False,0,NONE
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1487575865,Allow custom suffix when generating unit tests,hrkeni,9,1274796320,10,1487575865,0,1484114738,2023-03-28T20:51:39Z,@micalevisk Apologies for the spam. Can you take a look at the comments above and advise?,False,0,NONE
https://api.github.com/repos/nestjs/nest-cli/issues/1705,NPM Install is failing with package not found for es-lint@8.4.4,sicco-moonbeam,7,1290566899,1,1290566899,0,0,2022-06-30T19:46:59Z,"### Is there an existing issue for this?

- [X] I have searched the existing issues

### Current behavior

Running `npm i -g @nestjs/cli`, I get the following error:

```
npm i -g @nestjs/cli@8.2.7
npm ERR! code E404
npm ERR! 404 Not Found - GET https://registry.npmjs.org/@types/eslint/-/eslint-8.4.4.tgz - Not found
npm ERR! 404
npm ERR! 404  '@types/eslint@https://registry.npmjs.org/@types/eslint/-/eslint-8.4.4.tgz' is not in this registry.
npm ERR! 404 You should bug the author to publish it (or use the name yourself!)
npm ERR! 404
npm ERR! 404 Note that you can also install from a
npm ERR! 404 tarball, folder, http url, or git url.
```

### Minimum reproduction code

https://github.com/nestjs/nest-cli

### Steps to reproduce

Run the command `npm i -g @nestjs/cli`

### Expected behavior

NestJS/CLI installs globally

### Package version

8.2.8

### NestJS version

_No response_

### Node.js version

_No response_

### In which operating systems have you tested?

- [ ] macOS
- [X] Windows
- [ ] Linux

### Other

_No response_",True,0,NONE
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1171613302,NPM Install is failing with package not found for es-lint@8.4.4,jmcdo29,7,1290566899,2,1171613302,0,1290566899,2022-06-30T19:48:51Z,Looks like there was an error publishing `@types/eslint`. Follow [this thread](https://github.com/DefinitelyTyped/DefinitelyTyped/issues/61032) for more details,False,0,MEMBER
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1171634623,NPM Install is failing with package not found for es-lint@8.4.4,Segaja,7,1290566899,3,1171634623,0,1171613302,2022-06-30T20:15:27Z,"Am I missing something? I'm trying to install `@nestjs/cli` version 8.2.8, which has in its [`package.json`](https://github.com/nestjs/nest-cli/blob/8.2.8/package.json#L86=) version 8.18.0 of eslint as dependency. Why will it then during install try to load eslint 8.4.4 ?",False,0,NONE
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1171635794,NPM Install is failing with package not found for es-lint@8.4.4,jmcdo29,7,1290566899,4,1171635794,0,1171634623,2022-06-30T20:16:57Z,It's not that it's trying to install `eslint@8.4.4` it's that somewhere in the dependency tree something is request `@types/eslint@8.4.4` (presumably by `@types/eslint@^8.x.y`) which gets this missing package error. ,False,0,MEMBER
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1171637684,NPM Install is failing with package not found for es-lint@8.4.4,Segaja,7,1290566899,5,1171637684,0,1171635794,2022-06-30T20:19:08Z,Hm okay. still sounds add as this seems to be an old version. Why would it vanish from NPM? anyway. i guess we have to wait for eslint to fix this? What a set back... This kind of kills my first dive into nestjs...,False,0,NONE
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1171639606,NPM Install is failing with package not found for es-lint@8.4.4,jmcdo29,7,1290566899,6,1171639606,0,1171637684,2022-06-30T20:21:19Z,"This issue just came up today, within the last hour or so. It's a major issue that is effecting multiple packages, not just `@nestjs/cli`. Unfortunately, not much to do right now other than wait for `@types/8.4.5`. You could go without the CLI for now, I think we have a docs PR in the works of how to get started without it, but it's really unfortunate timing honestly",False,0,MEMBER
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1171640688,NPM Install is failing with package not found for es-lint@8.4.4,Segaja,7,1290566899,7,1171640688,0,1171639606,2022-06-30T20:22:36Z,"I will wait, but thanks ;)",False,0,NONE
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1171841819,NPM Install is failing with package not found for es-lint@8.4.4,jmcdo29,7,1290566899,8,1171841819,0,1171640688,2022-07-01T01:58:19Z,This has now been resolved. There was an incident with npm that did not allow for the publishing of new packages. Just tested in a clean docker environment and had no issues.,False,0,MEMBER
https://api.github.com/repos/nestjs/nest-cli/issues/1716,Node.js v10.13.0 not available to use cli v9,diyews,3,1299593465,1,1299593465,0,0,2022-07-09T07:10:47Z,"### Did you read the migration guide?

- [X] I have read the whole migration guide

### Is there an existing issue that is already proposing this?

- [X] I have searched the existing issues

### Potential Commit/PR that introduced the regression

_No response_

### Versions

8 -> 9

### Describe the regression

From the [doc site](https://docs.nestjs.com/first-steps#prerequisites) it said 

> Please make sure that [Node.js](https://nodejs.org/) (>= 10.13.0, except for v13) is installed on your operating system.

@nestjs/core v9 works in v10.13.0, see [link](https://github.com/nestjs/docs.nestjs.com/pull/2252)(v8, I tried v9 also)

With @nestjs/cli v9 I got
![image](https://user-images.githubusercontent.com/35769340/178095713-6c1bcda7-d6a7-4101-9b97-d63254e97847.png)



### Minimum reproduction code

```ts

```


### Expected behavior

Update docs or make it works in v10.13.0, prefer the first one :)

### Other

_No response_",True,0,NONE
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1179536887,Node.js v10.13.0 not available to use cli v9,micalevisk,3,1299593465,2,1179536887,0,1299593465,2022-07-09T12:40:04Z,"![image](https://user-images.githubusercontent.com/13461315/178106027-0410780b-e93f-4dba-bc9e-91de9ef9941d.png)

```bash
$ npm view yargs-parser engines.node
>=12
```

So I guess the solution to this would be either indicate that Nest CLI only supports node >= 12 or downgrade all the dependencies of it :/

---

I notice that the latest version `@angular-devkit/*` packages supports node14 or above

```bash
$ npm view @angular-devkit/core engines.node
^14.15.0 || >=16.10.0
```

note that v13 only supports node12",False,0,MEMBER
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1179550780,Node.js v10.13.0 not available to use cli v9,micalevisk,3,1299593465,3,1179550780,0,1179536887,2022-07-09T14:08:11Z,"also, please don't use node10 anymore. There's no reason to :smile: (to me we could drop the support for node10 entirely tbh as several other packages aren't supporting it anymore)

![image](https://user-images.githubusercontent.com/13461315/178109273-24939af8-0da6-4270-a412-f03b7698e228.png)
",False,0,MEMBER
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1179614677,Node.js v10.13.0 not available to use cli v9,micalevisk,3,1299593465,4,1179614677,0,1179550780,2022-07-09T22:19:57Z,"https://docs.nestjs.com/migration-guide#nodejs

I just notice that Kamil choose to drop the support for node10 lol I'll update the docs",False,0,MEMBER
https://api.github.com/repos/nestjs/nest-cli/issues/1720,"When installing the V9 version, the installation fails using nest g resource test, and the script that automatically generates test cases needs to be closed to install the dependencies normally.",webCoder-hm,22,1303501703,1,1303501703,0,0,2022-07-13T14:12:29Z,"### Did you read the migration guide?

- [ ] I have read the whole migration guide

### Is there an existing issue that is already proposing this?

- [X] I have searched the existing issues

### Potential Commit/PR that introduced the regression

_No response_

### Versions

8.0.0 -> 9.0.1

### Describe the regression

When installing the V9 version, the installation fails using nest g resource test, and the script that automatically generates test cases needs to be closed to install the dependencies normally.

### Minimum reproduction code

```ts

```


### Expected behavior

When installing the V9 version, the installation fails using nest g resource test, and the script that automatically generates test cases needs to be closed to install the dependencies normally.

### Other

_No response_",True,0,NONE
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1183283079,"When installing the V9 version, the installation fails using nest g resource test, and the script that automatically generates test cases needs to be closed to install the dependencies normally.",micalevisk,22,1303501703,2,1183283079,0,1303501703,2022-07-13T14:16:20Z,"could you please share with the steps to reproduce your issue? I didn't follow

Also, [why Reproductions are Required](https://antfu.me/posts/why-reproductions-are-required).",False,0,MEMBER
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1183285844,"When installing the V9 version, the installation fails using nest g resource test, and the script that automatically generates test cases needs to be closed to install the dependencies normally.",jmcdo29,22,1303501703,3,1183285844,0,1183283079,2022-07-13T14:18:36Z,"Just tested this in a docker container, is this the error you're getting?
```
npm i
npm ERR! code ETARGET
npm ERR! notarget No matching version found for @jest/console@^28.1.3.
npm ERR! notarget In most cases you or one of your dependencies are requesting
npm ERR! notarget a package version that doesn't exist.

npm ERR! A complete log of this run can be found in:
npm ERR!     /root/.npm/_logs/2022-07-13T14_16_18_752Z-debug-0.log
```
<details>

<summary>Full output</summary>

```
# npm i -g @nestjs/cli

added 249 packages, and audited 250 packages in 9s

39 packages are looking for funding
  run `npm fund` for details

found 0 vulnerabilities
npm notice
npm notice New minor version of npm available! 8.12.1 -> 8.13.2
npm notice Changelog: https://github.com/npm/cli/releases/tag/v8.13.2
npm notice Run npm install -g npm@8.13.2 to update!
npm notice
# nest new resource-test -p npm
⚡  We will scaffold your app in a few seconds..

CREATE resource-test/.eslintrc.js (665 bytes)
CREATE resource-test/.prettierrc (51 bytes)
CREATE resource-test/README.md (3340 bytes)
CREATE resource-test/nest-cli.json (118 bytes)
CREATE resource-test/package.json (1998 bytes)
CREATE resource-test/tsconfig.build.json (97 bytes)
CREATE resource-test/tsconfig.json (546 bytes)
CREATE resource-test/src/app.controller.spec.ts (617 bytes)
CREATE resource-test/src/app.controller.ts (274 bytes)
CREATE resource-test/src/app.module.ts (249 bytes)
CREATE resource-test/src/app.service.ts (142 bytes)
CREATE resource-test/src/main.ts (208 bytes)
CREATE resource-test/test/app.e2e-spec.ts (630 bytes)
CREATE resource-test/test/jest-e2e.json (183 bytes)

▹▹▹▹▸ Installation in progress... ☕
Failed to execute command: npm install --silent
✖ Installation in progress... ☕
🙀  Packages installation failed!
In case you don't see any errors above, consider manually running the failed command npm install to see more details on why it errored out.

                                                                                 Thanks for installing Nest 🙏
                                                                        Please consider donating to our open collective
                                                                               to help us maintain this package.


                                                                      🍷  Donate: https://opencollective.com/nest

# cd resource-test
# npm i
npm ERR! code ETARGET
npm ERR! notarget No matching version found for @jest/console@^28.1.3.
npm ERR! notarget In most cases you or one of your dependencies are requesting
npm ERR! notarget a package version that doesn't exist.

npm ERR! A complete log of this run can be found in:
npm ERR!     /root/.npm/_logs/2022-07-13T14_16_18_752Z-debug-0.log
```

</details>",False,0,MEMBER
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1183288504,"When installing the V9 version, the installation fails using nest g resource test, and the script that automatically generates test cases needs to be closed to install the dependencies normally.",webCoder-hm,22,1303501703,4,1183288504,0,1183285844,2022-07-13T14:20:50Z,"1. Uninstall nestcli
2. Install the latest @nestjs/cli
3. Execute nest g resource user
4. Error

> could you please share with the steps to reproduce your issue? I didn't follow
> 
> Also, [why Reproductions are Required](https://antfu.me/posts/why-reproductions-are-required).

1. Uninstall nestcli
2. Install the latest @nestjs/cli
3. Execute nest g resource user
4. Error",False,0,NONE
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1183290085,"When installing the V9 version, the installation fails using nest g resource test, and the script that automatically generates test cases needs to be closed to install the dependencies normally.",jmcdo29,22,1303501703,5,1183290085,0,1183288504,2022-07-13T14:22:00Z,"> 
    Uninstall nestcli
    Install the latest @nestjs/cli
    Execute nest g resource user
    Error

So is this in an existing project that this is happening, not a new one?",False,0,MEMBER
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1183297491,"When installing the V9 version, the installation fails using nest g resource test, and the script that automatically generates test cases needs to be closed to install the dependencies normally.",webCoder-hm,22,1303501703,6,1183297491,0,1183290085,2022-07-13T14:28:23Z,"> > 
> 
> ```
> Uninstall nestcli
> Install the latest @nestjs/cli
> Execute nest g resource user
> Error
> ```
> 
> So is this in an existing project that this is happening, not a new one?

Old project, I only upgraded ""@nestjs/core"", it seems to be the same",False,0,NONE
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1183298112,"When installing the V9 version, the installation fails using nest g resource test, and the script that automatically generates test cases needs to be closed to install the dependencies normally.",micalevisk,22,1303501703,7,1183298112,0,1183297491,2022-07-13T14:28:54Z,"you should upgrade every `@nestjs/*` package.

`npx @nestjs/cli@latest new` & `npm i` went fine here.",False,0,MEMBER
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1183300541,"When installing the V9 version, the installation fails using nest g resource test, and the script that automatically generates test cases needs to be closed to install the dependencies normally.",webCoder-hm,22,1303501703,8,1183300541,0,1183298112,2022-07-13T14:30:55Z,"> you should upgrade every `@nestjs/*` package.
> 
> `npx @nestjs/cli@latest new` & `npm i` went fine here.

I tried it, maybe this package @nestjs/schematics reported an error",False,0,NONE
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1183302034,"When installing the V9 version, the installation fails using nest g resource test, and the script that automatically generates test cases needs to be closed to install the dependencies normally.",jmcdo29,22,1303501703,9,1183302034,0,1183300541,2022-07-13T14:32:18Z,"This is the error I just got when trying to run `nest g resource test` on an old help project upgraded to v9

```
nest g resource test
? What transport layer do you use? REST API
? Would you like to generate CRUD entry points? Yes
CREATE src/test/test.controller.spec.ts (556 bytes)
CREATE src/test/test.controller.ts (883 bytes)
CREATE src/test/test.module.ts (240 bytes)
CREATE src/test/test.service.spec.ts (446 bytes)
CREATE src/test/test.service.ts (607 bytes)
CREATE src/test/dto/create-test.dto.ts (30 bytes)
CREATE src/test/dto/update-test.dto.ts (169 bytes)
CREATE src/test/entities/test.entity.ts (21 bytes)
UPDATE package.json (2028 bytes)
UPDATE src/app.module.ts (308 bytes)
⠼ Installing packages (npm)...npm ERR! Cannot read properties of null (reading 'matches')

npm ERR! A complete log of this run can be found in:
npm ERR!     /home/jay/.npm/_logs/2022-07-13T14_30_37_718Z-debug-0.log
✖ Package install failed, see above.
The Schematic workflow failed. See above.

Failed to execute command: node @nestjs/schematics:resource --name=test --no-dry-run --no-skip-import --language=""ts"" --source-root=""src"" --spec
```

Let me see if I can make a more solid reproduction with better steps all the way through",False,0,MEMBER
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1183304718,"When installing the V9 version, the installation fails using nest g resource test, and the script that automatically generates test cases needs to be closed to install the dependencies normally.",micalevisk,22,1303501703,10,1183304718,0,1183302034,2022-07-13T14:34:37Z,"@webCoder-hm please share us the output of the `npx nest info` command
",False,0,MEMBER
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1183306965,"When installing the V9 version, the installation fails using nest g resource test, and the script that automatically generates test cases needs to be closed to install the dependencies normally.",webCoder-hm,22,1303501703,11,1183306965,0,1183304718,2022-07-13T14:36:33Z,"> npx nest info


[System Information]
OS Version     : macOS Monterey
NodeJS Version : v16.13.2
PNPM Version    : 7.1.5 

[Nest CLI]
Nest CLI Version : 9.0.0 ",False,0,NONE
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1183310346,"When installing the V9 version, the installation fails using nest g resource test, and the script that automatically generates test cases needs to be closed to install the dependencies normally.",webCoder-hm,22,1303501703,12,1183310346,0,1183306965,2022-07-13T14:39:31Z,"> This is the error I just got when trying to run `nest g resource test` on an old help project upgraded to v9
> 
> ```
> nest g resource test
> ? What transport layer do you use? REST API
> ? Would you like to generate CRUD entry points? Yes
> CREATE src/test/test.controller.spec.ts (556 bytes)
> CREATE src/test/test.controller.ts (883 bytes)
> CREATE src/test/test.module.ts (240 bytes)
> CREATE src/test/test.service.spec.ts (446 bytes)
> CREATE src/test/test.service.ts (607 bytes)
> CREATE src/test/dto/create-test.dto.ts (30 bytes)
> CREATE src/test/dto/update-test.dto.ts (169 bytes)
> CREATE src/test/entities/test.entity.ts (21 bytes)
> UPDATE package.json (2028 bytes)
> UPDATE src/app.module.ts (308 bytes)
> ⠼ Installing packages (npm)...npm ERR! Cannot read properties of null (reading 'matches')
> 
> npm ERR! A complete log of this run can be found in:
> npm ERR!     /home/jay/.npm/_logs/2022-07-13T14_30_37_718Z-debug-0.log
> ✖ Package install failed, see above.
> The Schematic workflow failed. See above.
> 
> Failed to execute command: node @nestjs/schematics:resource --name=test --no-dry-run --no-skip-import --language=""ts"" --source-root=""src"" --spec
> ```
> 
> Let me see if I can make a more solid reproduction with better steps all the way through

yes that's it",False,0,NONE
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1183314245,"When installing the V9 version, the installation fails using nest g resource test, and the script that automatically generates test cases needs to be closed to install the dependencies normally.",micalevisk,22,1303501703,13,1183314245,0,1183310346,2022-07-13T14:42:50Z,looks like there is some version mismatch as that didn't happen in a fresh new app (running `npx nest g resource test` worked as expected),False,0,MEMBER
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1183316324,"When installing the V9 version, the installation fails using nest g resource test, and the script that automatically generates test cases needs to be closed to install the dependencies normally.",webCoder-hm,22,1303501703,14,1183316324,0,1183314245,2022-07-13T14:44:38Z,"> 看起来有一些版本不匹配，因为在新的新应用程序中没有发生这种情况（`npx nest g resource test`按预期运行）

you need to run
Error：Cannot find module '@nestjs/mapped-types' or its corresponding type declarations.

1 import { PartialType } from '@nestjs/mapped-types';

Found 1 error(s).",False,0,NONE
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1183323746,"When installing the V9 version, the installation fails using nest g resource test, and the script that automatically generates test cases needs to be closed to install the dependencies normally.",jmcdo29,22,1303501703,15,1183323746,0,1183316324,2022-07-13T14:50:54Z,"Not sure what's going on for you, but I couldn't replicate this in docker
```sh
docker run it node:latest sh
npx @nestjs/cli@8 new resource-upgrade-test -p npm --yes
cd resource-upgrade-test
npx nest g res test-v8
npm install @nestjs/common@^9 @nestjs/core@^9 @nestjs/platform-express@^9 @nestjs/cli@^9 @nestjs/schematics@^9 @nestjs/testing@^9
npx nest g res test-v9
```",False,0,MEMBER
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1183324994,"When installing the V9 version, the installation fails using nest g resource test, and the script that automatically generates test cases needs to be closed to install the dependencies normally.",micalevisk,22,1303501703,16,1183324994,0,1183323746,2022-07-13T14:51:56Z,"I notice that in v9 the new app has the hard dependency `@nestjs/mapped-types` 

@webCoder-hm install `@nestjs/mapped-types` and see if it works",False,0,MEMBER
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1183327805,"When installing the V9 version, the installation fails using nest g resource test, and the script that automatically generates test cases needs to be closed to install the dependencies normally.",webCoder-hm,22,1303501703,17,1183327805,0,1183324994,2022-07-13T14:54:16Z,"> I notice that in v9 the new app has the hard dependency `@nestjs/mapped-types`
> 
> @webCoder-hm install `@nestjs/mapped-types` and see if it works

pnpm i @nestjs/mapped-types

Error:
error TS2300: Duplicate identifier 'UserModule'.

4 import { UserModule } from './user/user.module';

error TS2300: Duplicate identifier 'UserModule'.

5 import { UserModule } from './user/user.module';",False,0,NONE
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1183329272,"When installing the V9 version, the installation fails using nest g resource test, and the script that automatically generates test cases needs to be closed to install the dependencies normally.",micalevisk,22,1303501703,18,1183329272,0,1183327805,2022-07-13T14:55:26Z,":thinking: looks like an issue with your environment or setup. 

I won't look at this anymore unless you share some minimum reproduction repository, sorry.

# [Why Reproductions are Required](https://antfu.me/posts/why-reproductions-are-required)",False,0,MEMBER
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1183335491,"When installing the V9 version, the installation fails using nest g resource test, and the script that automatically generates test cases needs to be closed to install the dependencies normally.",webCoder-hm,22,1303501703,19,1183335491,0,1183329272,2022-07-13T15:00:24Z,"> 🤔 looks like an issue with your environment or setup.
> 
> I won't look at this anymore unless you share some minimum reproduction repository, sorry.
> 
> # [Why Reproductions are Required](https://antfu.me/posts/why-reproductions-are-required)

""dependencies"": {
    ""@nestjs/common"": ""^9.0.0"",
    ""@nestjs/core"": ""^9.0.0"",
    ""@nestjs/mapped-types"": ""*"",
    ""@nestjs/platform-express"": ""^9.0.0"",
    ""reflect-metadata"": ""^0.1.13"",
    ""rimraf"": ""^3.0.2"",
    ""rxjs"": ""^7.2.0""
  },
  ""devDependencies"": {
    ""@nestjs/cli"": ""^9.0.0"",
    ""@nestjs/schematics"": ""^9.0.0"",
    ""@nestjs/testing"": ""^9.0.0"",
    ""@types/express"": ""^4.17.13"",
    ""@types/jest"": ""28.1.4"",
    ""@types/node"": ""^16.0.0"",
    ""@types/supertest"": ""^2.0.11"",
    ""@typescript-eslint/eslint-plugin"": ""^5.0.0"",
    ""@typescript-eslint/parser"": ""^5.0.0"",
    ""eslint"": ""^8.0.1"",
    ""eslint-config-prettier"": ""^8.3.0"",
    ""eslint-plugin-prettier"": ""^4.0.0"",
    ""jest"": ""28.1.2"",
    ""prettier"": ""^2.3.2"",
    ""source-map-support"": ""^0.5.20"",
    ""supertest"": ""^6.1.3"",
    ""ts-jest"": ""28.0.5"",
    ""ts-loader"": ""^9.2.3"",
    ""ts-node"": ""^10.0.0"",
    ""tsconfig-paths"": ""4.0.0"",
    ""typescript"": ""^4.3.5""
  },

are these ok？",False,0,NONE
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1183340292,"When installing the V9 version, the installation fails using nest g resource test, and the script that automatically generates test cases needs to be closed to install the dependencies normally.",micalevisk,22,1303501703,20,1183340292,0,1183335491,2022-07-13T15:04:11Z,"I copy paste your deps in a nest v8 app, removed the lock file, ran `npm install` & `npx nest g resource test` & `npm run start:dev`. Everything went fine here.",False,0,MEMBER
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1183350712,"When installing the V9 version, the installation fails using nest g resource test, and the script that automatically generates test cases needs to be closed to install the dependencies normally.",webCoder-hm,22,1303501703,21,1183350712,0,1183340292,2022-07-13T15:12:54Z,"> I copy paste your deps in a nest v8 app, removed the lock file, ran `npm install` & `npx nest g resource test` & `npm run start:dev`. Everything went fine here.

I need to sleep, I will reproduce it tomorrow (this is mandatory in the V9 version), what parameters do I need to provide?",False,0,NONE
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1183401977,"When installing the V9 version, the installation fails using nest g resource test, and the script that automatically generates test cases needs to be closed to install the dependencies normally.",micalevisk,22,1303501703,22,1183401977,0,1183350712,2022-07-13T15:58:52Z,just share some full project and the steps to reproduce your issue.,False,0,MEMBER
https://api.github.com/repos/nestjs/nest-cli/issues/comments/1184059711,"When installing the V9 version, the installation fails using nest g resource test, and the script that automatically generates test cases needs to be closed to install the dependencies normally.",kamilmysliwiec,22,1303501703,23,1184059711,0,1183401977,2022-07-14T06:45:04Z,"Please, use our [Discord](https://discord.gg/G7Qnnhy) channel (support) for such questions. We are using GitHub to track bugs, feature requests, and potential improvements.",False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/8892,LMDB Support for driver flags,Girgias,5,1288933721,1,1288933721,0,0,2022-06-29T15:54:05Z,"This fixes #8856

I'm not exactly sure about the implementation for the driver flags as the way DBA is currently built the headers seem to be added somewhat magically.

These commit should also be kept separately.",True,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1191513002,LMDB Support for driver flags,Girgias,5,1288933721,2,1191513002,0,1288933721,2022-07-21T13:51:34Z,"> 

I think the reason why I added the constant is that the default would not be ``0`` and it feels a bit weird, but I can remove it",False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1191520198,LMDB Support for driver flags,cmb69,5,1288933721,3,1191520198,0,1191513002,2022-07-21T13:58:06Z,"Yeah, I see your point. It is unfortunate, that we started with `MDB_NOSUBDIR` as default. Maybe keep `DBA_LMDB_USE_SUB_DIR`.",False,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/comments/1192396577,LMDB Support for driver flags,Girgias,5,1288933721,4,1192396577,0,1191520198,2022-07-22T09:54:35Z,"@kocsismate why am I getting an:
```
In ./ext/dba/dba.stub.php:
Constant DBA_LMDB_NO_SUB_DIR must have a @cvalue annotation
```
Error? I don't understand why it needs a CVALUE annotation as the value is defined in the stubs?",False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1192467389,LMDB Support for driver flags,kocsismate,5,1288933721,5,1192467389,0,1192396577,2022-07-22T11:18:29Z,"> why am I getting an:
In ./ext/dba/dba.stub.php:
Constant DBA_LMDB_NO_SUB_DIR must have a @cvalue annotation
Error? I don't understand why it needs a CVALUE annotation as the value is defined in the stubs?

But the value is `UNKNOWN`, right? `UNKNOWN` value means that `REGISTER_*_CONSTANT()` calls should use the C constant as value. If there is a proper constant value but there's no `@cvalue` then the former is used. If there are both, then the C constant value is used in C code, and an assertion is added that the 2 values match.",False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1192501205,LMDB Support for driver flags,Girgias,5,1288933721,6,1192501205,0,1192467389,2022-07-22T12:02:17Z,"> > why am I getting an:
> > In ./ext/dba/dba.stub.php:
> > Constant DBA_LMDB_NO_SUB_DIR must have a @cvalue annotation
> > Error? I don't understand why it needs a CVALUE annotation as the value is defined in the stubs?
> 
> But the value is `UNKNOWN`, right? `UNKNOWN` value means that `REGISTER_*_CONSTANT()` calls should use the C constant as value. If there is a proper constant value but there's no `@cvalue` then the former is used. If there are both, then the C constant value is used in C code, and an assertion is added that the 2 values match.

The value is not ``UNKNOWN`` it is ``0`` as it's a constant I created which does not have an equivalent in C, which is why I'm confused by the error",False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/8894,Update FreeBSD CI image.,devnexen,5,1289279331,1,1289279331,0,0,2022-06-29T20:41:14Z,,True,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1171072720,Update FreeBSD CI image.,Girgias,5,1289279331,2,1171072720,0,1289279331,2022-06-30T10:55:41Z,Do we need to specify the clang version because of the compiler warnings? If so other than the crypt ones what others one are present?,False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1171080228,Update FreeBSD CI image.,devnexen,5,1289279331,3,1171080228,0,1171072720,2022-06-30T11:03:52Z,"So far, on FreeBSD, these are the only ones.",False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1174022642,Update FreeBSD CI image.,devnexen,5,1289279331,4,1174022642,0,1171080228,2022-07-04T17:25:46Z,@girgias I realise I targeted master but is it ok if I push to all 3 branches ? do not know about CI policy,False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1174033978,Update FreeBSD CI image.,Girgias,5,1289279331,5,1174033978,0,1174022642,2022-07-04T17:46:04Z,"> @Girgias I realise I targeted master but is it ok if I push to all 3 branches ? do not know about CI policy

I don't know what the CI policy is about updating images, but usually we only change/add CI on master (well maybe Azure to GH Action was backported because azure just kinda broke) so I'm not so sure.

But the new version would use a more recent compiler which might emit warnings for previous versions.",False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1174407133,Update FreeBSD CI image.,devnexen,5,1289279331,6,1174407133,0,1174033978,2022-07-04T21:33:56Z,Closed with [f2d6e17](https://github.com/php/php-src/commit/f2d6e175fe54397a4b1ca5d1cab105875a6ebd96),False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/8896,Magic with memory usage of array,woodholly,3,1289435310,1,1289435310,0,0,2022-06-30T00:33:57Z,"### Description

The following code:

```php
<?php
$a = array();
for($i=1; $i<=1000000;$i++) {
	$a[$i] = var_export(array(""foobar$i""), true);
}
echo ""done, memory usage = "" . (memory_get_usage(true)/1024/1024) . ""Mb\n"";
```

Resulted in this output:
```
done, memory usage = 278.00390625Mb
```

But this code with var_export casted to ""real"" string:
```php
<?php
$a = array();
for($i=1; $i<=1000000;$i++) {
	$a[$i] = """" . var_export(array(""foob(ar$i""), true);
}
echo ""done, memory usage = "" . (memory_get_usage(true)/1024/1024) . ""Mb\n"";
```

Resulted in this output:
```
done, memory usage = 94.00390625Mb
```

1) Why original var_export eats x3 more memory in comparison with string-casted variant ? (same thing with json_encode)
2) Why casting using (string) does not help ?

What kind of magic is working here ?
 

### PHP Version

PHP 7.4

### Operating System

Ubuntu",True,0,NONE
https://api.github.com/repos/php/php-src/issues/comments/1170791679,Magic with memory usage of array,alecpl,3,1289435310,2,1170791679,0,1289435310,2022-06-30T05:48:41Z,Interesting. I confirm this on 3v4l.org in all supported versions. Number of iterations need to be at least 10000 to notice the memory usage difference (1000000 is too big there).,False,0,NONE
https://api.github.com/repos/php/php-src/issues/comments/1171256583,Magic with memory usage of array,arnaud-lb,3,1289435310,3,1171256583,0,1170791679,2022-06-30T13:59:38Z,"`var_export` uses a string builder internally that allocates a buffer a bit larger than necessary while building the string. The issue here is that the string is not copied to a smaller buffer at the end.

The cast to string does nothing when the value is already a string. The concatenation however will force the string to be reallocated, and will use the minimum amount of memory.",False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1178962887,Magic with memory usage of array,arnaud-lb,3,1289435310,4,1178962887,0,1171256583,2022-07-08T13:00:28Z,Fixed in #8902. Thank you @woodholly !,False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/8897,"crypt_sha256/crypt_sha512, fix build with more recent versions of cla…",devnexen,7,1289611953,1,1289611953,0,0,2022-06-30T05:38:34Z,"…ng (> 11).

clang picks up the address subtraction to null as UB, but the implementations
are based on glibc.

`error: performing pointer subtraction with a null pointer has undefined behavior [-Werror,-Wnull-pointer-subtraction]
        if ((key - (char *) 0) % __alignof__ (uint64_t) != 0) {`",True,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1171068162,"crypt_sha256/crypt_sha512, fix build with more recent versions of cla…",Girgias,7,1289611953,2,1171068162,0,1289611953,2022-06-30T10:51:02Z,"I noticed this warning when compiling with Clang but I'm not sure how to fix it and if pragmas are desirable, and because this is security related code I'm far from confident to touch it, so I suppose the pragmas are OK",False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1171081325,"crypt_sha256/crypt_sha512, fix build with more recent versions of cla…",devnexen,7,1289611953,3,1171081325,0,1171068162,2022-06-30T11:05:04Z,"Yes since it s well based on the glibc implementation, I did not want to touch it neither.",False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1171097486,"crypt_sha256/crypt_sha512, fix build with more recent versions of cla…",cmb69,7,1289611953,4,1171097486,0,1171081325,2022-06-30T11:23:21Z,"Undefined behavior is a serious issue, and I don't think we should suppress such warnings, if they are legit, and I think in this case they are.

Instead of subtracting a NULL pointer, shouldn't we just cast to `uintptr_t`?",False,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/comments/1171121516,"crypt_sha256/crypt_sha512, fix build with more recent versions of cla…",devnexen,7,1289611953,5,1171121516,0,1171097486,2022-06-30T11:48:46Z,"> Undefined behavior is a serious issue, and I don't think we should suppress such warnings, if they are legit, and I think in this case they are.
> 
> Instead of subtracting a NULL pointer, shouldn't we just cast to `uintptr_t`?

It appears even tough the related glibc code had been like this forever (even now). Ok will give a try then.",False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1171910558,"crypt_sha256/crypt_sha512, fix build with more recent versions of cla…",devnexen,7,1289611953,6,1171910558,0,1171121516,2022-07-01T04:07:33Z,Nope :-),False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1173628555,"crypt_sha256/crypt_sha512, fix build with more recent versions of cla…",cmb69,7,1289611953,7,1173628555,0,1171910558,2022-07-04T10:11:25Z,"@devnexen, there have been some issues with the branches, and apparently this fix is no longer in ""master"" now. I assume it should be applied there as well, but [you had reverted](https://github.com/php/php-src/commit/1a5414cd982dbabf4a9757aec5a5e714f15b40d6). Do we need to re-apply?",False,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/comments/1173632151,"crypt_sha256/crypt_sha512, fix build with more recent versions of cla…",devnexen,7,1289611953,8,1173632151,0,1173628555,2022-07-04T10:14:28Z,Yes I redid a new [PR just for master](https://github.com/php/php-src/pull/8905),False,0,MEMBER
https://api.github.com/repos/exercism/python/issues/3118,[Improve Concept Docs]: TRACEBACKS - Add PDB section,bobahop,4,1273687126,1,1273687126,0,0,2022-06-16T15:02:39Z,"If you have not yet contributed to concept documents, this issue will require some upfront reading to give you the needed background knowledge.  Additionally, we recommend reading the existing `about.md` docs [here](https://github.com/exercism/python/blob/main/concepts/functools/about.md), and an example of completed concept docs [here](https://github.com/exercism/python/tree/main/concepts/classes).

## ✅   Getting started

**`Please please read the docs before starting.`** Posting PRs without reading these docs will be a lot more frustrating for you during the review cycle, and exhaust Exercism's maintainers' time. 

**General Contributing Docs:**

- [Contributing to Exercism](https://exercism.org/docs/building) | [Exercism and GitHub](https://exercism.org/docs/building/github) | - [Contributor Pull Request Guide](https://exercism.org/docs/building/github/contributors-pull-request-guide)
- [What are those Weird Task Tags about?](https://exercism.org/docs/building/product/tasks)
- [Exercism Formatting and Style Guide](https://exercism.org/docs/building/markdown/style-guide)
- [Exercism Markdown Specification](https://exercism.org/docs/building/markdown/markdown)
- [Reputation](https://exercism.org/docs/using/product/reputation)  

**Documents on Language Tracks and Concepts:**

- [Building Language Tracks: An Overview](https://exercism.org/docs/building/tracks) 
- [What are Concepts?](https://exercism.org/docs/building/tracks/concepts)
- [Concept Specifications](https://exercism.org/docs/building/tracks/concepts) 

<br>

## 🙏🏽   Desired Improvements and Changes

Add section on [PDB](https://realpython.com/python-debugging-pdb/), either to #3059 before it's merged or to the [merged doc](https://github.com/exercism/python/tree/main/docs/TRACEBACKS.md) after the PR is approved and merged.
___________


# 🌟   Original Specifications

Below are the original specifications from the Concept issue.  Please use these as a guide in addition to the change list above.


Learn a little around error tracing tools such as [PDB](https://docs.python.org/3.9/library/pdb.html), and similar tools in common IDEs.

## 🎶  Implementation Notes

- Example code  should **only use syntax & concepts introduced within these docs or one of the prerequisite concept exercises or documents.** Where possible, please use REPL formatting, unless you are demonstrating pseudo code or a long code block.
  Please **do not use** syntax not previously covered in prerequisite topics or exercises.  Please also follow [PEP8](https://www.python.org/dev/peps/pep-0008/) guidelines.
- Our markdown and JSON files are checked against [prettier](https://prettier.io/) .  We recommend [setting prettier up locally](https://prettier.io/docs/en/install.html) and running it prior to submitting your PR  to avoid any CI errors.

<br>

##  🆘  Next Steps & Getting Help

1.  **`If you'd like to work on this issue, comment saying ""I'd like to work on this""`** (_there is no real need to wait for a response, just go ahead, we'll assign you and put a `[claimed]` label on the issue_).
2. If you have any questions while implementing, please post the questions as comments in here, or contact one of the maintainers on our Slack channel.",True,0,MEMBER
https://api.github.com/repos/exercism/python/issues/comments/1157776990,[Improve Concept Docs]: TRACEBACKS - Add PDB section,BethanyG,4,1273687126,2,1157776990,0,1273687126,2022-06-16T15:12:13Z,"@bobahop, please add the [appropriate tags](https://exercism.org/docs/building/product/tasks), so that this issue gets listed on the website.  It might also be helpful to add a **getting started** section, so that contributors have links to docs.   An example of that is [here](https://github.com/exercism/python/issues/3098) .  Thanks!",False,0,MEMBER
https://api.github.com/repos/exercism/python/issues/comments/1298303339,[Improve Concept Docs]: TRACEBACKS - Add PDB section,meatball133,4,1273687126,3,1298303339,0,1157776990,2022-11-01T10:08:36Z,The goal is to write a section in the tracebacks file about the python debugger?,False,0,MEMBER
https://api.github.com/repos/exercism/python/issues/comments/1298378042,[Improve Concept Docs]: TRACEBACKS - Add PDB section,meatball133,4,1273687126,4,1298378042,0,1298303339,2022-11-01T11:22:38Z,"This is my first ""big"" pr for Exercism, I would appreciate all the feedback I can get.",False,0,MEMBER
https://api.github.com/repos/exercism/python/issues/comments/1298937101,[Improve Concept Docs]: TRACEBACKS - Add PDB section,BethanyG,4,1273687126,5,1298937101,0,1298378042,2022-11-01T18:26:32Z,"@meatball133  -- Thank you for picking up the issue and for filing a PR!  

I don't have time to review the PR at the moment, but will get to it by the end of the week.  😄   One thing to note for future:  Comment on the issue and give us a little time to assign the issue to you and remove the `[help wanted]` tag -- that way, the issue won't show on the website, and we won't have any confusion as to who is working on it.  Otherwise -- this is great!  _Many thanks!_. 🎉 ⭐ ",False,0,MEMBER
https://api.github.com/repos/exercism/python/issues/3119,[New Concept Exercise]:  Decorators,BethanyG,9,1273690815,1,1273690815,0,0,2022-06-16T15:05:38Z,"This issue describes how to implement  the  `Decorators` **concept exercise** for the Python track.
This has been re-worked from an older concept exercise issue, which can be found [here](https://github.com/exercism/python/issues/2356).
The related **about.md** can be found [here](https://github.com/exercism/python/blob/main/concepts/decorators/about.md).
The `links.json`, `introduction.md` and metadata are still pending for the concept.  Please see this [improvement issue](https://github.com/exercism/python/issues/3120) for more details.

<br>

## ✅ Getting started

_If you have not yet created or contributed to a concept exercise, this issue will require some upfront reading to give you the needed background knowledge. Some good example exercises to look at in the repo:_

<details>
<summary>💡<b>Example Exercises</b>💡 (<em>click to expand</em>)</summary>
<br>

   1. [Little Sister's Vocabulary](https://github.com/exercism/python/tree/main/exercises/concept/little-sisters-vocab)
   2. [Meltdown Mitigation](https://github.com/exercism/python/tree/main/exercises/concept/meltdown-mitigation) 
   3. [Making the Grade](https://github.com/exercism/python/tree/main/exercises/concept/making-the-grade)
   4. [Ellen's Alien Game](https://github.com/exercism/python/tree/main/exercises/concept/ellens-alien-game)

</details>

We also recommend completing one or more of the concept exercises (_they're called ""learning exercises""_) [on the website](https://exercism.org/tracks/python/concepts). 

**`Please please read the docs before starting.`** Posting PRs without reading these docs will be a lot more frustrating for you during the review cycle, and exhaust Exercism's maintainers' time. So, before diving into the implementation, please go through the following documents:


**General Contributing Docs:**

- [Contributing to Exercism](https://exercism.org/docs/building) | [Exercism and GitHub](https://exercism.org/docs/building/github) | - [Contributor Pull Request Guide](https://exercism.org/docs/building/github/contributors-pull-request-guide)
- [What are those Weird Task Tags about?](https://exercism.org/docs/building/product/tasks)
- [Exercism Formatting and Style Guide](https://exercism.org/docs/building/markdown/style-guide)
- [Exercism Markdown Specification](https://exercism.org/docs/building/markdown/markdown)
- [Reputation](https://exercism.org/docs/using/product/reputation)  

**Documents on Language Tracks and Concept Exercises**

- [Building Language Tracks: An Overview](https://exercism.org/docs/building/tracks) 
- [What are Concept Exercises?](https://exercism.org/docs/building/tracks/concept-exercises)
- [Concept Exercise Specifications](https://exercism.org/docs/building/tracks/concept-exercises)
- [Concept Exercise Stories](https://exercism.org/docs/building/tracks/stories)


## 🎯 Goal

The goal of this concept exercise is to teach an understanding/use/creation of `decorators` in Python.

<br>

## 💡Learning objectives

- Review/understand more details on  `higher-order functions`  in Python
  - returning `functions` from `functions`
  - passing a `function` as an argument to another `function`
  - inner or nested `functions`
- Understand that the `decorator` form and the `@` symbols are `syntatic sugar` for making/calling `higher-order functions`
- Know that `decorators` extend the behavior of an ""inner"", ""wrapped"", or passed  `function`  without explicitly modifying it.
- Create & use simple function `decorators`
- Create & use a more ""complex"" function `decorator`
- Use `*args` and `**kwargs` to decorate a function with different arguments
- Understand that a `decorator` is not _required_ to wrap and modify a `function`, but can simply `return` it.

<br>

## 🤔 Concepts

- `decorators`
- `functions`, `higher-order functions`
- `functions as arguments`
- `functions as returns`
- `nested funcitons`
- `*args` and `**kwargs`

<br>

## 🚫 Topics that are Out of scope


<br>
<details>
<summary><b>Concepts & Subjects that are Out of Scope</b> (<em>click to expand</em>)</summary>
<br>

- `comprehensions`
- `class decorators`
- `classes` *as* `decorators`
- `functools` (_this will get its own exercise_)
- `functools.wraps`
- `generators`
- `lambda`, `anonymous functions`
- `map()`, `filter()`, and `reduce()` (_these will get their own exercise_)
- nested `decorators`
- stateful `decorators`

</details>
<br>


## ↩️  Prerequisites

These are the concepts/concept exercises the student should be familiar with before taking on/learning this concept.  
<br>
<details>
<summary>Prereqs  (<em>click to expand</em>)</summary>
<br>

- `basics`
- `bools`
- `comparisons`
- `dicts`
- `dict-methods`
- `functions`
- `function-arguments`
- `higher-order-functions`
- `iteration`
- `lists`
- `list-methods`
- `numbers`
- `sequences`
- `sets`
- `strings`
- `string-methods`
- `tuples`

</details>
<br>

##  📚 Resources for Writing and Reference

<details>
<summary><b>Resources</b> (<em>click to expand</em>)</summary>
<br>

- [Python Docs: Defining Functions](https://docs.python.org/3/tutorial/controlflow.html#defining-functions)
- [Python Docs: Term - decorator](https://docs.python.org/3/glossary.html#term-decorator)
- [Functions as Objects in Python](https://medium.com/python-pandemonium/function-as-objects-in-python-d5215e6d1b0d)
- [Composing Programs: Higher-Order Functions](https://composingprograms.com/pages/16-higher-order-functions.html)
- [Real Python: Primer on Python Decorators](https://realpython.com/primer-on-python-decorators/)
- [Dan Bader: Python Decorators: A Step-by-Step Introduction](https://dbader.org/blog/python-decorators)
- [Learn by Example: Python Decorators](https://www.learnbyexample.org/python-decorators/)
- [PEP 0318 (Python.org)](https://www.python.org/dev/peps/pep-0318/)

</details>
<br>  

### Exercise Ideas & Stories

Should you need inspiration for an exercise story, you can find a collection [here](https://exercism.org/docs/building/tracks/stories).  You can also port an exercise from another track, **but please make sure to only to include tasks that actually make sense in Python** and that add value for a student.  Remove/replace/add tasks as needed to make the concept clear/workable.

<br>

##  📁 Exercise Files to Be Created

<details open>
<summary><b>File Detail for this Exercise</b> (<em>click to collapse</em>)</summary>
<table>
<td>
<br>


* ### Exercise `introduction.md`

  For more information, see [**Exercise** `introduction.md`](https://github.com/exercism/docs/blob/main/building/tracks/concept-exercises.md#file-docsintroductionmd)

  - This can summarize/paraphrase the linked concept documents if they have already been created (either the `about` or the `introduction`).   The summary does need to have enough information and examples  for the student to complete all the tasks outlined for this concept exercise.

* ### Exercise `instructions.md`

   For more information, see [`instructions.md`](https://github.com/exercism/docs/blob/main/building/tracks/concept-exercises.md#file-docsinstructionsmd)

   Instructions for an exercise usually center on a story that sets up the code challenge to be solved.  You can create your own story, or fork one from the ones listed [here](https://exercism.org/docs/building/tracks/stories).  Please make sure to give credit to the original authors if you use a story or fork an exercise.

* ### Exercise `Exemplar.py` Solution
  For more information, see [exemplar implementation](https://github.com/exercism/docs/blob/main/building/tracks/concept-exercises.md#file-exemplar-implementation).
  
  This file should not use syntax or datas structures not introduced in this exercise or in this exercise's prerequisites.  It will be used as an ""ideal"" solution for the challenge, so make sure it conforms to PEP8 and other formatting conventions, and **does not use single letter variable names**.  It should also include proper module and function-level docstrings.  However, it should **NOT** include typehinting or type aliases.

* ### `<Exercise>.py` (Stub) for Implementation
  For more information, see [stub implementation](https://github.com/exercism/docs/blob/main/building/tracks/concept-exercises.md#file-stub-implementation).
  
  This file should provide the expected function names imported for testing, and optionally TODO comments and or docstrings to aid the student in their implementation.  TODOs and docstrings are not required.

* ### `<Exercise>_Test.py` Files
  For more information, see [Tests](https://github.com/exercism/docs/blob/main/building/tracks/concept-exercises.md#file-tests).
  Additionally, please note that Python associates exercise tasks to tests via a [Pytest Marker](https://docs.pytest.org/en/7.1.x/example/markers.html), and uses [`unittest subtests`](https://docs.python.org/3/library/unittest.html#subtests) as a form of test paramaterization.  See the test file for [`Little Sisters Vocab`](https://github.com/exercism/python/blob/main/exercises/concept/little-sisters-vocab/strings_test.py) for examples of how these techniques work.

* ### Exercise `Hints.md`

  For more information on writing hints see [`hints.md`](https://github.com/exercism/docs/blob/main/building/tracks/concept-exercises.md#file-docshintsmd)

  - Hints should provide enough information to get most students ""un-stuck"" and moving toward a solution.  They should **not** provide a student with a direct solution.
  - You can refer to one or more of the resources linked in this issue above, or analogous resources from a trusted source.  We prefer using links within the  [Python Docs](https://docs.python.org/3/) as the primary go-to, but other resources listed above are also good.  Please try to avoid paid or subscription-based links if possible.

* ### Exercise Metadata Files Under  `.meta/config.json`

  For more information on exercise  `.meta/`  files and formatting, see [concept exercise metadata files](https://github.com/exercism/docs/blob/main/building/tracks/concept-exercises.md#metadata-files)

   * `.meta/config.json` - see [this link](https://github.com/exercism/docs/blob/main/building/tracks/concept-exercises.md#file-metaconfigjson) for the fields and formatting of this file.
   * `.meta/design.md` - see [this link](https://github.com/exercism/docs/blob/main/building/tracks/concept-exercises.md#file-metadesignmd) for the formatting of this file.  Please use the **Goal**, **Learning Objectives**,**Concepts**, **Prerequisites** and , **Out of Scope**  sections  from this issue.

<br>
</td>
</table>
</details>
<br>

## ♾️ Exercise Metadata - Track

For more information on concept exercises and formatting for the Python track `config.json` , please see [`config.json`](https://exercism.org/docs/building/tracks/config-json).  The track `config.json` file can be found in the root of the Python repo.

You can use the below for the exercise **UUID**.  You can also generate a new  one via [exercism configlet](https://github.com/exercism/configlet), [uuidgenerator.net](https://www.uuidgenerator.net/version4), or any other favorite method.  The UUID must be a valid  [**V4 UUID**](https://en.wikipedia.org/wiki/Universally_unique_identifier).

- **Exercise UUID** :  `505c7e27-a17d-4d57-961b-304555af4a32`
- **concepts** should be filled in from the Concepts section in this issue
- **prerequisites** should be filled in from the Prerequisites section in this issue    

<br>

## 🎶 Implementation Notes

- As a reminder, code in the `.meta/examplar.py` file should **only use syntax & concepts introduced in this exercise or one of its prerequisite exercises.**  We run all our `examplar.py` files through PyLint, but do not strictly require module docstrings.  We **do** require function docstrings similar to [PEP257](https://www.python.org/dev/peps/pep-0257/).  See [this concept exercise `exemplar.py`](https://github.com/exercism/python/blob/main/exercises/concept/meltdown-mitigation/.meta/exemplar.py) for an example.
- Please **do not use** comprehensions, generator expressions, or other syntax not previously covered either in the introduction to this exercise, or to one of its prerequisites.  Please also follow [PEP8](https://www.python.org/dev/peps/pep-0008/) guidelines.
- In General, tests should be written using `unittest.TestCase` and the test file should be named `<EXERCISE-NAME>_test.py`.  

    - All asserts should contain a ""user friendly"" failure message (_these will display on the webiste to students, so be as clear as you can_). 
    - We use a `PyTest custom mark` to link test cases to exercise task numbers.  
    - We also use `unittest.subtest` to parameterize test input where/when needed.
Here is an [example testfile](https://github.com/exercism/python/blob/main/exercises/concept/making-the-grade/loops_test.py) that shows all three of these in action.

- While we do use [PyTest](https://docs.pytest.org/en/stable/) as our test runner and for some implementation tests, please check with a maintainer before using  a PyTest-specific test method, fixture,  or feature.
- Our markdown and JSON files are checked against [prettier](https://prettier.io/) .  We recommend [setting prettier up locally](https://prettier.io/docs/en/install.html) and running it prior to submitting your PR  to avoid any CI errors.

<br>

##  🆘  Next Steps & Getting Help

1.  **`If you'd like to work on this issue, comment saying ""I'd like to work on this""`** (_there is no real need to wait for a response, just go ahead, we'll assign you and put a `[claimed]` label on the issue_).
2. If you have any questions while implementing, please post the questions as comments in here, or contact one of the maintainers on our Slack channel.",True,0,MEMBER
https://api.github.com/repos/exercism/python/issues/comments/1180534234,[New Concept Exercise]:  Decorators,velaco,9,1273690815,2,1180534234,0,1273690815,2022-07-11T15:10:57Z,"Hi @BethanyG 👋 

I would like to give this issue a try now. I never worked on exercises before, so might take a while though 😅 
",False,0,CONTRIBUTOR
https://api.github.com/repos/exercism/python/issues/comments/1180814273,[New Concept Exercise]:  Decorators,BethanyG,9,1273690815,3,1180814273,0,1180534234,2022-07-11T20:04:21Z,"Hi @velaco 👋🏽 !

We would be delighted to have you work on this. 😄   Don't worry about taking a while - I've written several exercises, and they always take time to get through.  Just ping if you need help, or have any questions.  In particular, the tests might be complex for this exercise, and we may also want to discuss analyzer scenarios and comments.

During the writing of the concept `about.md`, we had a lot of back and forth about what to cover (_use vs making and how complex to get with examples and tasks_) - so if you get into this and decide what we need is two separate exercises, we can discuss that as well.",False,0,MEMBER
https://api.github.com/repos/exercism/python/issues/comments/1182465776,[New Concept Exercise]:  Decorators,velaco,9,1273690815,4,1182465776,0,1180814273,2022-07-12T20:22:03Z,"Hi @BethanyG 
Well, if you can suggest any resources that help you come up with exercise ideas, other than the existing concept exercises, I'd love to hear them 🙂 

We can discuss how many exercises we need and what to cover, that would be nice. I can ping you about that when I get some idea what kind of exercises will work for this concept.",False,0,CONTRIBUTOR
https://api.github.com/repos/exercism/python/issues/comments/1193309500,[New Concept Exercise]:  Decorators,BethanyG,9,1273690815,5,1193309500,0,1182465776,2022-07-24T12:34:34Z,"Hi @velaco -- sincere apologies for the delay in getting back to you.  I've been swamped.  Let me do a little thinking, and see what I can come up with within the next couple of days.  I'll post some things here as I go.

Thank you for your patience.  😄   Hopefully, we can come up with a great exercise together.",False,0,MEMBER
https://api.github.com/repos/exercism/python/issues/comments/1193399211,[New Concept Exercise]:  Decorators,velaco,9,1273690815,6,1193399211,0,1193309500,2022-07-24T21:41:52Z,"Hi @BethanyG 

No worries, this week I had to put this issue on the back-burner unfortunately, so no progress at all :(
Next week should be a bit slower, so I will also look into some ideas for the exercise.

Looking forward to hearing what you come up with 😄 ",False,0,CONTRIBUTOR
https://api.github.com/repos/exercism/python/issues/comments/1292871534,[New Concept Exercise]:  Decorators,github-actions[bot],9,1273690815,7,1292871534,0,1193399211,2022-10-27T02:12:39Z,This issue has been automatically marked as `abandoned 🏚` because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.,False,0,CONTRIBUTOR
https://api.github.com/repos/exercism/python/issues/comments/1571277360,[New Concept Exercise]:  Decorators,safwansamsudeen,9,1273690815,8,1571277360,0,1292871534,2023-06-01T03:33:19Z,Is this still claimed?,False,0,CONTRIBUTOR
https://api.github.com/repos/exercism/python/issues/comments/1572498280,[New Concept Exercise]:  Decorators,BethanyG,9,1273690815,9,1572498280,0,1571277360,2023-06-01T17:28:44Z,"@safwansamsudeen  - yes, it is.  As stated in the comments of the Yacht approach you are working on, we need to have a conversation (_and there are a ton of documents to go through_) before you tackle a concept exercise.  Additionally, we have higher-priority (_earlier in the concept tree_) exercises we'd like to complete on the track before we loop back to things like decorators or anonymous functions.

It would be preferable if you worked on exercises hints, exercise approaches, and exercise mentor notes while we get things sorted.  Thanks!",False,0,MEMBER
https://api.github.com/repos/exercism/python/issues/comments/1572982938,[New Concept Exercise]:  Decorators,safwansamsudeen,9,1273690815,10,1572982938,0,1572498280,2023-06-02T01:09:55Z,"Sounds good, sure!",False,0,CONTRIBUTOR
https://api.github.com/repos/exercism/python/issues/3120,[Improve Concept Docs]: Decorators,BethanyG,4,1273724712,1,1273724712,0,0,2022-06-16T15:31:47Z,"This issue describes desired additions and improvements to the `decorators` module **concept docs.**.
The completed portion of this concept can be found [here](https://github.com/exercism/python/blob/main/concepts/decorators/about.md).
The related **concept exercise** issue and specs can be found [here](https://github.com/exercism/python/issues/3119).

<br>

If you have not yet contributed to concept documents, this issue will require some upfront reading to give you the needed background knowledge.  Additionally, we recommend reading the existing `about.md` docs [here](https://github.com/exercism/python/blob/main/concepts/functools/about.md), and an example of completed concept docs [here](https://github.com/exercism/python/tree/main/concepts/classes).

## ✅   Getting started

**`Please please read the docs before starting.`** Posting PRs without reading these docs will be a lot more frustrating for you during the review cycle, and exhaust Exercism's maintainers' time. 

**General Contributing Docs:**

- [Contributing to Exercism](https://exercism.org/docs/building) | [Exercism and GitHub](https://exercism.org/docs/building/github) | - [Contributor Pull Request Guide](https://exercism.org/docs/building/github/contributors-pull-request-guide)
- [What are those Weird Task Tags about?](https://exercism.org/docs/building/product/tasks)
- [Exercism Formatting and Style Guide](https://exercism.org/docs/building/markdown/style-guide)
- [Exercism Markdown Specification](https://exercism.org/docs/building/markdown/markdown)
- [Reputation](https://exercism.org/docs/using/product/reputation)  

**Documents on Language Tracks and Concepts:**

- [Building Language Tracks: An Overview](https://exercism.org/docs/building/tracks) 
- [What are Concepts?](https://exercism.org/docs/building/tracks/concepts)
- [Concept Specifications](https://exercism.org/docs/building/tracks/concepts) 

<br>

## 🙏🏽   Desired Improvements and Changes

Create/complete the files for this concept:  

-  [x] `introduction.md`
-  [x] `links.json`
-  [x] `.meta/config.json` 

The `about.md` for this concept has already been completed.

<details open>
<summary><b>File Detail for this Issue</b> (<em>click to collapse</em>)</summary>
<table>
<td>
<br>

Please see the following for more details on these files:  [concepts](https://exercism.org/docs/building/tracks/concepts)

* ### `links.json`

  For more information, see [concept links file](https://github.com/exercism/docs/blob/main/building/tracks/concepts.md#file-linksjson)

  -  The same resources listed in this issue can be used as a starting point for the [ `concepts/links.json`](https://github.com/exercism/docs/blob/main/building/tracks/concepts.md#file-linksjson)  file, if it doesn't already exist.
  -  If there are particularly good/interesting information sources for this concept that extend or supplement the concept exercise material & the resources already listed -- please add them to the `links.json` document.


* ### Concept `about.md` 

  For more information, see [Concept `about.md`](https://github.com/exercism/docs/blob/main/anatomy/tracks/concepts.md#file-aboutmd)

  - This file provides information about this concept for a student who has completed the corresponding concept exercise.  It is intended as a reference for continued learning.   This portion has already been completed, and you can find the document [here](https://github.com/exercism/python/blob/main/concepts/decorators/about.md).


* ### Concept `introduction.md`

  For more information, see [Concept `introduction.md`](https://github.com/exercism/docs/blob/main/building/tracks/concepts.md#file-aboutmd)

  * This can also be a summary/paraphrase of the  `about.md` document listed above, and will provide a brief introduction of the concept for a student who has **not yet** completed the associated concept or practice exercises.   It should contain a good summation of the concept, but not go into lots of detail.


* ### Concept `.meta/config.json` Entries

  For more information, see [Concept `.meta/config.json`](https://github.com/exercism/docs/blob/main/building/tracks/concepts.md#file-metaconfigjson)

  * This file is likely already stubbed out.  Remember to add a concept **blurb** of less than 350 characters.  Please also add your GitHub username to the ""authors"" array, and any contributor GitHub usernames to the ""contributors"" array.

<br>
</td>
</table>
</details>",True,0,MEMBER
https://api.github.com/repos/exercism/python/issues/comments/1176233294,[Improve Concept Docs]: Decorators,velaco,4,1273724712,2,1176233294,0,1273724712,2022-07-06T13:37:43Z,"Hi @BethanyG 
I would like to be assigned to help out with this task if it hasn't been taken already 🙂",False,0,CONTRIBUTOR
https://api.github.com/repos/exercism/python/issues/comments/1176239637,[Improve Concept Docs]: Decorators,BethanyG,4,1273724712,3,1176239637,0,1176233294,2022-07-06T13:43:28Z,"@velaco  - _Happy to have you do it!_  🎉 

FYI - if after going over the `about.md` doc you have improvements or changes you think are needed, please feel free to make them - none of it is set in stone.

Give a shout if you have any questions or issues.",False,0,MEMBER
https://api.github.com/repos/exercism/python/issues/comments/1179035683,[Improve Concept Docs]: Decorators,velaco,4,1273724712,4,1179035683,0,1176239637,2022-07-08T14:12:16Z,"Hi @BethanyG 
Any chance you can give me permission to push a local dev branch, or do I need to fork the repo and create a PR from there?

Edit: nevermind, I checked how other users open PRs and created #3135 for this issue the same way",False,0,CONTRIBUTOR
https://api.github.com/repos/exercism/python/issues/comments/1183414252,[Improve Concept Docs]: Decorators,BethanyG,4,1273724712,5,1183414252,0,1179035683,2022-07-13T16:10:08Z,"Closing this as resolved now that #3135 has been merged.  

@velaco  -- thank you very much for working on this!  🎉 ",False,0,MEMBER
https://api.github.com/repos/exercism/python/issues/3121,[New Concept Exercise]:  Functions in Python,BethanyG,13,1273791774,1,1273791774,0,0,2022-06-16T16:16:53Z,"This issue describes how to implement  the  `functions` **concept exercise** for the Python track.
There is an outdated issue for this exercise with some discussion.  It can be found [here](https://github.com/exercism/python/issues/2353)
The related **concept documents** can be found [here](https://github.com/exercism/python/tree/main/concepts/functions).

<br>

## ✅ Getting started

_If you have not yet created or contributed to a concept exercise, this issue will require some upfront reading to give you the needed background knowledge. Some good example exercises to look at in the repo:_

<details>
<summary>💡<b>Example Exercises</b>💡 (<em>click to expand</em>)</summary>
<br>

   1. [Little Sister's Vocabulary](https://github.com/exercism/python/tree/main/exercises/concept/little-sisters-vocab)
   2. [Meltdown Mitigation](https://github.com/exercism/python/tree/main/exercises/concept/meltdown-mitigation) 
   3. [Making the Grade](https://github.com/exercism/python/tree/main/exercises/concept/making-the-grade)
   4. [Ellen's Alien Game](https://github.com/exercism/python/tree/main/exercises/concept/ellens-alien-game)

</details>

We also recommend completing one or more of the concept exercises (_they're called ""learning exercises""_) [on the website](https://exercism.org/tracks/python/concepts). 

**`Please please read the docs before starting.`** Posting PRs without reading these docs will be a lot more frustrating for you during the review cycle, and exhaust Exercism's maintainers' time. So, before diving into the implementation, please go through the following documents:


**General Contributing Docs:**

- [Contributing to Exercism](https://exercism.org/docs/building) | [Exercism and GitHub](https://exercism.org/docs/building/github) | - [Contributor Pull Request Guide](https://exercism.org/docs/building/github/contributors-pull-request-guide)
- [What are those Weird Task Tags about?](https://exercism.org/docs/building/product/tasks)
- [Exercism Formatting and Style Guide](https://exercism.org/docs/building/markdown/style-guide)
- [Exercism Markdown Specification](https://exercism.org/docs/building/markdown/markdown)
- [Reputation](https://exercism.org/docs/using/product/reputation)  

**Documents on Language Tracks and Concept Exercises**

- [Building Language Tracks: An Overview](https://exercism.org/docs/building/tracks) 
- [What are Concept Exercises?](https://exercism.org/docs/building/tracks/concept-exercises)
- [Concept Exercise Specifications](https://exercism.org/docs/building/tracks/concept-exercises)
- [Concept Exercise Stories](https://exercism.org/docs/building/tracks/stories)


## 🎯 Goal

This `functions` concept exercise is meant to teach a deeper understanding and use of `functions`  in Python. It should also explain how Python treats/views functions (_as callable objects_), and dig into some of the features that make Python `functions` unique.


<br>

## 💡Learning objectives

- Understand more about  Python `scopes` and `namespaces`
  - understand the difference between the `global` and `nonlocal` keywords and when to use them
- Get familiar with the [special attributes](https://docs.python.org/3/reference/datamodel.html#types) of Python functions
- Get familiar with best practices when using `return`, and the difference between _explicit_ and _implicit_ `return`
   - functions without an explicit return will return the singleton object `None`
- Understand what is meant by _""functions are first class **objects** in Python""_.
  - understand that `functions` **are** `objects` in Python, and that they have `types`
  - understand that `functions` can be assigned to variables, used in expressions,  and stored in various data structures such as `dicts` or `lists`
  - create `functons` that are assigned to variables, used in expressions, and stored in different data structures.
  - understand and create` functions` that are/can be nested inside one another
- Understand that Python considers a function a form of  `callable object`. 
- Understand that a user-defined `function object` is created by a `function definition`.

<br>

## 🤔 Concepts

- `callable objects`
- `first-class functions`
- `global`
- `nested functions`
- `nonlocal`
- `return`, `implicit return`, `explicit return`
- `scope`
-  special `function attributes`

<br>

## 🚫 Topics that are Out of scope


<br>
<details>
<summary><b>Concepts & Subjects that are Out of Scope</b> (<em>click to expand</em>)</summary>
<br>

- `named parameters` (_these can be touched on if needed_)
-  `default parameters` (_these can be touched on, if needed_)
- `arbitrary parameters`
- `*args & **kwargs`
- `keyword-only arguments`
- `/` and `*` for requiring parameter types
-  `functions-as-arguments` (_this can be mentioned, but shouldn't be required for the exercise_)
- `functions-as-returns`(_this can be mentioned, but will be covered in-depth in `higher-order functions`)
- `closures` (_these will be covered in a different exercise_)
- `decorators` (_these will be covered in a different exercise_)
-  `functools.wraps` (_this is used mostly for decorators_)
-  `functools` (_this will get its own exercise_)
- `comprehensions`
- `generators`
- `lambda`, `anonymous functions` (_these will be covered in a different exercise_)
- `recursion`

</details>
<br>


## ↩️  Prerequisites

_These are the concepts/concept exercises the student needs to complete/understand before solving this concept exercise.  Since `functions` is a ""meta"" topic,  these will probably need to be adjusted to fit the parameters of the exercise._ 

<details>
<summary>Prereqs  (<em>click to expand</em>)</summary>
<br>

- `basics`
- `bools`
- `comparisons`
- `lists`
- `list-methods`
- `loops`
- `numbers`
- `strings`
- `string-methods`

</details>

<br>

##  📚 Resources for Writing and Reference

<details>
<summary><b>Resources</b> (<em>click to expand</em>)</summary>
<br>

- [Python Docs: Naming and Binding](https://docs.python.org/3/reference/executionmodel.html#naming-and-binding)
- [Python Docs: Python Scopes and Namespaces](https://docs.python.org/3/tutorial/classes.html#python-scopes-and-namespaces)
- [Python Docs: Defining Functions](https://docs.python.org/3/tutorial/controlflow.html#defining-functions)
- [Function definitions (Python Library Reference)](https://docs.python.org/3/reference/compound_stmts.html#function-definitions)
- [Dan Bader:  Python s Functions are First-Class](https://dbader.org/blog/python-first-class-functions)
- [Real Python:  Python Scope & the LEGB Rule](https://realpython.com/python-scope-legb-rule/)
- [Stack Overflow: Short Description of Python's Scoping Rules?](https://stackoverflow.com/questions/291978/short-description-of-the-scoping-rules)
- [Real Python: Python Inner Functions: What are they Good For?](https://realpython.com/inner-functions-what-are-they-good-for/)
- [Stack Abuse: How to Use global and nonlocal variables in Python](https://stackabuse.com/how-to-use-global-and-nonlocal-variables-in-python/)
- [The `nonlocal` Statement (Python Docs)](https://docs.python.org/3/reference/simple_stmts.html#nonlocal)
- [The `global` Statement (Python Docs)](https://docs.python.org/3/reference/simple_stmts.html#global)
- [Real Python: The Python return Statement: Usage and Best Practices](https://stackabuse.com/how-to-use-global-and-nonlocal-variables-in-python/)
- [Calls (Python Library Reference)](https://docs.python.org/3/reference/expressions.html#calls)
- [Is it a Class or a Function?  It's a Callable! (Trey Hunner)](https://treyhunner.com/2019/04/is-it-a-class-or-a-function-its-a-callable/)
- [Callables in Python (Vimal A.R Blog)](https://arvimal.blog/2017/08/09/callables-in-python/)
- [Functions as Objects in Python](https://medium.com/python-pandemonium/function-as-objects-in-python-d5215e6d1b0d) -- _this is a subscription-based medium blog, so not good for hints or links_
- [Python Datamodel: Types](https://docs.python.org/3/reference/datamodel.html#types)

</details>
 
<br>

### Exercise Ideas & Stories

Should you need inspiration for an exercise story, you can find a collection [here](https://exercism.org/docs/building/tracks/stories).  You can also port an exercise from another track, **but please make sure to only to include tasks that actually make sense in Python** and that add value for a student.  Remove/replace/add tasks as needed to make the concept clear/workable.

<br>

##  📁 Exercise Files to Be Created

<details open>
<summary><b>File Detail for this Exercise</b> (<em>click to collapse</em>)</summary>
<table>
<td>
<br>


* ### Exercise `introduction.md`

  For more information, see [**Exercise** `introduction.md`](https://github.com/exercism/docs/blob/main/building/tracks/concept-exercises.md#file-docsintroductionmd)

  - This can summarize/paraphrase the linked concept documents if they have already been created (either the `about` or the `introduction`).   The summary does need to have enough information and examples  for the student to complete all the tasks outlined for this concept exercise.

* ### Exercise `instructions.md`

   For more information, see [`instructions.md`](https://github.com/exercism/docs/blob/main/building/tracks/concept-exercises.md#file-docsinstructionsmd)

   Instructions for an exercise usually center on a story that sets up the code challenge to be solved.  You can create your own story, or fork one from the ones listed [here](https://exercism.org/docs/building/tracks/stories).  Please make sure to give credit to the original authors if you use a story or fork an exercise.

* ### Exercise `Exemplar.py` Solution
  For more information, see [exemplar implementation](https://github.com/exercism/docs/blob/main/building/tracks/concept-exercises.md#file-exemplar-implementation).
  
  This file should not use syntax or datas structures not introduced in this exercise or in this exercise's prerequisites.  It will be used as an ""ideal"" solution for the challenge, so make sure it conforms to PEP8 and other formatting conventions, and **does not use single letter variable names**.  It should also include proper module and function-level docstrings.  However, it should **NOT** include typehinting or type aliases.

* ### `<Exercise>.py` (Stub) for Implementation
  For more information, see [stub implementation](https://github.com/exercism/docs/blob/main/building/tracks/concept-exercises.md#file-stub-implementation).
  
  This file should provide the expected function names imported for testing, and optionally TODO comments and or docstrings to aid the student in their implementation.  TODOs and docstrings are not required.

* ### `<Exercise>_Test.py` Files
  For more information, see [Tests](https://github.com/exercism/docs/blob/main/building/tracks/concept-exercises.md#file-tests).
  Additionally, please note that Python associates exercise tasks to tests via a [Pytest Marker](https://docs.pytest.org/en/7.1.x/example/markers.html), and uses [`unittest subtests`](https://docs.python.org/3/library/unittest.html#subtests) as a form of test paramaterization.  See the test file for [`Little Sisters Vocab`](https://github.com/exercism/python/blob/main/exercises/concept/little-sisters-vocab/strings_test.py) for examples of how these techniques work.

* ### Exercise `Hints.md`

  For more information on writing hints see [`hints.md`](https://github.com/exercism/docs/blob/main/building/tracks/concept-exercises.md#file-docshintsmd)

  - Hints should provide enough information to get most students ""un-stuck"" and moving toward a solution.  They should **not** provide a student with a direct solution.
  - You can refer to one or more of the resources linked in this issue above, or analogous resources from a trusted source.  We prefer using links within the  [Python Docs](https://docs.python.org/3/) as the primary go-to, but other resources listed above are also good.  Please try to avoid paid or subscription-based links if possible.

* ### Exercise Metadata Files Under  `.meta/config.json`

  For more information on exercise  `.meta/`  files and formatting, see [concept exercise metadata files](https://github.com/exercism/docs/blob/main/building/tracks/concept-exercises.md#metadata-files)

   * `.meta/config.json` - see [this link](https://github.com/exercism/docs/blob/main/building/tracks/concept-exercises.md#file-metaconfigjson) for the fields and formatting of this file.
   * `.meta/design.md` - see [this link](https://github.com/exercism/docs/blob/main/building/tracks/concept-exercises.md#file-metadesignmd) for the formatting of this file.  Please use the **Goal**, **Learning Objectives**,**Concepts**, **Prerequisites** and , **Out of Scope**  sections  from this issue.

<br>
</td>
</table>
</details>
<br>

## ♾️ Exercise Metadata - Track

For more information on concept exercises and formatting for the Python track `config.json` , please see [`config.json`](https://exercism.org/docs/building/tracks/config-json).  The track `config.json` file can be found in the root of the Python repo.

You can use the below for the exercise **UUID**.  You can also generate a new  one via [exercism configlet](https://github.com/exercism/configlet), [uuidgenerator.net](https://www.uuidgenerator.net/version4), or any other favorite method.  The UUID must be a valid  [**V4 UUID**](https://en.wikipedia.org/wiki/Universally_unique_identifier).

- **Exercise UUID** :  `9f38f70d-48f4-4934-ae6e-d8277ede8edc`
- **concepts** should be filled in from the Concepts section in this issue
- **prerequisites** should be filled in from the Prerequisites section in this issue    

<br>

## 🎶 Implementation Notes

- As a reminder, code in the `.meta/examplar.py` file should **only use syntax & concepts introduced in this exercise or one of its prerequisite exercises.**  We run all our `examplar.py` files through PyLint, but do not strictly require module docstrings.  We **do** require function docstrings similar to [PEP257](https://www.python.org/dev/peps/pep-0257/).  See [this concept exercise `exemplar.py`](https://github.com/exercism/python/blob/main/exercises/concept/meltdown-mitigation/.meta/exemplar.py) for an example.
- Please **do not use** comprehensions, generator expressions, or other syntax not previously covered either in the introduction to this exercise, or to one of its prerequisites.  Please also follow [PEP8](https://www.python.org/dev/peps/pep-0008/) guidelines.
- In General, tests should be written using `unittest.TestCase` and the test file should be named `<EXERCISE-NAME>_test.py`.  

    - All asserts should contain a ""user friendly"" failure message (_these will display on the webiste to students, so be as clear as you can_). 
    - We use a `PyTest custom mark` to link test cases to exercise task numbers.  
    - We also use `unittest.subtest` to parameterize test input where/when needed.
Here is an [example testfile](https://github.com/exercism/python/blob/main/exercises/concept/making-the-grade/loops_test.py) that shows all three of these in action.

- While we do use [PyTest](https://docs.pytest.org/en/stable/) as our test runner and for some implementation tests, please check with a maintainer before using  a PyTest-specific test method, fixture,  or feature.
- Our markdown and JSON files are checked against [prettier](https://prettier.io/) .  We recommend [setting prettier up locally](https://prettier.io/docs/en/install.html) and running it prior to submitting your PR  to avoid any CI errors.

<br>

##  🆘  Next Steps & Getting Help

1.  **`If you'd like to work on this issue, comment saying ""I'd like to work on this""`** (_there is no real need to wait for a response, just go ahead, we'll assign you and put a `[claimed]` label on the issue_).
2. If you have any questions while implementing, please post the questions as comments in here, or contact one of the maintainers on our Slack channel.",True,0,MEMBER
https://api.github.com/repos/exercism/python/issues/comments/1157870239,[New Concept Exercise]:  Functions in Python,BethanyG,13,1273791774,2,1157870239,0,1273791774,2022-06-16T16:21:47Z,"**Comments for discussion ported from original issue:**

@BethanyG  Any idea for what you want to see for the exercise here? Any analogous exercise you might want transcribed from another track? I can start looking at the tracks I'm familiar with. Nothing comes to mind right now.

_Originally posted by @bobahop in https://github.com/exercism/python/issues/2353#issuecomment-1157775990_

-----------

Rust uses lasagna, but we use lasagna for basics. Go uses Booking Up For Beauty, but that also makes significant use of string formatting, so it might not be as focused for functions as desired.

_Originally posted by @bobahop in https://github.com/exercism/python/issues/2353#issuecomment-1157788607_

------------

@bobahop there are a few things to note here:

1.   This issue has very outdated links and descriptions and it also pings the attached users every time we make a comment, so I think its best if we close it in favor of a new issue using the new template.  I will do that shortly.   

2. I have a strong preference for original stories/exercises, unless the port/concept is an almost 1-to-1, as was the case with `bools`.  That **isn't** to say that porting is verboten, but I'd much rather have  a purpose-built exercise than a shoehorned one.  We have had trouble in the past with contributors trying to port something and then getting stalled because they were not able to transfer some core piece to Python.

3.   As I've mentioned, this exercise is quite far ""down"" the exercise tree. It should not be considered an exercise on how to _make_ functions in Python, but rather as a setup to both `higher order functions` and related concepts.  So we should try to think of something that deepens a student's understanding/use of functions, and exercises some of the features unique to Python.  Otherwise, this may as well be a practice exercise or a concept-only topic.

I'll add some thoughts/ideas to the new issue.

_Originally posted by @BethanyG in https://github.com/exercism/python/issues/2353#issuecomment-1157841911_
",False,0,MEMBER
https://api.github.com/repos/exercism/python/issues/comments/1158117445,[New Concept Exercise]:  Functions in Python,BethanyG,13,1273791774,3,1158117445,0,1157870239,2022-06-16T20:51:01Z,"So this wouldn't be a port of the tasks, but if you like the `lasagna` story, [`lasagna master`](https://github.com/exercism/go/tree/main/exercises/concept/lasagna-master/.docs) from **go** could be used and the tasks replaced/adapted/added to.

[Secrets](https://github.com/exercism/elixir/blob/main/exercises/concept/secrets/.docs/instructions.md) on the **Elixir** track looks like it has a good setup, and that the tasks might be adaptable to Python scenarios.  They will probably need a lot of replacing, but could work.

Likewise, [Library Fees](https://github.com/exercism/elixir/blob/main/exercises/concept/library-fees/.docs/instructions.md) could be adapted, but the instructions and introduction to the exercise would have to be amended to cover whatever `datetime` functions or operations were needed for completion.

[New Passport](https://github.com/exercism/elixir/blob/main/exercises/concept/new-passport/.docs/instructions.md) could be adapted, but not to use `with`, because that really really belongs in its own exercise.  However, I think the tasks could be changed to make it about assigning functions to variables, calling functions from other functions, nesting, and scope.  It could also be renamed ""adventures at the DMV"" and made ... dystopian ... where the story is about getting in and getting out of the DMV in the fastest way possible, or avoiding cranky employees by finding and excuse to be in the ""quick processing"" line.

[Pizza Pricing](https://github.com/exercism/fsharp/tree/main/exercises/concept/pizza-pricing/.docs) holds some promise, but again - the tasks would have to be re-done for Python.

Really, you could use just about any story [here](https://exercism.org/docs/building/tracks/stories).  The problematic bit is coming up with 4-6 tasks that cover the concept. 

If sudden purpose-built inspiration strikes, I'll update.",False,0,MEMBER
https://api.github.com/repos/exercism/python/issues/comments/1158129966,[New Concept Exercise]:  Functions in Python,bobahop,13,1273791774,4,1158129966,0,1158117445,2022-06-16T21:05:07Z,"Sound like many promising leads. I'm a bit remiss on researching the tracks, as I'm also slowly slogging through crafting interpreters. Very slowly.",False,0,MEMBER
https://api.github.com/repos/exercism/python/issues/comments/1158131636,[New Concept Exercise]:  Functions in Python,bobahop,13,1273791774,5,1158131636,0,1158129966,2022-06-16T21:07:29Z,I like the dystopian DMV idea... a lot.,False,0,MEMBER
https://api.github.com/repos/exercism/python/issues/comments/1158157712,[New Concept Exercise]:  Functions in Python,BethanyG,13,1273791774,6,1158157712,0,1158131636,2022-06-16T21:35:53Z,"Creating an ""Adventures at the DMV"" story would have the added benefit of carrying a story credit (_and a legendary badge_).  😉

**Inspiration**:  https://www.youtube.com/watch?v=ONFj7AYgbko.  You could even borrow (with credit) the premise from Zootopia - the DMV is populated by Sloths, and any mistake not only sends you to a new line...but then you have to deal with the Sloths. 

Might need some brief background on what DMV stands for, but I think globally most people understand horrible bureaucracy, so it wouldn't take much.

",False,0,MEMBER
https://api.github.com/repos/exercism/python/issues/comments/1158247932,[New Concept Exercise]:  Functions in Python,bobahop,13,1273791774,7,1158247932,0,1158157712,2022-06-16T23:12:14Z,"I think I'll start to work up some files tomorrow. And you're getting author credit, too, since it's your story idea.

What do you think of the title ""Della's Delays at the DMV""?",False,0,MEMBER
https://api.github.com/repos/exercism/python/issues/comments/1158253603,[New Concept Exercise]:  Functions in Python,BethanyG,13,1273791774,8,1158253603,0,1158247932,2022-06-16T23:17:17Z,"""Della's Delays at the DMV""  is _**great**_.  A personal ambition of mine is to have as many alliterative concept exercise titles as possible.",False,0,MEMBER
https://api.github.com/repos/exercism/python/issues/comments/1158917422,[New Concept Exercise]:  Functions in Python,bobahop,13,1273791774,9,1158917422,0,1158253603,2022-06-17T14:17:12Z,I just looked over the learning objectives and concepts and I winced a bit at `global` and `nonlocal`. Is it okay to include them in a way that shows how they can be problematical? Or should we leave them just in the about.md and not give the student experience in them as if they are something encouraged to be done?,False,0,MEMBER
https://api.github.com/repos/exercism/python/issues/comments/1159211461,[New Concept Exercise]:  Functions in Python,BethanyG,13,1273791774,10,1159211461,0,1158917422,2022-06-17T20:36:59Z,"Apologies.  Had some things to take care of this afternoon, so am late with replying to things.

> _I just looked over the learning objectives and concepts and I winced a bit at `global` and `nonlocal.` Is it okay to include them in a way that shows how they can be problematical?_ 

I think for the _exercise_, it's important to provide students the opportunity to practice using both `global` and `nonlocal` in an appropriate or ""safe"" fashion (_heavy guardrails_).  It doesn't have to be elaborate, and it doesn't have to be much more than a basic mimic (_I am thinking of something similar to how we set up [error handling](https://github.com/exercism/python/issues/2563) messaging in a lot of practice exercises_ ). 

And I think for the instructions/introduction, it would be great to put cautions in, and examples of why it can be a bad idea.  Although my thinking here is that if the task or tasks set up a ""proper"" or ""good"" use case, the students will more than likely find the foot-gun, and that will convey a really good lesson, about scope, using the keywords, AND about how the Python ethos is to say _""we are all adults here, so you need to think through your choices, Python's not going to do that for you.""_   

It does seem somewhat ""unfair"" to set up students like that ... but I don't know that we teach them fluency by hiding the warts of the language.  While we do do that to some extent early on, by the time students are getting ready to feed functions to other functions, use recursion, nest functions, and all the other goodness that comes along with FP paradigms in Python, they should have a working sense of caution, and be building a sense of why endless mutability can be problematic.

So my thought is that maybe there is a task that has them reach out and modify/update a `global` constant.  Or _create_ a `global` in a function that other functions could read/access (and modify at peril).  I'm less clear on the `nonlocal`, although that could be done with an inner function -- and would be a quite legitimate (if minority) use-case.

...and thinking out loud here..... I don't know if we want to consider a `mutability` topic, or if we want to (_like we have with error handling_) insert messages and reminders about the dangers of mutability as we build out the exercises in the `functions` and `higher order functions` cluster ... as well as the `classes`, `class-customization`, `class-interfaces` cluster.",False,0,MEMBER
https://api.github.com/repos/exercism/python/issues/comments/1208265684,[New Concept Exercise]:  Functions in Python,BethanyG,13,1273791774,11,1208265684,0,1159211461,2022-08-08T15:18:24Z,"While stale, this issue should remain open.",False,0,MEMBER
https://api.github.com/repos/exercism/python/issues/comments/1233096581,[New Concept Exercise]:  Functions in Python,BethanyG,13,1273791774,12,1233096581,0,1208265684,2022-08-31T15:33:30Z,Arg.  This keeps falling off the radar.  Will do better this week!,False,0,MEMBER
https://api.github.com/repos/exercism/python/issues/comments/1233394001,[New Concept Exercise]:  Functions in Python,bobahop,13,1273791774,13,1233394001,0,1233096581,2022-08-31T20:34:28Z,"I still think it is a good idea, but I am just focused on other things. I also have an idea for a practice exercise, but that is on the back burner as well.",False,0,MEMBER
https://api.github.com/repos/exercism/python/issues/comments/1233408239,[New Concept Exercise]:  Functions in Python,BethanyG,13,1273791774,14,1233408239,0,1233394001,2022-08-31T20:50:54Z,"I won't have time before this weekend I don't think - but I am going to PR turning off the stale bot, since none of us on the track are moving very fast these days (which is OK!).  Right now, if we comment on anything and 22 days pass, the critter wakes up and flags things as abandoned.  It's starting to not be useful, so.  😀 ",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/10919,Feature: Environment variable to trigger `--prefer-lowest`,ciaranmcnulty,4,1292827121,1,1292827121,0,0,2022-07-04T08:37:32Z,"This would be very useful in a CI environment, where currently we are juggling around `COMPOSER_FLAGS` type variables and interpolating them into the CLI
",True,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/1175097335,Feature: Environment variable to trigger `--prefer-lowest`,Seldaek,4,1292827121,2,1175097335,0,1292827121,2022-07-05T14:01:12Z,True :) Should be easy enough to add if you wanna PR.,False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1175098541,Feature: Environment variable to trigger `--prefer-lowest`,ciaranmcnulty,4,1292827121,3,1175098541,0,1175097335,2022-07-05T14:02:13Z,"`Should be easy enough to add if you wanna PR.`

Oh I see how it is 😂 ",False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/1186592921,Feature: Environment variable to trigger `--prefer-lowest`,Seldaek,4,1292827121,4,1186592921,0,1175098541,2022-07-17T19:21:10Z,"I'll try and get to it if nobody else does as I absolutely do see the value, but not sure if it'll make the cut for 2.4 if it comes down to me.",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1186837183,Feature: Environment variable to trigger `--prefer-lowest`,ciaranmcnulty,4,1292827121,5,1186837183,0,1186592921,2022-07-18T07:03:05Z,Same here; if I have time to grok the codebase vs other projects,False,0,NONE
https://api.github.com/repos/composer/composer/issues/10920,Consider disallowed plugin a fatal error,damz,9,1293048520,1,1293048520,0,0,2022-07-04T11:38:11Z,"Since July 1st, [all plugins are now silently disabled](https://github.com/composer/composer/blob/d17c724f2323d16a38c2cbd4cdbb271f0febb1f9/src/Composer/PHPStan/ConfigReturnTypeExtension.php#L173-L176) if `allow-plugins` is not explicitely set in `composer.json`.

Unfortunately in that case, `composer install` still returns success. And in most cases this just results into a completely broken application, because composer plugins are used to install modules in the right place for Drupal, Wordpress, etc.

See #10912 

I suggest we consider a disallowed plugin as a fatal error.

(Unfortunately, this doesn't seem to be breaking any test)",True,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1173739320,Consider disallowed plugin a fatal error,Seldaek,9,1293048520,2,1173739320,0,1293048520,2022-07-04T12:04:42Z,"IMO this should rather be done here throwing instead of simply warning: 

https://github.com/composer/composer/blob/435e0f1aaf1408ccee180b3315daf02e5e3227f1/src/Composer/Plugin/PluginManager.php#L755-L756

So if you are running interactively, you will get prompted, if not it throws. And if you explicitly disable a plugin we don't want to throw either as that's a clear signal, we only want to throw for people without an `allow-plugins` configured.",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1173793323,Consider disallowed plugin a fatal error,damz,9,1293048520,3,1173793323,0,1173739320,2022-07-04T13:00:53Z,"@Seldaek That makes sense, I updated the PR, and confirmed that it works as expected:

```
Installing dependencies from lock file (including require-dev)
Verifying lock file contents can be installed on current platform.
Package operations: 99 installs, 0 updates, 0 removals
  - Installing composer/installers (v1.12.0): Extracting archive
Plugin initialization failed (composer/installers contains a Composer plugin which is blocked by your allow-plugins config. You may add it to the list if you consider it safe. See https://getcomposer.org/allow-plugins), uninstalling plugin
  - Removing composer/installers (v1.12.0)
    Install of composer/installers failed

In PluginManager.php line 759:
                                                                                                                        
  composer/installers contains a Composer plugin which is blocked by your allow-plugins config. You may add it to the   
  list if you consider it safe. See https://getcomposer.org/allow-plugins                                               
      
```",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1174011484,Consider disallowed plugin a fatal error,chx,9,1293048520,4,1174011484,0,1173793323,2022-07-04T17:06:51Z,"The solution is to version composer.json 

Old versions behave as if `composer config allow-plugins true -n` were run.

New versions get security hardened. `composer create-project` creates such.

I believe currently composer.json is not versioned, a default takes easy care of that. 

This allows future such changes not to break everyone's builds silently on a long weekend , one of the largest holidays in the United States...",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1174233597,Consider disallowed plugin a fatal error,Seldaek,9,1293048520,5,1174233597,0,1174011484,2022-07-04T20:04:46Z,"The versioning is a good point and a good idea. The composer.lock has some notion of version thanks to the composer-plugin-api being stored in there.

So I think what I'll add to this PR tomorrow (feel free to leave as is @damz) is that if the lock file predates Composer 2.2, it will keep the warning and default to `true` (during **installs**), and for all **updates** or **installs with 2.2+ lock** we keep the current PR throwing hard.

I absolutely see the point that if you haven't run any Composer update in the last 6 months and suddenly an install with a newer Composer fails this is not great. The timing for the US is unfortunate, but we planned/coded this late last year (probably around Thanksgiving..) and July 1st seemed like a decent far away date without much special context to it to me.

I hope this soften the blow even further, unfortunately we cannot fix any existing version out there but it should at least reduce problem for things running automated on the latest version.

Regarding BC in general, I believe we do have a pretty decent track record of BC keeping. Heck Composer 2.2 still supports PHP 5.3 after 11 years and even Composer 2.0 did not break all that much for most users. But note that if you want to version your composer.json and play it extra safe you can require [`composer`](https://getcomposer.org/doc/articles/composer-platform-dependencies.md#composer-package-composer) nowadays. Please don't do it in libraries ever tho, but for private projects why not I suppose, it may cause some pain but it is more explicit.",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1174463713,Consider disallowed plugin a fatal error,chx,9,1293048520,6,1174463713,0,1174233597,2022-07-04T23:52:06Z,"> I absolutely see the point that if you haven't run any Composer update in the last 6 months

composer 2.2 was released on 2021-12-22 you gave us _six months_ for the composer upgrade while not having any reason whatsoever to upgrade it. My local simply wasn't, the version my provider runs was.

This was all the worse because the time bomb was _hidden_ and the plugin warnings did not include any warnings that by July it will break so the community wasn't abuzz with warnings.",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1174764857,Consider disallowed plugin a fatal error,Seldaek,9,1293048520,7,1174764857,0,1174463713,2022-07-05T08:22:48Z,"> composer 2.2 was released on 2021-12-22 you gave us _six months_ for the composer upgrade while not having any reason whatsoever to upgrade it. My local simply wasn't, the version my provider runs was.

Yes, as I wrote above versioning could have helped and will help once I implement it, but I guess I now have to _argue with someone on the internet_ ™️ first, as somehow the plan above does not seem to be good enough and you had to go on a rant. 

There was 6 months to upgrade, and IMO plenty of reasons (see https://blog.packagist.com/composer-2-2/ and https://blog.packagist.com/composer-2-3/) to upgrade. If new features and huge perf boosts aren't enough motivation for you to upgrade, we also fixed a CVE back in April in https://github.com/composer/composer/releases/tag/2.2.12. Generally speaking upgrading software regularly is a good idea, and if you don't do it regularly you are bound to run into issues when doing huge version jumps.

> This was all the worse because the time bomb was _hidden_ and the plugin warnings did not include any warnings that by July it will break so the community wasn't abuzz with warnings.

That is just plain wrong. You must have had warnings printed out in every Composer run on your hosting provider: 

https://github.com/composer/composer/blob/c422fefda4f2bf4a911041683b7fcbba228c38c6/src/Composer/Plugin/PluginManager.php#L688-L692

This printed out:

**You have until July 2022 to add the setting. Composer will then switch the default behavior to disallow all plugins.**

If that isn't a clear enough warning, with a date, I don't know what is.

The problem is that some people never read warnings, and never act on them, so eventually we have to break things anyway, no matter how long we wait someone will always act surprised and come ranting.
",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1175106258,Consider disallowed plugin a fatal error,damz,9,1293048520,8,1175106258,0,1174764857,2022-07-05T14:09:22Z,"@Seldaek What is the behavior of this when there is no `composer.lock`?

It is unfortunate, but despite our best efforts, I am quite sure that a non-insignificant number of our customers do not have a `composer.lock` committed to their repository.",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1175147334,Consider disallowed plugin a fatal error,Seldaek,9,1293048520,9,1175147334,0,1175106258,2022-07-05T14:45:25Z,"It silently allows plugins only if there is a lock file and that lock file has a composer-plugin-api < 2.2 (or no composer-plugin-api defined, which could be the case).

So if there is no lock file or a ""modern"" lock file it throws:

<img width=""374"" alt=""image"" src=""https://user-images.githubusercontent.com/183678/177355015-d6806101-e051-41b3-a013-96599685c975.png"">
",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1175148456,Consider disallowed plugin a fatal error,Seldaek,9,1293048520,10,1175148456,0,1175147334,2022-07-05T14:46:21Z,"Note that I also made it throw very early in the prepare step so that it should hopefully throw before touching the vendor dir at all, avoiding a partially-updated vendor dir (tho for platform.sh I doubt this matters as it's always a new fresh dir I assume).",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/10923,Should I commit the dependencies in my vendor directory?,chx,7,1293648893,1,1293648893,0,0,2022-07-05T00:16:27Z,"https://getcomposer.org/doc/faqs/should-i-commit-the-dependencies-in-my-vendor-directory.md is misleading and as shown in the recent plugin catastrophe leads to broken builds.

Let's go step by step:

> The best practice is to then have all the developers use Composer to install the dependencies.

This has multiple problems: a) everyone on the team now needs to have and use Composer. That's very often unnecessary if this guidance is not followed b) it's slower than git. This is not to diss on Composer, it has made great improvement in speed but beating git is beyond what any PHP script can possibly do. 

> Similarly, the build server, CI, deployment tools etc should be adapted to run Composer as part of their project bootstrapping.

This can break the build when a) one of the repositories being pulled from is unresponsive b) one of the repositories being pulled from has a malicious attack aka supply chain attack c) composer itself breaks (let's hope this one doesn't happen again any time soon).

> Large VCS repository size and diffs when you update code.

1. Size? Disk space is, by and large, free. Derived from Jim Gray's seminal 2006 (!) presentation title, the rule of thumb for long has been ""Disk is the new tape"". Most of composer managed files are _text_ anyways. 
2. Diff: git has added pathspec magic `:(exclude)` and its short form `:!` in 2014, so excluding `vendor` from diff is trivial. And you actually might need to diff vendor code -- what if the bug you are currently working on is actually in vendor or it's an interaction with vendor code? It's not magic, it's just software. It has bugs. (Sometimes, it's _my_ code hiding in _your_ `vendor`. Of course it has bugs.)

> Duplication of the history of all your dependencies in your own VCS.

This is again at best a half truth: only the tags/releases you are actually using will be duplicated. Not every commit, not every branch.

> Adding dependencies installed via git to a git repo will show them as submodules. This is problematic because they are not real submodules, and you will run into issues.

Yeah, just remove `.git` after composer runs. Next time composer runs -- which will be infrequent anyways after this -- it will just clone from git anew. To quote my own `composer.json`:

    ""scripts"": {
        ""remove-git-submodules"": ""find vendor -type d -name .git | xargs rm -rf"",

",True,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1175172286,Should I commit the dependencies in my vendor directory?,Seldaek,7,1293648893,2,1175172286,0,1293648893,2022-07-05T15:08:06Z,"> it's slower than git

Yes and no, once your repo is 5GB worth of vendor dir diffs, cloning it isn't going to be fast.

Try a git clone https://github.com/phpstan/phpstan to see what I mean.

> Next time composer runs -- which will be infrequent anyways after this

I think you should probably run composer updates more often than you seem to be doing.

----

The rest is mostly opinions, you disagree with our recommendations, feel free to do it your way.",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1175208248,Should I commit the dependencies in my vendor directory?,stof,7,1293648893,3,1175208248,0,1175172286,2022-07-05T15:42:09Z,"> 2\. what if the bug you are currently working on is actually in vendor or it's an interaction with vendor code?

In that case, you should probably not edit the code in `vendor` to fix the bug (otherwise, you'll loose the bugfix the next time you run composer).
And if you fix the bug by updating to a newer version with Composer, the composer.lock file will also be modified (and this one will appear in the git diff)",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1177086813,Should I commit the dependencies in my vendor directory?,chx,7,1293648893,4,1177086813,0,1175208248,2022-07-07T05:22:16Z,"I needed to think quite a bit here and now I see clearly the problem is quite big: we have a very different world view.

Mine is bitter and pessimistic: software upgrades are a problem. You want to do them sparingly because any time you upgrade software it might introduce bugs and more regression testing is needed. Why change what's not broken? 

The worldview of Composer is a cheery one. Semver makes software upgrades harmless. No problem with upgrades. This worldview is well visible from the fact that anything you do with composer will do a sort of ""maximum run"" where just touching a single package will upgrade quite a few others. 

Because of this, your vendor directory changes often where mine does not. 

Perhaps two documentation pages here reflecting these world views would be better -- and also, perhaps some command line switches to composer as well to restrict it to a minimal run?",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1177288359,Should I commit the dependencies in my vendor directory?,stof,7,1293648893,5,1177288359,0,1177086813,2022-07-07T09:08:55Z,"`composer require` locks all existing packages by default. And `composer update` allows to update a few packages if you want instead of doing a full update. So those ""minimal run"" are still possible.

But all this can still work by committing only the lock file rather than the whole vendor directory.",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1178338812,Should I commit the dependencies in my vendor directory?,chx,7,1293648893,6,1178338812,0,1177288359,2022-07-07T22:52:59Z,"I use `composer require`, of course, in fact, I never use `composer update` itself exactly because of this, however that only works in the simplest of case: when there are no dependencies needed to be updated. The moment you do need to update, you do not really have any options afaik because `composer require -W` will do a maximal and there's no ""install this package, fix dependencies if needed and stop"" option.

This is an aside from my proposal to amend the documentation. ",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1178354030,Should I commit the dependencies in my vendor directory?,ksenzee,7,1293648893,7,1178354030,0,1178338812,2022-07-07T23:11:17Z,"I have always felt the documentation is doing newcomers a disservice by keeping it a secret that many people do commit their vendor directory by choice. Shouldn't the documentation reflect the reality of how people are using composer? In my case, I'm using a hosting service where if I want to change a line of code on my production server, I have to build a new version of my containers. If that build includes a composer step, I've tied my ability to hotfix production to whether or not github is up. The easiest way to work around that is to commit my vendor directory. Yes, there are other ways around it, but they're clunky in comparison to simply _keeping all my code in the repo_. That is not an unreasonable choice. The documentation doesn't even acknowledge that it's possible, much less that it might be the right choice for some situations.",False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/1183282490,Should I commit the dependencies in my vendor directory?,Seldaek,7,1293648893,8,1183282490,0,1178354030,2022-07-13T14:15:51Z,"> Mine is bitter and pessimistic: software upgrades are a problem. You want to do them sparingly because any time you upgrade software it might introduce bugs and more regression testing is needed. Why change what's not broken?

The issue with this worldview IMO is that it will bite you in the ass in the long run. You end up doing bigger upgrades of more dependencies at once, so if something breaks you don't know where to start looking.

Doing frequent updates requires less jumping through hoops, and yes it carries a more frequent risk of something minor going wrong, but at least you'll be able to quickly revert that and analyze. With bigger updates it's not always possible to go back smoothly.

So I disagree this world view is beneficial, and I don't want to encourage anyone to go there.

> I use `composer require`, of course, in fact, I never use `composer update` itself exactly because of this, however that only works in the simplest of case: when there are no dependencies needed to be updated.

I hardly use `require` except to add new dependencies. If I want to update some, I run `composer update x y vendor/*`, eventually with `-w` or `-W` if needed but I rarely resort to that. That gives fine-grained control.

If you use `-W` then yes you are telling Composer to update all the things that package depends on, there is no way to just ""fix dependencies if needed and stop"", unfortunately that is a much more complex problem than unlocking dependencies and letting the solver find a workable solution. We could try to unlock one by one until it works, but that's not guaranteed to give you the solution you want either, and it'd require a multi-pass solving which adds a lot of complexity and CPU time for a case which I don't see as super needed considering running updated deps is generally a good thing. Plus if you absolutely need an older dep of something then you can require that explicitly (or conflict against new versions) to avoid updates.

----

@ksenzee I think https://getcomposer.org/doc/faqs/should-i-commit-the-dependencies-in-my-vendor-directory.md kinda acknolwedges that it's possible. I still don't think it's a good idea, and have never felt the need to do so, so I'd rather not encourage it any further, sorry.",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/10925,non-specified plugin throws error with --no-plugins,jrushlow,8,1294493886,1,1294493886,0,0,2022-07-05T16:05:20Z,"<!--
The information we ask for below is IMPORTANT. It will help us help you faster.
Please FOLLOW THE ISSUE TEMPLATE unless you have a good reason not to, and help avoid wasting everyone's time.

Please also make sure you are using the latest Composer version. You can get the latest with `composer self-update`
or even try the latest dev build with `composer self-update --snapshot` to see if the bug was perhaps already fixed but not released yet.
-->

My `composer.json`:

```json
{
    ""description"": ""Symfony Maker helps you create empty commands, controllers, form classes, tests and more so you can forget about writing boilerplate code."",
    ""homepage"": ""https://symfony.com/doc/current/bundles/SymfonyMakerBundle/index.html"",
    ""name"": ""symfony/maker-bundle"",
    ""type"": ""symfony-bundle"",
    ""license"": ""MIT"",
    ""keywords"": [""generator"", ""code generator"", ""scaffolding"", ""scaffold""],
    ""authors"": [
        {
            ""name"": ""Symfony Community"",
            ""homepage"": ""https://symfony.com/contributors""
        }
    ],
    ""minimum-stability"": ""dev"",
    ""require"": {
        ""php"": "">=8.0"",
        ""doctrine/inflector"": ""^2.0"",
        ""nikic/php-parser"": ""^4.11"",
        ""symfony/config"": ""^5.4.7|^6.0"",
        ""symfony/console"": ""^5.4.7|^6.0"",
        ""symfony/dependency-injection"": ""^5.4.7|^6.0"",
        ""symfony/deprecation-contracts"": ""^2.2|^3"",
        ""symfony/filesystem"": ""^5.4.7|^6.0"",
        ""symfony/finder"": ""^5.4.3|^6.0"",
        ""symfony/framework-bundle"": ""^5.4.7|^6.0"",
        ""symfony/http-kernel"": ""^5.4.7|^6.0""
    },
    ""require-dev"": {
        ""composer/semver"": ""^3.0"",
        ""doctrine/doctrine-bundle"": ""^2.4"",
        ""doctrine/orm"": ""^2.10.0"",
        ""symfony/http-client"": ""^5.4.7|^6.0"",
        ""symfony/phpunit-bridge"": ""^5.4.7|^6.0"",
        ""symfony/polyfill-php80"": ""^1.16.0"",
        ""symfony/process"": ""^5.4.7|^6.0"",
        ""symfony/security-core"": ""^5.4.7|^6.0"",
        ""symfony/yaml"": ""^5.4.3|^6.0"",
        ""twig/twig"": ""^2.0|^3.0""
    },
    ""config"": {
        ""preferred-install"": ""dist"",
        ""sort-packages"": true
    },
    ""conflict"": {
        ""doctrine/orm"": ""<2.10"",
        ""doctrine/doctrine-bundle"": ""<2.4"",
        ""symfony/doctrine-bridge"": ""<5.4""
    },
    ""autoload"": {
        ""psr-4"": { ""Symfony\\Bundle\\MakerBundle\\"": ""src/"" }
    },
    ""autoload-dev"": {
        ""psr-4"": { ""Symfony\\Bundle\\MakerBundle\\Tests\\"": ""tests/"" }
    },
    ""extra"": {
        ""branch-alias"": {
            ""dev-main"": ""1.0-dev""
        }
    }
}
```

Output of `composer diagnose`:

Running on GH Actions (No pub key)
```
Checking composer.json: OK
Checking platform settings: OK
Checking git settings: OK
Checking http connectivity to packagist: OK
Checking https connectivity to packagist: OK
Checking github.com rate limit: OK
Checking disk free space: OK
Checking pubkeys: FAIL
Missing pubkey for tags verification
Missing pubkey for dev verification
Run composer self-update --update-keys to set them up
Checking composer version: OK
Composer version: 2.3.9
PHP version: 8.1.7
PHP binary path: /usr/bin/php8.1
OpenSSL version: OpenSSL 1.1.1  11 Sep 2018
cURL version: 7.58.0 libz 1.2.11 ssl OpenSSL/1.1.1
zip: extension present, unzip present, 7-Zip present (7z)
```

When I run this command: <!-- run it with `-vvv` added to it ideally to get full debug output -->

```
composer global require --no-progress --no-scripts --no-plugins symfony/flex
```

I get the following output: <!-- FULL OUTPUT please, not just what you think is relevant -->

```
Run composer global require --no-progress --no-scripts --no-plugins symfony/flex -vvv
Changed current directory to /home/runner/.composer
Running 2.3.9 (2022-07-05 16:52:11) with PHP 8.1.7 on Linux / 5.4.0-1085-azure
Reading ./composer.json (/home/runner/.composer/composer.json)
Loading config file ./composer.json (/home/runner/.composer/composer.json)
Checked CA file /etc/pki/tls/certs/ca-bundle.crt does not exist or it is not a file.
Checked directory /etc/pki/tls/certs/ca-bundle.crt does not exist or it is not a directory.
Checked CA file /etc/ssl/certs/ca-certificates.crt: valid
Executing command (/home/runner/.composer): 'git' 'branch' '-a' '--no-color' '--no-abbrev' '-v'
Executing command (/home/runner/.composer): git describe --exact-match --tags
Executing command (CWD): git --version
Executing command (/home/runner/.composer): git log --pretty=""%H"" -n1 HEAD --no-show-signature
Executing command (/home/runner/.composer): hg branch
Executing command (/home/runner/.composer): fossil branch list
Executing command (/home/runner/.composer): fossil tag list
Executing command (/home/runner/.composer): svn info --xml
Downloading https://repo.packagist.org/packages.json
[200] https://repo.packagist.org/packages.json
Info from https://repo.packagist.org: #StandWithUkraine
Writing /home/runner/.cache/composer/repo/https---repo.packagist.org/packages.json into cache
Downloading https://repo.packagist.org/p2/symfony/flex.json
[200] https://repo.packagist.org/p2/symfony/flex.json
Writing /home/runner/.cache/composer/repo/https---repo.packagist.org/provider-symfony~flex.json into cache
Using version ^2.2 for symfony/flex
./composer.json has been updated
Reading ./composer.json (/home/runner/.composer/composer.json)
Loading config file ./composer.json (/home/runner/.composer/composer.json)
Executing command (/home/runner/.composer): 'git' 'branch' '-a' '--no-color' '--no-abbrev' '-v'
Executing command (/home/runner/.composer): git describe --exact-match --tags
Executing command (/home/runner/.composer): git log --pretty=""%H"" -n1 HEAD --no-show-signature
Executing command (/home/runner/.composer): hg branch
Executing command (/home/runner/.composer): fossil branch list
Executing command (/home/runner/.composer): fossil tag list
Executing command (/home/runner/.composer): svn info --xml
Running composer update symfony/flex
Loading composer repositories with package information
Reading /home/runner/.cache/composer/repo/https---repo.packagist.org/packages.json from cache
Downloading https://repo.packagist.org/packages.json if modified
[304] https://repo.packagist.org/packages.json
Reading /home/runner/.cache/composer/repo/https---repo.packagist.org/provider-symfony~flex.json from cache
Downloading https://repo.packagist.org/p2/symfony/flex.json if modified
[304] https://repo.packagist.org/p2/symfony/flex.json
Built pool.
Running pool optimizer.
Pool optimizer completed in 0.001 seconds
Updating dependencies
Found 122 package versions referenced in your dependency graph. 2 (2%) were optimized away.
Generating rules
Resolving dependencies through SAT
Looking at all rules.
Dependency resolution completed in 0.000 seconds
Analyzed 120 packages to resolve dependencies
Analyzed 122 rules to resolve dependencies
Lock file operations: 1 install, 0 updates, 0 removals
Installs: symfony/flex:v2.2.2
  - Locking symfony/flex (v2.2.2)
Writing lock file
Installing dependencies from lock file (including require-dev)
Reading ./composer.lock (/home/runner/.composer/composer.lock)
Package operations: 1 install, 0 updates, 0 removals
Installs: symfony/flex:v2.2.2
  - Downloading symfony/flex (v2.2.2)
Downloading https://api.github.com/repos/symfony/flex/zipball/78510b1be591433513c8087deec24e9fd90d110d
[302] https://api.github.com/repos/symfony/flex/zipball/78510b1be591433513c8087deec24e9fd90d110d
Following redirect (1) https://codeload.github.com/symfony/flex/legacy.zip/78510b1be591433513c8087deec24e9fd90d110d
[200] https://codeload.github.com/symfony/flex/legacy.zip/78510b1be591433513c8087deec24e9fd90d110d
Writing /home/runner/.cache/composer/files/symfony/flex/a872a30e2334091ca412d735d0051cd3d480a576.zip into cache from /home/runner/.composer/vendor/composer/tmp-71acc520221622b1de876f8a95cb5bc6
Error: symfony/flex contains a Composer plugin which is blocked by your allow-plugins config. You may add it to the list if you consider it safe.
You can run ""composer config --no-plugins allow-plugins.symfony/flex [true|false]"" to enable it (true) or disable it explicitly and suppress this exception (false)
See https://getcomposer.org/allow-plugins
In PluginManager.php line 762:
  [UnexpectedValueException]                                                   
  symfony/flex contains a Composer plugin which is blocked by your allow-plug  
  ins config. You may add it to the list if you consider it safe.              
  You can run ""composer config --no-plugins allow-plugins.symfony/flex [true|  
  false]"" to enable it (true) or disable it explicitly and suppress this exce  
  ption (false)                                                                
  See https://getcomposer.org/allow-plugins
Exception trace:
  at phar:///usr/local/bin/composer/src/Composer/Plugin/PluginManager.php:762
 Composer\Plugin\PluginManager->isPluginAllowed() at phar:///usr/local/bin/composer/src/Composer/Installer/PluginInstaller.php:53
 Composer\Installer\PluginInstaller->prepare() at phar:///usr/local/bin/composer/src/Composer/Installer/InstallationManager.php:446
 Composer\Installer\InstallationManager->executeBatch() at phar:///usr/local/bin/composer/src/Composer/Installer/InstallationManager.php:390
 Composer\Installer\InstallationManager->downloadAndExecuteBatch() at phar:///usr/local/bin/composer/src/Composer/Installer/InstallationManager.php:282
 Composer\Installer\InstallationManager->execute() at phar:///usr/local/bin/composer/src/Composer/Installer.php:763
 Composer\Installer->doInstall() at phar:///usr/local/bin/composer/src/Composer/Installer.php:590
 Composer\Installer->doUpdate() at phar:///usr/local/bin/composer/src/Composer/Installer.php:279
 Composer\Installer->run() at phar:///usr/local/bin/composer/src/Composer/Command/RequireCommand.php:425
 Composer\Command\RequireCommand->doUpdate() at phar:///usr/local/bin/composer/src/Composer/Command/RequireCommand.php:288
 Composer\Command\RequireCommand->execute() at phar:///usr/local/bin/composer/vendor/symfony/console/Command/Command.php:298
 Symfony\Component\Console\Command\Command->run() at phar:///usr/local/bin/composer/vendor/symfony/console/Application.php:1024
 Symfony\Component\Console\Application->doRunCommand() at phar:///usr/local/bin/composer/vendor/symfony/console/Application.php:299
 Symfony\Component\Console\Application->doRun() at phar:///usr/local/bin/composer/src/Composer/Console/Application.php:335
 Composer\Console\Application->doRun() at phar:///usr/local/bin/composer/vendor/symfony/console/Application.php:171
 Symfony\Component\Console\Application->run() at phar:///usr/local/bin/composer/src/Composer/Console/Application.php:130
 Composer\Console\Application->run() at phar:///usr/local/bin/composer/src/Composer/Command/GlobalCommand.php:118
 Composer\Command\GlobalCommand->run() at phar:///usr/local/bin/composer/vendor/symfony/console/Application.php:1024
 Symfony\Component\Console\Application->doRunCommand() at phar:///usr/local/bin/composer/vendor/symfony/console/Application.php:299
 Symfony\Component\Console\Application->doRun() at phar:///usr/local/bin/composer/src/Composer/Console/Application.php:335
 Composer\Console\Application->doRun() at phar:///usr/local/bin/composer/vendor/symfony/console/Application.php:171
 Symfony\Component\Console\Application->run() at phar:///usr/local/bin/composer/src/Composer/Console/Application.php:130
 Composer\Console\Application->run() at phar:///usr/local/bin/composer/bin/composer:88
 require() at /usr/local/bin/composer:29
require [--dev] [--dry-run] [--prefer-source] [--prefer-dist] [--prefer-install PREFER-INSTALL] [--fixed] [--no-suggest] [--no-progress] [--no-update] [--no-install] [--update-no-dev] [-w|--update-with-dependencies] [-W|--update-with-all-dependencies] [--with-dependencies] [--with-all-dependencies] [--ignore-platform-req IGNORE-PLATFORM-REQ] [--ignore-platform-reqs] [--prefer-stable] [--prefer-lowest] [--sort-packages] [-o|--optimize-autoloader] [-a|--classmap-authoritative] [--apcu-autoloader] [--apcu-autoloader-prefix APCU-AUTOLOADER-PREFIX] [--] [<packages>...]
Error: Process completed with exit code 1.
```

And I expected this to happen:

Shouldn't the usage of `--no-plugins` negate any potential errors w/ allowed/disallowed plugins? E.g. no error should be thrown in this particular case.

For ref https://getcomposer.org/doc/articles/plugins.md#using-plugins",True,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/1175235121,non-specified plugin throws error with --no-plugins,stof,8,1294493886,2,1175235121,0,1294493886,2022-07-05T16:09:18Z,"Note that in your case, you will still need to run the command to configure it as allowed or forbidden, unless you also run each following command with `no-plugins` (assuming your proposal is implemented). There is no point installing a composer plugin globally if you don't intend to use it.",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1175263091,non-specified plugin throws error with --no-plugins,jrushlow,8,1294493886,3,1175263091,0,1175235121,2022-07-05T16:38:20Z,"In our particular use case, we need to install `symfony/flex` globally (main thread) so later when we run individual tests (run in child threads) - `flex` is available. 

MakerBundle doesn't lean on `flex` directly, each test case is an ""isolated"" symfony application which require flex.. 

Side note - running `composer global config --no-plugins allow-plugins.symfony/flex false` _before_ `composer global require --no-progress --no-scripts --no-plugins symfony/flex` fixes the issue. I guess I'm confused as to the purpose of the `--no-plugins` flag. I could be totally wrong in my understanding, but I thought when you passed `--no-plugins` w/ a composer command, composer was essentially saying ""ok, we'll run the command but will not load any of the plug-ins associated w/ that command..."" which is why I'm questioning why an error is thrown if a plugin is not explicitly allowed && `--no-plugins` is passed.",False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/1175265791,non-specified plugin throws error with --no-plugins,stof,8,1294493886,4,1175265791,0,1175263091,2022-07-05T16:41:23Z,"Well, disabling the check if `--no-plugins` is passed could indeed make sense (but maybe not, if you install a plugin ?).
But in your case, you would still need to configure the plugin as allowed, otherwise you'll get the exception on the next command you run (which might even be the `composer global config` one if you run it without `--no-plugins`)",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1175462691,non-specified plugin throws error with --no-plugins,Seldaek,8,1294493886,5,1175462691,0,1175265791,2022-07-05T20:20:20Z,This was definitely a mistake I made earlier in #10920,False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1175464372,non-specified plugin throws error with --no-plugins,Seldaek,8,1294493886,6,1175464372,0,1175462691,2022-07-05T20:22:32Z,Would be nice if you can confirm it works as you'd expect now with `composer self-update --snapshot` ,False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1175466377,non-specified plugin throws error with --no-plugins,Seldaek,8,1294493886,7,1175466377,0,1175464372,2022-07-05T20:25:25Z,"Note that it won't fix the need to configure allow-plugins to run flex, but it should at least allow runs with --no-plugins to go through.",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1175478913,non-specified plugin throws error with --no-plugins,jrushlow,8,1294493886,8,1175478913,0,1175466377,2022-07-05T20:42:02Z,"> Would be nice if you can confirm it works as you'd expect now with `composer self-update --snapshot` 

I'll run a test against the snapshot in a few hours and let you know the outcome. Thanks!",False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/1175884842,non-specified plugin throws error with --no-plugins,jrushlow,8,1294493886,9,1175884842,0,1175478913,2022-07-06T07:35:42Z,@Seldaek I can confirm the patch works as expected. Thanks again!,False,0,NONE
https://api.github.com/repos/elebumm/RedditVideoMakerBot/issues/947,UnicodeEncodeError: 'charmap' codec can't encode character,ass-warrior,6,1300321709,1,1300321709,0,0,2022-07-11T07:31:14Z,"so basically every time i run the bot it gives me this error

Traceback (most recent call last):
  File ""C:\Users\User\RedditVideoMakerBot\main.py"", line 61, in <module>
    main()
  File ""C:\Users\User\RedditVideoMakerBot\main.py"", line 27, in main
    reddit_object = get_subreddit_threads(POST_ID)
  File ""C:\Users\User\RedditVideoMakerBot\reddit\subreddit.py"", line 77, in get_subreddit_threads
    print_substep(f""Video will be: {submission.title} :thumbsup:"", style=""bold green"")
  File ""C:\Users\User\RedditVideoMakerBot\utils\console.py"", line 29, in print_substep
    console.print(text, style=style)
  File ""C:\Users\User\AppData\Local\Programs\Python\Python310\lib\site-packages\rich\console.py"", line 1635, in print
    with self:
  File ""C:\Users\User\AppData\Local\Programs\Python\Python310\lib\site-packages\rich\console.py"", line 838, in __exit__
    self._exit_buffer()
  File ""C:\Users\User\AppData\Local\Programs\Python\Python310\lib\site-packages\rich\console.py"", line 796, in _exit_buffer
    self._check_buffer()
  File ""C:\Users\User\AppData\Local\Programs\Python\Python310\lib\site-packages\rich\console.py"", line 1988, in _check_buffer
    legacy_windows_render(
  File ""C:\Users\User\AppData\Local\Programs\Python\Python310\lib\site-packages\rich\_windows_renderer.py"", line 17, in legacy_windows_render
    term.write_styled(text, style)
  File ""C:\Users\User\AppData\Local\Programs\Python\Python310\lib\site-packages\rich\_win32_console.py"", line 418, in write_styled
    self.write_text(text)
  File ""C:\Users\User\AppData\Local\Programs\Python\Python310\lib\site-packages\rich\_win32_console.py"", line 379, in write_text
    self.write(text)
  File ""C:\Users\User\AppData\Local\Programs\Python\Python310\lib\encodings\cp1252.py"", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode character '\U0001f44d' in position 74: character maps to <undefined>

- Python Version: python 3.10
- OS: windows 10
- App version master
",True,0,NONE
https://api.github.com/repos/elebumm/RedditVideoMakerBot/issues/comments/1180197774,UnicodeEncodeError: 'charmap' codec can't encode character,William9923,6,1300321709,2,1180197774,0,1300321709,2022-07-11T09:57:32Z,"hi, could we see the POST_ID value? (in the .env file)",False,0,COLLABORATOR
https://api.github.com/repos/elebumm/RedditVideoMakerBot/issues/comments/1180316806,UnicodeEncodeError: 'charmap' codec can't encode character,ass-warrior,6,1300321709,3,1180316806,0,1180197774,2022-07-11T11:53:53Z,"POST_ID=""""
i mean it said to put something if you want a specific post so i left it blank
",False,0,NONE
https://api.github.com/repos/elebumm/RedditVideoMakerBot/issues/comments/1180433401,UnicodeEncodeError: 'charmap' codec can't encode character,Anthony-Lloyd,6,1300321709,4,1180433401,0,1180316806,2022-07-11T13:48:41Z,"> POST_ID="""" i mean it said to put something if you want a specific post so i left it blank

he's asking for the specific post which produced this bug, for example. it could be set to random, but he wants to know the post that the program was running which resulted in the error you're experiencing",False,0,NONE
https://api.github.com/repos/elebumm/RedditVideoMakerBot/issues/comments/1181291949,UnicodeEncodeError: 'charmap' codec can't encode character,William9923,6,1300321709,5,1181291949,0,1180433401,2022-07-12T04:10:46Z,i think this issue happens on specific Reddit Title Video (edge case). If you happen to still save the Reddit post it would be great,False,0,COLLABORATOR
https://api.github.com/repos/elebumm/RedditVideoMakerBot/issues/comments/1181373253,UnicodeEncodeError: 'charmap' codec can't encode character,ass-warrior,6,1300321709,6,1181373253,0,1181291949,2022-07-12T06:36:31Z,unfortunately i dont but this happens every time i try to run the bot reguardless of the post that gets chosen,False,0,NONE
https://api.github.com/repos/elebumm/RedditVideoMakerBot/issues/comments/1182648262,UnicodeEncodeError: 'charmap' codec can't encode character,JasonLovesDoggo,6,1300321709,7,1182648262,0,1181373253,2022-07-13T01:03:52Z,use 2.3 ,False,0,COLLABORATOR
https://api.github.com/repos/elebumm/RedditVideoMakerBot/issues/949,not downloading / starting process,Minty569,3,1300528332,1,1300528332,0,0,2022-07-11T10:42:09Z,"when I run python main.py it runs code but never gives any errors or the vide
![Capture1](https://user-images.githubusercontent.com/106637473/178247127-3c855b7f-d2e1-4768-95aa-539a93571b39.PNG)
![Capture2](https://user-images.githubusercontent.com/106637473/178247133-d4ac6a71-9232-4da0-84a7-345e15bc25f6.PNG)
o",True,0,NONE
https://api.github.com/repos/elebumm/RedditVideoMakerBot/issues/comments/1180431697,not downloading / starting process,Anthony-Lloyd,3,1300528332,2,1180431697,0,1300528332,2022-07-11T13:47:13Z,have you setup your reddit api app,False,0,NONE
https://api.github.com/repos/elebumm/RedditVideoMakerBot/issues/comments/1181088700,not downloading / starting process,PersonHalf,3,1300528332,3,1181088700,0,1180431697,2022-07-11T23:36:29Z,"> have you setup your reddit api app

diff account but yes the reddit API was done",False,0,NONE
https://api.github.com/repos/elebumm/RedditVideoMakerBot/issues/comments/1181293216,not downloading / starting process,William9923,3,1300528332,4,1181293216,0,1181088700,2022-07-12T04:13:25Z,"I think this happen due to invalid credential. Please double check your credential (username, password, reddit_client_secret, etc). Feel free to open it again if issue persist",False,0,COLLABORATOR
https://api.github.com/repos/elebumm/RedditVideoMakerBot/issues/950,Bump botocore from 1.27.24 to 1.27.26,dependabot[bot],3,1300542090,1,1300542090,0,0,2022-07-11T10:55:53Z,"Bumps [botocore](https://github.com/boto/botocore) from 1.27.24 to 1.27.26.
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/boto/botocore/blob/develop/CHANGELOG.rst"">botocore's changelog</a>.</em></p>
<blockquote>
<h1>1.27.26</h1>
<ul>
<li>api-change:<code>backup</code>: This release adds support for authentication using IAM user identity instead of passed IAM role, identified by excluding the IamRoleArn field in the StartRestoreJob API. This feature applies to only resource clients with a destructive restore nature (e.g. SAP HANA).</li>
</ul>
<h1>1.27.25</h1>
<ul>
<li>api-change:<code>chime-sdk-meetings</code>: Adds support for AppKeys and TenantIds in Amazon Chime SDK WebRTC sessions</li>
<li>api-change:<code>dms</code>: New api to migrate event subscriptions to event bridge rules</li>
<li>api-change:<code>iot</code>: This release adds support to register a CA certificate without having to provide a verification certificate. This also allows multiple AWS accounts to register the same CA in the same region.</li>
<li>api-change:<code>iotwireless</code>: Adds 5 APIs: PutPositionConfiguration, GetPositionConfiguration, ListPositionConfigurations, UpdatePosition, GetPosition for the new Positioning Service feature which enables customers to configure solvers to calculate position of LoRaWAN devices, or specify position of LoRaWAN devices &amp; gateways.</li>
<li>api-change:<code>sagemaker</code>: Heterogeneous clusters: the ability to launch training jobs with multiple instance types. This enables running component of the training job on the instance type that is most suitable for it. e.g. doing data processing and augmentation on CPU instances and neural network training on GPU instances</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/boto/botocore/commit/7a48de90f39835a647a50b080c349c7a4edd8127""><code>7a48de9</code></a> Merge branch 'release-1.27.26'</li>
<li><a href=""https://github.com/boto/botocore/commit/9d833dfbb383ea035fd274c624803ceab4147e49""><code>9d833df</code></a> Bumping version to 1.27.26</li>
<li><a href=""https://github.com/boto/botocore/commit/112d557d3278e4c40df61b5d937282dd09b5de9c""><code>112d557</code></a> Update to latest models</li>
<li><a href=""https://github.com/boto/botocore/commit/7042057d6136102e49cac1db7d08195bb4ede98b""><code>7042057</code></a> Update lockfile to fix atomicwrite (<a href=""https://github-redirect.dependabot.com/boto/botocore/issues/2716"">#2716</a>)</li>
<li><a href=""https://github.com/boto/botocore/commit/0dfbdb9750404e94741086c6fc018626474ce09a""><code>0dfbdb9</code></a> Merge branch 'release-1.27.25'</li>
<li><a href=""https://github.com/boto/botocore/commit/259835683b3b63f3d7fdcce5915234232e5ed77b""><code>2598356</code></a> Merge branch 'release-1.27.25' into develop</li>
<li><a href=""https://github.com/boto/botocore/commit/8edc5be8c3da73bd9c48dae95f6f14f061dea508""><code>8edc5be</code></a> Bumping version to 1.27.25</li>
<li><a href=""https://github.com/boto/botocore/commit/318a3cb6b93007faccc7262b3706a9f7e4ce9c32""><code>318a3cb</code></a> Update to latest models</li>
<li><a href=""https://github.com/boto/botocore/commit/ae44d1de241c13626d05a9301cf62e460833c950""><code>ae44d1d</code></a> Merge branch 'release-1.27.24' into develop</li>
<li>See full diff in <a href=""https://github.com/boto/botocore/compare/1.27.24...1.27.26"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=botocore&package-manager=pip&previous-version=1.27.24&new-version=1.27.26)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",True,0,CONTRIBUTOR
https://api.github.com/repos/elebumm/RedditVideoMakerBot/issues/comments/1181095638,Bump botocore from 1.27.24 to 1.27.26,dependabot[bot],3,1300542090,2,1181095638,0,1300542090,2022-07-11T23:39:53Z,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file.

If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",False,0,CONTRIBUTOR
https://api.github.com/repos/elebumm/RedditVideoMakerBot/issues/comments/1181110687,Bump botocore from 1.27.24 to 1.27.26,JasonLovesDoggo,3,1300542090,3,1181110687,0,1181095638,2022-07-11T23:47:07Z,@dependabot ignore this major version,False,0,COLLABORATOR
https://api.github.com/repos/elebumm/RedditVideoMakerBot/issues/comments/1181110735,Bump botocore from 1.27.24 to 1.27.26,dependabot[bot],3,1300542090,4,1181110735,0,1181110687,2022-07-11T23:47:08Z,"OK, I won't notify you about version 1.x.x again, unless you re-open this PR or update to a 1.x.x release yourself.",False,0,CONTRIBUTOR
https://api.github.com/repos/elebumm/RedditVideoMakerBot/issues/953,can't sync to MPEG frame,Cmarino25,4,1300631567,1,1300631567,0,0,2022-07-11T12:19:46Z,"**Describe the bug**
Code stops and spits error:

raise HeaderNotFoundError(""can't sync to MPEG frame"")
mutagen.mp3.HeaderNotFoundError: can't sync to MPEG frame

**To Reproduce**
Steps to reproduce the behavior:
run program via ""python main.py""

**Expected behavior**
Program to run

**Screenshots**
If applicable, add screenshots to help explain your problem.
![image](https://user-images.githubusercontent.com/90123136/178262628-a7e1ad52-bba6-4f04-8c14-ec999f5148c4.png)

**System (please complete the following information):**

- Python Version: Python 3.10.5
- OS: Win 10
- App version: Latest

**Additional context**
Add any other context about the problem here.
",True,0,NONE
https://api.github.com/repos/elebumm/RedditVideoMakerBot/issues/comments/1180377771,can't sync to MPEG frame,Cmarino25,4,1300631567,2,1180377771,0,1300631567,2022-07-11T12:57:31Z,"Seems to work fine with the Google Translate TTS Voice. Will keep updated
",False,0,NONE
https://api.github.com/repos/elebumm/RedditVideoMakerBot/issues/comments/1180430482,can't sync to MPEG frame,Anthony-Lloyd,4,1300631567,3,1180430482,0,1180377771,2022-07-11T13:46:06Z,you using tiktok tts to get this error?,False,0,NONE
https://api.github.com/repos/elebumm/RedditVideoMakerBot/issues/comments/1181338979,can't sync to MPEG frame,Cmarino25,4,1300631567,4,1181338979,0,1180430482,2022-07-12T05:42:01Z,"> you using tiktok tts to get this error?

Yeah Using TikTok TTS gests this error googletranslate works fine but i havent tried anyothers
",False,0,NONE
https://api.github.com/repos/elebumm/RedditVideoMakerBot/issues/comments/1186756434,can't sync to MPEG frame,JasonLovesDoggo,4,1300631567,5,1186756434,0,1181338979,2022-07-18T04:29:55Z,Fixed in 2.3,False,0,COLLABORATOR
https://api.github.com/repos/microsoft/TypeScript/issues/49920,Incorrect type inference when using spread operator with index signature and adding another prop,danmana,3,1305778533,1,1305778533,0,0,2022-07-15T09:04:57Z,"# Bug Report

<!--
  Please fill in each section completely. Thank you!
-->

### 🔎 Search Terms

<!--
  What search terms did you use when trying to find an existing bug report?
  List them here so people in the future can find this one more easily.
-->
typescript spread wrong type inference

### 🕗 Version & Regression Information

<!-- When did you start seeing this bug occur?

""Bugs"" that have existed in TS for a long time are very likely to be FAQs; refer to
  https://github.com/Microsoft/TypeScript/wiki/FAQ#common-bugs-that-arent-bugs

If possible, please try testing the nightly version of TS to see if it's already been fixed.
For npm: `typescript@next`
This is also the 'Nightly' version in the playground: http://www.typescriptlang.org/play/?ts=Nightly

Note: The TypeScript Playground can be used to try older versions of TypeScript.

Please keep and fill in the line that best applies:
-->
- This is the behavior in every version I tried (ex: 3.3.3-4.7.4)

### ⏯ Playground Link

<!--
  A link to a TypeScript Playground ""Share"" link which shows this behavior

  The TypeScript Workbench can be used for more complex setups, try
  https://www.typescriptlang.org/dev/bug-workbench/

  As a last resort, you can link to a repo, but these will be slower for us to investigate.
-->
[Playground link with relevant code](https://www.typescriptlang.org/play?ts=3.3.3&ssl=8&ssc=34&pln=1&pc=1#code/JYOwLgpgTgZghgYwgAgILIN4Chm+WYMAGwgC5kBnMKUAcxzwG0BPCOKckAVwFsAjaAF1OvAVCwBfLCTDI45dAF5MBYmWQByVBoA0yAEwAGI+QCM+gMwSA3FmkRZfZMozIAdB7hSZyBM8zunnpEcAJE5BpQEABuENwQGlJAA)

### 💻 Code

<!-- Please post the relevant code sample here as well-->
```ts
interface A {
    title: string
    [year: number]: number
}
let a: A = {title: 'A', 2020: 123};

let b = { ...a}
let c = { ...a, label: 'revenue'}
```

### 🙁 Actual behavior

```ts
// d.ts inference
declare let b: {
    [x: number]: number;
    title: string;
};
declare let c: {
    label: string;
    title: string;
};
```

### 🙂 Expected behavior

```ts
// d.ts inference
declare let b: {
    [x: number]: number;
    title: string;
};
declare let c: {
    [x: number]: number; // <--- this is missing
    label: string;
    title: string;
};
```

It seems that when I add an extra property to the spread object, it loses the `index signature` properties from the spread source.  
But, if I do not add any extra property it does infer correctly the type...
",True,0,NONE
https://api.github.com/repos/microsoft/TypeScript/issues/comments/1185345211,Incorrect type inference when using spread operator with index signature and adding another prop,MartinJohns,3,1305778533,2,1185345211,0,1305778533,2022-07-15T09:12:10Z,Duplicate of #27273. Used search terms: `spread index in:title`,False,0,CONTRIBUTOR
https://api.github.com/repos/microsoft/TypeScript/issues/comments/1185371845,Incorrect type inference when using spread operator with index signature and adding another prop,danmana,3,1305778533,3,1185371845,0,1185345211,2022-07-15T09:44:06Z,"Yes, I think you are right and it's a duplicate ... sorry I missed that

For context, this situation is slightly different as there is no overlap in the keys `[x: number]: number` and `label: string`, unlike the linked issue which uses `Record<string, string>` and `a: ''` where there is no obvious resolution.  
I'm not sure if this is a relevant enough distinction to keep this issue open.


For reference, as mentioned in the comments there, `Object.assign` does produce an expected result
```ts
let d = Object.assign({}, a, {label: 'revenue'})

// infered d.ts
declare let d: A & {
    label: string;
};
```

",False,0,NONE
https://api.github.com/repos/microsoft/TypeScript/issues/comments/1201530404,Incorrect type inference when using spread operator with index signature and adding another prop,typescript-bot,3,1305778533,4,1201530404,0,1185371845,2022-08-01T18:00:05Z,This issue has been marked as a 'Duplicate' and has seen no recent activity. It has been automatically closed for house-keeping purposes.,False,0,COLLABORATOR
https://api.github.com/repos/microsoft/TypeScript/issues/49924,Inferred type parameter is too narrow with strictFunctionTypes enabled and branded types,jakebailey,3,1306341369,1,1306341369,0,0,2022-07-15T18:04:41Z,"# Bug Report

<!--
  Please fill in each section completely. Thank you!
-->

### 🔎 Search Terms

<!--
  What search terms did you use when trying to find an existing bug report?
  List them here so people in the future can find this one more easily.
-->

strictFunctionTypes inferred type parameter too narrow branded types

### 🕗 Version & Regression Information


- This is the behavior in every version I tried, and I reviewed the FAQ for entries about _________


### ⏯ Playground Link

[Playground Link](https://www.typescriptlang.org/play?ts=4.7.4#code/KYDwDg9gTgLgBAMwK4DsDGMCWEVxlATwGEBDAZxgB4AVAeSXlBmBQBMy5qBJFAGk55wAvHBIoCAPgAUANxIAbJMABcA3AB84qVsASYUwVv2YVVshUtXcUASmES4cxcDiYOdBjav14m7bv1DAG4AKFBIWERUDGxcfGJyKmppJ0tOY2BTOHNnKzshBwAjCAh5YDEvTjg-NgCDVlDw6HhkdCwcPEJSChoUixV0vEyYM1SB6nyikrKKq2qtWr16uABvELgNuChgGCQoXDG4AEIhEX8lwzgAMiuhihylOwB+R364VXPAhpCAXxCQtA4ChwFhIAC2cAAygQUDASCAANL6VirdabIjychkACi4G2ZDIsV4aI2GKxkLhzDBLBgxL+IX0zCgCBIaBcADkIDpUZs4ABrZGqaGw+FItihemM4DM1kuCkkKk0kEgZhsDic7lrXkAfQoCuA1NhACEoGJWKoxAQJf8pTK2XAyQTcWB8YSOkwWOw4BqXFrNgK2EKYXDEciAHSOnF4zJulDWhmw6Us+2R+WK2HK1VetMGpV+jYB81Q4Oi8Opym52HxmAEMAuSMAGUwfJcIkjztdsXm5f1hpgoRCOjQmO2UTaXbcjebwCkKC5Ax9lTn3LcDsxBKbLYHQ5HLkBKGBevTIyhFb780+9QH++BYJIBEKwB7x+EnQS9yPldprjIU5bNlCG94DvB8n3XMgcz7AAmV94m6Kg-2AfgfWkT8+34SdwM3YAAJCIA)

### 💻 Code

This is basically what I see in the TS repo.

<!-- Please post the relevant code sample here as well-->
```ts
export function tryCast<TOut extends TIn, TIn = any>(value: TIn | undefined, test: (value: TIn) => value is TOut): TOut | undefined;
export function tryCast<T>(value: T, test: (value: T) => boolean): T | undefined;
export function tryCast<T>(value: T, test: (value: T) => boolean): T | undefined {
    return value !== undefined && test(value) ? value : undefined;
}

const enum SyntaxKind {
    ClassExpression,
    ClassStatement,
}

interface Node {
    kind: SyntaxKind;
}

interface Statement extends Node {
    _statementBrand: any;
}

interface ClassExpression extends Node {
    kind: SyntaxKind.ClassExpression;
}

interface ClassStatement extends Statement {
    kind: SyntaxKind.ClassStatement;
}

type ClassLike = ClassExpression | ClassStatement;

declare function isClassLike(node: Node): node is ClassLike;

declare const statement: Statement | undefined;

const maybeClassStatement = tryCast(statement, isClassLike);
const maybeClassStatement2 = tryCast<ClassLike, Node>(statement, isClassLike);

```

### 🙁 Actual behavior

The second type parameter to `tryCast` is inferred to be `Statement`, which is too narrow.

### 🙂 Expected behavior

The inferred type should be `Node`. This helper is used in the TS repo, but can't be used in some conditions because inference is wrong.
",True,0,MEMBER
https://api.github.com/repos/microsoft/TypeScript/issues/comments/1186082752,Inferred type parameter is too narrow with strictFunctionTypes enabled and branded types,ahejlsberg,3,1306341369,2,1186082752,0,1306341369,2022-07-16T04:01:23Z,"This is working as intended. We infer the more specific `Statement` type for `TIn` because it satisfies both occurrences of `TIn` (the co-variant occurrence in the first parameter and the contra-variant occurrence in the second parameter), and we infer `ClassLike` for `TOut` based on the return type of `isClassLike`. `TOut` then fails its `extends TIn` constraint check because `ClassLike` doesn't extend `Statement`, so we default to the constraint, `Statement`. You need an extra type parameter to make this all work out:

```ts
declare function tryCast<TOut extends T, TIn extends T, T = any>(value: TIn | undefined, test: (value: T) => value is TOut): TOut | undefined;

// ...

const maybeClassStatement = tryCast(statement, isClassLike);  // infers tryCast<ClassLike, Statement, Node>(...)
```
",False,0,MEMBER
https://api.github.com/repos/microsoft/TypeScript/issues/comments/1186089068,Inferred type parameter is too narrow with strictFunctionTypes enabled and branded types,jakebailey,3,1306341369,3,1186089068,0,1186082752,2022-07-16T04:52:20Z,"Cool, I'll give it a try on my branch where I'm trying to enable this option.",False,0,MEMBER
https://api.github.com/repos/microsoft/TypeScript/issues/comments/1186106785,Inferred type parameter is too narrow with strictFunctionTypes enabled and branded types,jakebailey,3,1306341369,4,1186106785,0,1186089068,2022-07-16T07:20:46Z,"Unfortunately that has a bad interaction with generic type guards.

For example, this also from the TS repo for our parenthesizer rules:

```ts
declare function cast<TOut extends T, TIn extends T, T = any>(value: TIn | undefined, test: (value: T) => value is TOut): TOut;

interface Node {
    kind: number;
}

interface TypeNode extends Node {
    typeInfo: string;
}

interface NodeArray<T extends Node> extends Array<T> {
    someProp: string;
}

declare function isNodeArray<T extends Node>(array: readonly T[]): array is NodeArray<T>;

declare const types: readonly TypeNode[];


const x = cast(types, isNodeArray); // bad: NodeAray<Node>


declare function oldCast<TOut extends TIn, TIn = any>(value: TIn | undefined, test: (value: TIn) => value is TOut): TOut;

const y = oldCast(types, isNodeArray); // good: NodeArray<TypeNode>
```

[Playground Link](https://www.typescriptlang.org/play?ts=4.7.4#code/CYUwxgNghgTiAEAzArgOzAFwJYHtXzCgGcMAeAFQHlkN4QAPDEVYI+cgGnYEl8GmWbTu3gBeeFFQBPAHwAKAG5QIyEAC4e+AD7w0oRFlQhgXJiQ2LlqjeQCUYmfCUqEWIdQy2bHgNwAoP0MmGEQoMAQAORxQeABvP3hE+ABrQ2ANVGQAWwAjEBh-AF8AoPzQ8PYpAAcQKJj+ZlZ4OoR4pPgMapBeRBwNEhhDAHMiktRg8sjokABBGBgoKQo6Rka2FscGwXg5haXyRzakohwskAAFGBwq-oxB1BG-Yr9QSFgEFHRsPHg3Ft3Fsstk0NnJYHsNHAoMA8BApOwANoAXS8Enmi1+62mAP2Mn8L3A0DgBDwJA6XSIkJA0Nh8PIXRayPxfjApNo9DEBGIGDknRqRC4f2x6Kktn8AHpxe0AHoAfgCBLexM+mFw+BwEGAAGFuRQPCsBE1yLwuMb8OJJLJLC4bLx4Do9CADEYTB0QOZ4NbrJp7KJHM5VJj2B5UVQaPjWagyfDxBrtdzeRTBUR-iKxX5JTL5UA)

",False,0,MEMBER
https://api.github.com/repos/microsoft/TypeScript/issues/49926,"Allow "".ts"" in include/require statements.",tracker1,5,1306424457,1,1306424457,0,0,2022-07-15T19:48:38Z,"# Suggestion

In order to align with Deno usage, as well as potentially future support for a browser loader, it would be beneficial to be able to include files with the `.ts` extension included.

The option should be able to be configured. When enabled output of "".ts"" extension should be omitted on the output. 

If a module reference begins with `http:`, `https:` or `//` then the default behavior should be left in place. Possibly use separate option to download/process such modules placed in `(outdir)/_cache/https__www.foo.com/path/to/mod.js`.  where the protocol followed by two underscors is presented... preference for https, fallback to http in case of `//` at the front.

There's a pretty deep rabbit hole this could go down... that said, it would be really nice if it were easier to support Deno along with node and browser, and this would go a long way toward doing that.  Since Deno can reference project code directly in typescript, it would allow projects to be Deno first, but still allow for build targets for node and browser usage.

## 🔍 Search Terms

List of keywords you searched for before creating this issue. Write them down here so that others can find this suggestion more easily and help provide feedback.

- deno
- "".ts""
- extension

## ✅ Viability Checklist

<!--
   Suggestions that don't meet all these criteria are very, very unlikely to be accepted.
   We always recommend reviewing the TypeScript design goals before investing time writing
   a proposal for ideas outside the scope of the project.
-->
My suggestion meets these guidelines:

* [x] This wouldn't be a breaking change in existing TypeScript/JavaScript code
* [x] This wouldn't change the runtime behavior of existing JavaScript code
* [x] This could be implemented without emitting different JS based on the types of the expressions
* [x] This isn't a runtime feature (e.g. library functionality, non-ECMAScript syntax with JavaScript output, new syntax sugar for JS, etc.)
* [x] This feature would agree with the rest of [TypeScript's Design Goals](https://github.com/Microsoft/TypeScript/wiki/TypeScript-Design-Goals).


## ⭐ Suggestion

<!-- A summary of what you'd like to see added or changed -->

## 📃 Motivating Example

<!--
  If you were announcing this feature in a blog post, what's a short explanation that shows
  a developer why this feature improves the language?
-->

## 💻 Use Cases

<!--
  What do you want to use this for?
  What shortcomings exist with current approaches?
  What workarounds are you using in the meantime?
-->
",True,0,NONE
https://api.github.com/repos/microsoft/TypeScript/issues/comments/1185858894,"Allow "".ts"" in include/require statements.",MartinJohns,5,1306424457,2,1185858894,0,1306424457,2022-07-15T19:51:23Z,#38149?,False,0,CONTRIBUTOR
https://api.github.com/repos/microsoft/TypeScript/issues/comments/1185889391,"Allow "".ts"" in include/require statements.",tracker1,5,1306424457,3,1185889391,0,1185858894,2022-07-15T20:25:44Z,"While there are other references.. the #38149 was closed along with other mentioned issues.

https://github.com/microsoft/TypeScript/issues/38149#issuecomment-1185887354

To me, given that part of the purpose of TS should be to support browser usage, that explicitly requires an extension... it makes far *MORE* sense to include the output extension for files that TSC processes, not less.  Just because it's easier to ignore the issue, does emphatically *NOT* mean it's not an issue.  In fact, TSC should *ADD* the `.js` extension where none was specified when it will be transpiling the referenced location via magic extension detection.",False,0,NONE
https://api.github.com/repos/microsoft/TypeScript/issues/comments/1185896439,"Allow "".ts"" in include/require statements.",MartinJohns,5,1306424457,4,1185896439,0,1185889391,2022-07-15T20:34:51Z,"> the #38149 was closed along with other mentioned issues.

No idea what you're talking about. It's still open.

> TSC should _ADD_ the `.js` extension where none was specified when it will be transpiling the referenced location via magic extension detection.

Rewriting paths has come up again and again, and the TypeScript team called this a huge no-go. Just check this issue: https://github.com/microsoft/TypeScript/issues/49083 This is also something different from your initial issue.",False,0,CONTRIBUTOR
https://api.github.com/repos/microsoft/TypeScript/issues/comments/1186013708,"Allow "".ts"" in include/require statements.",tracker1,5,1306424457,5,1186013708,0,1185896439,2022-07-15T23:09:10Z,"@MartinJohns it's pretty much the same issue... Being able to use the `.ts` file extension and outputting `.js` for reference where the reference was outputted with a different extension.

Those is for better compatibility with the browser and deno, while it also would not break node.",False,0,NONE
https://api.github.com/repos/microsoft/TypeScript/issues/comments/1186021084,"Allow "".ts"" in include/require statements.",DanielRosenwasser,5,1306424457,6,1186021084,0,1186013708,2022-07-15T23:29:22Z,"We're not likely to transform paths, but the closest thing we may be considering is https://github.com/microsoft/TypeScript/issues/37582.",False,0,MEMBER
https://api.github.com/repos/microsoft/TypeScript/issues/49927,"Design Meeting Notes, 7/15/2022",DanielRosenwasser,4,1306623830,1,1306623830,0,0,2022-07-15T23:28:22Z,"# Enabling Computations on String Enums

https://github.com/microsoft/TypeScript/pull/49809

* Seems strange to allow `const foo: string = ""some string""`.
    * The `: string` annotation should ""spoil"" it.
    * What about a union of literals?
    * Must evaluate to exactly one string literal type.
* Aside: wtf?

  ```ts
  enum E {
     VALUE = ""SOME_STRING"",
  }
 
  enum F {
     VALUE = E.VALUE
  }
 
  // WORKS!?
  const value: number = F.VALUE;
  ```
* Is this an aside? Is it irrelevant?
    * Well, you really don't want to open the hole *further*.

        ```ts
        const s = ""some string"";
        enum F {
           VALUE = s
        }

        // !?
        const value: number = F.VALUE;
        ```
* Most people don't create a lot of indirect computations between enums and constants.
* We really have two enums: ""classic numeric"" and union.
    * Today, any computation opts you into classic numeric enums.
        * Classic numeric enums are assignable to/from `number`, are subtypes of `number`, are not assignable to/from most other enums.
    * This feature would imply that any union enum can contain computations.
* Usually you want a ""classic numeric"" enum to support bit-flags. The most common computation you might have is a left-shift.
    * Maybe rules between strings and numbers don't need to be the same.

  ```ts
  enum SomeStringEnum {
    Value = ""hello!"",
  }

  enum Flags {
    None = 0,
    One = 1 << 0,
    Uhh = SomeStringEnum.Value
  }
  ```
* How would you model operations other than concatenation?
    * Could in theory understand function signatures.
    * But the reason you can do inlining between enums is because you can ""guarantee"" the values. If you resolve emitted values based on function return (e.g. an initializer that calls `<T>(x: T) => Uppercase<T>`), then the types and values can diverge, and you have divergences between a non-type resolving compiler (e.g. Babel) and TypeScript itself.
* Two options for fixing classic enums.
    * One is to change the checking behavior of individual string members (use-site restrictions).
    * The other is to disallow string enums from classic/computed enums (declaration-side restrictions).
* What would be the user fix?
    * declaration site break requires extracting members out to their own enum
    * use-site break only happens when assigning to `number`. Same fix, but you might never have encountered it.
* We don't like the idea of needing deeper checks to determine the ""kind"" of enum that you have (vs. looking at the initializers syntactically).
* Are people really using strings in classic/numeric enums?
    * We see it with some regularity.
* Strictness flag?
* Conclusions
    * Enums are a mess - want to think about this some more.
    * We want to ""fix"" the behavior today for strings in computed enums - want to see how much we would break and decide from there.
    * Difference between direct and indirect computations that are hard to reason about.",True,0,MEMBER
https://api.github.com/repos/microsoft/TypeScript/issues/comments/1186528837,"Design Meeting Notes, 7/15/2022",Zamiell,4,1306623830,2,1186528837,0,1306623830,2022-07-17T14:05:45Z,"A ""strictEnums"" compiler flag has been on my wish list for years, so I'm overjoyed to see this issue!

Would this hypothetical flag prevent the following pattern? (I'm hoping for ""yes"".)

```ts
enum Vegetable {
  Lettuce = 'lettuce',
  Carrot = 'carrot',
}

declare const vegetable: Vegetable;

// Bad
if (vegetable === 'lettuce') {
  // The TypeScript compiler currently allows this.
}

// Good
if (vegetable === Vegetable.Lettuce) {
}
```

This pattern is dangerous. Say that I swapped the enum values of `Lettuce` and `Carrot` by using the F2 (rename) feature of VSCode. After this, the code block would be doing an entirely different thing than the author first intended. And the TypeScript compiler would never alert me to the error, because ""lettuce"" is still a ""valid"" value.

I'd rather that the TypeScript compiler forced me to change `vegetable === 'lettuce'` to `vegetable === Vegetable.Lettuce` from the get-go, such that the code becomes future-safe from any enum values arbitrarily changing. (At least in the world where I have the strictEnums compiler flag turned on.)

As for number enums, they have this same problem too, but of course it's much worse, because you can actually assign non-valid values at compile-time. I'd hope that a hypothetical strict flag would address all of the issues that [this ESLint rule does](https://github.com/typescript-eslint/typescript-eslint/blob/871e9cad34f3b690122cadff364f8b6b5cf1d667/packages/eslint-plugin/docs/rules/strict-enums.md).",False,0,CONTRIBUTOR
https://api.github.com/repos/microsoft/TypeScript/issues/comments/1186863105,"Design Meeting Notes, 7/15/2022",aghArdeshir,4,1306623830,3,1186863105,0,1186528837,2022-07-18T07:35:08Z,"Didn't understand most of mentioned notes in the bullet list :sweat_smile: 
I believe most of it was discussed implicitly verbal/unwritten.

But anyway thanks for sharing, considering and implementing this thing :+1: ",False,0,CONTRIBUTOR
https://api.github.com/repos/microsoft/TypeScript/issues/comments/1188160082,"Design Meeting Notes, 7/15/2022",DanielRosenwasser,4,1306623830,4,1188160082,0,1186863105,2022-07-18T19:14:49Z,"@Zamiell I don't believe so - the tightening we're considering is around the fact that ""classic""/numeric enums are usable in numeric arithmetic operations and are always assignable to `number`. That ""assignable to `number`"" part is a pretty big hole, but it's to allow assigning the result of arithmetic between enum members back to the enum member itself.

```ts
export enum Permissions {
  None = 0,
  Read = 1 << 0,
  Write = 1 << 1,
  Execute = 1 << 2,
}

// Debatable whether this should be allowed.
// Today, it is.
let p: Permissions = Permissions.Read | Permissions.Write;
```

The ""wtf"" we have in the notes refers to the fact that a ""classic numeric"" enum with computed members would usually disallow a string member. Here's an example where an inline string is disallowed:

```ts
export enum Permissions {
  None = 0,
  Read = 1 << 0,
  Write = 1 << 1,
  Execute = 1 << 2,
  
  // Errors - good! ✅
  UnrelatedMember = ""what?"",
}
```

And here's an example where a `const` value is disallowed:

```ts
const unrelated = ""what?"";

export enum Permissions {
  None = 0,
  Read = 1 << 0,
  Write = 1 << 1,
  Execute = 1 << 2,
  
  // This is also disallowed ✅, although the error message is kind of confusing...
  UnrelatedMember = unrelated,
}
```

**But** you can defeat the check through a layer of indirection by referencing an enum.

```ts
export enum Unrelated {
  Unrelated = ""what?"",
}

export enum Permissions {
  None = 0,
  Read = 1 << 0,
  Write = 1 << 1,
  Execute = 1 << 2,
  
  // What? This *is* allowed? 🤔
  UnrelatedMember = Unrelated.Unrelated,
}

// And therefore, this is allowed!? 😬
let p: number = Permissions.UnrelatedMember;

// Runtime: 💥
p.toExponential();
```

So it's unclear what the flag would do (maybe @RyanCavanaugh has thoughts). We could tighten the declarations to not allow strings in these cases to avoid breaking existing code unless under `--strict`.

We could also have the flag disallow the default arithmetic behavior as well. Maybe we'd have to come up with a way to mark how you intend the enum to be used.

```ts
// Possibly now disallowed unless `Permissions` is declared as a ""bitflags"" enum or something.
let p: Permissions = Permissions.Read | Permissions.Write;
```

The more I see these examples, the more I'm convinced that we should try to fix the string behavior without a flag if we can. @RyanCavanaugh mentioned that it feels like we see code like this with some regularity, but I still don't have a great sense of this.",False,0,MEMBER
https://api.github.com/repos/microsoft/TypeScript/issues/comments/1188161876,"Design Meeting Notes, 7/15/2022",DanielRosenwasser,4,1306623830,5,1188161876,0,1188160082,2022-07-18T19:16:41Z,"@aghArdeshir sorry if there's anything unclear. The notes are taken while the conversation is relatively fast (and while I often participate). I'll admit that likely makes things less clear, but hopefully my last comment clarifies some of the discussion.",False,0,MEMBER
https://api.github.com/repos/LibreELEC/LibreELEC.tv/issues/6706,[le10] Update kodi deinterlace patches for Allwinner and Rockchip,HiassofT,5,1306403661,1,1306403661,0,0,2022-07-15T19:21:57Z,"Completely untested except unpacking kodi sources+patches so it should at least fix the CI build error.

I replaced the deinterlace patches with the versions we use on RPi and I added back the LOGERROR->LOGDEBUG change for RK.

@jernejsk @knaerzche please give this a try and report back if it works fine.",True,0,MEMBER
https://api.github.com/repos/LibreELEC/LibreELEC.tv/issues/comments/1188248955,[le10] Update kodi deinterlace patches for Allwinner and Rockchip,jernejsk,5,1306403661,2,1188248955,0,1306403661,2022-07-18T20:06:14Z,It seems to work fine on H6. What are improvements of updated patches?,False,0,MEMBER
https://api.github.com/repos/LibreELEC/LibreELEC.tv/issues/comments/1188252303,[le10] Update kodi deinterlace patches for Allwinner and Rockchip,HiassofT,5,1306403661,3,1188252303,0,1188248955,2022-07-18T20:09:49Z,"No improvements, just rebased (by @popcornmix) so they apply on kodi in LE10 branch with DRM PRIME DVD fix PR (i.e. fix builds and get up to date)",False,0,MEMBER
https://api.github.com/repos/LibreELEC/LibreELEC.tv/issues/comments/1193170575,[le10] Update kodi deinterlace patches for Allwinner and Rockchip,HiassofT,5,1306403661,4,1193170575,0,1188252303,2022-07-23T18:41:21Z,"@knaerzche gentle ping, could you test this on RK? Would be nice to get the fix in",False,0,MEMBER
https://api.github.com/repos/LibreELEC/LibreELEC.tv/issues/comments/1193186308,[le10] Update kodi deinterlace patches for Allwinner and Rockchip,knaerzche,5,1306403661,5,1193186308,0,1193170575,2022-07-23T20:45:44Z,"> @knaerzche gentle ping, could you test this on RK? Would be nice to get the fix in

Srry, didn't notice this one. GTG for RK also.
",False,0,CONTRIBUTOR
https://api.github.com/repos/LibreELEC/LibreELEC.tv/issues/comments/1193238127,[le10] Update kodi deinterlace patches for Allwinner and Rockchip,heitbaum,5,1306403661,6,1193238127,0,1193186308,2022-07-24T03:22:40Z,Builds all completed successfully with the addition of this PR for both Allwinner and Rockchip.,False,0,CONTRIBUTOR
https://api.github.com/repos/LibreELEC/LibreELEC.tv/issues/6707,Add dislocker to System Tools Add On,ilpianista,6,1306607503,1,1306607503,0,0,2022-07-15T22:51:20Z,This adds [dislocker](https://github.com/Aorimn/dislocker) to the System Tools add on.,True,0,NONE
https://api.github.com/repos/LibreELEC/LibreELEC.tv/issues/comments/1186294377,Add dislocker to System Tools Add On,ilpianista,6,1306607503,2,1186294377,0,1306607503,2022-07-16T21:13:13Z,"> Does this support fuse3?

It doesn't build with fuse3, so no.",False,0,NONE
https://api.github.com/repos/LibreELEC/LibreELEC.tv/issues/comments/1186431280,Add dislocker to System Tools Add On,heitbaum,6,1306607503,3,1186431280,0,1186294377,2022-07-17T07:36:54Z,"I did some more looking into WITH_RUBY. The AUR patch at https://github.com/Aorimn/dislocker/pull/238 , https://aur.archlinux.org/packages/dislocker-noruby and https://aur.archlinux.org/cgit/aur.git/tree/no-ruby.patch?h=dislocker-noruby uses option (not set) as introduced in upstream.",False,0,CONTRIBUTOR
https://api.github.com/repos/LibreELEC/LibreELEC.tv/issues/comments/1187193588,Add dislocker to System Tools Add On,heitbaum,6,1306607503,4,1187193588,0,1186431280,2022-07-18T11:50:49Z,"Here is the missing patch to support WITH_RUBY
https://github.com/Aorimn/dislocker/commit/05cd96b1890d3bd4c6ea472edcc2e7b329e4e2e4.patch",False,0,CONTRIBUTOR
https://api.github.com/repos/LibreELEC/LibreELEC.tv/issues/comments/1792037644,Add dislocker to System Tools Add On,chewitt,6,1306607503,5,1792037644,0,1187193588,2023-11-03T08:26:42Z,@ilpianista do you plan to resume work on this PR?,False,0,MEMBER
https://api.github.com/repos/LibreELEC/LibreELEC.tv/issues/comments/1792071880,Add dislocker to System Tools Add On,ilpianista,6,1306607503,6,1792071880,0,1792037644,2023-11-03T08:56:28Z,"> @ilpianista do you plan to resume work on this PR?

No, I'm sorry.",False,0,NONE
https://api.github.com/repos/LibreELEC/LibreELEC.tv/issues/comments/1792075139,Add dislocker to System Tools Add On,CvH,6,1306607503,7,1792075139,0,1792071880,2023-11-03T08:59:22Z,please reopen if you want to continue working on it in the future,False,0,MEMBER
https://api.github.com/repos/LibreELEC/LibreELEC.tv/issues/6716,[BUG] TV show recording crash,JanHBade,4,1308503488,1,1308503488,0,0,2022-07-18T20:02:53Z,"### Describe the bug
Crash loop after playing ""bad"" TV Show

### To Reproduce
Steps to reproduce the behavior:
1. Play a ""bad"" TV Show (artifacts in picture)
2. Kodi crashes and reboot, okay not nice but okay
3. Play another TV show (that is OK) with the same encoding (h264) -> Kodi crashes, NOT okay
4. Play another TV show with different encoding -> works

To make it work I have to reinstall the sd card....

### Informations
 - LE Version: 10.0.2
 - Hardware Platform: RPi4

### Log file
[log-2022-07-18-19.49.25.zip](https://github.com/LibreELEC/LibreELEC.tv/files/9135436/log-2022-07-18-19.49.25.zip)

### Additional context
Logs are from the third step

",True,0,NONE
https://api.github.com/repos/LibreELEC/LibreELEC.tv/issues/comments/1188276185,[BUG] TV show recording crash,HiassofT,4,1308503488,2,1188276185,0,1308503488,2022-07-18T20:32:04Z,Please test with the latest LE10 nightly from here https://test.libreelec.tv/10.0/RPi/RPi4/ and post a new log with that build if the issue is still present,False,0,MEMBER
https://api.github.com/repos/LibreELEC/LibreELEC.tv/issues/comments/1216963591,[BUG] TV show recording crash,JanHBade,4,1308503488,3,1216963591,0,1188276185,2022-08-16T17:53:18Z,"I try LibreELEC-RPi4.arm-10.0-nightly-20220813-511ad11.img.gz

the issue is not complete gone but much better

1.  Play a ""bad"" TV Show, no artifacts but Kodi crashes
2. no auto reboot, hard reboot needed
3. Play another TV show with the same encoding -> works


[log-2022-08-16-17.50.05.zip](https://github.com/LibreELEC/LibreELEC.tv/files/9353250/log-2022-08-16-17.50.05.zip)

",False,0,NONE
https://api.github.com/repos/LibreELEC/LibreELEC.tv/issues/comments/1216979056,[BUG] TV show recording crash,JanHBade,4,1308503488,4,1216979056,0,1216963591,2022-08-16T18:08:12Z,"oh no nightly is not better, more crashes (without artifacts)
crashes with tv show that are ok -> switch back to stable

[log-2022-08-16-18.07.08.zip](https://github.com/LibreELEC/LibreELEC.tv/files/9353337/log-2022-08-16-18.07.08.zip)

",False,0,NONE
https://api.github.com/repos/LibreELEC/LibreELEC.tv/issues/comments/1705212827,[BUG] TV show recording crash,heitbaum,4,1308503488,5,1705212827,0,1216979056,2023-09-04T12:46:43Z,Closing as le10 is no longer being updated. If still and issue in LE11/LE12 - please reopen the issue or reference this issue.,False,0,CONTRIBUTOR
https://api.github.com/repos/LibreELEC/LibreELEC.tv/issues/6717,[le11] update to latest kodi master with DRMPRIME DVD fix,HiassofT,4,1308654505,1,1308654505,0,0,2022-07-18T21:16:59Z,"The filter/deinterlaced patches were rebased by @popcornmix 

Runtime test on RPi4 was fine, DVD menus and deinterlacing still works.

@knaerzche @jernejsk please test on AW/RK",True,0,MEMBER
https://api.github.com/repos/LibreELEC/LibreELEC.tv/issues/comments/1188884334,[le11] update to latest kodi master with DRMPRIME DVD fix,HiassofT,4,1308654505,2,1188884334,0,1308654505,2022-07-19T10:28:57Z,"I've now moved all RPi deinterlace/filter improvements/fixes except for the YUV420 patch to the common kodi patch dir.

Unpacked source for RPi is identical to previous versions.

I'll keep this PR as draft until we have confirmation if this also works on AW and RK",False,0,MEMBER
https://api.github.com/repos/LibreELEC/LibreELEC.tv/issues/comments/1189321072,[le11] update to latest kodi master with DRMPRIME DVD fix,jernejsk,4,1308654505,3,1189321072,0,1188884334,2022-07-19T16:44:13Z,"It works on AW, thanks for working on unification!",False,0,MEMBER
https://api.github.com/repos/LibreELEC/LibreELEC.tv/issues/comments/1189479929,[le11] update to latest kodi master with DRMPRIME DVD fix,knaerzche,4,1308654505,4,1189479929,0,1189321072,2022-07-19T19:39:48Z,"Works fine for RK also, thx.",False,0,CONTRIBUTOR
https://api.github.com/repos/LibreELEC/LibreELEC.tv/issues/comments/1189529868,[le11] update to latest kodi master with DRMPRIME DVD fix,HiassofT,4,1308654505,5,1189529868,0,1189479929,2022-07-19T20:40:14Z,"Thanks a lot to both of you for testing!

I've removed draft, approve and merge if you're happy",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/10977,[BUGFIX] respect PHP-CLI `error_reporting` parameter,xerc,4,1323249608,1,1323249608,0,0,2022-07-30T17:53:53Z,`/opt/php_8.1/bin/php -d error_reporting=8191 ~/composer u` # E_ALL & ~E_DEPRECATED & ~E_USER_DEPRECATED,True,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1216312036,[BUGFIX] respect PHP-CLI `error_reporting` parameter,Seldaek,4,1323249608,2,1216312036,0,1323249608,2022-08-16T08:30:14Z,"Sorry nope, we do this on purpose to ensure uniform experience across platforms/environments.",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1216559473,[BUGFIX] respect PHP-CLI `error_reporting` parameter,xerc,4,1323249608,3,1216559473,0,1216312036,2022-08-16T12:19:15Z,may introduce via arg./flag,False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1216587669,[BUGFIX] respect PHP-CLI `error_reporting` parameter,Seldaek,4,1323249608,4,1216587669,0,1216559473,2022-08-16T12:45:20Z,I don't see a need for it. We report deprecation errors without aborting the process. If you have an actual issue perhaps you should try to describe that in more details.,False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1216617933,[BUGFIX] respect PHP-CLI `error_reporting` parameter,xerc,4,1323249608,5,1216617933,0,1216587669,2022-08-16T13:10:34Z,"mainly because i have PHP 8.1 and PHP 7.4 runnig and compiled both with https://github.com/composer/composer/pull/10976 but there are a lot of deprecation messages in the [8] version which would be nice to hide if you do not want to patch in this specific feature into MAIN
for the example provided there ; it is relevant not to clear the (static-)cache if the database upgrade fails [sh:`&&`]",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/10982,Add SearchCommand tests,IonBazan,6,1328055416,1,1328055416,0,0,2022-08-04T04:36:31Z,"This PR adds functional tests for `SearchCommand` - searching in the local repository only. See #10796

Please take note of additional changes in `RequireCommandTest` , adding `'packagist.org' => false` to avoid HTTP hit in the tests and causing tests to fail due to unexpected `Info from https://repo.packagist.org: #StandWithUkraine` message in the output. 

@Seldaek Is there a better way to disable `packagist.org` in tests to make sure no additional requests are performed? I noticed `$this->getApplicationTester()` uses `Factory` instead of `FactoryMock` but not sure how to improve that.

Coverage changes from 16.98% to 94.34% for this class.",True,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1206318623,Add SearchCommand tests,Seldaek,6,1328055416,2,1206318623,0,1328055416,2022-08-05T10:58:12Z,I think setting packagist.org=>false in TestCase::initTempComposer inside $composerJson would probably be the better fix. I'd probably only do it if the `repositories` key is set though to avoid side effects in tests which are not interested in loading test packages.,False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1216334904,Add SearchCommand tests,Seldaek,6,1328055416,3,1216334904,0,1206318623,2022-08-16T08:50:44Z,Fixed the packagist.org issue in https://github.com/composer/composer/commit/a6d872191c14a00d907801c284756100d44c3f86  and rebased.,False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1216335228,Add SearchCommand tests,IonBazan,6,1328055416,4,1216335228,0,1216334904,2022-08-16T08:51:04Z,"Perfect, thanks!",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1216336109,Add SearchCommand tests,Seldaek,6,1328055416,5,1216336109,0,1216335228,2022-08-16T08:51:55Z,Thank you for the tests :),False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1216338239,Add SearchCommand tests,IonBazan,6,1328055416,6,1216338239,0,1216336109,2022-08-16T08:54:14Z,"I'll look into remaining commands that need testing, since the `packagist.org` repository is now disabled in tests. Are there any plans to host the coverage report somewhere like CodeCov, etc?",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1216342562,Add SearchCommand tests,Seldaek,6,1328055416,7,1216342562,0,1216338239,2022-08-16T08:58:40Z,"No plans. I am not a fan of code coverage monitoring as I don't think it brings much value as an obsession/metric. It is quite useful here as a one-off way to find totally untested code though.

But yes please feel free to send more tests",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/10987,"syntax error, unexpected ')', expecting '|' or variable (T_VARIABLE)   at vendor/symfony/yaml/Parser.php:478",ndethi,5,1331595188,1,1331595188,0,0,2022-08-08T09:33:08Z,"
`composer.json`:

```{
  ""name"": ""laravel/laravel"",
  ""description"": ""The Laravel Framework."",
  ""keywords"": [
    ""framework"",
    ""laravel""
  ],
  ""license"": ""MIT"",
  ""type"": ""project"",
  ""require"": {
    ""php"": ""^7.4|8.0"",
    ""ext-json"": ""*"",
    ""barryvdh/laravel-dompdf"": ""^0.8.3"",
    ""barryvdh/laravel-ide-helper"": ""^2.4"",
    ""barryvdh/laravel-snappy"": ""^0.4.4"",
    ""bugsnag/bugsnag-laravel"": ""^2.0"",
    ""doctrine/dbal"": ""^2.6"",
    ""fideloper/proxy"": ""^4.4"",
    ""fruitcake/laravel-cors"": ""^2.0"",
    ""guzzlehttp/guzzle"": ""^6.3.1|^7.0.1"",
    ""h4cc/wkhtmltopdf-amd64"": ""0.12.x"",
    ""hisorange/browser-detect"": ""^4.2"",
    ""intervention/image"": ""^2.4"",
    ""josiasmontag/laravel-redis-mock"": ""^1.2"",
    ""laravel/framework"": ""^7.0"",
    ""laravel/helpers"": ""^1.2"",
    ""laravel/horizon"": ""^4.0"",
    ""laravel/passport"": ""^9.0"",
    ""laravel/slack-notification-channel"": ""^2.0"",
    ""laravel/tinker"": ""^2.5"",
    ""laravel/ui"": ""^2.0"",
    ""league/csv"": ""^9.1"",
    ""loilo/fuse"": ""^3.3"",
    ""maatwebsite/excel"": ""^3.1"",
    ""nesbot/carbon"": ""^2.17"",
    ""pragmarx/version"": ""^1.2"",
    ""pusher/pusher-php-server"": ""~3.0"",
    ""spatie/laravel-backup"": ""^6.3"",
    ""spatie/laravel-permission"": ""^3.0"",
    ""yadakhov/insert-on-duplicate-key"": ""^1.2""
  },
  ""require-dev"": {
    ""barryvdh/laravel-debugbar"": ""^3.1"",
    ""facade/ignition"": ""^2.0"",
    ""fakerphp/faker"": ""^1.9.1"",
    ""filp/whoops"": ""~2.0"",
    ""friendsofphp/php-cs-fixer"": ""^3.0"",
    ""laravel/telescope"": ""^3.5"",
    ""mockery/mockery"": ""^1.3.1"",
    ""nunomaduro/collision"": ""^4.3"",
    ""phpunit/phpunit"": ""^8.5.8|^9.3.3""
  },
  ""autoload"": {
    ""classmap"": [
      ""database/seeds/"",
      ""database/factories/""
    ],
    ""psr-4"": {
      ""App\\"": ""app/""
    },
    ""files"": [
      ""app/Utilities/helpers.php""
    ]
  },
  ""autoload-dev"": {
    ""psr-4"": {
      ""Tests\\"": ""tests/""
    },
    ""files"": [
      ""database/seeds/seeder_helpers.php"",
      ""database/extended_factories/factories.php""
    ]
  },
  ""extra"": {
    ""laravel"": {
      ""dont-discover"": [
        ""laravel/telescope""
      ]
    }
  },
  ""scripts"": {
    ""test"": [
      ""vendor/bin/phpunit""
    ],
    ""fix"": [
      ""vendor/bin/php-cs-fixer fix --diff""
    ],
    ""lint"": [
      ""vendor/bin/php-cs-fixer fix --dry-run --diff""
    ],
    ""post-root-package-install"": [
      ""@php -r \""file_exists('.env') || copy('.env.example', '.env');\""""
    ],
    ""post-create-project-cmd"": [
      ""@php artisan key:generate""
    ],
    ""post-autoload-dump"": [
      ""Illuminate\\Foundation\\ComposerScripts::postAutoloadDump"",
      ""@php artisan package:discover""
    ]
  },
  ""config"": {
    ""preferred-install"": ""dist"",
    ""sort-packages"": true,
    ""optimize-autoloader"": true
  }
}

```

Output of `composer diagnose`:

```
```

When I run composer update

```composer update --ignore-platform-reqs -vvv
```

I get the following error: 

`ParseError
  syntax error, unexpected ')', expecting '|' or variable (T_VARIABLE)
  at vendor/symfony/yaml/Parser.php:478
    474|                     }
    475|
    476|                     try {
    477|                         return Inline::parse(trim($value));
  > 478|                     } catch (ParseException) {
    479|                         // fall-through to the ParseException thrown below
    480|                     }
    481|                 }
    482|``
```

And I expected this to happen:
Update/install should complete successfully but instead i get this error

```syntax error, unexpected ')', expecting '|' or variable (T_VARIABLE)
  at vendor/symfony/yaml/Parser.php:478
```
I am running php 7.4 and the latest version of composer",True,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/1207895838,"syntax error, unexpected ')', expecting '|' or variable (T_VARIABLE)   at vendor/symfony/yaml/Parser.php:478",xabbuh,5,1331595188,2,1207895838,0,1331595188,2022-08-08T09:39:31Z,Looks like you somehow ended up with the Symfony Yaml component being installed in version 6.1 or higher which requires at least PHP 8.1.,False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1207902698,"syntax error, unexpected ')', expecting '|' or variable (T_VARIABLE)   at vendor/symfony/yaml/Parser.php:478",ndethi,5,1331595188,3,1207902698,0,1207895838,2022-08-08T09:46:20Z,"> Looks like you somehow ended up with the Symfony Yaml component being installed in version 6.1 or higher which requires at least PHP 8.1.

Yes this is true. I have it Symfony Yaml at 6.1 and PHP at 7.4, I cant upgrade to 8.1 yet because of breaking changes but also when I downgrade Symfony Yaml to 5.4 I get breaking dependencies. I am currently upgrading to composer 2.3 to see if that helps (I had erroneously stated I was on the latest version.",False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/1207906519,"syntax error, unexpected ')', expecting '|' or variable (T_VARIABLE)   at vendor/symfony/yaml/Parser.php:478",ndethi,5,1331595188,4,1207906519,0,1207902698,2022-08-08T09:50:09Z,"Upgraded to latest composer and this is the output of:
`composer diagnose`

```Checking composer.json: OK
Checking platform settings: OK
Checking git settings: OK
Checking http connectivity to packagist: OK
Checking https connectivity to packagist: OK
Checking [github.com](http://github.com/) rate limit: OK
Checking disk free space: OK
Checking pubkeys:
Tags Public Key Fingerprint: 57815BA2 7E54DC31 7ECC7CC5 573090D0  87719BA6 8F3BB723 4E5D42D0 84A14642
Dev Public Key Fingerprint: 4AC45767 E5EC2265 2F0C1167 CBBB8A2B  0C708369 153E328C AD90147D AFE50952
OK
Checking composer version: OK
Composer version: 2.3.10
PHP version: 7.4.21 - Package overridden via config.platform, actual: 7.4.30
PHP binary path: /usr/bin/php7.4
OpenSSL version: OpenSSL 3.0.2 15 Mar 2022
cURL version: missing, using php streams fallback, which reduces performance
zip: extension not loaded, unzip present, 7-Zip not available
```

Now I get this error:
```
syntax error, unexpected '|', expecting variable (T_VARIABLE) in ../../../vendor/psr/log/src/LoggerInterface.php on line 30
```
",False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/1207909204,"syntax error, unexpected ')', expecting '|' or variable (T_VARIABLE)   at vendor/symfony/yaml/Parser.php:478",xabbuh,5,1331595188,5,1207909204,0,1207906519,2022-08-08T09:52:42Z,So the question is why and how did you end up with dependencies that are not compatible with the PHP version that you use?,False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1427223960,"syntax error, unexpected ')', expecting '|' or variable (T_VARIABLE)   at vendor/symfony/yaml/Parser.php:478",github-actions[bot],5,1331595188,6,1427223960,0,1207909204,2023-02-13T02:06:53Z,This issue has been automatically marked Stale and will be closed in 15 days if no further activity happens.,False,0,NONE
https://api.github.com/repos/composer/composer/issues/10990,composer 1.10 with max php 7.4,LarsBeiDrKlein,6,1336033478,1,1336033478,0,0,2022-08-11T14:21:06Z,"Hi,
I would like to use composer to compose a typo3v9.5 environment, which needs something less than php 7.4.
At the moment composer 1.10.26 contains php 8.1.9 which is too new for such good old running software.

My `composer.json`:

```
contains typo3 v9.5.x
```

Output of `composer diagnose`:

```
with what, composer seems to work, but the php version is too new. Max 7.4 expected. But was 8.1.9.
```


I get the following output: <!-- FULL OUTPUT please, not just what you think is relevant -->

```
[...]
[16:05:24]Loading composer repositories with package information
[16:05:25]Warning from [https://repo.packagist.org:](https://repo.packagist.org/) Support for Composer 1 is deprecated and some packages will not be available. You should upgrade to Composer 2. See https://blog.packagist.com/deprecating-composer-1-support/
[16:05:25]Info from [https://repo.packagist.org:](https://repo.packagist.org/) #StandWithUkraine
[16:05:25]Updating dependencies (including require-dev)
[16:05:46]Deprecation Notice: strpos(): Passing null to parameter #1 ($haystack) of type string is deprecated in phar:///usr/bin/composer/src/Composer/DependencyResolver/SolverProblemsException.php:80
[16:05:46]Your requirements could not be resolved to an installable set of packages.
[16:05:46]
[16:05:46]  Problem 1
[16:05:46]    - The requested PHP extension ext-json ^1.6 has the wrong version (8.1.9) installed. Install or enable PHP's json extension.
[16:05:46]  Problem 2
[16:05:46]    - Installation request for helhum/typo3-console 5.7.0 -> satisfiable by helhum/typo3-console[v5.7.0].
[16:05:46]    - helhum/typo3-console v5.7.0 requires php >=7.0.0 <7.4 -> your PHP version (8.1.9) does not satisfy that requirement.
[16:05:46]  Problem 3
[16:05:46]    - Installation request for lochmueller/staticfilecache 10.2.1 -> satisfiable by lochmueller/staticfilecache[10.2.1].
[16:05:46]    - lochmueller/staticfilecache 10.2.1 requires php ^7.2||^7.3 -> your PHP version (8.1.9) does not satisfy that requirement.
[16:05:46]  Problem 4
[16:05:46]    - Installation request for t3g/blog 9.1.2 -> satisfiable by t3g/blog[9.1.2].
[16:05:46]    - t3g/blog 9.1.2 requires php ^7.2 -> your PHP version (8.1.9) does not satisfy that requirement.
[16:05:46]  Problem 5
[16:05:46]    - typo3/cms-core v9.5.30 requires php ^7.2 -> your PHP version (8.1.9) does not satisfy that requirement.
[16:05:46]    - typo3/cms-core v9.5.30 requires php ^7.2 -> your PHP version (8.1.9) does not satisfy that requirement.
[16:05:46]    - Installation request for typo3/cms-core 9.5.30 -> satisfiable by typo3/cms-core[v9.5.30].```

And I expected this to happen:

let compose the good old typo3v9.5 with composer in a docker environment
",True,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/1212810095,composer 1.10 with max php 7.4,xabbuh,6,1336033478,2,1212810095,0,1336033478,2022-08-12T07:25:00Z,Composer does not ship PHP. The version reported here is the PHP version that is installed on the system you run Composer on.,False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1216392471,composer 1.10 with max php 7.4,Seldaek,6,1336033478,3,1216392471,0,1212810095,2022-08-16T09:30:14Z,"Yeah you should be able to (and you should) use latest Composer together with PHP 7.2 or above, and then install whatever packages you need. I don't know how you installed Composer nor PHP, but it seems like there's a misunderstanding.",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1220278125,composer 1.10 with max php 7.4,LarsBeiDrKlein,6,1336033478,4,1220278125,0,1216392471,2022-08-19T05:48:44Z,"Hi, I've used composer Container this way:

`CURRENT_DIR_ABS=$(pwd)`
`CONTAINER=composer:1.10.26`
`NAME=composer-$$`
`docker run --rm --name=${NAME} --volume ${CURRENT_DIR_ABS}:/rootfs \`
`  --workdir /rootfs ${CONTAINER} \`
`  bash -c 'git config --global url.""http://git.company.local/"".insteadOf git@git.company.local: && composer clearcache && composer update && composer -v install'`

find the composer.json in the current directory.

As you can see, I've used the php installed within the composer Container and this is php version 8.1.9.

But as you @Seldaek mentioned this could be the wrong way. So I create a docker container for myself based on php 7.4 and install composer like https://getcomposer.org/doc/faqs/how-to-install-composer-programmatically.md

Therefore your composer Container is useless for me. Or I don't understand how to use it the 'right' way but what is right?
",False,0,NONE
https://api.github.com/repos/composer/composer/issues/comments/1220394625,composer 1.10 with max php 7.4,stof,6,1336033478,5,1220394625,0,1220278125,2022-08-19T08:25:08Z,Running the composer container image indeed will not use your own PHP version. The composer container image is better used as a source to copy (or mount) composer into your own PHP image instead.,False,0,CONTRIBUTOR
https://api.github.com/repos/composer/composer/issues/comments/1221237714,composer 1.10 with max php 7.4,Seldaek,6,1336033478,6,1221237714,0,1220394625,2022-08-20T05:41:00Z,"Right, if you want to run it with the composer container PHP then you should make sure you define the platform config (https://getcomposer.org/doc/06-config.md#platform) to avoid surprises. ",False,0,MEMBER
https://api.github.com/repos/composer/composer/issues/comments/1433996061,composer 1.10 with max php 7.4,github-actions[bot],6,1336033478,7,1433996061,0,1221237714,2023-02-17T02:08:10Z,This issue has been automatically marked Stale and will be closed in 15 days if no further activity happens.,False,0,NONE
https://api.github.com/repos/osmandapp/OsmAnd/issues/15045,Loaded maps do not appear on the map,Zirochkabila,29,1333178643,1,1333178643,0,0,2022-08-09T12:22:51Z,"### Description
Loaded maps are not displayed on the map. Although they are displayed in the Download maps.
The user tried both the internal storage of the phone as well as his external SD card and it won't make a difference
[logcat map.log.zip](https://github.com/osmandapp/OsmAnd/files/9290247/logcat.map.log.zip)

### Steps to reproduce
Download map of some country 

### Actual result
Loaded maps do not appear
<table style=""width:100%"">
  <tr>
<th><img src=""https://user-images.githubusercontent.com/104760013/183644922-2501027f-d218-4d22-a59a-ba9263c0cfe8.jpeg""  width=""300"" height=""auto""/> </th>
 <th><img src=""https://user-images.githubusercontent.com/104760013/183644927-4deeab7b-6bf4-4f94-bf81-32a9621d0390.jpeg""  width=""300"" height=""auto""/> </th>
  </tr>
</table>  


### Expected result
Loaded maps are displayed on the map

### Your Environment
OsmAnd Version: 4.2.7
Android/iOS version: Android 11
Device model: Redmi note 9 pro",True,0,COLLABORATOR
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1209626887,Loaded maps do not appear on the map,sonora,29,1333178643,2,1209626887,0,1333178643,2022-08-09T16:49:46Z,"Have you tried zooming in further? The ""far out"" zoom levels are contained in the ""World Overview map"", but not included in any country or regional map. load both maps to see details at all zoom levels.",False,0,MEMBER
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1209633656,Loaded maps do not appear on the map,vshcherb,29,1333178643,3,1209633656,0,1209626887,2022-08-09T16:56:26Z,I don't think we will reproduce it probably reinstall should help,False,0,MEMBER
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1209654452,Loaded maps do not appear on the map,sonora,29,1333178643,4,1209654452,0,1209633656,2022-08-09T17:18:42Z,"Looks to me like the map is simply zoomed out too far. 200km scale on screenshot 2 without World basemap loaded may only display you some forest area from the mini-basemap...

Screenshot 1 also implies it is zoomed out very far, while displaying selected Water/Camping POIs from the full country map ok.",False,0,MEMBER
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1210359231,Loaded maps do not appear on the map,paulolaslo,29,1333178643,5,1210359231,0,1209654452,2022-08-10T08:46:59Z,"> Have you tried zooming in further? The ""far out"" zoom levels are contained in the ""World Overview map"", but not included in any country or regional map. load both maps to see details at all zoom levels.

Zooming doesn't help, the map remains invisible ",False,0,NONE
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1210359809,Loaded maps do not appear on the map,paulolaslo,29,1333178643,6,1210359809,0,1210359231,2022-08-10T08:47:28Z,"> I don't think we will reproduce it probably reinstall should help

I tried uninstalling and reinstalling many times but the same problem remains ",False,0,NONE
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1210363651,Loaded maps do not appear on the map,paulolaslo,29,1333178643,7,1210363651,0,1210359809,2022-08-10T08:50:43Z,"<table style=""width:100%"">
  <tr>
<th><img src=""https://user-images.githubusercontent.com/110971402/183858392-504d4b7f-e7d3-42a8-afdd-7b743b1aff00.jpg""  width=""300"" height=""auto""/> </th>
  </tr>
</table>  

Here's a screenshot of the map zoomed in. The interest points do display. I can create an itinerary toward it but still can't see the roads or anything else",False,0,NONE
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1210368511,Loaded maps do not appear on the map,paulolaslo,29,1333178643,8,1210368511,0,1210363651,2022-08-10T08:54:45Z,I just activated OpenGL before restarting the app and still nothing has changed ,False,0,NONE
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1210683809,Loaded maps do not appear on the map,pebogufi,29,1333178643,9,1210683809,0,1210368511,2022-08-10T13:35:47Z,"I also had a problem with disappearimg maps. 
4.3.0 #34465
During a bicycle trip I made a stop to look for something on the map. Suddenly map was all white.
Closing and clear cache several times did not help.
Reinstalling older version helped.",False,0,NONE
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1210890270,Loaded maps do not appear on the map,Antheii,29,1333178643,10,1210890270,0,1210683809,2022-08-10T15:42:31Z,"Same issue, with me it started after installing on a new phone, using the standard Google migrate tool (previous phone Moto G7, Android 10, new phone Pixel 6 Pro, Android 12).

Uninstalled OsmAnd+, and reinstalled same version (Beta), still same issue. 
Uninstalled again, removed from Beta program, and installed the standard version. Issue solved, with the maps shown correctly again.
On request of the support team, removed the app again, joined the Beta program, and installed the latest Beta. This time I only forgot to check the ""Keep xxx MB of app data"" - so I lost all my POI's :-( , but I guess  I got  a clean install now, which might or might not explain why this time all maps returned!


<table style=""width:100%"">
  <tr>
<th><img src=""https://user-images.githubusercontent.com/63048026/183943275-8897d74d-18d2-41c1-a530-4499c7b6b3c0.png""  width=""300"" height=""auto""/> </th>
 <th><img src=""https://user-images.githubusercontent.com/63048026/183944817-42629a00-f855-4171-9149-20fedc9f3899.png""  width=""300"" height=""auto""/> </th>
  </tr>
</table>  

Device : raven
Brand : google
Model : Pixel 6 Pro
Product : raven
Build : SP2A.220305.013.A3
Version : 12
App Version : OsmAnd+
Apk Version : 4.2.7 4207",False,0,NONE
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1210970482,Loaded maps do not appear on the map,vshcherb,29,1333178643,11,1210970482,0,1210890270,2022-08-10T16:37:45Z,I experienced similar issue with OpenGL enabled but then only reboot of the phone helped. Restart app was not helping somehow. Anyway it looks something specific to device is going on cause this behavior is consistent on Pixel phones where only OpenGL works,False,0,MEMBER
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1212058161,Loaded maps do not appear on the map,paulolaslo,29,1333178643,12,1212058161,0,1210970482,2022-08-11T14:23:06Z,Problem fixed after I did the very last update of the MIUI (12.5.8). Still unclear why the maps suddenly stopped showing,False,0,NONE
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1212153757,Loaded maps do not appear on the map,pebogufi,29,1333178643,13,1212153757,0,1212058161,2022-08-11T15:34:24Z,"Same problem again with OsmAnd~ 4.3.0#34467m, 2022-08-09
Just looking something at the map, then i got a plain white map display. 
Restart did not help. 
But reinstall the same version solved it.",False,0,NONE
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1212464799,Loaded maps do not appear on the map,tkoeller-max,29,1333178643,14,1212464799,0,1212153757,2022-08-11T20:31:30Z,Also having the same problem with Osmand 4.2.7 installed from Google Play Store. This is a fresh install to a pristine Google Pixel 6a device.,False,0,NONE
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1213003426,Loaded maps do not appear on the map,tkoeller-max,29,1333178643,15,1213003426,0,1212464799,2022-08-12T11:19:31Z,Also having the same problem with Osmand 4.2.7 installed from Google Play Store. This is a fresh install to a pristine Google Pixel 6a device.,False,0,NONE
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1213241118,Loaded maps do not appear on the map,vshcherb,29,1333178643,16,1213241118,0,1213003426,2022-08-12T15:35:12Z,Merged to https://github.com/osmandapp/OsmAnd/issues/14947,False,0,MEMBER
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1217982049,Loaded maps do not appear on the map,panicfarm,29,1333178643,17,1217982049,0,1213241118,2022-08-17T13:02:59Z,Installed from Play Store to new Pixel 6 Pro. Map is not rendered by default. In OsmAnd -> Plugins -> OsmAnd development -> Settings enabled Use OpenGL rendering. Restarted the app and the map started rendering. Should be enabled by default prob  ,False,0,NONE
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1219947755,Loaded maps do not appear on the map,tkoeller-max,29,1333178643,18,1219947755,0,1217982049,2022-08-18T20:49:53Z,"> Installed from Play Store to new Pixel 6 Pro. Map is not rendered by default. In OsmAnd -> Plugins -> OsmAnd development -> Settings enabled Use OpenGL rendering. Restarted the app and the map started rendering. Should be enabled by default prob

Works for me, too. However, map rendering is worse with this mode enabled. Coast lines are sometimes approximated coarsely by polygons.",False,0,NONE
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1220733162,Loaded maps do not appear on the map,Zirochkabila,29,1333178643,19,1220733162,0,1219947755,2022-08-19T14:15:55Z,"The user has a similar problem on Samsung S22, OsmAnd~ 4.3.0#13718mqta, released: 2022-08-17 - can be corrected by restarting the phone or disabling Open GL restarting the app, and activating Open GL again.
By the way, the problem with the empty card occurs during the compilation of 3D, even if the OpenGL parameter is turned off.",False,0,COLLABORATOR
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1220792841,Loaded maps do not appear on the map,vshcherb,29,1333178643,20,1220792841,0,1220733162,2022-08-19T15:12:28Z,"Release 4.2.7 - MiUI 12, Android 11 (Ticket 40331)",False,0,MEMBER
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1220821288,Loaded maps do not appear on the map,vshcherb,29,1333178643,21,1220821288,0,1220792841,2022-08-19T15:42:57Z,"<table style=""width:100%"">
  <tr>
<th><img src=""https://user-images.githubusercontent.com/1042025/185656311-e8f9b49e-25dc-4a9b-9e63-f033f59447c9.png""  width=""300"" height=""auto""/> </th>
  </tr>
</table>  
Pixel 6 - Android 13",False,0,MEMBER
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1221415514,Loaded maps do not appear on the map,amirhomayoun,29,1333178643,22,1221415514,0,1220821288,2022-08-20T21:54:30Z,"Had the same problem on new Google Pixel 6a. Android version 12, OsmAnd+ 4.2.7, released: 2022-07-13.

Android Auto Offtopic.

Turning on the OpenGL in the plugins fixed the issue on the phone. Android auto however, stays blank.

<details>
    <summary>Android Auto Offtopic</summary>

 I notice that overlay maps do show on the AA, but the map itself does not. So, I have the Google Traffic maps as an overlay, and AA does show it, but switching the map source from ""offline vector maps"" to ""OsmAnd (online tiles)"", or ""Microsoft Earth"", or any other source, won't work. The AA screen stays blank (if you don't have the overlay). You can use navigation, and it is functioning, you just cannot see anything on the map unless if you turn on the overlay. The open street plugin would work too, if you turn it on, you can see the red crosses on the blank black screen on the AA screen. Somehow map doesn't load on the Pixel 6a, the same version of OsmAnd, on the same car worked before (on Android 11, and a pixel 4). Turning OpenGL off won't make a difference. 

![PXL_20220820_231010288 MP](https://user-images.githubusercontent.com/1396660/185777370-e7966585-b857-4112-9d3f-aa1ae0665205.jpg)


</details>
",False,0,NONE
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1221487275,Loaded maps do not appear on the map,pebogufi,29,1333178643,23,1221487275,0,1221415514,2022-08-21T07:20:59Z,"@amirhomayoun 
OT. Can you please send the link for installing Google Traffic maps as an overlay?
Thanks.",False,0,NONE
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1221554335,Loaded maps do not appear on the map,amirhomayoun,29,1333178643,24,1221554335,0,1221487275,2022-08-21T14:13:55Z,"<details>
    <summary>Hidden Offtopic</summary>



![PXL_20220821_145215579 MP](https://user-images.githubusercontent.com/1396660/185804160-7c8a0669-ddf2-4a22-98b0-47d49f8c0da2.jpg)
Sure. If you want it without labels:

`https://maps.googleapis.com/maps/vt?pb=!1m5!1m4!1i{0}!2i{1}!3i{2}!4i256!2m3!1e0!2sm!3i0!2m6!1e2!2straffic!4m2!1st!2s0!5i1!3m17!2sen-BE!3sUS!5e18!12m4!1e68!2m2!1sset!2sRoadmap!12m3!1e37!2m1!1ssmartmaps!12m4!1e26!2m2!1sstyles!2sp.v%3Aoff!4e0!5m1!5f1)`

And if you want it with labels:

`http://mts0.googleapis.com/vt/lyrs=traffic&x={1}&y={2}&z={0}&style=15`

The first one is what you see in my previous post photo. If you use the second link, you will see the green/red traffic as well as some basic street/business names. I'd rather use the offline vector maps as map and just put the traffic overlay on top of that, so I use the first one. 

Note that the overlay is not the problem, the problem is the actual map not showing. If I remove the overlay, as you see in the photo in this comment, I will just see a blank screen (sometimes light blank screen and sometimes black).

</details>
",False,0,NONE
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1223763711,Loaded maps do not appear on the map,vshcherb,29,1333178643,25,1223763711,0,1221554335,2022-08-23T08:53:33Z,OpenGL in Android Auto is offtopic (separate issue) and it's a known limitation and it doesn't work now,False,0,MEMBER
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1225715548,Loaded maps do not appear on the map,johann-petrak,29,1333178643,26,1225715548,0,1223763711,2022-08-24T13:18:37Z,"I seem to have the same problem here: moved to a new phone Redmi Note 11 Pro+ 5G running MIUI 13.0.3 and Android 12 SP1A. I was using Google Sync to set up my apps from the old phone.

The symptoms were: 
* initially, offline map was not rendered, but location markers or things like cycle routes were rendered
* when moving/zooming the screen, the things that did get rendered ended up not to get properly repainted and produced a huge mess on screen
* online maps instead of the offline vector map did get rendered properly
* after some experimentation it turns out that map style ""Osmand"" was selected
* when changing the map style to ""Topo"", suddenly the offline map does get rendered properly
* support suggested to try enabling OpenGL which did not change anything
* UPDATE: after a complete uninstall and re-install, this problem seems to be fixed now!

<details>
    <summary>Screenshot</summary>

![Screenshot_2022-08-05-15-43-13-270_net osmand plus](https://user-images.githubusercontent.com/619106/186428559-24538819-13b5-454d-9494-2738a47f2be3.jpg)


</details>


",False,0,NONE
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1229175839,Loaded maps do not appear on the map,PvdBerg1998,29,1333178643,27,1229175839,0,1225715548,2022-08-27T11:35:03Z,"Same problem after changing to LineageOS 18.1 on my Oneplus 8, rendering using OpenGL fixed it.

UPDATE: OpenGL is not stable and the app likes to crash every now and then.",False,0,NONE
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1317268635,Loaded maps do not appear on the map,tkoeller-max,29,1333178643,28,1317268635,0,1229175839,2022-11-16T16:10:55Z,@Zirochkabila Problem still exists in 4.2.7,False,0,NONE
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1319196158,Loaded maps do not appear on the map,alewando,29,1333178643,29,1319196158,0,1317268635,2022-11-17T21:01:30Z,"#14947 says this is fixed in version 4.3.0 (three months ago), but that version is still not available in the app store ",False,0,NONE
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1324715209,Loaded maps do not appear on the map,Zirochkabila,29,1333178643,30,1324715209,0,1319196158,2022-11-23T08:44:59Z,@tkoeller-max Try to do as described in the article [No maps rendering for Google Pixel device](https://osmand.net/docs/user/troubleshooting/maps-data#no-maps-rendering-for-google-pixel-device),False,0,COLLABORATOR
https://api.github.com/repos/osmandapp/OsmAnd/issues/15046,Removing all tracks doesn't remove folder,anastasiia936,4,1333258025,1,1333258025,0,0,2022-08-09T13:26:21Z,"At the moment is not possible to remove track folder.
If you delete all tracks the folder will disappear, but if you try to move track to another folder deleted folder will be displayed in the list of folders, so you can put tracks for it. As a result, is not possible to remove track folder forever. 
Look at the screenshots below, I tried to delete Test folder. 
<table style=""width:100%"">
  </tr>
  <tr>
    <td><img src=""https://user-images.githubusercontent.com/80623554/183661695-5ea3ff77-4af3-422c-b62d-d469dfb45966.png""  width=""300"" height=""auto""/> </td>
    <td><img src=""https://user-images.githubusercontent.com/80623554/183661966-7a8bb712-4cbe-4493-ad8a-432b5b17b3d2.png""  width=""300"" height=""auto""/> </td>
  </tr>
</table>  
",True,0,NONE
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1209514597,Removing all tracks doesn't remove folder,vshcherb,4,1333258025,2,1209514597,0,1333258025,2022-08-09T15:13:33Z,You have bulk delete in My Places,False,0,MEMBER
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1209553148,Removing all tracks doesn't remove folder,anastasiia936,4,1333258025,3,1209553148,0,1209514597,2022-08-09T15:44:57Z,"I deleted by bulk delete, tracks deleting, but the folder still exists in the list.
",False,0,NONE
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1209560778,Removing all tracks doesn't remove folder,dmpr0,4,1333258025,4,1209560778,0,1209553148,2022-08-09T15:47:15Z,It will be implemented after the My Places > Tracks redesign.,False,0,CONTRIBUTOR
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1218010458,Removing all tracks doesn't remove folder,0xRe1nk0,4,1333258025,5,1218010458,0,1209560778,2022-08-17T13:27:52Z,"**Pull Request**
https://github.com/osmandapp/OsmAnd/pull/15103",False,0,CONTRIBUTOR
https://api.github.com/repos/osmandapp/OsmAnd/issues/15048,Send Group / Category of Tracks,gubrist,5,1333329081,1,1333329081,0,0,2022-08-09T14:17:42Z,"
# 🚀 feature request

### Description

I use OsmAnd+ 4.2.7

You can send a Group / Category of **favourites**

![Favourites send 1](https://user-images.githubusercontent.com/22197180/183672145-88091830-4e39-49b0-a791-6109c879c45f.jpg)

![Favourites send 2](https://user-images.githubusercontent.com/22197180/183672178-e6d81a23-e39d-40dd-9a4b-b3f24a113866.jpg)


### Describe the solution you'd like

I request to send  a Group / Category of **tracks** the same way

![Tracks send](https://user-images.githubusercontent.com/22197180/183672346-1547d40c-255d-4183-85f3-5a83af25de5b.jpg)


### Describe alternatives you've considered

Searching the Android files directory, which shows to be hidden and/or complicated.
",True,0,NONE
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1209465911,Send Group / Category of Tracks,scaidermern,5,1333329081,2,1209465911,0,1333329081,2022-08-09T14:36:26Z,Duplicate of #5558.,False,0,CONTRIBUTOR
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1209523808,Send Group / Category of Tracks,vshcherb,5,1333329081,3,1209523808,0,1209465911,2022-08-09T15:21:09Z,Please Keep in mind as well that you can export as OSF package already which accepted by other OsmAnd instance,False,0,MEMBER
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1209595659,Send Group / Category of Tracks,gubrist,5,1333329081,4,1209595659,0,1209523808,2022-08-09T16:18:42Z,"What is an ""OSF package""?

My expectation is a device-independent *.GPX File, or some files compressed in a *. ZIP File. ",False,0,NONE
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1209628116,Send Group / Category of Tracks,scaidermern,5,1333329081,5,1209628116,0,1209595659,2022-08-09T16:51:00Z,Actually osf is a zip file. But I understand what you are trying to say. ,False,0,CONTRIBUTOR
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1209635166,Send Group / Category of Tracks,vshcherb,5,1333329081,6,1209635166,0,1209628116,2022-08-09T16:58:09Z,"Sharing GPX as multiple files will overload the system in most of the cases, sending as a zip file technically exactly the same as doing manual backup OSF. which could be renamed to ZIP and unzipped.",False,0,MEMBER
https://api.github.com/repos/osmandapp/OsmAnd/issues/15050,"If a new user skips downloading maps, OsmAnd fails to display online tiles by default",unforgettableid,8,1334467136,1,1334467136,0,0,2022-08-10T11:16:00Z,"### How to reproduce?

1. Install OsmAnd.
1. When the new-user UI appears, tap ""Get started"".
1. When the ""Download map"" screen appears, tap the ""Skip"" button, in an attempt to conserve storage space.
1. When the confirmation dialog box appears, tap ""Skip"" again.

### The problem

1. You'll see a blank screen. No map is visible.

### Explanation

1. The ""Online maps"" plugin is disabled by default.
1. The ""Map source..."" setting is set to ""Offline vector maps"" by default.

### My request

1. On all new installations, please enable the ""Online maps"" plugin by default.
1. On all new installations, please allow OsmAnd to display online tiles by default, if offline maps are not available or were never downloaded.

Thank you for reading this!

### Your Environment
OsmAnd Version: 4.1.1 from F-Droid
Android/iOS version: Android 8.0.0 ""Oreo""
Device model: LG G5
",True,0,NONE
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1210583796,"If a new user skips downloading maps, OsmAnd fails to display online tiles by default",scaidermern,8,1334467136,2,1210583796,0,1334467136,2022-08-10T12:09:12Z,"My suggestion is to not enable online maps automatically. They cause significant data traffic. Instead, _ask_ the user whether to enable online maps if the user chooses to skip downloading offline maps.",False,0,CONTRIBUTOR
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1210638707,"If a new user skips downloading maps, OsmAnd fails to display online tiles by default",unforgettableid,8,1334467136,3,1210638707,0,1210583796,2022-08-10T12:58:27Z,"@scaidermern:

The data traffic is generally no problem over Wi-Fi, but it can indeed be costly when using cellular data.  Especially when the user is using pay-per-megabyte data roaming, which is offered by a few carriers around here.  For example:  Chatr Wireless Canada has traditionally charged about US$0.04/MB for USA roaming, and about US$25/MB for roaming in all other countries.  [(Source.)](https://www.google.com/search?q=Chatr+..+Data+roaming+rates+apply%3A+%240.05%2FMB+U.S.+roaming%2C+%2430%2FMB+international+roaming+(where+available).)

For what it's worth:  Google Maps seems not to worry much about the data traffic involved in fetching online maps.  It generally fetches online maps automatically, without prompting the user.  This only uses maybe ~5 MB per hour of driving.  [(Source.)](https://ting.blog/how-much-data-does-google-maps-use/)  I think Google Maps also uses Wi-Fi to automatically download and cache offline maps, again without prompting the user.

I guess that, if the user is using expensive metered data roaming, Google Maps expects the user to enable its ""Wi-Fi only"" setting manually.",False,0,NONE
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1212396815,"If a new user skips downloading maps, OsmAnd fails to display online tiles by default",lbdroid,8,1334467136,4,1212396815,0,1210638707,2022-08-11T19:25:17Z,"I would suspect that most users who have to pay for data roaming would very immediately hit the box that disables data while roaming. If not, I think its a safe assumption for most people that the phone will rack up some roaming data usage, which could cost an unpredictable amount.",False,0,NONE
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1213325463,"If a new user skips downloading maps, OsmAnd fails to display online tiles by default",vshcherb,8,1334467136,5,1213325463,0,1212396815,2022-08-12T16:56:46Z,"1. It goes a bit against our mission to provide fully functional offline maps
2. It doesn't have most important functions like context menu of points & tracks
3. Search / Navigation / Layers are a bit problematic


",False,0,MEMBER
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1215983031,"If a new user skips downloading maps, OsmAnd fails to display online tiles by default",unforgettableid,8,1334467136,6,1215983031,0,1213325463,2022-08-15T23:32:02Z,"> 1\. It goes a bit against our mission to provide fully functional offline maps

This is true.  Still, please consider cases in which the user specifically chose to skip the download.  In such cases, it's better to offer them online-only maps than to give them a confusing blank screen with no maps at all.

> 2\. It doesn't have most important functions like context menu of points & tracks
> 3\. Search / Navigation / Layers are a bit problematic

These are good points.  It would probably be good to warn the user about these issues on first run, when they first choose to skip the download of offline maps.  This might encourage them to reconsider their choice.",False,0,NONE
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1226050402,"If a new user skips downloading maps, OsmAnd fails to display online tiles by default",tanc,8,1334467136,7,1226050402,0,1215983031,2022-08-24T17:52:35Z,As a new user I'm totally confused about online vs offline maps. I discovered the online maps after a while but I can't seem to plot a route or search for an address. Is routing and searching an offline-only feature? Either way it would be great to be informed about my options at the beginning in some way.,False,0,NONE
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1226261891,"If a new user skips downloading maps, OsmAnd fails to display online tiles by default",vshcherb,8,1334467136,8,1226261891,0,1226050402,2022-08-24T20:25:18Z,Yes most of the features offline-only,False,0,MEMBER
https://api.github.com/repos/osmandapp/OsmAnd/issues/comments/1226807450,"If a new user skips downloading maps, OsmAnd fails to display online tiles by default",scaidermern,8,1334467136,9,1226807450,0,1226261891,2022-08-25T05:52:18Z,"> As a new user I'm totally confused about online vs offline maps. I discovered the online maps after a while but I can't seem to plot a route or search for an address. Is routing and searching an offline-only feature? Either way it would be great to be informed about my options at the beginning in some way.

Indeed it would be very nice to have a short list of features on startup that are only usable _with_ offline maps. And also a short explanation for how to use OsmAnd _without_ offline maps.",False,0,CONTRIBUTOR
https://api.github.com/repos/Cog-Creators/Red-DiscordBot/issues/5805,Config defaults not actually updating after a cog reload,i-am-zaidali,3,1317065867,1,1317065867,0,0,2022-07-25T16:13:20Z,"### What Red version are you using?

3.4.16

### What were you trying to do?

Updating guild defaults for Config in my cog.

### What did you expect to happen?

For the new defaults to be returned when `.all()` is called on a Group object. 

### What actually happened?

Old defaults being returned instead.

### How can we reproduce this error?

1. Create a cog and a config instance tied to the config with force registration set to True
2. Set guild defaults for the config objects.
3. Load the cog and modify the config values.
4. Change the defaults set to config by removing a few keys and adding a few.
5. Reload the cog and try running `.clear()` on a Group.


### Anything else?

_No response_",True,0,CONTRIBUTOR
https://api.github.com/repos/Cog-Creators/Red-DiscordBot/issues/comments/1221128407,Config defaults not actually updating after a cog reload,Flame442,3,1317065867,2,1221128407,0,1317065867,2022-08-19T22:11:49Z,"EDIT: Misread the report, see followup comment which actually addresses the real issue.

I believe this is intended behavior. Config **does not** have an option to **remove** defaults, only to **add** new defaults or to **override** current ones. As such, successive `register_scope` calls will **add** the provided keys (if they did not exist), and will **override** the current default (if they did exist) for each key. There is no way (I can see, through the public APIs) to **remove** a default once it has been set without creating a new Config object.

Through my testing, this behavior is correct:
When keys are **added**, they become functional, and have the new default (`baz` in the following example). 
When keys are **overridden**, a `clear` causes the new default to be used instead of the old one (`foo` in the following example).
When keys are **not included**, they are not ""removed"", they just do not get changed. The old default continues to be used (`bar` in the following example).

If you are seeing different behavior, please provide a code sample to reproduce the behavior you are describing, as your reproduction steps do not have any specific lines of code used beyond `.clear()`. If your issue matches with this intended behavior and you want to make a feature request to add a way to *remove* existing defaults during the life of a Config option, please make a new issue requesting that instead.

<details>
<summary>Code (Hidden, as it is not relevant to the actual bug report, see followup comment)</summary>
<br>
Code I used to attempt to reproduce your issue (this is code suited for a testing eval, not code that should be considered at all reasonable to use in production)

```py
from redbot.core.config import Config

async def printall():
  print(""> Printing current values"")
  print(""foo="",await bot.x.guild(ctx.guild).foo())
  try:
    print(""bar="",await bot.x.guild(ctx.guild).bar())
  except Exception as e:
    print(""bar="",e)
  try:
    print(""baz="",await bot.x.guild(ctx.guild).baz())
  except Exception as e:
    print(""baz="",e)

bot.x = Config.get_conf(""Testing"", identifier=145519400223506432, cog_name=""Testing"", force_registration=True)
print(""> Registering defaults foo=foo | bar=bar"")
bot.x.register_guild(
  foo=""foo"",
  bar=""bar"",
)
await printall()
print(""> Setting guild values foo=foofoo | bar=barbar | baz=bazbaz"")
await bot.x.guild(ctx.guild).foo.set(""foofoo"")
await bot.x.guild(ctx.guild).bar.set(""barbar"")
try:
  await bot.x.guild(ctx.guild).baz.set(""bazbaz"")
except Exception as e:
  print(""baz set: "", e)
await printall()
print(""> Registering defaults foo=foofoofoo | baz=bazbazbaz"")
bot.x.register_guild(
  foo=""foofoofoo"",
  baz=""bazbazbaz"",
)
await printall()
print(""> Clearing guild values"")
await bot.x.guild(ctx.guild).foo.clear()
try:
  await bot.x.guild(ctx.guild).bar.clear()
except Exception as e:
  print(""bar clear: "", e)
await bot.x.guild(ctx.guild).baz.clear()
await printall()
```
Output
```
> Registering defaults foo=foo | bar=bar
> Printing current values
foo= foo
bar= bar
baz= 'baz' is not a valid registered Group or value.
> Setting guild values foo=foofoo | bar=barbar | baz=bazbaz
baz set:  'baz' is not a valid registered Group or value.
> Printing current values
foo= foofoo
bar= barbar
baz= 'baz' is not a valid registered Group or value.
> Registering defaults foo=foofoofoo | baz=bazbazbaz
> Printing current values
foo= foofoo
bar= barbar
baz= bazbazbaz
> Clearing guild values
> Printing current values
foo= foofoofoo
bar= bar
baz= bazbazbaz
```
</details>",False,0,MEMBER
https://api.github.com/repos/Cog-Creators/Red-DiscordBot/issues/comments/1221133761,Config defaults not actually updating after a cog reload,Flame442,3,1317065867,3,1221133761,0,1221128407,2022-08-19T22:22:37Z,"So it looks like I missed the ""reload"" part of your original report - my bad. Updated code snippet below, which includes a simulated ""reload"", showing that creating a *new* Config object properly clears defaults (when used correctly).

The behavior is still consistent with what it should be in *this* case as well:
When keys are **added**, they become functional, and have the new default (baz in the following example).
When keys are **overridden**, a clear causes the new default to be used instead of the old one (foo in the following example).
When keys are **not included**, the default is ""removed"", but **internally** the current value (NOT the default) does not get changed If that key is registered later, it will **still have the old value**. However, attempting to get the value after clearing *while it has not been registered for the current Config object* will either raise an exception if `force_registration=True`, or will return the base default of `None` (bar in the following example).

Again, if this behavior is not what you expect for any reason, feel free to comment with a code snippet and an explanation of what you believe should be happening.

```py
from redbot.core.config import Config

async def printall():
  print(""> Printing current values"")
  print(""foo="",await bot.x.guild(ctx.guild).foo())
  try:
    print(""bar="",await bot.x.guild(ctx.guild).bar())
  except Exception as e:
    print(""bar="",e)
  try:
    print(""baz="",await bot.x.guild(ctx.guild).baz())
  except Exception as e:
    print(""baz="",e)

print(""> Creating Config object"")
bot.x = Config.get_conf(""Testing"", identifier=145519400223506432, cog_name=""Testing"", force_registration=True)
print(""> Registering defaults foo=foo | bar=bar"")
bot.x.register_guild(
  foo=""foo"",
  bar=""bar"",
)
await printall()
print(""> Setting guild values foo=foofoo | bar=barbar | baz=bazbaz"")
await bot.x.guild(ctx.guild).foo.set(""foofoo"")
await bot.x.guild(ctx.guild).bar.set(""barbar"")
try:
  await bot.x.guild(ctx.guild).baz.set(""bazbaz"")
except Exception as e:
  print(""baz set: "", e)
await printall()
print(""> Recreating Config object"")
del bot.x
bot.x = Config.get_conf(""Testing"", identifier=145519400223506432, cog_name=""Testing"", force_registration=True)
print(""> Registering defaults foo=foofoofoo | baz=bazbazbaz"")
bot.x.register_guild(
  foo=""foofoofoo"",
  baz=""bazbazbaz"",
)
await printall()
print(""> Clearing guild values"")
await bot.x.guild(ctx.guild).foo.clear()
try:
  await bot.x.guild(ctx.guild).bar.clear()
except Exception as e:
  print(""bar clear: "", e)
await bot.x.guild(ctx.guild).baz.clear()
await printall()
```
Output
```
> Creating Config object
> Registering defaults foo=foo | bar=bar
> Printing current values
foo= foo
bar= bar
baz= 'baz' is not a valid registered Group or value.
> Setting guild values foo=foofoo | bar=barbar | baz=bazbaz
baz set:  'baz' is not a valid registered Group or value.
> Printing current values
foo= foofoo
bar= barbar
baz= 'baz' is not a valid registered Group or value.
> Recreating Config object
> Registering defaults foo=foofoofoo | baz=bazbazbaz
> Printing current values
foo= foofoo
bar= 'bar' is not a valid registered Group or value.
baz= bazbazbaz
> Clearing guild values
bar clear:  'bar' is not a valid registered Group or value.
> Printing current values
foo= foofoofoo
bar= 'bar' is not a valid registered Group or value.
baz= bazbazbaz
```",False,0,MEMBER
https://api.github.com/repos/Cog-Creators/Red-DiscordBot/issues/comments/1308263890,Config defaults not actually updating after a cog reload,Flame442,3,1317065867,4,1308263890,0,1221133761,2022-11-09T06:13:42Z,"Due to not receiving a response, and this seeming like intended behavior, I'm closing this issue. If you still think there is an issue, and you can provide exact reproduction steps similar to what I wrote, I can take another look at this.",False,0,MEMBER
https://api.github.com/repos/Cog-Creators/Red-DiscordBot/issues/5821,[3.4] [Audio] Update application.yml for new Lavalink.jar,aikaterna,4,1337729460,1,1337729460,0,0,2022-08-12T21:44:21Z,"### Description of the changes
We will be using a new Lavalink.jar on build 1350 and later that includes a Spring Boot version update from 2.1.8 to 2.6.6. In this version change, some of the logging functions have changed so they have been moved to their new designation.

### Have the changes in this PR been tested?
Yes, I installed a copy of Red with this file from a GH repo and Red started up, it replaced my old application.yml with this file and then the newer Lavalink.jar started to create log files again.",True,0,MEMBER
https://api.github.com/repos/Cog-Creators/Red-DiscordBot/issues/comments/1214208613,[3.4] [Audio] Update application.yml for new Lavalink.jar,Jackenmen,4,1337729460,2,1214208613,0,1337729460,2022-08-13T19:09:32Z,I'm working on an equivalent PR (along with LL bump) for 3.5 and will merge this one once the 3.5 PR is up.,False,0,MEMBER
https://api.github.com/repos/Cog-Creators/Red-DiscordBot/issues/comments/1214209325,[3.4] [Audio] Update application.yml for new Lavalink.jar,Drapersniper,4,1337729460,3,1214209325,0,1214208613,2022-08-13T19:14:31Z,"You need this one if you are going to make a 3.4.18 release. Otherwise, the spring.log won't generate for users with issues.",False,0,CONTRIBUTOR
https://api.github.com/repos/Cog-Creators/Red-DiscordBot/issues/comments/1214209496,[3.4] [Audio] Update application.yml for new Lavalink.jar,Jackenmen,4,1337729460,4,1214209496,0,1214209325,2022-08-13T19:15:53Z,"I'm well aware, the PR is in the milestone for a reason.",False,0,MEMBER
https://api.github.com/repos/Cog-Creators/Red-DiscordBot/issues/5830,Get rid of localized guild feature list in serverinfo,Jackenmen,6,1338407975,1,1338407975,0,0,2022-08-15T01:05:47Z,"### Description of the changes

An attempt at lowering the requirement for constant maintenance of the guild feature list. This PR makes it so that instead of maintaining a guild features list, we show the guild features as given to us by the API. Mostly. I've made 3 exceptions where the automatic casing didn't really make sense to me.

Before:
![image](https://user-images.githubusercontent.com/6032823/184562006-19a1d8c1-668f-4e38-9d24-f233f7c90acd.png)

After:
![image](https://user-images.githubusercontent.com/6032823/184561972-030ad22c-1795-42f9-a793-c846d6a5524a.png)

As can be seen on the screenshots, this PR makes `[p]serverinfo 1` show more features than before but to me, it kind of seems like an upside... Feel free to comment if you disagree.

### Have the changes in this PR been tested?

Yes
",True,0,MEMBER
https://api.github.com/repos/Cog-Creators/Red-DiscordBot/issues/comments/1214503991,Get rid of localized guild feature list in serverinfo,Kowlin,6,1338407975,2,1214503991,0,1338407975,2022-08-15T01:11:39Z,"Thread archive duration, Threads active, New thread permissions and VIP regions can also be removed since they no longer apply.
Also News falls under Community now as it's a mainline community feature and the same applies to Enabled Discovery before with Discovery, as enabled discovery before only handles if it should show the discovery splash page.",False,0,MEMBER
https://api.github.com/repos/Cog-Creators/Red-DiscordBot/issues/comments/1214504990,Get rid of localized guild feature list in serverinfo,Jackenmen,6,1338407975,3,1214504990,0,1214503991,2022-08-15T01:13:29Z,I'm unsure whether it's worth making the change if we're just going to switch it from include list to exclude list. I guess it at least means that new features will show immediately so there is an upside there.,False,0,MEMBER
https://api.github.com/repos/Cog-Creators/Red-DiscordBot/issues/comments/1214529541,Get rid of localized guild feature list in serverinfo,Kowlin,6,1338407975,4,1214529541,0,1214504990,2022-08-15T01:57:30Z,"I think the change to an exclude list would be better due the fact that Discord *will* keep adding more feature flags over the years, without attempts at cleaning up their old flags.

``NEWS`` is given with ``COMMUNITY``,
``THREE_DAY_THREAD_ARCHIVE``, and ``SEVEN_DAY_THREAD_ARCHIVE`` have become baseline within Discord ever since Discord started rolling out Forum channels in limited private beta,
``VIP_REGIONS`` is an partner flag that Legacy Partners carried over along with a permanent ``VANITY_URL`` so is largely attached to ``PARTNERED``
``NEW_THREAD_PERMISSIONS``, ``THREADS_ENABLED``, and ``TEXT_IN_VOICE_ENABLED`` are considered not applicable because they have been rolled out entirely

The same can be seen with user flags, such as ``SPAMMER``.",False,0,MEMBER
https://api.github.com/repos/Cog-Creators/Red-DiscordBot/issues/comments/1214883392,Get rid of localized guild feature list in serverinfo,Jackenmen,6,1338407975,5,1214883392,0,1214529541,2022-08-15T10:54:46Z,"I added an exclude list.
Excluded:
- THREE_DAY_THREAD_ARCHIVE (available to everyone since forum channels private beta)
- SEVEN_DAY_THREAD_ARCHIVE (available to everyone since forum channels private beta)
- NEW_THREAD_PERMISSIONS (rolled out to everyone already)
- TEXT_IN_VOICE_ENABLED (rolled out to everyone already)
- THREADS_ENABLED (rolled out to everyone already)

> `NEWS` is given with `COMMUNITY`

I made it so `COMMUNITY` flag is present, `NEWS` is removed, does that make sense? News channels were a thing before community servers so some servers may have it without that flag.

> VIP regions can also be removed since they no longer apply.

Red doesn't have `PARTNERED` flag but it does have `VIP_REGIONS`. Legacy partners can have a higher bitrate in voice channels *without* the need for a boost level so this flag still has a meaning.

I think `ENABLED_DISCOVERABLE_BEFORE` actually means that a guild has been in Discovery at least once so it's not really a legacy flag. We could maybe consider showing it only if the guild isn't *currently* in Discovery (so when it doesn't have `DISCOVERABLE` flag)",False,0,MEMBER
https://api.github.com/repos/Cog-Creators/Red-DiscordBot/issues/comments/1214885291,Get rid of localized guild feature list in serverinfo,Kowlin,6,1338407975,6,1214885291,0,1214883392,2022-08-15T10:57:42Z,I honestly love those options and they all make sense to me.,False,0,MEMBER
https://api.github.com/repos/Cog-Creators/Red-DiscordBot/issues/comments/1515432887,Get rid of localized guild feature list in serverinfo,red-githubbot[bot],6,1338407975,7,1515432887,0,1214885291,2023-04-19T21:53:22Z,#6055 is a backport of this pull request to [Red 3.4](https://github.com/Cog-Creators/Red-DiscordBot/tree/3.4).,False,0,NONE
https://api.github.com/repos/Cog-Creators/Red-DiscordBot/issues/5836,[JSON Schema/Index] Add a new key for cog's info.json to indicate if ready for d.py 2.0/Red 3.5,madebylydia,4,1342864068,1,1342864068,0,0,2022-08-18T09:59:09Z,"### Type of feature request

API functionality, Other

### Description of the feature you're suggesting

The suggestion here implies the cogs `info.json` and Red's index.

The idea is to add a new key called for example `is_dpy_2_ready` to indicate that the bot has been updated for discord.py 2.0.
The values takes a bool, each of them representing the following:

`true`: The cog is ready for being usable after Red upgrades discord.py to `2.0`.
`false`: The cog is NOT ready for being usable with Red after it upgrades to discord.py `2.0`.
Not a boolean or not present: The status is unknown, cog should work but breakage should be expected by users.
`str`: The cog is NOT ready for being usable with Red and the contained value should be shown to users.

This new key would be available in the Red's Index.
If possible, this change should be ported too to the Twentysix's `index` cog to help users.

When installing (or even better, when loading) a cog, Red could indicate that the cog is not/may not be ready for discord.py 2.0 if the cog fails to load AND/OR the value of the key is `False` or not specified.

### Anything else?

If accepted, this suggestion should be implemented for when Red will upgrade discord.py, else there's no real point in this suggestion after then.

I am willing to create a PR for this issue.
If anyone else is interested in taking this issue, however, feel free to leave a comment.",True,0,CONTRIBUTOR
https://api.github.com/repos/Cog-Creators/Red-DiscordBot/issues/comments/1219402836,[JSON Schema/Index] Add a new key for cog's info.json to indicate if ready for d.py 2.0/Red 3.5,Dav-Git,4,1342864068,2,1219402836,0,1342864068,2022-08-18T11:56:41Z,"Why can't we use the already existing min and max bot version keys for this?

Since those aren't currently enforced we might want to add a [p]load implementation that respects the values of these keys.

I don't think we should be adding more attributes to the info.json if we can already represent the desired functionality with existing attributes.",False,0,CONTRIBUTOR
https://api.github.com/repos/Cog-Creators/Red-DiscordBot/issues/comments/1219489010,[JSON Schema/Index] Add a new key for cog's info.json to indicate if ready for d.py 2.0/Red 3.5,Vexed01,4,1342864068,3,1219489010,0,1219402836,2022-08-18T13:24:02Z,"If the approach to use existing keys is taken, I think there should be standardisation regarding how to set a max version. Should 3.5 compatibility be `3.5.99`, `3.6.0.dev0`, or maybe something like just `3.5` allowing for all 3.5 releases. I think this standadisation is especially important if this key will be incorperated with an automated 3.5 (and 3.6 etc?) compatibility flag.",False,0,CONTRIBUTOR
https://api.github.com/repos/Cog-Creators/Red-DiscordBot/issues/comments/1219743310,[JSON Schema/Index] Add a new key for cog's info.json to indicate if ready for d.py 2.0/Red 3.5,madebylydia,4,1342864068,4,1219743310,0,1219489010,2022-08-18T17:21:22Z,"> Why can't we use the already existing min and max bot version keys for this?

As of today, we can. I just think their use in this context is poor.
These keys are, in my sense, more interesting to use when it is about Red's APIs itself only (Config, Bank, and so on). The difference here being that it's about Red's dependency, and not its APIs in any sense.
This key stay vague, and I think that we need more clearance here.
Looking back of when some users asked about ""Have you guys heard of slash commands?"", I expect quite the same and some of the same kind to actually come and say ""Do you guys know if X cog support d.py? It doesn't damn load!"", this is where this key can be very useful IMO.

Also, I'm personally making this suggestion most especially for Red's Index as to indicate to users which cogs are ready and which are not.

> Since those aren't currently enforced we might want to add a [p]load implementation that respects the values of these keys.

They strongly are, but in `[p]cog install/update/...`. I guess that's what you meant? :p

> If the approach to use existing keys is taken, I think there should be standardisation regarding how to set a max version. 

Aren't they are already? (By the look of https://github.com/Cog-Creators/Red-DiscordBot/blob/V3/develop/schema/red_cog.schema.json#L30-L39)

--------

On another note, @jack1142 suggested adding a command to the downloader cog to ""check all of their installed cogs to know if they already have an update that makes them work with 3.5.""[^1].
I think it's important to add it here, but this might require a different issue to be opened.

[^1]: https://discord.com/channels/133049272517001216/718148684629540905/946374021329584148",False,0,CONTRIBUTOR
https://api.github.com/repos/Cog-Creators/Red-DiscordBot/issues/comments/1219801569,[JSON Schema/Index] Add a new key for cog's info.json to indicate if ready for d.py 2.0/Red 3.5,Flame442,4,1342864068,5,1219801569,0,1219743310,2022-08-18T18:26:00Z,"> These keys are, in my sense, more interesting to use when it is about Red's APIs itself only (Config, Bank, and so on). The difference here being that it's about Red's dependency, and not its APIs in any sense.

Then rather than a key *specific* to this update that would only be used one time, would you consider a `min/max_dpy_version` key something to satisfy this request?

I do agree with the idea to pass a partial update number to state ""all micro updates of this version"" (like passing `3.5`). While right now you *can* do `3.6.0.dev0` for the same behavior (since the first patch is almost always something trivial like the version bump) it is somewhat bad UX for a cog dev, and hard to *know* that's what to do. If this key (and the other `min/max`s) supported that functionality, I think that would be an OK solution to this problem. 

> On another note, jack suggested adding a command to the downloader cog to ""check all of their installed cogs to know if they already have an update that makes them work with 3.5.""

If the above key(s) are used, I'd be more inclined to agree with the previously discussed solution of unloading all of a user's cogs the first time they launch 3.5 (through the same system that `--no-cogs` uses, which doesn't remove them from the list of previously loaded cogs?), and messaging owners that they should *probably* run `[p]cog update` and restart the bot. That way they would get the same notice that some cogs do not support the new bot version without adding a new command which is *also* one time use for 3.5.

The other option I would agree with more is to enforce `info.json` versions in the loading code, but I personally don't like that option since it makes it borderline impossible to override a cog creator's claimed `info.json` versions in cases where you *know* it works (or works well enough) on a version not covered by the guarantees.",False,0,MEMBER
https://api.github.com/repos/space-wizards/space-station-14/issues/10706,boosts the quieter female scream,EmoGarbage404,3,1344886913,1,1344886913,0,0,2022-08-19T20:53:09Z,"<!-- The text between the arrows are comments - they will not be visible on your PR. -->
<!-- Please read these guidelines before opening your PR: https://docs.spacestation14.io/en/getting-started/pr-guideline -->

## About the PR <!-- Describe the Pull Request here. What does it change? What other things could this impact? -->
Closes #10669 
i kept it because i didn't feel like sourcing another one
**Screenshots**
<!-- If applicable, add screenshots to showcase your PR. If your PR is a visual change, add
screenshots or it's liable to be closed by maintainers. -->

**Changelog**
<!--
Here you can fill out a changelog that will automatically be added to the game when your PR is merged
There are 4 icons for changelog entries: add, remove, tweak, fix. I trust you can figure out the rest.

You can put your name after the :cl: symbol to change the name that shows in the changelog (otherwise it takes your GitHub username)
Like so: :cl: PJB

Generally, only put things in changelogs that players actually care about. Stuff like ""Refactored X system, no changes should be visible"" shouldn't be on a changelog.

For writing actual entries, don't consider the entry type suffix (e.g. add) to be ""part"" of the sentence:
bad: - add: a new tool for engineers
good: - add: added a new tool for engineers
-->
boring cl

",True,0,MEMBER
https://api.github.com/repos/space-wizards/space-station-14/issues/comments/1221193244,boosts the quieter female scream,Visne,3,1344886913,2,1221193244,0,1344886913,2022-08-20T00:54:15Z,"Here's a bunch of nice ones:
https://freesound.org/people/Volonda/sounds/439517/ (first scream, CC0)
https://freesound.org/people/CalGre/sounds/467126/ (CC0)
https://freesound.org/people/tomattka/sounds/400181/ (CC0)
https://freesound.org/people/DigestContent/sounds/449702/ (CC0)
https://freesound.org/people/XfiXy8/sounds/467283/ (CC-BY 4.0, the first scream before she breathes in)

Could maybe even implement all of them, if you feel like it. I still think the current `femalescream_3.ogg` sounds like trash, but maybe not everyone will agree.",False,0,MEMBER
https://api.github.com/repos/space-wizards/space-station-14/issues/comments/1232850739,boosts the quieter female scream,mirrorcult,3,1344886913,3,1232850739,0,1221193244,2022-08-31T12:08:18Z,i'd rather source another one tbh,False,0,CONTRIBUTOR
https://api.github.com/repos/space-wizards/space-station-14/issues/comments/1255660200,boosts the quieter female scream,EmoGarbage404,3,1344886913,4,1255660200,0,1232850739,2022-09-22T23:37:10Z,uhhh got too lazy :HECK:,False,0,MEMBER
https://api.github.com/repos/space-wizards/space-station-14/issues/10708,Content should not be using internal.,moonheart08,3,1344921209,1,1344921209,0,0,2022-08-19T21:47:45Z,"## Description
tl;dr some systems and components in Content.* are marked as internal. This makes it impossible for downstreams to use those classes in secondary modules.

SS14 has literally no business marking things internal without good reason, and ApcSystem for example should not be internal.

",True,0,CONTRIBUTOR
https://api.github.com/repos/space-wizards/space-station-14/issues/comments/1221117982,Content should not be using internal.,wrexbe,3,1344921209,2,1221117982,0,1344921209,2022-08-19T21:52:01Z,"I agree, internal doesn't make sense if it's not a library like toolbox",False,0,CONTRIBUTOR
https://api.github.com/repos/space-wizards/space-station-14/issues/comments/1221141229,Content should not be using internal.,ike709,3,1344921209,3,1221141229,0,1221117982,2022-08-19T22:37:58Z,"I tried having a go at this and it looks like it'll cause conflicts with the gamehud refactor, so I'm holding off until that's merged.",False,0,CONTRIBUTOR
https://api.github.com/repos/space-wizards/space-station-14/issues/comments/1221147014,Content should not be using internal.,wrexbe,3,1344921209,4,1221147014,0,1221141229,2022-08-19T22:49:06Z,"Just do it, I am planning on fixing the merge conflicts on that later today/tomorrow ",False,0,CONTRIBUTOR
https://api.github.com/repos/space-wizards/space-station-14/issues/10710,SanitizeMessagePeriod: Add Period at the end of sentences,tomasalves8,13,1344987191,1,1344987191,0,0,2022-08-19T23:59:55Z,"<!-- The text between the arrows are comments - they will not be visible on your PR. -->
<!-- Please read these guidelines before opening your PR: https://docs.spacestation14.io/en/getting-started/pr-guideline -->

## About the PR <!-- Describe the Pull Request here. What does it change? What other things could this impact? -->
- Creates method ``SanitizeMessagePeriod`` that adds a period at the end of sentences.

Closes #9261

**Changelog**
<!--
Here you can fill out a changelog that will automatically be added to the game when your PR is merged
There are 4 icons for changelog entries: add, remove, tweak, fix. I trust you can figure out the rest.

You can put your name after the :cl: symbol to change the name that shows in the changelog (otherwise it takes your GitHub username)
Like so: :cl: PJB

Generally, only put things in changelogs that players actually care about. Stuff like ""Refactored X system, no changes should be visible"" shouldn't be on a changelog.

For writing actual entries, don't consider the entry type suffix (e.g. add) to be ""part"" of the sentence:
bad: - add: a new tool for engineers
good: - add: added a new tool for engineers
-->",True,0,CONTRIBUTOR
https://api.github.com/repos/space-wizards/space-station-14/issues/comments/1221181956,SanitizeMessagePeriod: Add Period at the end of sentences,tomasalves8,13,1344987191,2,1221181956,0,1344987191,2022-08-20T00:10:29Z,"Dear maintainers, shall you find me worthy of the Junior Contributor role (2nd PR). I would be honored. Tomás#1110",False,0,CONTRIBUTOR
https://api.github.com/repos/space-wizards/space-station-14/issues/comments/1221191193,SanitizeMessagePeriod: Add Period at the end of sentences,Visne,13,1344987191,3,1221191193,0,1221181956,2022-08-20T00:45:19Z,I think the best way to go about this is by never adding a period if the last character is not an alphabetical character (a-z). That is assuming this is something we want in the first place (see https://github.com/space-wizards/space-station-14/issues/9261#issuecomment-1221188674).,False,0,MEMBER
https://api.github.com/repos/space-wizards/space-station-14/issues/comments/1221191728,SanitizeMessagePeriod: Add Period at the end of sentences,tomasalves8,13,1344987191,4,1221191728,0,1221191193,2022-08-20T00:48:04Z,"> I think the best way to go about this is by never adding a period if the last character is not an alphabetical character (a-z). That is assuming this is something we want in the first place (see [#9261 (comment)](https://github.com/space-wizards/space-station-14/issues/9261#issuecomment-1221188674)).

Can you give an example where you believe there should be no ponctuation?",False,0,CONTRIBUTOR
https://api.github.com/repos/space-wizards/space-station-14/issues/comments/1221195213,SanitizeMessagePeriod: Add Period at the end of sentences,Visne,13,1344987191,5,1221195213,0,1221191728,2022-08-20T01:04:42Z,"> Can you give an example where you believe there should be no ponctuation?

`""Hi there.""` should not get another period.
`(Hi there.)` should not get another period.
`Here's the thing:` should not get another period.
`**YES**` and many variations should not get a period I think, although it might not be so common.
`Hi…` should not get another period (note that … is a single character).

It's not hard to imagine that there are many other exceptions, and to me it seems like not adding a period when the sentence ends with any character that isn't a-z is the most safe.",False,0,MEMBER
https://api.github.com/repos/space-wizards/space-station-14/issues/comments/1221196788,SanitizeMessagePeriod: Add Period at the end of sentences,tomasalves8,13,1344987191,6,1221196788,0,1221195213,2022-08-20T01:12:06Z,Something like this?,False,0,CONTRIBUTOR
https://api.github.com/repos/space-wizards/space-station-14/issues/comments/1221306795,SanitizeMessagePeriod: Add Period at the end of sentences,vulppine,13,1344987191,7,1221306795,0,1221196788,2022-08-20T12:33:22Z,"This behavior should probably be tied to a cvar, so servers can choose if they want to have automatic punctuation or not.",False,0,CONTRIBUTOR
https://api.github.com/repos/space-wizards/space-station-14/issues/comments/1225206523,SanitizeMessagePeriod: Add Period at the end of sentences,wrexbe,13,1344987191,8,1225206523,0,1221306795,2022-08-24T05:21:26Z,"Not a fan.

- It's just as possible an exclamation, a question, or nothing would the appropriate thing at the end.
- It's unnecessary fluff, the period exists to separate sentences, but since each chat message is already separated, it comes across as weird. Which is why it's uncommon to see it in text messages, or on discord.
- It can changes the tone of the message, and may make it seem unfriendly
Ref: The full first page of google results say not to do it: https://www.google.com/search?q=periods+in+chat+messages
- If even a few people feel the style of how they speak shouldn't have periods, they shouldn't be forced to do it.",False,0,CONTRIBUTOR
https://api.github.com/repos/space-wizards/space-station-14/issues/comments/1225292744,SanitizeMessagePeriod: Add Period at the end of sentences,Visne,13,1344987191,9,1225292744,0,1225206523,2022-08-24T07:11:26Z,"Good arguments, I agree. But do you think that even with a CVar which is off by default it shouldn't be merged? Even taking into consideration you arguments, I can still imagine this feature being useful for HRP servers that want to enforce a serious tone.",False,0,MEMBER
https://api.github.com/repos/space-wizards/space-station-14/issues/comments/1225293800,SanitizeMessagePeriod: Add Period at the end of sentences,metalgearsloth,13,1344987191,10,1225293800,0,1225292744,2022-08-24T07:12:45Z,Are there servers that actively do this? At least in the case of detailed examine there was a precedent for it on some RP servers even if we left it turned off.,False,0,CONTRIBUTOR
https://api.github.com/repos/space-wizards/space-station-14/issues/comments/1225296090,SanitizeMessagePeriod: Add Period at the end of sentences,Visne,13,1344987191,11,1225296090,0,1225293800,2022-08-24T07:15:26Z,"I don't know, I don't play SS13 because it sucks.",False,0,MEMBER
https://api.github.com/repos/space-wizards/space-station-14/issues/comments/1225297087,SanitizeMessagePeriod: Add Period at the end of sentences,Just-a-Unity-Dev,13,1344987191,12,1225297087,0,1225296090,2022-08-24T07:16:34Z,"> Are there servers that actively do this? At least in the case of detailed examine there was a precedent for it on some RP servers even if we left it turned off.

IIRC Bay-downstreams do this such as that one SCP fork Foundation 19",False,0,CONTRIBUTOR
https://api.github.com/repos/space-wizards/space-station-14/issues/comments/1225910214,SanitizeMessagePeriod: Add Period at the end of sentences,rbertoche,13,1344987191,13,1225910214,0,1225297087,2022-08-24T15:50:40Z,"if you make a question in english without question marker, people will get you. add a period to that, and I'm not really sure, will it work out well.
not sure how and why that's not often mentioned, it seems a real conversation breaker literally
not sure how periods make things more serious, seems just more dry to me
edit take as an example:
do you
to
do you.",False,0,CONTRIBUTOR
https://api.github.com/repos/space-wizards/space-station-14/issues/comments/1232887613,SanitizeMessagePeriod: Add Period at the end of sentences,mirrorcult,13,1344987191,14,1232887613,0,1225910214,2022-08-31T12:42:26Z,cvar is false so im fine with merging. removing the changelog since this wont actually be live,False,0,CONTRIBUTOR
https://api.github.com/repos/space-wizards/space-station-14/issues/10712,Only use Bible on Mobs,tomasalves8,6,1344999650,1,1344999650,0,0,2022-08-20T00:31:14Z,"<!-- The text between the arrows are comments - they will not be visible on your PR. -->
<!-- Please read these guidelines before opening your PR: https://docs.spacestation14.io/en/getting-started/pr-guideline -->

## About the PR <!-- Describe the Pull Request here. What does it change? What other things could this impact? -->
Since ```SharedMobStateSystem.IsDead()``` returns false when mob is dead, or target isn't a mob. It was possible to use the bible on pretty much everything. Quick change to ```!SharedMobStateSystem.IsAlive()``` fixes it.

Fixes #10089",True,0,CONTRIBUTOR
https://api.github.com/repos/space-wizards/space-station-14/issues/comments/1221311397,Only use Bible on Mobs,Myctai,6,1344999650,2,1221311397,0,1344999650,2022-08-20T13:04:25Z,Stealth no changelog chaplain nerf :stuck_out_tongue:,False,0,CONTRIBUTOR
https://api.github.com/repos/space-wizards/space-station-14/issues/comments/1221313391,Only use Bible on Mobs,Just-a-Unity-Dev,6,1344999650,3,1221313391,0,1221311397,2022-08-20T13:17:06Z,How is this a chaplain nerf? At most this is a chaplain buff because they can't magically heal walls anymore.,False,0,CONTRIBUTOR
https://api.github.com/repos/space-wizards/space-station-14/issues/comments/1221313694,Only use Bible on Mobs,EmoGarbage404,6,1344999650,4,1221313694,0,1221313391,2022-08-20T13:18:48Z,it's not anything really. It's just a bugfix.,False,0,MEMBER
https://api.github.com/repos/space-wizards/space-station-14/issues/comments/1221315356,Only use Bible on Mobs,tomasalves8,6,1344999650,5,1221315356,0,1221313694,2022-08-20T13:29:08Z,Yeah I believe this behaviour wasn't intended.,False,0,CONTRIBUTOR
https://api.github.com/repos/space-wizards/space-station-14/issues/comments/1221420094,Only use Bible on Mobs,Myctai,6,1344999650,6,1221420094,0,1221315356,2022-08-20T22:37:08Z,I personally would like seeing return of chaplain's ability to bless items. It just needs distinct messages.,False,0,CONTRIBUTOR
https://api.github.com/repos/space-wizards/space-station-14/issues/comments/1221420230,Only use Bible on Mobs,EmoGarbage404,6,1344999650,7,1221420230,0,1221420094,2022-08-20T22:38:23Z,"> I personally would like seeing return of chaplain's ability to bless items. It just needs distinct messages.

that was never implemented? If someone wants to implement it properly, then they can do that. This is not the place to be discussing that though.",False,0,MEMBER
https://api.github.com/repos/fabricjs/fabric.js/issues/8181,setPositionByOrigin after use getBoundingRect Data error,tetap,5,1350256894,1,1350256894,0,0,2022-08-25T03:11:00Z,"<!-- ISSUES THAT ARE NOT BUGS OR LACK A TEST CASE WILL BE CLOSED. -->

<!-- BUG TEMPLATE -->

<!-- If you are working on a version below latest you should upgrade to latest before filing a bug report, your issue might have been resolved already -->
## Version
5.0.0

<!-- ISSUES THAT ARE NOT BUGS OR LACK A TEST CASE WILL BE CLOSED. -->
<!-- A good reproduction helps us understand better your issue, find the bug and fix it quickly so take the time to make it accurate and minimal -->
## Test Case
- [x] [Browser Issue Template](https://jsfiddle.net/Lcp2h3nv/)
- [ ] [Node Issue Template](https://codesandbox.io/s/exciting-browser-ytb701)

## Information about environment
Nodejs or browser?
Which browsers?

## Steps To Reproduce

1. 

<details><summary>Error Message & Stack Trace</summary><p>

```txt
<!-- Provide a log message if relevant -->
```
</p></details>

## Expected Behavior

## Actual Behavior

<!-- Provide screenshots/screencasts if relevant -->

",True,0,NONE
https://api.github.com/repos/fabricjs/fabric.js/issues/comments/1226785911,setPositionByOrigin after use getBoundingRect Data error,ShaMan123,5,1350256894,2,1226785911,0,1350256894,2022-08-25T05:16:21Z,follow [CONTRIBUTING](https://github.com/fabricjs/fabric.js/blob/master/CONTRIBUTING.md) and then I'll reopen,False,0,CONTRIBUTOR
https://api.github.com/repos/fabricjs/fabric.js/issues/comments/1229046401,setPositionByOrigin after use getBoundingRect Data error,ShaMan123,5,1350256894,3,1229046401,0,1226785911,2022-08-26T23:51:34Z,"probably you need to call `setCoords`
http://fabricjs.com/fabric-gotchas",False,0,CONTRIBUTOR
https://api.github.com/repos/fabricjs/fabric.js/issues/comments/1249976069,setPositionByOrigin after use getBoundingRect Data error,tetap,5,1350256894,4,1249976069,0,1229046401,2022-09-17T02:03:29Z,"> probably you need to call `setCoords` http://fabricjs.com/fabric-gotchas

I used setcoords, but it was still wrong.
My code is as follows:
`objs.setPositionByOrigin(point, 'center', 'center')
objs.setCoords()
objs.set({ dirty: true })
canvas.renderAll()
canvas.setActiveObject(objs)`

I call getBoundingRect contents later and it is wrong

![image](https://user-images.githubusercontent.com/57606461/190836229-77a09278-b57e-4dd4-bc81-a43c1ffa1edd.png)
",False,0,NONE
https://api.github.com/repos/fabricjs/fabric.js/issues/comments/1249976138,setPositionByOrigin after use getBoundingRect Data error,tetap,5,1350256894,5,1249976138,0,1249976069,2022-09-17T02:03:55Z,"This is the result of my call to left align. Its left is indeed 0, but getBoundingRect is indeed -1.77",False,0,NONE
https://api.github.com/repos/fabricjs/fabric.js/issues/comments/1249998940,setPositionByOrigin after use getBoundingRect Data error,ShaMan123,5,1350256894,6,1249998940,0,1249976138,2022-09-17T04:44:44Z,#7670 the object is on a group,False,0,CONTRIBUTOR
https://api.github.com/repos/fabricjs/fabric.js/issues/8182,chore(TS): migrate brushes,ShaMan123,11,1350681114,1,1350681114,0,0,2022-08-25T10:28:38Z,"I will migrate eraser on a separate PR
It will wait...",True,0,CONTRIBUTOR
https://api.github.com/repos/fabricjs/fabric.js/issues/comments/1227078380,chore(TS): migrate brushes,github-actions[bot],11,1350681114,2,1227078380,0,1350681114,2022-08-25T10:30:57Z,"## Code Coverage Summary
```
> fabric@5.1.0 coverage:report
> nyc report --reporter=lcov --reporter=text

-----------|---------|----------|---------|---------|-----------------------------------------------
File       | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s                             
-----------|---------|----------|---------|---------|-----------------------------------------------
All files  |   82.13 |    74.64 |   84.43 |   80.77 |                                               
 fabric.js |   82.13 |    74.64 |   84.43 |   80.77 | ...-27701,27828-27829,27851-27888,27905-28065 
-----------|---------|----------|---------|---------|-----------------------------------------------
```
",False,0,CONTRIBUTOR
https://api.github.com/repos/fabricjs/fabric.js/issues/comments/1227082709,chore(TS): migrate brushes,github-actions[bot],11,1350681114,3,1227082709,0,1227078380,2022-08-25T10:35:31Z,"## Code Coverage Summary
```
> fabric@5.1.0 coverage:report
> nyc report --reporter=lcov --reporter=text

-----------|---------|----------|---------|---------|-----------------------------------------------
File       | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s                             
-----------|---------|----------|---------|---------|-----------------------------------------------
All files  |   82.12 |     74.6 |   84.43 |   80.76 |                                               
 fabric.js |   82.12 |     74.6 |   84.43 |   80.76 | ...-27699,27826-27827,27849-27886,27903-28063 
-----------|---------|----------|---------|---------|-----------------------------------------------
```
",False,0,CONTRIBUTOR
https://api.github.com/repos/fabricjs/fabric.js/issues/comments/1227163157,chore(TS): migrate brushes,github-actions[bot],11,1350681114,4,1227163157,0,1227082709,2022-08-25T11:59:40Z,"## Code Coverage Summary
```
> fabric@5.1.0 coverage:report
> nyc report --reporter=lcov --reporter=text

-----------|---------|----------|---------|---------|-----------------------------------------------
File       | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s                             
-----------|---------|----------|---------|---------|-----------------------------------------------
All files  |   82.17 |    74.62 |   84.36 |    80.8 |                                               
 fabric.js |   82.17 |    74.62 |   84.36 |    80.8 | ...-27689,27805-27806,27827-27868,27883-28042 
-----------|---------|----------|---------|---------|-----------------------------------------------
```
",False,0,CONTRIBUTOR
https://api.github.com/repos/fabricjs/fabric.js/issues/comments/1227168077,chore(TS): migrate brushes,github-actions[bot],11,1350681114,5,1227168077,0,1227163157,2022-08-25T12:04:44Z,"## Code Coverage Summary
```
> fabric@5.1.0 coverage:report
> nyc report --reporter=lcov --reporter=text

-----------|---------|----------|---------|---------|-----------------------------------------------
File       | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s                             
-----------|---------|----------|---------|---------|-----------------------------------------------
All files  |   82.14 |    74.62 |   84.36 |   80.76 |                                               
 fabric.js |   82.14 |    74.62 |   84.36 |   80.76 | ...-27689,27805-27806,27827-27868,27883-28042 
-----------|---------|----------|---------|---------|-----------------------------------------------
```
",False,0,CONTRIBUTOR
https://api.github.com/repos/fabricjs/fabric.js/issues/comments/1227173709,chore(TS): migrate brushes,github-actions[bot],11,1350681114,6,1227173709,0,1227168077,2022-08-25T12:10:49Z,"## Code Coverage Summary
```
> fabric@5.1.0 coverage:report
> nyc report --reporter=lcov --reporter=text

-----------|---------|----------|---------|---------|-----------------------------------------------
File       | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s                             
-----------|---------|----------|---------|---------|-----------------------------------------------
All files  |   82.13 |    74.59 |   84.36 |   80.74 |                                               
 fabric.js |   82.13 |    74.59 |   84.36 |   80.74 | ...-27689,27805-27806,27827-27868,27883-28042 
-----------|---------|----------|---------|---------|-----------------------------------------------
```
",False,0,CONTRIBUTOR
https://api.github.com/repos/fabricjs/fabric.js/issues/comments/1227412120,chore(TS): migrate brushes,asturur,11,1350681114,7,1227412120,0,1227173709,2022-08-25T15:21:57Z,"I have no issue with adding initial state to a brush ( even if it can probably be done outisde the constructor ).
The point is that the brush interface as it is now does not make sense, they are way similar to objects and have this issue of starting and ending with mouse down/up.
I want to change that and i m not sure how things will translate, but in general we can assume is safe to think brushes can have options when created.",False,0,MEMBER
https://api.github.com/repos/fabricjs/fabric.js/issues/comments/1227417493,chore(TS): migrate brushes,ShaMan123,11,1350681114,8,1227417493,0,1227412120,2022-08-25T15:25:44Z,"I don't mind waiting and returning to it later.
I want to hear more of your thoughts regarding brushes",False,0,CONTRIBUTOR
https://api.github.com/repos/fabricjs/fabric.js/issues/comments/1227453783,chore(TS): migrate brushes,github-actions[bot],11,1350681114,9,1227453783,0,1227417493,2022-08-25T15:47:19Z,"## Code Coverage Summary
```
> fabric@5.1.0 coverage:report
> nyc report --reporter=lcov --reporter=text

-----------|---------|----------|---------|---------|-----------------------------------------------
File       | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s                             
-----------|---------|----------|---------|---------|-----------------------------------------------
All files  |   82.14 |    74.62 |   84.36 |   80.76 |                                               
 fabric.js |   82.14 |    74.62 |   84.36 |   80.76 | ...-27689,27805-27806,27827-27868,27883-28042 
-----------|---------|----------|---------|---------|-----------------------------------------------
```
",False,0,CONTRIBUTOR
https://api.github.com/repos/fabricjs/fabric.js/issues/comments/1227481712,chore(TS): migrate brushes,ShaMan123,11,1350681114,10,1227481712,0,1227453783,2022-08-25T16:12:16Z,let's merge this. enough changes for one iteration,False,0,CONTRIBUTOR
https://api.github.com/repos/fabricjs/fabric.js/issues/comments/1228158574,chore(TS): migrate brushes,asturur,11,1350681114,11,1228158574,0,1227481712,2022-08-26T07:36:30Z,"yes this will get merge with no additional changes today.
Regrding brushes, i would like a brush to expose an even handler for every mouse or touch event.
down, click, up, dblclick and so on.
Those events will get executed as today before standard canvas logic, and will by default block the event from running the canvas logic afterward, but is optional to the dev to do so.
The brush will be in control to terminate its own lifecycle on one of those events.

This should let current brushes work as they are working today, but would also allow brushes to work on clicks and collect points like to build a polygon and end when the polygon is closed or end on dblclick.

It doesn't change much but offer so much more flexibility.",False,0,MEMBER
https://api.github.com/repos/fabricjs/fabric.js/issues/comments/1228198599,chore(TS): migrate brushes,ShaMan123,11,1350681114,12,1228198599,0,1228158574,2022-08-26T08:17:07Z,"sounds great
and even not block events (with a return value) so things can run together creating complex UX.
This can be leveraged to many things like you suggested and a custom pointer for example or a laser.",False,0,CONTRIBUTOR
https://api.github.com/repos/fabricjs/fabric.js/issues/8183,chore(TS): `ElementsParser` => `parser/ElementsParser`,ShaMan123,4,1350808770,1,1350808770,0,0,2022-08-25T12:18:36Z,move under `parser` and update some imports,True,0,CONTRIBUTOR
https://api.github.com/repos/fabricjs/fabric.js/issues/comments/1227184540,chore(TS): `ElementsParser` => `parser/ElementsParser`,github-actions[bot],4,1350808770,2,1227184540,0,1350808770,2022-08-25T12:21:22Z,"## Code Coverage Summary
```
> fabric@5.1.0 coverage:report
> nyc report --reporter=lcov --reporter=text

-----------|---------|----------|---------|---------|-----------------------------------------------
File       | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s                             
-----------|---------|----------|---------|---------|-----------------------------------------------
All files  |   82.09 |    74.54 |   84.45 |   80.68 |                                               
 fabric.js |   82.09 |    74.54 |   84.45 |   80.68 | ...,27452,27510,27520-27564,27672,27759,27963 
-----------|---------|----------|---------|---------|-----------------------------------------------
```
",False,0,CONTRIBUTOR
https://api.github.com/repos/fabricjs/fabric.js/issues/comments/1227452597,chore(TS): `ElementsParser` => `parser/ElementsParser`,github-actions[bot],4,1350808770,3,1227452597,0,1227184540,2022-08-25T15:46:20Z,"## Code Coverage Summary
```
> fabric@5.1.0 coverage:report
> nyc report --reporter=lcov --reporter=text

-----------|---------|----------|---------|---------|-----------------------------------------------
File       | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s                             
-----------|---------|----------|---------|---------|-----------------------------------------------
All files  |   82.14 |    74.57 |   84.45 |   80.74 |                                               
 fabric.js |   82.14 |    74.57 |   84.45 |   80.74 | ...,27452,27510,27520-27564,27672,27759,27963 
-----------|---------|----------|---------|---------|-----------------------------------------------
```
",False,0,CONTRIBUTOR
https://api.github.com/repos/fabricjs/fabric.js/issues/comments/1228242795,chore(TS): `ElementsParser` => `parser/ElementsParser`,github-actions[bot],4,1350808770,4,1228242795,0,1227452597,2022-08-26T08:57:43Z,"## Code Coverage Summary
```
> fabric@5.1.0 coverage:report
> nyc report --reporter=lcov --reporter=text

-----------|---------|----------|---------|---------|-----------------------------------------------
File       | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s                             
-----------|---------|----------|---------|---------|-----------------------------------------------
All files  |   82.13 |    74.65 |   84.34 |   80.74 |                                               
 fabric.js |   82.13 |    74.65 |   84.34 |   80.74 | ...-27672,27788-27789,27810-27851,27866-28025 
-----------|---------|----------|---------|---------|-----------------------------------------------
```
",False,0,CONTRIBUTOR
https://api.github.com/repos/fabricjs/fabric.js/issues/comments/1228287999,chore(TS): `ElementsParser` => `parser/ElementsParser`,asturur,4,1350808770,5,1228287999,0,1228242795,2022-08-26T09:43:24Z,i m going to make a pr to remove that util/index.ts,False,0,MEMBER
https://api.github.com/repos/fabricjs/fabric.js/issues/8184,dep(): fabric.console,ShaMan123,3,1350811964,1,1350811964,0,0,2022-08-25T12:21:21Z,"remove dead code fabric.console

#8183 removes the last remaining usage",True,0,CONTRIBUTOR
https://api.github.com/repos/fabricjs/fabric.js/issues/comments/1227556718,dep(): fabric.console,github-actions[bot],3,1350811964,2,1227556718,0,1350811964,2022-08-25T17:24:22Z,"## Code Coverage Summary
```
> fabric@5.1.0 coverage:report
> nyc report --reporter=lcov --reporter=text

-----------|---------|----------|---------|---------|-----------------------------------------------
File       | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s                             
-----------|---------|----------|---------|---------|-----------------------------------------------
All files  |    82.1 |    74.58 |   84.45 |   80.69 |                                               
 fabric.js |    82.1 |    74.58 |   84.45 |   80.69 | ...,27440,27498,27508-27552,27660,27747,27951 
-----------|---------|----------|---------|---------|-----------------------------------------------
```
",False,0,CONTRIBUTOR
https://api.github.com/repos/fabricjs/fabric.js/issues/comments/1228222716,dep(): fabric.console,asturur,3,1350811964,3,1228222716,0,1227556718,2022-08-26T08:39:10Z,"this is fine,
if we ever need special logging we can add it.",False,0,MEMBER
https://api.github.com/repos/fabricjs/fabric.js/issues/comments/1228223429,dep(): fabric.console,ShaMan123,3,1350811964,4,1228223429,0,1228222716,2022-08-26T08:39:51Z,bye bye then,False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/10021,Merge 2.14.x into 3.0.x,derrabus,4,1356205849,1,1356205849,0,0,2022-08-30T19:27:42Z,,True,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/1232152644,Merge 2.14.x into 3.0.x,SenseException,4,1356205849,2,1232152644,0,1356205849,2022-08-30T20:49:08Z,Are the coding styles supposed to be fixed in another PR or in this PR for the upmerge?,False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/1232159512,Merge 2.14.x into 3.0.x,greg0ire,4,1356205849,3,1232159512,0,1232152644,2022-08-30T20:56:41Z,"I think PRs have been merged that passed the build before the CS PR was merged.

UPD: actually no, all 3 branches pass the CS build. This means the failures happen because of the difference in config between branch (3.0.x has PHP-8.1-specific rules)",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/1232172226,Merge 2.14.x into 3.0.x,SenseException,4,1356205849,4,1232172226,0,1232159512,2022-08-30T21:10:24Z,"> Error: Usage of short nullable type hint in ""?Animal"" is disallowed.",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/1232214581,Merge 2.14.x into 3.0.x,derrabus,4,1356205849,5,1232214581,0,1232172226,2022-08-30T22:02:39Z,I've fixed the CS issue while merging.,False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/10022,"AnnotationReader unable to parse annotations if the comment field contains an accented character (é, è, ...)",jkazal,6,1357079036,1,1357079036,0,0,2022-08-31T09:41:09Z,"### Bug Report

|    Q        |   A
|------------ | ------
| BC Break    | no
| Version     | 2.9.6

#### Summary

Sometimes `AnnotationReader` fails to parse the annotations of a given class, if that class's entity definition contains PHPDoc comments that include accented characters.

I am filing this as a bug report rather than an upgrade issue because I don't know if it did the same thing before the upgrade as the bug scenario wasn't applicable previously.

#### Current behavior

After upgrading my VM to PHP 7.4, Doctrine returned errors like this for every entity:
```
class ""Site\Entities\MyEntity"" sub class of ""Repo\Entity"" is not a valid entity or mapped super class. 
```
However both classes had the correct annotations, but debugging showed me that Doctrine's `AnnotationReader` failed to get the annotations from my `MyEntity` class.

After debugging for some time I finally found the source of the problem: 
```
/**
 * class my_entity
 *
 * @ORM\Entity
 * @ORM\Table(name=""...."")
 *
 * @author John La classe hérite de \Repo\Entity
 */
```
`AnnotationReader` was unable to read the annotations `Entity` and `Table` because of the accented character in `hérite`. By changing it to a normal `e`, I can get the annotations just fine.

I imagine this is unintended.

#### How to reproduce

See above

For the sake of information, my entity class files are encoded in `windows-1252`.

#### Expected behavior

I think having PHPDoc comments like `@author` that contain accented characters should not impact the way `AnnotationReader` parses a class's annotation.
",True,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/1232722755,"AnnotationReader unable to parse annotations if the comment field contains an accented character (é, è, ...)",greg0ire,6,1357079036,2,1232722755,0,1357079036,2022-08-31T09:53:16Z,Can you please post a [stack trace](https://symfony.com/doc/current/contributing/code/stack_trace.html)?,False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/1232842603,"AnnotationReader unable to parse annotations if the comment field contains an accented character (é, è, ...)",jkazal,6,1357079036,3,1232842603,0,1232722755,2022-08-31T12:00:09Z,"I'm not using Symfony so I can't give you a Symfony stack trace. I can give you the Fatal Error trace:

```
Fatal error: Uncaught Doctrine\ORM\Mapping\MappingException: Class ""LIB\MyLibrary\Entities\library"" sub class of ""DBAL\Entity"" is not a valid entity or mapped super class. in /doctrine-directory/Mapping/MappingException.php:371 

Stack trace: 
#0 /doctrine-directory/Mapping/Driver/AnnotationDriver.php(101): Doctrine\ORM\Mapping\MappingException::classIsNotAValidEntityOrMappedSuperClass('LIB\\MyLib...')
#1 /doctrine-directory/Mapping/ClassMetadataFactory.php(144): Doctrine\ORM\Mapping\Driver\AnnotationDriver->loadMetadataForClass('LIB\\MyLib...', Object(Doctrine\ORM\Mapping\ClassMetadata)) 
#2 in /doctrine-directory/Mapping/MappingException.php on line 371
```",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/1232866637,"AnnotationReader unable to parse annotations if the comment field contains an accented character (é, è, ...)",jkazal,6,1357079036,4,1232866637,0,1232842603,2022-08-31T12:23:13Z,"In addition, it seems the issue is fixed by switching the class file encoding to UTF-8 for the affected Entities.",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/1232909132,"AnnotationReader unable to parse annotations if the comment field contains an accented character (é, è, ...)",derrabus,6,1357079036,5,1232909132,0,1232866637,2022-08-31T13:02:08Z,"Well, what encoding did you use previously? That would be an important piece of information to track down the issue. That being said, I'm not really keen on fixing the Doctrine Annotations library for non-UTF-8 encodings.",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/1232911802,"AnnotationReader unable to parse annotations if the comment field contains an accented character (é, è, ...)",jkazal,6,1357079036,6,1232911802,0,1232909132,2022-08-31T13:04:30Z,"As mentioned in the OP:

> For the sake of information, my entity class files are encoded in windows-1252.

That being said, if UTF8 is the only encoding supported by Doctrine Annotations that's also fine, however I couldn't find any info regarding that. Feel free to close the issue if that's the case",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/1232931430,"AnnotationReader unable to parse annotations if the comment field contains an accented character (é, è, ...)",derrabus,6,1357079036,7,1232931430,0,1232911802,2022-08-31T13:21:24Z,"> As mentioned in the OP:
> 
> > For the sake of information, my entity class files are encoded in windows-1252.

Oh sorry, I missed that. 🙈 

> That being said, if UTF8 is the only encoding supported by Doctrine Annotations that's also fine, however I couldn't find any info regarding that. Feel free to close the issue if that's the case

If converting those files to UTF-8 works for you, I'd be in favor of closing the issue. Doctrine Annotations don't have a bright future, now that PHP has native attributes. Fixing this issue is probably not worth the effort.",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/10031,Hydrating  with `enumType` as array gives *string* instead of Enum (DQL with join),mzk,4,1363478800,1,1363478800,0,0,2022-09-06T15:38:32Z,"### Bug Report

When I have a query:
```
return $this->entityManager->createQuery('SELECT o.orderStatus FROM Entity\Order o')
            ->getResult(AbstractQuery::HYDRATE_ARRAY);
```
Then `$result[0]['orderStatus']` is instance of BackendEnum OrderStatus.

But when I have a query:
```
return $this->entityManager->createQuery('SELECT o FROM Entity\Order o')
            ->getResult(AbstractQuery::HYDRATE_ARRAY);
```
Then `$result[0]['orderStatus']` is simple string.


Our Order entity field:
```
    #[Column(type: Types::STRING, nullable: false, enumType: OrderStatus::class, options: ['charset' => 'utf8', 'collation' => 'utf8_unicode_ci'])]
    private OrderStatus $orderStatus;
```

|    Q        |   A
|------------ | ------
| BC Break    | no
| Version     | 2.13.1

#### Summary

It should be the same result for both cases. 

#### Current behavior

`SELECT o` retuns string, `SELECT o.orderStatus` returns the BackendEnum

#### How to reproduce

Use entity as [described](https://www.doctrine-project.org/2022/01/11/orm-2.11.html) and fetch from query builder as an array.

#### Expected behavior
`SELECT o` returns an array that contains BackendEnum.

for ref: https://github.com/doctrine/orm/issues/9622

",True,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/1243053073,Hydrating  with `enumType` as array gives *string* instead of Enum (DQL with join),michnovka,4,1363478800,2,1243053073,0,1363478800,2022-09-11T22:11:37Z,"I generally try to avoid Array Hydration, but I agree that this should work nonetheless. If you use standard object hydration (default) is there any issue?",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/1243304246,Hydrating  with `enumType` as array gives *string* instead of Enum (DQL with join),mzk,4,1363478800,3,1243304246,0,1243053073,2022-09-12T07:05:32Z,The default object hydration works fine.,False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/1243772355,Hydrating  with `enumType` as array gives *string* instead of Enum (DQL with join),janedbal,4,1363478800,4,1243772355,0,1243304246,2022-09-12T13:49:01Z,"The biggest issue I see here is the same reasoning I wrote in #9622:

> **Migrating from enums used as custom types to this native form is impossible as it behaves differently**",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/1254614209,Hydrating  with `enumType` as array gives *string* instead of Enum (DQL with join),derrabus,4,1363478800,5,1254614209,0,1243772355,2022-09-22T07:04:37Z,Duplicate of #9947,False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/10035,Optimize Object Hydration performance on large result sets,tucksaun,8,1367952424,1,1367952424,0,0,2022-09-09T14:56:26Z,"Hi folks!

While assessing a client's project performance I found some optimizations regarding the ORM hydration process that improves speed when working with large result sets and collections.

<details>
 <summary>Expand to get some context on how we reached this.</summary>
The context is about online carts on a B2B e-commerce platform with a high number of items and complex personalization logic.
We reached the point in the optimization process where most of the time was spent in the ORM (after serialization) when fetching a cart.

This makes sense because of the volume and the logic at stake.
Denormalization or caching does not make sense for us because of the low read/write ratio and the business logic involved so we first went with the 2-step hydration technic.
</details>

While analyzing profiling results we more or less came to the same conclusion as #8390: the hydration process converts data over and over again even if the entity is already hydrated>

But after trying to work around performance for specific DBAL types that were costly to convert (namely Symfony's UUID and Dunglas's JSON document) and digging deeper into profiles I concluded something could be done directly in the Hydrator for the benefit of everyone instead of writing our specific optimized hydrator:
![Screenshot 2022-09-08 at 17 51 38](https://user-images.githubusercontent.com/870118/189378440-36c194aa-38d3-43c4-88b5-f40f67b70294.png)


This PR acts according to one consideration: most parts of the hydration process are not slow per se but are repeated for every row and column. By applying some small optimizations, moving some code before the first iteration, or some code at the very last moment, we can improve the overall process.
The more rows and columns, the more the process is accelerated.

For examples:
- type conversion can be costly but only identifiers are required to determine if the entity is already hydrated or not: the actual data can be converted later on in the process only if needed using only the columns required for the current entity (not the data for other entities in relations);
- we can prepare the mapping information in a way that prevents repeating some part of the process thousands of times;
- and we can avoid using the reflection to retrieve relations properties if they are available in another mapping.

With this patch, I manage to reach the following results:

| Metric | Before | After | Notes |
|-----------------------------|--------|-------|----------------|
|`->getQuery()->getResult()`| 726.39 ms | 358.67 ms | -51%, best of 20 iterations, query result cache enabled, 11 826 entities created
|`Doctrine\ORM\PersistentCollection::*`| 164 634 | 77 345
|`TypedNoDefaultReflectionProperty::getValue` | 162 770  | 125 669
|`Doctrine\ORM\Internal\Hydration\AbstractHydrator::resultSetMapping` | 441 742 | 19 745
|`Doctrine\ORM\Internal\Hydration\AbstractHydrator::hydrateColumnInfo`| 946 970 | 337
|`Doctrine\DBAL\Types\IntegerType::convertToPHPValue`| 406 982 | 279 366
|`Doctrine\DBAL\Types\StringType::convertToPHPValue`| 181 207 | 63 473
|`Doctrine\DBAL\Types\BooleanType::convertToPHPValue`| 75 163 | 7 865
|`Doctrine\DBAL\Types\DateTimeImmutableType::convertToPHPValue`| 25 118 |  789
|`App\DBAL\Types\UuidType::convertToPHPValue`| 13 056 | 413

I hope we can manage to get this work so that everyone enjoys better performance 🤗
If you are willing to move in this direction, we can probably adapt ArrayHydrator the same way.",True,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/1251392298,Optimize Object Hydration performance on large result sets,beberlei,8,1367952424,2,1251392298,0,1367952424,2022-09-19T18:29:36Z,"Hey @tucksaun, this looks like fantastic work! Thank you! It will take some time to review the PR through as its touching essentially everything about hydrators, so I am not sure when we will get to it at this time.",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/1256161910,Optimize Object Hydration performance on large result sets,sips-richard,8,1367952424,3,1256161910,0,1251392298,2022-09-23T12:42:16Z,"I found this PR in relation to an issue we've been having when hydrating a graph with a couple left joins. Specifically that Doctrine calls convertToPHPValue() on all the NULL values for each column in any empty left join records, prior to hydrating the entities and then discarding those empty records. We noticed this because we have a custom data type that throws an exception if it encounters a NULL (the fix for now was to eliminate the check).

But I was wondering whether it is necessary for the calls to convertToPHPValue() up front when ultimately the record ID might be NULL and the empty data set gets thrown in the trash, or could the code could be reworked to only convert the values for columns belonging to entities that will actually be hydrated?
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/1259980933,Optimize Object Hydration performance on large result sets,tucksaun,8,1367952424,4,1259980933,0,1256161910,2022-09-27T19:55:29Z,"> Hey @tucksaun, this looks like fantastic work! Thank you! It will take some time to review the PR through as its touching essentially everything about hydrators, so I am not sure when we will get to it at this time.

@beberlei sure, I understand as this is quite a change.
If it can help you: I tried to keep a ""logical"" order in commits so that maybe it is easier to follow.
Also, feel free to ping me if you want to chat about it if you want.

I will try to maintain this PR as up-to-date as possible in the meantime.
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/1259985649,Optimize Object Hydration performance on large result sets,tucksaun,8,1367952424,5,1259985649,0,1259980933,2022-09-27T20:00:53Z,"> I found this PR in relation to an issue we've been having when hydrating a graph with a couple left joins. Specifically that Doctrine calls convertToPHPValue() on all the NULL values for each column in any empty left join records, prior to hydrating the entities and then discarding those empty records. We noticed this because we have a custom data type that throws an exception if it encounters a NULL (the fix for now was to eliminate the check).
> 
> But I was wondering whether it is necessary for the calls to convertToPHPValue() up front when ultimately the record ID might be NULL and the empty data set gets thrown in the trash, or could the code could be reworked to only convert the values for columns belonging to entities that will actually be hydrated?

@sips-richard I would say that the hydrator has to maintain the call to `convertToPHPValue` because the logic of what is done with a NULL value in the database might be reflected differently in PHP depending on the needs and the type implementation.
But if I got your problem correctly, the number of calls might be lower with this patch.
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/1307766695,Optimize Object Hydration performance on large result sets,greg0ire,8,1367952424,6,1307766695,0,1259985649,2022-11-08T20:06:38Z,Hi! `git rebase --exec vendor/bin/phpcbf` should fix some (but not all) cs issues :),False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/1307796775,Optimize Object Hydration performance on large result sets,tucksaun,8,1367952424,7,1307796775,0,1307766695,2022-11-08T20:37:28Z,"@greg0ire I though I already fixed them all and only casually rebased this PR today so thank you for the heads up about he CS issues.
They should be fixed now.",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/1308883181,Optimize Object Hydration performance on large result sets,sips-richard,8,1367952424,8,1308883181,0,1307796775,2022-11-09T14:53:02Z,"> > I found this PR in relation to an issue we've been having when hydrating a graph with a couple left joins. Specifically that Doctrine calls convertToPHPValue() on all the NULL values for each column in any empty left join records, prior to hydrating the entities and then discarding those empty records. We noticed this because we have a custom data type that throws an exception if it encounters a NULL (the fix for now was to eliminate the check).
> > But I was wondering whether it is necessary for the calls to convertToPHPValue() up front when ultimately the record ID might be NULL and the empty data set gets thrown in the trash, or could the code could be reworked to only convert the values for columns belonging to entities that will actually be hydrated?
> 
> @sips-richard I would say that the hydrator has to maintain the call to `convertToPHPValue` because the logic of what is done with a NULL value in the database might be reflected differently in PHP depending on the needs and the type implementation. But if I got your problem correctly, the number of calls might be lower with this patch.

@tucksaun Absolutely this will speed up our code, but I will try to clarify on our problem scenario because I think a change in the internals might be beneficial here.

Our ORM query included several left joins. Internally Doctrine was passing all the null values for any non-existent left join entities to the convertToPHPValue() method and only determining afterward that there was no relationship and then throwing these values away.

The `convertToPHPValue` method on the type for one of our columns did not permit null values and would throw an exception (because this would never happen in normal operation), but because Doctrine is hydrating null values for the empty left joins it was.

**My question therefore is:** can the logic be reworked in such a way that Doctrine could determine whether or not the ID columns represent a joined entity or an empty left join *up front*, prior to any hydration.

It would save a lot of function calls where there are empty left joins for a start.",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/1328122681,Optimize Object Hydration performance on large result sets,NoiseByNorthwest,8,1367952424,9,1328122681,0,1308883181,2022-11-26T22:14:48Z,"It looks very close to the issue I've described here https://github.com/doctrine/orm/issues/8390
And I've shared a custom hydrator which fixes the useless ""repeated rows hydration"" with a simple caching logic.

Does my workaround make sense ? Should it be implemented into ORM ?",False,0,NONE
https://api.github.com/repos/microsoft/vscode/issues/163785,Running `code.sh` script during container setup results in an error,Voodu,3,1410541739,1,1410541739,0,0,2022-10-16T16:30:33Z,"<!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- 🕮 Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!-- 🔎 Search existing issues to avoid creating duplicates. -->
<!-- 🧪 Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!-- 💡 Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->
<!-- 🔧 Launch with `code --disable-extensions` to check. -->

- VS Code Version:
```
Version: 1.73.0-insider (user setup)
Commit: 7ef8e6b87a2a5a25ba1ef946bd1640ca3510956c
Date: 2022-10-14T05:17:07.227Z
Electron: 19.0.17
Chromium: 102.0.5005.167
Node.js: 16.14.2
V8: 10.2.154.15-electron.0
OS: Windows_NT x64 10.0.22623
Sandboxed: Yes
```
- OS Version: Windows 11 Pro Version 10.0.22623 Build 22623 (Insider, Beta channel)


The problem is related to the container setup. I tried setting up my environment using all three approaches mentioned in [the tutorial](https://github.com/microsoft/vscode/blob/main/.devcontainer/README.md) and all of them ended up with an error shown below.

Additional information:
- For local container setup I used the latest Docker for Windows (4.12.0) with WSL 2 backend
  - I have 32GB RAM and i7-11370 with 4/8 CPUs, but I have no idea how WSL manages those
- For Codespaces + browser and Codespaces + local VSCode I used the default size
- To try out the Codespaces,  I forked the repo in a Codespaces-enabled organization
- `yarn install` seems to work okay
- tried everything above with the latest main https://github.com/microsoft/vscode/commit/6455bf1608dfa1b955717f66295f0f9200db0f73

## Steps to Reproduce:

1. Follow the [tutorial for container setup](https://github.com/microsoft/vscode/blob/main/.devcontainer/README.md) (any version)
2. At the ""Try it"" step and executing `bash scripts/code.sh` the following error appears:
```
@Voodu ➜ /workspaces/vscode $ bash scripts/code.sh
yarn run v1.22.19
$ node build/lib/electron
Done in 0.20s.
[15:38:01] Synchronizing built-in extensions...
[15:38:01] You can manage built-in extensions with the --builtin flag
[15:38:01] [github] ms-vscode.js-debug-companion@1.0.18 ✔︎
[15:38:02] [github] ms-vscode.js-debug@1.72.0 ✔︎
[15:38:02] [github] ms-vscode.vscode-js-profile-table@1.0.3 ✔︎
[27369:1016/153802.254015:WARNING:bluez_dbus_manager.cc(248)] Floss manager not present, cannot set Floss enable/disable.
[27456:1016/153802.360016:ERROR:gl_surface_egl.cc(804)] No suitable EGL configs found.
[27456:1016/153802.360169:ERROR:gl_context_egl.cc(136)] eglGetConfigAttrib failed with error EGL_BAD_CONFIG
libva error: vaGetDriverNameByIndex() failed with unknown libva error, driver_name = (null)
[27456:1016/153802.362121:ERROR:gl_surface_egl.cc(804)] No suitable EGL configs found.
[27456:1016/153802.362228:ERROR:gl_surface_egl.cc(2250)] eglCreatePbufferSurface failed with error EGL_BAD_CONFIG
[27456:1016/153802.362286:ERROR:gpu_info_collector.cc(80)] gl::GLContext::CreateOffscreenGLSurface failed
[27456:1016/153802.362334:ERROR:gpu_info_collector.cc(342)] Could not create surface for info collection.
[27456:1016/153802.362383:ERROR:gpu_init.cc(86)] CollectGraphicsInfo failed.
[27456:1016/153802.388392:ERROR:viz_main_impl.cc(186)] Exiting GPU process due to errors during initialization
[27511:1016/153802.496773:ERROR:gl_surface_egl.cc(804)] No suitable EGL configs found.
[27511:1016/153802.496909:ERROR:gl_context_egl.cc(136)] eglGetConfigAttrib failed with error EGL_BAD_CONFIG
libva error: vaGetDriverNameByIndex() failed with unknown libva error, driver_name = (null)
[27511:1016/153802.497960:ERROR:gl_surface_egl.cc(804)] No suitable EGL configs found.
[27511:1016/153802.498032:ERROR:gl_surface_egl.cc(2250)] eglCreatePbufferSurface failed with error EGL_BAD_CONFIG
[27511:1016/153802.498083:ERROR:gpu_info_collector.cc(80)] gl::GLContext::CreateOffscreenGLSurface failed
[27511:1016/153802.498143:ERROR:gpu_info_collector.cc(342)] Could not create surface for info collection.
[27511:1016/153802.498195:ERROR:gpu_init.cc(86)] CollectGraphicsInfo failed.
[27511:1016/153802.499923:ERROR:viz_main_impl.cc(186)] Exiting GPU process due to errors during initialization
libva error: vaGetDriverNameByIndex() failed with unknown libva error, driver_name = (null)
[27561:1016/153802.599881:WARNING:sandbox_linux.cc(376)] InitializeSandbox() called with multiple threads in process gpu-process.
[27561:1016/153802.603359:ERROR:gpu_memory_buffer_support_x11.cc(44)] dri3 extension not supported.
[27369:1016/153804.299486:INFO:CONSOLE(252)] ""[uncaught exception]: Error: [object Event]"", source: vscode-file://vscode-app/workspaces/vscode/out/bootstrap-window.js (252)
[27369:1016/153804.299543:INFO:CONSOLE(255)] ""Error: [object Event]
    at Object.ensureError (vscode-file://vscode-app/workspaces/vscode/out/vs/loader.js:256:22)
    at ModuleManager._createLoadError (vscode-file://vscode-app/workspaces/vscode/out/vs/loader.js:1508:33)
    at ModuleManager._onLoadError (vscode-file://vscode-app/workspaces/vscode/out/vs/loader.js:1519:30)
    at loadNextPath (vscode-file://vscode-app/workspaces/vscode/out/vs/loader.js:1665:27)
    at Object.errorback (vscode-file://vscode-app/workspaces/vscode/out/vs/loader.js:1685:25)
    at OnlyOnceScriptLoader.triggerErrorback (vscode-file://vscode-app/workspaces/vscode/out/vs/loader.js:631:36)
    at vscode-file://vscode-app/workspaces/vscode/out/vs/loader.js:618:151
    at HTMLScriptElement.errorEventListener (vscode-file://vscode-app/workspaces/vscode/out/vs/loader.js:654:17)"", source: vscode-file://vscode-app/workspaces/vscode/out/bootstrap-window.js (255)
```
",True,0,NONE
https://api.github.com/repos/microsoft/vscode/issues/comments/1280764933,Running `code.sh` script during container setup results in an error,yume-chan,3,1410541739,2,1280764933,0,1410541739,2022-10-17T12:15:43Z,I have also reported a similar issue microsoft/vscode-remote-release/issues/7296,False,0,CONTRIBUTOR
https://api.github.com/repos/microsoft/vscode/issues/comments/1280867653,Running `code.sh` script during container setup results in an error,Voodu,3,1410541739,3,1280867653,0,1280764933,2022-10-17T13:32:17Z,"I guess that might be a duplicate then. I'll leave the decision to the maintainers, though, as I don't know if it's the exact same problem",False,0,NONE
https://api.github.com/repos/microsoft/vscode/issues/comments/1281071026,Running `code.sh` script during container setup results in an error,lramos15,3,1410541739,4,1281071026,0,1280867653,2022-10-17T15:36:48Z,I'll mark it as a duplicate for now since Christof is the right person and they sound like the same problem.,False,0,MEMBER
https://api.github.com/repos/microsoft/vscode/issues/163788,Reduce Reliance on Keybindings - Pin Commands,oaahmad,3,1410602509,1,1410602509,0,0,2022-10-16T19:55:23Z,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->

## Summary of Problem

The VSCode team has put a lot of effort into making the product keyboard-accessible (great work). However, there is work to do for users who can't effectively memorize several keybindings. The general response to someone wanting a quick way to perform action x is they should create a keybinding for it. I understand why that is the response, but I feel like that ignores a large class of users that struggle to memorize all those keybindings. I also imagine that users may have a memory impairment that makes this especially difficult. I don't think that is far-fetched given millions of people use VSCode. In either case, I consider this an accessibility issue.

## General Solution (Pin Commands)

I think the single biggest improvement the team can make in this regard is to allow pinning commands (via the command palette). Another user opened an issue for this many years ago (can't find it now), but I wanted to propose it here again for two reasons:
1) That other issue lacked any context for why it is important (I want to propose it in the larger context of making VSCode accessible for users who can't memorize many keybindings)
2) At that time, there were no plans to allow pinning quick pick items anywhere. Now, we can pin tasks and recent terminal commands.

The current workaround is to search for the command you want, but this is problematic for two reasons:
1) It is more time consuming to do it this way
2) I often just forget what the command is specifically called. For example, I often type ""collapse"", then spend several seconds trying to remember what the command is actually called (""Fold All"").

I can think of other ways to make specific things easier in VSCode without keybindings such as:
* Allow right clicking a code folding icon to the left of an editor (or anywhere on the column where code folding icons appear) to show a menu with the following: ""Fold All"", ""Unfold All""
* Allow right clicking on a line number to the left of the editor to show the ""type a line number to navigate to"" dialog (trying to click the ""Ln X, ColY"" status bar button is annoying for a few reasons I won't enumerate)

However, changes like the above just aren't as necessary if we can pin commands. I still encourage the VSCode team to consider the above and any other changes to help users who can't effectively rely on keybindings for everything. However, pinning commands should be the priority.

Think of all the times a user has opened an issue that is just ""I want an easier / more efficient way to do X"". Usually those issues are just closed with ""make a keybinding"". Most of these users are probably already aware that they can make a keybinding, but don't want to for whatever reason. Imagine having to deal with far fewer of those issues because users can now just pin that command.

Thank you.",True,0,NONE
https://api.github.com/repos/microsoft/vscode/issues/comments/1281556003,Reduce Reliance on Keybindings - Pin Commands,daviddossett,3,1410602509,2,1281556003,0,1410602509,2022-10-17T22:07:24Z,@TylerLeonhardt did pinned quick pick items ever land? And have we considered this for the command palette? ,False,0,CONTRIBUTOR
https://api.github.com/repos/microsoft/vscode/issues/comments/1288130056,Reduce Reliance on Keybindings - Pin Commands,TylerLeonhardt,3,1410602509,3,1288130056,0,1281556003,2022-10-23T14:49:39Z,/duplicate https://github.com/microsoft/vscode/issues/163509,False,0,MEMBER
https://api.github.com/repos/microsoft/vscode/issues/comments/1288130183,Reduce Reliance on Keybindings - Pin Commands,VSCodeTriageBot,3,1410602509,4,1288130183,0,1288130056,2022-10-23T14:50:08Z,"Thanks for creating this issue! We figured it's covering the same as another one we already have. Thus, we closed this one as a duplicate. You can search for [similar existing issues](https://github.com/microsoft/vscode/issues?utf8=%E2%9C%93&q=is%3Aopen+is%3Aissue+). See also our [issue reporting guidelines](https://aka.ms/vscodeissuereporting).

Happy Coding!",False,0,COLLABORATOR
https://api.github.com/repos/microsoft/vscode/issues/163789,Terminal: Focus Terminal Tabs view keybinding appears dead/non-working.,nzwart,5,1410613621,1,1410613621,0,0,2022-10-16T20:34:07Z,"I'm on macOS 12.6 running VS Code version 1.72.2 (Universal) and after a recent update, the ""Terminal: Focus Terminal Tabs View"" keybinding won't function.

In short, while focused on the terminal pane, I used to be able to press cmd+shift+\ and move the focus to the Terminal Tabs to the right of the terminal pane (if I had more than one terminal open, which caused the Terminal Tabs to exist).

Now, that keybinding doesn't work anymore, nor does any alternative keybinding for ""Terminal: Focus Terminal Tabs"". 

These are the current when expressions:
""terminalFocus && terminalHasBeenCreated || terminalFocus && terminalProcessSupported || terminalHasBeenCreated && terminalTabsFocus || terminalProcessSupported && terminalTabsFocus""

But removing those when expression entirely or altering them or testing them one at a time does nothing to solve this issue either.",True,0,NONE
https://api.github.com/repos/microsoft/vscode/issues/comments/1280065152,Terminal: Focus Terminal Tabs view keybinding appears dead/non-working.,gjsjohnmurray,5,1410613621,2,1280065152,0,1410613621,2022-10-16T21:54:03Z,I suggest you check any`terminal.integrated.commandsToSkipShell` and `terminal.integrated.sendKeybindingsToShell` settings. ,False,0,CONTRIBUTOR
https://api.github.com/repos/microsoft/vscode/issues/comments/1280078339,Terminal: Focus Terminal Tabs view keybinding appears dead/non-working.,nzwart,5,1410613621,3,1280078339,0,1280065152,2022-10-16T22:54:07Z,I just tried enabling `terminal.integrated.sendKeybindingsToShell` and that didn't change any behavior. I also looked through the default commands in `terminal.integrated.commandsToSkipShell` and didn't see any that were skipping the Focus on Terminal Tabs view command.,False,0,NONE
https://api.github.com/repos/microsoft/vscode/issues/comments/1288098382,Terminal: Focus Terminal Tabs view keybinding appears dead/non-working.,AHopley,5,1410613621,4,1288098382,0,1280078339,2022-10-23T12:10:40Z,"I'm getting the same issue for 1.72.2 on Windows. It isn't just about keybindings. Pressing F1 and doing ""Terminal: Focus Terminal Tabs View"" moves focus to the active terminal rather than the terminal tabs view. This is true when focus is in the editor, and also if the focus is in the terminal tabs view (which now only seems to be selectable using the mouse).",False,0,NONE
https://api.github.com/repos/microsoft/vscode/issues/comments/1288270673,Terminal: Focus Terminal Tabs view keybinding appears dead/non-working.,nzwart,5,1410613621,5,1288270673,0,1288098382,2022-10-24T01:10:41Z,"@AHopley Interesting. I just tried doing what you did with F1 and ""Terminal: Focus Terminal Tabs View"" in the command palette and had the same behavior. Focusing on the active terminal instead of the terminal tabs view. I also can only select the terminal tabs view with the mouse.",False,0,NONE
https://api.github.com/repos/microsoft/vscode/issues/comments/1288287549,Terminal: Focus Terminal Tabs view keybinding appears dead/non-working.,jeanp413,5,1410613621,6,1288287549,0,1288270673,2022-10-24T01:32:50Z,"This is a regression from https://github.com/microsoft/vscode/pull/161989, created a PR fixing this https://github.com/microsoft/vscode/pull/164408",False,0,CONTRIBUTOR
https://api.github.com/repos/microsoft/vscode/issues/163791,terminal,ludy237,3,1410633955,1,1410633955,0,0,2022-10-16T21:52:48Z,"
Type: <b>Performance Issue</b>

In the terminal is difficult to write.


VS Code version: Code 1.72.1 (129500ee4c8ab7263461ffe327268ba56b9f210d, 2022-10-10T17:22:48.346Z)
OS version: Windows_NT x64 6.2.9200
Modes:
Sandboxed: No

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|Intel(R) Core(TM) i3-6100U CPU @ 2.30GHz (4 x 2304)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>skia_renderer: enabled_on<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: disabled_off|
|Load (avg)|undefined|
|Memory (System)|5.89GB (0.43GB free)|
|Process Argv|C:\\Users\\ludy237\\AppData\\Local\\Programs\\Microsoft VS Code\\bin\\..\\resources\\app\\out\\cli.js --ms-enable-electron-run-as-node C:\\Users\\ludy237\\OneDrive\\Documentos\\GitHub\\fastify-todo-example --enable-proposed-api TabNine.tabnine-vscode --crash-reporter-id 0616f56e-e78c-4ea0-971d-91da7dbd4e0b|
|Screen Reader|no|
|VM|0%|
</details><details>
<summary>Process Info</summary>

```
CPU %	Mem MB	   PID	Process
    1	   127	  2248	code main
    0	    93	  5220	   window (undefined)
    0	    88	  7460	   shared-process
    0	    22	  3804	     fileWatcher
    0	    51	  9716	     ptyHost
    0	    22	  1040	       winpty-process
    0	     8	  7860	         C:\WINDOWS\System32\cmd.exe
    0	    12	  9872	         console-window-host (Windows internal process)
    0	    17	  1848	       winpty-process
    0	     8	   784	         C:\WINDOWS\System32\cmd.exe
    0	    12	  9168	         console-window-host (Windows internal process)
    0	    21	  3292	       winpty-process
    0	     7	  9132	         C:\WINDOWS\System32\cmd.exe
    0	    10	 10436	         console-window-host (Windows internal process)
    0	    20	  4036	       winpty-process
    0	     7	  4276	         C:\WINDOWS\System32\cmd.exe
    0	    10	 11920	         console-window-host (Windows internal process)
    0	    22	  4572	       winpty-process
    0	    12	  9828	         console-window-host (Windows internal process)
    0	     8	 13880	         C:\WINDOWS\System32\cmd.exe
    0	    20	  4980	       winpty-process
    0	     7	   188	         console-window-host (Windows internal process)
    0	     6	 14828	         C:\WINDOWS\System32\cmd.exe
    0	    20	  5244	       winpty-process
    0	    12	  7820	         console-window-host (Windows internal process)
    0	     8	 10892	         C:\WINDOWS\System32\cmd.exe
    1	    21	  5356	       winpty-process
    0	     7	 10316	         C:\WINDOWS\System32\cmd.exe
    0	    10	 12240	         console-window-host (Windows internal process)
    0	    22	  6664	       winpty-process
    0	     8	  5376	         C:\WINDOWS\System32\cmd.exe
    1	    12	 13324	         console-window-host (Windows internal process)
    0	    22	  6944	       winpty-process
    0	    12	 14468	         console-window-host (Windows internal process)
    0	     8	 14672	         C:\WINDOWS\System32\cmd.exe
    0	    20	  7032	       winpty-process
    0	     6	 15244	         C:\WINDOWS\System32\cmd.exe
    0	     7	 15292	         console-window-host (Windows internal process)
    0	    20	  7036	       winpty-process
    0	     7	  2024	         console-window-host (Windows internal process)
    0	     6	  9040	         C:\WINDOWS\System32\cmd.exe
    0	    20	  7096	       winpty-process
    0	     6	 11516	         C:\WINDOWS\System32\cmd.exe
    0	     7	 12080	         console-window-host (Windows internal process)
    0	    20	  7200	       winpty-process
    0	     6	 13032	         C:\WINDOWS\System32\cmd.exe
    0	     7	 14732	         console-window-host (Windows internal process)
    0	    22	  7352	       winpty-process
    0	    12	  7048	         console-window-host (Windows internal process)
    0	    12	  2388	           ""C:\Program Files (x86)\IncrediBuild\xgTrayIcon.exe"" 
    0	     8	 14224	         C:\WINDOWS\System32\cmd.exe
    0	    22	  7936	       winpty-process
    0	    12	  4228	         console-window-host (Windows internal process)
    0	     8	 14844	         C:\WINDOWS\System32\cmd.exe
    0	    22	  8304	       winpty-process
    0	     8	  4568	         C:\WINDOWS\System32\cmd.exe
    0	    12	 10512	         console-window-host (Windows internal process)
    0	    19	  8644	       winpty-process
    0	     6	  7264	         C:\WINDOWS\System32\cmd.exe
    0	     7	  8480	         console-window-host (Windows internal process)
    0	    22	  9340	       winpty-process
    0	     7	  3620	         C:\WINDOWS\System32\cmd.exe
    0	    10	 12892	         console-window-host (Windows internal process)
    0	    20	  9448	       winpty-process
    0	     6	 10996	         C:\WINDOWS\System32\cmd.exe
    0	     7	 14640	         console-window-host (Windows internal process)
    0	    22	  9472	       winpty-process
    0	    10	  7212	         console-window-host (Windows internal process)
    0	     8	 10764	         C:\WINDOWS\System32\cmd.exe
    0	    20	  9512	       winpty-process
    0	     8	 10260	         console-window-host (Windows internal process)
    0	     7	 13652	         C:\WINDOWS\System32\cmd.exe
    0	    21	 10268	       winpty-process
    0	    10	  6964	         console-window-host (Windows internal process)
    0	     8	 15276	         C:\WINDOWS\System32\cmd.exe
    0	    22	 10308	       winpty-process
    0	    12	  4208	         console-window-host (Windows internal process)
    0	     8	  9008	         C:\WINDOWS\System32\cmd.exe
    0	    22	 10364	       winpty-process
    0	     8	 10032	         C:\WINDOWS\System32\cmd.exe
    0	    12	 14752	         console-window-host (Windows internal process)
    0	    22	 10432	       winpty-process
    0	     8	 11776	         C:\WINDOWS\System32\cmd.exe
    0	    12	 12860	         console-window-host (Windows internal process)
    0	    22	 10496	       winpty-process
    0	     8	   520	         C:\WINDOWS\System32\cmd.exe
    0	    12	  1280	         console-window-host (Windows internal process)
    0	    22	 10504	       winpty-process
    0	     8	  7092	         C:\WINDOWS\System32\cmd.exe
    0	    12	 10228	         console-window-host (Windows internal process)
    1	    19	 10884	       winpty-process
    0	     7	  2128	         console-window-host (Windows internal process)
    0	     6	 10256	         C:\WINDOWS\System32\cmd.exe
    0	    21	 11228	       winpty-process
    0	    10	  9492	         console-window-host (Windows internal process)
    0	     7	 13948	         C:\WINDOWS\System32\cmd.exe
    0	    20	 11288	       winpty-process
    0	     6	  1260	         C:\WINDOWS\System32\cmd.exe
    0	     7	  3840	         console-window-host (Windows internal process)
    0	    20	 11300	       winpty-process
    0	     7	 13260	         console-window-host (Windows internal process)
    0	     6	 14780	         C:\WINDOWS\System32\cmd.exe
    0	    22	 11752	       winpty-process
    0	     8	 10356	         C:\WINDOWS\System32\cmd.exe
    0	    12	 15108	         console-window-host (Windows internal process)
    0	     7	 11888	       winpty-process
    0	     7	 12332	         console-window-host (Windows internal process)
    0	    20	 12364	       winpty-process
    0	     6	 10616	         C:\WINDOWS\System32\cmd.exe
    0	     7	 11168	         console-window-host (Windows internal process)
    0	    22	 12412	       winpty-process
    0	    12	  8904	         console-window-host (Windows internal process)
    0	     8	 12408	         C:\WINDOWS\System32\cmd.exe
    0	    20	 12436	       winpty-process
    0	     7	  3548	         console-window-host (Windows internal process)
    0	     6	  6464	         C:\WINDOWS\System32\cmd.exe
    0	    19	 12512	       winpty-process
    0	     6	  1328	         C:\WINDOWS\System32\cmd.exe
    0	     7	 12804	         console-window-host (Windows internal process)
    0	    20	 13060	       winpty-process
    0	     7	  7120	         console-window-host (Windows internal process)
    0	     6	 15060	         C:\WINDOWS\System32\cmd.exe
    0	    20	 13104	       winpty-process
    0	     6	  7424	         C:\WINDOWS\System32\cmd.exe
    0	     7	  9504	         console-window-host (Windows internal process)
    0	    20	 13116	       winpty-process
    0	     6	 10344	         C:\WINDOWS\System32\cmd.exe
    1	     7	 14408	         console-window-host (Windows internal process)
    0	    22	 13252	       winpty-process
    0	     8	 11124	         C:\WINDOWS\System32\cmd.exe
    0	    12	 15240	         console-window-host (Windows internal process)
    0	    22	 13256	       winpty-process
    0	    12	  3264	         console-window-host (Windows internal process)
    0	     8	  5028	         C:\WINDOWS\System32\cmd.exe
    0	    22	 13572	       winpty-process
    0	     8	 13748	         C:\WINDOWS\System32\cmd.exe
    0	    12	 15144	         console-window-host (Windows internal process)
    0	    21	 13620	       winpty-process
    0	     8	 11276	         C:\WINDOWS\System32\cmd.exe
    0	    10	 12388	         console-window-host (Windows internal process)
    0	    22	 13640	       winpty-process
    0	    12	  9096	         console-window-host (Windows internal process)
    0	     8	 12276	         C:\WINDOWS\System32\cmd.exe
    0	    22	 13672	       winpty-process
    0	     8	 13824	         C:\WINDOWS\System32\cmd.exe
    0	    12	 14284	         console-window-host (Windows internal process)
    0	    20	 13704	       winpty-process
    0	     6	  9396	         C:\WINDOWS\System32\cmd.exe
    1	     7	 14364	         console-window-host (Windows internal process)
    0	    22	 13728	       winpty-process
    0	     8	  7228	         C:\WINDOWS\System32\cmd.exe
    0	    12	  9700	         console-window-host (Windows internal process)
    0	    20	 13800	       winpty-process
    0	     7	  2328	         C:\WINDOWS\System32\cmd.exe
    0	    10	 14136	         console-window-host (Windows internal process)
    0	    20	 13940	       winpty-process
    0	     6	 11660	         C:\WINDOWS\System32\cmd.exe
    0	     7	 12252	         console-window-host (Windows internal process)
    0	    20	 13968	       winpty-process
    0	    10	 11308	         console-window-host (Windows internal process)
    0	     7	 12780	         C:\WINDOWS\System32\cmd.exe
    0	    22	 14104	       winpty-process
    0	     8	  4536	         C:\WINDOWS\System32\cmd.exe
    0	    12	 10940	         console-window-host (Windows internal process)
    0	    22	 14772	       winpty-process
    0	     8	  9440	         C:\WINDOWS\System32\cmd.exe
    0	    12	  9956	         console-window-host (Windows internal process)
    0	    22	 14868	       winpty-process
    0	   114	 11932	         ""C:\Program Files\PowerShell\7\pwsh.exe"" -noexit -command ""try { . \""c:\Users\ludy237\AppData\Local\Programs\Microsoft VS Code\resources\app\out\vs\workbench\contrib\terminal\browser\media\shellIntegration.ps1\"" } catch {}""
    0	    12	 14448	         console-window-host (Windows internal process)
    0	    20	 14896	       winpty-process
    1	     7	  8576	         console-window-host (Windows internal process)
    0	     6	 13152	         C:\WINDOWS\System32\cmd.exe
    0	    20	 14992	       winpty-process
    0	     7	 10112	         console-window-host (Windows internal process)
    0	     6	 10352	         C:\WINDOWS\System32\cmd.exe
    0	    20	 15268	       winpty-process
    0	     8	 11476	         console-window-host (Windows internal process)
    0	     7	 13160	         C:\WINDOWS\System32\cmd.exe
    0	    20	 15356	       winpty-process
    0	     7	 10464	         console-window-host (Windows internal process)
    0	     6	 14596	         C:\WINDOWS\System32\cmd.exe
    0	    99	  9856	   issue-reporter
    0	    19	 10208	   utility-network-service
    2	   302	 11072	   window (Running Extensions - fastify-todo-example - Visual Studio Code [Administrator])
    0	     7	 12160	   crashpad-handler
    0	   443	 12308	   extensionHost
    0	    21	  4936	     ""C:\Users\ludy237\AppData\Local\Programs\Microsoft VS Code\Code.exe"" --ms-enable-electron-run-as-node c:\Users\ludy237\.vscode\extensions\codestream.codestream-14.2.0\dist\agent.js --node-ipc --clientProcessId=12308
    0	    29	  7300	     ""C:\Users\ludy237\AppData\Local\Programs\Microsoft VS Code\Code.exe"" --ms-enable-electron-run-as-node c:\Users\ludy237\.vscode\extensions\redhat.vscode-yaml-1.10.1\dist\languageserver.js --node-ipc --clientProcessId=12308
    0	    33	  8596	     ""C:\Users\ludy237\AppData\Local\Programs\Microsoft VS Code\Code.exe"" --ms-enable-electron-run-as-node ""c:\Users\ludy237\AppData\Local\Programs\Microsoft VS Code\resources\app\extensions\markdown-language-features\server\dist\node\main"" --node-ipc --clientProcessId=12308
    0	    37	 10596	     ""C:\Users\ludy237\AppData\Local\Programs\Microsoft VS Code\Code.exe"" --ms-enable-electron-run-as-node c:\Users\ludy237\.vscode\extensions\amazonwebservices.aws-toolkit-vscode-1.51.0\dist\src\ssmDocument\ssm\ssmServer.js --node-ipc --clientProcessId=12308
    0	    15	 11388	     ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python39_64\python.exe"" c:\Users\ludy237\.vscode\extensions\ms-python.python-2022.16.0\pythonFiles\run-jedi-language-server.py
    0	     6	  2080	       console-window-host (Windows internal process)
    0	    74	 11860	     ""C:\Users\ludy237\AppData\Local\Programs\Microsoft VS Code\Code.exe"" --ms-enable-electron-run-as-node c:\Users\ludy237\.vscode\extensions\ms-edgedevtools.vscode-edge-devtools-2.1.1\node_modules\vscode-webhint\dist\src\server.js c:\Users\ludy237\AppData\Roaming\Code\User\globalStorage\ms-edgedevtools.vscode-edge-devtools ""Microsoft Edge Tools"" --node-ipc --clientProcessId=12308
    0	    32	 12384	     ""C:\Users\ludy237\AppData\Local\Programs\Microsoft VS Code\Code.exe"" --ms-enable-electron-run-as-node c:\Users\ludy237\.vscode\extensions\amazonwebservices.aws-toolkit-vscode-1.51.0\dist\src\stepFunctions\asl\aslServer.js --node-ipc --clientProcessId=12308
    0	    93	 13480	     ""C:\Users\ludy237\AppData\Local\Programs\Microsoft VS Code\Code.exe"" --ms-enable-electron-run-as-node ""c:\Users\ludy237\AppData\Local\Programs\Microsoft VS Code\resources\app\extensions\json-language-features\server\dist\node\jsonServerMain"" --node-ipc --clientProcessId=12308
    0	    69	 13528	     ""C:\Users\ludy237\AppData\Local\Programs\Microsoft VS Code\Code.exe"" --ms-enable-electron-run-as-node c:\Users\ludy237\.vscode\extensions\streetsidesoftware.code-spell-checker-2.10.1\packages\_server\dist\main.js --node-ipc --clientProcessId=12308
    2	   202	 12644	   gpu-process
```

</details>
<details>
<summary>Workspace Info</summary>

```
|  Window (Running Extensions - fastify-todo-example - Visual Studio Code [Administrator])
|    Folder (fastify-todo-example): 12 files
|      File types: json(3) yaml(1) gitignore(1) md(1) js(1)
|      Conf files: github-actions(1) package.json(1);
```

</details>
<details><summary>Extensions (166)</summary>

Extension|Author (truncated)|Version
---|---|---
Bookmarks|ale|13.3.1
project-manager|ale|12.7.0
cucumberautocomplete|ale|2.15.2
arepl|alm|2.0.3
aws-toolkit-vscode|ama|1.51.0
cpp-helper|ami|0.3.1
git-tools|ank|1.0.0
gitstash|art|5.1.0
python-six|asc|2022.5.0
ruby-on-rails-snippets|ate|0.0.1
All-Autocomplete|Ati|0.0.23
code-gnu-global|aus|0.2.2
azurite|Azu|3.19.0
vscode-django|bat|1.10.0
git-easy|bib|1.11.0
emojisense|bie|0.9.1
markdown-checkbox|bie|0.3.3
ruby-test-launcher|bla|0.0.3
vscode-intelephense-client|bme|1.8.2
phpserver|bra|3.0.2
ruby-debug|cas|0.3.5
solargraph|cas|0.24.0
npm-intellisense|chr|1.4.2
path-intellisense|chr|2.8.1
ruby-and-rails-snippets|Cja|1.0.0
codestream|Cod|14.3.0
gitignore|cod|0.9.0
vscode-ruby-test-adapter|con|0.9.1
erb|Cra|0.0.1
macros|ctf|0.0.4
c-cpp-compile-run|dan|1.0.18
dockerlive|dav|1.0.21
algorithm-mnemonics-vscode|dav|1.0.3
vscode-dash|dee|2.4.0
composer-php-vscode|DEV|1.18.10892
phptools-vscode|DEV|1.18.10892
profiler-php-vscode|DEV|1.18.10892
git-extension-pack|don|0.1.3
githistory|don|0.6.19
python-extension-pack|don|1.7.0
xml|Dot|2.5.1
vscode-docker-syntax|dun|0.1.5
git-cheatsheet|dzh|1.4.4
gitlens|eam|12.2.2
tslint|eg2|1.0.47
ruby-around-the-block|ell|0.1.2
vscode-install-vsix|fab|1.4.0
git-project-manager|fel|1.8.2
code-runner|for|0.11.8
docker-explorer|for|0.1.7
c-cpp-runner|fra|4.1.2
codespaces|Git|1.11.0
vscode-pull-request-github|Git|0.50.0
gitpod-desktop|git|0.0.60
todo-tree|Gru|0.0.219
CppSnippets|har|0.0.15
vscode-test-explorer|hbe|2.21.1
ruby-starter|Hoo|0.0.2
vscode-git-tags|how|1.4.4
githd|hui|2.3.3
output-colorizer|IBM|0.1.2
easy-snippet|inu|0.6.3
vscode-git-add-and-commit|iva|2.1.1
vscode-essentials|jab|1.6.0
search-editor-apply-changes|jak|0.1.1
hungry-delete|jas|1.7.0
vstsbuildstatus|jep|0.7.1
vscode-text-pastry|jkj|1.3.1
vscode-rufo|jnb|0.0.5
vscode-peacock|joh|4.2.2
chat|kar|0.35.0
vsc-python-indent|Kev|1.18.0
wsl-path|kgr|0.1.0
vscode-github|Kni|0.30.7
vscode-phpfmt|kok|1.0.31
ruby-language-server|Kur|0.1.1
vscode-format-context-menu|lac|1.0.4
git-indicators|lam|2.1.2
vscode-python-test-adapter|lit|0.7.1
vscode-clangd|llv|0.1.22
vscode-catch2-test-adapter|mat|4.3.1
vscode-rubycommentdoc|mat|1.0.1
metago|met|4.3.1
MetaJump|met|1.4.0
MetaWord|met|1.3.0
python-path|mge|0.0.14
git-graph|mhu|1.30.0
vscode-git-branch-sidebar|mia|1.5.1
azure-dev|ms-|0.3.0
vscode-azureresourcegroups|ms-|0.5.6
vscode-azurestaticwebapps|ms-|0.11.3
vscode-azurevirtualmachines|ms-|0.6.2
vscode-docker|ms-|1.22.1
csharp|ms-|1.25.0
vscode-dotnet-runtime|ms-|1.5.0
vscode-edge-devtools|ms-|2.1.1
mssql|ms-|1.16.0
sql-bindings-vscode|ms-|0.3.0
python|ms-|2022.16.1
remote-containers|ms-|0.255.3
remote-wsl|ms-|0.72.0
atom-keybindings|ms-|3.0.9
azure-account|ms-|0.11.2
azurecli|ms-|0.5.0
cpptools|ms-|1.12.4
js-debug-nightly|ms-|2022.10.1317
sublime-keybindings|ms-|4.0.10
test-adapter-converter|ms-|0.1.6
vs-keybindings|ms-|0.2.1
vscode-node-azure-pack|ms-|1.1.0
vsliveshare|ms-|1.0.5735
vsliveshare-audio|ms-|0.1.91
azurerm-vscode-tools|msa|0.15.8
debugger-for-edge|msj|1.0.15
php-docblocker|nei|2.7.0
gremlins|nho|0.26.0
autodocstring|njp|0.6.1
vsix-viewer|onl|1.0.5
vscode-ruby-ctags|oto|1.4.1
gitpatch|par|0.2.1
explorer-exclude|Pet|1.3.2
material-icon-theme|PKi|4.21.0
iar-vsc|plu|1.3.1
ruby|reb|0.28.1
vscode-yaml|red|1.10.1
explorer-exclude-vscode-extension|Red|1.2.2
ruby-snippet|rob|0.1.0
py-snippets|RTG|1.0.1
partial-diff|ryu|1.4.3
salesforcedx-vscode-apex|sal|55.8.0
salesforcedx-vscode-apex-debugger|sal|55.8.0
salesforcedx-vscode-core|sal|55.8.0
vscode-ruby-syntax|Sar|0.0.11
git-merger|sha|0.4.1
code-settings-sync|Sha|3.4.3
trailing-spaces|sha|0.4.1
php-ci|sma|0.4.2
vscode-vslauncher|spm|1.0.8
git-prefix|srm|1.3.0
rewrap|stk|1.16.3
code-spell-checker|str|2.10.1
control-snippets|svi|1.9.1
nextflow-aws-docker-training-pack|tee|0.0.2
vscode-docker-ws|tii|0.5.0
pdf|tom|1.2.0
vscode-lldb|vad|1.8.1
intellicode-api-usage-examples|Vis|0.2.5
vscodeintellicode|Vis|1.2.28
simple-ruby-erb|vor|0.2.1
vscode-java-debug|vsc|0.45.0
vim|vsc|1.24.1
codetour|vsl|0.0.58
gistfs|vsl|0.4.1
gitblame|wad|9.0.1
jinja|who|0.0.8
vscode-ruby|win|0.28.0
php-sniffer|won|1.3.0
JavaScriptSnippets|xab|1.8.0
clang-format|xav|1.9.0
php-debug|xde|1.29.0
php-pack|xde|1.0.3
local-history|xyz|1.8.1
auto-git|zei|1.1.4
vsc-docker|Zim|0.34.0
vscode-open-in-github|ziy|1.3.6
php-intellisense|zob|1.0.11

(3 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vstes627:30244334
vslsvsres303:30308271
pythonvspyl392:30443607
vserr242cf:30382550
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vsdfh931:30280409
vshan820:30294714
vstes263:30335439
vscorecescf:30445987
pythondataviewer:30285071
vscod805:30301674
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
cmake_vspar411:30581797
vsaa593:30376534
pythonvs932:30410667
cppdebug:30492333
vscaat:30438848
vsclangdc:30486549
c4g48928:30535728
dsvsc012cf:30540253
azure-dev_surveyone:30548225
i497e931:30553904
pyindex848cf:30577861
nodejswelcome1:30587005
fc301958:30573243

```

</details>

<!-- generated by issue reporter -->",True,0,NONE
https://api.github.com/repos/microsoft/vscode/issues/comments/1280065032,terminal,VSCodeTriageBot,3,1410633955,2,1280065032,0,1410633955,2022-10-16T21:53:19Z,"Thanks for creating this issue! It looks like you may be using an old version of VS Code, the latest stable release is 1.72.2. Please try upgrading to the latest version and checking whether this issue remains.

Happy Coding!",False,0,COLLABORATOR
https://api.github.com/repos/microsoft/vscode/issues/comments/1280065517,terminal,gjsjohnmurray,3,1410633955,3,1280065517,0,1280065032,2022-10-16T21:56:26Z,"Please use the Start Extension Bisect command to investigate whether the problem is being caused by one of your extensions.

If this does not resolve the issue please provide more details about what you mean by ""difficult to write"". ",False,0,CONTRIBUTOR
https://api.github.com/repos/microsoft/vscode/issues/comments/1290401626,terminal,VSCodeTriageBot,3,1410633955,4,1290401626,0,1280065517,2022-10-25T11:29:53Z,"This issue has been closed automatically because it needs more information and has not had recent activity. See also our [issue reporting](https://aka.ms/vscodeissuereporting) guidelines.

Happy Coding!",False,0,COLLABORATOR
https://api.github.com/repos/Warzone2100/warzone2100/issues/2904,tweaks to tank factory,MaNGusT-,3,1415626844,1,1415626844,0,0,2022-10-19T21:54:10Z,"Changes:
-fixed texture coords on the back side with some tweaks to geometry
-added connectors for each steam effect
-all meshes are split on pie levels
-all models now use pie 3 format

issues:
1) adding more than 1 connector switches steam effect to flashing red dot
2) wz renders only first level of model when you build a new factory
3) wz renders only first level of model when you build a factory module
4) when you build a factory module, wz renders only first level of model of already built factory

",True,0,CONTRIBUTOR
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1285680559,tweaks to tank factory,MaNGusT-,3,1415626844,2,1285680559,0,1415626844,2022-10-20T14:50:21Z,"UPD2: [structs.zip](https://github.com/Warzone2100/warzone2100/files/9831227/structs.zip)
-updated page-13
-fixed geometry",False,0,CONTRIBUTOR
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1285844973,tweaks to tank factory,maxsupermanhd,3,1415626844,3,1285844973,0,1285680559,2022-10-20T16:32:12Z,You know you can make pull requests?,False,0,MEMBER
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1285858041,tweaks to tank factory,past-due,3,1415626844,4,1285858041,0,1285844973,2022-10-20T16:43:17Z,"> You know you can make pull requests?

@maxsupermanhd Sometimes it's easiest to just open an issue and add an attachment, and I'm also perfectly fine with that for such high-quality contributions. 👍 

(Especially in this case where we have textures in another repo / submodule.)",False,0,MEMBER
https://api.github.com/repos/Warzone2100/warzone2100/issues/2908,Incendiary Mortar tweak,KJeff01,3,1416924690,1,1416924690,0,0,2022-10-20T16:27:23Z,"Testing Tipchik's suggestion of reducing periodical damage to 24 from 26. This will go in the autohosted balance mod when it gets updated. If still not enough I will do more tweaks to parameters like the build time, price, and maximum long range.",True,0,MEMBER
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1285918090,Incendiary Mortar tweak,maxsupermanhd,3,1416924690,2,1285918090,0,1416924690,2022-10-20T17:38:48Z,I am not sure that it will be enough of a nerf but it is something and I am not pushing for more,False,0,MEMBER
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1286481922,Incendiary Mortar tweak,Tipchik87,3,1416924690,3,1286481922,0,1285918090,2022-10-21T05:33:32Z,"> I am not sure that it will be enough of a nerf but it is something and I am not pushing for more

Initially, there was a value of 22 and this mortar was of little interest to anyone. I didn't change the rest of the settings.",False,0,CONTRIBUTOR
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1287869415,Incendiary Mortar tweak,Evolution01,3,1416924690,4,1287869415,0,1286481922,2022-10-22T17:53:48Z,"You can do 22, but it will do.",False,0,CONTRIBUTOR
https://api.github.com/repos/Warzone2100/warzone2100/issues/2920,replacement for generic green item in design menu,MaNGusT-,4,1419495787,1,1419495787,0,0,2022-10-22T20:31:41Z,"Currently it's hardcoded to use green body that is also used when you design a unit.
",True,0,CONTRIBUTOR
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1296070338,replacement for generic green item in design menu,MaNGusT-,4,1419495787,2,1296070338,0,1419495787,2022-10-30T02:26:45Z,"UPD:
Found a way to do what I want without code changes. It's ready to merge.

can be deleted:
_mibnkbod.pie 
mibnkdr.pie 
mibnkdrl.pie 
mibnkdrr.pie 
mibnkgun.pie 
mibnktur.pie_ ",False,0,CONTRIBUTOR
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1304954292,replacement for generic green item in design menu,KJeff01,4,1419495787,3,1304954292,0,1296070338,2022-11-07T00:51:23Z,I get assert spam about a missing turret with znullweapon... maybe the turret can be made invisible as a workaround.,False,0,MEMBER
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1305124631,replacement for generic green item in design menu,MaNGusT-,4,1419495787,4,1305124631,0,1304954292,2022-11-07T06:01:06Z,"> I get assert spam about a missing turret with znullweapon... maybe the turret can be made invisible as a workaround.

game forces me to set up the gun model and keep it separately from turret :D or create 1 polygon fake model to shut up this assert. Anyway, I was just trying to remove 1 useless draw call",False,0,CONTRIBUTOR
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1305143527,replacement for generic green item in design menu,MaNGusT-,4,1419495787,5,1305143527,0,1305124631,2022-11-07T06:26:33Z,"fixed assert by splitting weapon model onto turret and gun
[znull_replacement2.zip](https://github.com/Warzone2100/warzone2100/files/9948686/znull_replacement2.zip)
",False,0,CONTRIBUTOR
https://api.github.com/repos/Warzone2100/warzone2100/issues/2922,"(MP)Hurricane, Whirlwind and AG Turrets Tweaks",Tipchik87,6,1419526648,1,1419526648,0,0,2022-10-22T22:05:09Z,"Today we discussed the AA branches of the MG in the Russian chat and came to the conclusion that a simple transfer of the Whirlwind turret will not be enough.
It is necessary that AA (Hurricane and Whirlwind) receive all buffs (damage and ROF) from buffs for MG, just like it works now for Cyclone and Sunburst. I compared the number of buffs and it turned out that Hurricane and Whirlwind in total will receive 8 damage buffs instead of 6 and -45% ROF instead of -60%. The remaining 3 accuracy buffs can be removed and increase the accuracy of Hurricane and Whirlwind turrets, which I did.

Results:
Hurricane receiving on ~13 minute
Whirlwind receiving on ~19 minute
Required research for Hurricane: Rapid Fire Chaingun
Required research for Whirlwind: Assault Gun and Hurricane
Accuracy of turrets was increased by 20 points from 60 to 80 for long range and from 55 to 70 for short range
Cheaper Whirlwind AA Turret research:
research Points: 9700 ->7200
research Power: 303 -> 225
___________________________________
Modified: Hurricane acc -10
Swap Hyper Fire Chaingun Upgrade with Assault Gun
Required research for Whirlwind AA Turret now: Hyper Fire Chaingun Upgrade and Hurricane AA Turret

",True,0,CONTRIBUTOR
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1288101582,"(MP)Hurricane, Whirlwind and AG Turrets Tweaks",Blagodel,6,1419526648,2,1288101582,0,1419526648,2022-10-23T12:27:29Z,"WZ really needs MG AA became pretty to use. This change wil make em more popular and less research-requiring. Hope some time there will be the seme situation as it is with rocket and laser AA, when no special AA-buff researches needed",False,0,CONTRIBUTOR
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1288104637,"(MP)Hurricane, Whirlwind and AG Turrets Tweaks",Evolution01,6,1419526648,3,1288104637,0,1288101582,2022-10-23T12:44:12Z,A good idea,False,0,CONTRIBUTOR
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1288105575,"(MP)Hurricane, Whirlwind and AG Turrets Tweaks",maxsupermanhd,6,1419526648,4,1288105575,0,1288104637,2022-10-23T12:49:27Z,"I want this in balance testing rooms as soon as possible, looks really promising",False,0,MEMBER
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1293700274,"(MP)Hurricane, Whirlwind and AG Turrets Tweaks",KJeff01,6,1419526648,5,1293700274,0,1288105575,2022-10-27T15:23:27Z,"It is necessary to keep the weapon subclass ""A-A GUN"" as this is needed for spectator images and some graphics related special behavior.

To do this you only need to add the ""results""  of MGAA specific damage/rof research upgrades to the MG damage/rof upgrades.

Edit: An example:
```
""results"": [
			{
				""class"": ""Weapon"",
				""filterParameter"": ""ImpactClass"",
				""filterValue"": ""MACHINE GUN"",
				""parameter"": ""Damage"",
				""value"": 25
			},
                        {
				""class"": ""Weapon"",
				""filterParameter"": ""ImpactClass"",
				""filterValue"": ""A-A GUN"",
				""parameter"": ""Damage"",
				""value"": 25
			},
			{
				""class"": ""Weapon"",
				""filterParameter"": ""ImpactClass"",
				""filterValue"": ""A-A GUN"",
				""parameter"": ""RadiusDamage"",
				""value"": 25
			}
],
```",False,0,MEMBER
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1293876135,"(MP)Hurricane, Whirlwind and AG Turrets Tweaks",Tipchik87,6,1419526648,6,1293876135,0,1293700274,2022-10-27T17:55:29Z,"> It is necessary to keep the weapon subclass ""A-A GUN"" as this is needed for spectator images and some graphics related special behavior.
> 
> To do this you only need to add the ""results"" of MGAA specific damage/rof research upgrades to the MG damage/rof upgrades.
> 
> Edit: An example:
> 
> ```
> ""results"": [
> 			{
> 				""class"": ""Weapon"",
> 				""filterParameter"": ""ImpactClass"",
> 				""filterValue"": ""MACHINE GUN"",
> 				""parameter"": ""Damage"",
> 				""value"": 25
> 			},
>                         {
> 				""class"": ""Weapon"",
> 				""filterParameter"": ""ImpactClass"",
> 				""filterValue"": ""A-A GUN"",
> 				""parameter"": ""Damage"",
> 				""value"": 25
> 			},
> 			{
> 				""class"": ""Weapon"",
> 				""filterParameter"": ""ImpactClass"",
> 				""filterValue"": ""A-A GUN"",
> 				""parameter"": ""RadiusDamage"",
> 				""value"": 25
> 			}
> ],
> ```

ok",False,0,CONTRIBUTOR
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1306633020,"(MP)Hurricane, Whirlwind and AG Turrets Tweaks",KJeff01,6,1419526648,7,1306633020,0,1293876135,2022-11-08T04:54:53Z,"Good. Now Whirlwind can see the battlefield once again.

:+1: ",False,0,MEMBER
https://api.github.com/repos/Monika-After-Story/MonikaModDev/issues/9690,"Piano ""Your reality"" Not working.",BlackSilver07,3,1425496686,1,1425496686,0,0,2022-10-27T11:42:03Z,"After the update I wanted to play your reality. But for some reason some of the notes are different or missing. 

On the second verse the silent chorus instead of ""OPOOPO]]P[OP[O"" it shortened to ""OPOOPO]]P["" and in the third verse (normally ""OOOIUTTYUO"") it became ""OOOIUT unknown"" I have no idea what is the next note I tried q,w,e,r,t,y,u,i,o,p,[,]. Have not tried the upper notes. But clearly something is off.

Is this happening to anyone?",True,0,NONE
https://api.github.com/repos/Monika-After-Story/MonikaModDev/issues/comments/1293409803,"Piano ""Your reality"" Not working.",Booplicate,3,1425496686,2,1293409803,0,1425496686,2022-10-27T11:50:07Z,Check this #8759,False,0,MEMBER
https://api.github.com/repos/Monika-After-Story/MonikaModDev/issues/comments/1293425252,"Piano ""Your reality"" Not working.",BlackSilver07,3,1425496686,3,1293425252,0,1293409803,2022-10-27T12:04:06Z,I'll give it a shot. Thank you,False,0,NONE
https://api.github.com/repos/Monika-After-Story/MonikaModDev/issues/comments/1293780926,"Piano ""Your reality"" Not working.",BlackSilver07,3,1425496686,4,1293780926,0,1293425252,2022-10-27T16:27:13Z,Got it thank you very much.,False,0,NONE
https://api.github.com/repos/Monika-After-Story/MonikaModDev/issues/9693,Will changing your system locale affect MAS?,t0kichii,3,1426587008,1,1426587008,0,0,2022-10-28T03:16:03Z,"I know this is a weird and probably easy to answer question, but i needed to change my system locale for something and I want to know if I need to change it back before opening MAS. I figured I _should_ but I haven't done anything yet and would just like to check to make sure I don't make a mistake. (I don't know a lot about system locale so I'm just hoping someone here does. If you don't know what I'm referring to you can look it up but I'm not sure if that will help you jsjdhdxjxj)",True,0,NONE
https://api.github.com/repos/Monika-After-Story/MonikaModDev/issues/comments/1294547686,Will changing your system locale affect MAS?,Booplicate,3,1426587008,2,1294547686,0,1426587008,2022-10-28T06:59:53Z,"You don't have to, MAS should work on any locale. Just restart MAS when you change it. Also make sure the path to the game contains only latin characters.",False,0,MEMBER
https://api.github.com/repos/Monika-After-Story/MonikaModDev/issues/comments/1294916442,Will changing your system locale affect MAS?,t0kichii,3,1426587008,3,1294916442,0,1294547686,2022-10-28T12:05:36Z,Thank you!!!,False,0,NONE
https://api.github.com/repos/Monika-After-Story/MonikaModDev/issues/comments/1296144585,Will changing your system locale affect MAS?,dreamscached,3,1426587008,4,1296144585,0,1294916442,2022-10-30T07:15:12Z,Closing as resolved.,False,0,MEMBER
https://api.github.com/repos/Monika-After-Story/MonikaModDev/issues/9694,Monika won’t turn herself into a file,a-goodey,4,1428469821,1,1428469821,0,0,2022-10-29T21:46:49Z,"When I tell Monika I’m going to take her out somewhere she says she can’t turn herself into a file, and I don’t know why. It used to work, it just recently stopped, but I didn’t change anything about the files since it was working",True,0,NONE
https://api.github.com/repos/Monika-After-Story/MonikaModDev/issues/comments/1296014717,Monika won’t turn herself into a file,MrBebra,4,1428469821,2,1296014717,0,1428469821,2022-10-29T23:08:42Z,"if mas is running in a folder protected by windows(`C:/Program Files,` for example), it won't be able to generate the file. 

See if your folder is protected (Programs normally couldn't save files into protected folders).

Also might be a good idea to show your mfgen and mfread files from the log folder.",False,0,NONE
https://api.github.com/repos/Monika-After-Story/MonikaModDev/issues/comments/1296015384,Monika won’t turn herself into a file,multimokia,4,1428469821,3,1296015384,0,1296014717,2022-10-29T23:11:26Z,Where is MAS installed for you? (What is the full path to your DDLC exe),False,0,MEMBER
https://api.github.com/repos/Monika-After-Story/MonikaModDev/issues/comments/1299479645,Monika won’t turn herself into a file,a-goodey,4,1428469821,4,1299479645,0,1296015384,2022-11-02T02:32:11Z,"> Where is MAS installed for you? (What is the full path to your DDLC exe)

Downloads —> ddlc.win —> Ddlc-1.1.1-pc —> DDLC.exe",False,0,NONE
https://api.github.com/repos/Monika-After-Story/MonikaModDev/issues/comments/1307670349,Monika won’t turn herself into a file,Booplicate,4,1428469821,5,1307670349,0,1299479645,2022-11-08T18:41:36Z,"Provide a screenshot with the path to your DDLC directory.
Attach your log files: `mas_log.log`, `mfgen.log`.",False,0,MEMBER
https://api.github.com/repos/Monika-After-Story/MonikaModDev/issues/9696,v0.12.12 typos,ThePotatoGuy,8,1428548965,1,1428548965,0,0,2022-10-30T01:54:04Z,"![kachow](https://user-images.githubusercontent.com/3499462/198859032-34a8f749-2376-47eb-8cb9-61a17710f4cd.jpg)
",True,0,MEMBER
https://api.github.com/repos/Monika-After-Story/MonikaModDev/issues/comments/1297716451,v0.12.12 typos,jmwall24,8,1428548965,2,1297716451,0,1428548965,2022-10-31T21:37:13Z,"## Fixed

`greeting_o31_briaryoung_shuchiin_academy_uniform`

Instead shouldn't be capped.",False,0,MEMBER
https://api.github.com/repos/Monika-After-Story/MonikaModDev/issues/comments/1299453889,v0.12.12 typos,Justformas,8,1428548965,3,1299453889,0,1297716451,2022-11-02T01:59:36Z,"## Fixed

In script-stories.rpy `label mas_scary_story_prison_escape` line 1892:

`""Next, he got the body and put it in a casket, and then entered his office to fill out the death certificate before returning to the nail the casket lid shut.""`

There is an extra ""the"" between ""to"" and ""nail"". Should just be ""to nail the casket lid shut"".",False,0,NONE
https://api.github.com/repos/Monika-After-Story/MonikaModDev/issues/comments/1312555959,v0.12.12 typos,ThePotatoGuy,8,1428548965,4,1312555959,0,1299453889,2022-11-12T19:28:31Z,"## Pog

```mermaid
graph TD;
    A-->B;
    A-->C;
    B-->D;
    C-->D;
```
oh pog",False,0,MEMBER
https://api.github.com/repos/Monika-After-Story/MonikaModDev/issues/comments/1322085511,v0.12.12 typos,Wingdinggaster656,8,1428548965,5,1322085511,0,1312555959,2022-11-21T13:43:07Z,"## Fixed

[`script-topics.rpy`, label `monika_player_appearance`](https://github.com/Monika-After-Story/MonikaModDev/blob/master/Monika%20After%20Story/game/script-topics.rpy#L12475):

```
    m 1ekd ""I understand, [player]""
```

Obviously a `.` missed.",False,0,CONTRIBUTOR
https://api.github.com/repos/Monika-After-Story/MonikaModDev/issues/comments/1350356674,v0.12.12 typos,Wingdinggaster656,8,1428548965,6,1350356674,0,1322085511,2022-12-14T03:50:30Z,"## Fixed

`script-topics.rpy`, label `monika_using_pcs_healthily`:

```
m 4eud ""In addition, remember to take frequent breaks. {w=0.3}Look away from the screen, {w=0.2}ideally at something far away, {w=0.2}and perhaps do a few stretches. ""
```

Here, `...do a few stretches. ""`, we have one extra space after the period, which should be deleted.",False,0,CONTRIBUTOR
https://api.github.com/repos/Monika-After-Story/MonikaModDev/issues/comments/1356109914,v0.12.12 typos,Wingdinggaster656,8,1428548965,7,1356109914,0,1350356674,2022-12-17T07:55:39Z,"## Fixed

`script-topics.rpy`, label `monika_justice`:

```
m 5hubfa ""Ehehe, You're so cute, [player]~""
```

We should not capitalize the letter `Y` of `You`.",False,0,CONTRIBUTOR
https://api.github.com/repos/Monika-After-Story/MonikaModDev/issues/comments/1356759948,v0.12.12 typos,Wingdinggaster656,8,1428548965,8,1356759948,0,1356109914,2022-12-18T09:46:54Z,"## Not a bug

Not sure, but looks like a typo:

Label `monika_travelling`:

```
m 1eua ""Do you like travelling?{nw}""
```

While in this topic, we used `travelling` and doubled the letter `l`, but in the `init 5 python:`, we got:

```
prompt=""Traveling"",
```

We didn't double the letter `l` in the prompt.",False,0,CONTRIBUTOR
https://api.github.com/repos/Monika-After-Story/MonikaModDev/issues/comments/1363551523,v0.12.12 typos,ThePotatoGuy,8,1428548965,9,1363551523,0,1356759948,2022-12-23T02:29:16Z,[closing as fixed],False,0,MEMBER
https://api.github.com/repos/LuaLS/lua-language-server/issues/1674,problem with table return type checking,max397574,3,1438445851,1,1438445851,0,0,2022-11-07T14:19:04Z,"related: https://github.com/sumneko/lua-language-server/issues/1667
I expected this to give an error
```lua
---@class cool_tbl
---@field test fun():string[]
local my_tbl = {
    test = function()
        return {
            2,
            { ""test"" },
        }
    end,
}
```",True,0,NONE
https://api.github.com/repos/LuaLS/lua-language-server/issues/comments/1641655736,problem with table return type checking,Papipo,3,1438445851,2,1641655736,0,1438445851,2023-07-19T08:30:23Z,How is this coming along? Thanks!,False,0,NONE
https://api.github.com/repos/LuaLS/lua-language-server/issues/comments/1816796012,problem with table return type checking,max397574,3,1438445851,3,1816796012,0,1641655736,2023-11-17T17:12:31Z,"@sumneko any updates on this?
since 3.7 was already released",False,0,NONE
https://api.github.com/repos/LuaLS/lua-language-server/issues/comments/1816802782,problem with table return type checking,max397574,3,1438445851,4,1816802782,0,1816796012,2023-11-17T17:17:51Z,"here is the example where I encountered this problem again
```lua
---@return { [1]: string, [2]: string }[][]
local function x()
    return {
        { { 3, ""b"" } },
        { { ""c"", ""d"" } },
    }
end
```
",False,0,NONE
https://api.github.com/repos/LuaLS/lua-language-server/issues/1678,3.6.0 Started overriding my code coloring,Wutname1,4,1440830363,1,1440830363,0,0,2022-11-08T20:05:11Z,"### How are you using the lua-language-server?

Visual Studio Code Extension (sumneko.lua)

### Which OS are you using?

Windows

### What is the issue affecting?

Other

### Expected Behaviour

Not to override all my editor colors

### Actual Behaviour

3.6.0 Started overriding my code coloring and there does not seem to be an option to stop it.

### Reproduction steps

Update to 3.6.0+

### Additional Notes

_No response_

### Log File

_No response_",True,0,NONE
https://api.github.com/repos/LuaLS/lua-language-server/issues/comments/1308254823,3.6.0 Started overriding my code coloring,sumneko,4,1440830363,2,1308254823,0,1440830363,2022-11-09T06:03:06Z,Please provide screenshot with command `editor.action.inspectTMScopes`,False,0,COLLABORATOR
https://api.github.com/repos/LuaLS/lua-language-server/issues/comments/1308304463,3.6.0 Started overriding my code coloring,Wutname1,4,1440830363,3,1308304463,0,1308254823,2022-11-09T07:05:35Z,"![image](https://user-images.githubusercontent.com/704321/200761353-65c6a0f9-97fa-43c8-a8b8-1be80947738d.png) 
![image](https://user-images.githubusercontent.com/704321/200761654-9d1e4d2e-d07c-4a31-a722-5c984f21f2f2.png)
![image](https://user-images.githubusercontent.com/704321/200761789-8160a095-0e5c-466e-aa6a-6b2afe489bbf.png)

When I open the workspace everything looks fine until the extension finishes loading/scanning everything then it changes the styles.",False,0,NONE
https://api.github.com/repos/LuaLS/lua-language-server/issues/comments/1308307234,3.6.0 Started overriding my code coloring,sumneko,4,1440830363,4,1308307234,0,1308304463,2022-11-09T07:08:21Z,"Maybe you are looking for `Lua.semantic.enable`.
~Otherwise~ Besides, you can custom semantic style by `editor.semanticTokenColorCustomizations`",False,0,COLLABORATOR
https://api.github.com/repos/LuaLS/lua-language-server/issues/comments/1309179258,3.6.0 Started overriding my code coloring,Wutname1,4,1440830363,5,1309179258,0,1308307234,2022-11-09T18:17:08Z,Thanks those will do it. ,False,0,NONE
https://api.github.com/repos/LuaLS/lua-language-server/issues/1680,Type checking regression,AFCMS,4,1440868003,1,1440868003,0,0,2022-11-08T20:35:11Z,"### How are you using the lua-language-server?

Visual Studio Code Extension (sumneko.lua)

### Which OS are you using?

Linux

### What is the issue affecting?

Type Checking

### Expected Behaviour

It seems to be a regression, as it worked just fine a few weeks ago.

The parameters I used should be accepted. 

### Actual Behaviour

![image](https://user-images.githubusercontent.com/61794590/200668491-d534eea2-3088-4d03-bf74-160039cf5fb9.png)
![image](https://user-images.githubusercontent.com/61794590/200668538-fc2af74a-d4f2-429d-bb2f-4fe70444232b.png)


### Reproduction steps

Try something like this:

```lua
---@class some_thing
---@field test string|string[]

---@param s some_thing
function test(s)
end

test({test = {""dd""}})
```


### Additional Notes

None

### Log File

[file.log](https://github.com/sumneko/lua-language-server/files/9965024/file.log)
",True,0,NONE
https://api.github.com/repos/LuaLS/lua-language-server/issues/comments/1308267216,Type checking regression,sumneko,4,1440868003,2,1308267216,0,1440868003,2022-11-09T06:17:55Z,I cannot reproduce this with your example code.,False,0,COLLABORATOR
https://api.github.com/repos/LuaLS/lua-language-server/issues/comments/1308529197,Type checking regression,AFCMS,4,1440868003,3,1308529197,0,1308267216,2022-11-09T10:20:05Z,"Here is the exact code I used:

```lua
---@meta

---@class craft_recipe
---@field type '""shaped""'|'""shapeless""'|'""toolrepair""'|'""cooking""'|'""fuel""'
---@field output string
---@field recipe string|string[]|string[][]
---@field replacements string[][]
---@field additional_wear number
---@field cooktime number
---@field burntime number

---Register a craft recipe
---@param recipe craft_recipe
function minetest.register_craft(recipe) end
```",False,0,NONE
https://api.github.com/repos/LuaLS/lua-language-server/issues/comments/1308550072,Type checking regression,sumneko,4,1440868003,4,1308550072,0,1308529197,2022-11-09T10:37:31Z,"The example code should be:

```lua
---@type string|string[]|string[][]
local t = {{'a'}}
```",False,0,COLLABORATOR
https://api.github.com/repos/LuaLS/lua-language-server/issues/comments/1309227372,Type checking regression,AFCMS,4,1440868003,5,1309227372,0,1308550072,2022-11-09T19:03:51Z,:+1::+1::+1:,False,0,NONE
https://api.github.com/repos/LuaLS/lua-language-server/issues/1685,Allow enums to be specific elements of a table and not the whole table,AFCMS,4,1444064267,1,1444064267,0,0,2022-11-10T15:02:03Z,"The Minetest engine give access to most of his API with the `minetest` global table (+300 fields).

Some functions except an enum, but the enum values are stored in the global table:

https://github.com/minetest/minetest/blob/master/doc/lua_api.txt#L5668-L5673

A way to make an enum out of specific values of a table should be added IMO.",True,0,NONE
https://api.github.com/repos/LuaLS/lua-language-server/issues/comments/1324995562,Allow enums to be specific elements of a table and not the whole table,sumneko,4,1444064267,2,1324995562,0,1444064267,2022-11-23T12:36:52Z,I think you can just use `---@alias` instead of `---@enum`,False,0,COLLABORATOR
https://api.github.com/repos/LuaLS/lua-language-server/issues/comments/1325040796,Allow enums to be specific elements of a table and not the whole table,AFCMS,4,1444064267,3,1325040796,0,1324995562,2022-11-23T13:11:12Z,"I can't use something like this:
```lua
---Block emerge status constants (for use with `minetest.emerge_area`)
minetest.EMERGE_CANCELLED = 0

---Block emerge status constants (for use with `minetest.emerge_area`)
minetest.EMERGE_ERRORED = 1

---Block emerge status constants (for use with `minetest.emerge_area`)
minetest.EMERGE_FROM_MEMORY = 2

---Block emerge status constants (for use with `minetest.emerge_area`)
minetest.EMERGE_FROM_DISK = 3

---Block emerge status constants (for use with `minetest.emerge_area`)
minetest.EMERGE_GENERATED = 4

---@alias emerge_status
---| minetest.EMERGE_CANCELLED
---| minetest.EMERGE_ERRORED
---| minetest.EMERGE_FROM_MEMORY
---| minetest.EMERGE_FROM_DISK
---| minetest.EMERGE_GENERATED
```

Type names are undefined in that case.

I don't want to alias the real values, since these values are internal and should not be used directly.",False,0,NONE
https://api.github.com/repos/LuaLS/lua-language-server/issues/comments/1325048479,Allow enums to be specific elements of a table and not the whole table,sumneko,4,1444064267,4,1325048479,0,1325040796,2022-11-23T13:14:44Z,"```lua
---@alias emerge_status
---| `minetest.EMERGE_CANCELLED`
---| `minetest.EMERGE_ERRORED`
---| `minetest.EMERGE_FROM_MEMORY`
---| `minetest.EMERGE_FROM_DISK`
---| `minetest.EMERGE_GENERATED`
```",False,0,COLLABORATOR
https://api.github.com/repos/LuaLS/lua-language-server/issues/comments/1325064633,Allow enums to be specific elements of a table and not the whole table,AFCMS,4,1444064267,5,1325064633,0,1325048479,2022-11-23T13:24:01Z,"Thanks it works!!

Maybe this usecase could be added to the `---@alias`  tag tooltip?",False,0,NONE
https://api.github.com/repos/truecharts/charts/issues/4436,fix(magicmirror2) remove config extras,xstar97,5,1449384750,1,1449384750,0,0,2022-11-15T08:37:27Z,"**Description**
remove excess config map causing read-only access to the config file.

⚒️ Fixes  # <!--(issue)-->

**⚙️ Type of change**

- [ ] ⚙️ Feature/App addition
- [X] 🪛 Bugfix
- [X] ⚠️ Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [X] 🔃 Refactor of current code

**🧪 How Has This Been Tested?**
<!--
Please describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration
-->

**📃 Notes:**
<!-- Please enter any other relevant information here -->

**✔️ Checklist:**

- [X] ⚖️ My code follows the style guidelines of this project
- [X] 👀 I have performed a self-review of my own code
- [ ] #️⃣ I have commented my code, particularly in hard-to-understand areas
- [ ] 📄 I have made corresponding changes to the documentation
- [ ] ⚠️ My changes generate no new warnings
- [ ] 🧪 I have added tests to this description that prove my fix is effective or that my feature works
- [X] ⬆️ I increased versions for any altered app according to semantic versioning

**➕ App addition**

If this PR is an app addition please make sure you have done the following.

- [ ] 🪞 I have opened a PR on [truecharts/containers](https://github.com/truecharts/containers) adding the container to TrueCharts mirror repo.
- [ ] 🖼️ I have added an icon in the Chart's root directory called `icon.png`

---

_Please don't blindly check all the boxes. Read them and only check those that apply.
Those checkboxes are there for the reviewer to see what is this all about and
the status of this PR with a quick glance._
",True,0,CONTRIBUTOR
https://api.github.com/repos/truecharts/charts/issues/comments/1314981348,fix(magicmirror2) remove config extras,stavros-k,5,1449384750,2,1314981348,0,1449384750,2022-11-15T08:48:55Z,"I don't see a point having the app if users have to go to shell to configure every aspect of it.
That makes it no different than the custom-app.

Either the rest of the settings will be templated and have a UI or remove it...",False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1314982947,fix(magicmirror2) remove config extras,xstar97,5,1449384750,3,1314982947,0,1314981348,2022-11-15T08:50:30Z,"> I don't see a point having the app if users have to go to shell to configure every aspect of it. That makes it no different than the custom-app.
> 
> Either the rest of the settings will be templated and have a UI or remove it...

thats the problem...how can we template custom js objects? there's a set limit of 1024 chars for string fields. IIRC.",False,0,CONTRIBUTOR
https://api.github.com/repos/truecharts/charts/issues/comments/1314985743,fix(magicmirror2) remove config extras,stavros-k,5,1449384750,4,1314985743,0,1314982947,2022-11-15T08:53:08Z,"> thats the problem...how can we template custom js objects? there's a set limit of 1024 chars for string fields. IIRC.

There is no arbitrary js objects here.

It needs very few things. Very easily templated. I might do it at when I have time",False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1315021545,fix(magicmirror2) remove config extras,xstar97,5,1449384750,5,1315021545,0,1314985743,2022-11-15T09:20:13Z,"
> It needs very few things. Very easily templated. I might do it at when I have time

ill close this PR then",False,0,CONTRIBUTOR
https://api.github.com/repos/truecharts/charts/issues/comments/1483956153,fix(magicmirror2) remove config extras,truecharts-admin,5,1449384750,6,1483956153,0,1315021545,2023-03-26T00:24:00Z,This PR is locked to prevent necro-posting on closed PRs. Please create a issue or contact staff on discord if you want to further discuss this,False,0,COLLABORATOR
https://api.github.com/repos/truecharts/charts/issues/4438,[Add]: Nicotine+,heroku-miraheze,3,1449583516,1,1449583516,0,0,2022-11-15T10:58:28Z,"### Short description of the app

Nicotine+ is a graphical client for the [Soulseek](https://www.slsknet.org/) peer-to-peer network.


### Sources

https://hub.docker.com/r/paulbismuth0/nicotine-plus
https://github.com/paulbismuth/nicotine-plus-docker

### I've read and agree with the following

- [X] I've checked all open and closed issues and my request is not there.
- [X] I've checked all open and closed pull requests and my request is not there.",True,0,NONE
https://api.github.com/repos/truecharts/charts/issues/comments/1546989192,[Add]: Nicotine+,truecharts-admin,3,1449583516,2,1546989192,0,1449583516,2023-05-14T20:01:01Z,This issue has been automatically marked as stale because it has not had recent activity. It will be closed in two weeks if no further activity occurs. Thank you for your contributions.,False,0,COLLABORATOR
https://api.github.com/repos/truecharts/charts/issues/comments/1547365172,[Add]: Nicotine+,Ornias1993,3,1449583516,3,1547365172,0,1546989192,2023-05-15T07:55:07Z,"We've decided to not-accept issues for chart requests anymore, because the vast majority of the issue tracker if flooded with them and we don't (and never have) actually plan to do anything with chart requests as maintainers.

Please join the discord to continue discussing chart requests :)",False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1558261491,[Add]: Nicotine+,truecharts-admin,3,1449583516,4,1558261491,0,1547365172,2023-05-23T00:22:39Z,This issue is locked to prevent necro-posting on closed issues. Please create a new issue or contact staff on discord of the problem persists,False,0,COLLABORATOR
https://api.github.com/repos/truecharts/charts/issues/4453,docker-compose upgrade losing the Ingress configuration section,qraynaud,9,1450001485,1,1450001485,0,0,2022-11-15T15:50:11Z,"### App Name

docker-compose

### SCALE Version

22.02.4

### App Version

 20.10.21_5.0.0

### Application Configuration

![image](https://user-images.githubusercontent.com/65991/201963889-15779f20-69df-4cea-b2f1-de1b30a9e3f4.png)

### Describe the bug

I upgraded my docker-compose app from `20.10.21_3.0.11` to `20.10.21_5.0.0`. I used the `Ingress` configuration section but it disappeared after upgrade. Right now it does not work anymore.

### To Reproduce

I don’t think it’s possible to reproduce since scale does not seem to allow to install old app versions.

### Expected Behavior

The Ingress section should still be available.

### I've read and agree with the following

- [X] I've checked all open and closed issues and my issue is not there.",True,0,NONE
https://api.github.com/repos/truecharts/charts/issues/comments/1315563799,docker-compose upgrade losing the Ingress configuration section,Ornias1993,9,1450001485,2,1315563799,0,1450001485,2022-11-15T16:29:23Z,"""additional ingress"" is not a supported option.
I'll make a note to thoroughly flag it as ""advanced"" like it shouldn've been :)",False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1316823152,docker-compose upgrade losing the Ingress configuration section,qraynaud,9,1450001485,3,1316823152,0,1315563799,2022-11-16T11:09:39Z,"@Ornias1993 I know this is advanced, but what harm does it do to just keep the section available? It was removed and now I have an app that is not working since I rollbacked it (I did not know rollback was not supported on major versions) and I can’t even reinstall from scratch since the ingress settings were removed. It was working real fine…

I'm just asking for the option to be re-added on the app. Not to have any support on it.",False,0,NONE
https://api.github.com/repos/truecharts/charts/issues/comments/1316843532,docker-compose upgrade losing the Ingress configuration section,Ornias1993,9,1450001485,4,1316843532,0,1316823152,2022-11-16T11:26:59Z,"To be honest, I read your ticket wrong, I understood the input was being wiped... sorry!

The removal was not even really on-purpose, but it's a side effect of another change.

However: That section being available here, was an accident. It should never have been there in the first place, as the docker-compose app is supposed to be an ""out of ecosystem"" App.

At the same time additional services (also required for additional ingress) shouldn't be available on it either.

Our main reasoning is that the docker-compose app should work like it's ran ""on the host"", with all the downsides that come with it. We don't want it to be an ""enhanced"" ""variant"" of docker compose with ingress and kubernetes tie-in.",False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1316911104,docker-compose upgrade losing the Ingress configuration section,qraynaud,9,1450001485,5,1316911104,0,1316843532,2022-11-16T12:10:49Z,"I understood the point about the ""outside the ecosystem"" part. It was not something that sat well with be. I understood I would get no support for it but I LOVED the fact that you let all the needed options to make it happen at my own risks. And I  successfully made it work in the ecosystem like a charm. It’s not even that hard when you understand the options you provide(d).

I can understand that you might want to hide all this stuff in an `Advanced` thing not easily used for now (though I think this is sad since you are so close to make it work perfectly inside the ecosystem) but really, I would love this to be kept possible.",False,0,NONE
https://api.github.com/repos/truecharts/charts/issues/comments/1316954590,docker-compose upgrade losing the Ingress configuration section,Ornias1993,9,1450001485,6,1316954590,0,1316911104,2022-11-16T12:37:33Z,We've discussed this internally and will re-add the custom ingress on this app specifically.,False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1317650513,docker-compose upgrade losing the Ingress configuration section,qraynaud,9,1450001485,7,1317650513,0,1316954590,2022-11-16T20:48:35Z,Thanks! That’s awesome news!,False,0,NONE
https://api.github.com/repos/truecharts/charts/issues/comments/1465887218,docker-compose upgrade losing the Ingress configuration section,Ornias1993,9,1450001485,8,1465887218,0,1317650513,2023-03-13T10:32:23Z,fixed in the dev branch for moving to new common,False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1474080495,docker-compose upgrade losing the Ingress configuration section,qraynaud,9,1450001485,9,1474080495,0,1465887218,2023-03-17T16:18:26Z,Thanks a lot @Ornias1993!,False,0,NONE
https://api.github.com/repos/truecharts/charts/issues/comments/1483625341,docker-compose upgrade losing the Ingress configuration section,truecharts-admin,9,1450001485,10,1483625341,0,1474080495,2023-03-25T00:20:21Z,This issue is locked to prevent necro-posting on closed issues. Please create a new issue or contact staff on discord of the problem persists,False,0,COLLABORATOR
https://api.github.com/repos/truecharts/charts/issues/4454,helm repo not working !!!,jadsy2107,4,1450071740,1,1450071740,0,0,2022-11-15T16:38:19Z,"### App Name

helm install nginx-proxy-manager TrueCharts/nginx-proxy-manager

### SCALE Version

Not using SCALE

### App Version

helm install nginx-proxy-manager TrueCharts/nginx-proxy-manager

### Application Events

```Shell
helm install nginx-proxy-manager TrueCharts/nginx-proxy-manager
```


### Application Logs

```Shell
helm install nginx-proxy-manager TrueCharts/nginx-proxy-manager
Error: INSTALLATION FAILED: chart ""nginx-proxy-manager"" matching  not found in TrueCharts index. (try 'helm repo update'): no chart name found
```


### Application Configuration

helm install nginx-proxy-manager TrueCharts/nginx-proxy-manager


### Describe the bug

helm install nginx-proxy-manager TrueCharts/nginx-proxy-manager


### To Reproduce

helm install nginx-proxy-manager TrueCharts/nginx-proxy-manager


### Expected Behavior

helm install nginx-proxy-manager TrueCharts/nginx-proxy-manager


### Screenshots

helm install nginx-proxy-manager TrueCharts/nginx-proxy-manager


### Additional Context

helm install nginx-proxy-manager TrueCharts/nginx-proxy-manager


### I've read and agree with the following

- [X] I've checked all open and closed issues and my issue is not there.",True,0,NONE
https://api.github.com/repos/truecharts/charts/issues/comments/1315593804,helm repo not working !!!,bikram990,4,1450071740,2,1315593804,0,1450071740,2022-11-15T16:50:36Z,"looks like `index.yaml` was recreated recently and all of the apps are missing in the new `index.yaml`, only dependencies are present

https://github.com/truecharts/charts/commits/gh-pages/index.yaml",False,0,NONE
https://api.github.com/repos/truecharts/charts/issues/comments/1315637377,helm repo not working !!!,Ornias1993,4,1450071740,3,1315637377,0,1315593804,2022-11-15T17:22:12Z,"Please actually follow our announcements on twitter, facebook or, preferably, discord before filing issues on github.
We've stopped offering helm charts and our latest releases might even actually damage your cluster when installed outside of SCALE Apps.",False,0,MEMBER
https://api.github.com/repos/truecharts/charts/issues/comments/1315649428,helm repo not working !!!,bikram990,4,1450071740,4,1315649428,0,1315637377,2022-11-15T17:32:20Z,This is very inconvenient that such destructive announcements are not added to project README.,False,0,NONE
https://api.github.com/repos/truecharts/charts/issues/comments/1315662389,helm repo not working !!!,Ornias1993,4,1450071740,5,1315662389,0,1315649428,2022-11-15T17:44:49Z,"> This is very inconvenient that such destructive announcements are not added to project README.

Luckily this is what I would consider ""self-solving"" convenience. 

Note:
We never ever had any announcements in the readme. Including any of the breaking changes.",False,0,MEMBER
https://api.github.com/repos/laravel/framework/issues/45045,[9.x] Add ability to set middleware on PendingDispatch job,dammy001,3,1458423810,1,1458423810,0,0,2022-11-21T18:52:55Z,"<!--
Please only send a pull request to branches that are currently supported: https://laravel.com/docs/releases#support-policy 

If you are unsure which branch your pull request should be sent to, please read: https://laravel.com/docs/contributions#which-branch

Pull requests without a descriptive title, thorough description, or tests will be closed.

In addition, please describe the benefit to end users; the reasons it does not break any existing features; how it makes building web applications easier, etc.
-->
",True,0,CONTRIBUTOR
https://api.github.com/repos/laravel/framework/issues/comments/1322507823,[9.x] Add ability to set middleware on PendingDispatch job,dammy001,3,1458423810,2,1322507823,0,1458423810,2022-11-21T18:54:13Z,"Example

```php
ProcessPodcast::dispatch($podcast)->middleware([new ThrottlesExceptions(10, 5)]);
```",False,0,CONTRIBUTOR
https://api.github.com/repos/laravel/framework/issues/comments/1322705697,[9.x] Add ability to set middleware on PendingDispatch job,taylorotwell,3,1458423810,3,1322705697,0,1322507823,2022-11-21T22:00:01Z,I would just put it in the job.,False,0,MEMBER
https://api.github.com/repos/laravel/framework/issues/comments/1322901241,[9.x] Add ability to set middleware on PendingDispatch job,dammy001,3,1458423810,4,1322901241,0,1322705697,2022-11-22T01:51:57Z,Why if I want to set different middlewares for same job?,False,0,CONTRIBUTOR
https://api.github.com/repos/laravel/framework/issues/45052,[9.x] Create new `schema:load` Artisan command,calebdw,3,1460609595,1,1460609595,0,0,2022-11-22T21:58:40Z,"<!--
Please only send a pull request to branches that are currently supported: https://laravel.com/docs/releases#support-policy 

If you are unsure which branch your pull request should be sent to, please read: https://laravel.com/docs/contributions#which-branch

Pull requests without a descriptive title, thorough description, or tests will be closed.

In addition, please describe the benefit to end users; the reasons it does not break any existing features; how it makes building web applications easier, etc.
-->

Hello,

Currently any existing schema files are loaded by the `migrate`/`migrate:fresh` commands when creating a new database. However, I have a couple of  non-default connections that need their schema files to be loaded but *without performing any migrations on those connections*---which is not possible at the moment.

This PR plucks the schema loading logic out of the `migrate` command and creates the sister command to `schema:dump`---namely, it loads/restores a schema file for a given database, but *does not perform any migrations*.


Thanks!",True,0,CONTRIBUTOR
https://api.github.com/repos/laravel/framework/issues/comments/1325662730,[9.x] Create new `schema:load` Artisan command,taylorotwell,3,1460609595,2,1325662730,0,1460609595,2022-11-23T21:13:21Z,I don't really want to make these changes on a patch release. You could likely write your own custom command in your application to do this?,False,0,MEMBER
https://api.github.com/repos/laravel/framework/issues/comments/1325666375,[9.x] Create new `schema:load` Artisan command,calebdw,3,1460609595,3,1325666375,0,1325662730,2022-11-23T21:18:02Z,"@taylorotwell,

Yes, I could move the `schema:load` command into my own application but I thought it would be useful to the community at large.

Would you be willing to consider adding this in the next major release?",False,0,CONTRIBUTOR
https://api.github.com/repos/laravel/framework/issues/comments/1326087037,[9.x] Create new `schema:load` Artisan command,driesvints,3,1460609595,4,1326087037,0,1325666375,2022-11-24T08:06:26Z,@CalebDW I think it's best to just write your own custom command for now. Thanks,False,0,MEMBER
https://api.github.com/repos/laravel/framework/issues/45059,"[HTTP Client] ""withHeaders"" method do not overwrite previous headers.",juanparati,3,1461605811,1,1461605811,0,0,2022-11-23T11:44:29Z,"<!-- DO NOT THROW THIS AWAY -->
<!-- Fill out the FULL versions with patch versions -->

- Laravel Version: 9.26.0 and 9.36.1
- PHP Version: 8.1.10
- Database Driver & Version: None

### Description:

I observed that when ""withHeaders"" method is called twice passing the same header, the HTTP Client appends the header value. Despite that that line folding was supported in the old [RFC 2616](https://www.ietf.org/rfc/rfc2616.txt), is obsolete according to [RFC 7230]( https://www.rfc-editor.org/rfc/rfc7230#section-3.2.4). That is means that the right behavior when headers are added is to overwrite the value instead of append it because each header should use one line.

### Steps To Reproduce:

```php
use Illuminate\Support\Facades\Http;

$myClient = Http::retry(2);

$myClient->withHeaders(['X-Token' => 'foo']);           // X-Token = foo
$myClient->post('https://example.net/foobar');

$myClient->withHeaders(['X-Token' => 'bar']);           // X-Token = [foo, bar]
$myClient->post('https://example.net/foobar');
```

#### Explanation:

The method ""withHeaders"" use ""array_merge_recursive"" in order to merge the headers, the method ""array_merge_recursive"" it appends the elements that already exists instead of overwrite the values. Replacing ""array_merge"" by ""array_merge_recursive"" can fix the problem.
",True,0,CONTRIBUTOR
https://api.github.com/repos/laravel/framework/issues/comments/1324957848,"[HTTP Client] ""withHeaders"" method do not overwrite previous headers.",WendellAdriel,3,1461605811,2,1324957848,0,1461605811,2022-11-23T12:06:11Z,"That's interesting!
I could work on a PR for that if someone approves this update",False,0,CONTRIBUTOR
https://api.github.com/repos/laravel/framework/issues/comments/1325020108,"[HTTP Client] ""withHeaders"" method do not overwrite previous headers.",driesvints,3,1461605811,3,1325020108,0,1324957848,2022-11-23T13:00:35Z,I think it's best that you start a new HTTP request for the second call.,False,0,MEMBER
https://api.github.com/repos/laravel/framework/issues/comments/1326123093,"[HTTP Client] ""withHeaders"" method do not overwrite previous headers.",juanparati,3,1461605811,4,1326123093,0,1325020108,2022-11-24T08:41:06Z,"I use ""withOptions"" method instead of ""withHeaders"" as a workaround.

Example:

```php
$client->withOptions(['headers' => ['X-Token' => 'foo']]);
```

I can observed that ""withOptions"" overwrite the all the values instead of append them.",False,0,CONTRIBUTOR
https://api.github.com/repos/laravel/framework/issues/45064,Relationship is empty after using `hasAttached()` with model that `$touches` its parent,bakerkretzmar,4,1462464231,1,1462464231,0,0,2022-11-23T22:04:22Z,"<!-- DO NOT THROW THIS AWAY -->
<!-- Fill out the FULL versions with patch versions -->

- Laravel Version: 9.41.0
- PHP Version: 8.1.11
- Database Driver & Version: SQLite 3.37.0 and MySQL 8.0.30

### Description:

Using the `hasAttached()` factory method to relate models, if either model `$touches` the relationship, the model instances will not be related correctly after being created—their relations to each other will be loaded but empty.

### Steps To Reproduce:

- New Laravel app demonstrating this issue: https://github.com/bakerkretzmar/laravel-has-attached-touches-bug (see [this test](https://github.com/bakerkretzmar/laravel-has-attached-touches-bug/blob/main/tests/Feature/ExampleTest.php))

- Failing `laravel/framework` test case: https://github.com/laravel/framework/compare/9.x...bakerkretzmar:framework:fix-factory-relations-with-touches

You have two Eloquent models, e.g. `User` and `Group`, connected with a BelongsToMany relationship. We want users to have their timestamps updated any time any of their groups are updated, so the `Group` model contains `protected $touches = ['users']`.

In a test, you create a user and group and attach them:

```php
$user = User::factory()->create();
$group = Group::factory()->hasAttached($user)->create();

$this->assertCount(1, $group->users);
```

That assertion fails.

The `users` relation is set on the new `$group` model, _as if_ it was just loaded from the database, but it's an empty collection (output from `dump($group)` inside the above test):

<img width=""498"" alt=""image"" src=""https://user-images.githubusercontent.com/18192441/203652395-00936003-d36a-49b3-8ee8-a329cb7ffabf.png"">

This only happens when one of the models has the relationship listed in its `$touches` property.",True,0,CONTRIBUTOR
https://api.github.com/repos/laravel/framework/issues/comments/1326166404,Relationship is empty after using `hasAttached()` with model that `$touches` its parent,github-actions[bot],4,1462464231,2,1326166404,0,1462464231,2022-11-24T09:18:42Z,"Thank you for reporting this issue!

As Laravel is an open source project, we rely on the community to help us diagnose and fix issues as it is not possible to research and fix every issue reported to us via GitHub.
If possible, please make a pull request fixing the issue you have described, along with corresponding tests. All pull requests are promptly reviewed by the Laravel team.

Thank you!",False,0,NONE
https://api.github.com/repos/laravel/framework/issues/comments/1326418648,Relationship is empty after using `hasAttached()` with model that `$touches` its parent,WendellAdriel,4,1462464231,3,1326418648,0,1326166404,2022-11-24T12:58:34Z,"Hello @bakerkretzmar @driesvints 
I worked on a fix for this, but I'm not sure if this is correct so IDK if I should create the PR already here or not, can you help me check and guide me if I should create this PR or not?",False,0,CONTRIBUTOR
https://api.github.com/repos/laravel/framework/issues/comments/1326678543,Relationship is empty after using `hasAttached()` with model that `$touches` its parent,bakerkretzmar,4,1462464231,4,1326678543,0,1326418648,2022-11-24T16:52:11Z,"@WendellAdriel that looks like it might work... but I'm actually not so sure anymore whether this is a bug. It might just be how `$touches` works, although to me it was quite unintuitive. Here's another example that's weird but I guess correct if I think about it:

```php
$user = User::create();

// Because of `$touches`, this automatically loads the `users` relationship, which is empty
$group = Group::create();

// This attaches the user correctly but does not reload the relationship
$group->users()->attach($user);

// Empty collection, because it uses the already-loaded (empty) relationship
dump($group->users);
```

Is that expected? Just something people need to be aware of and account for when using `$touches`?",False,0,CONTRIBUTOR
https://api.github.com/repos/laravel/framework/issues/comments/1326683535,Relationship is empty after using `hasAttached()` with model that `$touches` its parent,WendellAdriel,4,1462464231,5,1326683535,0,1326678543,2022-11-24T16:58:12Z,"@bakerkretzmar that's interesting. IDK either if that's a bug or not TBH
I worked on that fix but we would need to know the expected behaviour first to be able to check if that's a bug or not and what would be the best solution for that. I think we have to wait on more feedback on this. But that's a good catch and it was good for me to start looking at how things work on this side of the framework since I'm just starting out to try to contribute to it",False,0,CONTRIBUTOR
https://api.github.com/repos/Warzone2100/warzone2100/issues/3014,Artillery units get detached from a commander when they get repaired,highlander1599,5,1460199132,1,1460199132,0,0,2022-11-22T16:33:38Z,"**Describe the bug**
MRA units assigned to a commander get detached when the MRA unit gets damaged

**To Reproduce**
Steps to reproduce the behavior:
1. Produce an ~~MRA~~ artillery unit and a commander
2. Assign the ~~MRA~~ artillery unit to the commander
3. Damage the ~~MRA~~ artillery unit
4. Let it get repaired
5. See the ~~MRA~~ artillery unit detached

**Expected behavior**
The ~~MRA~~ artillery units should stay assigned

**Your System:**
 - OS: Windows 7 64 bit
 - Game version: master version 3a1a066
 
**Additional context**
This sucks too (like #3013 )
Edit: I missed the real cause for detaching ~~MRA~~ artillery units. It's not when it gets damaged but after it gets repaired and tries to move to the rally point despite its hold order. Refers to #3013 
Edit 2: Happens also to Bombards.
",True,0,CONTRIBUTOR
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1324179527,Artillery units get detached from a commander when they get repaired,DARwins1,5,1460199132,2,1324179527,0,1460199132,2022-11-22T20:03:47Z,I will take this opportunity to reference this (related) old request here: #1621 ,False,0,CONTRIBUTOR
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1331005982,Artillery units get detached from a commander when they get repaired,gantsevdenis,5,1460199132,3,1331005982,0,1324179527,2022-11-29T17:17:01Z,"I tested, in version 4.2.7,  Artillery unit gets ""detached"" too (in quotes, because it is technically not ""attached"" but only in ""FIRESUPPORT"" mode).
So this doesn't look like an issue to me?",False,0,CONTRIBUTOR
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1331101244,Artillery units get detached from a commander when they get repaired,highlander1599,5,1460199132,4,1331101244,0,1331005982,2022-11-29T18:19:52Z,"> I tested, in version 4.2.7, Artillery unit gets ""detached"" too (in quotes, because it is technically not ""attached"" but only in ""FIRESUPPORT"" mode). So this doesn't look like an issue to me?

First, this did not happen in earlier versions. 
Second, units should only released from FIRESUPPORT if the player decide it.
I'm very busy with RL stuff currently but I will make a test on Friday if this also happens if the artillery is ""attached"" to a sensor tower. If yes, it would make CB towers useless for artillery units.

For me it's still and clearly an issue.",False,0,CONTRIBUTOR
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1331166146,Artillery units get detached from a commander when they get repaired,gantsevdenis,5,1460199132,5,1331166146,0,1331101244,2022-11-29T19:08:37Z,"Take your time, but i just tested 4.2.7, and indeed, Artillery (with ""Retreat at Medium damage""), attached to a Sensor Tower, when gets damaged, goes to repair station, and then moves to rally point; and loses FIRESUPPORT. It then terminates with GUARD order.",False,0,CONTRIBUTOR
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1332394679,Artillery units get detached from a commander when they get repaired,highlander1599,5,1460199132,6,1332394679,0,1331166146,2022-11-30T16:03:25Z,"@gantsevdenis 
I think I wasn't precise enough with my issue. Artillery units set to ""retreat at medium/heavy damage and get medium/heavy damaged should move to the Repair Facility rally point. The problem is that artillery units that take only one hit and are still on green health are released from FIRESUPPORT and move to the rally point. And this should not be.",False,0,CONTRIBUTOR
https://api.github.com/repos/Warzone2100/warzone2100/issues/3022,(MP)Heavy Repair Turret & Repair Facility Tweak,Tipchik87,3,1465542800,1,1465542800,0,0,2022-11-27T18:54:58Z,"Currently, players have stopped using the Repair Facility for the following reasons:
1. Repair Facility needs to be explored even at the start with Full Base.
2. Repair Facility is inferior to Heavy Repair Turret in unit repair speed and at the same time HRT is already available for production at the start with a Full Base. In addition, mobile HRTs can be produced by more than 5 units. The more HRT the higher the repair rate.
3. Repair Facility has no chassis and therefore no ability to move quickly in case of need.

Based on all of the above, I made the appearance of HRT at the same time as the Repair Facility, which means that now at the start with the Full Base you will need to investigate HRT. In addition, I increased the ""repairPoints"" parameter for Repair Facility from 40 to 50. As a result, one Repair Facility will still be second to two HRTs in repair speed (50 points vs. 30+30), but you'll need to occupy factories to make HRTs, while Repair Facility does not. Seems like everything is fair here and there is some sort of balance than it was before
_______
To make the regular Repair Turret more popular on low and high oil I reduced the production time and the price a bit. Compared to Cyborg Mechanic and HRT, it now looks more balanced ",True,0,CONTRIBUTOR
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1333922401,(MP)Heavy Repair Turret & Repair Facility Tweak,Evolution01,3,1465542800,2,1333922401,0,1465542800,2022-12-01T15:15:59Z,"It is necessary to remove the ""mandatory"" distance between the building Repair Facility.",False,0,CONTRIBUTOR
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1335609624,(MP)Heavy Repair Turret & Repair Facility Tweak,maxsupermanhd,3,1465542800,3,1335609624,0,1333922401,2022-12-02T17:57:04Z,You do you but I demand a repair turret to be available at full base setting. I disagree with this change.,False,0,MEMBER
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1336201536,(MP)Heavy Repair Turret & Repair Facility Tweak,Next67,3,1465542800,4,1336201536,0,1335609624,2022-12-03T17:18:38Z,"I don't like reducing the weight of the heavy repair turret, it will increase the speed of the units. This will further improve mobile repairs, and the use of heavy repair turrets will have priority over stationary workshops.
I propose not to touch the weight - in my opinion, this is a fee for mobility and good repairs.

Considering that the current request is more related to the full base, high oil mode, then making 10 repair units, instead of 10 combat units at the research stage of the heavy repair turret, is an easy and not dangerous task.",False,0,CONTRIBUTOR
https://api.github.com/repos/Warzone2100/warzone2100/issues/3032,Objective: Alpha base intelligence report: nexus. Mission failed automatically,grandadvance,9,1472093947,1,1472093947,0,0,2022-12-01T23:26:12Z,"The current mission automatically failed when transport with your cyborgs is coming to a new location

Steps to reproduce the behavior:
1. Create cyborg factory
2. Loaded cyborgs on transport
3. Send transport
4. Starting new mission, where the transport is coming
5. Objective failed notification is shown

 - Linux (Ubuntu 20.04)
 - Game version: [4.3.2]
 
Savegame folder is bellow
The problem savefile name is 11st1 and 11stBeta in campaign folder

![0](https://user-images.githubusercontent.com/107808446/205204251-6367672c-8efe-4bb0-9001-8df0219e232e.png)
![1](https://user-images.githubusercontent.com/107808446/205204261-453b00da-19f2-4fae-81d6-785b1956c486.png)
![2](https://user-images.githubusercontent.com/107808446/205204268-1e2368b0-fa2e-4be5-8dfc-5f1f10665372.png)
![3](https://user-images.githubusercontent.com/107808446/205204271-d3191a99-7dca-400a-8ba3-53200ca22cd2.png)
[savegames.zip](https://github.com/Warzone2100/warzone2100/files/10137970/savegames.zip)
",True,0,NONE
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1334681699,Objective: Alpha base intelligence report: nexus. Mission failed automatically,highlander1599,9,1472093947,2,1334681699,0,1472093947,2022-12-02T02:21:37Z,"@grandadvance  I couldn't reproduce this issue with your instructions, neither with version 4.3.2 nor with one of the latest master versions. I loaded 10 cyborgs into the transport at the beginning of mission sub-1_7 (aka Alpha 11), started the transporter, and could play the mission after the transporter has landed. Maybe I missed something but that's how I understand your instructions. I don't know if there are differences between the different OS versions because I use a Windows 64-bit version.",False,0,CONTRIBUTOR
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1334684690,Objective: Alpha base intelligence report: nexus. Mission failed automatically,grandadvance,9,1472093947,3,1334684690,0,1334681699,2022-12-02T02:27:13Z,"@highlander1599 yes, all instructions you make right. However your operation system is other. Therefore your trying was successful ))

Can you show PrintScreen of moment when mission is beginning after the transporter has landed?

There is probability that you checking other mission...
",False,0,NONE
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1334700479,Objective: Alpha base intelligence report: nexus. Mission failed automatically,highlander1599,9,1472093947,4,1334700479,0,1334684690,2022-12-02T02:58:33Z,"@grandadvance Here you are
![wz2100-20221202_035613-SUB_1_7](https://user-images.githubusercontent.com/47194838/205204883-129086dc-9fa0-4bd1-8d21-7438edb5fe4d.png)
",False,0,CONTRIBUTOR
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1334703354,Objective: Alpha base intelligence report: nexus. Mission failed automatically,grandadvance,9,1472093947,5,1334703354,0,1334700479,2022-12-02T03:03:32Z,@highlander1599 Yes this is exactly that mission,False,0,NONE
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1334718018,Objective: Alpha base intelligence report: nexus. Mission failed automatically,KJeff01,9,1472093947,6,1334718018,0,1334703354,2022-12-02T03:30:11Z,Can you upload the save folder (compressed into .zip)? Main Menu > Options > Open Configuration Directory > savegames/campaign.,False,0,MEMBER
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1334723909,Objective: Alpha base intelligence report: nexus. Mission failed automatically,grandadvance,9,1472093947,7,1334723909,0,1334718018,2022-12-02T03:42:27Z,@KJeff01 done )) The problem savefile name is 11st1 and 11stBeta in campaign folder,False,0,NONE
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1334749781,Objective: Alpha base intelligence report: nexus. Mission failed automatically,KJeff01,9,1472093947,8,1334749781,0,1334723909,2022-12-02T04:26:23Z,"Most fortunate you uploaded everything. We don't guarantee saves will function normally between very large version gaps such as 3.3.0 and current versions. Attempting to do so likely will cause strange and funny issues only you will experience, such as this.

It would be best to complete the rest of Alpha campaign on 3.3.0, as you initially started the Alpha campaign on, then switch to the latest version and simply start on Beta campaign from the main menu.",False,0,MEMBER
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1334752451,Objective: Alpha base intelligence report: nexus. Mission failed automatically,grandadvance,9,1472093947,9,1334752451,0,1334749781,2022-12-02T04:31:31Z,"@KJeff01 okay, thanks for advice! ))",False,0,NONE
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1343726607,Objective: Alpha base intelligence report: nexus. Mission failed automatically,KJeff01,9,1472093947,10,1343726607,0,1334752451,2022-12-09T01:44:13Z,Not really anything to fix but I will attempt to not show ancient saves so people can't load stuff if they are coming from say the Ubuntu Software Center versions or whatever.,False,0,MEMBER
https://api.github.com/repos/Warzone2100/warzone2100/issues/3040,Units are sometimes stuck or inactive during combat,Pangaea666,4,1489039333,1,1489039333,0,0,2022-12-10T22:15:29Z,"**Describe the bug**
During different missions in the campaign, I have noticed that units will sometimes be stuck or stay inactive during combat, not firing back. This has mostly been AI units, but it also occurred to cannon hardpoints at least once. Some of the instances that I happened to 'catch':

1) During the big NP invasion at the end of Alpha campaign, I blocked the mountain pass in the south of the map with bunkers and cannon hardpoints. When the NP approached, one of the cannons didn't fire for some reason, while the other 3 did. It eventually started firing, but it stayed inactive for a long time. All were on a line across, so all had the same distance to the enemy. The troublesome hardpoint was also in the middle, while the two on the side kept firing.

2) During Alpha 10, cyborgs got stuck on a hill in the SE. They stayed there, not doing anything for a couple of minutes.

3) Later in Alpha 10, the NP had overrun our defences in the north, so I had to go looking for them. On the plateau we found them, again it was cyborgs. Some of them just stood there, kinda turning on their own axis sometimes, and took shots in the face, without fighting back. Some NP tanks then came up from the south, and then the cyborgs started firing too. It looked related, maybe the tanks somehow spurred them into action, but ofc it could have been a coincidence too.

4) During Alpha 12, once again with cyborgs, they would sometimes move around a bit in front of us, but not really fight back. At least for a time. I saw this on the central ridge that is bottlenecked hard, and sometimes the units would just more or less stand there, or move around a little, but without firing back. Not as severe as in those alpha 6 instances, but then alpha 12 is very chaotic, so it's quite possible it happened without me noticing it.

**To Reproduce**
No idea what could trigger this unfortunately. But I suspect it has something to do with pathfinding, or not finding targets or something. 

**Expected behavior**
All units should fight back when fired upon, and when in range of enemy units.

**Screenshots or Videos**
If applicable, add screenshots to help explain your problem.

**Your System:**
 - OS: Linux Mint 21 Cinnamon
 - Game version: 4.3.2 (the .deb version)

**Additional context**
If relevant, I'm playing on Normal difficulty. The GPU is a Nvidia 770 GTX card, and I've played with Vulkan (not OpenGL). Also have the Art Revolution mod active, but I doubt that impacts actual gameplay.
PS: The save visible in one of the screenshots is unfortunately overwritten now (please add more saveslots!!), but the cyborgs started moving just about when I saved it, so it was probably of little use anyway at that point.

PS: The save visible in one of the screenshots is unfortunately overwritten now (please add more saveslots!!), but the cyborgs started moving just about when I saved it, so it was probably of little use anyway at that point.

![Stuck cyborgs2](https://user-images.githubusercontent.com/2002335/206877178-895b0e55-3c45-4eff-84c1-e6234ddd611e.jpg)
![Stuck cyborgs1](https://user-images.githubusercontent.com/2002335/206877179-01ecf25f-6297-4dd3-9d75-ccd182ffa220.jpg)
",True,0,NONE
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1345435809,Units are sometimes stuck or inactive during combat,KJeff01,4,1489039333,2,1345435809,0,1489039333,2022-12-11T02:10:14Z,"Some weapons need a minimum distance to fire at and won't fire if something is too close (or if another structure is blocking it). It's also possible the terrain is too bumpy and the required weapon angle is too extreme to lock onto a target (maps have an illusion of being oddly 2-dimensional cause of the default top-down camera angle, but try looking at the Beta 1 base you start off with on a tilted camera for a great example).

The movement behavior you are seeing is true to the original game and is intended. It's called ""patrol"" internally where units are told to try to move to a spot, for some allotted time, and then go to another. This I will not change as it could negatively affect many missions by allowing users to lure groups out of their patrol pathways to clear maps easily.

I think I saw that non-attacking behavior though on EBmod when I was testing Alpha 10 a bit ago and I fixed it by turning off regrouping movement for the cyborg groups. I think I'll do that here in the base game too. Those cyborgs most likely have the range to hit those units. I should probably rip out that infernal regrouping mechanism out of the campaign library, lol.",False,0,MEMBER
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1345445783,Units are sometimes stuck or inactive during combat,Pangaea666,4,1489039333,3,1345445783,0,1345435809,2022-12-11T03:22:20Z,"Perhaps this would be a different issue altogether, but I've also noticed that units under a commander will sometimes not attack enemies within range, and instead keep moving when I've made a move order. (Normally units fire while moving.) But if I directly target an enemy, they will instantly start firing.

Will check out the Beta 1 map and try to spot what you mean with the angles and terrain.",False,0,NONE
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1345451398,Units are sometimes stuck or inactive during combat,KJeff01,4,1489039333,4,1345451398,0,1345445783,2022-12-11T04:06:26Z,"Believe it or not, units attached to a Commander are explicitly programmed to feel depression during combat at times, especially so if a good comrade dies next to one, and that can result in them not wanting to attack for however long. Of course, it can be overridden by forcing a target command. Actually called the ""sulk action"" though I think the timer needs to be looked at closer and if it's working correctly.",False,0,MEMBER
https://api.github.com/repos/Warzone2100/warzone2100/issues/comments/1345662746,Units are sometimes stuck or inactive during combat,Pangaea666,4,1489039333,5,1345662746,0,1345451398,2022-12-11T21:36:55Z,"Oh wow! Definitely didn't know that was a thing. Would it happen to all units simultaneously? I didn't lose any units in those fights where I noticed this non-firing behaviour, but I suppose it's still possible they were all ""sulking"".",False,0,NONE
https://api.github.com/repos/rubygems/rubygems/issues/6259,"""gem install"" installs logs and other ""noisy"", non-reproducible files",Apteryks,3,1527384628,1,1527384628,0,0,2023-01-10T13:22:16Z,"Hi!

When building/installing C extensions via `gem install`, log files
produced during the build get installed to the `GEM_VENDOR` location.
This is undesirable because these files are not functional and they
contain non-reproducible information such as temporary compilation
file names or similar.

Would it be possible to *not* have any log file installed, or have an option to turn it off?

Reproducer, using nokogiri as an example:

```
$ GEM_VENDOR=output gem install nokogiri-1.13.10.gem --verbose --local --ignore-dependencies --vendor --bindir output/bin
```
```
$ find output/extensions/
output/extensions/
output/extensions/x86_64-linux
output/extensions/x86_64-linux/2.7.0
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/mkmf.log
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/nokogiri.so
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/xmlversion.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/SAX.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/entities.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/encoding.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/parser.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/parserInternals.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/xmlerror.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/HTMLparser.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/HTMLtree.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/debugXML.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/tree.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/list.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/hash.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/xpath.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/xpathInternals.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/xpointer.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/xinclude.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/xmlIO.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/xmlmemory.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/nanohttp.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/nanoftp.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/uri.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/valid.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/xlink.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/catalog.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/threads.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/globals.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/c14n.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/xmlautomata.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/xmlregexp.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/xmlmodule.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/xmlschemas.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/schemasInternals.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/xmlschemastypes.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/xmlstring.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/xmlunicode.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/xmlreader.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/relaxng.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/dict.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/SAX2.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/xmlexports.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/xmlwriter.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/chvalid.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/pattern.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/xmlsave.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxml2/libxml/schematron.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxslt
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxslt/xsltconfig.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxslt/xslt.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxslt/xsltutils.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxslt/pattern.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxslt/templates.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxslt/variables.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxslt/keys.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxslt/numbersInternals.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxslt/extensions.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxslt/extra.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxslt/functions.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxslt/namespaces.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxslt/imports.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxslt/attributes.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxslt/documents.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxslt/preproc.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxslt/transform.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxslt/security.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxslt/xsltInternals.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxslt/xsltexports.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libxslt/xsltlocale.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libexslt
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libexslt/exslt.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libexslt/exsltexports.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/nokogiri/include/libexslt/exsltconfig.h
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/gem_make.out
output/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/gem.build_complete
```

The mkmf.log file contains non-deterministic temporary file names, as shown in the following diffoscope:


```
$ diffoscope /gnu/store/9aba01y3kfdcpxjqg5wx2sbvz4mss5hq-ruby-nokogiri-1.13.10{,-check}
--- /gnu/store/9aba01y3kfdcpxjqg5wx2sbvz4mss5hq-ruby-nokogiri-1.13.10
+++ /gnu/store/9aba01y3kfdcpxjqg5wx2sbvz4mss5hq-ruby-nokogiri-1.13.10-check
│   --- /gnu/store/9aba01y3kfdcpxjqg5wx2sbvz4mss5hq-ruby-nokogiri-1.13.10/lib
├── +++ /gnu/store/9aba01y3kfdcpxjqg5wx2sbvz4mss5hq-ruby-nokogiri-1.13.10-check/lib
│ │   --- /gnu/store/9aba01y3kfdcpxjqg5wx2sbvz4mss5hq-ruby-nokogiri-1.13.10/lib/ruby
│ ├── +++ /gnu/store/9aba01y3kfdcpxjqg5wx2sbvz4mss5hq-ruby-nokogiri-1.13.10-check/lib/ruby
│ │ │   --- /gnu/store/9aba01y3kfdcpxjqg5wx2sbvz4mss5hq-ruby-nokogiri-1.13.10/lib/ruby/vendor_ruby
│ │ ├── +++ /gnu/store/9aba01y3kfdcpxjqg5wx2sbvz4mss5hq-ruby-nokogiri-1.13.10-check/lib/ruby/vendor_ruby
│ │ │ │   --- /gnu/store/9aba01y3kfdcpxjqg5wx2sbvz4mss5hq-ruby-nokogiri-1.13.10/lib/ruby/vendor_ruby/extensions
│ │ │ ├── +++ /gnu/store/9aba01y3kfdcpxjqg5wx2sbvz4mss5hq-ruby-nokogiri-1.13.10-check/lib/ruby/vendor_ruby/extensions
│ │ │ │ │   --- /gnu/store/9aba01y3kfdcpxjqg5wx2sbvz4mss5hq-ruby-nokogiri-1.13.10/lib/ruby/vendor_ruby/extensions/x86_64-linux
│ │ │ │ ├── +++ /gnu/store/9aba01y3kfdcpxjqg5wx2sbvz4mss5hq-ruby-nokogiri-1.13.10-check/lib/ruby/vendor_ruby/extensions/x86_64-linux
│ │ │ │ │ │   --- /gnu/store/9aba01y3kfdcpxjqg5wx2sbvz4mss5hq-ruby-nokogiri-1.13.10/lib/ruby/vendor_ruby/extensions/x86_64-linux/2.7.0
│ │ │ │ │ ├── +++ /gnu/store/9aba01y3kfdcpxjqg5wx2sbvz4mss5hq-ruby-nokogiri-1.13.10-check/lib/ruby/vendor_ruby/extensions/x86_64-linux/2.7.0
│ │ │ │ │ │ │   --- /gnu/store/9aba01y3kfdcpxjqg5wx2sbvz4mss5hq-ruby-nokogiri-1.13.10/lib/ruby/vendor_ruby/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10
│ │ │ │ │ │ ├── +++ /gnu/store/9aba01y3kfdcpxjqg5wx2sbvz4mss5hq-ruby-nokogiri-1.13.10-check/lib/ruby/vendor_ruby/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10
│ │ │ │ │ │ │ │   --- /gnu/store/9aba01y3kfdcpxjqg5wx2sbvz4mss5hq-ruby-nokogiri-1.13.10/lib/ruby/vendor_ruby/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/mkmf.log
│ │ │ │ │ │ │ ├── +++ /gnu/store/9aba01y3kfdcpxjqg5wx2sbvz4mss5hq-ruby-nokogiri-1.13.10-check/lib/ruby/vendor_ruby/extensions/x86_64-linux/2.7.0/nokogiri-1.13.10/mkmf.log
│ │ │ │ │ │ │ │ @@ -607,15 +607,15 @@
│ │ │ │ │ │ │ │  11: 
│ │ │ │ │ │ │ │  12:   return !!argv[argc];
│ │ │ │ │ │ │ │  13: }
│ │ │ │ │ │ │ │  14: int t(void) { void ((*volatile p)()); p = (void ((*)()))rb_category_warning; return !p; }
│ │ │ │ │ │ │ │  /* end */
│ │ │ │ │ │ │ │  
│ │ │ │ │ │ │ │ ""gcc -o conftest
-I/gnu/store/j4z07lyi1ykk8bc68h1p4bpj1il9dn3f-ruby-2.7.4/include/ruby-2.7.0/x86_64-linux
-I/gnu/store/j4z07lyi1ykk8bc68h1p4bpj1il9dn3f-ruby-2.7.4/include/ruby-2.7.0/ruby/backward
-I/gnu/store/j4z07lyi1ykk8bc68h1p4bpj1il9dn3f-ruby-2.7.4/include/ruby-2.7.0
-I. -I/gnu/store/g3y6ifhm0751vgsxv90yipfw6mk189kj-libxml2-2.9.12/include/libxml2
-I/gnu/store/9aba01y3kfdcpxjqg5wx2sbvz4mss5hq-ruby-nokogiri-1.13.10/lib/ruby/vendor_ruby/gems/nokogiri-1.13.10/ext/nokogiri/ports/x86_64-linux/libgumbo/1.0.0-nokogiri/include
-g -O2 -fPIC -std=c99 -Wno-declaration-after-statement -g -Winline
-Wmissing-noreturn conftest.c
-L. -L/gnu/store/j4z07lyi1ykk8bc68h1p4bpj1il9dn3f-ruby-2.7.4/lib
-Wl,-rpath,/gnu/store/j4z07lyi1ykk8bc68h1p4bpj1il9dn3f-ruby-2.7.4/lib
-L/gnu/store/9aba01y3kfdcpxjqg5wx2sbvz4mss5hq-ruby-nokogiri-1.13.10/lib/ruby/vendor_ruby/gems/nokogiri-1.13.10/ext/nokogiri/ports/x86_64-linux/libgumbo/1.0.0-nokogiri/lib
-Wl,-rpath,/gnu/store/9aba01y3kfdcpxjqg5wx2sbvz4mss5hq-ruby-nokogiri-1.13.10/lib/ruby/vendor_ruby/gems/nokogiri-1.13.10/ext/nokogiri/ports/x86_64-linux/libgumbo/1.0.0-nokogiri/lib
-L. -fstack-protector-strong -rdynamic -Wl,-export-dynamic -lexslt
-lxslt -lxml2 -lz
/gnu/store/9aba01y3kfdcpxjqg5wx2sbvz4mss5hq-ruby-nokogiri-1.13.10/lib/ruby/vendor_ruby/gems/nokogiri-1.13.10/ext/nokogiri/ports/x86_64-linux/libgumbo/1.0.0-nokogiri/lib/libgumbo.a
-Wl,-rpath,/gnu/store/j4z07lyi1ykk8bc68h1p4bpj1il9dn3f-ruby-2.7.4/lib
-L/gnu/store/j4z07lyi1ykk8bc68h1p4bpj1il9dn3f-ruby-2.7.4/lib -lruby
-lexslt -lxslt -lxml2 -lz
/gnu/store/9aba01y3kfdcpxjqg5wx2sbvz4mss5hq-ruby-nokogiri-1.13.10/lib/ruby/vendor_ruby/gems/nokogiri-1.13.10/ext/nokogiri/ports/x86_64-linux/libgumbo/1.0.0-nokogiri/lib/libgumbo.a
-lm -lc""
│ │ │ │ │ │ │ │ +ld: /tmp/guix-build-ruby-nokogiri-1.13.10.drv-0/cc6zUuPL.o: in function `t':
│ │ │ │ │ │ │ │ -ld: /tmp/guix-build-ruby-nokogiri-1.13.10.drv-0/ccaC0A0J.o: in function `t':
│ │ │ │ │ │ │ │  /gnu/store/9aba01y3kfdcpxjqg5wx2sbvz4mss5hq-ruby-nokogiri-1.13.10/lib/ruby/vendor_ruby/gems/nokogiri-1.13.10/ext/nokogiri/conftest.c:15: undefined reference to `rb_category_warning'
│ │ │ │ │ │ │ │  collect2: error: ld returned 1 exit status
│ │ │ │ │ │ │ │  checked program was:
│ │ │ │ │ │ │ │  /* begin */
│ │ │ │ │ │ │ │   1: #include ""ruby.h""
│ │ │ │ │ │ │ │   2: 
│ │ │ │ │ │ │ │   3: /*top*/
```

The original issue was reported here: https://github.com/sparklemotion/nokogiri/issues/2755

Thank you!

Note: this was originally miss-filed here: https://bugs.ruby-lang.org/issues/19329",True,0,NONE
https://api.github.com/repos/rubygems/rubygems/issues/comments/1378216564,"""gem install"" installs logs and other ""noisy"", non-reproducible files",hsbt,3,1527384628,2,1378216564,0,1527384628,2023-01-11T04:08:50Z,I'm not sure what you want. Did you want to remove all temporary files like log after `gem install`?,False,0,MEMBER
https://api.github.com/repos/rubygems/rubygems/issues/comments/1378742491,"""gem install"" installs logs and other ""noisy"", non-reproducible files",Apteryks,3,1527384628,3,1378742491,0,1378216564,2023-01-11T13:19:44Z,"It'd be nice if the log files were not installed (copied to the VENDOR_GEM directory) by `gem install` in the first place, since they are mostly useful to debug the build and are not reproducible.",False,0,NONE
https://api.github.com/repos/rubygems/rubygems/issues/comments/1378744479,"""gem install"" installs logs and other ""noisy"", non-reproducible files",Apteryks,3,1527384628,4,1378744479,0,1378742491,2023-01-11T13:21:10Z,"Currently distributions with a focus on reproducibility like Guix System are left to delete these files themselves, which feels like a workaround.",False,0,NONE
https://api.github.com/repos/rubygems/rubygems/issues/6260,Allow to disable `gem update` reminded,voxik,3,1527548744,1,1527548744,0,0,2023-01-10T15:02:05Z,"Installing some gem, at the end, I am reminded to update RubyGems:

~~~
A new release of RubyGems is available: 3.4.1 → 3.4.3!
Run `gem update --system 3.4.3` to update your installation.
~~~

However, it is not nice to make such suggestion to distribution users, because e.g. Fedora users will get the installation via system updates. Suggesting `gem update` might even be harmful, because if nothing else, this is not tested on Fedora.

So is there chance:

1) To drop this, because I fail to see the utility of the banner.
2) Allow to disable this banner via configuration (e.g. via operating_sytem.rb). If that is already possible, then sorry for the noise and thx in advance for guidance.",True,0,CONTRIBUTOR
https://api.github.com/repos/rubygems/rubygems/issues/comments/1377430329,Allow to disable `gem update` reminded,deivid-rodriguez,3,1527548744,2,1377430329,0,1527548744,2023-01-10T15:18:12Z,Please have a look at the PR where this banner was introduced to see available options for disabling it. Thanks!,False,0,MEMBER
https://api.github.com/repos/rubygems/rubygems/issues/comments/1377441102,Allow to disable `gem update` reminded,simi,3,1527548744,3,1377441102,0,1377430329,2023-01-10T15:25:49Z,"> To drop this, because I fail to see the utility of the banner.

:trollface: 

---

@voxik please, if possible (I think I have recommended this already few times), implement `Gem.disable_system_update_message` in Fedora. You can inspire at https://salsa.debian.org/ruby-team/rubygems-integration/-/blob/master/lib/rubygems/defaults/operating_system.rb#L7-14. It will prevent this message as well.",False,0,MEMBER
https://api.github.com/repos/rubygems/rubygems/issues/comments/1377638644,Allow to disable `gem update` reminded,voxik,3,1527548744,4,1377638644,0,1377441102,2023-01-10T17:54:20Z,Thanks for pointers,False,0,CONTRIBUTOR
https://api.github.com/repos/rubygems/rubygems/issues/6263,Platform locked Gemfile.lock not changed correctly by bundle install,owst,6,1528941439,1,1528941439,0,0,2023-01-11T12:21:13Z,"### Describe the problem as clearly as you can

A Gemfile.lock that is locked to certain (versionless) platforms is updated in an unexpected way by `bundle install`. 

Given the following Gemfile.lock (that I think is malformed/incomplete - it's missing a load of GEM specs for other darwin versions, I'm not sure how this was arrived at, probably an older `bundler` version):
```
GEM
  remote: https://rubygems.org/
  specs:
    sorbet (0.5.10549)
      sorbet-static (= 0.5.10549)
    sorbet-static (0.5.10549-universal-darwin-20)
    sorbet-static (0.5.10549-x86_64-linux)

PLATFORMS
  arm64-darwin
  x86_64-darwin
  x86_64-linux

DEPENDENCIES
  sorbet (= 0.5.10549)

BUNDLED WITH
   2.4.3
```
and simple `Gemfile`:
```
source ""https://rubygems.org""

gem ""sorbet"", ""= 0.5.10549""
```
when on platform `x86_64-darwin-21`, running `bundle install` gives this diff:
```diff
diff --git a/Gemfile.lock b/Gemfile.lock
index ec8dea1..e2f125c 100644
--- a/Gemfile.lock
+++ b/Gemfile.lock
@@ -3,8 +3,7 @@ GEM
   specs:
     sorbet (0.5.10549)
       sorbet-static (= 0.5.10549)
-    sorbet-static (0.5.10549-universal-darwin-20)
-    sorbet-static (0.5.10549-x86_64-linux)
+    sorbet-static (0.5.10549-universal-darwin-21)
 
 PLATFORMS
   arm64-darwin
```
which is surprising - we've removed the Linux spec and swapped out darwin-20 for darwin-21 (the current platform).

If instead of `bundle install` we run `bundle update --conservative sorbet-static` (which should be a no-op due to our version pin) we end up with this diff:
```diff
diff --git a/Gemfile.lock b/Gemfile.lock
index ec8dea1..6da2848 100644
--- a/Gemfile.lock
+++ b/Gemfile.lock
@@ -3,7 +3,15 @@ GEM
   specs:
     sorbet (0.5.10549)
       sorbet-static (= 0.5.10549)
+    sorbet-static (0.5.10549-universal-darwin-14)
+    sorbet-static (0.5.10549-universal-darwin-15)
+    sorbet-static (0.5.10549-universal-darwin-16)
+    sorbet-static (0.5.10549-universal-darwin-17)
+    sorbet-static (0.5.10549-universal-darwin-18)
+    sorbet-static (0.5.10549-universal-darwin-19)
     sorbet-static (0.5.10549-universal-darwin-20)
+    sorbet-static (0.5.10549-universal-darwin-21)
+    sorbet-static (0.5.10549-universal-darwin-22)
     sorbet-static (0.5.10549-x86_64-linux)
 
 PLATFORMS
```
which looks correct to me (I think the ""incomplete/wrong"" existing specs have been corrected to add all darwin versions). I wonder why this is different to the behaviour of `bundle install`?

### Did you try upgrading rubygems & bundler?

Already on the latest version.

### Post steps to reproduce the problem

As above.

### Which command did you run?

`bundle install`

### What were you expecting to happen?

The `Gemfile.lock` changes to be the same as for the (""no-op"") `bundle update` command.

### What actually happened?

The output was different/wrong.

### If not included with the output of your command, run `bundle env` and paste the output below

```
Bundler       2.4.3
  Platforms   ruby, x86_64-darwin-21
Ruby          2.7.6p219 (2022-04-12 revision c9c2245c0a25176072e02db9254f0e0c84c805cd) [x86_64-darwin-21]
RubyGems      3.4.3
```",True,0,NONE
https://api.github.com/repos/rubygems/rubygems/issues/comments/1378800396,Platform locked Gemfile.lock not changed correctly by bundle install,deivid-rodriguez,6,1528941439,2,1378800396,0,1528941439,2023-01-11T14:03:59Z,Thanks for the report @owst. I will have a look.,False,0,MEMBER
https://api.github.com/repos/rubygems/rubygems/issues/comments/1379349833,Platform locked Gemfile.lock not changed correctly by bundle install,deivid-rodriguez,6,1528941439,3,1379349833,0,1378800396,2023-01-11T19:01:21Z,#6266 should fix this!,False,0,MEMBER
https://api.github.com/repos/rubygems/rubygems/issues/comments/1380053440,Platform locked Gemfile.lock not changed correctly by bundle install,owst,6,1528941439,4,1380053440,0,1379349833,2023-01-12T09:40:43Z,"Great, thanks @deivid-rodriguez for the speedy response as always!",False,0,NONE
https://api.github.com/repos/rubygems/rubygems/issues/comments/1380098138,Platform locked Gemfile.lock not changed correctly by bundle install,owst,6,1528941439,5,1380098138,0,1380053440,2023-01-12T10:11:40Z,"Actually, @deivid-rodriguez I've just looked at the test in that PR:
```ruby
      expect(lockfile).to eq <<~L
        GEM
          remote: #{file_uri_for(gem_repo4)}/
          specs:
            sorbet-static (0.5.10549-universal-darwin-20)
            sorbet-static (0.5.10549-universal-darwin-21)
        PLATFORMS
          x86_64-darwin
```
should we expect that all versions of that gem are added to the lock file (so `darwin-22`, `darwin-19`, etc.)? I wonder if it's also worth including the `x86_64-linux` platform to ensure that different platforms are handled properly. ",False,0,NONE
https://api.github.com/repos/rubygems/rubygems/issues/comments/1380110819,Platform locked Gemfile.lock not changed correctly by bundle install,deivid-rodriguez,6,1528941439,6,1380110819,0,1380098138,2023-01-12T10:21:42Z,"Yes, all versions matching any platforms included under PLATFORMS.

The bug ended up being related, not to the specific set of platforms locked under PLATFORMS, but to whether the gem was previously installed or not (you can verify this by running `gem uninstall sorbet sorbet-static` before running your repro `bundle install` command). If gems are not already installed before running `bundle install` then things work as expected and all platforms are added.

In an effort to write a minimal test case that reproduces the issue, I limit the locked platforms to a single one, and the matching versions to two, just to make sure both are added and the current platform does not just replace what's already in the lockfile.",False,0,MEMBER
https://api.github.com/repos/rubygems/rubygems/issues/comments/1380128491,Platform locked Gemfile.lock not changed correctly by bundle install,owst,6,1528941439,7,1380128491,0,1380110819,2023-01-12T10:36:05Z,"Aha yes, I'd missed the test setup limiting the versions - that all makes sense, thanks for the explanation! 👍 And just to confirm that uninstalling gems before `bundle install` does indeed make things work as expected",False,0,NONE
https://api.github.com/repos/rubygems/rubygems/issues/6264,ArgumentError Malformed version number string 0.42.0.pre.b1e6081|checksum:117e4fe894c0fa9d9d1ffae9395311df271c8119a1db08b1dd29b4a5905fe396,jedrekdomanski,3,1529332213,1,1529332213,0,0,2023-01-11T16:23:46Z,"<!--

Thank you for contributing to the
[rubygems](https://github.com/rubygems/rubygems) repository, and specifically to
[RubyGems](https://guides.rubygems.org/).

-->

### Describe the problem as clearly as you can
I am not able to install any gems either in CI or locally.
```
Retrying fetcher due to error (2/4): ArgumentError Malformed version number string 0.42.0.pre.b1e6081|checksum:117e4fe894c0fa9d9d1ffae9395311df271c8119a1db08b1dd29b4a5905fe396

ArgumentError: Malformed version number string 0.42.0.pre.b1e6081|checksum:117e4fe894c0fa9d9d1ffae9395311df271c8119a1db08b1dd29b4a5905fe396

  /usr/local/lib/ruby/2.7.0/rubygems/version.rb:215:in `initialize'

  /usr/local/lib/ruby/2.7.0/rubygems/version.rb:206:in `new'

  /usr/local/lib/ruby/2.7.0/rubygems/version.rb:206:in `new'

  /usr/local/lib/ruby/2.7.0/rubygems/version.rb:195:in `create'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/endpoint_specification.rb:15:in `initialize'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/fetcher.rb:142:in `new'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/fetcher.rb:142:in `block in specs'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/fetcher.rb:140:in `each'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/fetcher.rb:140:in `specs'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/fetcher.rb:118:in `block in specs_with_retry'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/retry.rb:40:in `run'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/retry.rb:30:in `attempt'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/fetcher.rb:117:in `specs_with_retry'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/source/rubygems.rb:427:in `block in fetch_names'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/source/rubygems.rb:424:in `each'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/source/rubygems.rb:424:in `fetch_names'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/source/rubygems.rb:294:in `double_check_for'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/spec_set.rb:82:in `block in materialize'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/spec_set.rb:77:in `each'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/spec_set.rb:77:in `materialize'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/definition.rb:188:in `specs'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/installer.rb:247:in `ensure_specs_are_compatible!'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/installer.rb:84:in `block in run'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/process_lock.rb:12:in `block in lock'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/process_lock.rb:9:in `open'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/process_lock.rb:9:in `lock'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/installer.rb:72:in `run'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/installer.rb:24:in `install'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/cli/install.rb:60:in `run'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/cli.rb:260:in `block in install'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/settings.rb:131:in `temporary'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/cli.rb:259:in `install'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/vendor/thor/lib/thor/command.rb:27:in `run'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/vendor/thor/lib/thor/invocation.rb:127:in `invoke_command'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/vendor/thor/lib/thor.rb:392:in `dispatch'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/cli.rb:31:in `dispatch'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/vendor/thor/lib/thor/base.rb:485:in `start'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/cli.rb:25:in `start'

  /usr/local/bundle/gems/bundler-2.2.24/exe/bundle:49:in `block in <top (required)>'

  /usr/local/bundle/gems/bundler-2.2.24/lib/bundler/friendly_errors.rb:128:in `with_friendly_errors'

  /usr/local/bundle/gems/bundler-2.2.24/exe/bundle:37:in `<top (required)>'

  /usr/local/bundle/bin/bundle:23:in `load'

  /usr/local/bundle/bin/bundle:23:in `<main>'
```
<!--

Replace this with an explanation of the problem you are having. Be as much clear and precise as you can.

-->

### Did you try upgrading RubyGems?
No
<!--

Make sure you're using the latest version of both RubyGems by running `gem
update --system`.

It's likely that your issue has been fixed in recent versions, so just upgrading
might do the trick, and will also save us some time :)

-->

### Post steps to reproduce the problem

<!--

Fill this with a list of steps maintainers can follow to reproduce your issue.
Note that while you are seeing this issue in your computer, maintainers might
not see the same thing on theirs. There is a number of things that could
influence this:

* How your ruby is setup (OS package, from source, using a version manager).
* How RubyGems is configured.
* The version of each involved piece of software that you are using.
* ...

The more complete the steps to simulate your particular environment are, the
easier it will be for maintainers to reproduce your issue on their machines.

Ideally, we recommend you to set up the list of steps as a
[Dockerfile](https://docs.docker.com/get-started/). A Dockerfile provides a
neutral environment that should give the same results, no matter where it's run.

-->

### Which command did you run?
```
bundle install
```
<!-- Replace this with the specific command that is causing trouble. -->

### What were you expecting to happen?
Install gems
<!-- Replace this with the results you expected before running the command. -->

### What actually happened?
```
Retrying fetcher due to error (2/4): ArgumentError Malformed version number string 0.42.0.pre.b1e6081|checksum:117e4fe894c0fa9d9d1ffae9395311df271c8119a1db08b1dd29b4a5905fe396
```
<!-- Replace this with the actual result you got. Paste the output of your command here. -->

### Run `gem env` and paste the output below
```
## Environment

Bundler       2.2.24

  Platforms   ruby, x86_64-linux-musl

Ruby          2.7.4p191 (2021-07-07 revision a21a3b7d23704a01d34bd79d09dc37897e00922a) [x86_64-linux-musl]

  Full Path   /usr/local/bin/ruby

  Config Dir  /usr/local/etc

RubyGems      3.1.6

  Gem Home    /app/vendor/bundle/ruby/2.7.0

  Gem Path    /app/vendor/bundle/ruby/2.7.0

  User Home   /root

  User Path   /root/.gem/ruby/2.7.0

  Bin Dir     /app/vendor/bundle/ruby/2.7.0/bin

OpenSSL       

  Compiled    OpenSSL 1.1.1l  24 Aug 2021

  Loaded      OpenSSL 1.1.1l  24 Aug 2021

  Cert File   /etc/ssl/cert.pem

  Cert Dir    /etc/ssl/certs

Tools         

  Git         2.32.0

  RVM         not installed

  rbenv       not installed

  chruby      not installed
```
<!-- Replace this with the result of `gem env`. Don't forget to anonymize any private data! -->
",True,0,NONE
https://api.github.com/repos/rubygems/rubygems/issues/comments/1379102326,ArgumentError Malformed version number string 0.42.0.pre.b1e6081|checksum:117e4fe894c0fa9d9d1ffae9395311df271c8119a1db08b1dd29b4a5905fe396,deivid-rodriguez,3,1529332213,2,1379102326,0,1529332213,2023-01-11T16:31:51Z,"The latest commit is not released yet, and you're not even using the latest Bundler, so I don't see how it could be related. Is this a GitHub package source by any chance?",False,0,MEMBER
https://api.github.com/repos/rubygems/rubygems/issues/comments/1379118769,ArgumentError Malformed version number string 0.42.0.pre.b1e6081|checksum:117e4fe894c0fa9d9d1ffae9395311df271c8119a1db08b1dd29b4a5905fe396,deivid-rodriguez,3,1529332213,3,1379118769,0,1379102326,2023-01-11T16:38:36Z,"I believe GitHub Packages are migrating to the compact index API (which is quite awesome), but it's still not fully working. Please subscribe to https://github.com/orgs/community/discussions/43861 instead :)",False,0,MEMBER
https://api.github.com/repos/rubygems/rubygems/issues/comments/1379144165,ArgumentError Malformed version number string 0.42.0.pre.b1e6081|checksum:117e4fe894c0fa9d9d1ffae9395311df271c8119a1db08b1dd29b4a5905fe396,jedrekdomanski,3,1529332213,4,1379144165,0,1379118769,2023-01-11T16:49:03Z,"Ok, I now see there are some other changes from the past couple of hours so I edited my post. Thanks for checking, it looks like GitHub Packages issue because some other people are seeing the same issue.",False,0,NONE
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/11545,Changelog improvements,k3n,5,1611896601,1,1611896601,0,0,2023-03-06T17:28:18Z,"### If the feature request is for a plugin or theme, specify it here.

_No response_

### If the feature solves a problem you have, specify it here.

OMZ helpfully nudges me to update, and when I do, it lists a lot of things that were changed but it's a chore to get more details.

For instance, the latest update contained this line:

```
- 041c35f [amuse]                Add virtualenv support (#8987)
```

Sounds cool, but how does it work? It links the issue #, but now I have to open a browser, navigate to the project, then nav to its issues, and then lastly nav to #8987. Is it hard? No. Is it time-consuming? When there's 25 issues mentioned (like today), it can really add up!

That's part of the friction. The other part is updates like this:

```
 - cc73a92 [git]                  Add `gpod` alias
```

I understand that not all commits have an issue # to tie them to, but there's a git hash -- I can look at the code changes, but that requires roughly same amount of steps as above.

### Describe the proposed feature.

Add clickable links for each git hash & issue #. I'm making an assumption that most (if not all) of these refs are to the main project; if that's true, then this should be pretty straightforward. If not, then maybe alternatives would need to be considered.

>  - [041c35f](https://github.com/ohmyzsh/ohmyzsh/commit/041c35f) [amuse]                Add virtualenv support ([#8987](https://github.com/ohmyzsh/ohmyzsh/pull/8987))
>  - [cc73a92](https://github.com/ohmyzsh/ohmyzsh/commit/cc73a92) [git]                  Add `gpod` alias



### Describe alternatives you've considered

An alternative to providing this in the terminal would be to publish such and link it from the terminal, but I think having the details available in your terminal would be the easiest to work with.

### Additional context

I apologize if this is rehashing old decisions, I searched the issues (and online) but it seems the only way I can find details on the updated items is to do a ton of manual navigating myself. This seems like such an obvious omission that I can't but think it's intentional for some reason?

### Related Issues

_No response_",True,0,NONE
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1458236908,Changelog improvements,mcornella,5,1611896601,2,1458236908,0,1611896601,2023-03-07T14:07:55Z,"Hi @k3n, thank you very much for the thorough feature request, it shows that you took the time to provide an actionable feedback and did the research.

To first answer your last point, this hasn't been discussed yet. To be fair, the only way to add links to both commits and issues on the terminal output is if the terminal emulator supports hyperlinks (i.e. [terminal hyperlinks](https://gist.github.com/egmontkob/eb114294efbcd5adb1944c9f3cb5feda) feature).

We are already testing for that feature on a variety of terminals in the installer and updater, so it isn't difficult to adapt the terminal changelog to add suport for that. If the terminal doesn't support this, it isn't feasible to add links as they'd be fully visible in the terminal output. 

The other option you sh, linking to a browser changelog, is only possible once we start using GitHub releases but that will come when we use a proper versioning process which is a long time coming.

So to summarize, I'll start working on adding hyperlinks to the output which is what can be shipped sooner. Do check if your terminal will support this feature though. ",False,0,MEMBER
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1458523188,Changelog improvements,k3n,5,1611896601,3,1458523188,0,1458236908,2023-03-07T17:04:20Z,"Using iTerm2 on Mac, links do indeed work. As a matter of fact, the current update text (which includes the changelog) includes clickable links to Discord and another link or 2.

This is great news, thank you!",False,0,NONE
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1497990264,Changelog improvements,k3n,5,1611896601,4,1497990264,0,1458523188,2023-04-05T19:12:43Z,"This is A++++, thank you @mcornella! Saw it today and was excited :D",False,0,NONE
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1498002272,Changelog improvements,mcornella,5,1611896601,5,1498002272,0,1497990264,2023-04-05T19:24:10Z,This was all @GuySartorelli! I agree they did a great job! ,False,0,MEMBER
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1514923779,Changelog improvements,k3n,5,1611896601,6,1514923779,0,1498002272,2023-04-19T15:18:53Z,Thank you @GuySartorelli!!,False,0,NONE
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/11549,Visual/copy mode indicator in vi-mode plugin,ajaydwarkani,4,1615619174,1,1615619174,0,0,2023-03-08T17:09:35Z,"Currently I can only show indicators for ""Insert"" and ""normal"" mode. Can you please also add ""Visual/Copy"" mode indicator?",True,0,NONE
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1491383128,Visual/copy mode indicator in vi-mode plugin,mcornella,4,1615619174,2,1491383128,0,1615619174,2023-03-31T06:29:41Z,Duplicate of #11586. See https://github.com/ohmyzsh/ohmyzsh/issues/11586#issuecomment-1491356516.,False,0,MEMBER
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1491388447,Visual/copy mode indicator in vi-mode plugin,mcornella,4,1615619174,3,1491388447,0,1491383128,2023-03-31T06:36:10Z,"Disregard that. This is for an indicator and not a cursor. 

I'd like to know what is the purpose behind that. Do you not get a highlight of the text when entering visual mode? ",False,0,MEMBER
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1498083815,Visual/copy mode indicator in vi-mode plugin,mcornella,4,1615619174,4,1498083815,0,1491388447,2023-04-05T20:22:59Z,"I'll close this because I don't really see a use for this feature, feel free to reopen with a clear use case.",False,0,MEMBER
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1498147717,Visual/copy mode indicator in vi-mode plugin,rwmitchell,4,1615619174,5,1498147717,0,1498083815,2023-04-05T20:58:15Z,"Using p10k, I have these settings, which changes my prompt based on the the current vi mode:

```  typeset -g POWERLEVEL9K_PROMPT_CHAR_{OK,ERROR}_VIINS_CONTENT_EXPANSION='❯'
  typeset -g POWERLEVEL9K_PROMPT_CHAR_{OK,ERROR}_VICMD_CONTENT_EXPANSION='' # ❮'
  typeset -g POWERLEVEL9K_PROMPT_CHAR_{OK,ERROR}_VIVIS_CONTENT_EXPANSION='V'
  typeset -g POWERLEVEL9K_PROMPT_CHAR_{OK,ERROR}_VIOWR_CONTENT_EXPANSION='▶'```

The glyphs don't render here, but otherwise it indicates the method.  For visual mode, a rather boring 'V' is displayed.  But yes, I'm not sure how much attention I pay to it given the text being marked has the background highlighted.",False,0,CONTRIBUTOR
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/11550,feat(init)!: allow turning off aliases for libs and plugins,mcornella,9,1615814220,1,1615814220,0,0,2023-03-08T19:38:58Z,"## Standards checklist:

<!-- Fill with an x the ones that apply. Example: [x] -->

- [x] The PR title is descriptive.
- [x] The PR doesn't replicate another PR which is already open.
- [x] I have read the contribution guide and followed all the instructions.
- [x] The code follows the code style guide detailed in the wiki.
- [x] The code is mine or it's from somewhere with an MIT-compatible license.
- [x] The code is efficient, to the best of my ability, and does not waste computer resources.
- [x] The code is stable and I have tested it myself, to the best of my abilities.
- [x] If the code introduces new aliases, I provide a valid use case for all plugin users down below.

----

Proof of concept work for backing up and restoring aliases on libs and plugins that have them turned off by the user via ztyle:

```zsh
zstyle ':omz:*' aliases no
zstyle ':omz:lib:*' aliases no
zstyle ':omz:plugins:*' aliases no
zstyle ':omz:plugins:git' aliases no
```

Aliases could also be selectively enabled for specific components, such as:

```zsh
zstyle ':omz:plugins:*' aliases no
zstyle ':omz:plugins:git' aliases yes
```

Work in collaboration with @carlosala.

Fixes #9414",True,0,MEMBER
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1460857965,feat(init)!: allow turning off aliases for libs and plugins,carlosala,9,1615814220,2,1460857965,0,1615814220,2023-03-08T20:49:34Z,We can see in #10510 what does this PR closes also 👌🏻 ,False,0,MEMBER
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1493312988,feat(init)!: allow turning off aliases for libs and plugins,carlosala,9,1615814220,3,1493312988,0,1460857965,2023-04-02T12:02:31Z,"Just a quick reminder here, when merging this we should soft-deprecate https://github.com/ohmyzsh/ohmyzsh/blob/f7d903f3a31567f326d0f8ec2414722d0e3b992a/lib/directories.zsh#L12 as is not following the `':omz:lib:<file>` structure and document properly also that in README (removing also https://github.com/ohmyzsh/ohmyzsh/blob/f7d903f3a31567f326d0f8ec2414722d0e3b992a/README.md?plain=1#L279)",False,0,MEMBER
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1493320745,feat(init)!: allow turning off aliases for libs and plugins,carlosala,9,1615814220,4,1493320745,0,1493312988,2023-04-02T12:36:54Z,"After testing with https://github.com/romkatv/zsh-bench, I cannot see a difference while removing all aliases and leaving all of them. It seems that the way we are keeping and restoring aliases has no performance issues.
I think we can merge this, and see how the community receives it.
I'm quite happy we finally sorted it :)",False,0,MEMBER
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1493363459,feat(init)!: allow turning off aliases for libs and plugins,mcornella,9,1615814220,5,1493363459,0,1493320745,2023-04-02T14:54:25Z,"I'm currently debugging why setting `galiases` does not remove the global aliases, don't merge it yet.",False,0,MEMBER
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1493381721,feat(init)!: allow turning off aliases for libs and plugins,carlosala,9,1615814220,6,1493381721,0,1493363459,2023-04-02T16:11:51Z,"At least from the documentation perspective, it should work exactly the same. Even though, if it's giving issues, I only see global aliases defined [here](https://github.com/ohmyzsh/ohmyzsh/blob/d47e1d65f66f9bb2e7a96ba58797b33f0e91a623/lib/directories.zsh#L14) and [here](https://github.com/ohmyzsh/ohmyzsh/blob/d47e1d65f66f9bb2e7a96ba58797b33f0e91a623/plugins/rails/rails.plugin.zsh#L41). We could have some workaround there 👍🏻 ",False,0,MEMBER
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1493424758,feat(init)!: allow turning off aliases for libs and plugins,mcornella,9,1615814220,7,1493424758,0,1493381721,2023-04-02T19:47:42Z,"OK it looks like the same happens with `aliases` and the rest of special parameters when we're doing `array=()` (empty array).

When that happens, the resulting hash table does not actually get modified, I don't know exactly why by looking at the code: https://github.com/zsh-users/zsh/blob/c006d760/Src/Modules/parameter.c#L1767-L1807

I have pushed a version that uses `unalias` directly in a ""smarter"" way to avoid many calls, but I don't know if it is actually slower. Could you try it out with `zsh-bench` again?

----

EDIT: it looks like the culprit is that the hashtable is actually empty, so this check matches and nothing is done: https://github.com/zsh-users/zsh/blob/c006d7609703afcfb2162c36d4f745125df45879/Src/Modules/parameter.c#L1773-L1774",False,0,MEMBER
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1493780769,feat(init)!: allow turning off aliases for libs and plugins,carlosala,9,1615814220,8,1493780769,0,1493424758,2023-04-03T06:57:55Z,"I think the code is a bit more difficult to read. What about adding always a garbage alias, maybe `alias __omz_tmp=<whatever>`. Then we are sure the hash table is never empty (and we could use `unalias` only for that).
What do you think?",False,0,MEMBER
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1494949958,feat(init)!: allow turning off aliases for libs and plugins,mcornella,9,1615814220,9,1494949958,0,1493780769,2023-04-03T20:38:11Z,"That looks like a hack, I have instead pushed a change that doesn't resort to weird tricks, a simple `unalias` was enough. It should not be less fast, or even faster.",False,0,MEMBER
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1494989692,feat(init)!: allow turning off aliases for libs and plugins,mcornella,9,1615814220,10,1494989692,0,1494949958,2023-04-03T21:14:57Z,Shipped! 🚀  Thank you for the review!,False,0,MEMBER
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/11558,Bar broken after OMZ update,Oman395,3,1620165643,1,1620165643,0,0,2023-03-11T22:32:11Z,"### Describe the bug

Title says it. Updated omz, now this is what I get:
```
/home/oran/.oh-my-zsh/lib/theme-and-appearance.zsh:4: parse error near `<<<'
${ret_status}$fg_bold[green] $fg[cyan]~ $fg_bold[blue]$(git_prompt_info)$fg_bold[blue]$(svn_prompt_info)$reset_color
```
Using awesomepanda, when I switch to certain themes (jonathan is the most recent one I tested) it works fine except the right side of the jonathan theme still shows up. Based on my limited testing, it looks like any theme that has nothing on the right has this issue, but that could just be a coincidence. When I attempt to update manually, I get `lib/theme-and-appearance.zsh: needs merge`, so that might have something to do with it.

### Steps to reproduce

1. Update omz to latest
2. That's it.

### Expected behavior

The bar to display normally.

### Screenshots and recordings

_No response_

### OS / Linux distribution

Arch Linux

### Zsh version

5.9

### Oh My Zsh version

master (92387d9f)

### Terminal emulator

Kitty and Konsole

### If using WSL on Windows, which version of WSL

None

### Additional context

_No response_",True,0,NONE
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1465043675,Bar broken after OMZ update,carlosala,3,1620165643,2,1465043675,0,1620165643,2023-03-11T22:51:12Z,Follow the instructions here https://github.com/ohmyzsh/ohmyzsh/issues/11058#issuecomment-1190024382,False,0,MEMBER
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1465061386,Bar broken after OMZ update,Oman395,3,1620165643,3,1465061386,0,1465043675,2023-03-12T00:55:57Z,"Thanks, that worked. Any idea why updating broke it like that, despite other updates not? It'd also be nice if there was just something in place to say ""hey, if there's three random arrows, and the git repo is messed up, maybe we should warn the user"". That's just a thought though, I don't have nearly enough experience with the omz code to know how hard that would be",False,0,NONE
https://api.github.com/repos/ohmyzsh/ohmyzsh/issues/comments/1465063175,Bar broken after OMZ update,rwmitchell,3,1620165643,4,1465063175,0,1465061386,2023-03-12T01:09:32Z,"It means you or something not in OMZ that you ran updated at least one file under git control that was also getting updated by omz update. This is purely user error. 

If you had read the lines with <<< and >>> they would have explained everything ",False,0,CONTRIBUTOR
https://api.github.com/repos/tinymce/tinymce/issues/8619,Issue 8616: Fixes keyboard navigation in sliding toolbar.,Yona-Appletree,3,1656164527,1,1656164527,0,0,2023-04-05T19:23:23Z,"GitHub issue: #8618

Description of Changes:

* Updated Keying config of SplitSlidingToolbar to behave like the main toolbar, which correct keyboard tab navigation in the overflow toolbar

Pre-checks:
* [x] Changelog entry added
* [ ] Tests have been added (if applicable)
* [x] Branch prefixed with `feature/`, `hotfix/` or `spike/`

Review:
* [ ] Milestone set
* [ ] Docs ticket created (if applicable)
",True,0,NONE
https://api.github.com/repos/tinymce/tinymce/issues/comments/1504764127,Issue 8616: Fixes keyboard navigation in sliding toolbar.,TheSpyder,3,1656164527,2,1504764127,0,1656164527,2023-04-12T06:59:37Z,"That might be how we fix it, although I think we should also not emit the tabstop attribute on non-group elements. I'll add this to our internal development notes, thank you!",False,0,MEMBER
https://api.github.com/repos/tinymce/tinymce/issues/comments/1504767463,Issue 8616: Fixes keyboard navigation in sliding toolbar.,TheSpyder,3,1656164527,3,1504767463,0,1504764127,2023-04-12T07:02:11Z,"Ah, we already have a draft PR open by now - #8638

I'll get a discussion going",False,0,MEMBER
https://api.github.com/repos/tinymce/tinymce/issues/comments/1508337535,Issue 8616: Fixes keyboard navigation in sliding toolbar.,TheSpyder,3,1656164527,4,1508337535,0,1504767463,2023-04-14T11:04:54Z,"We found a surprisingly simple solution to the problem. Thank you for you efforts, but we won't be using this PR. Please follow the other PR for updates.",False,0,MEMBER
https://api.github.com/repos/tinymce/tinymce/issues/8620,“TINY-9623: Prepare for 6.4.1 community release #8598“，This update iteration caused the upload graph function to be abnormal,huyanyawei,4,1656648971,1,1656648971,0,0,2023-04-06T04:36:12Z,"**What is the current behavior? Describe the bug**
6.4.1  Abnormal image transfer function
**Please provide the steps to reproduce and if possible a minimal demo of the problem via [fiddle.tiny.cloud](https://fiddle.tiny.cloud/) or similar.**
![image](https://user-images.githubusercontent.com/33106712/230272977-bd7df712-d2f2-4f9a-a724-e7f64be7f7d8.png)

**What is the expected behavior?**


**Which versions of TinyMCE, and which browser / OS are affected by this issue? Did this work in previous versions of TinyMCE?**
6.4.1 any browser",True,0,NONE
https://api.github.com/repos/tinymce/tinymce/issues/comments/1498599674,“TINY-9623: Prepare for 6.4.1 community release #8598“，This update iteration caused the upload graph function to be abnormal,TheSpyder,4,1656648971,2,1498599674,0,1656648971,2023-04-06T07:14:09Z,"I'm not sure what problem you're reporting, sorry. That popup is supposed to appear in our [full-featured demo](https://www.tiny.cloud/docs/tinymce/6/full-featured-premium-demo/) because the `quickbars` plugin is enabled.",False,0,MEMBER
https://api.github.com/repos/tinymce/tinymce/issues/comments/1499898101,“TINY-9623: Prepare for 6.4.1 community release #8598“，This update iteration caused the upload graph function to be abnormal,StriveTeam,4,1656648971,3,1499898101,0,1498599674,2023-04-07T03:38:32Z,"@TheSpyder > full-featured demo

[https://www.tiny.cloud/docs/tinymce/6/full-featured-premium-demo/](https://www.tiny.cloud/docs/tinymce/6/full-featured-premium-demo/)

 it's not ok through the quick upload function  in the latest version, but  ok in v5",False,0,NONE
https://api.github.com/repos/tinymce/tinymce/issues/comments/1502752908,“TINY-9623: Prepare for 6.4.1 community release #8598“，This update iteration caused the upload graph function to be abnormal,TheSpyder,4,1656648971,4,1502752908,0,1499898101,2023-04-11T06:29:02Z,"Oh, you mean clicking that button doesn't insert the selected image? That's the `quickimage` button, not the ""quick upload"" function.

This does appear to be a bug, thank you for the report.",False,0,MEMBER
https://api.github.com/repos/tinymce/tinymce/issues/comments/1502760176,“TINY-9623: Prepare for 6.4.1 community release #8598“，This update iteration caused the upload graph function to be abnormal,TheSpyder,4,1656648971,5,1502760176,0,1502752908,2023-04-11T06:37:44Z,Moving to #8626 for tracking as it has better information for our developers,False,0,MEMBER
https://api.github.com/repos/tinymce/tinymce/issues/8622,Powerpaste plugin and version 6.0 results in content paste duplication,neilBitflux,5,1657511170,1,1657511170,0,0,2023-04-06T14:15:39Z,"**What is the current behavior? Describe the bug**

Just upgraded from 5 to 6. I am told that the paste is now a core feature. Prior to 6 was a plugin that could be disabled by not adding it to the list of plugins. Now as its a core feature is enabled by deafault. If you install the powerpaste plugin this results in both plugins being enabled and causing the content to be pasted twice.

Remove powerpaste from the list of plugins and it pastes once.

**Please provide the steps to reproduce and if possible a minimal demo of the problem via [fiddle.tiny.cloud](https://fiddle.tiny.cloud/) or similar.**
I am using this in combination with @tinymce-angular 7.0. 
add the powerpaste plugin to tinymce version 6 and use it with @tinymce-angular 7.0.

**What is the expected behavior?**
Content should be pasted once when powerpaste plugin is being used. So we need a way of disabling paste core when in 6.0.

**Which versions of TinyMCE, and which browser / OS are affected by this issue? Did this work in previous versions of TinyMCE?**
chrome.
tinymce 6
tinymce-angular 7
this worked fine with tinymce 5 (I assuming because with 5 it was a plugin and not added to the list  so was disabled automaticaly) resulting in 1 pasted when powerPaste plugin was in the list.",True,0,NONE
https://api.github.com/repos/tinymce/tinymce/issues/comments/1502725066,Powerpaste plugin and version 6.0 results in content paste duplication,TheSpyder,5,1657511170,2,1502725066,0,1657511170,2023-04-11T05:54:36Z,"Something else is going on here. Powerpaste has always been supported on 6.x and doesn't paste twice. We use it in our own demos all the time:
https://www.tiny.cloud/docs/tinymce/6/full-featured-premium-demo/

I wonder if you still have the TinyMCE 5 paste plugin running? That's a scenario we didn't consider.",False,0,MEMBER
https://api.github.com/repos/tinymce/tinymce/issues/comments/1502767899,Powerpaste plugin and version 6.0 results in content paste duplication,neilBitflux,5,1657511170,3,1502767899,0,1502725066,2023-04-11T06:46:48Z,"Didn’t realise you needed to upgrade the plugins separately so Haven’t upgraded the plug-in itself from 5 to 6. When I upgraded tinymce
Does that need doing?
Thanks

Sent from my iPhone

On 11 Apr 2023, at 07:54, Andrew Herron ***@***.***> wrote:

﻿

Something else is going on here. Powerpaste has always been supported on 6.x and doesn't paste twice. We use it in our own demos all the time:
https://www.tiny.cloud/docs/tinymce/6/full-featured-premium-demo/

I wonder if you still have the TinyMCE 5 paste plugin running? That's a scenario we didn't consider.

—
Reply to this email directly, view it on GitHub<https://github.com/tinymce/tinymce/issues/8622#issuecomment-1502725066>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKRKLBAY7V23PM6IDLHEJ5LXATW2NANCNFSM6AAAAAAWVPCDSA>.
You are receiving this because you authored the thread.Message ID: ***@***.***>
",False,0,NONE
https://api.github.com/repos/tinymce/tinymce/issues/comments/1506441881,Powerpaste plugin and version 6.0 results in content paste duplication,TheSpyder,5,1657511170,4,1506441881,0,1502767899,2023-04-13T06:50:56Z,"The plugins are bundled with the editor, but if all you did was overwrite the existing `tinymce` folder on your server it may have left v5 plugins behind that we deleted in 6. We didn't ship stub plugins to overwrite things that are no longer needed.

If your configuration then still includes the v5 `paste` plugin it _might_ lead to this situation. Either way, removing `paste` from your config (since it's built-in now) and leaving just `powerpaste` should definitely fix it.",False,0,MEMBER
https://api.github.com/repos/tinymce/tinymce/issues/comments/1511031139,Powerpaste plugin and version 6.0 results in content paste duplication,neilBitflux,5,1657511170,5,1511031139,0,1506441881,2023-04-17T09:46:37Z,"I’m using powerpaste plugin 5.6.2-4
In the plug-ins folder. Could this be an old version that didn’t get updated when moving from tinymce 5>6?

Is there a newer version that I can download and install here?

If so where could I get this from.

Sent from my iPhone

On 13 Apr 2023, at 07:51, Andrew Herron ***@***.***> wrote:

﻿

The plugins are bundled with the editor, but if all you did was overwrite the existing tinymce folder on your server it may have left v5 plugins behind that we deleted in 6. We didn't ship stub plugins to overwrite things that are no longer needed.

If your configuration then still includes the v5 paste plugin it might lead to this situation. Either way, removing paste from your config (since it's built-in now) and leaving just powerpaste should definitely fix it.

—
Reply to this email directly, view it on GitHub<https://github.com/tinymce/tinymce/issues/8622#issuecomment-1506441881>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKRKLBDPYYE2BSQ6O2EBKFDXA6O5XANCNFSM6AAAAAAWVPCDSA>.
You are receiving this because you authored the thread.Message ID: ***@***.***>
",False,0,NONE
https://api.github.com/repos/tinymce/tinymce/issues/comments/2109059619,Powerpaste plugin and version 6.0 results in content paste duplication,tiny-stale-bot,5,1657511170,6,2109059619,0,1511031139,2024-05-14T00:39:02Z,This issue is stale because it has been open 365 days with no activity. Please comment if you wish to keep this issue open or it will be closed in 30 days.,False,0,COLLABORATOR
https://api.github.com/repos/tinymce/tinymce/issues/8625,"When newline behavior is changed to <br> in TinyMCE 6, alignment plugin is not working properly",sha2nktiwade,4,1658445635,1,1658445635,0,0,2023-04-07T06:53:32Z,"**What is the current behavior? Describe the bug**

In TinyMCE 6, when the newline behavior is changed from p to br, the alignment plugin is giving incorrect result as the alignment style is applied to the outer p tag rather the individual brs where alignment option was applied.

**Please provide the steps to reproduce and if possible a minimal demo of the problem via [fiddle.tiny.cloud](https://fiddle.tiny.cloud/) or similar.**

1. Change the newline behavior is TinyMCE 6 with this line in config: newline_behavior: 'invert'.
2. Write multiple line text in the editor.
3. When togging and viewing the source code, it looks like below:
    <p>Text1<br>Text2<br>Text3<br>Text4</p>
4. Now try to the alignment of the only the second or third line in the editor.
5. The source code now looks like below:
    <p style=""text-align: center;"">Text1<br>Text2<br>Text3<br>Text4</p>
6. We can see that the alignment of all the lines are changed even when we wanted to change the alignment of a single line. This happened because even when the newline behavior is changed to <br>, still we are getting one outer <p> tag and all the content is wrapped in that tag.

Expected Result: Only the specific line should have changed the alignment. All the content should be separated by <br> and there should not be any <p> tag here.

Actual result: The alignment option is not working properly in version 6 of TinyMCE.

**What is the expected behavior?**
Expected Result: Only the specific line should have changed the alignment. All the content should be separated by <br> and there should not be any <p> tag here.

**Which versions of TinyMCE, and which browser / OS are affected by this issue? Did this work in previous versions of TinyMCE?**
We are using latest version TinyMCE 6. This is reproducable in any browser and is not browser specific. In earlier version of TinyMCE, it was not wraping the content in <p> and hence even after changing the newline behavior it was working properly.",True,0,NONE
https://api.github.com/repos/tinymce/tinymce/issues/comments/1500002723,"When newline behavior is changed to <br> in TinyMCE 6, alignment plugin is not working properly",sha2nktiwade,4,1658445635,2,1500002723,0,1658445635,2023-04-07T06:59:37Z,"Initial Source mode:
![image](https://user-images.githubusercontent.com/130130998/230558516-64fd6a55-1a61-4e02-a0fc-6e1256405840.png)

Source mode after changing the alignment:
![image](https://user-images.githubusercontent.com/130130998/230558695-202cf546-cce7-42a7-aff9-54c0479e86d4.png)

",False,0,NONE
https://api.github.com/repos/tinymce/tinymce/issues/comments/1502767563,"When newline behavior is changed to <br> in TinyMCE 6, alignment plugin is not working properly",TheSpyder,4,1658445635,3,1502767563,0,1500002723,2023-04-11T06:46:22Z,"This was an unfortunate loss with the removal of `forced_root_block: false` in TinyMCE 6. Block operations now only apply to block elements.

I will have a chat to our PM and see if we might consider bringing this back before I close the issue.",False,0,MEMBER
https://api.github.com/repos/tinymce/tinymce/issues/comments/1524822587,"When newline behavior is changed to <br> in TinyMCE 6, alignment plugin is not working properly",sha2nktiwade,4,1658445635,4,1524822587,0,1502767563,2023-04-27T06:19:38Z,@TheSpyder - Could you please share if there are any updates on this issue.,False,0,NONE
https://api.github.com/repos/tinymce/tinymce/issues/comments/1525066935,"When newline behavior is changed to <br> in TinyMCE 6, alignment plugin is not working properly",TheSpyder,4,1658445635,5,1525066935,0,1524822587,2023-04-27T08:10:32Z,"Apologies, I’ve had a lot going on and by the time the conversation ended I forgot it had started here.

The answer is no. There isn’t enough demand to consider bringing back even this small piece of the `false` code. Sorry to disappoint you.",False,0,MEMBER
https://api.github.com/repos/doctrine/DoctrineFixturesBundle/issues/367,"""PHPUnit highest"" build fails",hlecorche,6,1218544859,1,1218544859,0,0,2022-04-28T10:46:46Z,"See #365 #366

```
HPUnit 9.5.20 #StandWithUkraine

Warning:       Your XML configuration validates against a deprecated schema.
Suggestion:    Migrate your XML configuration using ""--migrate-configuration""!

Testing 
....S......EEEE...                                                18 / 18 (100%)

Time: 00:00.482, Memory: 30.00 MB

There were 4 errors:

1) Doctrine\Bundle\FixturesBundle\Tests\IntegrationTest::testRunCommandWithDefaultPurger
Calling `transactional()` instead of `wrapInTransaction()` which is not implemented on Mock_EntityManagerInterface_69c8e1e4

/home/runner/work/DoctrineFixturesBundle/DoctrineFixturesBundle/vendor/doctrine/orm/lib/Doctrine/ORM/Decorator/EntityManagerDecorator.php:93
/home/runner/work/DoctrineFixturesBundle/DoctrineFixturesBundle/vendor/doctrine/data-fixtures/lib/Doctrine/Common/DataFixtures/Executor/ORMExecutor.php:88
/home/runner/work/DoctrineFixturesBundle/DoctrineFixturesBundle/Command/LoadDataFixturesDoctrineCommand.php:158
/home/runner/work/DoctrineFixturesBundle/DoctrineFixturesBundle/vendor/symfony/console/Command/Command.php:298
/home/runner/work/DoctrineFixturesBundle/DoctrineFixturesBundle/vendor/symfony/console/Tester/CommandTester.php:74
/home/runner/work/DoctrineFixturesBundle/DoctrineFixturesBundle/Tests/IntegrationTest.php:353
phpvfscomposer:///home/runner/work/DoctrineFixturesBundle/DoctrineFixturesBundle/vendor/phpunit/phpunit/phpunit:97

2) Doctrine\Bundle\FixturesBundle\Tests\IntegrationTest::testRunCommandWithPurgeExclusions
Calling `transactional()` instead of `wrapInTransaction()` which is not implemented on Mock_EntityManagerInterface_69c8e1e4

/home/runner/work/DoctrineFixturesBundle/DoctrineFixturesBundle/vendor/doctrine/orm/lib/Doctrine/ORM/Decorator/EntityManagerDecorator.php:93
/home/runner/work/DoctrineFixturesBundle/DoctrineFixturesBundle/vendor/doctrine/data-fixtures/lib/Doctrine/Common/DataFixtures/Executor/ORMExecutor.php:88
/home/runner/work/DoctrineFixturesBundle/DoctrineFixturesBundle/Command/LoadDataFixturesDoctrineCommand.php:158
/home/runner/work/DoctrineFixturesBundle/DoctrineFixturesBundle/vendor/symfony/console/Command/Command.php:298
/home/runner/work/DoctrineFixturesBundle/DoctrineFixturesBundle/vendor/symfony/console/Tester/CommandTester.php:74
/home/runner/work/DoctrineFixturesBundle/DoctrineFixturesBundle/Tests/IntegrationTest.php:400
phpvfscomposer:///home/runner/work/DoctrineFixturesBundle/DoctrineFixturesBundle/vendor/phpunit/phpunit/phpunit:97

3) Doctrine\Bundle\FixturesBundle\Tests\IntegrationTest::testRunCommandWithCustomPurgerAndCustomEntityManager
Calling `transactional()` instead of `wrapInTransaction()` which is not implemented on Mock_EntityManagerInterface_69c8e1e4

/home/runner/work/DoctrineFixturesBundle/DoctrineFixturesBundle/vendor/doctrine/orm/lib/Doctrine/ORM/Decorator/EntityManagerDecorator.php:93
/home/runner/work/DoctrineFixturesBundle/DoctrineFixturesBundle/vendor/doctrine/data-fixtures/lib/Doctrine/Common/DataFixtures/Executor/ORMExecutor.php:88
/home/runner/work/DoctrineFixturesBundle/DoctrineFixturesBundle/Command/LoadDataFixturesDoctrineCommand.php:158
/home/runner/work/DoctrineFixturesBundle/DoctrineFixturesBundle/vendor/symfony/console/Command/Command.php:298
/home/runner/work/DoctrineFixturesBundle/DoctrineFixturesBundle/vendor/symfony/console/Tester/CommandTester.php:74
/home/runner/work/DoctrineFixturesBundle/DoctrineFixturesBundle/Tests/IntegrationTest.php:450
phpvfscomposer:///home/runner/work/DoctrineFixturesBundle/DoctrineFixturesBundle/vendor/phpunit/phpunit/phpunit:97

4) Doctrine\Bundle\FixturesBundle\Tests\IntegrationTest::testRunCommandWithPurgeMode
Calling `transactional()` instead of `wrapInTransaction()` which is not implemented on Mock_EntityManagerInterface_69c8e1e4

/home/runner/work/DoctrineFixturesBundle/DoctrineFixturesBundle/vendor/doctrine/orm/lib/Doctrine/ORM/Decorator/EntityManagerDecorator.php:93
/home/runner/work/DoctrineFixturesBundle/DoctrineFixturesBundle/vendor/doctrine/data-fixtures/lib/Doctrine/Common/DataFixtures/Executor/ORMExecutor.php:88
/home/runner/work/DoctrineFixturesBundle/DoctrineFixturesBundle/Command/LoadDataFixturesDoctrineCommand.php:158
/home/runner/work/DoctrineFixturesBundle/DoctrineFixturesBundle/vendor/symfony/console/Command/Command.php:298
/home/runner/work/DoctrineFixturesBundle/DoctrineFixturesBundle/vendor/symfony/console/Tester/CommandTester.php:74
/home/runner/work/DoctrineFixturesBundle/DoctrineFixturesBundle/Tests/IntegrationTest.php:497
phpvfscomposer:///home/runner/work/DoctrineFixturesBundle/DoctrineFixturesBundle/vendor/phpunit/phpunit/phpunit:97

ERRORS!
Tests: 18, Assertions: 32, Errors: 4, Skipped: 1.

Generating code coverage report in Clover XML format ... done [00:00.004]
Error: Process completed with exit code 2.
```",True,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/DoctrineFixturesBundle/issues/comments/1112091651,"""PHPUnit highest"" build fails",greg0ire,6,1218544859,2,1112091651,0,1218544859,2022-04-28T11:28:28Z,"This is related to https://github.com/doctrine/orm/pull/8419 : the method was introduced as a comment, but is not officially part of the interface, which explains why it is missing from the mock. I wonder if it wouldn't have been better to introduce it as an `@method` annotation on the interface. Maybe we could avoid some static analysis errors like that. Cc @snapshotpl

Also, I'm working on addressing a deprecation I saw when running the test suite of this bundle in https://github.com/doctrine/data-fixtures/pull/395",False,0,MEMBER
https://api.github.com/repos/doctrine/DoctrineFixturesBundle/issues/comments/1112094788,"""PHPUnit highest"" build fails",greg0ire,6,1218544859,3,1112094788,0,1112091651,2022-04-28T11:31:59Z,It's important to note that this failure happens with dev dependencies. It can be reproduced locally by using `composer config minimum-stability dev`,False,0,MEMBER
https://api.github.com/repos/doctrine/DoctrineFixturesBundle/issues/comments/1112419849,"""PHPUnit highest"" build fails",derrabus,6,1218544859,4,1112419849,0,1112094788,2022-04-28T16:34:13Z,@greg0ire It's a bit odd that the ORM emits an `E_USER_NOTICE` error in this situation. Maybe we should demote that to a deprecation?,False,0,MEMBER
https://api.github.com/repos/doctrine/DoctrineFixturesBundle/issues/comments/1112452079,"""PHPUnit highest"" build fails",derrabus,6,1218544859,5,1112452079,0,1112419849,2022-04-28T17:07:15Z,Fixed by #366,False,0,MEMBER
https://api.github.com/repos/doctrine/DoctrineFixturesBundle/issues/comments/1112487217,"""PHPUnit highest"" build fails",greg0ire,6,1218544859,6,1112487217,0,1112452079,2022-04-28T17:38:23Z,"@derrabus sorry, what `E_USER_NOTICE` are you referring to?",False,0,MEMBER
https://api.github.com/repos/doctrine/DoctrineFixturesBundle/issues/comments/1112531918,"""PHPUnit highest"" build fails",derrabus,6,1218544859,7,1112531918,0,1112487217,2022-04-28T18:30:43Z,https://github.com/doctrine/orm/blob/38d1124be9b51d5ca7ecd86e2fb634797116f48f/lib/Doctrine/ORM/Decorator/EntityManagerDecorator.php#L90-L97,False,0,MEMBER
https://api.github.com/repos/doctrine/DoctrineFixturesBundle/issues/368,Fix build,hlecorche,10,1218592940,1,1218592940,0,0,2022-04-28T11:31:41Z,Fix #367 ,True,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/DoctrineFixturesBundle/issues/comments/1112096059,Fix build,greg0ire,10,1218592940,2,1112096059,0,1218592940,2022-04-28T11:33:24Z,Nice job! Please improve your commit message according to [the contributing guide](https://www.doctrine-project.org/contribute/index.html#working-on-topic-branches). It's hard to understand what you did and why.,False,0,MEMBER
https://api.github.com/repos/doctrine/DoctrineFixturesBundle/issues/comments/1112114566,Fix build,greg0ire,10,1218592940,3,1112114566,0,1112096059,2022-04-28T11:56:34Z,The Psalm failures look weird :thinking: ,False,0,MEMBER
https://api.github.com/repos/doctrine/DoctrineFixturesBundle/issues/comments/1112122967,Fix build,hlecorche,10,1218592940,4,1112122967,0,1112114566,2022-04-28T12:06:38Z,"> The Psalm failures look weird 🤔

Yes, where does it see the word `object`?",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/DoctrineFixturesBundle/issues/comments/1112126797,Fix build,stof,10,1218592940,5,1112126797,0,1112122967,2022-04-28T12:10:19Z,"Probably in a dependency using the `object` typehint that is not valid on PHP 7.1, because the job installs deps for PHP 8.0 but analyses for PHP 7.1",False,0,MEMBER
https://api.github.com/repos/doctrine/DoctrineFixturesBundle/issues/comments/1112127289,Fix build,hlecorche,10,1218592940,6,1112127289,0,1112126797,2022-04-28T12:10:51Z,I fixed the CS. I would do a squash at the end.,False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/DoctrineFixturesBundle/issues/comments/1112144334,Fix build,hlecorche,10,1218592940,7,1112144334,0,1112127289,2022-04-28T12:29:33Z,"@stof Is it a good solution to add `phpVersion=""8.0""` in  `psalm.xml` file ? Thanks.

With this addition, the problem is solved.",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/DoctrineFixturesBundle/issues/comments/1112179022,Fix build,stof,10,1218592940,8,1112179022,0,1112144334,2022-04-28T13:05:16Z,"Well, analyzing based on PHP 7.1 is expected, as that's what the code needs to support. but that job should configure composer to resolve deps compatible with 7.1",False,0,MEMBER
https://api.github.com/repos/doctrine/DoctrineFixturesBundle/issues/comments/1112204519,Fix build,hlecorche,10,1218592940,9,1112204519,0,1112179022,2022-04-28T13:28:14Z,"@stof I can replace

```yaml
jobs:
  static-analysis:
    uses: ""doctrine/.github/.github/workflows/static-analysis.yml@1.1.1""
```

By

```yaml
jobs:
  static-analysis:
    uses: ""doctrine/.github/.github/workflows/static-analysis.yml@1.1.1""
    with:
      php-version: ""7.1""
```

Everything will be executed in PHP 7.1 (Composer + psalm). Is it a good idea ?",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/DoctrineFixturesBundle/issues/comments/1112453338,Fix build,derrabus,10,1218592940,10,1112453338,0,1112204519,2022-04-28T17:08:38Z,My take on this: #366,False,0,MEMBER
https://api.github.com/repos/doctrine/DoctrineFixturesBundle/issues/comments/1112497667,Fix build,derrabus,10,1218592940,11,1112497667,0,1112453338,2022-04-28T17:51:22Z,"Closing in favor of #366. Thank you for your attempt to fix the CI, though. 👍🏻 ",False,0,MEMBER
https://api.github.com/repos/doctrine/DoctrineFixturesBundle/issues/370,FK error by purge (incorrect order of deleting from tables),maximmandrik,3,1255635149,1,1255635149,0,0,2022-06-01T10:37:35Z,"There is such an tables architecture:
<img src=""https://user-images.githubusercontent.com/2076970/171383898-71a4b427-fd01-4b30-94ae-d5facf4699a9.png"" width=""600"">

Execute `app:fixtures:load` with purge.

When automatically deleting from network_switches_ports, I get an error:

```
[critical] Error thrown while running command ""doctrine:fixtures:load"". Message: ""An exception occurred while executing a query: SQLSTATE[23503]: Foreign key violation: 7 ERROR:  update or delete on table ""network_switches_ports"" violates foreign key constraint ""fk_47b01a1e7449a980"" on table ""hardware_ip_cameras""
DETAIL:  Key (id)=(1ece1947-037b-6c14-90d9-8784702a4f98) is still referenced from table ""hardware_ip_cameras"".""
```

FK from `hardware_ip_cameras`.

If you delete in the correct order, then such an error would not have occurred.

Correct order of deleting from tables:
`hardware_ip_cameras`, `hardware_video_servers`, `network_switches_ports`, `hardware_network_switches`, `hardware`.",True,0,NONE
https://api.github.com/repos/doctrine/DoctrineFixturesBundle/issues/comments/1143493217,FK error by purge (incorrect order of deleting from tables),greg0ire,3,1255635149,2,1143493217,0,1255635149,2022-06-01T11:38:49Z,Please provide [a stack trace](https://symfony.com/doc/current/contributing/code/stack_trace.html),False,0,MEMBER
https://api.github.com/repos/doctrine/DoctrineFixturesBundle/issues/comments/1161701964,FK error by purge (incorrect order of deleting from tables),fd6130,3,1255635149,3,1161701964,0,1143493217,2022-06-21T12:47:04Z,"There are no other way to disable the FK constraint in `doctrine:fixtures:load` command when you want to refresh the database, so have to use this way instead:

From https://github.com/doctrine/DoctrineFixturesBundle/issues/50
```
php bin/console doctrine:schema:drop --force
php bin/console doctrine:schema:update --force
php bin/console doctrine:fixtures:load
```",False,0,NONE
https://api.github.com/repos/doctrine/DoctrineFixturesBundle/issues/comments/1403274007,FK error by purge (incorrect order of deleting from tables),bobvandevijver,3,1255635149,4,1403274007,0,1161701964,2023-01-25T08:50:49Z,"Depending on you database, you could try the truncate flag. However, if it causes an implicit flush for the transaction, you will be out of luck with that method on PHP 8.

I've solved this issue by using a custom purger, basically as described here: https://stackoverflow.com/questions/64570346/doctrine-fixtures-how-to-override-the-purger-class",False,0,NONE
https://api.github.com/repos/doctrine/DoctrineFixturesBundle/issues/375,chore: add ci tests for php 8.2,Chris53897,5,1518732705,1,1518732705,0,0,2023-01-04T10:38:08Z,"bump github action version for checkout 2 => 3

The failing test is not related to php 8.2.
If i run tests locally with php 8.2 (and php 8.1) i get different results after each run.
range is from 0 to 3 errors.

`Symfony\Component\DependencyInjection\Exception\ServiceNotFoundException : You have requested a non-existent service ""test.doctrine.fixtures.loader"". Did you mean this: ""test.doctrine.fixtures_load_command""?`",True,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/DoctrineFixturesBundle/issues/comments/1370767271,chore: add ci tests for php 8.2,greg0ire,5,1518732705,2,1370767271,0,1518732705,2023-01-04T10:48:26Z,"Indeed if I re-run the tests, fewer are failing… I don't know why that is.",False,0,MEMBER
https://api.github.com/repos/doctrine/DoctrineFixturesBundle/issues/comments/1370771918,chore: add ci tests for php 8.2,greg0ire,5,1518732705,3,1370771918,0,1370767271,2023-01-04T10:53:00Z,The remaining failure seems similar to https://github.com/doctrine/data-fixtures/issues/414,False,0,MEMBER
https://api.github.com/repos/doctrine/DoctrineFixturesBundle/issues/comments/1370805897,chore: add ci tests for php 8.2,Chris53897,5,1518732705,4,1370805897,0,1370771918,2023-01-04T11:26:34Z,The remaining PhpStan error should be resolved in a sperate PR in my eyes. WDYT?,False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/DoctrineFixturesBundle/issues/comments/1370807544,chore: add ci tests for php 8.2,greg0ire,5,1518732705,5,1370807544,0,1370805897,2023-01-04T11:28:22Z,I agree.,False,0,MEMBER
https://api.github.com/repos/doctrine/DoctrineFixturesBundle/issues/comments/1372600430,chore: add ci tests for php 8.2,greg0ire,5,1518732705,6,1372600430,0,1370807544,2023-01-05T18:46:38Z,Thanks @Chris53897 !,False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/10610,Bug when use Featch EGER and SQLFilter,dbannik,5,1651062483,1,1651062483,0,0,2023-04-02T19:16:21Z,"### Bug Report

|    Q        |   A
|------------ | ------
| BC Break    | yes
| Version     | 2.14.x

#### Summary

There is entity:
`Patient`
with property collection `Order` (orders with Fetch EGER)

`Order`
with property `Practice` (sets SQLFilter of current Company in system)

Company is system: `1`, `2`

When first entity load `Patient` with Company `1` is good
When (SQLFilter update parameter to Company `2`) and load next `Patient` , Orders collection load with practice `1` in SQL QUERY!

#### Current behavior

Cached `Join sql` in persist entity (Patient) if use `Fetch EGER` property
If change SQLFilter parameter, cached join sql does not refreshed and used old sql join parameters!

_entityManager->clear() persisted entity metadata does not removed!_

#### How to reproduce

Entity: Company
Entity: Patient
Entity: Order

Patient -> OneToMany (Fetch EGER) -> Order
Order -> ManyToOne -> Company

SQLFilter set parameter Company `1` (added to `Order` filter)

#### Expected behavior

When switch SQLFilter parameter (Company)  join sql should be refreshed with actual SQLFilters!

",True,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/1494241046,Bug when use Featch EGER and SQLFilter,derrabus,5,1651062483,2,1494241046,0,1651062483,2023-04-03T12:33:13Z,"I'm sorry, I don't really understand this bug report. I tried to make sense of the test you've provided in your PR but that confuses me even more. Can you please elaborate again in full sentences…

* what you're trying to do
* how you're trying to achive that
* why you believe that the ORMs current behavior is wrong?",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/1494988677,Bug when use Featch EGER and SQLFilter,dbannik,5,1651062483,3,1494988677,0,1494241046,2023-04-03T21:14:09Z,"@derrabus 
I have an orm running in a message queue and I need to be able to switch context using SQL filters.
when changing the context of the ""filter options"" I want to get the correct correct answer result!
but when changing the filter parameter now the join is cached from the previous filter",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/1577147912,Bug when use Featch EGER and SQLFilter,jelovac,5,1651062483,4,1577147912,0,1494988677,2023-06-05T16:56:51Z,"@derrabus ,

I think I am experiencing the same issue as the author. 

Take a look at the following piece of code:

```
// vendor/doctrine/orm/lib/Doctrine/ORM/Internal/Hydration/ObjectHydrator.php

    protected function hydrateAllData()
    {
        $result = [];

        while ($row = $this->statement()->fetchAssociative()) {
            $this->hydrateRowData($row, $result);
        }
```

What happens is that for some reason `$this->statement()->fetchAssociative()` returns wrong result set. 

In my case it seems that this happens when there were already queries against database for the same entity. 

When I inspect using xdebug the $this->statement object I can see that it is an instance of `\Doctrine\DBAL\Driver\PDO\Result` and navigating inside it I can see that actual `\PDOStatement` object contains the SQL Filter part. However when statement is iterated over using `fetchAssociative()` it includes rows which shouldn't be there.

I am suspecting that there is some kind of cache involved.
",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/1577698979,Bug when use Featch EGER and SQLFilter,derrabus,5,1651062483,5,1577698979,0,1577147912,2023-06-05T23:54:21Z,"Same questions for you then: https://github.com/doctrine/orm/issues/10610#issuecomment-1494241046

I need clear steps to reproduce the issue before I can help you.",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/1578136905,Bug when use Featch EGER and SQLFilter,jelovac,5,1651062483,6,1578136905,0,1577698979,2023-06-06T08:03:56Z,"> Same questions for you then: [#10610 (comment)](https://github.com/doctrine/orm/issues/10610#issuecomment-1494241046)
> 
> I need clear steps to reproduce the issue before I can help you.

I was wrong. My subquery condition in the filter was bad. And as I troubleshooted directly on the test database the generated PDO statement SQL I though that the filter was working because it was missing one row which I intended to filter. However, I forgot that I am using test environment and that records which are inserted during tests are not commited to the test DB (Doctrine Test Bundle). So the row was missing from the result set because it was never actually inserted.

So not an issue for me anymore.",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/10613,Extract AssociationMapping in its own DTO,greg0ire,4,1652772243,1,1652772243,0,0,2023-04-03T21:07:57Z,,True,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/1494986179,Extract AssociationMapping in its own DTO,greg0ire,4,1652772243,2,1494986179,0,1652772243,2023-04-03T21:12:13Z,"I've tried splitting out `JoinColumnMapping` in a separate PR, but it was too hard. Sorry for the big PR :sweat: ",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/1494989807,Extract AssociationMapping in its own DTO,greg0ire,4,1652772243,3,1494989807,0,1494986179,2023-04-03T21:15:02Z,Oh and I realized right after closing my laptop I need to address @SenseException 's review on the previous monster PR,False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/1497013130,Extract AssociationMapping in its own DTO,greg0ire,4,1652772243,4,1497013130,0,1494989807,2023-04-05T07:01:07Z,"> Those instanceof checks of mappings are reoccurring multiple times. I'd prefer to have them in their own mapping-methods for simplicity.

I just pushed a new version where I introduce more of those methods. There are still `instanceof` checks that remain, some of which might disappear when https://github.com/phpstan/phpstan/issues/8904 gets fixed. Other are checks inside tests, I assumed you didn't mean those ones.",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/comments/1504700724,Extract AssociationMapping in its own DTO,greg0ire,4,1652772243,5,1504700724,0,1497013130,2023-04-12T05:57:53Z,"@SenseException @derrabus I actually addressed that comment by introducing a few lines of code above, which might explain why that diff is not marked as outdated.",False,0,MEMBER
https://api.github.com/repos/doctrine/orm/issues/10618,Why does my entity need an arbitrary ::getId() method in this scenario?,danielrhodeswarp,3,1662260562,1,1662260562,0,0,2023-04-11T11:10:14Z,"### Bug Report

<!-- Fill in the relevant information below to help triage your issue. -->

|    Q        |   A
|------------ | ------
| BC Break    | no
| Version     | 2.14.1


#### Summary

<!-- Provide a summary describing the problem you are experiencing. -->
I have a ""parent"" entity (Grouping) which may have zero, one or more ""child"" entities (GroupingAssociation).
Grouping has a few standard text and date fields.
GroupingAssociation is a polymorphic tracking table and it stores Individuals (another Doctrine entity) and / or Services (another Doctrine entity) that may belong to a Grouping.
One novel thing with the GroupingAssociation entity is that it does not have a single primary identifier column of its own - its primary key is a composite of every field that it has. (And I suspect that this might be the cause of the issue.)

#### Current behavior

<!-- What is the current (buggy) behavior? -->
I can only persist() and flush() my Grouping and GroupingAssociation entities if I add an arbitrary `getID()` method to the GroupingAssociation entity.
If I do not have this arbitrary `getID()` method - I get this error:

> Attempted to call an undefined method named ""getId"" of class ""App\Entity\GroupingAssociation"".

#### How to reproduce

<!--
Provide steps to reproduce the bug.
If possible, also add a code snippet with relevant configuration, entity mappings, DQL etc.
Adding a failing Unit or Functional Test would help us a lot - you can submit one in a Pull Request separately, referencing this bug report.
-->

I get the error every time with the following controller method and configuration of entities:

![orm_issue_4](https://user-images.githubusercontent.com/1181906/231140308-8080786b-bddb-432b-be18-a17bf1a4685d.png)
![orm_issue_1](https://user-images.githubusercontent.com/1181906/231140314-502803d7-22a1-47ab-bc32-23c709f96593.png)
![orm_issue_2](https://user-images.githubusercontent.com/1181906/231140316-7836fe50-d953-4368-84a3-6e0be67b990e.png)
![orm_issue_3](https://user-images.githubusercontent.com/1181906/231140317-c0e52506-878f-43ee-8fe1-7f61237d9fce.png)

#### Expected behavior

<!-- What was the expected (correct) behavior? -->

I would not expect to have to insert an arbitrary `getId()` method into an entity that doesn't have an ""id"" column, or that doesn't have a single primary key column.
",True,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/1505565806,Why does my entity need an arbitrary ::getId() method in this scenario?,mpdude,3,1662260562,2,1505565806,0,1662260562,2023-04-12T16:20:36Z,"Can you use a debugger to find out when/why/where the code reaches/calls that getId()` method?

Also, I notice you're using the same property as the `@Id` column and declare it to be an association. I guess this is valid, but at the same time it's a pattern I have seen rarely until today.",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/orm/issues/comments/1508413147,Why does my entity need an arbitrary ::getId() method in this scenario?,danielrhodeswarp,3,1662260562,3,1508413147,0,1505565806,2023-04-14T12:14:10Z,"Thanks @mpdude , yes I think the quirkiness here stems from having such an unusual primary key on my entity.
Debugging - and even just stack tracing - is a great idea that I will look into.
Who knows, this could be an actual bug in Doctrine?",False,0,NONE
https://api.github.com/repos/doctrine/orm/issues/comments/1508570653,Why does my entity need an arbitrary ::getId() method in this scenario?,danielrhodeswarp,3,1662260562,4,1508570653,0,1508413147,2023-04-14T13:59:44Z,"Ah, OK, well I think we can close this issue as far as it being an issue with Doctrine.
The thing that is trying to call ->getID() is the data-dog/audit-bundle package that I am using.
So either a bug or a mis-configuration with data-dog and nothing sinister with Doctrine :-) ",False,0,NONE
https://api.github.com/repos/doctrine/DoctrineBundle/issues/1643,Error in XML mapping (gedmo) afer upgrade to 2.9,eisberg,20,1665316056,1,1665316056,0,0,2023-04-12T17:42:51Z,"### BC Break Report

<!-- Fill in the relevant information below to help triage your issue. -->

|    Q        |   A
|------------ | ------
| BC Break    | yes
| Version     | 2.9

#### Summary
i get error after upgrade this version.

```
libxml error: Element '{http://gediminasm.org/schemas/orm/doctrine-extensions-mapping}timestampable': No matching global element declaration available, but demanded by the strict wildcard.
in src/Resources/config/doctrine/UserGroupRelation.orm.xml at line 21
```


Problem in PR: https://github.com/doctrine/orm/pull/10579

see comments in issue: https://github.com/doctrine/orm/issues/10552


",True,0,NONE
https://api.github.com/repos/doctrine/DoctrineBundle/issues/comments/1506010981,Error in XML mapping (gedmo) afer upgrade to 2.9,dmaicher,20,1665316056,2,1506010981,0,1665316056,2023-04-12T17:47:02Z,"you are using DoctrineBundle, right? Can you check if this is fixed if you revert back to `v2.8.3` for DoctrineBundle? I'm guessing you are currently on the latest version `v2.9.0`?",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/DoctrineBundle/issues/comments/1506010984,Error in XML mapping (gedmo) afer upgrade to 2.9,eisberg,20,1665316056,3,1506010984,0,1506010981,2023-04-12T17:52:03Z,"That's right, in DoctrineBundle  v2.8.3 everything is ok",False,0,NONE
https://api.github.com/repos/doctrine/DoctrineBundle/issues/comments/1506010990,Error in XML mapping (gedmo) afer upgrade to 2.9,dmaicher,20,1665316056,4,1506010990,0,1506010984,2023-04-12T17:57:46Z,"Its caused by [enabling strict XSD validation by default](https://github.com/doctrine/DoctrineBundle/blob/2.9.x/UPGRADE-2.9.md#xsd-schema-validation) on DoctrineBundle `v2.9.0`. 

We decided to not make it configurable for now by adding yet another config option. Can this issue be resolved instead by making the XML valid for this XSD validation?

cc @ostrolucky ",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/DoctrineBundle/issues/comments/1506010993,Error in XML mapping (gedmo) afer upgrade to 2.9,alexander-schranz,20,1665316056,5,1506010993,0,1506010990,2023-04-12T20:53:13Z,"We @sulu are running into the same problem. Here is our

> Can this issue be resolved instead by making the XML valid for this XSD validation?

I think the validation is failing because `gedmo` extension requires additional xml tags.

Here is our XML: https://github.com/sulu/sulu/blob/08a40b7de9c1b3f9a6c42edc928ee8e4ff9ea97c/src/Sulu/Bundle/MediaBundle/Resources/config/doctrine/Collection.orm.xml#L5

It follows the gedmo docs and:

```xml
xmlns:gedmo=""http://gediminasm.org/schemas/orm/doctrine-extensions-mapping""
```

Is added but still seems failing.

As already mention the enabled validation here seems be the problem:

https://github.com/dmaicher/DoctrineBundle/blob/14b66ef3bef181f663d07a1d475bc67ed8a4ce56/DependencyInjection/DoctrineExtension.php#L1158-L1159",False,0,CONTRIBUTOR
https://api.github.com/repos/doctrine/DoctrineBundle/issues/comments/1506015450,Error in XML mapping (gedmo) afer upgrade to 2.9,greg0ire,20,1665316056,6,1506015450,0,1506010993,2023-04-12T21:59:51Z,"Transferring to the correct repository.

Also, not sure if this is going to fix your issue @alexander-schranz but I'd recommend you use `vendor/doctrine/orm/doctrine-mapping.xsd` instead of `http://doctrine-project.org/schemas/orm/doctrine-mapping.xsd`. That way you are validating your mapping against the right version of the schema.",False,0,MEMBER
https://api.github.com/repos/doctrine/DoctrineBundle/issues/comments/1506379141,Error in XML mapping (gedmo) afer upgrade to 2.9,jakubtobiasz,20,1665316056,7,1506379141,0,1506015450,2023-04-13T05:45:23Z,Same problem in @Sylius 🙋🏼‍♂️.,False,0,NONE
https://api.github.com/repos/doctrine/DoctrineBundle/issues/comments/1506387079,Error in XML mapping (gedmo) afer upgrade to 2.9,greg0ire,20,1665316056,8,1506387079,0,1506379141,2023-04-13T05:55:48Z,"@jakubtobiasz noted, but please, let's not pile up +1s here, and focus on getting to a solution instead. If you want to +1, you have reactions.

A way forward could be to disable XSD validation in a patch release of the doctrine bundle, then expose a configuration node in the next minor release, and deprecate not setting it to `true`.",False,0,MEMBER
https://api.github.com/repos/doctrine/DoctrineBundle/issues/comments/1506492462,Error in XML mapping (gedmo) afer upgrade to 2.9,ostrolucky,20,1665316056,9,1506492462,0,1506387079,2023-04-13T07:35:55Z,"Gedmo has wrong schema, it should be fixed there. Adding config option that we have to keep around for 2 major releases just because of deprecations is precisely what we wanted to avoid.",False,0,MEMBER
https://api.github.com/repos/doctrine/DoctrineBundle/issues/comments/1506559004,Error in XML mapping (gedmo) afer upgrade to 2.9,jakubtobiasz,20,1665316056,10,1506559004,0,1506492462,2023-04-13T08:27:11Z,"@ostrolucky I understand your move from a maintainer perspective, but from a user perspective it's a troublemaker. In should be introduced with a switch or postponed until the next major release IMO. For now, it'd be great to have an option to disable it.",False,0,NONE
https://api.github.com/repos/doctrine/DoctrineBundle/issues/comments/1506601849,Error in XML mapping (gedmo) afer upgrade to 2.9,stof,20,1665316056,11,1506601849,0,1506559004,2023-04-13T08:58:35Z,"DoctrineBundle should not force users to enable the XSD validation if they are not compatible with it yet. Otherwise, it effectively turns the ORM deprecation into a BC break.

The fact that the doctrine extensions need to change the way to configure their mapping is reported at https://github.com/doctrine-extensions/DoctrineExtensions/issues/2318 already, but there is not yet an alternative.",False,0,MEMBER
https://api.github.com/repos/doctrine/DoctrineBundle/issues/comments/1506663356,Error in XML mapping (gedmo) afer upgrade to 2.9,ostrolucky,20,1665316056,12,1506663356,0,1506601849,2023-04-13T09:40:37Z,"You wouldn't complain if symfony validation constraint validator is extended to cover some edge case, would you? BC break is matter of opinion. Every bug fix is a BC break for people relying on that bug and invalid schema looks like a bug to me, we just opted to stop supporting that to make people fix those. Link above where it was reported already in 2021 that gedmo is relying on invalid schema and nothing was done about it is a proof it won't be fixed until it's necessary. Anyways if someone works on such option in bundle I will merge it, but wouldn't it be easier to fix gedmo?",False,0,MEMBER
https://api.github.com/repos/doctrine/DoctrineBundle/issues/comments/1506676345,Error in XML mapping (gedmo) afer upgrade to 2.9,stof,20,1665316056,13,1506676345,0,1506663356,2023-04-13T09:50:20Z,"@ostrolucky the ORM introduces this change as a opt-in precisely because it is known that this change has a BC impact. the way the bundle handled it is to force the new behavior in a minor version of the bundle, effectively ignoring the decision of the ORM maintainers to make it opt-in for BC reasons. gedmo being a widely used package impacted by the ORM change was a known thing, which is why it was opt-in. And before ORM 2.10, the ORM XSD was explicitly allowing to have nodes from different namespaces in those places, so the gedmo decision (done at the time of ORM 2.0) cannot be considered a bug in gedmo (they rely on a feature that has been deprecated 10 years after they started using it).

And even if Gedmo is fixed, this won't magically solve things: projects will need to migrate to the new way of configuring gedmo _before_ enabling the ORM validation (and AFAIK, nobody is working yet on implementing such new configuration format in gedmo).",False,0,MEMBER
https://api.github.com/repos/doctrine/DoctrineBundle/issues/comments/1506778490,Error in XML mapping (gedmo) afer upgrade to 2.9,ostrolucky,20,1665316056,14,1506778490,0,1506676345,2023-04-13T11:10:21Z,"There are several options:
- Gedmo can define standalone xml schema. That's easier than having to change to new way of configuring gedmo.
- ORM enables strict validation by default, but in 2.x turns schema errors into deprecation only. Then we can stop enabling it in bundle and have green deprecation CI build at the same time
- Related code is moved to doctrine-bridge like we were asking in https://github.com/doctrine/DoctrineBundle/pull/1634/files#r1135594578, this way deprecation will not be direct for bundle, also achieving green build
- We ignore this particular deprecation via baseline. But then users will not have an option to deal with the deprecation.
- Setting for bundle which flips between these two is added. Least favorite option for me because not only we have to count with more possible combinations of execution paths or having to have some option that we already know we will have to remove, but also setting will stop working in ORM 3, then we will have yet more options around that don't do anything.",False,0,MEMBER
https://api.github.com/repos/doctrine/DoctrineBundle/issues/comments/1506875023,Error in XML mapping (gedmo) afer upgrade to 2.9,stof,20,1665316056,15,1506875023,0,1506778490,2023-04-13T12:25:07Z,"@ostrolucky Defining a standalone XML schema in gedmo implies that the gedmo config should be in a separate XML file than the ORM mapping. That's precisely what requires changing the way gedmo is configured. And this will take time and will require projects using gedmo to migrate to the new configuration system using separate files.

Moving the code to the bridge will **not** solve the fact that without exposing a configuration setting, you still force users to use the new ORM behavior which is a BC break.

> * Least favorite option for me because not only we have to count with more possible combinations of execution paths or having to have some option that we already know we will have to remove, but also setting will stop working in ORM 3, then we will have yet more options around that don't do anything.

Well, this is a way that is regularly used in Symfony's core bundles when we need _projects_ to opt in for a new behavior.
We introduce the new setting (which is a then passed directly to the driver constructor so there is no combinations to take into account) and we deprecate setting it to `false` (or not setting it as the default would be `false`). Then, in the next major version of the bundle, we remove that setting (and if DoctrineBundle 2.x adds support for ORM 3.0, it can trigger an exception instead of reporting a deprecation for `false` values when ORM 3.0 is used).

> * ORM enables strict validation by default, but in 2.x turns schema errors into deprecation only. Then we can stop enabling it in bundle and have green deprecation CI build at the same time

This option could work, but I'm not sure how feasible it is for the ORM. That's an interesting idea as it would report deprecations only for projects that have an invalid XML configuration according to the new XSD.",False,0,MEMBER
https://api.github.com/repos/doctrine/DoctrineBundle/issues/comments/1506914128,Error in XML mapping (gedmo) afer upgrade to 2.9,ostrolucky,20,1665316056,16,1506914128,0,1506875023,2023-04-13T12:52:38Z,"> Well, this is a way that is regularly used in Symfony's core bundles when we need projects to opt in for a new behavior.
We introduce the new setting (which is a then passed directly to the driver constructor so there is no combinations to take into account) and we deprecate setting it to false (or not setting it as the default would be false). Then, in the next major version of the bundle, we remove that setting (and if DoctrineBundle 2.x adds support for ORM 3.0, it can trigger an exception instead of reporting a deprecation for false values when ORM 3.0 is used)

I don't think Symfony ends up being in situation where you have config options related to external libraries that don't do anything anymore (because those options don't exist in newer versions of those libraries but both versions still need to be supported). Anyways I'm well aware of how Symfony does it, doctrine-bundle is not required to follow same policies though. But like I said, if someone creates MR for this, it's fair enough.",False,0,MEMBER
https://api.github.com/repos/doctrine/DoctrineBundle/issues/comments/1507063086,Error in XML mapping (gedmo) afer upgrade to 2.9,eisberg,20,1665316056,17,1507063086,0,1506914128,2023-04-13T14:23:36Z,"I propose a solution:

1. In  Doctrine\ORM\Mapping\Driver\XmlDriver:

```
// Doctrine\ORM\Mapping\Driver\XmlDriver:


private function validateMapping(string $file): void
    {
        if (!$this->isXsdValidationEnabled) {
            return;
        }

        $backedUpErrorSetting = libxml_use_internal_errors(true);

        try {
            $document = new DOMDocument();
            $document->load($file);
            // if (! $document->schemaValidate(__DIR__ . '/../../../../../doctrine-mapping.xsd')) {
            //     throw MappingException::fromLibXmlErrors(libxml_get_errors());
            // }

            $this->validateDocument($document); // <<<  instead of the code above
        } finally {
            libxml_clear_errors();
            libxml_use_internal_errors($backedUpErrorSetting);
        }
    }

    private function validateDocument(DOMDocument $document): void
    {
        $allSchemas = $this->extractAllSchemas($document);
        $allSchemas['http://doctrine-project.org/schemas/orm/doctrine-mapping'] = __DIR__ . '/../../../../../doctrine-mapping.xsd';

        // Create a combined schema
        $imports = [];
        foreach ($allSchemas as $namespace => $location) {
            $imports[] = sprintf('<xsd:import namespace=""%s"" schemaLocation=""%s"" />', $namespace, $location);
        }

        $combinedSchema = '
            <xsd:schema
                xmlns:xsd=""http://www.w3.org/2001/XMLSchema""
                elementFormDefault=""qualified"">
                <xsd:import namespace=""http://www.w3.org/XML/1998/namespace"" />
                ' . implode(PHP_EOL, $imports) . '
            </xsd:schema>
        ';

        $this->safeSchemaValidateSource($document, $combinedSchema);
    }

    private function safeSchemaValidateSource(DOMDocument $document, string $schema): void
    {
        $initialErrorsFlag = libxml_use_internal_errors(true);
        if (!$document->schemaValidateSource($schema)) {
            throw MappingException::fromLibXmlErrors(libxml_get_errors());
        }

        libxml_clear_errors();

        // Return the use internal errors to what it was.
        libxml_use_internal_errors($initialErrorsFlag);
    }
protected  function extractAllSchemas(\DOMDocument $document): array
    {
        $xpath = new \DOMXPath($document);
        $schemaLocations = $xpath->query('//*[@xsi:schemaLocation]');


        // ""namespace1 location1 namespace2 location2""
        $locationRegex = '/'
            . '(?P<namespace>[^\s]+)'
            . '\s+'
            . '(?P<location>[^\s]+)'
            . '/';

        $allSchemas = [];
        foreach ($schemaLocations as $element) {
            $schemaLocation = $element->getAttribute('xsi:schemaLocation');
            if (preg_match_all($locationRegex, $schemaLocation, $matches)) {
                $schemas = array_combine($matches['namespace'], $matches['location']);
                $allSchemas = array_merge($allSchemas, $schemas);
            } else {
                throw new Exception(
                    'Unable to parse the value of schemaLocation. Expected ""namespace1 xsd1 namespace2 xsd2"" '
                    . 'but found ""' . $schemaLocation . '""'
                );
            }
        }

        return array_unique($allSchemas);
    }
```

2. In ORM XML (for example):
```
<?xml version=""1.0"" encoding=""utf-8""?>
<doctrine-mapping xmlns=""http://doctrine-project.org/schemas/orm/doctrine-mapping""
                  xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
                  xsi:schemaLocation=""http://doctrine-project.org/schemas/orm/doctrine-mapping
                    https://www.doctrine-project.org/schemas/orm/doctrine-mapping.xsd
                    http://gediminasm.org/schemas/orm/doctrine-extensions-mapping
                    http://gediminasm.org/schemas/orm/doctrine-extensions-mapping""
                  xmlns:gedmo=""http://gediminasm.org/schemas/orm/doctrine-extensions-mapping"">
    <entity
```

A solution similar to what Symfony does in `Symfony\Component\DependencyInjection\Loader\XmlFileLoader`


",False,0,NONE
https://api.github.com/repos/doctrine/DoctrineBundle/issues/comments/1507079148,Error in XML mapping (gedmo) afer upgrade to 2.9,stof,20,1665316056,18,1507079148,0,1507063086,2023-04-13T14:33:44Z,"@eisberg that's not a solution, given that the goal of ORM maintainers is to *stop* allowing to add external nodes in XML mapping files (otherwise, they would not have removed support for using external nodes in the ORM XSD.

What we need here is a proper deprecation path, not a new feature that does the opposite of that deprecation.",False,0,MEMBER
https://api.github.com/repos/doctrine/DoctrineBundle/issues/comments/1507088837,Error in XML mapping (gedmo) afer upgrade to 2.9,greg0ire,20,1665316056,19,1507088837,0,1507079148,2023-04-13T14:39:24Z,"I'll reiterate what I think is the best course of action:
1. release a patch disabling validation;
2. release a minor allowing to enable it, and deprecating not doing so;
3. make the knob a no-op in next major;
4. remove the knob in next next major.

Having many unused nodes is a big deal because we don't do major releases often. That's what should IMO change.",False,0,MEMBER
https://api.github.com/repos/doctrine/DoctrineBundle/issues/comments/1507380582,Error in XML mapping (gedmo) afer upgrade to 2.9,greg0ire,20,1665316056,20,1507380582,0,1507088837,2023-04-13T17:49:28Z,"By the way, I just realized that the best value for this validation setting is probably `%kernel.debug%`, which means it should stay available forever, thus removing one of the things that makes you uncomfortable @ostrolucky (having a no-op setting): we don't need to check this in production, do we?

So new plan:


1. release a patch disabling validation;
2. tweak the ORM to trigger a deprecation when the setting is not configured explicitely as opposed to set to `true` (or removing the deprecation entirely, I don't know);
3. release a minor allowing to enable it, and deprecating not setting it to `%kernel.debug%`.
",False,0,MEMBER
https://api.github.com/repos/doctrine/DoctrineBundle/issues/comments/1507396980,Error in XML mapping (gedmo) afer upgrade to 2.9,dmaicher,20,1665316056,21,1507396980,0,1507380582,2023-04-13T18:00:28Z,"I propose to revert it with a patch release first: https://github.com/doctrine/DoctrineBundle/pull/1644

Then we can think about how to tackle it properly",False,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/11136,PHP 8.2.5 shows wrong day in date,juedan,10,1684867028,1,1684867028,0,0,2023-04-26T11:46:49Z,"### Description

Dear developers,

for testing my code on several PHP platforms I have installed three versions of it.
Today I found a very interesting and weird thing.

The following code shows surprisingly different results on the **day of the date**.

```
date_default_timezone_set('Europe/Berlin');
locale_set_default('de-DE');
$heute = new DateTime('now');
var_dump($heute):
```
PHP Version 8.2.5:
```
object(DateTime)#17 (3) {
  [""date""] => string(26) ""2023-04-24 13:09:00.792457""
  [""timezone_type""] => int(3)
  [""timezone""] => string(13) ""Europe/Berlin""
}
```

PHP Version 8.1.18:
```
object(DateTime)#17 (3) {
  [""date""] => string(26) ""2023-04-26 13:18:45.175232""
  [""timezone_type""] => int(3)
  [""timezone""] => string(13) ""Europe/Berlin""
}
```

PHP Version 7.4.33:
```
object(DateTime)#17 (3) {
  [""date""] => string(26) ""2023-04-26 13:17:51.332491""
  [""timezone_type""] => int(3)
  [""timezone""] => string(13) ""Europe/Berlin""
}
```

I'm running these PHP versions on an Debian 5.10.162-1 (2023-01-21) x86_64 with 
Build Date  Apr 14 2023 04:39:46.

Best regards and many thanks for your answers in advance.

### PHP Version

PHP 8.2.5

### Operating System

Debian 5.10.162-1",True,0,NONE
https://api.github.com/repos/php/php-src/issues/comments/1523404882,PHP 8.2.5 shows wrong day in date,iluuu1994,10,1684867028,2,1523404882,0,1684867028,2023-04-26T13:15:58Z,"I can't reproduce this. Is your environment for the compiled PHP versions otherwise the same? E.g. icu version? (I'm not sure how exactly `ext-date` interacts with icu, if at all).",False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1525125566,PHP 8.2.5 shows wrong day in date,juedan,10,1684867028,3,1525125566,0,1523404882,2023-04-27T08:35:10Z,"Hello,
thanks for your reply.
On my one and only system I have 3 versions of PHP installed for testing purposes.
Here ist some output:
```
php7.4 -r""echo phpinfo();"" | grep -i 'icu'
ICU version => 67.1
ICU Data version => 67.1
ICU TZData version => 2019c
ICU Unicode version => 13.0

php8.1 -r""echo phpinfo();"" | grep -i 'icu'
ICU version => 67.1
ICU Data version => 67.1
ICU Unicode version => 13.0

php8.2 -r""echo phpinfo();"" | grep -i 'icu'
ICU version => 67.1
ICU Data version => 67.1
ICU Unicode version => 13.0

```
Best regards and thanks",False,0,NONE
https://api.github.com/repos/php/php-src/issues/comments/1525213712,PHP 8.2.5 shows wrong day in date,iluuu1994,10,1684867028,4,1525213712,0,1525125566,2023-04-27T09:10:41Z,@derickr Any clue how this could happen?,False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1528614539,PHP 8.2.5 shows wrong day in date,andypost,10,1684867028,5,1528614539,0,1525213712,2023-04-29T03:40:33Z,with new ICU 73.1 also one test fails https://github.com/php/php-src/issues/11128,False,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/comments/1528682178,PHP 8.2.5 shows wrong day in date,juedan,10,1684867028,6,1528682178,0,1528614539,2023-04-29T06:20:19Z,"Hello,
in this context I remember that this effect came up after an update of the libtimezonemap. Usually an restart is suggested but this time nothing. After restarting  the machine DateTime in PHP8.2.5 delivers the correct date.
But I think there is a bug in PHP 8.2.5 because older versions did not show the effect.",False,0,NONE
https://api.github.com/repos/php/php-src/issues/comments/1545774617,PHP 8.2.5 shows wrong day in date,heiglandreas,10,1684867028,7,1545774617,0,1528682178,2023-05-12T13:44:31Z,@iluuu1994 `ext-date` does not interact with ICU at all.,False,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/comments/1545779940,PHP 8.2.5 shows wrong day in date,heiglandreas,10,1684867028,8,1545779940,0,1545774617,2023-05-12T13:48:36Z,"Either 3v4l.org has the same issue as reported or there is indeed something borked:

```php
<?php

date_default_timezone_set('Europe/Berlin');
locale_set_default('de-DE');
$heute = new DateTime('now');
var_dump($heute);
```

[this script](https://3v4l.org/vlIdL) showed (amongst others) this output:

![image](https://github.com/php/php-src/assets/91998/92d568f0-4787-45c7-afd5-30e0b5e5cae9)

Note the change between 8.1.6 and 8.1.7 from 12. of may to 29th of april...",False,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/comments/1545797124,PHP 8.2.5 shows wrong day in date,iluuu1994,10,1684867028,9,1545797124,0,1545779940,2023-05-12T14:01:02Z,@heiglandreas AFAIK 3v4l.org caches the output of scripts. That's why something like `var_dump(new \DateTime());` will show old dates. If you change the variable name the date looks ok across the board. https://3v4l.org/efHKd,False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1545808440,PHP 8.2.5 shows wrong day in date,heiglandreas,10,1684867028,10,1545808440,0,1545797124,2023-05-12T14:08:36Z,Thanks. I already feared that. Then ignore my comment :see_no_evil: ,False,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/comments/1822942129,PHP 8.2.5 shows wrong day in date,derickr,10,1684867028,11,1822942129,0,1545808440,2023-11-22T15:05:05Z,"No idea how this can happen. I have not heard anybody else about it either, and neither can I reproduce this.",False,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/11137,feat: add function num_cpus (formerly nproc),kesselb,13,1685604702,1,1685604702,0,0,2023-04-26T19:39:00Z,"Returns the number of processors which are currently online.

The idea, to add a feature similar to nproc, comes from https://github.com/nextcloud/server/issues/37921. 

We use the number of processors to limit the parallel generation of thumbnails. Unfortunately, we forgot to implement a check if access to /proc/cpuinfo is allowed and /proc is not available for FreeBSD. 

Our use case is probably not the best, but it is complicated to get the number of processors without shell_exec. 

`nproc` is likely not a good name. The actual nproc implementation covers much more corner cases[^1]. 

I was curious if I could add such a functionality with my limited c knowledge :see_no_evil: 
If you like the idea and there is a chance, this patch could be accepted, I'm happy to spend more time on it.

[^1]: https://github.com/coreutils/gnulib/blob/master/lib/nproc.c

",True,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/comments/1523955602,feat: add function num_cpus (formerly nproc),devnexen,13,1685604702,2,1523955602,0,1685604702,2023-04-26T19:47:38Z,Do you have an use case in mind ?,False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1530071147,feat: add function num_cpus (formerly nproc),kesselb,13,1685604702,3,1530071147,0,1523955602,2023-05-01T18:53:47Z,"> Do you have an use case in mind ?

Thank you @devnexen :+1:
I updated the pull request description.",False,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/comments/1530421109,feat: add function num_cpus (formerly nproc),devnexen,13,1685604702,4,1530421109,0,1530071147,2023-05-01T22:14:47Z,"I see. I m not against personally, I ll leave the decision to Mate on this one.",False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1556207410,feat: add function num_cpus (formerly nproc),kesselb,13,1685604702,5,1556207410,0,1530421109,2023-05-21T15:28:11Z,Renamed the function to `cpu_cores` to avoid confusion with the nproc (because nproc is more advancend). ,False,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/comments/1564624383,feat: add function num_cpus (formerly nproc),kesselb,13,1685604702,6,1564624383,0,1556207410,2023-05-26T16:15:37Z,Renamed the function to `num_cpus` so it's easier to guess that we just return a number.,False,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/comments/1564682224,feat: add function num_cpus (formerly nproc),kocsismate,13,1685604702,7,1564682224,0,1564624383,2023-05-26T17:06:39Z,"My personal opinion: I would love to see convenient OO APIs like what ext/random has instead of creating functions scattered here and there. The way I can imagine this is adding a `ReflectionServer` (or something similar) class into ext/reflection. How does it sound to you?
",False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1564684857,feat: add function num_cpus (formerly nproc),iluuu1994,13,1685604702,8,1564684857,0,1564682224,2023-05-26T17:09:03Z,"@kocsismate Unless there's some common configuration/parameter these functions would share, I don't see the point in hiding this function behind an object. A namespace is a different story, but I'm not ready for the bike-shedding :stuck_out_tongue_winking_eye: ",False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1564699850,feat: add function num_cpus (formerly nproc),kocsismate,13,1685604702,9,1564699850,0,1564684857,2023-05-26T17:22:50Z,"@iluuu1994 I don't see it as ""hiding"", but grouping them together, so that the complete list of available functions for ""server reflection"" could be seen at once when someone starts to write `(new ReflectionServer())->`.",False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1564740324,feat: add function num_cpus (formerly nproc),iluuu1994,13,1685604702,10,1564740324,0,1564699850,2023-05-26T18:03:39Z,"@kocsismate Grouping is what namespaces are for. :slightly_smiling_face: `(new \ReflectionServer())->numCores()` is less readable than `\Cpu\num_cores()` (or whatever namespace) and requires an unnecessary allocation. `ReflectionServer::numCores()` would be slightly better, but I still don't see why this should be associated with a class. Autocomplete works fine for namespaces.",False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1609185109,feat: add function num_cpus (formerly nproc),bukka,13,1685604702,11,1609185109,0,1564740324,2023-06-27T10:00:32Z,In terms of naming I agree that just single function is fine here (we don't really need OO API for this IMHO). The name `num_cpus` seems also fine to me.,False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1609321703,feat: add function num_cpus (formerly nproc),kesselb,13,1685604702,12,1609321703,0,1609185109,2023-06-27T11:33:57Z,"Hey :wave: 

Addressed the code review suggestions, had a brief look at Solaris/OpenBSD compatibility and rebased.",False,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/comments/1609396650,feat: add function num_cpus (formerly nproc),bukka,13,1685604702,13,1609396650,0,1609321703,2023-06-27T12:23:18Z,"@kocsismate Are you still have an objection against the naming? Just checking if we need an RFC for this basically?

@kesselb If there are no objections from @kocsismate, then it would be good to drop email to internals to see if there any objections in the next two weeks. If not, we could still get it to 8.3, otherwise the RFC would be required which would mean waiting for 8.4 due to discussion and voting period being both 2 weeks and feature freeze on July 18th.",False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1611022524,feat: add function num_cpus (formerly nproc),kocsismate,13,1685604702,14,1611022524,0,1609396650,2023-06-28T08:52:36Z,"> Are you still have an objection against the naming? Just checking if we need an RFC for this basically?

To be honest, I'd be much happier if there was some structuring of the functionality which we add. I agree that the bike shedding can be extremely frustrating, but at least sometimes it improve things.

Unfortunately, I'm still pretty much obsessed with my ReflectionServer idea, probably because I like the OO API of PHP much more than the procedural one: I always refer to ext/random as the best example for adding a new API.

So the very least, it would make sense to think about the possible extensions of num_cpus? What kind of further info do we plan to provide about the environment in the future? If we want to stop here then ok, let's add a simple function no matter in which namespace. If we plan to add further related functionality then let's go for either a class (possibly with static methods) or with a separate namespace so that the choice is in line with our long term plans.

As far as I noticed, PHP is evolving towards more and more object oriented APIs (ext/random, resource to object migrations, stop adding dual APIs with the preference of OO), so I think this topic is worth having a discussion at least internally.",False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/11139,BUG: PHP-Embed: php_embed_module.php_ini_path_override not properly processed. ,ronpinkas,6,1686001128,1,1686001128,0,0,2023-04-27T02:49:35Z,"### Description

The following self contained, reduced, code:

```
#include <stdio.h>
#include <sapi/embed/php_embed.h>

void cb_php( int argc, char **argv, const char *eval_string, const char *cPathINI ){
   char sIniPath[ 1024 ];

   if( cPathINI && strlen(cPathINI) > 0 ){   
		strcpy( sIniPath, cPathINI );
      php_embed_module.php_ini_path_override = sIniPath;
      printf( ""INI: %s\n"", php_embed_module.php_ini_path_override );
   }
   else{
		php_embed_module.php_ini_path_override = NULL;
   }

   PHP_EMBED_START_BLOCK(argc, argv);

   zend_eval_string((char *)eval_string, NULL, ""embed_script"");

   PHP_EMBED_END_BLOCK();
}

void CreateFile( char *FileName, char *Content ){
   FILE *file = fopen( FileName, ""w"" );
   if (file == NULL){
       printf(""Error: Unable to create '%s' file!\n"", FileName );
       exit( 1 );
   }
   fprintf( file, ""%s"", Content );
   fclose( file );
}

int main(int argc, char *argv[]){   
   #define IniName     ""myphp.ini""
   #define ScriptName  ""check_settings.php""
   char *sPHP = ""<?php\n""
               ""// Check relevant PHP settings\n""
               ""$settings = [\n""
               ""    'max_input_time',\n""
               ""    'obscure_setting'\n"" // Add the obscure setting here
               ""];\n""
               ""echo \""PHP Settings:\\n\"";\n""
               ""foreach ($settings as $setting) {\n""
               ""    echo $setting . ': ' . ini_get($setting) . \""\\n\"";\n""
               ""}\n""
               ""echo 'Loaded Configuration File: ' . php_ini_loaded_file() . \""\\n\"";\n""
               ""?>\n"";
  
   CreateFile( IniName, ""max_input_time = 30\nobscure_setting = 12345\n"" );
   CreateFile( ScriptName, sPHP );

   cb_php( argc, argv, ""require( \""./"" ScriptName ""\"" );"", ""./""IniName );

   return 0;
}

```

Resulted in this output:
```
INI: ./myphp.ini
PHP Settings:
max_input_time: -1
obscure_setting: 
Loaded Configuration File: /home/omie/dsv/omie-corevm/phpemb/myphp.ini
```

But I expected this output instead:
```
INI: ./myphp.ini
PHP Settings:
max_input_time: 30
obscure_setting: 12345
Loaded Configuration File: /home/omie/dsv/omie-corevm/phpemb/myphp.ini
```


### PHP Version

PHP 8.1.16

### Operating System

Amazon Linux 2",True,0,NONE
https://api.github.com/repos/php/php-src/issues/comments/1524946462,BUG: PHP-Embed: php_embed_module.php_ini_path_override not properly processed. ,KapitanOczywisty,6,1686001128,2,1524946462,0,1686001128,2023-04-27T07:17:18Z,"`max_input_time` could be overridden by hardcoded `.ini_entries`:
https://github.com/php/php-src/blob/7b4b40f06f39f1dc05fc4be8531fa3d582062488/sapi/embed/php_embed.c#L26-L32
https://github.com/php/php-src/blob/7b4b40f06f39f1dc05fc4be8531fa3d582062488/sapi/embed/php_embed.c#L202-L217

As for `obscure_setting` it might be discarded because it's unknown, can you test different settings?",False,0,NONE
https://api.github.com/repos/php/php-src/issues/comments/1525717089,BUG: PHP-Embed: php_embed_module.php_ini_path_override not properly processed. ,ronpinkas,6,1686001128,3,1525717089,0,1524946462,2023-04-27T13:40:54Z,"I have tried additional settings, like odbc.defaultlrl and it also appear to have been silently ignored. Oddly there are other settings that are being respected.

As to the hardcoded note - I have seen this code but could not find documentation suggesting that any ini settings could not be set by means of a php.ini file - is that intentional, I mean overriding a provided ini file setting such as max_input_time with a value that counter the documented recommended values?

> On Apr 27, 2023, at 2:17 AM, KapitanOczywisty ***@***.***> wrote:
> 
> 
> max_input_time could be overridden by hardcoded .ini_entries:
> https://github.com/php/php-src/blob/7b4b40f06f39f1dc05fc4be8531fa3d582062488/sapi/embed/php_embed.c#L202-L217
> 
> As for obscure_setting it might be discarded because it's unknown, can you test different settings?
> 
> —
> Reply to this email directly, view it on GitHub <https://github.com/php/php-src/issues/11139#issuecomment-1524946462>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/ADYCEI5BGTKLBPFKA2YNIJ3XDIMQVANCNFSM6AAAAAAXNHMLHA>.
> You are receiving this because you authored the thread.
> 

",False,0,NONE
https://api.github.com/repos/php/php-src/issues/comments/1525791810,BUG: PHP-Embed: php_embed_module.php_ini_path_override not properly processed. ,KapitanOczywisty,6,1686001128,4,1525791810,0,1525717089,2023-04-27T14:24:01Z,"> I have tried additional settings, like odbc.defaultlrl and it also appear to have been silently ignored.

Is extension successfully compiled and loaded (settings shows up in `phpinfo`)?

> As to the hardcoded note - I have seen this code but could not find documentation suggesting that any ini settings could not be set by means of a php.ini file - is that intentional

Documentation for embed is rather poor, I tend to [grep](https://grep.app/search?q=.ini_entries&filter[repo][0]=php/php-src) php source to find how something works. And as I understand, `php_embed.c` is more like `hello world`, and is there to help you start, but you can (and probably should) rewrite it to fit your needs. Everything what `php_embed.c` is doing you can do in your code directly.",False,0,NONE
https://api.github.com/repos/php/php-src/issues/comments/1526022874,BUG: PHP-Embed: php_embed_module.php_ini_path_override not properly processed. ,ronpinkas,6,1686001128,5,1526022874,0,1525791810,2023-04-27T16:47:42Z,"Thanks for the great hint :) <rf>
Namaste.

> On Apr 27, 2023, at 9:24 AM, KapitanOczywisty ***@***.***> wrote:
> 
> 
> I have tried additional settings, like odbc.defaultlrl and it also appear to have been silently ignored.
> 
> Is extension successfully compiled and loaded (settings shows up in phpinfo)?
> 
> As to the hardcoded note - I have seen this code but could not find documentation suggesting that any ini settings could not be set by means of a php.ini file - is that intentional
> 
> Documentation for embed is rather poor, I tend to grep <https://grep.app/search?q=.ini_entries&filter%5Brepo%5D%5B0%5D=php/php-src> php source to find how something works. And as I understand, php_embed.c is more like hello world, and is there to help you start, but you can (and probably should) rewrite it to fit your needs. Everything what php_embed.c is doing you can do in your code directly.
> 
> —
> Reply to this email directly, view it on GitHub <https://github.com/php/php-src/issues/11139#issuecomment-1525791810>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/ADYCEI4AKQT5UAYIK3TM2ILXDJ6Q3ANCNFSM6AAAAAAXNHMLHA>.
> You are receiving this because you authored the thread.
> 

",False,0,NONE
https://api.github.com/repos/php/php-src/issues/comments/1526052860,BUG: PHP-Embed: php_embed_module.php_ini_path_override not properly processed. ,ronpinkas,6,1686001128,6,1526052860,0,1526022874,2023-04-27T17:12:34Z,"Based on input from KapitanOczywisty and further investigation, it appears that the issue isn't a bug, but rather an intended behavior. This is due to the invalidity of certain settings in a given context, such as:

    - unknown setting
    - setting belonging to an extension which is not loaded
    - belonging to a special class of settings overridden  by 'php_embed_init()' as per php-src/sapi/embed/php_embed.c:

> const char HARDCODED_INI[] =
> 	""html_errors=0\n""
> 	""register_argc_argv=1\n""
> 	""implicit_flush=1\n""
> 	""output_buffering=0\n""
> 	""max_execution_time=0\n""
> 	""max_input_time=-1\n\0"";

Please forgive my premature bug report .",False,0,NONE
https://api.github.com/repos/php/php-src/issues/comments/1526077221,BUG: PHP-Embed: php_embed_module.php_ini_path_override not properly processed. ,KapitanOczywisty,6,1686001128,7,1526077221,0,1526052860,2023-04-27T17:33:26Z,"@ronpinkas Also take a note how ini files are handled:
https://github.com/php/php-src/blob/945db3cd616cb0ff2d3680529e480306c8dd9c17/Zend/zend_ini_scanner.l#L73-L91
Ini files are parsed first then settings are actually registered and custom values retrieved/validated. To not emit warnings for settings from disabled modules there is also no check for non-existent keys.

> Please forgive my premature bug report .

No worry, this might help someone down the road",False,0,NONE
https://api.github.com/repos/php/doc-en/issues/2450,Document ArgumentCountError for internal functions,enumag,11,1686462036,1,1686462036,0,0,2023-04-27T07:50:41Z,"### Description

The following code doesn't report any issue because PHP generally doesn't care about extra arguments being passed to a method:

```php
class Y {
    public static function from(string $value): self
    {
        return new self();
    }
}

Y::from('name', 1);
```

However the following code:

```php
enum X: string {
    case NAME = 'name';
}

X::from('name', 1);
```

causes a fatal error:

```
Fatal error: Uncaught ArgumentCountError: X::from() expects exactly 1 argument, 2 given in /in/aKdjL:7
Stack trace:
#0 /in/aKdjL(7): X::from('name', 1)
php/php-src#1 {main}
  thrown in /in/aKdjL on line 7

Process exited with code 255.
```

This is a really nasty behavior, especially because it is neither documented nor detectable with reflection: https://3v4l.org/6XPsW#v8.2.5

It matters especially when using such function as a first-class-callable. I stumbled upon it with this code: https://3v4l.org/YWSEo#v8.2.5

The worst thing about this is that due to this behavior being undocumented and undetectable there is no way for tools like PHPStan to report such problem either.

I don't even know if `BackedEnum::from()` is the only such function or if there are any others.


### PHP Version

8.2.5

### Operating System

any",True,0,NONE
https://api.github.com/repos/php/doc-en/issues/comments/1525238833,Document ArgumentCountError for internal functions,damianwadley,11,1686462036,2,1525238833,0,1686462036,2023-04-27T08:19:26Z,"> I don't even know if `BackedEnum::from()` is the only such function or if there are any others.

I'm going to assume you didn't even try to look. https://3v4l.org/H0bmY

PHP doesn't check arguments on userland functions because passing ""extra"" arguments is completely supported.
https://www.php.net/manual/en/function.func-get-args.php

There isn't much of a use case for it nowadays since the advent of variable-length argument lists, but it's still a valid feature. If you don't want your code to make use it of then you can do what PHP does: throw an `ArgumentCountError` if the number of arguments passed is incorrect.",False,0,MEMBER
https://api.github.com/repos/php/doc-en/issues/comments/1525238844,Document ArgumentCountError for internal functions,enumag,11,1686462036,3,1525238844,0,1525238833,2023-04-27T08:27:15Z,"> I'm going to assume you didn't even try to look. [3v4l.org/H0bmY](https://3v4l.org/H0bmY)

I didn't because I have no clue how to search for them. How did you find these?

My main concern is that PHPStan should be able to detect such bug. How can we tell that a function / method doesn't accept extra arguments? Or is it simply all functions passing the following condition?

```
ReflectionFunctionAbstract::isInternal() === true && ReflectionFunctionAbstract::isVariadic() === false
```
",False,0,NONE
https://api.github.com/repos/php/doc-en/issues/comments/1525238859,Document ArgumentCountError for internal functions,MorganLOCode,11,1686462036,4,1525238859,0,1525238844,2023-04-27T08:29:23Z,"> I don't even know if `BackedEnum::from()` is the only such function or if there are any others.

`strlen` is an example.
```php
echo strlen(""five"", ""extra"");
```

which triggers warnings as far back as [3v4l](https://3v4l.org/rJgQI) goes. In 8.0 it changed to an ArgumentCountError, without any mention on the corresponding [Backward incompatible changes](https://www.php.net/manual/en/migration80.incompatible.php) page. It ought to be in this list:
>  A number of warnings have been converted into Error exceptions:
> *    Attempting to write to a property of a non-object. Previously this implicitly created an stdClass object for null, false and empty strings.
> *    Attempting to append an element to an array for which the PHP_INT_MAX key is already used.
> *    Attempting to use an invalid type (array or object) as an array key or string offset.
> *    Attempting to write to an array index of a scalar value.
> *    Attempting to unpack a non-array/Traversable.
> *    Attempting to access unqualified constants which are undefined. Previously, unqualified constant accesses resulted in a warning and were interpreted as strings.
",False,0,CONTRIBUTOR
https://api.github.com/repos/php/doc-en/issues/comments/1525238871,Document ArgumentCountError for internal functions,enumag,11,1686462036,5,1525238871,0,1525238859,2023-04-27T08:31:08Z,"> `strlen` is an example.

Thanks but sadly examples aren't very helpful. I need to know how to tell apart the functions with this behavior from the rest so that PHPStan can detect and report such issue.",False,0,NONE
https://api.github.com/repos/php/doc-en/issues/comments/1525238884,Document ArgumentCountError for internal functions,MorganLOCode,11,1686462036,6,1525238884,0,1525238871,2023-04-27T08:41:52Z,"> > `strlen` is an example.
> 
> Thanks but I don't care about examples. I need to know how to tell apart the functions with this behavior from the rest so that PHPStan can detect and report such issue.

At this point I'm guessing by examining the manual and looking at the declared signatures, to see how many (optional) arguments they take and whether they include `...` variadics.

Incidentally, the description of `ArgumentCountError` doesn't mention that it's thrown on _maximum_ argument counts on _inbuilt_ functions, only _minimum_ counts on _user-defined_ functions.",False,0,CONTRIBUTOR
https://api.github.com/repos/php/doc-en/issues/comments/1525238898,Document ArgumentCountError for internal functions,enumag,11,1686462036,7,1525238898,0,1525238884,2023-04-27T08:43:36Z,"Are we even sure that all non-variadic internal functions and methods have this behavior? :thinking: 

And what about functions that are defined neither in core nor in user-land code but in a pecl extension? :thinking: 

Also are there any plans to enforce the same behavior for user-land functions in a future version? For instance along with deprecating `func_get_args()` in favor of variadic parameters?",False,0,NONE
https://api.github.com/repos/php/doc-en/issues/comments/1525238921,Document ArgumentCountError for internal functions,iluuu1994,11,1686462036,8,1525238921,0,1525238898,2023-04-27T09:08:38Z,"> Are we even sure that all non-variadic internal functions and methods have this behavior? thinking

If they use `ZEND_PARSE_PARAMETERS_START` or `zend_parse_parameters` then yes.

> And what about functions that are defined neither in core nor in user-land code but in a pecl extension? thinking

If they use  `ZEND_PARSE_PARAMETERS_START` or `zend_parse_parameters`, then they'll behave the same way.

> Also are there any plans to enforce the same behavior for user-land functions in a future version?

I don't think there is one. Extra arguments for PHP are heavily used. We *could* remove this restriction from internal functions, but passing extra arguments will generally be a mistake, so it seems better for PHP to tell you about it.",False,0,MEMBER
https://api.github.com/repos/php/doc-en/issues/comments/1525238935,Document ArgumentCountError for internal functions,enumag,11,1686462036,9,1525238935,0,1525238921,2023-04-27T09:15:17Z,"> If they use `ZEND_PARSE_PARAMETERS_START` or `zend_parse_parameters` then yes.

So there is no way to tell without studying the C source code of each function?",False,0,NONE
https://api.github.com/repos/php/doc-en/issues/comments/1525238951,Document ArgumentCountError for internal functions,iluuu1994,11,1686462036,10,1525238951,0,1525238935,2023-04-27T09:16:43Z,"Those are used pretty much universally. I can't guarantee there aren't a few functions that don't (e.g. some functions have multiple signatures and so will do multiple calls to the above with the `quiet` flag), but that's standard behavior for internal functions.",False,0,MEMBER
https://api.github.com/repos/php/doc-en/issues/comments/1525238963,Document ArgumentCountError for internal functions,enumag,11,1686462036,11,1525238963,0,1525238951,2023-04-27T09:19:22Z,"Alright. Thank you! :)

I guess I know what I need now so we can close the issue. There is still the problem with `ArgumentCountError` documentation being incomplete but that belongs to the documentation repository.",False,0,NONE
https://api.github.com/repos/php/doc-en/issues/comments/1525238972,Document ArgumentCountError for internal functions,iluuu1994,11,1686462036,12,1525238972,0,1525238963,2023-04-27T09:20:37Z,I also looked through the docs and was surprised that there isn't any mention of this. We can convert this to a documentation issue.,False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/12424,Fix GH-12423: [pdo_pgsql] Changed to prioritize DSN authentication information over arguments.,SakiTakamachi,8,1939017608,1,1939017608,0,0,2023-10-12T01:38:13Z,"fixes #12423

I was a little worried about which branch to target, but decided to target master because the behavior would change.",True,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1759186612,Fix GH-12423: [pdo_pgsql] Changed to prioritize DSN authentication information over arguments.,devnexen,8,1939017608,2,1759186612,0,1939017608,2023-10-12T08:42:33Z,would it be possible to add a test ?,False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1759298298,Fix GH-12423: [pdo_pgsql] Changed to prioritize DSN authentication information over arguments.,SakiTakamachi,8,1939017608,3,1759298298,0,1759186612,2023-10-12T09:54:49Z,"Okay, I'll add it later.",False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1759536586,Fix GH-12423: [pdo_pgsql] Changed to prioritize DSN authentication information over arguments.,SakiTakamachi,8,1939017608,4,1759536586,0,1759298298,2023-10-12T12:38:54Z,"@devnexen 

I added a test.",False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1759713009,Fix GH-12423: [pdo_pgsql] Changed to prioritize DSN authentication information over arguments.,jorgsowa,8,1939017608,5,1759713009,0,1759536586,2023-10-12T14:23:00Z,Probably it requires a note in UPGRADING as this may change the code behavior for some users.,False,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/comments/1763416861,Fix GH-12423: [pdo_pgsql] Changed to prioritize DSN authentication information over arguments.,devnexen,8,1939017608,6,1763416861,0,1759713009,2023-10-15T15:03:17Z,"While at it, would you mind squashing into 1 commit when you can ? If no one object I ll either commit today or tomorrow. Cheers.",False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1763420167,Fix GH-12423: [pdo_pgsql] Changed to prioritize DSN authentication information over arguments.,SakiTakamachi,8,1939017608,7,1763420167,0,1763416861,2023-10-15T15:13:04Z,"@devnexen 
I've compiled the commits!",False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1763481785,Fix GH-12423: [pdo_pgsql] Changed to prioritize DSN authentication information over arguments.,devnexen,8,1939017608,8,1763481785,0,1763420167,2023-10-15T19:24:55Z,Thank you !,False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1763577099,Fix GH-12423: [pdo_pgsql] Changed to prioritize DSN authentication information over arguments.,SakiTakamachi,8,1939017608,9,1763577099,0,1763481785,2023-10-16T01:09:26Z,Thank you!,False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/12425,Improve jit tests,danog,10,1939778984,1,1939778984,0,0,2023-10-12T11:24:25Z,"I added a patch.php checker just as a sanity check for the nightly tests, to make sure none of them fill up the opcache memory, preventing some JIT traces from being compiled: there is value in testing the edge case of filling up the opcache memory, as proved by https://github.com/php/php-src/issues/12366, but my intent was more to improve JIT coverage :)

Based on https://github.com/php/php-src/pull/12406.",True,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/comments/1766792818,Improve jit tests,danog,10,1939778984,2,1766792818,0,1939778984,2023-10-17T16:42:02Z,Ping @iluuu1994 :),False,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/comments/1771598745,Improve jit tests,danog,10,1939778984,3,1771598745,0,1766792818,2023-10-19T19:39:57Z,"> If you'd like to move phpseclib to a separate PR targetting master, that should be uncontroversial.

@iluuu1994 

Already done :) 

https://github.com/php/php-src/pull/12406/files",False,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/comments/1771603170,Improve jit tests,iluuu1994,10,1939778984,4,1771603170,0,1771598745,2023-10-19T19:43:24Z,"> Already done :)

Ah, sorry. I got confused by the PRs ^^",False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1774072207,Improve jit tests,danog,10,1939778984,5,1774072207,0,1771603170,2023-10-22T11:47:44Z,"Ping @iluuu1994 split the Psalm/jit_check changes to https://github.com/php/php-src/pull/12406/files, removing them from this PR, both PRs should be good to merge now :)",False,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/comments/1810719319,Improve jit tests,danog,10,1939778984,6,1810719319,0,1774072207,2023-11-14T17:12:21Z,@dstogov Awesome! Could you or @iluuu1994 or someone else merge this then? :),False,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/comments/1810722183,Improve jit tests,iluuu1994,10,1939778984,7,1810722183,0,1810719319,2023-11-14T17:13:48Z,@danog I'll have a look at your PRs in an hour or so.,False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1810940174,Improve jit tests,dstogov,10,1939778984,8,1810940174,0,1810722183,2023-11-14T18:49:35Z,@iluuu1994 please merge this if you don't see problems,False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1811025208,Improve jit tests,iluuu1994,10,1939778984,9,1811025208,0,1810940174,2023-11-14T19:13:26Z,"Note that I only merged this for master. I don't think such improvements should be made on the maintenance branches. The reason I sometimes backport things for CI is just because the nightly build unfortunately mixes config files from multiple branches (nightly.yml from master, everything else from the tested branch). Some of these improvements were already fixed on master.

@danog Please rebase your branches instead of merging. That makes them easier to merge. E.g. in this case I had to squash into a temporary branch so I could rebase the single commit onto master. No big deal, but would be slightly easier if its commits were linear.",False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1811028289,Improve jit tests,iluuu1994,10,1939778984,10,1811028289,0,1811025208,2023-11-14T19:14:55Z,"But most importantly, thanks @danog :wink: ",False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1811077667,Improve jit tests,danog,10,1939778984,11,1811077667,0,1811028289,2023-11-14T19:40:17Z,">Please rebase your branches instead of merging

Sure, no problem!",False,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/12427,ASAN heap-buffer-overflow with tracing JIT,danog,5,1940483797,1,1940483797,0,0,2023-10-12T17:41:03Z,"### Description

Running the phpunit testsuite of psalm commit 7428e49b115a2a837aa29cf0fafd0ca902fe2457 yields a heap-buffer-overflow ASAN assertion with this PHP config (ASAN debug build, USE_ZEND_ALLOC=0):

```
memory_limit = -1
zend.assertions = 1
display_errors = On
display_startup_errors = On
extension=uv
extension=gmp
extension=iconv
[opcache]
zend_extension=opcache
opcache.memory_consumption=4096M
opcache.enable=1
opcache.enable_cli=1
opcache.jit=tracing
opcache.validate_timestamps=0
opcache.jit_buffer_size=1G
opcache.file_update_protection=0
opcache.max_accelerated_files=1000000
opcache.interned_strings_buffer=64

;opcache.jit_debug=28672
;opcache.jit_debug=16384

opcache.jit_prof_threshold=0.000000001
opcache.jit_max_root_traces=  30000000
opcache.jit_max_side_traces=  30000000
opcache.jit_max_exit_counters=30000000
opcache.jit_hot_loop=1
opcache.jit_hot_func=1
opcache.jit_hot_return=1
opcache.jit_hot_side_exit=1

opcache.jit_blacklist_root_trace=255
opcache.jit_blacklist_side_trace=255

opcache.protect_memory=1
```

Command:
```
php patch.php vendor/bin/phpunit --debug
```

Result: https://paste.daniil.it/tracing_detailed

patch.php from https://github.com/php/php-src/pull/12425/files:

```php
<?php

register_shutdown_function(function () {
    $status = opcache_get_status(false);
    var_dump($status);

    $ok = true;
    if ($status[""memory_usage""][""free_memory""] < 10*1024*1024) {
        echo ""Not enough free opcache memory!"".PHP_EOL;
        $ok = false;
    }
    if ($status[""interned_strings_usage""][""free_memory""] < 1*1024*1024) {
        echo ""Not enough free interned strings memory!"".PHP_EOL;
        $ok = false;
    }
    if ($status[""jit""][""buffer_free""] < 10*1024*1024) {
        echo ""Not enough free JIT memory!"".PHP_EOL;
        $ok = false;
    }
    if (!$status[""jit""][""on""]) {
        echo ""JIT is not enabled!"".PHP_EOL;
        $ok = false;
    }

    unset($status);
    gc_collect_cycles();

    if (!$ok) die(130);
});

$argc--;
array_shift($argv);

$_SERVER['argc']--;
array_shift($_SERVER['argv']);

require $argv[0];
```

### PHP Version

3a41dc8b2e24b4ccff8148ef768a3025bb818215

Ping @dstogov ",True,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/comments/1760092438,ASAN heap-buffer-overflow with tracing JIT,danog,5,1940483797,2,1760092438,0,1940483797,2023-10-12T17:51:16Z,"Actually realized the trace I linked contains an invalid read, not a heap-buffer-overflow, here's the heap-buffer-overflow I got when running the first time:

```
==1545382==ERROR: AddressSanitizer: heap-buffer-overflow on address 0x60e0002ec154 at pc 0x7ffa70c078a7 bp 0x7ffde68b4b90 sp 0x7ffde68b4b88
READ of size 4 at 0x60e0002ec154 thread T0
    #0 0x7ffa70c078a6 in zend_jit_assign_to_typed_prop /root/php-src/ext/opcache/jit/zend_jit_helpers.c:2567:30
LLVMSymbolizer: error reading file: No such file or directory
    #1 0x7ffa311a2aaa  (/dev/zero (deleted)+0x100a15aaa)

0x60e0002ec154 is located 60 bytes to the right of 152-byte region [0x60e0002ec080,0x60e0002ec118)
allocated by thread T0 here:
    #0 0x67cf4d in malloc (/usr/local/bin/php+0x67cf4d)
    #1 0x157e2f4 in __zend_malloc /root/php-src/Zend/zend_alloc.c:3130:14
    #2 0x157da52 in _malloc_custom /root/php-src/Zend/zend_alloc.c:2493:10
    #3 0x157d901 in _emalloc /root/php-src/Zend/zend_alloc.c:2612:10
    #4 0x1a62186 in zend_objects_new /root/php-src/Zend/zend_objects.c:189:24
    #5 0x1a639b2 in zend_objects_clone_obj /root/php-src/Zend/zend_objects.c:291:15
    #6 0x189de57 in ZEND_CLONE_SPEC_TMPVAR_HANDLER /root/php-src/Zend/zend_vm_execute.h:14772:2
    #7 0x7ffa311a2a6d  (/dev/zero (deleted)+0x100a15a6d)
    #8 0x173224d in zend_execute /root/php-src/Zend/zend_vm_execute.h:61584:2
    #9 0x166c70c in zend_execute_scripts /root/php-src/Zend/zend.c:1876:4
    #10 0x14455a2 in php_execute_script /root/php-src/main/main.c:2492:13
    #11 0x1c8934a in do_cli /root/php-src/sapi/cli/php_cli.c:966:5
    #12 0x1c86c90 in main /root/php-src/sapi/cli/php_cli.c:1340:18
    #13 0x7ffa760c5082 in __libc_start_main /build/glibc-BHL3KM/glibc-2.31/csu/../csu/libc-start.c:308:16

SUMMARY: AddressSanitizer: heap-buffer-overflow /root/php-src/ext/opcache/jit/zend_jit_helpers.c:2567:30 in zend_jit_assign_to_typed_prop
Shadow bytes around the buggy address:
  0x0c1c800557d0: fa fa fa fa fa fa fa fa fd fd fd fd fd fd fd fd
  0x0c1c800557e0: fd fd fd fd fd fd fd fd fd fd fd fa fa fa fa fa
  0x0c1c800557f0: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa
  0x0c1c80055800: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa
  0x0c1c80055810: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
=>0x0c1c80055820: 00 00 00 fa fa fa fa fa fa fa[fa]fa fd fd fd fd
  0x0c1c80055830: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fa
  0x0c1c80055840: fa fa fa fa fa fa fa fa fd fd fd fd fd fd fd fd
  0x0c1c80055850: fd fd fd fd fd fd fd fd fd fd fd fa fa fa fa fa
  0x0c1c80055860: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa
  0x0c1c80055870: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa
Shadow byte legend (one shadow byte represents 8 application bytes):
  Addressable:           00
  Partially addressable: 01 02 03 04 05 06 07
  Heap left redzone:       fa
  Freed heap region:       fd
  Stack left redzone:      f1
  Stack mid redzone:       f2
  Stack right redzone:     f3
  Stack after return:      f5
  Stack use after scope:   f8
  Global redzone:          f9
  Global init order:       f6
  Poisoned by user:        f7
  Container overflow:      fc
  Array cookie:            ac
  Intra object redzone:    bb
  ASan internal:           fe
  Left alloca redzone:     ca
  Right alloca redzone:    cb
  Shadow gap:              cc
==1545382==ABORTING
```",False,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/comments/1764267845,ASAN heap-buffer-overflow with tracing JIT,dstogov,5,1940483797,3,1764267845,0,1760092438,2023-10-16T11:28:29Z,It looks like this test run should take hours. Can you try to isolate the case to something smaller...,False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1771662285,ASAN heap-buffer-overflow with tracing JIT,danog,5,1940483797,4,1771662285,0,1764267845,2023-10-19T20:31:08Z,"Hi @dstogov, can reproduce immediately just by running the magic annotation tests:

```
USE_ZEND_ALLOC=0 php-asan vendor/bin/phpunit --debug tests/MagicMethodAnnotationTest.php
```

Same ini config and psalm commit as specified in the top message, php-src commit 48f0b10f32ee52594685f9b885e0926fbccfa866.",False,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/comments/1774804746,ASAN heap-buffer-overflow with tracing JIT,dstogov,5,1940483797,5,1774804746,0,1771662285,2023-10-23T09:39:05Z,"``opcache.memory_consumption`` accepts amount of memory in MB , ``4096M`` is interpreted as ``4096``.
Anyway, this helped me to fix an unrelated bug in 32-bit PHP build.

Now I can't reproduce the failure. I remember, I reproduced it once running the whole test suite, but the second run worked for an hour(s) without failures. Now I didn't see the failure on ``tests/MagicMethodAnnotationTest.php``, and I tried to start testing from scratch (cloning git repo etc), but I even can't find the commit ``7428e49b115a2a837aa29cf0fafd0ca902fe2457``. I'm lost :(. Please provide the complete instruction to reproduce the failure in the bug report.

Also, please don't include third-party extensions (``uv.so``) if they are not really necessary for reproduction.",False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1776070323,ASAN heap-buffer-overflow with tracing JIT,danog,5,1940483797,6,1776070323,0,1774804746,2023-10-23T21:44:22Z,"Indeed, can't reproduce anymore with https://github.com/danog/jit_bugs, quite strange, closing this then.",False,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/12428,Assertion with function/tracing JIT,danog,10,1940527116,1,1940527116,0,0,2023-10-12T18:07:39Z,"### Description

### Description

Running the [infection](https://github.com/infection/infection) phpunit testsuite, commit 2789fdd689689b0c85f2c0ae9db50c8d2b39fb92 throws an assertion:

```
php: /root/php-src/Zend/zend_execute.c:251: zval *_get_zval_ptr_tmp(uint32_t, zend_execute_data *): Assertion `zval_get_type(&(*(ret))) != 10' failed.
```


php.ini:
```
memory_limit = -1
zend.assertions = 1
display_errors = On
display_startup_errors = On
extension=uv
extension=gmp
extension=iconv
[opcache]
zend_extension=opcache
opcache.memory_consumption=4096M
opcache.enable=1
opcache.enable_cli=1
opcache.jit=tracing
opcache.validate_timestamps=0
opcache.jit_buffer_size=1G
opcache.file_update_protection=0
opcache.max_accelerated_files=1000000
opcache.interned_strings_buffer=64

;opcache.jit_debug=28672
;opcache.jit_debug=16384

opcache.jit_prof_threshold=0.000000001
opcache.jit_max_root_traces=  30000000
opcache.jit_max_side_traces=  30000000
opcache.jit_max_exit_counters=30000000
opcache.jit_hot_loop=1
opcache.jit_hot_func=1
opcache.jit_hot_return=1
opcache.jit_hot_side_exit=1

opcache.jit_blacklist_root_trace=255
opcache.jit_blacklist_side_trace=255

opcache.protect_memory=1
```

Command:
```
php patch.php vendor/bin/phpunit ./tests/phpunit/Configuration/Schema/SchemaConfigurationFactoryTest.php --filter test_it_can_create_a_config --debug
```

Result: 

patch.php from https://github.com/php/php-src/pull/12425/files:

```php
<?php

register_shutdown_function(function () {
    $status = opcache_get_status(false);
    var_dump($status);

    $ok = true;
    if ($status[""memory_usage""][""free_memory""] < 10*1024*1024) {
        echo ""Not enough free opcache memory!"".PHP_EOL;
        $ok = false;
    }
    if ($status[""interned_strings_usage""][""free_memory""] < 1*1024*1024) {
        echo ""Not enough free interned strings memory!"".PHP_EOL;
        $ok = false;
    }
    if ($status[""jit""][""buffer_free""] < 10*1024*1024) {
        echo ""Not enough free JIT memory!"".PHP_EOL;
        $ok = false;
    }
    if (!$status[""jit""][""on""]) {
        echo ""JIT is not enabled!"".PHP_EOL;
        $ok = false;
    }

    unset($status);
    gc_collect_cycles();

    if (!$ok) die(130);
});

$argc--;
array_shift($argv);

$_SERVER['argc']--;
array_shift($_SERVER['argv']);

require $argv[0];
```

Ping @dstogov 

### PHP Version

3a41dc8b2e24b4ccff8148ef768a3025bb818215

### Operating System

_No response_",True,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/comments/1760124215,Assertion with function/tracing JIT,danog,10,1940527116,2,1760124215,0,1940527116,2023-10-12T18:09:45Z,"Full output:

```
vendor/bin/phpunit ./tests/phpunit/Configuration/Schema/SchemaConfigurationFactoryTest.php --filter test_it_can_create_a_config --debug
PHPUnit 9.6.13 by Sebastian Bergmann and contributors.

Runtime:       PHP 8.4.0-dev
Configuration: /root/infection/phpunit.xml.dist
Random Seed:   1697134123

Testing Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest
Test 'Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config with data set ""[mutators][generic][UnwrapArrayUdiffUassoc] enabled"" ('{\n    ""source"": {\n        ""...  }\n}', Infection\Configuration\Schema\SchemaConfiguration Object (...))' started
Test 'Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config with data set ""[mutators][generic][UnwrapArrayUdiffUassoc] enabled"" ('{\n    ""source"": {\n        ""...  }\n}', Infection\Configuration\Schema\SchemaConfiguration Object (...))' ended
Test 'Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config with data set ""[mutators][BCMath] true"" ('{\n    ""source"": {\n        ""...  }\n}', Infection\Configuration\Schema\SchemaConfiguration Object (...))' started
Test 'Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config with data set ""[mutators][BCMath] true"" ('{\n    ""source"": {\n        ""...  }\n}', Infection\Configuration\Schema\SchemaConfiguration Object (...))' ended
Test 'Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config with data set ""[mutators][generic][Coalesce] disabled"" ('{\n    ""source"": {\n        ""...  }\n}', Infection\Configuration\Schema\SchemaConfiguration Object (...))' started
Test 'Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config with data set ""[mutators][generic][Coalesce] disabled"" ('{\n    ""source"": {\n        ""...  }\n}', Infection\Configuration\Schema\SchemaConfiguration Object (...))' ended
Test 'Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config with data set ""[mutators][profile] @default ignore"" ('{\n    ""source"": {\n        ""...  }\n}', Infection\Configuration\Schema\SchemaConfiguration Object (...))' started
Test 'Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config with data set ""[mutators][profile] @default ignore"" ('{\n    ""source"": {\n        ""...  }\n}', Infection\Configuration\Schema\SchemaConfiguration Object (...))' ended
Test 'Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config with data set ""[mutators][generic][UnwrapArrayUintersectAssoc] ignore"" ('{\n    ""source"": {\n        ""...  }\n}', Infection\Configuration\Schema\SchemaConfiguration Object (...))' started
Test 'Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config with data set ""[mutators][generic][UnwrapArrayUintersectAssoc] ignore"" ('{\n    ""source"": {\n        ""...  }\n}', Infection\Configuration\Schema\SchemaConfiguration Object (...))' ended
Test 'Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config with data set ""[mutators][generic][UnwrapArrayDiffAssoc] enabled"" ('{\n    ""source"": {\n        ""...  }\n}', Infection\Configuration\Schema\SchemaConfiguration Object (...))' started
Test 'Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config with data set ""[mutators][generic][UnwrapArrayDiffAssoc] enabled"" ('{\n    ""source"": {\n        ""...  }\n}', Infection\Configuration\Schema\SchemaConfiguration Object (...))' ended
Test 'Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config with data set ""[mutators][generic][UnwrapLcFirst] ignore empty & untrimmed"" ('{\n    ""source"": {\n        ""...  }\n}', Infection\Configuration\Schema\SchemaConfiguration Object (...))' started
Test 'Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config with data set ""[mutators][generic][UnwrapLcFirst] ignore empty & untrimmed"" ('{\n    ""source"": {\n        ""...  }\n}', Infection\Configuration\Schema\SchemaConfiguration Object (...))' ended
Test 'Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config with data set ""[mutators][profile] @loop ignore"" ('{\n    ""source"": {\n        ""...  }\n}', Infection\Configuration\Schema\SchemaConfiguration Object (...))' started
Test 'Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config with data set ""[mutators][profile] @loop ignore"" ('{\n    ""source"": {\n        ""...  }\n}', Infection\Configuration\Schema\SchemaConfiguration Object (...))' ended
Test 'Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config with data set ""[mutators][ArrayItemRemoval] ignore"" ('{\n    ""source"": {\n        ""...  }\n}', Infection\Configuration\Schema\SchemaConfiguration Object (...))' started
Test 'Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config with data set ""[mutators][ArrayItemRemoval] ignore"" ('{\n    ""source"": {\n        ""...  }\n}', Infection\Configuration\Schema\SchemaConfiguration Object (...))' ended
Test 'Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config with data set ""minimal"" ('{\n    ""source"": {\n        ""...  }\n}', Infection\Configuration\Schema\SchemaConfiguration Object (...))' started
Test 'Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config with data set ""minimal"" ('{\n    ""source"": {\n        ""...  }\n}', Infection\Configuration\Schema\SchemaConfiguration Object (...))' ended
Test 'Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config with data set ""[mutators][generic][NotIdentical] disabled"" ('{\n    ""source"": {\n        ""...  }\n}', Infection\Configuration\Schema\SchemaConfiguration Object (...))' started
Test 'Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config with data set ""[mutators][generic][NotIdentical] disabled"" ('{\n    ""source"": {\n        ""...  }\n}', Infection\Configuration\Schema\SchemaConfiguration Object (...))' ended
Test 'Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config with data set ""[mutators][generic][UnwrapArrayKeys] disabled"" ('{\n    ""source"": {\n        ""...  }\n}', Infection\Configuration\Schema\SchemaConfiguration Object (...))' started
Test 'Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config with data set ""[mutators][generic][UnwrapArrayKeys] disabled"" ('{\n    ""source"": {\n        ""...  }\n}', Infection\Configuration\Schema\SchemaConfiguration Object (...))' ended
Test 'Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config with data set ""[mutators][generic][FloatNegation] ignore"" ('{\n    ""source"": {\n        ""...  }\n}', Infection\Configuration\Schema\SchemaConfiguration Object (...))' started
Test 'Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config with data set ""[mutators][generic][FloatNegation] ignore"" ('{\n    ""source"": {\n        ""...  }\n}', Infection\Configuration\Schema\SchemaConfiguration Object (...))' ended
Test 'Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config with data set ""[minCoveredMsi] is int"" ('{\n    ""source"": {\n        ""... 32\n}', Infection\Configuration\Schema\SchemaConfiguration Object (...))' started
Test 'Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config with data set ""[minCoveredMsi] is int"" ('{\n    ""source"": {\n        ""... 32\n}', Infection\Configuration\Schema\SchemaConfiguration Object (...))' ended
Test 'Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config with data set ""[logs][perMutator] nominal"" ('{\n    ""source"": {\n        ""...  }\n}', Infection\Configuration\Schema\SchemaConfiguration Object (...))' started
php: /root/php-src/Zend/zend_execute.c:251: zval *_get_zval_ptr_tmp(uint32_t, zend_execute_data *): Assertion `zval_get_type(&(*(ret))) != 10' failed.
Aborted
```",False,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/comments/1760125332,Assertion with function/tracing JIT,danog,10,1940527116,3,1760125332,0,1760124215,2023-10-12T18:10:41Z,"Same assertion occurs when using function JIT, not when JIT is disabled.",False,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/comments/1760190554,Assertion with function/tracing JIT,danog,10,1940527116,4,1760190554,0,1760125332,2023-10-12T18:45:22Z,"Backtraces:

```
(gdb) back
#0  __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:50
#1  0x00007ffff7209859 in __GI_abort () at abort.c:79
#2  0x00007ffff7209729 in __assert_fail_base (fmt=0x7ffff739f588 ""%s%s%s:%u: %s%sAssertion `%s' failed.\n%n"", assertion=0x2ac4d20 <str> ""zval_get_type(&(*(ret))) != 10"",
    file=0x2ab75a0 <str> ""/root/php-src/Zend/zend_execute.c"", line=251, function=<optimized out>) at assert.c:92
#3  0x00007ffff721afd6 in __GI___assert_fail (assertion=0x2ac4d20 <str> ""zval_get_type(&(*(ret))) != 10"", file=0x2ab75a0 <str> ""/root/php-src/Zend/zend_execute.c"", line=251,
    function=0x2ac4d60 <__PRETTY_FUNCTION__._get_zval_ptr_tmp> ""zval *_get_zval_ptr_tmp(uint32_t, zend_execute_data *)"") at assert.c:101
#4  0x00000000019967d5 in _get_zval_ptr_tmp (var=144, execute_data=0x7ffff1e08ed0) at Zend/zend_execute.c:251
#5  0x0000000001935ef5 in ZEND_COALESCE_SPEC_TMP_HANDLER (execute_data=0x7ffff1e08ed0) at Zend/zend_vm_execute.h:19710
#6  0x00007fffb17379d0 in ?? ()
#7  0x0000000000000000 in ?? ()
(gdb) zback
[0x7ffff1e08ed0] Infection\Configuration\Schema\SchemaConfigurationFactory->create(""/path/to/config"", object[0x7ffff1e08f30])
/root/infection/src/Configuration/Schema/SchemaConfigurationFactory.php:59
[0x7ffff1e08e10] Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest->test_it_can_create_a_config(""{\12    ""source"": {\12        ""directories"": [""src""]\12    },\12    ""logs"": {
\12        ""perMutator"": ""perMutator.log""\12    }\12}"", object[0x7ffff1e08e70]) /root/infection/tests/phpunit/Configuration/Schema/SchemaConfigurationFactoryTest.php:104
[0x7ffff1e08d70] PHPUnit\Framework\TestCase->runTest() /root/infection/vendor/phpunit/phpunit/src/Framework/TestCase.php:1612
[0x7ffff1e08ca0] PHPUnit\Framework\TestCase->runBare() /root/infection/vendor/phpunit/phpunit/src/Framework/TestCase.php:1218
[0x7ffff1e08a50] PHPUnit\Framework\TestResult->run(object[0x7ffff1e08aa0]) /root/infection/vendor/phpunit/phpunit/src/Framework/TestResult.php:728
[0x7ffff1e08800] PHPUnit\Framework\TestCase->run(object[0x7ffff1e08850]) /root/infection/vendor/phpunit/phpunit/src/Framework/TestCase.php:968
[0x7ffff1e086b0] PHPUnit\Framework\TestSuite->run(object[0x7ffff1e08700]) /root/infection/vendor/phpunit/phpunit/src/Framework/TestSuite.php:684
[0x7ffff1e08560] PHPUnit\Framework\TestSuite->run(object[0x7ffff1e085b0]) /root/infection/vendor/phpunit/phpunit/src/Framework/TestSuite.php:684
[0x7ffff1e082d0] PHPUnit\TextUI\TestRunner->run(object[0x7ffff1e08320], reference, reference, true) /root/infection/vendor/phpunit/phpunit/src/TextUI/TestRunner.php:651
[0x7ffff1e081f0] PHPUnit\TextUI\Command->run(array(5)[0x7ffff1e08240], true) /root/infection/vendor/phpunit/phpunit/src/TextUI/Command.php:144
[0x7ffff1e08150] PHPUnit\TextUI\Command->main() /root/infection/vendor/phpunit/phpunit/src/TextUI/Command.php:97
[0x7ffff1e080a0] (main) /root/infection/vendor/phpunit/phpunit/phpunit:107
[0x7ffff1e08020] (main) /root/infection/vendor/bin/phpunit:122
```",False,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/comments/1763495688,Assertion with function/tracing JIT,danog,10,1940527116,5,1763495688,0,1760190554,2023-10-15T20:25:53Z,"Minimal reproducer:

```php
<?php

function validate($value)
{
    foreach ([0] as $_) {
        $a = &$value->a;
        $value->a ?? null;
    }
}

validate((object) []);
validate((object) []);
validate((object) ['b' => 0]);

```",False,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/comments/1764347956,Assertion with function/tracing JIT,dstogov,10,1940527116,6,1764347956,0,1763495688,2023-10-16T12:15:47Z,"Thanks for the small test case. It's fixed now.
When do you plan to land all these community tests improvements?",False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1764770784,Assertion with function/tracing JIT,danog,10,1940527116,7,1764770784,0,1764347956,2023-10-16T15:43:40Z,"Hi @dstogov, no problem, but it seems another similar assertion is still being emitted when running the testsuite, will try to isolate again but maybe there's another similar place in the code that can trigger the issue?

```
(gdb) back
#0  __pthread_kill_implementation (threadid=<optimized out>, signo=signo@entry=6, no_tid=no_tid@entry=0) at pthread_kill.c:44
#1  0x00007ffff6ffa8a3 in __pthread_kill_internal (signo=6, threadid=<optimized out>) at pthread_kill.c:78
#2  0x00007ffff6faa668 in __GI_raise (sig=sig@entry=6) at ../sysdeps/posix/raise.c:26
#3  0x00007ffff6f924b8 in __GI_abort () at abort.c:79
#4  0x00007ffff6f923dc in __assert_fail_base (fmt=0x7ffff710bae8 ""%s%s%s:%u: %s%sAssertion `%s' failed.\n%n"",
    assertion=assertion@entry=0x555557953f60 <str> ""zval_get_type(&(*(ret))) != 10"",
    file=file@entry=0x55555794f240 <str> ""/home/daniil/repos/php-src/Zend/zend_execute.c"", line=line@entry=251,
    function=function@entry=0x555557953fa0 <__PRETTY_FUNCTION__._get_zval_ptr_tmp> ""zval *_get_zval_ptr_tmp(uint32_t, zend_execute_data *)"")
    at assert.c:92
#5  0x00007ffff6fa2d26 in __assert_fail (assertion=0x555557953f60 <str> ""zval_get_type(&(*(ret))) != 10"",
    file=0x55555794f240 <str> ""/home/daniil/repos/php-src/Zend/zend_execute.c"", line=251,
    function=0x555557953fa0 <__PRETTY_FUNCTION__._get_zval_ptr_tmp> ""zval *_get_zval_ptr_tmp(uint32_t, zend_execute_data *)"") at assert.c:101
#6  0x0000555556ac6d5c in _get_zval_ptr_tmp (var=160, execute_data=0x7ffff4802610) at /home/daniil/repos/php-src/Zend/zend_execute.c:251
#7  0x0000555556a6eaa4 in ZEND_COALESCE_SPEC_TMP_HANDLER (execute_data=0x7ffff4802610) at Zend/zend_vm_execute.h:19710
#8  0x00007fffb16ebdcb in TRACE-608$Infection\Tests\Configuration\Schema\SchemaConfigurationFactoryTest::test_it_can_create_a_config$106 ()
    at unknown:1
```

Regarding the testsuite improvements PRs, https://github.com/php/php-src/pull/12425 is ready to merge, as is https://github.com/php/php-src/pull/12406.

Will submit a new PR with a nightly test for infection, and another PR that further improves JIT coverage by running all unit tests 3x times in a php-fpm daemon, or by using the file cache this weekend.",False,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/comments/1769105132,Assertion with function/tracing JIT,dstogov,10,1940527116,8,1769105132,0,1764770784,2023-10-18T18:30:56Z,I can't reproduce the bug with infection,False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1771650022,Assertion with function/tracing JIT,danog,10,1940527116,9,1771650022,0,1769105132,2023-10-19T20:20:54Z,"Hi @dstogov, I can reproduce with this slightly reduced testcase using commit 745a34646f20f0f0fc77a9223bc5fc57a975a957 of php-src:

```php
<?php

require 'vendor/autoload.php';

use Infection\Configuration\Entry\Logs;
use Infection\Configuration\Entry\PhpUnit;
use Infection\Configuration\Entry\Source;
use Infection\Configuration\Schema\SchemaConfiguration;
use Infection\Configuration\Schema\SchemaConfigurationFactory;
use JsonSchema\Validator;

function test_it_can_create_a_config(
    string $json,
): void {
    $rawConfig = json_decode($json);

    $validator = new Validator();

    $validator->validate($rawConfig, json_decode('{
        ""$schema"": ""https://json-schema.org/draft-07/schema#"",
        ""properties"": {
            ""source"": {""type"": ""string""}
        }
    }'));

    $actual = (new SchemaConfigurationFactory())->create(
        '/path/to/config',
        $rawConfig
    );
}

function provideRawConfig(): iterable
{

    yield '[timeout] nominal' => [
        <<<'JSON'
{
""timeout"": 100,
""source"": {
    ""directories"": [""src""]
}
}
JSON
        ,
    ];


    yield '[logs][text] nominal' => [
        <<<'JSON'
{
""source"": {
    ""directories"": [""src""]
},
""logs"": {
    ""text"": ""text.log""
}
}
JSON
        ,
    ];
    yield '[logs][html] nominal' => [
        <<<'JSON'
{
""source"": {
    ""directories"": [""src""]
},
""logs"": {
    ""html"": ""report.html""
}
}
JSON
        ,
    ];
}

for ($x = 0; $x < 10000; $x++) {
    foreach (provideRawConfig() as [$a]) {
        test_it_can_create_a_config($a);
    }
}
```

The same assertion also occurs when running phpunit.

Same config as usual:

```
memory_limit = -1
zend.assertions = 1
display_errors = On
display_startup_errors = On
extension=uv
extension=gmp
extension=iconv
[opcache]
zend_extension=opcache
opcache.memory_consumption=4096M
opcache.enable=1
opcache.enable_cli=1
opcache.jit=tracing
opcache.validate_timestamps=0
opcache.jit_buffer_size=1G
opcache.file_update_protection=0
opcache.max_accelerated_files=1000000
opcache.interned_strings_buffer=64

;opcache.jit_debug=28672
;opcache.jit_debug=16384

opcache.jit_prof_threshold=0.000000001
opcache.jit_max_root_traces=  30000000
opcache.jit_max_side_traces=  30000000
opcache.jit_max_exit_counters=30000000
opcache.jit_hot_loop=1
opcache.jit_hot_func=1
opcache.jit_hot_return=1
opcache.jit_hot_side_exit=1

opcache.jit_blacklist_root_trace=255
opcache.jit_blacklist_side_trace=255

opcache.protect_memory=1
```",False,0,CONTRIBUTOR
https://api.github.com/repos/php/php-src/issues/comments/1774892365,Assertion with function/tracing JIT,dstogov,10,1940527116,10,1774892365,0,1771650022,2023-10-23T10:26:44Z,I still can't reproduce this,False,0,MEMBER
https://api.github.com/repos/php/php-src/issues/comments/1776075736,Assertion with function/tracing JIT,danog,10,1940527116,11,1776075736,0,1774892365,2023-10-23T21:48:53Z,"Indeed, can't reproduce anymore with https://github.com/danog/jit_bugs, quite strange, closing this then.",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/1389,"Update failed, invalid composer.json metadata [Composer\Repository\InvalidRepositoryException]",remarkablemark,5,1837999289,1,1837999289,0,0,2023-08-06T01:17:25Z,"I submitted a [package](https://packagist.org/packages/remarkablemark/php-composer-test) and it failed with the error:

<img width=""879"" alt=""Screen Shot 2023-08-05 at 9 14 44 PM"" src=""https://github.com/composer/packagist/assets/10594555/06275074-b9c8-401d-bfbf-d683e1d6f988"">

Here's the copied error:

```
Update of remarkablemark/php-composer-test failed, invalid composer.json metadata [Composer\Repository\InvalidRepositoryException] Some branches contained invalid data and were discarded, it is advised to review the log and fix any issues present in branches
```

```
Reading composer.json of remarkablemark/php-composer-test (v1.0.0)
Importing tag v1.0.0 (1.0.0.0)
Reading composer.json of remarkablemark/php-composer-test (master)
Importing branch master (dev-master)
Skipped branch master, Invalid package information: 
funding.7.url : invalid value (['link1), must be an http/https URL
funding.8.url : invalid value (link2), must be an http/https URL
```

I believe this is caused by a parsing error from [.github/FUNDING.yml](https://github.com/remarkablemark/.github/blob/master/FUNDING.yml).

I ran `composer validate` and didn't get any errors:

```
./composer.json is valid, but with a few warnings
See https://getcomposer.org/doc/04-schema.md for details on the schema
# General warnings
- The version field is present, it is recommended to leave it out if the package is published on Packagist.
```

Related to #1097",True,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1667322114,"Update failed, invalid composer.json metadata [Composer\Repository\InvalidRepositoryException]",stof,5,1837999289,2,1667322114,0,1837999289,2023-08-07T07:19:27Z,Try removing the comments in that file. This will avoid confusing the extractor.,False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1668244269,"Update failed, invalid composer.json metadata [Composer\Repository\InvalidRepositoryException]",remarkablemark,5,1837999289,3,1668244269,0,1667322114,2023-08-07T16:46:55Z,Makes sense! Is that a bug with the extractor?,False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1669113788,"Update failed, invalid composer.json metadata [Composer\Repository\InvalidRepositoryException]",stof,5,1837999289,4,1669113788,0,1668244269,2023-08-08T08:01:17Z,"Yeah. The logic is at https://github.com/composer/composer/blob/95dca79fc2e18c3a4e33f207c1fcaa7d5b559400/src/Composer/Repository/Vcs/GitHubDriver.php#L204

It does not use an actual Yaml parser to avoid introducing that as a dependency of composer.",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1670082976,"Update failed, invalid composer.json metadata [Composer\Repository\InvalidRepositoryException]",remarkablemark,5,1837999289,5,1670082976,0,1669113788,2023-08-08T18:14:01Z,"Gotcha, thanks for the context!",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1757689008,"Update failed, invalid composer.json metadata [Composer\Repository\InvalidRepositoryException]",Seldaek,5,1837999289,6,1757689008,0,1670082976,2023-10-11T13:20:47Z,I think the problem might be the empty lines like `open_collective: # ...`. Not sure though. ,False,0,MEMBER
https://api.github.com/repos/composer/packagist/issues/1391,"Get ""dependents"" with specific version constraints",fe-hicking,3,1862070893,1,1862070893,0,0,2023-08-22T19:28:15Z,"I would love for a possibility on packagist to get a list of packages which depend on a specific version constraint of a base package.

There is i.e. https://packagist.org/packages/typo3/cms-core/dependents?order_by=downloads - but that lists a few thousand packages. I would like to only see packages that are compatible with TYPO3 ^12.0.

Reason is I want to check for a specific code fragment in all public extensions for this project for research, and I somehow need to download&grep in all these packages.

As a fallback I could use a filter option on https://packagist.org/search.json?type=typo3-cms-extension&per_page=100 with version constraints?

(I tried for a few hours to research existing issues and stackoverflow, didn't really find anything. I'm sorry if there is a duplicate issue on this)",True,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1757304933,"Get ""dependents"" with specific version constraints",Seldaek,3,1862070893,2,1757304933,0,1862070893,2023-10-11T09:58:32Z,"Yeah this is not so simple as you'd need to examine really the versions and whether the constraints intersect. E.g. you are interested in ^12 but what about something requiring 12.5.3, or >=11, or ~12.4, all those should be found too.

So this isn't something we can defer to the database, and it's thus way more cpu intensive to query. But yes we maybe could add a filter option.. It'd just maybe need to come with some restrictions on the amount of packages/versions we inspect. For sure looking only at the latest version of each minor release of each dependent would already reduce the dataset, if the original amount is too large.",False,0,MEMBER
https://api.github.com/repos/composer/packagist/issues/comments/1757330909,"Get ""dependents"" with specific version constraints",fe-hicking,3,1862070893,3,1757330909,0,1757304933,2023-10-11T10:15:01Z,"Thanks for your response! Yes I figured that is harder than it sounds. :-) 

For TYPO3 development and most importantly for supporting it, it would be quite awesome if we have such a filter.

For certain features that may get deprecated or where a major bug is found, it would be cool if we could just automatically parse all matching ""external"" dependents on that package and maybe inform package authors specifically. Or just see, how many dependents use specific functionality that may change.

And developers may easier look up examples for specific versions of a dependency to see how ""others do it"".

(I've actually went the route and downloaded ALL dependents there, extracted latest releases, do a code-search on it. That might be a pro-feature idea for the private packagist maybe, which touches that)",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1758835088,"Get ""dependents"" with specific version constraints",GuySartorelli,3,1862070893,4,1758835088,0,1757330909,2023-10-12T02:58:32Z,FYI this is similar to (if not a duplicate of) https://github.com/composer/packagist/issues/1048,False,0,NONE
https://api.github.com/repos/composer/packagist/issues/1393,Sudden 404 not found on API for some existing packages,kylekatarnls,6,1886564677,1,1886564677,0,0,2023-09-07T21:06:55Z,"Hello, 👋 

Until recently, I was able to get info from API about `pug/pug` using https://repo.packagist.org/p/pug/pug.json

As you can see the package exists for long:
https://packagist.org/packages/pug/pug

And the web page properly shows it, only the API say it's missing, and some other similar packages still work:
https://repo.packagist.org/p/pug/slim.json

I get: `""404 not found, no packages here""` both locally and via GitHub Actions.

Thanks 🙏 ",True,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1711235609,Sudden 404 not found on API for some existing packages,stof,6,1886564677,2,1711235609,0,1886564677,2023-09-08T07:52:06Z,"the `/p/` endpoints are the endpoints for the Composer v1 metadata format, which is deprecated and not guaranteed to provide all packages anymore. See https://blog.packagist.com/deprecating-composer-1-support/

You should use the endpoints of the v2 format.

See https://packagist.org/apidoc#get-package-data",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1711341647,Sudden 404 not found on API for some existing packages,kylekatarnls,6,1886564677,3,1711341647,0,1711235609,2023-09-08T09:11:04Z,"Thank you, I was not aware and so moving to `/p2/` will be just fine for me. However I think mentioning in the doc is of little help for discoverability.

And it sounds like not being sure either the data are correct or not in `/p/` actually make it useless (I can't  see a use-case where unreliable API result would be fine).

Considering this, wouldn't it make more sense to shutdown completely at once and either redirect to `/p2/` or send some generic 5xx error.",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1711365050,Sudden 404 not found on API for some existing packages,stof,6,1886564677,4,1711365050,0,1711341647,2023-09-08T09:29:13Z,"Redirecting is a no-go as the structure of the data is different (that's why the v2 metadata is provided in new endpoints).

And dropping the `/p/` endpoints entirely means dropping support entirely for Composer 1.x, so this needs to be based on the usage of Composer 1.x.",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1711379003,Sudden 404 not found on API for some existing packages,vtsykun,6,1886564677,5,1711379003,0,1711365050,2023-09-08T09:40:19Z,"More simple to use this endpoint if you call API directly 

```
https://packagist.org/packages/pug/pug.json
```",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1711395071,Sudden 404 not found on API for some existing packages,stof,6,1886564677,6,1711395071,0,1711379003,2023-09-08T09:51:15Z,"Well, depending on what you want to do, this can indeed provide more infos. But it is much more costly in term of resources for the server than the metadata endpoints (which are served from static files dumped on the filesystem). So if you call the API a lot for metadata that appear in the composer repository metadata, it is much better to use the metadata endpoints.",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1711580032,Sudden 404 not found on API for some existing packages,Seldaek,6,1886564677,7,1711580032,0,1711395071,2023-09-08T12:18:17Z,"Yeah please don't use the `/packages/` API unless you need data that is only available in it. Sure it's a bit more complex to use the `/p2/` API as you need to use https://github.com/composer/metadata-minifier to decompress the data, but that's not *that* hard it's one extra line of code.",False,0,MEMBER
https://api.github.com/repos/composer/packagist/issues/1404,How can i update the version of my library correctly and remove the tag ignored warning message ?,richardsonoge,3,2009047745,1,2009047745,0,0,2023-11-24T03:42:35Z,"Hello to the Packagist.org team!

I don't know what's going on but I uploaded my ""https://packagist.org/packages/richardsonoge/pdf-translator"" package, fixed some bugs and added a new version in my Github code. And when I got to my ""https://packagist.org/packages/richardsonoge/pdf-translator"" package and clicked on ""Update"", there was no update of my ""https://packagist.org/packages/richardsonoge/pdf-translator"" package. No code has been updated see my version will change. I don't know what to do... The old version is ""1.0.0"" and it should be in this new version ""1.0.1"" Can you help me in this case? And show me how can i too remove [packagist.org](http://packagist.org/) Tag Ignored Warning Message? Tell me what to do step by step so that I can better understand this problem.
![Capture+_2023-11-23-21-57-31](https://github.com/composer/packagist/assets/37945903/fd60961f-a8fc-44d4-907a-d4888e53eb5e)

**Here the link of my library on Github:** [github.com/richardsonoge/pdf-translator](https://github.com/richardsonoge/pdf-translator)",True,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1825469262,How can i update the version of my library correctly and remove the tag ignored warning message ?,stof,3,2009047745,2,1825469262,0,2009047745,2023-11-24T10:36:41Z,"have you tried clicking on the ""read more"" link ?

for a package that is in a VCS repo, you should not specify the `version` in your composer.json. Composer will *always* guess the version based on the git metadata and the explicit version can never help (as it will mark versions as invalid in case of mismatch and provide no benefit when it matches)",False,0,CONTRIBUTOR
https://api.github.com/repos/composer/packagist/issues/comments/1825605395,How can i update the version of my library correctly and remove the tag ignored warning message ?,richardsonoge,3,2009047745,3,1825605395,0,1825469262,2023-11-24T12:26:11Z,"> have you tried clicking on the ""read more"" link ?
> 
> for a package that is in a VCS repo, you should not specify the `version` in your composer.json. Composer will _always_ guess the version based on the git metadata and the explicit version can never help (as it will mark versions as invalid in case of mismatch and provide no benefit when it matches)

Thank you very much, the update has been done correctly. However, this problem still doesn't want to be solved ""Some tags were ignored because of a version mismatch in composer.json, read more.
View Last Update Log"" and when I click on Read more it displays this ""Found cached composer.json of richardsonoge/pdf-translator (1.0.2)
Reading composer.json of richardsonoge/pdf-translator (1.0.1)
Skipped tag 1.0.1, tag (1.0.1.0) does not match version (1.0.0.0) in composer.json
Found cached composer.json of richardsonoge/pdf-translator (1.0.0) Reading composer.json of richardsonoge/pdf-translator (master) 
Importing branch master (dev-master)"" ?

```
Found cached composer.json of richardsonoge/pdf-translator (1.0.2)
Reading composer.json of richardsonoge/pdf-translator (1.0.1)
Skipped tag 1.0.1, tag (1.0.1.0) does not match version (1.0.0.0) in composer.json
Found cached composer.json of richardsonoge/pdf-translator (1.0.0)
Reading composer.json of richardsonoge/pdf-translator (master)
Importing branch master (dev-master)
```",False,0,NONE
https://api.github.com/repos/composer/packagist/issues/comments/1825665728,How can i update the version of my library correctly and remove the tag ignored warning message ?,richardsonoge,3,2009047745,4,1825665728,0,1825605395,2023-11-24T13:17:28Z,"
Ok now the problem was been resolved.",False,0,NONE
https://api.github.com/repos/factor/factor/issues/2900,added a missing CODE OF CONDUCT file ,romitp4l,8,1957305607,1,1957305607,0,0,2023-10-23T14:26:56Z,"Adding a Code of Conduct file to your GitHub repository is a good practice for several reasons:

1. **Promotes Inclusivity**: A Code of Conduct sets clear expectations for respectful and inclusive behavior within your project's community. It helps ensure that contributors and participants are treated with respect and dignity, regardless of their background, identity, or beliefs.

2. **Fosters a Positive Environment**: It helps create a positive and welcoming environment for all participants. This can encourage more people to contribute and collaborate effectively.

3. **Reduces Conflict**: A Code of Conduct provides guidelines for resolving conflicts and disputes within your project. This can help prevent and manage difficult situations, ultimately improving the overall health of your community.

4. **Protects Your Community**: It establishes a framework for dealing with inappropriate behavior or harassment, making it clear that such behavior is not acceptable. This helps protect your community members from harmful situations.

5. **Supports Legal Protection**: Some jurisdictions and organizations require a Code of Conduct for open-source projects. Having one in place can offer legal protection for both project maintainers and participants.

6. **Signals Professionalism**: A well-crafted Code of Conduct demonstrates professionalism and a commitment to a safe and respectful environment for everyone involved in your project.

7. **GitHub Recommends It**: GitHub itself encourages open-source projects to include a Code of Conduct. They even provide a feature to add a Code of Conduct to your repository automatically when creating a new repository.

When adding a Code of Conduct to your GitHub repository, you can use established templates like the Contributor Covenant or the Community Covenant, or you can create a custom one tailored to your project's specific needs. Make sure to clearly communicate how violations of the Code of Conduct will be handled and who to contact in case of issues.

By adopting and enforcing a Code of Conduct, you're helping to create a more inclusive and harmonious community, which can contribute to the success and sustainability of your project.",True,0,NONE
https://api.github.com/repos/factor/factor/issues/comments/1775364012,added a missing CODE OF CONDUCT file ,razetime,8,1957305607,2,1775364012,0,1957305607,2023-10-23T14:42:49Z,why have you PRed a code of conduct without raising an issue or speaking with the community even once?,False,0,MEMBER
https://api.github.com/repos/factor/factor/issues/comments/1775416077,added a missing CODE OF CONDUCT file ,phred,8,1957305607,3,1775416077,0,1775364012,2023-10-23T15:06:09Z,"I've seen this pattern before, when a streamer or other organization runs a contest for ""contributing to open source"". Looking at @romitp4l's profile they opened ~60 such PRs on various repositories. This is noise, not signal.

A code of conduct might be a good idea for Factor, but I agree with @razetime that this needs to come from the community itself. There is no one-size-fits all CoC.
",False,0,CONTRIBUTOR
https://api.github.com/repos/factor/factor/issues/comments/1775546531,added a missing CODE OF CONDUCT file ,mrjbq7,8,1957305607,4,1775546531,0,1775416077,2023-10-23T16:14:16Z,"Perhaps we can discuss this as a community, I think the contents of this are in the spirit of our current moderation but we are not at a position to accept this PR. Thank you.",False,0,MEMBER
https://api.github.com/repos/factor/factor/issues/comments/1775551514,added a missing CODE OF CONDUCT file ,mrjbq7,8,1957305607,5,1775551514,0,1775546531,2023-10-23T16:17:04Z,"I think in light of the 60 similar PRs made by this user, I am going to mark this as hacktoberfest-spam. I do not believe this is well-intentioned.",False,0,MEMBER
https://api.github.com/repos/factor/factor/issues/comments/1775575039,added a missing CODE OF CONDUCT file ,romitp4l,8,1957305607,6,1775575039,0,1775551514,2023-10-23T16:30:50Z,"I am new to open source  and somewhat very exited , and someone just suggeated me and i was not able to  conclude its repercussions. 

I sincerely apologize 😔 for any inconvenience caused by my PR. I now understand that it might have been considered spam, and I will be more considerate in my future contributions. Thank you for your understanding.",False,0,NONE
https://api.github.com/repos/factor/factor/issues/comments/1775577277,added a missing CODE OF CONDUCT file ,romitp4l,8,1957305607,7,1775577277,0,1775575039,2023-10-23T16:32:06Z,"@razetime @phred @mrjbq7  sorry ,  and thanks for  positive  criticism. ",False,0,NONE
https://api.github.com/repos/factor/factor/issues/comments/1775642071,added a missing CODE OF CONDUCT file ,romitp4l,8,1957305607,8,1775642071,0,1775577277,2023-10-23T17:08:53Z,"
""Dear @mrjbq7 ,

 I'd like to clarify that I have also made genuine contributions to open source, and I'm committed to improving my approach in the future.

I kindly request the removal of the 'hacktoberfest-spam' and 'hacktoberfest-invalid' labels from my PR. I would also appreciate it if similar PRs by me that were marked with these labels could be reviewed in light of my genuine contributions.

Thank you for your consideration, and I'm looking forward to being a more responsible contributor in the open source community.


i have closed  the  PR 's of this type  by myself . here are some of my genuine and simple contributions.


	https://github.com/zero-to-mastery/Animation-Nation/pull/2289

	https://github.com/nikohoffren/fork-commit-merge/pull/1148

![Screenshot_2023-10-23_22_28_24](https://github.com/factor/factor/assets/85341342/de7aea0c-dd52-4821-b4b1-fc3ba3e83559)
![Screenshot_2023-10-23_22_28_56](https://github.com/factor/factor/assets/85341342/23aa1ed6-7938-4ef1-ade5-3e9c8d5b9059)
",False,0,NONE
https://api.github.com/repos/factor/factor/issues/comments/1775658004,added a missing CODE OF CONDUCT file ,mrjbq7,8,1957305607,9,1775658004,0,1775642071,2023-10-23T17:18:28Z,"Hi @romitp4l, I love open source, and I love contributors.  I don't know what motivates your particular interest in codes of conduct, or if this is just participation in HackSquad, but I don't want to encourage this kind of behavior. It is a burden for maintainers, and it is not in the spirit of Hacktoberfest.

We have a list of https://github.com/factor/factor/labels/hacktoberfest issues, and the original idea of hacktoberfest was not PR mining for t-shirts or whatever, but was to make substantial entry-level open-source contributions and hope that that continued into further community participation.

Thanks,",False,0,MEMBER
https://api.github.com/repos/factor/factor/issues/2904,"Parsing JSON value ""-0""",mrjbq7,3,1966006847,1,1966006847,0,0,2023-10-27T18:29:34Z,"This should work:

```factor
{ -0.0 } [ ""-0"" json> ] unit-test
```

Should match Javascript ``JSON.parse(""-0"")``

Noticed this Zig issue https://github.com/ziglang/zig/pull/17729",True,0,MEMBER
https://api.github.com/repos/factor/factor/issues/comments/1783771508,"Parsing JSON value ""-0""",razetime,3,1966006847,2,1783771508,0,1966006847,2023-10-28T10:25:48Z,i just added a special case for `-0` in the PR. Is that an alright way to handle it?,False,0,MEMBER
https://api.github.com/repos/factor/factor/issues/comments/1783833379,"Parsing JSON value ""-0""",mrjbq7,3,1966006847,3,1783833379,0,1783771508,2023-10-28T14:40:35Z,"I think that’s a perfectly fine way to do it, since we probably don’t want to change our math.parser for this case. Thank you!On Oct 28, 2023, at 3:25 AM, Raghu R ***@***.***> wrote:﻿
i just added a special case for -0 in the PR. Is that an alright way to handle it?

—Reply to this email directly, view it on GitHub, or unsubscribe.You are receiving this because you authored the thread.Message ID: ***@***.***>",False,0,MEMBER
https://api.github.com/repos/factor/factor/issues/comments/1783834740,"Parsing JSON value ""-0""",razetime,3,1966006847,4,1783834740,0,1783833379,2023-10-28T14:44:41Z,complete in [e79f02d](https://github.com/factor/factor/commit/e79f02d161fd939774e4ae5f681393b291f10535).,False,0,MEMBER
https://api.github.com/repos/factor/factor/issues/2909,Bit-arrays bug,nomennescio,4,1970711596,1,1970711596,0,0,2023-10-31T15:20:47Z,"```factor
M: bit-array equal?
    over bit-array? [ [ underlying>> ] bi@ sequence= ] [ 2drop f ] if ;
```

by not checking `length` this might accidentally compare equal",True,0,CONTRIBUTOR
https://api.github.com/repos/factor/factor/issues/comments/1787448861,Bit-arrays bug,mrjbq7,4,1970711596,2,1787448861,0,1970711596,2023-10-31T15:26:09Z,"``sequence=`` checks length, but perhaps you mean this should return ``t``:

```factor
IN: scratchpad 2 B{ 0b011 } bit-array boa 
               2 B{ 0b111 } bit-array boa = .
f
```
",False,0,MEMBER
https://api.github.com/repos/factor/factor/issues/comments/1787947516,Bit-arrays bug,nomennescio,4,1970711596,3,1787947516,0,1787448861,2023-10-31T19:58:50Z,"`sequence=` checks the length of the *underlying* byte array, but what's missing is the check on the bit array length:
```
3 B{ 0b0 } bit-array boa
2 B{ 0b0 } bit-array boa = .
t
```

Your example however shows a different issue as well.

The sequence comparison works well on *full* bytes, but not on partially used bytes.",False,0,CONTRIBUTOR
https://api.github.com/repos/factor/factor/issues/comments/1788073702,Bit-arrays bug,mrjbq7,4,1970711596,4,1788073702,0,1787947516,2023-10-31T21:39:11Z,"Okay two bugs!On Oct 31, 2023, at 12:59 PM, nomennescio ***@***.***> wrote:﻿
sequence= checks the length of the underlying byte array, but what's missing is the check on the bit array length:```
3 B{ 0b0 } bit-array boa
2 B{ 0b0 } bit-array boa = .
t


—Reply to this email directly, view it on GitHub, or unsubscribe.You are receiving this because you commented.Message ID: ***@***.***>",False,0,MEMBER
https://api.github.com/repos/factor/factor/issues/comments/1788344646,Bit-arrays bug,mrjbq7,4,1970711596,5,1788344646,0,1788073702,2023-11-01T03:19:56Z,Fixed in fd09fc222233e06d1f8c7a915a7a1d43e16456eb.,False,0,MEMBER
https://api.github.com/repos/factor/factor/issues/2910,calendar: do not call day-of-week twice in weekday?,blin,3,1972124259,1,1972124259,0,0,2023-11-01T10:43:59Z,"Calling `today weekday?` fails with 

```
Generic word year>> does not define a method for the fixnum class.
Dispatching on object: 3
```

Sorry for not including the tests, didn't have the time to figure how to do that yet.",True,0,CONTRIBUTOR
https://api.github.com/repos/factor/factor/issues/comments/1788786112,calendar: do not call day-of-week twice in weekday?,razetime,3,1972124259,2,1788786112,0,1972124259,2023-11-01T11:15:09Z,"if you do `""calendar"" edit-tests` in the listener it should open the file for you. Should be easy to understand unit tests through the `tools.test` vocab docs after that.

I will merge this once the regression test is added.",False,0,MEMBER
https://api.github.com/repos/factor/factor/issues/comments/1789448127,calendar: do not call day-of-week twice in weekday?,blin,3,1972124259,3,1789448127,0,1788786112,2023-11-01T18:27:33Z,"Done, please take another look.",False,0,CONTRIBUTOR
https://api.github.com/repos/factor/factor/issues/comments/1789502789,calendar: do not call day-of-week twice in weekday?,mrjbq7,3,1972124259,4,1789502789,0,1789448127,2023-11-01T19:08:13Z,"Awesome, thank you!!",False,0,MEMBER
https://api.github.com/repos/ReVanced/revanced-patches/issues/2470,feat(youtube): change default video sort order to 'sort by latest',Shane9248,8,2044991681,1,2044991681,0,0,2023-04-06T05:40:55Z,"### Application

YouTube ReVanced

### Issue

![Screenshot_20230406-110244~2](https://user-images.githubusercontent.com/83491863/230281386-f3d37c9c-2deb-4323-8ebe-380d29eef96a.png)

When u open the videos section of a channel it always sorts the videos by 'FOR u' fitler 

### Patch

It would be really helpful if we can get a option to always show videos by 'LATEST' filter by default so that we don't have to manually select the option everytime 

### Motivation

It makes the UX way better

### Acknowledgements

- [X] I have searched the existing issues and this is a new and no duplicate or related to another open issue.
- [X] I have written a short but informative title.
- [X] I filled out all of the requested information in this issue properly.",True,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985478,feat(youtube): change default video sort order to 'sort by latest',xDARKxDEVILx,8,2044991681,2,1858985478,0,2044991681,2023-04-06T15:42:10Z,"I have never seen thay ""for you"" button before! Does it appear on every channel? ",False,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985486,feat(youtube): change default video sort order to 'sort by latest',Shane9248,8,2044991681,3,1858985486,0,1858985478,2023-04-06T16:24:02Z,"> I have never seen thay ""for you"" button before! Does it appear on every channel? 

yes it is on every channel ..only just popped up a couple of days ago on official yt app too",False,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985493,feat(youtube): change default video sort order to 'sort by latest',xDARKxDEVILx,8,2044991681,4,1858985493,0,1858985486,2023-04-06T16:45:58Z,"> > I have never seen thay ""for you"" button before! Does it appear on every channel?
> 
> yes it is on every channel ..only just popped up a couple of days ago on official yt app too

It doesn't appear for me, maybe it will pop up for me later but for now I only have to ways to sort videos, and that ""for you "" button sounds weird and i don't want it too",False,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985500,feat(youtube): change default video sort order to 'sort by latest',Shane9248,8,2044991681,5,1858985500,0,1858985493,2023-04-06T17:22:32Z,"> > > I have never seen thay ""for you"" button before! Does it appear on every channel?
> > 
> > yes it is on every channel ..only just popped up a couple of days ago on official yt app too
> 
> It doesn't appear for me, maybe it will pop up for me later but for now I only have to ways to sort videos, and that ""for you "" button sounds weird and i don't want it too

google never fails to impress ..what really useful would be to bring back the sort by OLDEST filter instead they bring this which makes videos order completely random 🤷🏻‍♂️",False,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985511,feat(youtube): change default video sort order to 'sort by latest',xDARKxDEVILx,8,2044991681,6,1858985511,0,1858985500,2023-04-06T17:25:29Z,"
Exactly, we need sort by oldest back , the only reason i still have vanced is so i can use it 

",False,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985519,feat(youtube): change default video sort order to 'sort by latest',Temepest74,8,2044991681,7,1858985519,0,1858985511,2023-04-11T18:00:21Z,Still no patch for this? :(,False,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985525,feat(youtube): change default video sort order to 'sort by latest',Shane9248,8,2044991681,8,1858985525,0,1858985519,2023-04-11T20:42:35Z,"> Still no patch for this? :(

only been up for a week... it's probably been kept open so as to keep an eye on this",False,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985533,feat(youtube): change default video sort order to 'sort by latest',genesisrhapsodos98,8,2044991681,9,1858985533,0,1858985525,2023-04-19T05:59:14Z,This has been a major annoyance for me for the past few weeks too. Hopefully there's a patch for it soon.,False,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/2471,Sudden infinite buffering after watching for some time,muchisx,10,2044991682,1,2044991682,0,0,2023-04-13T04:19:48Z,"### Type

Error at runtime

### Bug description

During playback, after a random amount of time, the video stops playing and shows a loading circle (as if connection was lost), the player never reconnects and it gets stuck in an infinite loading/buffering black screen.

### Steps to reproduce

1. Play any video (better if its a long one, 10+min)
2. Wait
3. Infinite loading/buffer will appear randomly

### Relevant log output

```shell
It doesn't crash
```


### Screenshots or videos

_No response_

### Solution

There are a bunch of posts in reddit r/revancedapp outlining the same issue

### Additional context

_No response_

### Acknowledgements

- [ ] I have searched the existing issues and this is a new and no duplicate or related to another open issue.
- [X] I have written a short but informative title.
- [X] I filled out all of the requested information in this issue properly.",True,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985475,Sudden infinite buffering after watching for some time,oSumAtrIX,10,2044991682,2,1858985475,0,2044991682,2023-04-13T04:23:13Z,ReVanced/revanced-patches-template#1256,False,0,MEMBER
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985484,Sudden infinite buffering after watching for some time,Elias-Graf,10,2044991682,3,1858985484,0,1858985475,2023-04-13T09:37:16Z,@oSumAtrIX the problem just started occurring in the last 12 hours. Are you sure it is related to that older issue?,False,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985489,Sudden infinite buffering after watching for some time,oSumAtrIX,10,2044991682,4,1858985489,0,1858985484,2023-04-13T09:38:01Z,Yes I am certain.,False,0,MEMBER
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985498,Sudden infinite buffering after watching for some time,oSumAtrIX,10,2044991682,5,1858985498,0,1858985489,2023-04-13T09:38:50Z,You likely also did something wrong as playback is working once the fix is applied.,False,0,MEMBER
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985506,Sudden infinite buffering after watching for some time,Elias-Graf,10,2044991682,6,1858985506,0,1858985498,2023-04-13T09:43:51Z,"> You likely also did something wrong as playback is working once the fix is applied.

@oSumAtrIX I patched the app a few days ago, everything worked. It stopped working a few hours ago. I'm 100% certain. I repatched the app today with the latest release, same result.",False,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985510,Sudden infinite buffering after watching for some time,oSumAtrIX,10,2044991682,7,1858985510,0,1858985506,2023-04-13T09:45:27Z,"In that case please send a full recording of the following:

1. Close & open ReVanced Manager
2. Patch YouTube
4. Open it & showcase the issue",False,0,MEMBER
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985512,Sudden infinite buffering after watching for some time,Nathanwoodburn,10,2044991682,8,1858985512,0,1858985510,2023-04-13T11:05:42Z,I'm having the same issue. The last time I patched it was over 6 months ago. It just stopped working today. I've repatched it and still doesn't work. It will just start buffering,False,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985518,Sudden infinite buffering after watching for some time,Loadren,10,2044991682,9,1858985518,0,1858985512,2023-04-13T11:25:50Z,"Same error here.

Just repatched on 18.05.40 with :
`java -jar revanced-cli.jar -a youtube.apk -b revanced-patches.jar -i client-spoof -i custom-branding -i custom-video-speed  -i disable-auto-captions -i disable-player-popup-panels -i disable-shorts-on-startup -i downloads -i enable-wide-searchbar -i general-ads -i hide-floating-microphone-button -i microg-support -i minimized-playback -i remember-video-quality -i return-youtube-dislike -i sponsorblock -i theme -i video-ads -o Revanced.apk --exclusive -m int.apk`

Seems like it stops working after some time (~30 sec or 1 min) and keeps buffering. It also happens on Home Screen with autoplay.

https://user-images.githubusercontent.com/23261689/231744388-61e3aac2-cd8e-4c73-9431-fce8da933a30.mp4



",False,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985524,Sudden infinite buffering after watching for some time,marcelalani,10,2044991682,10,1858985524,0,1858985518,2023-04-13T11:28:11Z,"> I'm having the same issue. The last time I patched it was over 6 months ago. It just stopped working today. I've repatched it and still doesn't work. It will just start buffering

Patch a new apk with the ""spoof signature verification"" patch, make sure the setting is on in the app once it's done. This fixed the issue for me.
![Screenshot_20230413_232541](https://user-images.githubusercontent.com/8307088/231744758-355e6515-0d03-422b-b83e-f7b40ba864e6.jpg)
![Screenshot_20230413_232703](https://user-images.githubusercontent.com/8307088/231744996-bff352fc-d5ca-4e8e-b3ad-fc7f02c08d1a.jpg)

",False,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985535,Sudden infinite buffering after watching for some time,Nathanwoodburn,10,2044991682,11,1858985535,0,1858985524,2023-04-13T11:30:31Z,"> > I'm having the same issue. The last time I patched it was over 6 months ago. It just stopped working today. I've repatched it and still doesn't work. It will just start buffering
> 
> Patch a new apk with the ""spoof signature verification"" patch, make sure the setting is on in the app once it's done. This fixed the issue for me.

It has randomly started working again. I disabled and reenabled the spoofing a few times and it seems to have fixed it.",False,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/2472,Unlock Telegram Premium,Qaz-7,8,2044991685,1,2044991685,0,0,2023-04-01T05:08:58Z,"### Application

Telegram

### Issue

Unlock Telegram Premium features.

### Patch

Unlock premium features without subscribing to Telegram Premium

![Screenshot_20230401-090801_Telegram](https://user-images.githubusercontent.com/124310688/229266794-73f18113-7670-4f79-9fce-c9a348cded40.jpg)


### Motivation

Because, all the mod apks on the Internet are fake. Also, Telegram Premium offers many functions

### Acknowledgements

- [X] I have searched the existing issues and this is a new and no duplicate or related to another open issue.
- [X] I have written a short but informative title.
- [X] I filled out all of the requested information in this issue properly.",True,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985509,Unlock Telegram Premium,wolf-yuan-6115,8,2044991685,2,1858985509,0,2044991685,2023-04-01T05:14:16Z,"I don't think it will work, if you are looking for faster download speed, you can try MDgram",False,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985513,Unlock Telegram Premium,Qaz-7,8,2044991685,3,1858985513,0,1858985509,2023-04-01T05:15:00Z,Premium features can be unlocked.,False,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985516,Unlock Telegram Premium,reisxd,8,2044991685,4,1858985516,0,1858985513,2023-04-01T05:31:19Z,"The premium features are server-sided, not client sided.",False,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985523,Unlock Telegram Premium,Qaz-7,8,2044991685,5,1858985523,0,1858985516,2023-04-01T05:41:54Z,MDgram does not offer all features.,False,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985528,Unlock Telegram Premium,oSumAtrIX,8,2044991685,6,1858985528,0,1858985523,2023-04-01T08:41:51Z,Closing due to being locked by server.,False,0,MEMBER
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985538,Unlock Telegram Premium,Qaz-7,8,2044991685,7,1858985538,0,1858985528,2023-04-01T09:49:54Z,Subscribe to Telegram Premium and modify the Apk.Premium unlocked,False,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985543,Unlock Telegram Premium,oSumAtrIX,8,2044991685,8,1858985543,0,1858985538,2023-04-01T10:00:40Z,Works without modifying the app 👍,False,0,MEMBER
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985545,Unlock Telegram Premium,Qaz-7,8,2044991685,9,1858985545,0,1858985543,2023-04-01T10:06:46Z,You subscribe to unlock.You modify and share that APK.,False,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/2473,bug: YouTube videos stop playing after 30 seconds,theofficialgman,12,2044991686,1,2044991686,0,0,2023-03-11T04:40:31Z,"### Type

Error at runtime

### Bug description

Starting about 2-3 weeks ago YouTube videos would stop playing after about the first 20-30 seconds and will infinitely buffer. 

This did not happen on previous versions and seems to have been a change on YouTubes end (maybe they implemented some sort of server side detection).

Reinstalling and repatching does not fix it. The regular YouTube app does not display these issues.

### Steps to reproduce

Install v18.03.36 of YouTube.
Patch with non-root (spoof app version, video ads, microg, etc)
Play any video

### Relevant log output

```shell
None
```


### Screenshots or videos

_No response_

### Solution

_No response_

### Additional context

_No response_

### Acknowledgements

- [ ] I have searched the existing issues and this is a new and no duplicate or related to another open issue.
- [X] I have written a short but informative title.
- [X] I filled out all of the requested information in this issue properly.",True,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985522,bug: YouTube videos stop playing after 30 seconds,reisxd,12,2044991686,2,1858985522,0,2044991686,2023-03-11T04:41:28Z,Acknowledgements not met (dupe).,False,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985529,bug: YouTube videos stop playing after 30 seconds,theofficialgman,12,2044991686,3,1858985529,0,1858985522,2023-03-11T14:28:00Z,@reisxd umm no this is not a dupe. I search 3 months back of issues and did not see this reported. Please reopen or link the duplicated issue ,False,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985534,bug: YouTube videos stop playing after 30 seconds,reisxd,12,2044991686,4,1858985534,0,1858985529,2023-03-11T14:40:12Z,"> @reisxd umm no this is not a dupe. I search 3 months back of issues and did not see this reported. Please reopen or link the duplicated issue 

ReVanced/revanced-patches#981",False,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985539,bug: YouTube videos stop playing after 30 seconds,Xyur1,12,2044991686,5,1858985539,0,1858985534,2023-03-12T13:47:59Z,"> Acknowledgements not met (dupe).

what do you mean? ",False,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985542,bug: YouTube videos stop playing after 30 seconds,theofficialgman,12,2044991686,6,1858985542,0,1858985539,2023-03-15T18:00:50Z,"@reisxd @oSumAtrIX  I would appreciate a bug remaining OPEN at this repo even if it is an upstream problem.

Users typically don't search for closed bug reports as that usually indicates that the bug has been fixed which it has not.
At my own repos I keep the bug open and add a tag ""Upstream Bug""

https://github.com/microg/GmsCore/issues/1870",False,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985546,bug: YouTube videos stop playing after 30 seconds,reisxd,12,2044991686,7,1858985546,0,1858985542,2023-03-15T18:02:08Z,"> @reisxd I would appreciate a bug remaining OPEN at this repo even if it is an upstream problem.
> 
> Users typically don't search for closed bug reports as that usually indicates that the bug has been fixed which it has not.
> At my own repos I keep the bug open and add a tag ""Upstream Bug""
> 
> https://github.com/microg/GmsCore/issues/1870

Their fault for not searching properly. Also, the issue has been fixed.",False,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985550,bug: YouTube videos stop playing after 30 seconds,oSumAtrIX,12,2044991686,8,1858985550,0,1858985546,2023-03-15T18:06:41Z,This issue is deprecated in favour of https://github.com/revanced/revanced-patches/issues/1752.,False,0,MEMBER
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985554,bug: YouTube videos stop playing after 30 seconds,Cartman34,12,2044991686,9,1858985554,0,1858985550,2023-04-20T15:32:36Z,"I am experiencing the same issue with YT Revanced and i did not find any workaround here...
Please, could you explicitly tell us what to do to fix it ? With details ?

Something new happened, I updated MicroG (idk if this improved the situation...) and now the video is buffering, then stop, buffer another part of the video (the video is still stopped), then play it, then stop... There is no more continuous buffering, this is very annoying.",False,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985556,bug: YouTube videos stop playing after 30 seconds,LisoUseInAIKyrios,12,2044991686,10,1858985556,0,1858985554,2023-04-20T16:13:13Z,"How to fix:
- Patch using latest ReVanced release
- Patch the recommended version of YouTube
- _Patch using only the recommended patches_
- ensure `ReVanced Settings -> Misc -> Spoof app signature` is turned on

If it still does not work, then you are currently out of luck.
",False,0,CONTRIBUTOR
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985562,bug: YouTube videos stop playing after 30 seconds,Cartman34,12,2044991686,11,1858985562,0,1858985556,2023-04-20T16:31:41Z,"Thank you for your answer, but I never patched anything here, things seem not obvious...
I was using Revanced app downloaded from revanced.io, now the website is dead.
I checked everything was up to date using website revanced.net.
Then I downloaded the revanced manager, it seems to allow to patch YouTube (not revanced ?).
I selected recommended, but when I tap Install, I got an error because it's not a non-root app. I'm lost.",False,0,NONE
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985567,bug: YouTube videos stop playing after 30 seconds,LisoUseInAIKyrios,12,2044991686,12,1858985567,0,1858985562,2023-04-20T16:34:24Z,https://www.reddit.com/r/revancedapp/comments/xlcny9/revanced_manager_guide_for_dummies/,False,0,CONTRIBUTOR
https://api.github.com/repos/ReVanced/revanced-patches/issues/comments/1858985572,bug: YouTube videos stop playing after 30 seconds,oSumAtrIX,12,2044991686,13,1858985572,0,1858985567,2023-04-20T17:06:58Z,Neither revanced.io nor revanced.net are from us.,False,0,MEMBER
